{
  "best_global_step": 1830,
  "best_metric": 0.7220361687876758,
  "best_model_checkpoint": "./results_clora_20250705_233004/checkpoint-1830",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 1830,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "classification_loss": 6.029106140136719,
      "epoch": 0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6689748764038086,
      "orthogonal_weight": 0.1,
      "step": 0,
      "total_loss": 6.296003818511963,
      "weighted_orthogonal_loss": 0.2668974995613098
    },
    {
      "classification_loss": 5.26099967956543,
      "epoch": 0.003278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6689748764038086,
      "orthogonal_weight": 0.1,
      "step": 1,
      "total_loss": 5.527897357940674,
      "weighted_orthogonal_loss": 0.2668974995613098
    },
    {
      "classification_loss": 6.7860026359558105,
      "epoch": 0.006557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6683950424194336,
      "orthogonal_weight": 0.1,
      "step": 2,
      "total_loss": 7.052842140197754,
      "weighted_orthogonal_loss": 0.26683950424194336
    },
    {
      "classification_loss": 6.7634358406066895,
      "epoch": 0.009836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.667250871658325,
      "orthogonal_weight": 0.1,
      "step": 3,
      "total_loss": 7.030160903930664,
      "weighted_orthogonal_loss": 0.266725093126297
    },
    {
      "classification_loss": 7.246151447296143,
      "epoch": 0.013114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.665543556213379,
      "orthogonal_weight": 0.1,
      "step": 4,
      "total_loss": 7.5127058029174805,
      "weighted_orthogonal_loss": 0.2665543556213379
    },
    {
      "classification_loss": 5.674765586853027,
      "epoch": 0.01639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6632893085479736,
      "orthogonal_weight": 0.1,
      "step": 5,
      "total_loss": 5.941094398498535,
      "weighted_orthogonal_loss": 0.26632893085479736
    },
    {
      "classification_loss": 7.140424728393555,
      "epoch": 0.019672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.660460948944092,
      "orthogonal_weight": 0.1,
      "step": 6,
      "total_loss": 7.406470775604248,
      "weighted_orthogonal_loss": 0.26604610681533813
    },
    {
      "classification_loss": 7.132098197937012,
      "epoch": 0.022950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6571168899536133,
      "orthogonal_weight": 0.1,
      "step": 7,
      "total_loss": 7.397809982299805,
      "weighted_orthogonal_loss": 0.2657116949558258
    },
    {
      "classification_loss": 6.112251281738281,
      "epoch": 0.02622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6532886028289795,
      "orthogonal_weight": 0.1,
      "step": 8,
      "total_loss": 6.377580165863037,
      "weighted_orthogonal_loss": 0.26532885432243347
    },
    {
      "classification_loss": 6.752294540405273,
      "epoch": 0.029508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6489667892456055,
      "orthogonal_weight": 0.1,
      "step": 9,
      "total_loss": 7.017191410064697,
      "weighted_orthogonal_loss": 0.2648966908454895
    },
    {
      "classification_loss": 4.769307613372803,
      "epoch": 0.03278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.644219160079956,
      "orthogonal_weight": 0.1,
      "step": 10,
      "total_loss": 5.033729553222656,
      "weighted_orthogonal_loss": 0.26442191004753113
    },
    {
      "classification_loss": 6.934882164001465,
      "epoch": 0.036065573770491806,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6389694213867188,
      "orthogonal_weight": 0.1,
      "step": 11,
      "total_loss": 7.198779106140137,
      "weighted_orthogonal_loss": 0.2638969421386719
    },
    {
      "classification_loss": 6.747993469238281,
      "epoch": 0.03934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6334264278411865,
      "orthogonal_weight": 0.1,
      "step": 12,
      "total_loss": 7.011336326599121,
      "weighted_orthogonal_loss": 0.26334264874458313
    },
    {
      "classification_loss": 7.058483600616455,
      "epoch": 0.04262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.627656936645508,
      "orthogonal_weight": 0.1,
      "step": 13,
      "total_loss": 7.321249485015869,
      "weighted_orthogonal_loss": 0.26276570558547974
    },
    {
      "classification_loss": 6.772679328918457,
      "epoch": 0.04590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.62174129486084,
      "orthogonal_weight": 0.1,
      "step": 14,
      "total_loss": 7.034853458404541,
      "weighted_orthogonal_loss": 0.262174129486084
    },
    {
      "classification_loss": 5.077550411224365,
      "epoch": 0.04918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6157190799713135,
      "orthogonal_weight": 0.1,
      "step": 15,
      "total_loss": 5.339122295379639,
      "weighted_orthogonal_loss": 0.2615719139575958
    },
    {
      "classification_loss": 6.445642471313477,
      "epoch": 0.05245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.609454870223999,
      "orthogonal_weight": 0.1,
      "step": 16,
      "total_loss": 6.706587791442871,
      "weighted_orthogonal_loss": 0.26094549894332886
    },
    {
      "classification_loss": 5.5243353843688965,
      "epoch": 0.05573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6032156944274902,
      "orthogonal_weight": 0.1,
      "step": 17,
      "total_loss": 5.784657001495361,
      "weighted_orthogonal_loss": 0.26032158732414246
    },
    {
      "classification_loss": 7.282344818115234,
      "epoch": 0.05901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.596896171569824,
      "orthogonal_weight": 0.1,
      "step": 18,
      "total_loss": 7.54203462600708,
      "weighted_orthogonal_loss": 0.2596896290779114
    },
    {
      "classification_loss": 6.820548057556152,
      "epoch": 0.06229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5907387733459473,
      "orthogonal_weight": 0.1,
      "step": 19,
      "total_loss": 7.0796217918396,
      "weighted_orthogonal_loss": 0.2590738832950592
    },
    {
      "classification_loss": 6.7228899002075195,
      "epoch": 0.06557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5847160816192627,
      "orthogonal_weight": 0.1,
      "step": 20,
      "total_loss": 6.981361389160156,
      "weighted_orthogonal_loss": 0.25847160816192627
    },
    {
      "classification_loss": 5.326779365539551,
      "epoch": 0.06885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.578901767730713,
      "orthogonal_weight": 0.1,
      "step": 21,
      "total_loss": 5.584669589996338,
      "weighted_orthogonal_loss": 0.2578901946544647
    },
    {
      "classification_loss": 5.278411388397217,
      "epoch": 0.07213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.57309889793396,
      "orthogonal_weight": 0.1,
      "step": 22,
      "total_loss": 5.535721302032471,
      "weighted_orthogonal_loss": 0.2573098838329315
    },
    {
      "classification_loss": 6.287415504455566,
      "epoch": 0.07540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5674164295196533,
      "orthogonal_weight": 0.1,
      "step": 23,
      "total_loss": 6.544157028198242,
      "weighted_orthogonal_loss": 0.25674164295196533
    },
    {
      "classification_loss": 5.367364883422852,
      "epoch": 0.07868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5620079040527344,
      "orthogonal_weight": 0.1,
      "step": 24,
      "total_loss": 5.623565673828125,
      "weighted_orthogonal_loss": 0.25620079040527344
    },
    {
      "classification_loss": 5.69620418548584,
      "epoch": 0.08196721311475409,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.556762933731079,
      "orthogonal_weight": 0.1,
      "step": 25,
      "total_loss": 5.95188045501709,
      "weighted_orthogonal_loss": 0.2556762993335724
    },
    {
      "classification_loss": 5.254683971405029,
      "epoch": 0.08524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.551814556121826,
      "orthogonal_weight": 0.1,
      "step": 26,
      "total_loss": 5.5098652839660645,
      "weighted_orthogonal_loss": 0.2551814615726471
    },
    {
      "classification_loss": 5.507903099060059,
      "epoch": 0.08852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5470831394195557,
      "orthogonal_weight": 0.1,
      "step": 27,
      "total_loss": 5.762611389160156,
      "weighted_orthogonal_loss": 0.25470831990242004
    },
    {
      "classification_loss": 4.623619079589844,
      "epoch": 0.09180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5427157878875732,
      "orthogonal_weight": 0.1,
      "step": 28,
      "total_loss": 4.877890586853027,
      "weighted_orthogonal_loss": 0.25427159667015076
    },
    {
      "classification_loss": 6.627934455871582,
      "epoch": 0.09508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.538606643676758,
      "orthogonal_weight": 0.1,
      "step": 29,
      "total_loss": 6.8817949295043945,
      "weighted_orthogonal_loss": 0.2538606822490692
    },
    {
      "classification_loss": 4.975618839263916,
      "epoch": 0.09836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5349950790405273,
      "orthogonal_weight": 0.1,
      "step": 30,
      "total_loss": 5.229118347167969,
      "weighted_orthogonal_loss": 0.25349950790405273
    },
    {
      "classification_loss": 5.713532447814941,
      "epoch": 0.10163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.531794548034668,
      "orthogonal_weight": 0.1,
      "step": 31,
      "total_loss": 5.96671199798584,
      "weighted_orthogonal_loss": 0.2531794607639313
    },
    {
      "classification_loss": 5.490506649017334,
      "epoch": 0.10491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.529078483581543,
      "orthogonal_weight": 0.1,
      "step": 32,
      "total_loss": 5.743414402008057,
      "weighted_orthogonal_loss": 0.2529078423976898
    },
    {
      "classification_loss": 3.672903299331665,
      "epoch": 0.10819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.526867389678955,
      "orthogonal_weight": 0.1,
      "step": 33,
      "total_loss": 3.9255900382995605,
      "weighted_orthogonal_loss": 0.2526867389678955
    },
    {
      "classification_loss": 4.524785041809082,
      "epoch": 0.11147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5250084400177,
      "orthogonal_weight": 0.1,
      "step": 34,
      "total_loss": 4.777286052703857,
      "weighted_orthogonal_loss": 0.25250086188316345
    },
    {
      "classification_loss": 5.16352653503418,
      "epoch": 0.11475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5236823558807373,
      "orthogonal_weight": 0.1,
      "step": 35,
      "total_loss": 5.415894985198975,
      "weighted_orthogonal_loss": 0.2523682415485382
    },
    {
      "classification_loss": 4.898519515991211,
      "epoch": 0.1180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.522979497909546,
      "orthogonal_weight": 0.1,
      "step": 36,
      "total_loss": 5.150817394256592,
      "weighted_orthogonal_loss": 0.252297967672348
    },
    {
      "classification_loss": 5.681025505065918,
      "epoch": 0.12131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.522891044616699,
      "orthogonal_weight": 0.1,
      "step": 37,
      "total_loss": 5.933314800262451,
      "weighted_orthogonal_loss": 0.2522891163825989
    },
    {
      "classification_loss": 4.990190029144287,
      "epoch": 0.12459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.523538589477539,
      "orthogonal_weight": 0.1,
      "step": 38,
      "total_loss": 5.242543697357178,
      "weighted_orthogonal_loss": 0.25235387682914734
    },
    {
      "classification_loss": 4.978434085845947,
      "epoch": 0.12786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.524894952774048,
      "orthogonal_weight": 0.1,
      "step": 39,
      "total_loss": 5.230923652648926,
      "weighted_orthogonal_loss": 0.25248950719833374
    },
    {
      "classification_loss": 3.8018133640289307,
      "epoch": 0.13114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5269787311553955,
      "orthogonal_weight": 0.1,
      "step": 40,
      "total_loss": 4.054511070251465,
      "weighted_orthogonal_loss": 0.2526978850364685
    },
    {
      "classification_loss": 4.9732465744018555,
      "epoch": 0.13442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5297348499298096,
      "orthogonal_weight": 0.1,
      "step": 41,
      "total_loss": 5.22622013092041,
      "weighted_orthogonal_loss": 0.2529734969139099
    },
    {
      "classification_loss": 3.458460569381714,
      "epoch": 0.1377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5333282947540283,
      "orthogonal_weight": 0.1,
      "step": 42,
      "total_loss": 3.7117934226989746,
      "weighted_orthogonal_loss": 0.25333282351493835
    },
    {
      "classification_loss": 4.225672245025635,
      "epoch": 0.14098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5376477241516113,
      "orthogonal_weight": 0.1,
      "step": 43,
      "total_loss": 4.479436874389648,
      "weighted_orthogonal_loss": 0.2537647783756256
    },
    {
      "classification_loss": 3.6510958671569824,
      "epoch": 0.14426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5428504943847656,
      "orthogonal_weight": 0.1,
      "step": 44,
      "total_loss": 3.905380964279175,
      "weighted_orthogonal_loss": 0.25428506731987
    },
    {
      "classification_loss": 2.6419272422790527,
      "epoch": 0.14754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.548938274383545,
      "orthogonal_weight": 0.1,
      "step": 45,
      "total_loss": 2.8968210220336914,
      "weighted_orthogonal_loss": 0.25489383935928345
    },
    {
      "classification_loss": 3.2036118507385254,
      "epoch": 0.15081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.555878162384033,
      "orthogonal_weight": 0.1,
      "step": 46,
      "total_loss": 3.4591996669769287,
      "weighted_orthogonal_loss": 0.2555878162384033
    },
    {
      "classification_loss": 2.4892373085021973,
      "epoch": 0.1540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5638327598571777,
      "orthogonal_weight": 0.1,
      "step": 47,
      "total_loss": 2.7456204891204834,
      "weighted_orthogonal_loss": 0.2563832700252533
    },
    {
      "classification_loss": 2.441755771636963,
      "epoch": 0.15737704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5727598667144775,
      "orthogonal_weight": 0.1,
      "step": 48,
      "total_loss": 2.6990318298339844,
      "weighted_orthogonal_loss": 0.2572759985923767
    },
    {
      "classification_loss": 2.0744705200195312,
      "epoch": 0.16065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5827181339263916,
      "orthogonal_weight": 0.1,
      "step": 49,
      "total_loss": 2.332742214202881,
      "weighted_orthogonal_loss": 0.25827181339263916
    },
    {
      "classification_loss": 1.9794857501983643,
      "epoch": 0.16393442622950818,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5937271118164062,
      "orthogonal_weight": 0.1,
      "step": 50,
      "total_loss": 2.238858461380005,
      "weighted_orthogonal_loss": 0.2593727111816406
    },
    {
      "classification_loss": 1.3289541006088257,
      "epoch": 0.16721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6057732105255127,
      "orthogonal_weight": 0.1,
      "step": 51,
      "total_loss": 1.589531421661377,
      "weighted_orthogonal_loss": 0.26057732105255127
    },
    {
      "classification_loss": 1.186947226524353,
      "epoch": 0.17049180327868851,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6188149452209473,
      "orthogonal_weight": 0.1,
      "step": 52,
      "total_loss": 1.4488286972045898,
      "weighted_orthogonal_loss": 0.2618815004825592
    },
    {
      "classification_loss": 1.0085456371307373,
      "epoch": 0.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.632462501525879,
      "orthogonal_weight": 0.1,
      "step": 53,
      "total_loss": 1.271791934967041,
      "weighted_orthogonal_loss": 0.2632462680339813
    },
    {
      "classification_loss": 1.037002444267273,
      "epoch": 0.17704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6431357860565186,
      "orthogonal_weight": 0.1,
      "step": 54,
      "total_loss": 1.3013160228729248,
      "weighted_orthogonal_loss": 0.26431357860565186
    },
    {
      "classification_loss": 1.2069694995880127,
      "epoch": 0.18032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.648866653442383,
      "orthogonal_weight": 0.1,
      "step": 55,
      "total_loss": 1.4718561172485352,
      "weighted_orthogonal_loss": 0.26488667726516724
    },
    {
      "classification_loss": 1.1363950967788696,
      "epoch": 0.18360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6489028930664062,
      "orthogonal_weight": 0.1,
      "step": 56,
      "total_loss": 1.4012854099273682,
      "weighted_orthogonal_loss": 0.26489028334617615
    },
    {
      "classification_loss": 1.0314213037490845,
      "epoch": 0.18688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.644852876663208,
      "orthogonal_weight": 0.1,
      "step": 57,
      "total_loss": 1.2959065437316895,
      "weighted_orthogonal_loss": 0.26448529958724976
    },
    {
      "classification_loss": 0.9691781997680664,
      "epoch": 0.1901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6382951736450195,
      "orthogonal_weight": 0.1,
      "step": 58,
      "total_loss": 1.2330076694488525,
      "weighted_orthogonal_loss": 0.2638295292854309
    },
    {
      "classification_loss": 0.8740141987800598,
      "epoch": 0.19344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6283934116363525,
      "orthogonal_weight": 0.1,
      "step": 59,
      "total_loss": 1.136853575706482,
      "weighted_orthogonal_loss": 0.26283934712409973
    },
    {
      "classification_loss": 0.8204762935638428,
      "epoch": 0.19672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6152679920196533,
      "orthogonal_weight": 0.1,
      "step": 60,
      "total_loss": 1.082003116607666,
      "weighted_orthogonal_loss": 0.26152679324150085
    },
    {
      "classification_loss": 1.0283122062683105,
      "epoch": 0.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6010470390319824,
      "orthogonal_weight": 0.1,
      "step": 61,
      "total_loss": 1.288416862487793,
      "weighted_orthogonal_loss": 0.2601047158241272
    },
    {
      "classification_loss": 1.0024651288986206,
      "epoch": 0.20327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5887563228607178,
      "orthogonal_weight": 0.1,
      "step": 62,
      "total_loss": 1.2613407373428345,
      "weighted_orthogonal_loss": 0.25887563824653625
    },
    {
      "classification_loss": 1.0454679727554321,
      "epoch": 0.20655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5765154361724854,
      "orthogonal_weight": 0.1,
      "step": 63,
      "total_loss": 1.3031195402145386,
      "weighted_orthogonal_loss": 0.25765153765678406
    },
    {
      "classification_loss": 1.1010493040084839,
      "epoch": 0.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5662407875061035,
      "orthogonal_weight": 0.1,
      "step": 64,
      "total_loss": 1.3576734066009521,
      "weighted_orthogonal_loss": 0.2566240727901459
    },
    {
      "classification_loss": 0.9731278419494629,
      "epoch": 0.21311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.556680917739868,
      "orthogonal_weight": 0.1,
      "step": 65,
      "total_loss": 1.2287960052490234,
      "weighted_orthogonal_loss": 0.25566810369491577
    },
    {
      "classification_loss": 1.144801378250122,
      "epoch": 0.21639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.548336982727051,
      "orthogonal_weight": 0.1,
      "step": 66,
      "total_loss": 1.3996350765228271,
      "weighted_orthogonal_loss": 0.2548336982727051
    },
    {
      "classification_loss": 0.9935204386711121,
      "epoch": 0.21967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5415260791778564,
      "orthogonal_weight": 0.1,
      "step": 67,
      "total_loss": 1.2476730346679688,
      "weighted_orthogonal_loss": 0.2541526257991791
    },
    {
      "classification_loss": 0.9687477350234985,
      "epoch": 0.22295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5360910892486572,
      "orthogonal_weight": 0.1,
      "step": 68,
      "total_loss": 1.2223567962646484,
      "weighted_orthogonal_loss": 0.2536091208457947
    },
    {
      "classification_loss": 1.00104820728302,
      "epoch": 0.2262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.531756639480591,
      "orthogonal_weight": 0.1,
      "step": 69,
      "total_loss": 1.2542238235473633,
      "weighted_orthogonal_loss": 0.25317567586898804
    },
    {
      "classification_loss": 0.9809482097625732,
      "epoch": 0.22950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5284628868103027,
      "orthogonal_weight": 0.1,
      "step": 70,
      "total_loss": 1.2337944507598877,
      "weighted_orthogonal_loss": 0.25284630060195923
    },
    {
      "classification_loss": 1.0222573280334473,
      "epoch": 0.23278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5263774394989014,
      "orthogonal_weight": 0.1,
      "step": 71,
      "total_loss": 1.2748950719833374,
      "weighted_orthogonal_loss": 0.25263774394989014
    },
    {
      "classification_loss": 0.773695707321167,
      "epoch": 0.2360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5249032974243164,
      "orthogonal_weight": 0.1,
      "step": 72,
      "total_loss": 1.0261859893798828,
      "weighted_orthogonal_loss": 0.2524903416633606
    },
    {
      "classification_loss": 0.8191356658935547,
      "epoch": 0.23934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.52418851852417,
      "orthogonal_weight": 0.1,
      "step": 73,
      "total_loss": 1.0715545415878296,
      "weighted_orthogonal_loss": 0.2524188458919525
    },
    {
      "classification_loss": 0.8136652112007141,
      "epoch": 0.24262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.519164800643921,
      "orthogonal_weight": 0.1,
      "step": 74,
      "total_loss": 1.0655816793441772,
      "weighted_orthogonal_loss": 0.2519164979457855
    },
    {
      "classification_loss": 0.9791576266288757,
      "epoch": 0.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5093865394592285,
      "orthogonal_weight": 0.1,
      "step": 75,
      "total_loss": 1.2300963401794434,
      "weighted_orthogonal_loss": 0.25093865394592285
    },
    {
      "classification_loss": 0.7410611510276794,
      "epoch": 0.24918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5000650882720947,
      "orthogonal_weight": 0.1,
      "step": 76,
      "total_loss": 0.99106764793396,
      "weighted_orthogonal_loss": 0.2500065267086029
    },
    {
      "classification_loss": 0.6837482452392578,
      "epoch": 0.25245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4890193939208984,
      "orthogonal_weight": 0.1,
      "step": 77,
      "total_loss": 0.9326502084732056,
      "weighted_orthogonal_loss": 0.24890194833278656
    },
    {
      "classification_loss": 0.8047066926956177,
      "epoch": 0.25573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.475247383117676,
      "orthogonal_weight": 0.1,
      "step": 78,
      "total_loss": 1.0522314310073853,
      "weighted_orthogonal_loss": 0.24752473831176758
    },
    {
      "classification_loss": 0.837968647480011,
      "epoch": 0.25901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4596540927886963,
      "orthogonal_weight": 0.1,
      "step": 79,
      "total_loss": 1.0839340686798096,
      "weighted_orthogonal_loss": 0.2459654062986374
    },
    {
      "classification_loss": 0.788935124874115,
      "epoch": 0.26229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4406421184539795,
      "orthogonal_weight": 0.1,
      "step": 80,
      "total_loss": 1.0329992771148682,
      "weighted_orthogonal_loss": 0.24406421184539795
    },
    {
      "classification_loss": 0.8450242280960083,
      "epoch": 0.26557377049180325,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4179203510284424,
      "orthogonal_weight": 0.1,
      "step": 81,
      "total_loss": 1.0868163108825684,
      "weighted_orthogonal_loss": 0.24179203808307648
    },
    {
      "classification_loss": 0.766061007976532,
      "epoch": 0.26885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3968160152435303,
      "orthogonal_weight": 0.1,
      "step": 82,
      "total_loss": 1.0057425498962402,
      "weighted_orthogonal_loss": 0.23968160152435303
    },
    {
      "classification_loss": 0.7939802408218384,
      "epoch": 0.2721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3748397827148438,
      "orthogonal_weight": 0.1,
      "step": 83,
      "total_loss": 1.0314642190933228,
      "weighted_orthogonal_loss": 0.23748397827148438
    },
    {
      "classification_loss": 0.7005400657653809,
      "epoch": 0.2754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3529064655303955,
      "orthogonal_weight": 0.1,
      "step": 84,
      "total_loss": 0.9358307123184204,
      "weighted_orthogonal_loss": 0.23529064655303955
    },
    {
      "classification_loss": 0.8697884678840637,
      "epoch": 0.2786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3332266807556152,
      "orthogonal_weight": 0.1,
      "step": 85,
      "total_loss": 1.1031111478805542,
      "weighted_orthogonal_loss": 0.23332266509532928
    },
    {
      "classification_loss": 0.895841121673584,
      "epoch": 0.2819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.315654754638672,
      "orthogonal_weight": 0.1,
      "step": 86,
      "total_loss": 1.1274065971374512,
      "weighted_orthogonal_loss": 0.2315654754638672
    },
    {
      "classification_loss": 0.8096129894256592,
      "epoch": 0.28524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.300110101699829,
      "orthogonal_weight": 0.1,
      "step": 87,
      "total_loss": 1.0396239757537842,
      "weighted_orthogonal_loss": 0.2300110161304474
    },
    {
      "classification_loss": 0.8452727794647217,
      "epoch": 0.28852459016393445,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.28566312789917,
      "orthogonal_weight": 0.1,
      "step": 88,
      "total_loss": 1.0738390684127808,
      "weighted_orthogonal_loss": 0.22856631875038147
    },
    {
      "classification_loss": 0.8693258166313171,
      "epoch": 0.29180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2725987434387207,
      "orthogonal_weight": 0.1,
      "step": 89,
      "total_loss": 1.096585750579834,
      "weighted_orthogonal_loss": 0.22725987434387207
    },
    {
      "classification_loss": 0.7535688877105713,
      "epoch": 0.29508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2609405517578125,
      "orthogonal_weight": 0.1,
      "step": 90,
      "total_loss": 0.9796629548072815,
      "weighted_orthogonal_loss": 0.226094052195549
    },
    {
      "classification_loss": 0.6669889688491821,
      "epoch": 0.2983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.250796318054199,
      "orthogonal_weight": 0.1,
      "step": 91,
      "total_loss": 0.89206862449646,
      "weighted_orthogonal_loss": 0.22507964074611664
    },
    {
      "classification_loss": 0.902565598487854,
      "epoch": 0.3016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2356839179992676,
      "orthogonal_weight": 0.1,
      "step": 92,
      "total_loss": 1.1261340379714966,
      "weighted_orthogonal_loss": 0.223568394780159
    },
    {
      "classification_loss": 0.8264880180358887,
      "epoch": 0.30491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2209060192108154,
      "orthogonal_weight": 0.1,
      "step": 93,
      "total_loss": 1.0485786199569702,
      "weighted_orthogonal_loss": 0.22209060192108154
    },
    {
      "classification_loss": 0.8139362931251526,
      "epoch": 0.3081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2047553062438965,
      "orthogonal_weight": 0.1,
      "step": 94,
      "total_loss": 1.0344117879867554,
      "weighted_orthogonal_loss": 0.22047553956508636
    },
    {
      "classification_loss": 0.6911259889602661,
      "epoch": 0.3114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1828343868255615,
      "orthogonal_weight": 0.1,
      "step": 95,
      "total_loss": 0.9094094038009644,
      "weighted_orthogonal_loss": 0.21828344464302063
    },
    {
      "classification_loss": 0.7275919914245605,
      "epoch": 0.31475409836065577,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1578385829925537,
      "orthogonal_weight": 0.1,
      "step": 96,
      "total_loss": 0.943375825881958,
      "weighted_orthogonal_loss": 0.21578386425971985
    },
    {
      "classification_loss": 0.6946571469306946,
      "epoch": 0.3180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.133897542953491,
      "orthogonal_weight": 0.1,
      "step": 97,
      "total_loss": 0.9080469012260437,
      "weighted_orthogonal_loss": 0.21338975429534912
    },
    {
      "classification_loss": 0.7733399271965027,
      "epoch": 0.32131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1062653064727783,
      "orthogonal_weight": 0.1,
      "step": 98,
      "total_loss": 0.9839664697647095,
      "weighted_orthogonal_loss": 0.2106265276670456
    },
    {
      "classification_loss": 0.6981164216995239,
      "epoch": 0.32459016393442625,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.080247640609741,
      "orthogonal_weight": 0.1,
      "step": 99,
      "total_loss": 0.9061411619186401,
      "weighted_orthogonal_loss": 0.2080247700214386
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 6.185621738433838,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3925,
      "step": 100
    },
    {
      "classification_loss": 0.7426848411560059,
      "epoch": 0.32786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.055699586868286,
      "orthogonal_weight": 0.1,
      "step": 100,
      "total_loss": 0.9482548236846924,
      "weighted_orthogonal_loss": 0.20556996762752533
    },
    {
      "classification_loss": 0.6891850829124451,
      "epoch": 0.33114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.029672384262085,
      "orthogonal_weight": 0.1,
      "step": 101,
      "total_loss": 0.8921523094177246,
      "weighted_orthogonal_loss": 0.20296724140644073
    },
    {
      "classification_loss": 0.7061011791229248,
      "epoch": 0.3344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.0059235095977783,
      "orthogonal_weight": 0.1,
      "step": 102,
      "total_loss": 0.9066935181617737,
      "weighted_orthogonal_loss": 0.20059235394001007
    },
    {
      "classification_loss": 0.7441895008087158,
      "epoch": 0.3377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9799668788909912,
      "orthogonal_weight": 0.1,
      "step": 103,
      "total_loss": 0.942186176776886,
      "weighted_orthogonal_loss": 0.19799669086933136
    },
    {
      "classification_loss": 0.7127572894096375,
      "epoch": 0.34098360655737703,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9559729099273682,
      "orthogonal_weight": 0.1,
      "step": 104,
      "total_loss": 0.9083545804023743,
      "weighted_orthogonal_loss": 0.19559729099273682
    },
    {
      "classification_loss": 0.6998700499534607,
      "epoch": 0.3442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9322149753570557,
      "orthogonal_weight": 0.1,
      "step": 105,
      "total_loss": 0.8930915594100952,
      "weighted_orthogonal_loss": 0.19322149455547333
    },
    {
      "classification_loss": 0.7448074221611023,
      "epoch": 0.3475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9066753387451172,
      "orthogonal_weight": 0.1,
      "step": 106,
      "total_loss": 0.9354749917984009,
      "weighted_orthogonal_loss": 0.1906675398349762
    },
    {
      "classification_loss": 0.6869522333145142,
      "epoch": 0.35081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8818331956863403,
      "orthogonal_weight": 0.1,
      "step": 107,
      "total_loss": 0.8751355409622192,
      "weighted_orthogonal_loss": 0.18818332254886627
    },
    {
      "classification_loss": 0.6886175870895386,
      "epoch": 0.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8586485385894775,
      "orthogonal_weight": 0.1,
      "step": 108,
      "total_loss": 0.8744824528694153,
      "weighted_orthogonal_loss": 0.18586485087871552
    },
    {
      "classification_loss": 0.7040539979934692,
      "epoch": 0.35737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.835504174232483,
      "orthogonal_weight": 0.1,
      "step": 109,
      "total_loss": 0.8876044154167175,
      "weighted_orthogonal_loss": 0.1835504174232483
    },
    {
      "classification_loss": 0.7814279794692993,
      "epoch": 0.36065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8076725006103516,
      "orthogonal_weight": 0.1,
      "step": 110,
      "total_loss": 0.9621952176094055,
      "weighted_orthogonal_loss": 0.1807672530412674
    },
    {
      "classification_loss": 0.7390244603157043,
      "epoch": 0.3639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7812973260879517,
      "orthogonal_weight": 0.1,
      "step": 111,
      "total_loss": 0.9171541929244995,
      "weighted_orthogonal_loss": 0.17812973260879517
    },
    {
      "classification_loss": 0.7582592368125916,
      "epoch": 0.36721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7543021440505981,
      "orthogonal_weight": 0.1,
      "step": 112,
      "total_loss": 0.9336894750595093,
      "weighted_orthogonal_loss": 0.17543022334575653
    },
    {
      "classification_loss": 0.7349966764450073,
      "epoch": 0.3704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7262160778045654,
      "orthogonal_weight": 0.1,
      "step": 113,
      "total_loss": 0.9076182842254639,
      "weighted_orthogonal_loss": 0.17262160778045654
    },
    {
      "classification_loss": 0.7470751404762268,
      "epoch": 0.3737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.697990894317627,
      "orthogonal_weight": 0.1,
      "step": 114,
      "total_loss": 0.9168742299079895,
      "weighted_orthogonal_loss": 0.1697990894317627
    },
    {
      "classification_loss": 0.7774783968925476,
      "epoch": 0.3770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.668585181236267,
      "orthogonal_weight": 0.1,
      "step": 115,
      "total_loss": 0.9443368911743164,
      "weighted_orthogonal_loss": 0.1668585240840912
    },
    {
      "classification_loss": 0.7047059535980225,
      "epoch": 0.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.641814947128296,
      "orthogonal_weight": 0.1,
      "step": 116,
      "total_loss": 0.8688874244689941,
      "weighted_orthogonal_loss": 0.16418150067329407
    },
    {
      "classification_loss": 0.6888832449913025,
      "epoch": 0.3836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.6151257753372192,
      "orthogonal_weight": 0.1,
      "step": 117,
      "total_loss": 0.8503957986831665,
      "weighted_orthogonal_loss": 0.1615125834941864
    },
    {
      "classification_loss": 0.6846457719802856,
      "epoch": 0.38688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5903894901275635,
      "orthogonal_weight": 0.1,
      "step": 118,
      "total_loss": 0.843684732913971,
      "weighted_orthogonal_loss": 0.1590389460325241
    },
    {
      "classification_loss": 0.7355442643165588,
      "epoch": 0.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5673773288726807,
      "orthogonal_weight": 0.1,
      "step": 119,
      "total_loss": 0.8922820091247559,
      "weighted_orthogonal_loss": 0.15673772990703583
    },
    {
      "classification_loss": 0.7269623875617981,
      "epoch": 0.39344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5465493202209473,
      "orthogonal_weight": 0.1,
      "step": 120,
      "total_loss": 0.8816173076629639,
      "weighted_orthogonal_loss": 0.15465493500232697
    },
    {
      "classification_loss": 0.7183887362480164,
      "epoch": 0.39672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5278308391571045,
      "orthogonal_weight": 0.1,
      "step": 121,
      "total_loss": 0.8711718320846558,
      "weighted_orthogonal_loss": 0.1527830809354782
    },
    {
      "classification_loss": 0.7033119797706604,
      "epoch": 0.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5105900764465332,
      "orthogonal_weight": 0.1,
      "step": 122,
      "total_loss": 0.8543710112571716,
      "weighted_orthogonal_loss": 0.15105901658535004
    },
    {
      "classification_loss": 0.7219618558883667,
      "epoch": 0.40327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4942139387130737,
      "orthogonal_weight": 0.1,
      "step": 123,
      "total_loss": 0.8713832497596741,
      "weighted_orthogonal_loss": 0.14942139387130737
    },
    {
      "classification_loss": 0.7120789289474487,
      "epoch": 0.4065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4757157564163208,
      "orthogonal_weight": 0.1,
      "step": 124,
      "total_loss": 0.8596504926681519,
      "weighted_orthogonal_loss": 0.14757157862186432
    },
    {
      "classification_loss": 0.7315850853919983,
      "epoch": 0.4098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.459177017211914,
      "orthogonal_weight": 0.1,
      "step": 125,
      "total_loss": 0.8775027990341187,
      "weighted_orthogonal_loss": 0.14591769874095917
    },
    {
      "classification_loss": 0.6936371326446533,
      "epoch": 0.4131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4402127265930176,
      "orthogonal_weight": 0.1,
      "step": 126,
      "total_loss": 0.8376584053039551,
      "weighted_orthogonal_loss": 0.14402127265930176
    },
    {
      "classification_loss": 0.718295156955719,
      "epoch": 0.4163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4218240976333618,
      "orthogonal_weight": 0.1,
      "step": 127,
      "total_loss": 0.8604775667190552,
      "weighted_orthogonal_loss": 0.14218240976333618
    },
    {
      "classification_loss": 0.7113460898399353,
      "epoch": 0.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4018245935440063,
      "orthogonal_weight": 0.1,
      "step": 128,
      "total_loss": 0.851528525352478,
      "weighted_orthogonal_loss": 0.1401824653148651
    },
    {
      "classification_loss": 0.6943801045417786,
      "epoch": 0.42295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3820618391036987,
      "orthogonal_weight": 0.1,
      "step": 129,
      "total_loss": 0.8325862884521484,
      "weighted_orthogonal_loss": 0.13820618391036987
    },
    {
      "classification_loss": 0.7153773903846741,
      "epoch": 0.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3630012273788452,
      "orthogonal_weight": 0.1,
      "step": 130,
      "total_loss": 0.8516775369644165,
      "weighted_orthogonal_loss": 0.13630013167858124
    },
    {
      "classification_loss": 0.7149412631988525,
      "epoch": 0.42950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3447939157485962,
      "orthogonal_weight": 0.1,
      "step": 131,
      "total_loss": 0.8494206666946411,
      "weighted_orthogonal_loss": 0.13447938859462738
    },
    {
      "classification_loss": 0.6908293962478638,
      "epoch": 0.43278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3265150785446167,
      "orthogonal_weight": 0.1,
      "step": 132,
      "total_loss": 0.8234809041023254,
      "weighted_orthogonal_loss": 0.13265150785446167
    },
    {
      "classification_loss": 0.7326231598854065,
      "epoch": 0.4360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3080021142959595,
      "orthogonal_weight": 0.1,
      "step": 133,
      "total_loss": 0.8634233474731445,
      "weighted_orthogonal_loss": 0.13080021739006042
    },
    {
      "classification_loss": 0.757449746131897,
      "epoch": 0.43934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2909541130065918,
      "orthogonal_weight": 0.1,
      "step": 134,
      "total_loss": 0.8865451812744141,
      "weighted_orthogonal_loss": 0.1290954202413559
    },
    {
      "classification_loss": 0.7170520424842834,
      "epoch": 0.4426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2747467756271362,
      "orthogonal_weight": 0.1,
      "step": 135,
      "total_loss": 0.8445267081260681,
      "weighted_orthogonal_loss": 0.12747468054294586
    },
    {
      "classification_loss": 0.7196593880653381,
      "epoch": 0.4459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2603119611740112,
      "orthogonal_weight": 0.1,
      "step": 136,
      "total_loss": 0.8456906080245972,
      "weighted_orthogonal_loss": 0.12603120505809784
    },
    {
      "classification_loss": 0.712405264377594,
      "epoch": 0.4491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.244301199913025,
      "orthogonal_weight": 0.1,
      "step": 137,
      "total_loss": 0.8368353843688965,
      "weighted_orthogonal_loss": 0.12443011999130249
    },
    {
      "classification_loss": 0.7355287671089172,
      "epoch": 0.4524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2262957096099854,
      "orthogonal_weight": 0.1,
      "step": 138,
      "total_loss": 0.8581583499908447,
      "weighted_orthogonal_loss": 0.1226295754313469
    },
    {
      "classification_loss": 0.7072960734367371,
      "epoch": 0.4557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2101514339447021,
      "orthogonal_weight": 0.1,
      "step": 139,
      "total_loss": 0.8283112049102783,
      "weighted_orthogonal_loss": 0.12101514637470245
    },
    {
      "classification_loss": 0.6731440424919128,
      "epoch": 0.45901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1936216354370117,
      "orthogonal_weight": 0.1,
      "step": 140,
      "total_loss": 0.792506217956543,
      "weighted_orthogonal_loss": 0.11936216801404953
    },
    {
      "classification_loss": 0.7076795101165771,
      "epoch": 0.46229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.17788565158844,
      "orthogonal_weight": 0.1,
      "step": 141,
      "total_loss": 0.8254680633544922,
      "weighted_orthogonal_loss": 0.11778856813907623
    },
    {
      "classification_loss": 0.7777341604232788,
      "epoch": 0.46557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1615368127822876,
      "orthogonal_weight": 0.1,
      "step": 142,
      "total_loss": 0.8938878178596497,
      "weighted_orthogonal_loss": 0.11615367978811264
    },
    {
      "classification_loss": 0.729986310005188,
      "epoch": 0.46885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1454901695251465,
      "orthogonal_weight": 0.1,
      "step": 143,
      "total_loss": 0.8445353507995605,
      "weighted_orthogonal_loss": 0.11454901844263077
    },
    {
      "classification_loss": 0.7311764359474182,
      "epoch": 0.4721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.129646897315979,
      "orthogonal_weight": 0.1,
      "step": 144,
      "total_loss": 0.8441411256790161,
      "weighted_orthogonal_loss": 0.1129646897315979
    },
    {
      "classification_loss": 0.6491072773933411,
      "epoch": 0.47540983606557374,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1137056350708008,
      "orthogonal_weight": 0.1,
      "step": 145,
      "total_loss": 0.7604778409004211,
      "weighted_orthogonal_loss": 0.11137056350708008
    },
    {
      "classification_loss": 0.7160710692405701,
      "epoch": 0.4786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.099495530128479,
      "orthogonal_weight": 0.1,
      "step": 146,
      "total_loss": 0.8260205984115601,
      "weighted_orthogonal_loss": 0.10994955152273178
    },
    {
      "classification_loss": 0.727759838104248,
      "epoch": 0.4819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0856809616088867,
      "orthogonal_weight": 0.1,
      "step": 147,
      "total_loss": 0.8363279104232788,
      "weighted_orthogonal_loss": 0.10856809467077255
    },
    {
      "classification_loss": 0.7034668326377869,
      "epoch": 0.4852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0707390308380127,
      "orthogonal_weight": 0.1,
      "step": 148,
      "total_loss": 0.8105407357215881,
      "weighted_orthogonal_loss": 0.10707390308380127
    },
    {
      "classification_loss": 0.7194979190826416,
      "epoch": 0.4885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0541177988052368,
      "orthogonal_weight": 0.1,
      "step": 149,
      "total_loss": 0.8249096870422363,
      "weighted_orthogonal_loss": 0.10541178286075592
    },
    {
      "classification_loss": 0.7147797346115112,
      "epoch": 0.4918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0390430688858032,
      "orthogonal_weight": 0.1,
      "step": 150,
      "total_loss": 0.8186840415000916,
      "weighted_orthogonal_loss": 0.10390430688858032
    },
    {
      "classification_loss": 0.7428256869316101,
      "epoch": 0.49508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0247352123260498,
      "orthogonal_weight": 0.1,
      "step": 151,
      "total_loss": 0.8452991843223572,
      "weighted_orthogonal_loss": 0.10247351974248886
    },
    {
      "classification_loss": 0.7292930483818054,
      "epoch": 0.49836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0122216939926147,
      "orthogonal_weight": 0.1,
      "step": 152,
      "total_loss": 0.8305152058601379,
      "weighted_orthogonal_loss": 0.10122217237949371
    },
    {
      "classification_loss": 0.7249622344970703,
      "epoch": 0.5016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9987656474113464,
      "orthogonal_weight": 0.1,
      "step": 153,
      "total_loss": 0.8248388171195984,
      "weighted_orthogonal_loss": 0.09987656772136688
    },
    {
      "classification_loss": 0.7035542726516724,
      "epoch": 0.5049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9839968085289001,
      "orthogonal_weight": 0.1,
      "step": 154,
      "total_loss": 0.8019539713859558,
      "weighted_orthogonal_loss": 0.09839968383312225
    },
    {
      "classification_loss": 0.6589342355728149,
      "epoch": 0.5081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9711233973503113,
      "orthogonal_weight": 0.1,
      "step": 155,
      "total_loss": 0.7560465931892395,
      "weighted_orthogonal_loss": 0.09711234271526337
    },
    {
      "classification_loss": 0.7039651274681091,
      "epoch": 0.5114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9561624526977539,
      "orthogonal_weight": 0.1,
      "step": 156,
      "total_loss": 0.7995813488960266,
      "weighted_orthogonal_loss": 0.09561624377965927
    },
    {
      "classification_loss": 0.7236469984054565,
      "epoch": 0.5147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9427283406257629,
      "orthogonal_weight": 0.1,
      "step": 157,
      "total_loss": 0.8179198503494263,
      "weighted_orthogonal_loss": 0.09427283704280853
    },
    {
      "classification_loss": 0.7276714444160461,
      "epoch": 0.5180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9287170767784119,
      "orthogonal_weight": 0.1,
      "step": 158,
      "total_loss": 0.8205431699752808,
      "weighted_orthogonal_loss": 0.09287171065807343
    },
    {
      "classification_loss": 0.7140398025512695,
      "epoch": 0.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9148684740066528,
      "orthogonal_weight": 0.1,
      "step": 159,
      "total_loss": 0.8055266737937927,
      "weighted_orthogonal_loss": 0.0914868488907814
    },
    {
      "classification_loss": 0.6990319490432739,
      "epoch": 0.5245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9020745158195496,
      "orthogonal_weight": 0.1,
      "step": 160,
      "total_loss": 0.7892394065856934,
      "weighted_orthogonal_loss": 0.09020745009183884
    },
    {
      "classification_loss": 0.6984525918960571,
      "epoch": 0.5278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8891884684562683,
      "orthogonal_weight": 0.1,
      "step": 161,
      "total_loss": 0.7873714566230774,
      "weighted_orthogonal_loss": 0.08891884982585907
    },
    {
      "classification_loss": 0.7134472727775574,
      "epoch": 0.5311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8737286925315857,
      "orthogonal_weight": 0.1,
      "step": 162,
      "total_loss": 0.8008201122283936,
      "weighted_orthogonal_loss": 0.08737286925315857
    },
    {
      "classification_loss": 0.7060546875,
      "epoch": 0.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8575027585029602,
      "orthogonal_weight": 0.1,
      "step": 163,
      "total_loss": 0.7918049693107605,
      "weighted_orthogonal_loss": 0.0857502743601799
    },
    {
      "classification_loss": 0.7144131064414978,
      "epoch": 0.5377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8400660753250122,
      "orthogonal_weight": 0.1,
      "step": 164,
      "total_loss": 0.798419713973999,
      "weighted_orthogonal_loss": 0.08400660753250122
    },
    {
      "classification_loss": 0.6880045533180237,
      "epoch": 0.5409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8225589394569397,
      "orthogonal_weight": 0.1,
      "step": 165,
      "total_loss": 0.7702604532241821,
      "weighted_orthogonal_loss": 0.08225589245557785
    },
    {
      "classification_loss": 0.746560275554657,
      "epoch": 0.5442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8071876168251038,
      "orthogonal_weight": 0.1,
      "step": 166,
      "total_loss": 0.8272790312767029,
      "weighted_orthogonal_loss": 0.0807187631726265
    },
    {
      "classification_loss": 0.7193000316619873,
      "epoch": 0.5475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7937963604927063,
      "orthogonal_weight": 0.1,
      "step": 167,
      "total_loss": 0.7986796498298645,
      "weighted_orthogonal_loss": 0.07937964051961899
    },
    {
      "classification_loss": 0.7028284072875977,
      "epoch": 0.5508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7820057272911072,
      "orthogonal_weight": 0.1,
      "step": 168,
      "total_loss": 0.7810289859771729,
      "weighted_orthogonal_loss": 0.0782005712389946
    },
    {
      "classification_loss": 0.7108005285263062,
      "epoch": 0.5540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7714784145355225,
      "orthogonal_weight": 0.1,
      "step": 169,
      "total_loss": 0.7879483699798584,
      "weighted_orthogonal_loss": 0.07714784145355225
    },
    {
      "classification_loss": 0.7389585971832275,
      "epoch": 0.5573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7616114020347595,
      "orthogonal_weight": 0.1,
      "step": 170,
      "total_loss": 0.815119743347168,
      "weighted_orthogonal_loss": 0.07616113871335983
    },
    {
      "classification_loss": 0.7115561962127686,
      "epoch": 0.5606557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7530691623687744,
      "orthogonal_weight": 0.1,
      "step": 171,
      "total_loss": 0.7868630886077881,
      "weighted_orthogonal_loss": 0.07530691474676132
    },
    {
      "classification_loss": 0.6993051767349243,
      "epoch": 0.5639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7455280423164368,
      "orthogonal_weight": 0.1,
      "step": 172,
      "total_loss": 0.7738579511642456,
      "weighted_orthogonal_loss": 0.07455280423164368
    },
    {
      "classification_loss": 0.7437798380851746,
      "epoch": 0.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7389239072799683,
      "orthogonal_weight": 0.1,
      "step": 173,
      "total_loss": 0.8176722526550293,
      "weighted_orthogonal_loss": 0.07389239221811295
    },
    {
      "classification_loss": 0.6863051652908325,
      "epoch": 0.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7329471707344055,
      "orthogonal_weight": 0.1,
      "step": 174,
      "total_loss": 0.7595998644828796,
      "weighted_orthogonal_loss": 0.07329472154378891
    },
    {
      "classification_loss": 0.7252180576324463,
      "epoch": 0.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7264596223831177,
      "orthogonal_weight": 0.1,
      "step": 175,
      "total_loss": 0.7978640198707581,
      "weighted_orthogonal_loss": 0.07264596223831177
    },
    {
      "classification_loss": 0.7183805704116821,
      "epoch": 0.5770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7172539830207825,
      "orthogonal_weight": 0.1,
      "step": 176,
      "total_loss": 0.790105938911438,
      "weighted_orthogonal_loss": 0.07172539830207825
    },
    {
      "classification_loss": 0.6911704540252686,
      "epoch": 0.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7079337239265442,
      "orthogonal_weight": 0.1,
      "step": 177,
      "total_loss": 0.7619638442993164,
      "weighted_orthogonal_loss": 0.07079337537288666
    },
    {
      "classification_loss": 0.7050225138664246,
      "epoch": 0.5836065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6988174915313721,
      "orthogonal_weight": 0.1,
      "step": 178,
      "total_loss": 0.7749042510986328,
      "weighted_orthogonal_loss": 0.06988175213336945
    },
    {
      "classification_loss": 0.7067538499832153,
      "epoch": 0.5868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6901066303253174,
      "orthogonal_weight": 0.1,
      "step": 179,
      "total_loss": 0.775764524936676,
      "weighted_orthogonal_loss": 0.0690106675028801
    },
    {
      "classification_loss": 0.6712997555732727,
      "epoch": 0.5901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6827086806297302,
      "orthogonal_weight": 0.1,
      "step": 180,
      "total_loss": 0.7395706176757812,
      "weighted_orthogonal_loss": 0.06827086955308914
    },
    {
      "classification_loss": 0.7013258934020996,
      "epoch": 0.5934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6763409376144409,
      "orthogonal_weight": 0.1,
      "step": 181,
      "total_loss": 0.7689599990844727,
      "weighted_orthogonal_loss": 0.06763409823179245
    },
    {
      "classification_loss": 0.7177046537399292,
      "epoch": 0.5967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6700928211212158,
      "orthogonal_weight": 0.1,
      "step": 182,
      "total_loss": 0.7847139239311218,
      "weighted_orthogonal_loss": 0.06700928509235382
    },
    {
      "classification_loss": 0.6969925761222839,
      "epoch": 0.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6622061729431152,
      "orthogonal_weight": 0.1,
      "step": 183,
      "total_loss": 0.7632132172584534,
      "weighted_orthogonal_loss": 0.06622061878442764
    },
    {
      "classification_loss": 0.713304340839386,
      "epoch": 0.6032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6538342237472534,
      "orthogonal_weight": 0.1,
      "step": 184,
      "total_loss": 0.7786877751350403,
      "weighted_orthogonal_loss": 0.0653834268450737
    },
    {
      "classification_loss": 0.6959580779075623,
      "epoch": 0.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6462763547897339,
      "orthogonal_weight": 0.1,
      "step": 185,
      "total_loss": 0.7605857253074646,
      "weighted_orthogonal_loss": 0.06462763994932175
    },
    {
      "classification_loss": 0.7177587151527405,
      "epoch": 0.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6394720673561096,
      "orthogonal_weight": 0.1,
      "step": 186,
      "total_loss": 0.781705915927887,
      "weighted_orthogonal_loss": 0.06394720822572708
    },
    {
      "classification_loss": 0.7390300035476685,
      "epoch": 0.6131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6332750916481018,
      "orthogonal_weight": 0.1,
      "step": 187,
      "total_loss": 0.8023574948310852,
      "weighted_orthogonal_loss": 0.06332751363515854
    },
    {
      "classification_loss": 0.7136139273643494,
      "epoch": 0.6163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6276147961616516,
      "orthogonal_weight": 0.1,
      "step": 188,
      "total_loss": 0.776375412940979,
      "weighted_orthogonal_loss": 0.06276147812604904
    },
    {
      "classification_loss": 0.7045691609382629,
      "epoch": 0.6196721311475409,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6229007840156555,
      "orthogonal_weight": 0.1,
      "step": 189,
      "total_loss": 0.766859233379364,
      "weighted_orthogonal_loss": 0.06229007989168167
    },
    {
      "classification_loss": 0.7169452905654907,
      "epoch": 0.6229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6183456182479858,
      "orthogonal_weight": 0.1,
      "step": 190,
      "total_loss": 0.7787798643112183,
      "weighted_orthogonal_loss": 0.061834562569856644
    },
    {
      "classification_loss": 0.7381787896156311,
      "epoch": 0.6262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6144683957099915,
      "orthogonal_weight": 0.1,
      "step": 191,
      "total_loss": 0.7996256351470947,
      "weighted_orthogonal_loss": 0.061446841806173325
    },
    {
      "classification_loss": 0.7247123122215271,
      "epoch": 0.6295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6094496846199036,
      "orthogonal_weight": 0.1,
      "step": 192,
      "total_loss": 0.7856572866439819,
      "weighted_orthogonal_loss": 0.060944970697164536
    },
    {
      "classification_loss": 0.6660178303718567,
      "epoch": 0.6327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6037217378616333,
      "orthogonal_weight": 0.1,
      "step": 193,
      "total_loss": 0.72639000415802,
      "weighted_orthogonal_loss": 0.06037217378616333
    },
    {
      "classification_loss": 0.7119050621986389,
      "epoch": 0.6360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5987588763237,
      "orthogonal_weight": 0.1,
      "step": 194,
      "total_loss": 0.7717809677124023,
      "weighted_orthogonal_loss": 0.059875886887311935
    },
    {
      "classification_loss": 0.7103061079978943,
      "epoch": 0.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5928035974502563,
      "orthogonal_weight": 0.1,
      "step": 195,
      "total_loss": 0.769586443901062,
      "weighted_orthogonal_loss": 0.059280361980199814
    },
    {
      "classification_loss": 0.6347771286964417,
      "epoch": 0.6426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5860375761985779,
      "orthogonal_weight": 0.1,
      "step": 196,
      "total_loss": 0.6933808922767639,
      "weighted_orthogonal_loss": 0.05860375985503197
    },
    {
      "classification_loss": 0.6949501633644104,
      "epoch": 0.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5803974866867065,
      "orthogonal_weight": 0.1,
      "step": 197,
      "total_loss": 0.7529898881912231,
      "weighted_orthogonal_loss": 0.05803975090384483
    },
    {
      "classification_loss": 0.7041467428207397,
      "epoch": 0.6491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5744933485984802,
      "orthogonal_weight": 0.1,
      "step": 198,
      "total_loss": 0.7615960836410522,
      "weighted_orthogonal_loss": 0.0574493370950222
    },
    {
      "classification_loss": 0.7606134414672852,
      "epoch": 0.6524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5679471492767334,
      "orthogonal_weight": 0.1,
      "step": 199,
      "total_loss": 0.8174081444740295,
      "weighted_orthogonal_loss": 0.05679471418261528
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 5.728487968444824,
      "learning_rate": 0.0001967,
      "loss": 0.8273,
      "step": 200
    },
    {
      "classification_loss": 0.7116988897323608,
      "epoch": 0.6557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5610496401786804,
      "orthogonal_weight": 0.1,
      "step": 200,
      "total_loss": 0.7678038477897644,
      "weighted_orthogonal_loss": 0.05610496550798416
    },
    {
      "classification_loss": 0.7220116853713989,
      "epoch": 0.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5541437268257141,
      "orthogonal_weight": 0.1,
      "step": 201,
      "total_loss": 0.7774260640144348,
      "weighted_orthogonal_loss": 0.05541437491774559
    },
    {
      "classification_loss": 0.6721393465995789,
      "epoch": 0.6622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5483297109603882,
      "orthogonal_weight": 0.1,
      "step": 202,
      "total_loss": 0.7269723415374756,
      "weighted_orthogonal_loss": 0.05483297258615494
    },
    {
      "classification_loss": 0.6306853890419006,
      "epoch": 0.6655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5426285862922668,
      "orthogonal_weight": 0.1,
      "step": 203,
      "total_loss": 0.6849482655525208,
      "weighted_orthogonal_loss": 0.054262857884168625
    },
    {
      "classification_loss": 0.709265410900116,
      "epoch": 0.6688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5367624759674072,
      "orthogonal_weight": 0.1,
      "step": 204,
      "total_loss": 0.7629416584968567,
      "weighted_orthogonal_loss": 0.05367624759674072
    },
    {
      "classification_loss": 0.7012773752212524,
      "epoch": 0.6721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5310946702957153,
      "orthogonal_weight": 0.1,
      "step": 205,
      "total_loss": 0.754386842250824,
      "weighted_orthogonal_loss": 0.05310946702957153
    },
    {
      "classification_loss": 0.720333456993103,
      "epoch": 0.6754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5251572132110596,
      "orthogonal_weight": 0.1,
      "step": 206,
      "total_loss": 0.7728492021560669,
      "weighted_orthogonal_loss": 0.052515722811222076
    },
    {
      "classification_loss": 0.7018915414810181,
      "epoch": 0.6786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5191977024078369,
      "orthogonal_weight": 0.1,
      "step": 207,
      "total_loss": 0.7538112998008728,
      "weighted_orthogonal_loss": 0.05191976949572563
    },
    {
      "classification_loss": 0.6653981804847717,
      "epoch": 0.6819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5132253766059875,
      "orthogonal_weight": 0.1,
      "step": 208,
      "total_loss": 0.716720700263977,
      "weighted_orthogonal_loss": 0.051322538405656815
    },
    {
      "classification_loss": 0.6778106093406677,
      "epoch": 0.6852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5067413449287415,
      "orthogonal_weight": 0.1,
      "step": 209,
      "total_loss": 0.7284847497940063,
      "weighted_orthogonal_loss": 0.050674136728048325
    },
    {
      "classification_loss": 0.7002927660942078,
      "epoch": 0.6885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5006607174873352,
      "orthogonal_weight": 0.1,
      "step": 210,
      "total_loss": 0.7503588199615479,
      "weighted_orthogonal_loss": 0.05006607249379158
    },
    {
      "classification_loss": 0.7151138782501221,
      "epoch": 0.6918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4948391020298004,
      "orthogonal_weight": 0.1,
      "step": 211,
      "total_loss": 0.7645977735519409,
      "weighted_orthogonal_loss": 0.04948391020298004
    },
    {
      "classification_loss": 0.6979647278785706,
      "epoch": 0.6950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4887544810771942,
      "orthogonal_weight": 0.1,
      "step": 212,
      "total_loss": 0.7468401789665222,
      "weighted_orthogonal_loss": 0.04887544736266136
    },
    {
      "classification_loss": 0.6869545578956604,
      "epoch": 0.6983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.48377370834350586,
      "orthogonal_weight": 0.1,
      "step": 213,
      "total_loss": 0.7353319525718689,
      "weighted_orthogonal_loss": 0.048377372324466705
    },
    {
      "classification_loss": 0.7263725399971008,
      "epoch": 0.7016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4793614447116852,
      "orthogonal_weight": 0.1,
      "step": 214,
      "total_loss": 0.7743086814880371,
      "weighted_orthogonal_loss": 0.04793614521622658
    },
    {
      "classification_loss": 0.6604940295219421,
      "epoch": 0.7049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.47478798031806946,
      "orthogonal_weight": 0.1,
      "step": 215,
      "total_loss": 0.7079728245735168,
      "weighted_orthogonal_loss": 0.047478798776865005
    },
    {
      "classification_loss": 0.6522423624992371,
      "epoch": 0.7081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4700516164302826,
      "orthogonal_weight": 0.1,
      "step": 216,
      "total_loss": 0.6992475390434265,
      "weighted_orthogonal_loss": 0.04700516164302826
    },
    {
      "classification_loss": 0.6462717056274414,
      "epoch": 0.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.46474435925483704,
      "orthogonal_weight": 0.1,
      "step": 217,
      "total_loss": 0.6927461624145508,
      "weighted_orthogonal_loss": 0.04647443816065788
    },
    {
      "classification_loss": 0.6989960074424744,
      "epoch": 0.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.45896536111831665,
      "orthogonal_weight": 0.1,
      "step": 218,
      "total_loss": 0.7448925375938416,
      "weighted_orthogonal_loss": 0.045896537601947784
    },
    {
      "classification_loss": 0.715009331703186,
      "epoch": 0.7180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4543754756450653,
      "orthogonal_weight": 0.1,
      "step": 219,
      "total_loss": 0.7604469060897827,
      "weighted_orthogonal_loss": 0.04543754830956459
    },
    {
      "classification_loss": 0.7178640961647034,
      "epoch": 0.7213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4506312906742096,
      "orthogonal_weight": 0.1,
      "step": 220,
      "total_loss": 0.762927234172821,
      "weighted_orthogonal_loss": 0.04506313055753708
    },
    {
      "classification_loss": 0.6671947240829468,
      "epoch": 0.7245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.44750723242759705,
      "orthogonal_weight": 0.1,
      "step": 221,
      "total_loss": 0.7119454741477966,
      "weighted_orthogonal_loss": 0.044750723987817764
    },
    {
      "classification_loss": 0.7280611991882324,
      "epoch": 0.7278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4433830678462982,
      "orthogonal_weight": 0.1,
      "step": 222,
      "total_loss": 0.7723994851112366,
      "weighted_orthogonal_loss": 0.04433830827474594
    },
    {
      "classification_loss": 0.7156656980514526,
      "epoch": 0.7311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4398602545261383,
      "orthogonal_weight": 0.1,
      "step": 223,
      "total_loss": 0.7596517205238342,
      "weighted_orthogonal_loss": 0.04398602619767189
    },
    {
      "classification_loss": 0.6979781985282898,
      "epoch": 0.7344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4366690218448639,
      "orthogonal_weight": 0.1,
      "step": 224,
      "total_loss": 0.741645097732544,
      "weighted_orthogonal_loss": 0.04366690292954445
    },
    {
      "classification_loss": 0.7222327589988708,
      "epoch": 0.7377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.43384334444999695,
      "orthogonal_weight": 0.1,
      "step": 225,
      "total_loss": 0.7656170725822449,
      "weighted_orthogonal_loss": 0.043384335935115814
    },
    {
      "classification_loss": 0.7155141830444336,
      "epoch": 0.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4313594400882721,
      "orthogonal_weight": 0.1,
      "step": 226,
      "total_loss": 0.7586501240730286,
      "weighted_orthogonal_loss": 0.04313594475388527
    },
    {
      "classification_loss": 0.7037650942802429,
      "epoch": 0.7442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.42943400144577026,
      "orthogonal_weight": 0.1,
      "step": 227,
      "total_loss": 0.7467085123062134,
      "weighted_orthogonal_loss": 0.04294339939951897
    },
    {
      "classification_loss": 0.6553806066513062,
      "epoch": 0.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4282200038433075,
      "orthogonal_weight": 0.1,
      "step": 228,
      "total_loss": 0.6982026100158691,
      "weighted_orthogonal_loss": 0.04282199963927269
    },
    {
      "classification_loss": 0.722605288028717,
      "epoch": 0.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.42652979493141174,
      "orthogonal_weight": 0.1,
      "step": 229,
      "total_loss": 0.765258252620697,
      "weighted_orthogonal_loss": 0.042652979493141174
    },
    {
      "classification_loss": 0.6863751411437988,
      "epoch": 0.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4242936670780182,
      "orthogonal_weight": 0.1,
      "step": 230,
      "total_loss": 0.7288045287132263,
      "weighted_orthogonal_loss": 0.042429368942976
    },
    {
      "classification_loss": 0.702657163143158,
      "epoch": 0.7573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.421884685754776,
      "orthogonal_weight": 0.1,
      "step": 231,
      "total_loss": 0.7448456287384033,
      "weighted_orthogonal_loss": 0.04218846932053566
    },
    {
      "classification_loss": 0.6711210012435913,
      "epoch": 0.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.41894879937171936,
      "orthogonal_weight": 0.1,
      "step": 232,
      "total_loss": 0.7130158543586731,
      "weighted_orthogonal_loss": 0.041894879192113876
    },
    {
      "classification_loss": 0.6562107801437378,
      "epoch": 0.7639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4154166579246521,
      "orthogonal_weight": 0.1,
      "step": 233,
      "total_loss": 0.6977524757385254,
      "weighted_orthogonal_loss": 0.04154166579246521
    },
    {
      "classification_loss": 0.6899065971374512,
      "epoch": 0.7672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4118153154850006,
      "orthogonal_weight": 0.1,
      "step": 234,
      "total_loss": 0.7310881018638611,
      "weighted_orthogonal_loss": 0.041181530803442
    },
    {
      "classification_loss": 0.6890919804573059,
      "epoch": 0.7704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.40810805559158325,
      "orthogonal_weight": 0.1,
      "step": 235,
      "total_loss": 0.7299028038978577,
      "weighted_orthogonal_loss": 0.040810804814100266
    },
    {
      "classification_loss": 0.7369409203529358,
      "epoch": 0.7737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.40386271476745605,
      "orthogonal_weight": 0.1,
      "step": 236,
      "total_loss": 0.7773271799087524,
      "weighted_orthogonal_loss": 0.040386270731687546
    },
    {
      "classification_loss": 0.7048996090888977,
      "epoch": 0.7770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.39908087253570557,
      "orthogonal_weight": 0.1,
      "step": 237,
      "total_loss": 0.7448077201843262,
      "weighted_orthogonal_loss": 0.039908088743686676
    },
    {
      "classification_loss": 0.7355625629425049,
      "epoch": 0.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3949201703071594,
      "orthogonal_weight": 0.1,
      "step": 238,
      "total_loss": 0.7750545740127563,
      "weighted_orthogonal_loss": 0.03949201852083206
    },
    {
      "classification_loss": 0.6937424540519714,
      "epoch": 0.7836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3899405300617218,
      "orthogonal_weight": 0.1,
      "step": 239,
      "total_loss": 0.7327365279197693,
      "weighted_orthogonal_loss": 0.03899405524134636
    },
    {
      "classification_loss": 0.7060497403144836,
      "epoch": 0.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.38490715622901917,
      "orthogonal_weight": 0.1,
      "step": 240,
      "total_loss": 0.7445404529571533,
      "weighted_orthogonal_loss": 0.038490716367959976
    },
    {
      "classification_loss": 0.7354292273521423,
      "epoch": 0.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3800651729106903,
      "orthogonal_weight": 0.1,
      "step": 241,
      "total_loss": 0.7734357714653015,
      "weighted_orthogonal_loss": 0.03800651803612709
    },
    {
      "classification_loss": 0.7072373628616333,
      "epoch": 0.7934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3746589124202728,
      "orthogonal_weight": 0.1,
      "step": 242,
      "total_loss": 0.7447032332420349,
      "weighted_orthogonal_loss": 0.0374658927321434
    },
    {
      "classification_loss": 0.6770834922790527,
      "epoch": 0.7967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3681049048900604,
      "orthogonal_weight": 0.1,
      "step": 243,
      "total_loss": 0.7138940095901489,
      "weighted_orthogonal_loss": 0.0368104912340641
    },
    {
      "classification_loss": 0.6760765314102173,
      "epoch": 0.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.36248090863227844,
      "orthogonal_weight": 0.1,
      "step": 244,
      "total_loss": 0.7123246192932129,
      "weighted_orthogonal_loss": 0.036248091608285904
    },
    {
      "classification_loss": 0.7230172753334045,
      "epoch": 0.8032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35802164673805237,
      "orthogonal_weight": 0.1,
      "step": 245,
      "total_loss": 0.7588194608688354,
      "weighted_orthogonal_loss": 0.035802166908979416
    },
    {
      "classification_loss": 0.6754835844039917,
      "epoch": 0.8065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35427799820899963,
      "orthogonal_weight": 0.1,
      "step": 246,
      "total_loss": 0.7109113931655884,
      "weighted_orthogonal_loss": 0.03542780131101608
    },
    {
      "classification_loss": 0.7139962315559387,
      "epoch": 0.8098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35121163725852966,
      "orthogonal_weight": 0.1,
      "step": 247,
      "total_loss": 0.749117374420166,
      "weighted_orthogonal_loss": 0.035121165215969086
    },
    {
      "classification_loss": 0.7339947819709778,
      "epoch": 0.8131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3485611379146576,
      "orthogonal_weight": 0.1,
      "step": 248,
      "total_loss": 0.7688509225845337,
      "weighted_orthogonal_loss": 0.03485611453652382
    },
    {
      "classification_loss": 0.6876821517944336,
      "epoch": 0.8163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34651097655296326,
      "orthogonal_weight": 0.1,
      "step": 249,
      "total_loss": 0.7223332524299622,
      "weighted_orthogonal_loss": 0.034651096910238266
    },
    {
      "classification_loss": 0.7027570605278015,
      "epoch": 0.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34494906663894653,
      "orthogonal_weight": 0.1,
      "step": 250,
      "total_loss": 0.7372519969940186,
      "weighted_orthogonal_loss": 0.03449490666389465
    },
    {
      "classification_loss": 0.7102451920509338,
      "epoch": 0.8229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3430878818035126,
      "orthogonal_weight": 0.1,
      "step": 251,
      "total_loss": 0.7445539832115173,
      "weighted_orthogonal_loss": 0.0343087874352932
    },
    {
      "classification_loss": 0.6936730742454529,
      "epoch": 0.8262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34157025814056396,
      "orthogonal_weight": 0.1,
      "step": 252,
      "total_loss": 0.7278301119804382,
      "weighted_orthogonal_loss": 0.034157026559114456
    },
    {
      "classification_loss": 0.6746993660926819,
      "epoch": 0.8295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3401494324207306,
      "orthogonal_weight": 0.1,
      "step": 253,
      "total_loss": 0.7087143063545227,
      "weighted_orthogonal_loss": 0.03401494398713112
    },
    {
      "classification_loss": 0.702947199344635,
      "epoch": 0.8327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3385455012321472,
      "orthogonal_weight": 0.1,
      "step": 254,
      "total_loss": 0.7368017435073853,
      "weighted_orthogonal_loss": 0.03385455161333084
    },
    {
      "classification_loss": 0.682108998298645,
      "epoch": 0.8360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33690619468688965,
      "orthogonal_weight": 0.1,
      "step": 255,
      "total_loss": 0.7157996296882629,
      "weighted_orthogonal_loss": 0.033690620213747025
    },
    {
      "classification_loss": 0.7020871639251709,
      "epoch": 0.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3358319401741028,
      "orthogonal_weight": 0.1,
      "step": 256,
      "total_loss": 0.7356703281402588,
      "weighted_orthogonal_loss": 0.03358319401741028
    },
    {
      "classification_loss": 0.6923204064369202,
      "epoch": 0.8426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33521562814712524,
      "orthogonal_weight": 0.1,
      "step": 257,
      "total_loss": 0.7258419990539551,
      "weighted_orthogonal_loss": 0.033521562814712524
    },
    {
      "classification_loss": 0.6896883249282837,
      "epoch": 0.8459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3348219096660614,
      "orthogonal_weight": 0.1,
      "step": 258,
      "total_loss": 0.7231705188751221,
      "weighted_orthogonal_loss": 0.03348219022154808
    },
    {
      "classification_loss": 0.7251152992248535,
      "epoch": 0.8491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3347092866897583,
      "orthogonal_weight": 0.1,
      "step": 259,
      "total_loss": 0.7585862278938293,
      "weighted_orthogonal_loss": 0.03347092866897583
    },
    {
      "classification_loss": 0.7211924195289612,
      "epoch": 0.8524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.334046870470047,
      "orthogonal_weight": 0.1,
      "step": 260,
      "total_loss": 0.7545971274375916,
      "weighted_orthogonal_loss": 0.03340468928217888
    },
    {
      "classification_loss": 0.690490186214447,
      "epoch": 0.8557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33374887704849243,
      "orthogonal_weight": 0.1,
      "step": 261,
      "total_loss": 0.7238650918006897,
      "weighted_orthogonal_loss": 0.033374886959791183
    },
    {
      "classification_loss": 0.6625384092330933,
      "epoch": 0.8590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3333245813846588,
      "orthogonal_weight": 0.1,
      "step": 262,
      "total_loss": 0.6958708763122559,
      "weighted_orthogonal_loss": 0.033332459628582
    },
    {
      "classification_loss": 0.686402440071106,
      "epoch": 0.8622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33239856362342834,
      "orthogonal_weight": 0.1,
      "step": 263,
      "total_loss": 0.7196422815322876,
      "weighted_orthogonal_loss": 0.033239856362342834
    },
    {
      "classification_loss": 0.704214870929718,
      "epoch": 0.8655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33172574639320374,
      "orthogonal_weight": 0.1,
      "step": 264,
      "total_loss": 0.7373874187469482,
      "weighted_orthogonal_loss": 0.033172573894262314
    },
    {
      "classification_loss": 0.7487438321113586,
      "epoch": 0.8688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3311729431152344,
      "orthogonal_weight": 0.1,
      "step": 265,
      "total_loss": 0.7818611264228821,
      "weighted_orthogonal_loss": 0.03311729431152344
    },
    {
      "classification_loss": 0.6932242512702942,
      "epoch": 0.8721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3302973210811615,
      "orthogonal_weight": 0.1,
      "step": 266,
      "total_loss": 0.7262539863586426,
      "weighted_orthogonal_loss": 0.03302973136305809
    },
    {
      "classification_loss": 0.6740738153457642,
      "epoch": 0.8754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3285060524940491,
      "orthogonal_weight": 0.1,
      "step": 267,
      "total_loss": 0.7069244384765625,
      "weighted_orthogonal_loss": 0.03285060450434685
    },
    {
      "classification_loss": 0.6913735270500183,
      "epoch": 0.8786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3267294466495514,
      "orthogonal_weight": 0.1,
      "step": 268,
      "total_loss": 0.7240464687347412,
      "weighted_orthogonal_loss": 0.0326729454100132
    },
    {
      "classification_loss": 0.6990469694137573,
      "epoch": 0.8819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.325399249792099,
      "orthogonal_weight": 0.1,
      "step": 269,
      "total_loss": 0.7315868735313416,
      "weighted_orthogonal_loss": 0.03253992646932602
    },
    {
      "classification_loss": 0.682963490486145,
      "epoch": 0.8852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3239305913448334,
      "orthogonal_weight": 0.1,
      "step": 270,
      "total_loss": 0.7153565287590027,
      "weighted_orthogonal_loss": 0.03239306062459946
    },
    {
      "classification_loss": 0.6843394041061401,
      "epoch": 0.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3226834237575531,
      "orthogonal_weight": 0.1,
      "step": 271,
      "total_loss": 0.7166077494621277,
      "weighted_orthogonal_loss": 0.03226834163069725
    },
    {
      "classification_loss": 0.6777904033660889,
      "epoch": 0.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.32093891501426697,
      "orthogonal_weight": 0.1,
      "step": 272,
      "total_loss": 0.7098842859268188,
      "weighted_orthogonal_loss": 0.032093893736600876
    },
    {
      "classification_loss": 0.6715376377105713,
      "epoch": 0.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31853845715522766,
      "orthogonal_weight": 0.1,
      "step": 273,
      "total_loss": 0.7033914923667908,
      "weighted_orthogonal_loss": 0.031853847205638885
    },
    {
      "classification_loss": 0.6627050042152405,
      "epoch": 0.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31624945998191833,
      "orthogonal_weight": 0.1,
      "step": 274,
      "total_loss": 0.6943299770355225,
      "weighted_orthogonal_loss": 0.03162494674324989
    },
    {
      "classification_loss": 0.676760196685791,
      "epoch": 0.9016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3136797845363617,
      "orthogonal_weight": 0.1,
      "step": 275,
      "total_loss": 0.7081281542778015,
      "weighted_orthogonal_loss": 0.03136797994375229
    },
    {
      "classification_loss": 0.7003521919250488,
      "epoch": 0.9049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31109386682510376,
      "orthogonal_weight": 0.1,
      "step": 276,
      "total_loss": 0.7314615845680237,
      "weighted_orthogonal_loss": 0.031109387055039406
    },
    {
      "classification_loss": 0.7159556746482849,
      "epoch": 0.9081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3090585768222809,
      "orthogonal_weight": 0.1,
      "step": 277,
      "total_loss": 0.7468615174293518,
      "weighted_orthogonal_loss": 0.03090585768222809
    },
    {
      "classification_loss": 0.6953652501106262,
      "epoch": 0.9114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3072658181190491,
      "orthogonal_weight": 0.1,
      "step": 278,
      "total_loss": 0.7260918617248535,
      "weighted_orthogonal_loss": 0.030726581811904907
    },
    {
      "classification_loss": 0.7143878936767578,
      "epoch": 0.9147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.30486053228378296,
      "orthogonal_weight": 0.1,
      "step": 279,
      "total_loss": 0.7448739409446716,
      "weighted_orthogonal_loss": 0.030486052855849266
    },
    {
      "classification_loss": 0.6829066276550293,
      "epoch": 0.9180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.30287325382232666,
      "orthogonal_weight": 0.1,
      "step": 280,
      "total_loss": 0.713193953037262,
      "weighted_orthogonal_loss": 0.030287325382232666
    },
    {
      "classification_loss": 0.6761268973350525,
      "epoch": 0.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3009670078754425,
      "orthogonal_weight": 0.1,
      "step": 281,
      "total_loss": 0.7062236070632935,
      "weighted_orthogonal_loss": 0.03009670041501522
    },
    {
      "classification_loss": 0.6428988575935364,
      "epoch": 0.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2989319860935211,
      "orthogonal_weight": 0.1,
      "step": 282,
      "total_loss": 0.6727920770645142,
      "weighted_orthogonal_loss": 0.02989319898188114
    },
    {
      "classification_loss": 0.6993380784988403,
      "epoch": 0.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2969207465648651,
      "orthogonal_weight": 0.1,
      "step": 283,
      "total_loss": 0.7290301322937012,
      "weighted_orthogonal_loss": 0.02969207428395748
    },
    {
      "classification_loss": 0.699422299861908,
      "epoch": 0.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2955167293548584,
      "orthogonal_weight": 0.1,
      "step": 284,
      "total_loss": 0.7289739847183228,
      "weighted_orthogonal_loss": 0.0295516736805439
    },
    {
      "classification_loss": 0.6834523677825928,
      "epoch": 0.9344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.29412275552749634,
      "orthogonal_weight": 0.1,
      "step": 285,
      "total_loss": 0.7128646373748779,
      "weighted_orthogonal_loss": 0.029412275180220604
    },
    {
      "classification_loss": 0.7117388844490051,
      "epoch": 0.9377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.29269206523895264,
      "orthogonal_weight": 0.1,
      "step": 286,
      "total_loss": 0.7410081028938293,
      "weighted_orthogonal_loss": 0.029269207268953323
    },
    {
      "classification_loss": 0.6747452616691589,
      "epoch": 0.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2909381687641144,
      "orthogonal_weight": 0.1,
      "step": 287,
      "total_loss": 0.7038390636444092,
      "weighted_orthogonal_loss": 0.029093816876411438
    },
    {
      "classification_loss": 0.6852865219116211,
      "epoch": 0.9442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2891594469547272,
      "orthogonal_weight": 0.1,
      "step": 288,
      "total_loss": 0.7142024636268616,
      "weighted_orthogonal_loss": 0.028915945440530777
    },
    {
      "classification_loss": 0.6936940550804138,
      "epoch": 0.9475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2878511846065521,
      "orthogonal_weight": 0.1,
      "step": 289,
      "total_loss": 0.7224791646003723,
      "weighted_orthogonal_loss": 0.028785118833184242
    },
    {
      "classification_loss": 0.707270085811615,
      "epoch": 0.9508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28675803542137146,
      "orthogonal_weight": 0.1,
      "step": 290,
      "total_loss": 0.7359458804130554,
      "weighted_orthogonal_loss": 0.028675803914666176
    },
    {
      "classification_loss": 0.7036523818969727,
      "epoch": 0.9540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28540727496147156,
      "orthogonal_weight": 0.1,
      "step": 291,
      "total_loss": 0.732193112373352,
      "weighted_orthogonal_loss": 0.028540728613734245
    },
    {
      "classification_loss": 0.6904401183128357,
      "epoch": 0.9573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28368279337882996,
      "orthogonal_weight": 0.1,
      "step": 292,
      "total_loss": 0.7188084125518799,
      "weighted_orthogonal_loss": 0.028368279337882996
    },
    {
      "classification_loss": 0.6631379127502441,
      "epoch": 0.9606557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28198614716529846,
      "orthogonal_weight": 0.1,
      "step": 293,
      "total_loss": 0.6913365125656128,
      "weighted_orthogonal_loss": 0.028198614716529846
    },
    {
      "classification_loss": 0.7169894576072693,
      "epoch": 0.9639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2804989516735077,
      "orthogonal_weight": 0.1,
      "step": 294,
      "total_loss": 0.7450393438339233,
      "weighted_orthogonal_loss": 0.0280498955398798
    },
    {
      "classification_loss": 0.7204880714416504,
      "epoch": 0.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27930310368537903,
      "orthogonal_weight": 0.1,
      "step": 295,
      "total_loss": 0.748418390750885,
      "weighted_orthogonal_loss": 0.027930309996008873
    },
    {
      "classification_loss": 0.6865708827972412,
      "epoch": 0.9704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27766022086143494,
      "orthogonal_weight": 0.1,
      "step": 296,
      "total_loss": 0.7143369317054749,
      "weighted_orthogonal_loss": 0.027766022831201553
    },
    {
      "classification_loss": 0.6753189563751221,
      "epoch": 0.9737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27612653374671936,
      "orthogonal_weight": 0.1,
      "step": 297,
      "total_loss": 0.7029315829277039,
      "weighted_orthogonal_loss": 0.027612654492259026
    },
    {
      "classification_loss": 0.6865256428718567,
      "epoch": 0.9770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2745974659919739,
      "orthogonal_weight": 0.1,
      "step": 298,
      "total_loss": 0.7139853835105896,
      "weighted_orthogonal_loss": 0.027459746226668358
    },
    {
      "classification_loss": 0.6472933888435364,
      "epoch": 0.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2729785740375519,
      "orthogonal_weight": 0.1,
      "step": 299,
      "total_loss": 0.6745912432670593,
      "weighted_orthogonal_loss": 0.027297858148813248
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 1.6842888593673706,
      "learning_rate": 0.0001933666666666667,
      "loss": 0.7322,
      "step": 300
    },
    {
      "classification_loss": 0.7104954719543457,
      "epoch": 0.9836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27099910378456116,
      "orthogonal_weight": 0.1,
      "step": 300,
      "total_loss": 0.7375953793525696,
      "weighted_orthogonal_loss": 0.027099911123514175
    },
    {
      "classification_loss": 0.6617653369903564,
      "epoch": 0.9868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2692602872848511,
      "orthogonal_weight": 0.1,
      "step": 301,
      "total_loss": 0.6886913776397705,
      "weighted_orthogonal_loss": 0.026926029473543167
    },
    {
      "classification_loss": 0.6774289608001709,
      "epoch": 0.9901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2675319314002991,
      "orthogonal_weight": 0.1,
      "step": 302,
      "total_loss": 0.7041821479797363,
      "weighted_orthogonal_loss": 0.026753192767500877
    },
    {
      "classification_loss": 0.7033531665802002,
      "epoch": 0.9934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2659913897514343,
      "orthogonal_weight": 0.1,
      "step": 303,
      "total_loss": 0.729952335357666,
      "weighted_orthogonal_loss": 0.026599138975143433
    },
    {
      "classification_loss": 0.6561520099639893,
      "epoch": 0.9967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.26472708582878113,
      "orthogonal_weight": 0.1,
      "step": 304,
      "total_loss": 0.6826246976852417,
      "weighted_orthogonal_loss": 0.026472708210349083
    },
    {
      "classification_loss": 0.7586381435394287,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.784975528717041,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7098091840744019,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7361465692520142,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7640462517738342,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7903836369514465,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7550459504127502,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7813833355903625,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7194478511810303,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7457852363586426,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7673956155776978,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7937330007553101,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7585721015930176,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7849094867706299,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7495399713516235,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7758773565292358,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.397,
      "eval_f1": 0.12481857764876633,
      "eval_loss": 0.774107813835144,
      "eval_precision": 0.6515151515151515,
      "eval_recall": 0.06902086677367576,
      "eval_runtime": 8.1845,
      "eval_samples_per_second": 122.182,
      "eval_steps_per_second": 0.977,
      "step": 305
    },
    {
      "classification_loss": 0.6760485172271729,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7023859024047852,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7126295566558838,
      "epoch": 1.0032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2619192898273468,
      "orthogonal_weight": 0.1,
      "step": 306,
      "total_loss": 0.7388215065002441,
      "weighted_orthogonal_loss": 0.02619192935526371
    },
    {
      "classification_loss": 0.7062454223632812,
      "epoch": 1.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.26080402731895447,
      "orthogonal_weight": 0.1,
      "step": 307,
      "total_loss": 0.7323258519172668,
      "weighted_orthogonal_loss": 0.026080403476953506
    },
    {
      "classification_loss": 0.6753818988800049,
      "epoch": 1.0098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25991737842559814,
      "orthogonal_weight": 0.1,
      "step": 308,
      "total_loss": 0.7013736367225647,
      "weighted_orthogonal_loss": 0.025991737842559814
    },
    {
      "classification_loss": 0.7051671743392944,
      "epoch": 1.0131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25883716344833374,
      "orthogonal_weight": 0.1,
      "step": 309,
      "total_loss": 0.7310509085655212,
      "weighted_orthogonal_loss": 0.025883717462420464
    },
    {
      "classification_loss": 0.6903932690620422,
      "epoch": 1.0163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2579008638858795,
      "orthogonal_weight": 0.1,
      "step": 310,
      "total_loss": 0.7161833643913269,
      "weighted_orthogonal_loss": 0.025790086016058922
    },
    {
      "classification_loss": 0.7038006782531738,
      "epoch": 1.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2571604549884796,
      "orthogonal_weight": 0.1,
      "step": 311,
      "total_loss": 0.7295167446136475,
      "weighted_orthogonal_loss": 0.02571604587137699
    },
    {
      "classification_loss": 0.6735870242118835,
      "epoch": 1.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2565362751483917,
      "orthogonal_weight": 0.1,
      "step": 312,
      "total_loss": 0.6992406249046326,
      "weighted_orthogonal_loss": 0.025653628632426262
    },
    {
      "classification_loss": 0.6625359058380127,
      "epoch": 1.0262295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2562583386898041,
      "orthogonal_weight": 0.1,
      "step": 313,
      "total_loss": 0.6881617307662964,
      "weighted_orthogonal_loss": 0.025625834241509438
    },
    {
      "classification_loss": 0.6659154891967773,
      "epoch": 1.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25571343302726746,
      "orthogonal_weight": 0.1,
      "step": 314,
      "total_loss": 0.6914868354797363,
      "weighted_orthogonal_loss": 0.025571344420313835
    },
    {
      "classification_loss": 0.6828592419624329,
      "epoch": 1.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2551187574863434,
      "orthogonal_weight": 0.1,
      "step": 315,
      "total_loss": 0.708371102809906,
      "weighted_orthogonal_loss": 0.02551187574863434
    },
    {
      "classification_loss": 0.7066404223442078,
      "epoch": 1.0360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2545590400695801,
      "orthogonal_weight": 0.1,
      "step": 316,
      "total_loss": 0.7320963144302368,
      "weighted_orthogonal_loss": 0.025455905124545097
    },
    {
      "classification_loss": 0.6811386942863464,
      "epoch": 1.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2541184425354004,
      "orthogonal_weight": 0.1,
      "step": 317,
      "total_loss": 0.7065505385398865,
      "weighted_orthogonal_loss": 0.02541184425354004
    },
    {
      "classification_loss": 0.6844079494476318,
      "epoch": 1.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25375205278396606,
      "orthogonal_weight": 0.1,
      "step": 318,
      "total_loss": 0.709783136844635,
      "weighted_orthogonal_loss": 0.025375206023454666
    },
    {
      "classification_loss": 0.7242345809936523,
      "epoch": 1.0459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2534180283546448,
      "orthogonal_weight": 0.1,
      "step": 319,
      "total_loss": 0.7495763897895813,
      "weighted_orthogonal_loss": 0.025341803207993507
    },
    {
      "classification_loss": 0.7201464772224426,
      "epoch": 1.0491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25268611311912537,
      "orthogonal_weight": 0.1,
      "step": 320,
      "total_loss": 0.7454150915145874,
      "weighted_orthogonal_loss": 0.025268612429499626
    },
    {
      "classification_loss": 0.6628994345664978,
      "epoch": 1.0524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25221168994903564,
      "orthogonal_weight": 0.1,
      "step": 321,
      "total_loss": 0.6881206035614014,
      "weighted_orthogonal_loss": 0.025221168994903564
    },
    {
      "classification_loss": 0.6726695895195007,
      "epoch": 1.0557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2513557970523834,
      "orthogonal_weight": 0.1,
      "step": 322,
      "total_loss": 0.6978051662445068,
      "weighted_orthogonal_loss": 0.025135580450296402
    },
    {
      "classification_loss": 0.6924920678138733,
      "epoch": 1.0590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25038012862205505,
      "orthogonal_weight": 0.1,
      "step": 323,
      "total_loss": 0.7175300717353821,
      "weighted_orthogonal_loss": 0.025038013234734535
    },
    {
      "classification_loss": 0.7081001400947571,
      "epoch": 1.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24958749115467072,
      "orthogonal_weight": 0.1,
      "step": 324,
      "total_loss": 0.7330588698387146,
      "weighted_orthogonal_loss": 0.02495875023305416
    },
    {
      "classification_loss": 0.6917634010314941,
      "epoch": 1.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24864427745342255,
      "orthogonal_weight": 0.1,
      "step": 325,
      "total_loss": 0.716627836227417,
      "weighted_orthogonal_loss": 0.024864427745342255
    },
    {
      "classification_loss": 0.6682489514350891,
      "epoch": 1.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24746115505695343,
      "orthogonal_weight": 0.1,
      "step": 326,
      "total_loss": 0.6929950714111328,
      "weighted_orthogonal_loss": 0.024746116250753403
    },
    {
      "classification_loss": 0.6603385806083679,
      "epoch": 1.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24605976045131683,
      "orthogonal_weight": 0.1,
      "step": 327,
      "total_loss": 0.6849445700645447,
      "weighted_orthogonal_loss": 0.024605976417660713
    },
    {
      "classification_loss": 0.6837171912193298,
      "epoch": 1.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2445550560951233,
      "orthogonal_weight": 0.1,
      "step": 328,
      "total_loss": 0.7081726789474487,
      "weighted_orthogonal_loss": 0.02445550635457039
    },
    {
      "classification_loss": 0.6548986434936523,
      "epoch": 1.0786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.242965966463089,
      "orthogonal_weight": 0.1,
      "step": 329,
      "total_loss": 0.6791952252388,
      "weighted_orthogonal_loss": 0.0242965966463089
    },
    {
      "classification_loss": 0.6678162217140198,
      "epoch": 1.0819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24151889979839325,
      "orthogonal_weight": 0.1,
      "step": 330,
      "total_loss": 0.6919680833816528,
      "weighted_orthogonal_loss": 0.024151889607310295
    },
    {
      "classification_loss": 0.7265428304672241,
      "epoch": 1.0852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23989789187908173,
      "orthogonal_weight": 0.1,
      "step": 331,
      "total_loss": 0.7505326271057129,
      "weighted_orthogonal_loss": 0.023989789187908173
    },
    {
      "classification_loss": 0.6921221613883972,
      "epoch": 1.0885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23853611946105957,
      "orthogonal_weight": 0.1,
      "step": 332,
      "total_loss": 0.7159757614135742,
      "weighted_orthogonal_loss": 0.023853613063693047
    },
    {
      "classification_loss": 0.7118532061576843,
      "epoch": 1.0918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23719435930252075,
      "orthogonal_weight": 0.1,
      "step": 333,
      "total_loss": 0.7355726361274719,
      "weighted_orthogonal_loss": 0.023719435557723045
    },
    {
      "classification_loss": 0.7200711965560913,
      "epoch": 1.0950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23590455949306488,
      "orthogonal_weight": 0.1,
      "step": 334,
      "total_loss": 0.743661642074585,
      "weighted_orthogonal_loss": 0.023590456694364548
    },
    {
      "classification_loss": 0.7556063532829285,
      "epoch": 1.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23463289439678192,
      "orthogonal_weight": 0.1,
      "step": 335,
      "total_loss": 0.7790696620941162,
      "weighted_orthogonal_loss": 0.023463290184736252
    },
    {
      "classification_loss": 0.7305862307548523,
      "epoch": 1.1016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23346887528896332,
      "orthogonal_weight": 0.1,
      "step": 336,
      "total_loss": 0.7539331316947937,
      "weighted_orthogonal_loss": 0.02334688790142536
    },
    {
      "classification_loss": 0.67507404088974,
      "epoch": 1.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23229748010635376,
      "orthogonal_weight": 0.1,
      "step": 337,
      "total_loss": 0.6983038187026978,
      "weighted_orthogonal_loss": 0.023229748010635376
    },
    {
      "classification_loss": 0.6927985548973083,
      "epoch": 1.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2317238450050354,
      "orthogonal_weight": 0.1,
      "step": 338,
      "total_loss": 0.7159709334373474,
      "weighted_orthogonal_loss": 0.02317238412797451
    },
    {
      "classification_loss": 0.7131684422492981,
      "epoch": 1.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23110826313495636,
      "orthogonal_weight": 0.1,
      "step": 339,
      "total_loss": 0.7362792491912842,
      "weighted_orthogonal_loss": 0.023110827431082726
    },
    {
      "classification_loss": 0.6603859066963196,
      "epoch": 1.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23047961294651031,
      "orthogonal_weight": 0.1,
      "step": 340,
      "total_loss": 0.6834338903427124,
      "weighted_orthogonal_loss": 0.02304796129465103
    },
    {
      "classification_loss": 0.7127755284309387,
      "epoch": 1.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22975431382656097,
      "orthogonal_weight": 0.1,
      "step": 341,
      "total_loss": 0.7357509732246399,
      "weighted_orthogonal_loss": 0.022975431755185127
    },
    {
      "classification_loss": 0.6814512014389038,
      "epoch": 1.1213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22878728806972504,
      "orthogonal_weight": 0.1,
      "step": 342,
      "total_loss": 0.7043299078941345,
      "weighted_orthogonal_loss": 0.022878728806972504
    },
    {
      "classification_loss": 0.6962905526161194,
      "epoch": 1.1245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22793176770210266,
      "orthogonal_weight": 0.1,
      "step": 343,
      "total_loss": 0.7190837264060974,
      "weighted_orthogonal_loss": 0.022793177515268326
    },
    {
      "classification_loss": 0.6649888157844543,
      "epoch": 1.1278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22697816789150238,
      "orthogonal_weight": 0.1,
      "step": 344,
      "total_loss": 0.6876866221427917,
      "weighted_orthogonal_loss": 0.022697817534208298
    },
    {
      "classification_loss": 0.6876322031021118,
      "epoch": 1.1311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22612686455249786,
      "orthogonal_weight": 0.1,
      "step": 345,
      "total_loss": 0.71024489402771,
      "weighted_orthogonal_loss": 0.022612687200307846
    },
    {
      "classification_loss": 0.680931568145752,
      "epoch": 1.1344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.225213423371315,
      "orthogonal_weight": 0.1,
      "step": 346,
      "total_loss": 0.7034528851509094,
      "weighted_orthogonal_loss": 0.02252134308218956
    },
    {
      "classification_loss": 0.6928059458732605,
      "epoch": 1.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.224138081073761,
      "orthogonal_weight": 0.1,
      "step": 347,
      "total_loss": 0.7152197360992432,
      "weighted_orthogonal_loss": 0.02241380885243416
    },
    {
      "classification_loss": 0.7037478089332581,
      "epoch": 1.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2234186828136444,
      "orthogonal_weight": 0.1,
      "step": 348,
      "total_loss": 0.7260896563529968,
      "weighted_orthogonal_loss": 0.02234186790883541
    },
    {
      "classification_loss": 0.6988489031791687,
      "epoch": 1.1442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22254525125026703,
      "orthogonal_weight": 0.1,
      "step": 349,
      "total_loss": 0.7211034297943115,
      "weighted_orthogonal_loss": 0.022254524752497673
    },
    {
      "classification_loss": 0.6351805925369263,
      "epoch": 1.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22204752266407013,
      "orthogonal_weight": 0.1,
      "step": 350,
      "total_loss": 0.6573853492736816,
      "weighted_orthogonal_loss": 0.022204753011465073
    },
    {
      "classification_loss": 0.6750702261924744,
      "epoch": 1.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22062623500823975,
      "orthogonal_weight": 0.1,
      "step": 351,
      "total_loss": 0.6971328258514404,
      "weighted_orthogonal_loss": 0.022062623873353004
    },
    {
      "classification_loss": 0.693098783493042,
      "epoch": 1.1540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21890169382095337,
      "orthogonal_weight": 0.1,
      "step": 352,
      "total_loss": 0.7149889469146729,
      "weighted_orthogonal_loss": 0.021890169009566307
    },
    {
      "classification_loss": 0.6444952487945557,
      "epoch": 1.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21752937138080597,
      "orthogonal_weight": 0.1,
      "step": 353,
      "total_loss": 0.6662482023239136,
      "weighted_orthogonal_loss": 0.021752936765551567
    },
    {
      "classification_loss": 0.6842991709709167,
      "epoch": 1.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2158692479133606,
      "orthogonal_weight": 0.1,
      "step": 354,
      "total_loss": 0.7058861255645752,
      "weighted_orthogonal_loss": 0.02158692479133606
    },
    {
      "classification_loss": 0.6565185785293579,
      "epoch": 1.1639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21479228138923645,
      "orthogonal_weight": 0.1,
      "step": 355,
      "total_loss": 0.6779978275299072,
      "weighted_orthogonal_loss": 0.021479228511452675
    },
    {
      "classification_loss": 0.6757163405418396,
      "epoch": 1.1672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2138439565896988,
      "orthogonal_weight": 0.1,
      "step": 356,
      "total_loss": 0.6971007585525513,
      "weighted_orthogonal_loss": 0.02138439565896988
    },
    {
      "classification_loss": 0.6578404903411865,
      "epoch": 1.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2133059948682785,
      "orthogonal_weight": 0.1,
      "step": 357,
      "total_loss": 0.679171085357666,
      "weighted_orthogonal_loss": 0.02133060060441494
    },
    {
      "classification_loss": 0.6937738656997681,
      "epoch": 1.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21287782490253448,
      "orthogonal_weight": 0.1,
      "step": 358,
      "total_loss": 0.7150616645812988,
      "weighted_orthogonal_loss": 0.02128778211772442
    },
    {
      "classification_loss": 0.6706214547157288,
      "epoch": 1.1770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21231801807880402,
      "orthogonal_weight": 0.1,
      "step": 359,
      "total_loss": 0.6918532848358154,
      "weighted_orthogonal_loss": 0.02123180218040943
    },
    {
      "classification_loss": 0.6946905255317688,
      "epoch": 1.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21176491677761078,
      "orthogonal_weight": 0.1,
      "step": 360,
      "total_loss": 0.7158670425415039,
      "weighted_orthogonal_loss": 0.021176492795348167
    },
    {
      "classification_loss": 0.7009189128875732,
      "epoch": 1.1836065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21143463253974915,
      "orthogonal_weight": 0.1,
      "step": 361,
      "total_loss": 0.722062349319458,
      "weighted_orthogonal_loss": 0.021143464371562004
    },
    {
      "classification_loss": 0.691291093826294,
      "epoch": 1.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113853543996811,
      "orthogonal_weight": 0.1,
      "step": 362,
      "total_loss": 0.7124296426773071,
      "weighted_orthogonal_loss": 0.02113853581249714
    },
    {
      "classification_loss": 0.6869188547134399,
      "epoch": 1.1901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21133418381214142,
      "orthogonal_weight": 0.1,
      "step": 363,
      "total_loss": 0.7080522775650024,
      "weighted_orthogonal_loss": 0.0211334191262722
    },
    {
      "classification_loss": 0.6407412886619568,
      "epoch": 1.1934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099312603473663,
      "orthogonal_weight": 0.1,
      "step": 364,
      "total_loss": 0.6618406176567078,
      "weighted_orthogonal_loss": 0.021099312230944633
    },
    {
      "classification_loss": 0.7371107339859009,
      "epoch": 1.1967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21058566868305206,
      "orthogonal_weight": 0.1,
      "step": 365,
      "total_loss": 0.7581692934036255,
      "weighted_orthogonal_loss": 0.021058566868305206
    },
    {
      "classification_loss": 0.6989250779151917,
      "epoch": 1.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21007034182548523,
      "orthogonal_weight": 0.1,
      "step": 366,
      "total_loss": 0.7199321389198303,
      "weighted_orthogonal_loss": 0.021007034927606583
    },
    {
      "classification_loss": 0.6605021953582764,
      "epoch": 1.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20950500667095184,
      "orthogonal_weight": 0.1,
      "step": 367,
      "total_loss": 0.6814526915550232,
      "weighted_orthogonal_loss": 0.020950501784682274
    },
    {
      "classification_loss": 0.7338178753852844,
      "epoch": 1.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092246562242508,
      "orthogonal_weight": 0.1,
      "step": 368,
      "total_loss": 0.7547403573989868,
      "weighted_orthogonal_loss": 0.02092246524989605
    },
    {
      "classification_loss": 0.6947116851806641,
      "epoch": 1.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20880532264709473,
      "orthogonal_weight": 0.1,
      "step": 369,
      "total_loss": 0.7155922055244446,
      "weighted_orthogonal_loss": 0.020880533382296562
    },
    {
      "classification_loss": 0.6464808583259583,
      "epoch": 1.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086644470691681,
      "orthogonal_weight": 0.1,
      "step": 370,
      "total_loss": 0.6673473119735718,
      "weighted_orthogonal_loss": 0.02086644433438778
    },
    {
      "classification_loss": 0.6603268384933472,
      "epoch": 1.2163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20871475338935852,
      "orthogonal_weight": 0.1,
      "step": 371,
      "total_loss": 0.6811982989311218,
      "weighted_orthogonal_loss": 0.020871475338935852
    },
    {
      "classification_loss": 0.7224637866020203,
      "epoch": 1.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087203413248062,
      "orthogonal_weight": 0.1,
      "step": 372,
      "total_loss": 0.7433358430862427,
      "weighted_orthogonal_loss": 0.02087203413248062
    },
    {
      "classification_loss": 0.7160760164260864,
      "epoch": 1.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20881342887878418,
      "orthogonal_weight": 0.1,
      "step": 373,
      "total_loss": 0.7369573712348938,
      "weighted_orthogonal_loss": 0.020881343632936478
    },
    {
      "classification_loss": 0.6603718996047974,
      "epoch": 1.2262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867934823036194,
      "orthogonal_weight": 0.1,
      "step": 374,
      "total_loss": 0.6812398433685303,
      "weighted_orthogonal_loss": 0.020867934450507164
    },
    {
      "classification_loss": 0.707343339920044,
      "epoch": 1.2295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20831549167633057,
      "orthogonal_weight": 0.1,
      "step": 375,
      "total_loss": 0.7281748652458191,
      "weighted_orthogonal_loss": 0.020831549540162086
    },
    {
      "classification_loss": 0.6637990474700928,
      "epoch": 1.2327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20814068615436554,
      "orthogonal_weight": 0.1,
      "step": 376,
      "total_loss": 0.6846131086349487,
      "weighted_orthogonal_loss": 0.020814068615436554
    },
    {
      "classification_loss": 0.6992805004119873,
      "epoch": 1.2360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20656615495681763,
      "orthogonal_weight": 0.1,
      "step": 377,
      "total_loss": 0.7199370861053467,
      "weighted_orthogonal_loss": 0.020656615495681763
    },
    {
      "classification_loss": 0.6749974489212036,
      "epoch": 1.2393442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20476697385311127,
      "orthogonal_weight": 0.1,
      "step": 378,
      "total_loss": 0.6954741477966309,
      "weighted_orthogonal_loss": 0.020476697012782097
    },
    {
      "classification_loss": 0.6727122068405151,
      "epoch": 1.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306670665740967,
      "orthogonal_weight": 0.1,
      "step": 379,
      "total_loss": 0.6930188536643982,
      "weighted_orthogonal_loss": 0.020306671038269997
    },
    {
      "classification_loss": 0.6686294674873352,
      "epoch": 1.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20184336602687836,
      "orthogonal_weight": 0.1,
      "step": 380,
      "total_loss": 0.6888138055801392,
      "weighted_orthogonal_loss": 0.020184336230158806
    },
    {
      "classification_loss": 0.7060471773147583,
      "epoch": 1.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2008264809846878,
      "orthogonal_weight": 0.1,
      "step": 381,
      "total_loss": 0.7261298298835754,
      "weighted_orthogonal_loss": 0.02008264884352684
    },
    {
      "classification_loss": 0.6292046308517456,
      "epoch": 1.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2000742107629776,
      "orthogonal_weight": 0.1,
      "step": 382,
      "total_loss": 0.6492120623588562,
      "weighted_orthogonal_loss": 0.02000742219388485
    },
    {
      "classification_loss": 0.6614510416984558,
      "epoch": 1.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19913014769554138,
      "orthogonal_weight": 0.1,
      "step": 383,
      "total_loss": 0.6813640594482422,
      "weighted_orthogonal_loss": 0.019913015887141228
    },
    {
      "classification_loss": 0.7295617461204529,
      "epoch": 1.2590163934426228,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19836504757404327,
      "orthogonal_weight": 0.1,
      "step": 384,
      "total_loss": 0.7493982315063477,
      "weighted_orthogonal_loss": 0.019836505874991417
    },
    {
      "classification_loss": 0.653960108757019,
      "epoch": 1.2622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19769173860549927,
      "orthogonal_weight": 0.1,
      "step": 385,
      "total_loss": 0.6737293004989624,
      "weighted_orthogonal_loss": 0.019769174978137016
    },
    {
      "classification_loss": 0.7309483289718628,
      "epoch": 1.2655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19716045260429382,
      "orthogonal_weight": 0.1,
      "step": 386,
      "total_loss": 0.7506643533706665,
      "weighted_orthogonal_loss": 0.019716044887900352
    },
    {
      "classification_loss": 0.6260085105895996,
      "epoch": 1.2688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19669222831726074,
      "orthogonal_weight": 0.1,
      "step": 387,
      "total_loss": 0.6456777453422546,
      "weighted_orthogonal_loss": 0.019669223576784134
    },
    {
      "classification_loss": 0.6501620411872864,
      "epoch": 1.2721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19645285606384277,
      "orthogonal_weight": 0.1,
      "step": 388,
      "total_loss": 0.6698073148727417,
      "weighted_orthogonal_loss": 0.019645286723971367
    },
    {
      "classification_loss": 0.6825761795043945,
      "epoch": 1.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19600921869277954,
      "orthogonal_weight": 0.1,
      "step": 389,
      "total_loss": 0.702177107334137,
      "weighted_orthogonal_loss": 0.019600922241806984
    },
    {
      "classification_loss": 0.7074939608573914,
      "epoch": 1.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19559258222579956,
      "orthogonal_weight": 0.1,
      "step": 390,
      "total_loss": 0.7270532250404358,
      "weighted_orthogonal_loss": 0.019559258595108986
    },
    {
      "classification_loss": 0.6679697036743164,
      "epoch": 1.2819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19518104195594788,
      "orthogonal_weight": 0.1,
      "step": 391,
      "total_loss": 0.687487781047821,
      "weighted_orthogonal_loss": 0.019518105313181877
    },
    {
      "classification_loss": 0.6675586700439453,
      "epoch": 1.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1944340318441391,
      "orthogonal_weight": 0.1,
      "step": 392,
      "total_loss": 0.6870020627975464,
      "weighted_orthogonal_loss": 0.01944340392947197
    },
    {
      "classification_loss": 0.7105339765548706,
      "epoch": 1.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.193699911236763,
      "orthogonal_weight": 0.1,
      "step": 393,
      "total_loss": 0.7299039959907532,
      "weighted_orthogonal_loss": 0.01936999149620533
    },
    {
      "classification_loss": 0.6982964277267456,
      "epoch": 1.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1929759681224823,
      "orthogonal_weight": 0.1,
      "step": 394,
      "total_loss": 0.7175940275192261,
      "weighted_orthogonal_loss": 0.01929759792983532
    },
    {
      "classification_loss": 0.6925759315490723,
      "epoch": 1.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1922474205493927,
      "orthogonal_weight": 0.1,
      "step": 395,
      "total_loss": 0.7118006944656372,
      "weighted_orthogonal_loss": 0.0192247424274683
    },
    {
      "classification_loss": 0.6858789324760437,
      "epoch": 1.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19115379452705383,
      "orthogonal_weight": 0.1,
      "step": 396,
      "total_loss": 0.7049943208694458,
      "weighted_orthogonal_loss": 0.019115379080176353
    },
    {
      "classification_loss": 0.6950842142105103,
      "epoch": 1.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19025449454784393,
      "orthogonal_weight": 0.1,
      "step": 397,
      "total_loss": 0.7141096591949463,
      "weighted_orthogonal_loss": 0.019025450572371483
    },
    {
      "classification_loss": 0.7008205652236938,
      "epoch": 1.3049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18919292092323303,
      "orthogonal_weight": 0.1,
      "step": 398,
      "total_loss": 0.7197398543357849,
      "weighted_orthogonal_loss": 0.018919292837381363
    },
    {
      "classification_loss": 0.716442883014679,
      "epoch": 1.3081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1879114955663681,
      "orthogonal_weight": 0.1,
      "step": 399,
      "total_loss": 0.7352340221405029,
      "weighted_orthogonal_loss": 0.01879115030169487
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 3.5166385173797607,
      "learning_rate": 0.00019003333333333336,
      "loss": 0.7093,
      "step": 400
    },
    {
      "classification_loss": 0.7023847103118896,
      "epoch": 1.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1867154985666275,
      "orthogonal_weight": 0.1,
      "step": 400,
      "total_loss": 0.7210562825202942,
      "weighted_orthogonal_loss": 0.01867154985666275
    },
    {
      "classification_loss": 0.6966331601142883,
      "epoch": 1.3147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18561314046382904,
      "orthogonal_weight": 0.1,
      "step": 401,
      "total_loss": 0.7151944637298584,
      "weighted_orthogonal_loss": 0.018561314791440964
    },
    {
      "classification_loss": 0.6615169048309326,
      "epoch": 1.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18448621034622192,
      "orthogonal_weight": 0.1,
      "step": 402,
      "total_loss": 0.6799654960632324,
      "weighted_orthogonal_loss": 0.018448621034622192
    },
    {
      "classification_loss": 0.6886668801307678,
      "epoch": 1.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18355810642242432,
      "orthogonal_weight": 0.1,
      "step": 403,
      "total_loss": 0.7070226669311523,
      "weighted_orthogonal_loss": 0.01835581101477146
    },
    {
      "classification_loss": 0.6691579818725586,
      "epoch": 1.3245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18270279467105865,
      "orthogonal_weight": 0.1,
      "step": 404,
      "total_loss": 0.6874282360076904,
      "weighted_orthogonal_loss": 0.018270280212163925
    },
    {
      "classification_loss": 0.7182741165161133,
      "epoch": 1.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18182948231697083,
      "orthogonal_weight": 0.1,
      "step": 405,
      "total_loss": 0.7364570498466492,
      "weighted_orthogonal_loss": 0.018182948231697083
    },
    {
      "classification_loss": 0.6815933585166931,
      "epoch": 1.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18094505369663239,
      "orthogonal_weight": 0.1,
      "step": 406,
      "total_loss": 0.6996878385543823,
      "weighted_orthogonal_loss": 0.018094506114721298
    },
    {
      "classification_loss": 0.7136009931564331,
      "epoch": 1.3344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18006837368011475,
      "orthogonal_weight": 0.1,
      "step": 407,
      "total_loss": 0.7316078543663025,
      "weighted_orthogonal_loss": 0.018006836995482445
    },
    {
      "classification_loss": 0.6581984162330627,
      "epoch": 1.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17931456863880157,
      "orthogonal_weight": 0.1,
      "step": 408,
      "total_loss": 0.6761298775672913,
      "weighted_orthogonal_loss": 0.017931457608938217
    },
    {
      "classification_loss": 0.6597433686256409,
      "epoch": 1.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1786605417728424,
      "orthogonal_weight": 0.1,
      "step": 409,
      "total_loss": 0.6776094436645508,
      "weighted_orthogonal_loss": 0.01786605454981327
    },
    {
      "classification_loss": 0.6578325033187866,
      "epoch": 1.3442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17808100581169128,
      "orthogonal_weight": 0.1,
      "step": 410,
      "total_loss": 0.6756405830383301,
      "weighted_orthogonal_loss": 0.0178081002086401
    },
    {
      "classification_loss": 0.6972450017929077,
      "epoch": 1.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17726559937000275,
      "orthogonal_weight": 0.1,
      "step": 411,
      "total_loss": 0.7149715423583984,
      "weighted_orthogonal_loss": 0.017726561054587364
    },
    {
      "classification_loss": 0.7191892862319946,
      "epoch": 1.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17663680016994476,
      "orthogonal_weight": 0.1,
      "step": 412,
      "total_loss": 0.7368529438972473,
      "weighted_orthogonal_loss": 0.017663680016994476
    },
    {
      "classification_loss": 0.7038128972053528,
      "epoch": 1.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1761375218629837,
      "orthogonal_weight": 0.1,
      "step": 413,
      "total_loss": 0.7214266657829285,
      "weighted_orthogonal_loss": 0.01761375181376934
    },
    {
      "classification_loss": 0.73073810338974,
      "epoch": 1.3573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17577716708183289,
      "orthogonal_weight": 0.1,
      "step": 414,
      "total_loss": 0.7483158111572266,
      "weighted_orthogonal_loss": 0.01757771708071232
    },
    {
      "classification_loss": 0.6523041725158691,
      "epoch": 1.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1755356788635254,
      "orthogonal_weight": 0.1,
      "step": 415,
      "total_loss": 0.6698577404022217,
      "weighted_orthogonal_loss": 0.01755356788635254
    },
    {
      "classification_loss": 0.697857141494751,
      "epoch": 1.3639344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17538869380950928,
      "orthogonal_weight": 0.1,
      "step": 416,
      "total_loss": 0.715395987033844,
      "weighted_orthogonal_loss": 0.017538869753479958
    },
    {
      "classification_loss": 0.6723056435585022,
      "epoch": 1.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17528767883777618,
      "orthogonal_weight": 0.1,
      "step": 417,
      "total_loss": 0.6898344159126282,
      "weighted_orthogonal_loss": 0.017528768628835678
    },
    {
      "classification_loss": 0.6879700422286987,
      "epoch": 1.3704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752515435218811,
      "orthogonal_weight": 0.1,
      "step": 418,
      "total_loss": 0.7054951786994934,
      "weighted_orthogonal_loss": 0.01752515509724617
    },
    {
      "classification_loss": 0.6672960519790649,
      "epoch": 1.3737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17517590522766113,
      "orthogonal_weight": 0.1,
      "step": 419,
      "total_loss": 0.6848136186599731,
      "weighted_orthogonal_loss": 0.017517590895295143
    },
    {
      "classification_loss": 0.6645621657371521,
      "epoch": 1.3770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17516350746154785,
      "orthogonal_weight": 0.1,
      "step": 420,
      "total_loss": 0.6820785403251648,
      "weighted_orthogonal_loss": 0.017516350373625755
    },
    {
      "classification_loss": 0.654904842376709,
      "epoch": 1.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17510023713111877,
      "orthogonal_weight": 0.1,
      "step": 421,
      "total_loss": 0.6724148392677307,
      "weighted_orthogonal_loss": 0.017510024830698967
    },
    {
      "classification_loss": 0.6455605030059814,
      "epoch": 1.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746787577867508,
      "orthogonal_weight": 0.1,
      "step": 422,
      "total_loss": 0.663028359413147,
      "weighted_orthogonal_loss": 0.01746787689626217
    },
    {
      "classification_loss": 0.697586178779602,
      "epoch": 1.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17437441647052765,
      "orthogonal_weight": 0.1,
      "step": 423,
      "total_loss": 0.7150236368179321,
      "weighted_orthogonal_loss": 0.017437441274523735
    },
    {
      "classification_loss": 0.6837738752365112,
      "epoch": 1.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17383024096488953,
      "orthogonal_weight": 0.1,
      "step": 424,
      "total_loss": 0.7011569142341614,
      "weighted_orthogonal_loss": 0.017383024096488953
    },
    {
      "classification_loss": 0.6789612770080566,
      "epoch": 1.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17335140705108643,
      "orthogonal_weight": 0.1,
      "step": 425,
      "total_loss": 0.6962963938713074,
      "weighted_orthogonal_loss": 0.017335141077637672
    },
    {
      "classification_loss": 0.6729797124862671,
      "epoch": 1.3967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17292919754981995,
      "orthogonal_weight": 0.1,
      "step": 426,
      "total_loss": 0.6902726292610168,
      "weighted_orthogonal_loss": 0.017292920500040054
    },
    {
      "classification_loss": 0.6355559229850769,
      "epoch": 1.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726539433002472,
      "orthogonal_weight": 0.1,
      "step": 427,
      "total_loss": 0.6528213024139404,
      "weighted_orthogonal_loss": 0.01726539433002472
    },
    {
      "classification_loss": 0.7157954573631287,
      "epoch": 1.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17239733040332794,
      "orthogonal_weight": 0.1,
      "step": 428,
      "total_loss": 0.7330352067947388,
      "weighted_orthogonal_loss": 0.017239732667803764
    },
    {
      "classification_loss": 0.6634870767593384,
      "epoch": 1.4065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17215056717395782,
      "orthogonal_weight": 0.1,
      "step": 429,
      "total_loss": 0.6807021498680115,
      "weighted_orthogonal_loss": 0.017215056344866753
    },
    {
      "classification_loss": 0.6395498514175415,
      "epoch": 1.4098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17164736986160278,
      "orthogonal_weight": 0.1,
      "step": 430,
      "total_loss": 0.6567145586013794,
      "weighted_orthogonal_loss": 0.01716473698616028
    },
    {
      "classification_loss": 0.7211899161338806,
      "epoch": 1.4131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17108888924121857,
      "orthogonal_weight": 0.1,
      "step": 431,
      "total_loss": 0.7382988333702087,
      "weighted_orthogonal_loss": 0.017108889296650887
    },
    {
      "classification_loss": 0.679692804813385,
      "epoch": 1.4163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17060372233390808,
      "orthogonal_weight": 0.1,
      "step": 432,
      "total_loss": 0.696753203868866,
      "weighted_orthogonal_loss": 0.017060372978448868
    },
    {
      "classification_loss": 0.6816567778587341,
      "epoch": 1.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17020975053310394,
      "orthogonal_weight": 0.1,
      "step": 433,
      "total_loss": 0.6986777782440186,
      "weighted_orthogonal_loss": 0.017020976170897484
    },
    {
      "classification_loss": 0.6598649621009827,
      "epoch": 1.4229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1695837527513504,
      "orthogonal_weight": 0.1,
      "step": 434,
      "total_loss": 0.6768233180046082,
      "weighted_orthogonal_loss": 0.01695837639272213
    },
    {
      "classification_loss": 0.7216187715530396,
      "epoch": 1.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16904012858867645,
      "orthogonal_weight": 0.1,
      "step": 435,
      "total_loss": 0.7385227680206299,
      "weighted_orthogonal_loss": 0.016904013231396675
    },
    {
      "classification_loss": 0.6686830520629883,
      "epoch": 1.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16885380446910858,
      "orthogonal_weight": 0.1,
      "step": 436,
      "total_loss": 0.6855684518814087,
      "weighted_orthogonal_loss": 0.016885381191968918
    },
    {
      "classification_loss": 0.6622757911682129,
      "epoch": 1.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687709540128708,
      "orthogonal_weight": 0.1,
      "step": 437,
      "total_loss": 0.6791529059410095,
      "weighted_orthogonal_loss": 0.01687709614634514
    },
    {
      "classification_loss": 0.7167749404907227,
      "epoch": 1.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1688273698091507,
      "orthogonal_weight": 0.1,
      "step": 438,
      "total_loss": 0.7336576581001282,
      "weighted_orthogonal_loss": 0.01688273809850216
    },
    {
      "classification_loss": 0.6775994300842285,
      "epoch": 1.4393442622950818,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16891181468963623,
      "orthogonal_weight": 0.1,
      "step": 439,
      "total_loss": 0.6944906115531921,
      "weighted_orthogonal_loss": 0.016891181468963623
    },
    {
      "classification_loss": 0.6316713690757751,
      "epoch": 1.4426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16898831725120544,
      "orthogonal_weight": 0.1,
      "step": 440,
      "total_loss": 0.64857017993927,
      "weighted_orthogonal_loss": 0.016898831352591515
    },
    {
      "classification_loss": 0.7247359752655029,
      "epoch": 1.4459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16900552809238434,
      "orthogonal_weight": 0.1,
      "step": 441,
      "total_loss": 0.7416365146636963,
      "weighted_orthogonal_loss": 0.016900552436709404
    },
    {
      "classification_loss": 0.6699919700622559,
      "epoch": 1.4491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1689058095216751,
      "orthogonal_weight": 0.1,
      "step": 442,
      "total_loss": 0.6868825554847717,
      "weighted_orthogonal_loss": 0.01689058169722557
    },
    {
      "classification_loss": 0.6843569874763489,
      "epoch": 1.4524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687161773443222,
      "orthogonal_weight": 0.1,
      "step": 443,
      "total_loss": 0.7012286186218262,
      "weighted_orthogonal_loss": 0.01687161810696125
    },
    {
      "classification_loss": 0.7133574485778809,
      "epoch": 1.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16855983436107635,
      "orthogonal_weight": 0.1,
      "step": 444,
      "total_loss": 0.7302134037017822,
      "weighted_orthogonal_loss": 0.016855983063578606
    },
    {
      "classification_loss": 0.6527412533760071,
      "epoch": 1.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16847673058509827,
      "orthogonal_weight": 0.1,
      "step": 445,
      "total_loss": 0.6695889234542847,
      "weighted_orthogonal_loss": 0.016847673803567886
    },
    {
      "classification_loss": 0.7041845321655273,
      "epoch": 1.4622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16840772330760956,
      "orthogonal_weight": 0.1,
      "step": 446,
      "total_loss": 0.721025288105011,
      "weighted_orthogonal_loss": 0.016840772703289986
    },
    {
      "classification_loss": 0.6711299419403076,
      "epoch": 1.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16834130883216858,
      "orthogonal_weight": 0.1,
      "step": 447,
      "total_loss": 0.6879640817642212,
      "weighted_orthogonal_loss": 0.016834130510687828
    },
    {
      "classification_loss": 0.6618975400924683,
      "epoch": 1.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682841181755066,
      "orthogonal_weight": 0.1,
      "step": 448,
      "total_loss": 0.6787259578704834,
      "weighted_orthogonal_loss": 0.01682841219007969
    },
    {
      "classification_loss": 0.7346258163452148,
      "epoch": 1.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16827106475830078,
      "orthogonal_weight": 0.1,
      "step": 449,
      "total_loss": 0.7514529228210449,
      "weighted_orthogonal_loss": 0.016827106475830078
    },
    {
      "classification_loss": 0.6776800155639648,
      "epoch": 1.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682426780462265,
      "orthogonal_weight": 0.1,
      "step": 450,
      "total_loss": 0.6945042610168457,
      "weighted_orthogonal_loss": 0.01682426780462265
    },
    {
      "classification_loss": 0.7116441130638123,
      "epoch": 1.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682754009962082,
      "orthogonal_weight": 0.1,
      "step": 451,
      "total_loss": 0.7284716367721558,
      "weighted_orthogonal_loss": 0.01682754047214985
    },
    {
      "classification_loss": 0.6829038858413696,
      "epoch": 1.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16835613548755646,
      "orthogonal_weight": 0.1,
      "step": 452,
      "total_loss": 0.6997395157814026,
      "weighted_orthogonal_loss": 0.016835613176226616
    },
    {
      "classification_loss": 0.6859257221221924,
      "epoch": 1.4852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1686127483844757,
      "orthogonal_weight": 0.1,
      "step": 453,
      "total_loss": 0.7027869820594788,
      "weighted_orthogonal_loss": 0.01686127483844757
    },
    {
      "classification_loss": 0.7086890935897827,
      "epoch": 1.4885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16889937222003937,
      "orthogonal_weight": 0.1,
      "step": 454,
      "total_loss": 0.725579023361206,
      "weighted_orthogonal_loss": 0.016889937222003937
    },
    {
      "classification_loss": 0.7025039196014404,
      "epoch": 1.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691422015428543,
      "orthogonal_weight": 0.1,
      "step": 455,
      "total_loss": 0.7194181680679321,
      "weighted_orthogonal_loss": 0.01691422052681446
    },
    {
      "classification_loss": 0.6664518713951111,
      "epoch": 1.4950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16924826800823212,
      "orthogonal_weight": 0.1,
      "step": 456,
      "total_loss": 0.683376669883728,
      "weighted_orthogonal_loss": 0.016924826428294182
    },
    {
      "classification_loss": 0.6821839213371277,
      "epoch": 1.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691545844078064,
      "orthogonal_weight": 0.1,
      "step": 457,
      "total_loss": 0.6990993618965149,
      "weighted_orthogonal_loss": 0.0169154591858387
    },
    {
      "classification_loss": 0.6638921499252319,
      "epoch": 1.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16912803053855896,
      "orthogonal_weight": 0.1,
      "step": 458,
      "total_loss": 0.680804967880249,
      "weighted_orthogonal_loss": 0.016912803053855896
    },
    {
      "classification_loss": 0.7036628127098083,
      "epoch": 1.5049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691640168428421,
      "orthogonal_weight": 0.1,
      "step": 459,
      "total_loss": 0.720579206943512,
      "weighted_orthogonal_loss": 0.01691640168428421
    },
    {
      "classification_loss": 0.703702449798584,
      "epoch": 1.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1692972183227539,
      "orthogonal_weight": 0.1,
      "step": 460,
      "total_loss": 0.7206321954727173,
      "weighted_orthogonal_loss": 0.01692972145974636
    },
    {
      "classification_loss": 0.6953514814376831,
      "epoch": 1.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16950930655002594,
      "orthogonal_weight": 0.1,
      "step": 461,
      "total_loss": 0.7123023867607117,
      "weighted_orthogonal_loss": 0.016950931400060654
    },
    {
      "classification_loss": 0.667876124382019,
      "epoch": 1.5147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1699363738298416,
      "orthogonal_weight": 0.1,
      "step": 462,
      "total_loss": 0.6848697662353516,
      "weighted_orthogonal_loss": 0.01699363812804222
    },
    {
      "classification_loss": 0.6868926286697388,
      "epoch": 1.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1703789085149765,
      "orthogonal_weight": 0.1,
      "step": 463,
      "total_loss": 0.7039304971694946,
      "weighted_orthogonal_loss": 0.01703789085149765
    },
    {
      "classification_loss": 0.6933236718177795,
      "epoch": 1.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17079584300518036,
      "orthogonal_weight": 0.1,
      "step": 464,
      "total_loss": 0.7104032635688782,
      "weighted_orthogonal_loss": 0.017079584300518036
    },
    {
      "classification_loss": 0.6643062829971313,
      "epoch": 1.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17119818925857544,
      "orthogonal_weight": 0.1,
      "step": 465,
      "total_loss": 0.6814261078834534,
      "weighted_orthogonal_loss": 0.017119819298386574
    },
    {
      "classification_loss": 0.6985829472541809,
      "epoch": 1.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17155137658119202,
      "orthogonal_weight": 0.1,
      "step": 466,
      "total_loss": 0.71573805809021,
      "weighted_orthogonal_loss": 0.01715513877570629
    },
    {
      "classification_loss": 0.6831623315811157,
      "epoch": 1.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1718934178352356,
      "orthogonal_weight": 0.1,
      "step": 467,
      "total_loss": 0.7003516554832458,
      "weighted_orthogonal_loss": 0.01718934252858162
    },
    {
      "classification_loss": 0.6757249236106873,
      "epoch": 1.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17181284725666046,
      "orthogonal_weight": 0.1,
      "step": 468,
      "total_loss": 0.6929062008857727,
      "weighted_orthogonal_loss": 0.017181284725666046
    },
    {
      "classification_loss": 0.654961884021759,
      "epoch": 1.5377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17169158160686493,
      "orthogonal_weight": 0.1,
      "step": 469,
      "total_loss": 0.6721310615539551,
      "weighted_orthogonal_loss": 0.017169158905744553
    },
    {
      "classification_loss": 0.6669833660125732,
      "epoch": 1.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17143896222114563,
      "orthogonal_weight": 0.1,
      "step": 470,
      "total_loss": 0.6841272711753845,
      "weighted_orthogonal_loss": 0.017143895849585533
    },
    {
      "classification_loss": 0.7055588364601135,
      "epoch": 1.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17138071358203888,
      "orthogonal_weight": 0.1,
      "step": 471,
      "total_loss": 0.7226969003677368,
      "weighted_orthogonal_loss": 0.017138071358203888
    },
    {
      "classification_loss": 0.6933652758598328,
      "epoch": 1.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17086918652057648,
      "orthogonal_weight": 0.1,
      "step": 472,
      "total_loss": 0.7104521989822388,
      "weighted_orthogonal_loss": 0.017086919397115707
    },
    {
      "classification_loss": 0.6704497337341309,
      "epoch": 1.5508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1703992635011673,
      "orthogonal_weight": 0.1,
      "step": 473,
      "total_loss": 0.6874896883964539,
      "weighted_orthogonal_loss": 0.01703992672264576
    },
    {
      "classification_loss": 0.668506383895874,
      "epoch": 1.5540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17016953229904175,
      "orthogonal_weight": 0.1,
      "step": 474,
      "total_loss": 0.6855233311653137,
      "weighted_orthogonal_loss": 0.017016952857375145
    },
    {
      "classification_loss": 0.6590902805328369,
      "epoch": 1.5573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16992521286010742,
      "orthogonal_weight": 0.1,
      "step": 475,
      "total_loss": 0.6760827898979187,
      "weighted_orthogonal_loss": 0.01699252240359783
    },
    {
      "classification_loss": 0.7076919078826904,
      "epoch": 1.5606557377049182,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16996431350708008,
      "orthogonal_weight": 0.1,
      "step": 476,
      "total_loss": 0.7246883511543274,
      "weighted_orthogonal_loss": 0.016996432095766068
    },
    {
      "classification_loss": 0.6784491539001465,
      "epoch": 1.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16998516023159027,
      "orthogonal_weight": 0.1,
      "step": 477,
      "total_loss": 0.6954476833343506,
      "weighted_orthogonal_loss": 0.016998516395688057
    },
    {
      "classification_loss": 0.6775699257850647,
      "epoch": 1.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16965825855731964,
      "orthogonal_weight": 0.1,
      "step": 478,
      "total_loss": 0.6945357322692871,
      "weighted_orthogonal_loss": 0.016965826973319054
    },
    {
      "classification_loss": 0.6925027370452881,
      "epoch": 1.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1693854182958603,
      "orthogonal_weight": 0.1,
      "step": 479,
      "total_loss": 0.7094413042068481,
      "weighted_orthogonal_loss": 0.01693854294717312
    },
    {
      "classification_loss": 0.6549202799797058,
      "epoch": 1.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16915912926197052,
      "orthogonal_weight": 0.1,
      "step": 480,
      "total_loss": 0.6718361973762512,
      "weighted_orthogonal_loss": 0.01691591367125511
    },
    {
      "classification_loss": 0.6731011271476746,
      "epoch": 1.5770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16865593194961548,
      "orthogonal_weight": 0.1,
      "step": 481,
      "total_loss": 0.6899667382240295,
      "weighted_orthogonal_loss": 0.016865594312548637
    },
    {
      "classification_loss": 0.6873932480812073,
      "epoch": 1.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16816414892673492,
      "orthogonal_weight": 0.1,
      "step": 482,
      "total_loss": 0.7042096853256226,
      "weighted_orthogonal_loss": 0.016816414892673492
    },
    {
      "classification_loss": 0.6888163685798645,
      "epoch": 1.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16774232685565948,
      "orthogonal_weight": 0.1,
      "step": 483,
      "total_loss": 0.7055906057357788,
      "weighted_orthogonal_loss": 0.016774233430624008
    },
    {
      "classification_loss": 0.6565361618995667,
      "epoch": 1.5868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1672513782978058,
      "orthogonal_weight": 0.1,
      "step": 484,
      "total_loss": 0.673261284828186,
      "weighted_orthogonal_loss": 0.01672513782978058
    },
    {
      "classification_loss": 0.7030242085456848,
      "epoch": 1.5901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16683293879032135,
      "orthogonal_weight": 0.1,
      "step": 485,
      "total_loss": 0.7197074890136719,
      "weighted_orthogonal_loss": 0.016683293506503105
    },
    {
      "classification_loss": 0.6840543150901794,
      "epoch": 1.5934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16646428406238556,
      "orthogonal_weight": 0.1,
      "step": 486,
      "total_loss": 0.7007007598876953,
      "weighted_orthogonal_loss": 0.016646428033709526
    },
    {
      "classification_loss": 0.6683555245399475,
      "epoch": 1.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16617460548877716,
      "orthogonal_weight": 0.1,
      "step": 487,
      "total_loss": 0.6849730014801025,
      "weighted_orthogonal_loss": 0.016617460176348686
    },
    {
      "classification_loss": 0.7317874431610107,
      "epoch": 1.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16597981750965118,
      "orthogonal_weight": 0.1,
      "step": 488,
      "total_loss": 0.7483854293823242,
      "weighted_orthogonal_loss": 0.016597982496023178
    },
    {
      "classification_loss": 0.650676429271698,
      "epoch": 1.6032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16595511138439178,
      "orthogonal_weight": 0.1,
      "step": 489,
      "total_loss": 0.6672719120979309,
      "weighted_orthogonal_loss": 0.01659551076591015
    },
    {
      "classification_loss": 0.7491114735603333,
      "epoch": 1.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16564880311489105,
      "orthogonal_weight": 0.1,
      "step": 490,
      "total_loss": 0.7656763792037964,
      "weighted_orthogonal_loss": 0.016564881429076195
    },
    {
      "classification_loss": 0.6435094475746155,
      "epoch": 1.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16523857414722443,
      "orthogonal_weight": 0.1,
      "step": 491,
      "total_loss": 0.6600332856178284,
      "weighted_orthogonal_loss": 0.016523858532309532
    },
    {
      "classification_loss": 0.6761810779571533,
      "epoch": 1.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.165061816573143,
      "orthogonal_weight": 0.1,
      "step": 492,
      "total_loss": 0.6926872730255127,
      "weighted_orthogonal_loss": 0.01650618202984333
    },
    {
      "classification_loss": 0.715707540512085,
      "epoch": 1.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16473327577114105,
      "orthogonal_weight": 0.1,
      "step": 493,
      "total_loss": 0.7321808934211731,
      "weighted_orthogonal_loss": 0.016473328694701195
    },
    {
      "classification_loss": 0.7353987693786621,
      "epoch": 1.6196721311475408,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16453559696674347,
      "orthogonal_weight": 0.1,
      "step": 494,
      "total_loss": 0.7518523335456848,
      "weighted_orthogonal_loss": 0.016453560441732407
    },
    {
      "classification_loss": 0.6509639024734497,
      "epoch": 1.6229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1643315702676773,
      "orthogonal_weight": 0.1,
      "step": 495,
      "total_loss": 0.6673970818519592,
      "weighted_orthogonal_loss": 0.01643315702676773
    },
    {
      "classification_loss": 0.6864845156669617,
      "epoch": 1.6262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1643032282590866,
      "orthogonal_weight": 0.1,
      "step": 496,
      "total_loss": 0.702914834022522,
      "weighted_orthogonal_loss": 0.01643032394349575
    },
    {
      "classification_loss": 0.688167929649353,
      "epoch": 1.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16412825882434845,
      "orthogonal_weight": 0.1,
      "step": 497,
      "total_loss": 0.7045807838439941,
      "weighted_orthogonal_loss": 0.016412826254963875
    },
    {
      "classification_loss": 0.7271003127098083,
      "epoch": 1.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16406936943531036,
      "orthogonal_weight": 0.1,
      "step": 498,
      "total_loss": 0.7435072660446167,
      "weighted_orthogonal_loss": 0.016406936571002007
    },
    {
      "classification_loss": 0.6969819664955139,
      "epoch": 1.6360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16383953392505646,
      "orthogonal_weight": 0.1,
      "step": 499,
      "total_loss": 0.713365912437439,
      "weighted_orthogonal_loss": 0.016383953392505646
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 15.952454566955566,
      "learning_rate": 0.0001867,
      "loss": 0.7014,
      "step": 500
    },
    {
      "classification_loss": 0.7035514116287231,
      "epoch": 1.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16377432644367218,
      "orthogonal_weight": 0.1,
      "step": 500,
      "total_loss": 0.7199288606643677,
      "weighted_orthogonal_loss": 0.016377432271838188
    },
    {
      "classification_loss": 0.6830261945724487,
      "epoch": 1.6426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16387471556663513,
      "orthogonal_weight": 0.1,
      "step": 501,
      "total_loss": 0.6994136571884155,
      "weighted_orthogonal_loss": 0.016387471929192543
    },
    {
      "classification_loss": 0.6712586283683777,
      "epoch": 1.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16402550041675568,
      "orthogonal_weight": 0.1,
      "step": 502,
      "total_loss": 0.6876611709594727,
      "weighted_orthogonal_loss": 0.016402550041675568
    },
    {
      "classification_loss": 0.6788092255592346,
      "epoch": 1.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1641198992729187,
      "orthogonal_weight": 0.1,
      "step": 503,
      "total_loss": 0.6952211856842041,
      "weighted_orthogonal_loss": 0.01641198992729187
    },
    {
      "classification_loss": 0.6670709252357483,
      "epoch": 1.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16396036744117737,
      "orthogonal_weight": 0.1,
      "step": 504,
      "total_loss": 0.6834669709205627,
      "weighted_orthogonal_loss": 0.016396036371588707
    },
    {
      "classification_loss": 0.7145345211029053,
      "epoch": 1.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16386139392852783,
      "orthogonal_weight": 0.1,
      "step": 505,
      "total_loss": 0.730920672416687,
      "weighted_orthogonal_loss": 0.016386140137910843
    },
    {
      "classification_loss": 0.6637324094772339,
      "epoch": 1.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16389663517475128,
      "orthogonal_weight": 0.1,
      "step": 506,
      "total_loss": 0.6801220774650574,
      "weighted_orthogonal_loss": 0.016389664262533188
    },
    {
      "classification_loss": 0.7109330892562866,
      "epoch": 1.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16396696865558624,
      "orthogonal_weight": 0.1,
      "step": 507,
      "total_loss": 0.7273297905921936,
      "weighted_orthogonal_loss": 0.016396697610616684
    },
    {
      "classification_loss": 0.6600582599639893,
      "epoch": 1.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640256643295288,
      "orthogonal_weight": 0.1,
      "step": 508,
      "total_loss": 0.6764608025550842,
      "weighted_orthogonal_loss": 0.01640256680548191
    },
    {
      "classification_loss": 0.7044861316680908,
      "epoch": 1.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16416285932064056,
      "orthogonal_weight": 0.1,
      "step": 509,
      "total_loss": 0.7209024429321289,
      "weighted_orthogonal_loss": 0.016416287049651146
    },
    {
      "classification_loss": 0.7063079476356506,
      "epoch": 1.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16418243944644928,
      "orthogonal_weight": 0.1,
      "step": 510,
      "total_loss": 0.7227261662483215,
      "weighted_orthogonal_loss": 0.016418244689702988
    },
    {
      "classification_loss": 0.6702702045440674,
      "epoch": 1.6754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16423280537128448,
      "orthogonal_weight": 0.1,
      "step": 511,
      "total_loss": 0.6866934895515442,
      "weighted_orthogonal_loss": 0.016423281282186508
    },
    {
      "classification_loss": 0.6997666358947754,
      "epoch": 1.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16397126019001007,
      "orthogonal_weight": 0.1,
      "step": 512,
      "total_loss": 0.7161637544631958,
      "weighted_orthogonal_loss": 0.016397126019001007
    },
    {
      "classification_loss": 0.6980461478233337,
      "epoch": 1.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16374802589416504,
      "orthogonal_weight": 0.1,
      "step": 513,
      "total_loss": 0.7144209742546082,
      "weighted_orthogonal_loss": 0.016374802216887474
    },
    {
      "classification_loss": 0.6987468600273132,
      "epoch": 1.6852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16346284747123718,
      "orthogonal_weight": 0.1,
      "step": 514,
      "total_loss": 0.7150931358337402,
      "weighted_orthogonal_loss": 0.016346285119652748
    },
    {
      "classification_loss": 0.6885150671005249,
      "epoch": 1.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1630365550518036,
      "orthogonal_weight": 0.1,
      "step": 515,
      "total_loss": 0.7048187255859375,
      "weighted_orthogonal_loss": 0.01630365662276745
    },
    {
      "classification_loss": 0.6872536540031433,
      "epoch": 1.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16273610293865204,
      "orthogonal_weight": 0.1,
      "step": 516,
      "total_loss": 0.7035272717475891,
      "weighted_orthogonal_loss": 0.016273610293865204
    },
    {
      "classification_loss": 0.6739598512649536,
      "epoch": 1.6950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16216500103473663,
      "orthogonal_weight": 0.1,
      "step": 517,
      "total_loss": 0.6901763677597046,
      "weighted_orthogonal_loss": 0.016216499730944633
    },
    {
      "classification_loss": 0.6817578673362732,
      "epoch": 1.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1617746651172638,
      "orthogonal_weight": 0.1,
      "step": 518,
      "total_loss": 0.6979353427886963,
      "weighted_orthogonal_loss": 0.01617746613919735
    },
    {
      "classification_loss": 0.6485798358917236,
      "epoch": 1.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16133494675159454,
      "orthogonal_weight": 0.1,
      "step": 519,
      "total_loss": 0.6647133231163025,
      "weighted_orthogonal_loss": 0.016133494675159454
    },
    {
      "classification_loss": 0.6742690801620483,
      "epoch": 1.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16085363924503326,
      "orthogonal_weight": 0.1,
      "step": 520,
      "total_loss": 0.6903544664382935,
      "weighted_orthogonal_loss": 0.016085363924503326
    },
    {
      "classification_loss": 0.6976214051246643,
      "epoch": 1.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1604287475347519,
      "orthogonal_weight": 0.1,
      "step": 521,
      "total_loss": 0.7136642932891846,
      "weighted_orthogonal_loss": 0.01604287512600422
    },
    {
      "classification_loss": 0.7529674172401428,
      "epoch": 1.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16012297570705414,
      "orthogonal_weight": 0.1,
      "step": 522,
      "total_loss": 0.7689797282218933,
      "weighted_orthogonal_loss": 0.016012297943234444
    },
    {
      "classification_loss": 0.6413609981536865,
      "epoch": 1.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15988200902938843,
      "orthogonal_weight": 0.1,
      "step": 523,
      "total_loss": 0.6573492288589478,
      "weighted_orthogonal_loss": 0.015988200902938843
    },
    {
      "classification_loss": 0.6290376782417297,
      "epoch": 1.7180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1596118062734604,
      "orthogonal_weight": 0.1,
      "step": 524,
      "total_loss": 0.6449988484382629,
      "weighted_orthogonal_loss": 0.0159611813724041
    },
    {
      "classification_loss": 0.7045848965644836,
      "epoch": 1.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1595068871974945,
      "orthogonal_weight": 0.1,
      "step": 525,
      "total_loss": 0.7205355763435364,
      "weighted_orthogonal_loss": 0.01595068909227848
    },
    {
      "classification_loss": 0.6631888747215271,
      "epoch": 1.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15940093994140625,
      "orthogonal_weight": 0.1,
      "step": 526,
      "total_loss": 0.6791289448738098,
      "weighted_orthogonal_loss": 0.015940094366669655
    },
    {
      "classification_loss": 0.7032192945480347,
      "epoch": 1.7278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15918423235416412,
      "orthogonal_weight": 0.1,
      "step": 527,
      "total_loss": 0.7191377282142639,
      "weighted_orthogonal_loss": 0.015918424353003502
    },
    {
      "classification_loss": 0.6446242332458496,
      "epoch": 1.7311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15885744988918304,
      "orthogonal_weight": 0.1,
      "step": 528,
      "total_loss": 0.6605100035667419,
      "weighted_orthogonal_loss": 0.015885746106505394
    },
    {
      "classification_loss": 0.6340620517730713,
      "epoch": 1.7344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15841656923294067,
      "orthogonal_weight": 0.1,
      "step": 529,
      "total_loss": 0.6499037146568298,
      "weighted_orthogonal_loss": 0.015841657295823097
    },
    {
      "classification_loss": 0.6745927929878235,
      "epoch": 1.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15796461701393127,
      "orthogonal_weight": 0.1,
      "step": 530,
      "total_loss": 0.6903892755508423,
      "weighted_orthogonal_loss": 0.015796462073922157
    },
    {
      "classification_loss": 0.6513535976409912,
      "epoch": 1.7409836065573772,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15751753747463226,
      "orthogonal_weight": 0.1,
      "step": 531,
      "total_loss": 0.6671053767204285,
      "weighted_orthogonal_loss": 0.015751754865050316
    },
    {
      "classification_loss": 0.7154311537742615,
      "epoch": 1.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15708930790424347,
      "orthogonal_weight": 0.1,
      "step": 532,
      "total_loss": 0.7311400771141052,
      "weighted_orthogonal_loss": 0.015708930790424347
    },
    {
      "classification_loss": 0.6916189789772034,
      "epoch": 1.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1566482037305832,
      "orthogonal_weight": 0.1,
      "step": 533,
      "total_loss": 0.7072837948799133,
      "weighted_orthogonal_loss": 0.01566482149064541
    },
    {
      "classification_loss": 0.6954048275947571,
      "epoch": 1.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1561947464942932,
      "orthogonal_weight": 0.1,
      "step": 534,
      "total_loss": 0.711024284362793,
      "weighted_orthogonal_loss": 0.015619474463164806
    },
    {
      "classification_loss": 0.6907498240470886,
      "epoch": 1.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1557590663433075,
      "orthogonal_weight": 0.1,
      "step": 535,
      "total_loss": 0.7063257098197937,
      "weighted_orthogonal_loss": 0.015575907193124294
    },
    {
      "classification_loss": 0.6788167953491211,
      "epoch": 1.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15538795292377472,
      "orthogonal_weight": 0.1,
      "step": 536,
      "total_loss": 0.6943556070327759,
      "weighted_orthogonal_loss": 0.015538795851171017
    },
    {
      "classification_loss": 0.6712943911552429,
      "epoch": 1.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1542268842458725,
      "orthogonal_weight": 0.1,
      "step": 537,
      "total_loss": 0.6867170929908752,
      "weighted_orthogonal_loss": 0.01542268879711628
    },
    {
      "classification_loss": 0.673389196395874,
      "epoch": 1.7639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.153333380818367,
      "orthogonal_weight": 0.1,
      "step": 538,
      "total_loss": 0.688722550868988,
      "weighted_orthogonal_loss": 0.015333338640630245
    },
    {
      "classification_loss": 0.7303884625434875,
      "epoch": 1.7672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15265551209449768,
      "orthogonal_weight": 0.1,
      "step": 539,
      "total_loss": 0.7456539869308472,
      "weighted_orthogonal_loss": 0.015265551395714283
    },
    {
      "classification_loss": 0.7153174877166748,
      "epoch": 1.7704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1521044671535492,
      "orthogonal_weight": 0.1,
      "step": 540,
      "total_loss": 0.730527937412262,
      "weighted_orthogonal_loss": 0.015210446901619434
    },
    {
      "classification_loss": 0.7162790298461914,
      "epoch": 1.7737704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15162280201911926,
      "orthogonal_weight": 0.1,
      "step": 541,
      "total_loss": 0.7314413189888,
      "weighted_orthogonal_loss": 0.015162280760705471
    },
    {
      "classification_loss": 0.6909464597702026,
      "epoch": 1.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.151070237159729,
      "orthogonal_weight": 0.1,
      "step": 542,
      "total_loss": 0.7060534954071045,
      "weighted_orthogonal_loss": 0.015107023529708385
    },
    {
      "classification_loss": 0.6629173159599304,
      "epoch": 1.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1504497230052948,
      "orthogonal_weight": 0.1,
      "step": 543,
      "total_loss": 0.6779623031616211,
      "weighted_orthogonal_loss": 0.01504497230052948
    },
    {
      "classification_loss": 0.6942386627197266,
      "epoch": 1.7836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1501297503709793,
      "orthogonal_weight": 0.1,
      "step": 544,
      "total_loss": 0.7092516422271729,
      "weighted_orthogonal_loss": 0.015012974850833416
    },
    {
      "classification_loss": 0.6623823642730713,
      "epoch": 1.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499616652727127,
      "orthogonal_weight": 0.1,
      "step": 545,
      "total_loss": 0.6773785352706909,
      "weighted_orthogonal_loss": 0.014996166341006756
    },
    {
      "classification_loss": 0.7166447043418884,
      "epoch": 1.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14966797828674316,
      "orthogonal_weight": 0.1,
      "step": 546,
      "total_loss": 0.7316114902496338,
      "weighted_orthogonal_loss": 0.014966798014938831
    },
    {
      "classification_loss": 0.6748201251029968,
      "epoch": 1.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494189351797104,
      "orthogonal_weight": 0.1,
      "step": 547,
      "total_loss": 0.6897619962692261,
      "weighted_orthogonal_loss": 0.014941893517971039
    },
    {
      "classification_loss": 0.6781036853790283,
      "epoch": 1.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14928293228149414,
      "orthogonal_weight": 0.1,
      "step": 548,
      "total_loss": 0.6930319666862488,
      "weighted_orthogonal_loss": 0.014928293414413929
    },
    {
      "classification_loss": 0.6911383867263794,
      "epoch": 1.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14914549887180328,
      "orthogonal_weight": 0.1,
      "step": 549,
      "total_loss": 0.7060529589653015,
      "weighted_orthogonal_loss": 0.014914549887180328
    },
    {
      "classification_loss": 0.6598801016807556,
      "epoch": 1.8032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1489856094121933,
      "orthogonal_weight": 0.1,
      "step": 550,
      "total_loss": 0.6747786402702332,
      "weighted_orthogonal_loss": 0.01489856094121933
    },
    {
      "classification_loss": 0.687782883644104,
      "epoch": 1.8065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1488451361656189,
      "orthogonal_weight": 0.1,
      "step": 551,
      "total_loss": 0.7026674151420593,
      "weighted_orthogonal_loss": 0.014884513802826405
    },
    {
      "classification_loss": 0.6797230243682861,
      "epoch": 1.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.148699551820755,
      "orthogonal_weight": 0.1,
      "step": 552,
      "total_loss": 0.6945929527282715,
      "weighted_orthogonal_loss": 0.014869955368340015
    },
    {
      "classification_loss": 0.6728688478469849,
      "epoch": 1.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14851832389831543,
      "orthogonal_weight": 0.1,
      "step": 553,
      "total_loss": 0.6877206563949585,
      "weighted_orthogonal_loss": 0.014851832762360573
    },
    {
      "classification_loss": 0.702341616153717,
      "epoch": 1.8163934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14819061756134033,
      "orthogonal_weight": 0.1,
      "step": 554,
      "total_loss": 0.717160701751709,
      "weighted_orthogonal_loss": 0.014819062314927578
    },
    {
      "classification_loss": 0.633303701877594,
      "epoch": 1.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14776109158992767,
      "orthogonal_weight": 0.1,
      "step": 555,
      "total_loss": 0.6480798125267029,
      "weighted_orthogonal_loss": 0.014776109717786312
    },
    {
      "classification_loss": 0.6701069474220276,
      "epoch": 1.8229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14690662920475006,
      "orthogonal_weight": 0.1,
      "step": 556,
      "total_loss": 0.6847975850105286,
      "weighted_orthogonal_loss": 0.014690662734210491
    },
    {
      "classification_loss": 0.6900566816329956,
      "epoch": 1.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1460864096879959,
      "orthogonal_weight": 0.1,
      "step": 557,
      "total_loss": 0.7046653032302856,
      "weighted_orthogonal_loss": 0.014608641155064106
    },
    {
      "classification_loss": 0.678128182888031,
      "epoch": 1.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14554257690906525,
      "orthogonal_weight": 0.1,
      "step": 558,
      "total_loss": 0.6926824450492859,
      "weighted_orthogonal_loss": 0.01455425750464201
    },
    {
      "classification_loss": 0.6623897552490234,
      "epoch": 1.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14503592252731323,
      "orthogonal_weight": 0.1,
      "step": 559,
      "total_loss": 0.6768933534622192,
      "weighted_orthogonal_loss": 0.014503592625260353
    },
    {
      "classification_loss": 0.6897371411323547,
      "epoch": 1.8360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1446065753698349,
      "orthogonal_weight": 0.1,
      "step": 560,
      "total_loss": 0.7041978240013123,
      "weighted_orthogonal_loss": 0.014460657723248005
    },
    {
      "classification_loss": 0.6643086671829224,
      "epoch": 1.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1443159431219101,
      "orthogonal_weight": 0.1,
      "step": 561,
      "total_loss": 0.6787402629852295,
      "weighted_orthogonal_loss": 0.014431594870984554
    },
    {
      "classification_loss": 0.7102059721946716,
      "epoch": 1.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14404208958148956,
      "orthogonal_weight": 0.1,
      "step": 562,
      "total_loss": 0.7246102094650269,
      "weighted_orthogonal_loss": 0.014404209330677986
    },
    {
      "classification_loss": 0.67300945520401,
      "epoch": 1.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14370444416999817,
      "orthogonal_weight": 0.1,
      "step": 563,
      "total_loss": 0.6873798966407776,
      "weighted_orthogonal_loss": 0.014370444230735302
    },
    {
      "classification_loss": 0.6220810413360596,
      "epoch": 1.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14320655167102814,
      "orthogonal_weight": 0.1,
      "step": 564,
      "total_loss": 0.6364017128944397,
      "weighted_orthogonal_loss": 0.014320655725896358
    },
    {
      "classification_loss": 0.6533961296081543,
      "epoch": 1.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14277732372283936,
      "orthogonal_weight": 0.1,
      "step": 565,
      "total_loss": 0.6676738858222961,
      "weighted_orthogonal_loss": 0.01427773293107748
    },
    {
      "classification_loss": 0.6745474338531494,
      "epoch": 1.8557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14240027964115143,
      "orthogonal_weight": 0.1,
      "step": 566,
      "total_loss": 0.6887874603271484,
      "weighted_orthogonal_loss": 0.014240028336644173
    },
    {
      "classification_loss": 0.698609471321106,
      "epoch": 1.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14214394986629486,
      "orthogonal_weight": 0.1,
      "step": 567,
      "total_loss": 0.7128238677978516,
      "weighted_orthogonal_loss": 0.01421439554542303
    },
    {
      "classification_loss": 0.6419087648391724,
      "epoch": 1.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14184780418872833,
      "orthogonal_weight": 0.1,
      "step": 568,
      "total_loss": 0.6560935378074646,
      "weighted_orthogonal_loss": 0.014184780418872833
    },
    {
      "classification_loss": 0.694909393787384,
      "epoch": 1.8655737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14153876900672913,
      "orthogonal_weight": 0.1,
      "step": 569,
      "total_loss": 0.7090632915496826,
      "weighted_orthogonal_loss": 0.014153877273201942
    },
    {
      "classification_loss": 0.6412785649299622,
      "epoch": 1.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14126992225646973,
      "orthogonal_weight": 0.1,
      "step": 570,
      "total_loss": 0.655405580997467,
      "weighted_orthogonal_loss": 0.014126992784440517
    },
    {
      "classification_loss": 0.6837173700332642,
      "epoch": 1.8721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14096276462078094,
      "orthogonal_weight": 0.1,
      "step": 571,
      "total_loss": 0.6978136301040649,
      "weighted_orthogonal_loss": 0.014096276834607124
    },
    {
      "classification_loss": 0.6645664572715759,
      "epoch": 1.8754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14063993096351624,
      "orthogonal_weight": 0.1,
      "step": 572,
      "total_loss": 0.6786304712295532,
      "weighted_orthogonal_loss": 0.014063993468880653
    },
    {
      "classification_loss": 0.7072283625602722,
      "epoch": 1.8786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1403225213289261,
      "orthogonal_weight": 0.1,
      "step": 573,
      "total_loss": 0.7212606072425842,
      "weighted_orthogonal_loss": 0.014032252132892609
    },
    {
      "classification_loss": 0.6770250797271729,
      "epoch": 1.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1400606632232666,
      "orthogonal_weight": 0.1,
      "step": 574,
      "total_loss": 0.6910311579704285,
      "weighted_orthogonal_loss": 0.014006066136062145
    },
    {
      "classification_loss": 0.6395100355148315,
      "epoch": 1.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13982629776000977,
      "orthogonal_weight": 0.1,
      "step": 575,
      "total_loss": 0.6534926891326904,
      "weighted_orthogonal_loss": 0.013982630334794521
    },
    {
      "classification_loss": 0.7033917307853699,
      "epoch": 1.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13953913748264313,
      "orthogonal_weight": 0.1,
      "step": 576,
      "total_loss": 0.717345654964447,
      "weighted_orthogonal_loss": 0.013953913934528828
    },
    {
      "classification_loss": 0.6750102639198303,
      "epoch": 1.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13926757872104645,
      "orthogonal_weight": 0.1,
      "step": 577,
      "total_loss": 0.6889370083808899,
      "weighted_orthogonal_loss": 0.01392675843089819
    },
    {
      "classification_loss": 0.6576554179191589,
      "epoch": 1.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13851593434810638,
      "orthogonal_weight": 0.1,
      "step": 578,
      "total_loss": 0.6715070009231567,
      "weighted_orthogonal_loss": 0.013851593248546124
    },
    {
      "classification_loss": 0.6514862775802612,
      "epoch": 1.8983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13794907927513123,
      "orthogonal_weight": 0.1,
      "step": 579,
      "total_loss": 0.6652811765670776,
      "weighted_orthogonal_loss": 0.013794908300042152
    },
    {
      "classification_loss": 0.6984235644340515,
      "epoch": 1.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13766491413116455,
      "orthogonal_weight": 0.1,
      "step": 580,
      "total_loss": 0.7121900320053101,
      "weighted_orthogonal_loss": 0.013766491785645485
    },
    {
      "classification_loss": 0.686271071434021,
      "epoch": 1.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13755981624126434,
      "orthogonal_weight": 0.1,
      "step": 581,
      "total_loss": 0.7000270485877991,
      "weighted_orthogonal_loss": 0.01375598181039095
    },
    {
      "classification_loss": 0.6999109983444214,
      "epoch": 1.9081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374008059501648,
      "orthogonal_weight": 0.1,
      "step": 582,
      "total_loss": 0.7136510610580444,
      "weighted_orthogonal_loss": 0.013740080408751965
    },
    {
      "classification_loss": 0.6921502947807312,
      "epoch": 1.9114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13742932677268982,
      "orthogonal_weight": 0.1,
      "step": 583,
      "total_loss": 0.7058932185173035,
      "weighted_orthogonal_loss": 0.013742933049798012
    },
    {
      "classification_loss": 0.6701326370239258,
      "epoch": 1.9147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749286532402039,
      "orthogonal_weight": 0.1,
      "step": 584,
      "total_loss": 0.683881938457489,
      "weighted_orthogonal_loss": 0.013749286532402039
    },
    {
      "classification_loss": 0.7110649943351746,
      "epoch": 1.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13728605210781097,
      "orthogonal_weight": 0.1,
      "step": 585,
      "total_loss": 0.7247936129570007,
      "weighted_orthogonal_loss": 0.013728605583310127
    },
    {
      "classification_loss": 0.708429753780365,
      "epoch": 1.9213114754098362,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13719774782657623,
      "orthogonal_weight": 0.1,
      "step": 586,
      "total_loss": 0.7221495509147644,
      "weighted_orthogonal_loss": 0.013719774782657623
    },
    {
      "classification_loss": 0.6886913776397705,
      "epoch": 1.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13714773952960968,
      "orthogonal_weight": 0.1,
      "step": 587,
      "total_loss": 0.7024061679840088,
      "weighted_orthogonal_loss": 0.013714774511754513
    },
    {
      "classification_loss": 0.6668559312820435,
      "epoch": 1.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717372715473175,
      "orthogonal_weight": 0.1,
      "step": 588,
      "total_loss": 0.6805732846260071,
      "weighted_orthogonal_loss": 0.01371737290173769
    },
    {
      "classification_loss": 0.7039204239845276,
      "epoch": 1.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13724878430366516,
      "orthogonal_weight": 0.1,
      "step": 589,
      "total_loss": 0.7176452875137329,
      "weighted_orthogonal_loss": 0.013724878430366516
    },
    {
      "classification_loss": 0.7200135588645935,
      "epoch": 1.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13761326670646667,
      "orthogonal_weight": 0.1,
      "step": 590,
      "total_loss": 0.7337749004364014,
      "weighted_orthogonal_loss": 0.013761326670646667
    },
    {
      "classification_loss": 0.6630491018295288,
      "epoch": 1.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13779278099536896,
      "orthogonal_weight": 0.1,
      "step": 591,
      "total_loss": 0.6768283843994141,
      "weighted_orthogonal_loss": 0.01377927791327238
    },
    {
      "classification_loss": 0.6379361748695374,
      "epoch": 1.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13794578611850739,
      "orthogonal_weight": 0.1,
      "step": 592,
      "total_loss": 0.6517307758331299,
      "weighted_orthogonal_loss": 0.013794578611850739
    },
    {
      "classification_loss": 0.6700040698051453,
      "epoch": 1.9442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13812491297721863,
      "orthogonal_weight": 0.1,
      "step": 593,
      "total_loss": 0.6838165521621704,
      "weighted_orthogonal_loss": 0.013812491670250893
    },
    {
      "classification_loss": 0.7326921224594116,
      "epoch": 1.9475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1383545696735382,
      "orthogonal_weight": 0.1,
      "step": 594,
      "total_loss": 0.7465275526046753,
      "weighted_orthogonal_loss": 0.013835457153618336
    },
    {
      "classification_loss": 0.7327626347541809,
      "epoch": 1.9508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13847258687019348,
      "orthogonal_weight": 0.1,
      "step": 595,
      "total_loss": 0.7466098666191101,
      "weighted_orthogonal_loss": 0.013847258873283863
    },
    {
      "classification_loss": 0.6691921949386597,
      "epoch": 1.9540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13859684765338898,
      "orthogonal_weight": 0.1,
      "step": 596,
      "total_loss": 0.6830518841743469,
      "weighted_orthogonal_loss": 0.013859684579074383
    },
    {
      "classification_loss": 0.703101634979248,
      "epoch": 1.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13875575363636017,
      "orthogonal_weight": 0.1,
      "step": 597,
      "total_loss": 0.7169772386550903,
      "weighted_orthogonal_loss": 0.013875575736165047
    },
    {
      "classification_loss": 0.7006300091743469,
      "epoch": 1.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388891637325287,
      "orthogonal_weight": 0.1,
      "step": 598,
      "total_loss": 0.7145189046859741,
      "weighted_orthogonal_loss": 0.013888916932046413
    },
    {
      "classification_loss": 0.6764107346534729,
      "epoch": 1.9639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13902297616004944,
      "orthogonal_weight": 0.1,
      "step": 599,
      "total_loss": 0.6903130412101746,
      "weighted_orthogonal_loss": 0.013902298174798489
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 5.76666259765625,
      "learning_rate": 0.00018336666666666666,
      "loss": 0.6972,
      "step": 600
    },
    {
      "classification_loss": 0.7128793597221375,
      "epoch": 1.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920684158802032,
      "orthogonal_weight": 0.1,
      "step": 600,
      "total_loss": 0.7268000245094299,
      "weighted_orthogonal_loss": 0.013920684345066547
    },
    {
      "classification_loss": 0.7261967062950134,
      "epoch": 1.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13937316834926605,
      "orthogonal_weight": 0.1,
      "step": 601,
      "total_loss": 0.7401340007781982,
      "weighted_orthogonal_loss": 0.013937316834926605
    },
    {
      "classification_loss": 0.6677441000938416,
      "epoch": 1.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13952071964740753,
      "orthogonal_weight": 0.1,
      "step": 602,
      "total_loss": 0.6816961765289307,
      "weighted_orthogonal_loss": 0.013952071778476238
    },
    {
      "classification_loss": 0.6802635788917542,
      "epoch": 1.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13943995535373688,
      "orthogonal_weight": 0.1,
      "step": 603,
      "total_loss": 0.6942075490951538,
      "weighted_orthogonal_loss": 0.013943995349109173
    },
    {
      "classification_loss": 0.6451836824417114,
      "epoch": 1.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13937599956989288,
      "orthogonal_weight": 0.1,
      "step": 604,
      "total_loss": 0.6591212749481201,
      "weighted_orthogonal_loss": 0.013937599956989288
    },
    {
      "classification_loss": 0.6391912698745728,
      "epoch": 1.9836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13938020169734955,
      "orthogonal_weight": 0.1,
      "step": 605,
      "total_loss": 0.6531292796134949,
      "weighted_orthogonal_loss": 0.01393801998347044
    },
    {
      "classification_loss": 0.7171729207038879,
      "epoch": 1.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1393430531024933,
      "orthogonal_weight": 0.1,
      "step": 606,
      "total_loss": 0.731107234954834,
      "weighted_orthogonal_loss": 0.013934305869042873
    },
    {
      "classification_loss": 0.6468100547790527,
      "epoch": 1.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392393857240677,
      "orthogonal_weight": 0.1,
      "step": 607,
      "total_loss": 0.6607339978218079,
      "weighted_orthogonal_loss": 0.013923938386142254
    },
    {
      "classification_loss": 0.6871572136878967,
      "epoch": 1.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13921351730823517,
      "orthogonal_weight": 0.1,
      "step": 608,
      "total_loss": 0.7010785937309265,
      "weighted_orthogonal_loss": 0.013921352103352547
    },
    {
      "classification_loss": 0.7371491193771362,
      "epoch": 1.9967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920044898986816,
      "orthogonal_weight": 0.1,
      "step": 609,
      "total_loss": 0.751069188117981,
      "weighted_orthogonal_loss": 0.013920045457780361
    },
    {
      "classification_loss": 0.6875877380371094,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.701511800289154,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6975090503692627,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.7114331126213074,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6771702170372009,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6910942792892456,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6785628199577332,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6924868822097778,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6814645528793335,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6953886151313782,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6839240193367004,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6978480815887451,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.676777720451355,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6907017827033997,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.7038714289665222,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.7177954912185669,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.541,
      "eval_f1": 0.6307320997586484,
      "eval_loss": 0.6993502378463745,
      "eval_precision": 0.632258064516129,
      "eval_recall": 0.6292134831460674,
      "eval_runtime": 6.2057,
      "eval_samples_per_second": 161.142,
      "eval_steps_per_second": 1.289,
      "step": 610
    },
    {
      "classification_loss": 0.6631269454956055,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6770510077476501,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.675663411617279,
      "epoch": 2.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13925881683826447,
      "orthogonal_weight": 0.1,
      "step": 611,
      "total_loss": 0.6895893216133118,
      "weighted_orthogonal_loss": 0.013925882056355476
    },
    {
      "classification_loss": 0.6387726068496704,
      "epoch": 2.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13921406865119934,
      "orthogonal_weight": 0.1,
      "step": 612,
      "total_loss": 0.6526939868927002,
      "weighted_orthogonal_loss": 0.013921407051384449
    },
    {
      "classification_loss": 0.6548963785171509,
      "epoch": 2.0098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390584111213684,
      "orthogonal_weight": 0.1,
      "step": 613,
      "total_loss": 0.6688022017478943,
      "weighted_orthogonal_loss": 0.013905840925872326
    },
    {
      "classification_loss": 0.6407982707023621,
      "epoch": 2.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388881802558899,
      "orthogonal_weight": 0.1,
      "step": 614,
      "total_loss": 0.6546871066093445,
      "weighted_orthogonal_loss": 0.013888818211853504
    },
    {
      "classification_loss": 0.6849182844161987,
      "epoch": 2.0163934426229506,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13884204626083374,
      "orthogonal_weight": 0.1,
      "step": 615,
      "total_loss": 0.6988024711608887,
      "weighted_orthogonal_loss": 0.013884204439818859
    },
    {
      "classification_loss": 0.6662309765815735,
      "epoch": 2.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13867796957492828,
      "orthogonal_weight": 0.1,
      "step": 616,
      "total_loss": 0.6800987720489502,
      "weighted_orthogonal_loss": 0.013867797330021858
    },
    {
      "classification_loss": 0.642135500907898,
      "epoch": 2.0229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13850991427898407,
      "orthogonal_weight": 0.1,
      "step": 617,
      "total_loss": 0.655986487865448,
      "weighted_orthogonal_loss": 0.013850991614162922
    },
    {
      "classification_loss": 0.6575379967689514,
      "epoch": 2.0262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13836674392223358,
      "orthogonal_weight": 0.1,
      "step": 618,
      "total_loss": 0.6713746786117554,
      "weighted_orthogonal_loss": 0.013836674392223358
    },
    {
      "classification_loss": 0.6869693398475647,
      "epoch": 2.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1379912793636322,
      "orthogonal_weight": 0.1,
      "step": 619,
      "total_loss": 0.7007684707641602,
      "weighted_orthogonal_loss": 0.013799128122627735
    },
    {
      "classification_loss": 0.611780047416687,
      "epoch": 2.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376379132270813,
      "orthogonal_weight": 0.1,
      "step": 620,
      "total_loss": 0.6255438327789307,
      "weighted_orthogonal_loss": 0.013763791881501675
    },
    {
      "classification_loss": 0.70892333984375,
      "epoch": 2.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13726922869682312,
      "orthogonal_weight": 0.1,
      "step": 621,
      "total_loss": 0.7226502895355225,
      "weighted_orthogonal_loss": 0.013726922683417797
    },
    {
      "classification_loss": 0.7123057842254639,
      "epoch": 2.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13700713217258453,
      "orthogonal_weight": 0.1,
      "step": 622,
      "total_loss": 0.7260065078735352,
      "weighted_orthogonal_loss": 0.013700713403522968
    },
    {
      "classification_loss": 0.6245718598365784,
      "epoch": 2.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1368894875049591,
      "orthogonal_weight": 0.1,
      "step": 623,
      "total_loss": 0.6382607817649841,
      "weighted_orthogonal_loss": 0.013688948936760426
    },
    {
      "classification_loss": 0.6619150638580322,
      "epoch": 2.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367984414100647,
      "orthogonal_weight": 0.1,
      "step": 624,
      "total_loss": 0.6755949258804321,
      "weighted_orthogonal_loss": 0.013679844327270985
    },
    {
      "classification_loss": 0.6552832722663879,
      "epoch": 2.0491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1366952657699585,
      "orthogonal_weight": 0.1,
      "step": 625,
      "total_loss": 0.6689528226852417,
      "weighted_orthogonal_loss": 0.013669527135789394
    },
    {
      "classification_loss": 0.6902874112129211,
      "epoch": 2.0524590163934424,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13661396503448486,
      "orthogonal_weight": 0.1,
      "step": 626,
      "total_loss": 0.7039487957954407,
      "weighted_orthogonal_loss": 0.013661396689713001
    },
    {
      "classification_loss": 0.6807511448860168,
      "epoch": 2.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364680975675583,
      "orthogonal_weight": 0.1,
      "step": 627,
      "total_loss": 0.6943979263305664,
      "weighted_orthogonal_loss": 0.013646810315549374
    },
    {
      "classification_loss": 0.6690577268600464,
      "epoch": 2.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13634343445301056,
      "orthogonal_weight": 0.1,
      "step": 628,
      "total_loss": 0.6826920509338379,
      "weighted_orthogonal_loss": 0.01363434363156557
    },
    {
      "classification_loss": 0.6825783848762512,
      "epoch": 2.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13626503944396973,
      "orthogonal_weight": 0.1,
      "step": 629,
      "total_loss": 0.6962049007415771,
      "weighted_orthogonal_loss": 0.013626503758132458
    },
    {
      "classification_loss": 0.6807635426521301,
      "epoch": 2.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13629209995269775,
      "orthogonal_weight": 0.1,
      "step": 630,
      "total_loss": 0.694392740726471,
      "weighted_orthogonal_loss": 0.01362921018153429
    },
    {
      "classification_loss": 0.663696825504303,
      "epoch": 2.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13637283444404602,
      "orthogonal_weight": 0.1,
      "step": 631,
      "total_loss": 0.6773341298103333,
      "weighted_orthogonal_loss": 0.013637283816933632
    },
    {
      "classification_loss": 0.6620309352874756,
      "epoch": 2.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13646617531776428,
      "orthogonal_weight": 0.1,
      "step": 632,
      "total_loss": 0.6756775379180908,
      "weighted_orthogonal_loss": 0.013646617531776428
    },
    {
      "classification_loss": 0.6384421586990356,
      "epoch": 2.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13617035746574402,
      "orthogonal_weight": 0.1,
      "step": 633,
      "total_loss": 0.6520591974258423,
      "weighted_orthogonal_loss": 0.013617035932838917
    },
    {
      "classification_loss": 0.6761725544929504,
      "epoch": 2.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359611302614212,
      "orthogonal_weight": 0.1,
      "step": 634,
      "total_loss": 0.6897686719894409,
      "weighted_orthogonal_loss": 0.013596112839877605
    },
    {
      "classification_loss": 0.6678457260131836,
      "epoch": 2.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580960035324097,
      "orthogonal_weight": 0.1,
      "step": 635,
      "total_loss": 0.6814267039299011,
      "weighted_orthogonal_loss": 0.013580960221588612
    },
    {
      "classification_loss": 0.6220820546150208,
      "epoch": 2.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13573512434959412,
      "orthogonal_weight": 0.1,
      "step": 636,
      "total_loss": 0.6356555819511414,
      "weighted_orthogonal_loss": 0.013573512434959412
    },
    {
      "classification_loss": 0.6857736706733704,
      "epoch": 2.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13564720749855042,
      "orthogonal_weight": 0.1,
      "step": 637,
      "total_loss": 0.6993383765220642,
      "weighted_orthogonal_loss": 0.013564720749855042
    },
    {
      "classification_loss": 0.6384184956550598,
      "epoch": 2.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13563299179077148,
      "orthogonal_weight": 0.1,
      "step": 638,
      "total_loss": 0.651981770992279,
      "weighted_orthogonal_loss": 0.013563299551606178
    },
    {
      "classification_loss": 0.6587923765182495,
      "epoch": 2.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13565748929977417,
      "orthogonal_weight": 0.1,
      "step": 639,
      "total_loss": 0.6723581552505493,
      "weighted_orthogonal_loss": 0.013565748929977417
    },
    {
      "classification_loss": 0.6565413475036621,
      "epoch": 2.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356365829706192,
      "orthogonal_weight": 0.1,
      "step": 640,
      "total_loss": 0.67010498046875,
      "weighted_orthogonal_loss": 0.013563658110797405
    },
    {
      "classification_loss": 0.7034303545951843,
      "epoch": 2.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356664001941681,
      "orthogonal_weight": 0.1,
      "step": 641,
      "total_loss": 0.716996967792511,
      "weighted_orthogonal_loss": 0.013566640205681324
    },
    {
      "classification_loss": 0.6701549887657166,
      "epoch": 2.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13556678593158722,
      "orthogonal_weight": 0.1,
      "step": 642,
      "total_loss": 0.6837116479873657,
      "weighted_orthogonal_loss": 0.013556678779423237
    },
    {
      "classification_loss": 0.6694207191467285,
      "epoch": 2.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355249434709549,
      "orthogonal_weight": 0.1,
      "step": 643,
      "total_loss": 0.6829732060432434,
      "weighted_orthogonal_loss": 0.01355249434709549
    },
    {
      "classification_loss": 0.6858741641044617,
      "epoch": 2.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13551096618175507,
      "orthogonal_weight": 0.1,
      "step": 644,
      "total_loss": 0.6994252800941467,
      "weighted_orthogonal_loss": 0.013551096431910992
    },
    {
      "classification_loss": 0.6497952342033386,
      "epoch": 2.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13546089828014374,
      "orthogonal_weight": 0.1,
      "step": 645,
      "total_loss": 0.6633413434028625,
      "weighted_orthogonal_loss": 0.013546089641749859
    },
    {
      "classification_loss": 0.6224135160446167,
      "epoch": 2.1180327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13543754816055298,
      "orthogonal_weight": 0.1,
      "step": 646,
      "total_loss": 0.6359572410583496,
      "weighted_orthogonal_loss": 0.013543754816055298
    },
    {
      "classification_loss": 0.6452400088310242,
      "epoch": 2.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13539569079875946,
      "orthogonal_weight": 0.1,
      "step": 647,
      "total_loss": 0.6587795615196228,
      "weighted_orthogonal_loss": 0.013539569452404976
    },
    {
      "classification_loss": 0.6707666516304016,
      "epoch": 2.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13537713885307312,
      "orthogonal_weight": 0.1,
      "step": 648,
      "total_loss": 0.6843043565750122,
      "weighted_orthogonal_loss": 0.013537714257836342
    },
    {
      "classification_loss": 0.5907464027404785,
      "epoch": 2.1278688524590166,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13520202040672302,
      "orthogonal_weight": 0.1,
      "step": 649,
      "total_loss": 0.6042665839195251,
      "weighted_orthogonal_loss": 0.013520202599465847
    },
    {
      "classification_loss": 0.6476250290870667,
      "epoch": 2.1311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13502950966358185,
      "orthogonal_weight": 0.1,
      "step": 650,
      "total_loss": 0.6611279845237732,
      "weighted_orthogonal_loss": 0.01350295078009367
    },
    {
      "classification_loss": 0.7083233594894409,
      "epoch": 2.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1348603516817093,
      "orthogonal_weight": 0.1,
      "step": 651,
      "total_loss": 0.7218093872070312,
      "weighted_orthogonal_loss": 0.013486035168170929
    },
    {
      "classification_loss": 0.7047362923622131,
      "epoch": 2.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13471588492393494,
      "orthogonal_weight": 0.1,
      "step": 652,
      "total_loss": 0.7182078957557678,
      "weighted_orthogonal_loss": 0.013471588492393494
    },
    {
      "classification_loss": 0.6722798347473145,
      "epoch": 2.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13455533981323242,
      "orthogonal_weight": 0.1,
      "step": 653,
      "total_loss": 0.6857353448867798,
      "weighted_orthogonal_loss": 0.013455534353852272
    },
    {
      "classification_loss": 0.7083224654197693,
      "epoch": 2.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13442426919937134,
      "orthogonal_weight": 0.1,
      "step": 654,
      "total_loss": 0.7217649221420288,
      "weighted_orthogonal_loss": 0.013442426919937134
    },
    {
      "classification_loss": 0.6549153923988342,
      "epoch": 2.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13423489034175873,
      "orthogonal_weight": 0.1,
      "step": 655,
      "total_loss": 0.6683388948440552,
      "weighted_orthogonal_loss": 0.013423489406704903
    },
    {
      "classification_loss": 0.6784593462944031,
      "epoch": 2.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13399028778076172,
      "orthogonal_weight": 0.1,
      "step": 656,
      "total_loss": 0.6918583512306213,
      "weighted_orthogonal_loss": 0.013399029150605202
    },
    {
      "classification_loss": 0.6990267634391785,
      "epoch": 2.1540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336912214756012,
      "orthogonal_weight": 0.1,
      "step": 657,
      "total_loss": 0.7123959064483643,
      "weighted_orthogonal_loss": 0.01336912252008915
    },
    {
      "classification_loss": 0.7076823115348816,
      "epoch": 2.1573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13337381184101105,
      "orthogonal_weight": 0.1,
      "step": 658,
      "total_loss": 0.7210196852684021,
      "weighted_orthogonal_loss": 0.013337381184101105
    },
    {
      "classification_loss": 0.6760309338569641,
      "epoch": 2.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331375688314438,
      "orthogonal_weight": 0.1,
      "step": 659,
      "total_loss": 0.6893447041511536,
      "weighted_orthogonal_loss": 0.013313757255673409
    },
    {
      "classification_loss": 0.6378170847892761,
      "epoch": 2.1639344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13300246000289917,
      "orthogonal_weight": 0.1,
      "step": 660,
      "total_loss": 0.6511173248291016,
      "weighted_orthogonal_loss": 0.013300246559083462
    },
    {
      "classification_loss": 0.6846320033073425,
      "epoch": 2.1672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13282443583011627,
      "orthogonal_weight": 0.1,
      "step": 661,
      "total_loss": 0.6979144215583801,
      "weighted_orthogonal_loss": 0.013282443396747112
    },
    {
      "classification_loss": 0.6763468980789185,
      "epoch": 2.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13267169892787933,
      "orthogonal_weight": 0.1,
      "step": 662,
      "total_loss": 0.6896140575408936,
      "weighted_orthogonal_loss": 0.013267169706523418
    },
    {
      "classification_loss": 0.6610320210456848,
      "epoch": 2.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13266243040561676,
      "orthogonal_weight": 0.1,
      "step": 663,
      "total_loss": 0.6742982864379883,
      "weighted_orthogonal_loss": 0.013266243040561676
    },
    {
      "classification_loss": 0.653738796710968,
      "epoch": 2.177049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13273850083351135,
      "orthogonal_weight": 0.1,
      "step": 664,
      "total_loss": 0.667012631893158,
      "weighted_orthogonal_loss": 0.013273850083351135
    },
    {
      "classification_loss": 0.6513218283653259,
      "epoch": 2.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13276371359825134,
      "orthogonal_weight": 0.1,
      "step": 665,
      "total_loss": 0.6645982265472412,
      "weighted_orthogonal_loss": 0.01327637117356062
    },
    {
      "classification_loss": 0.6487203240394592,
      "epoch": 2.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1327941119670868,
      "orthogonal_weight": 0.1,
      "step": 666,
      "total_loss": 0.6619997620582581,
      "weighted_orthogonal_loss": 0.013279411010444164
    },
    {
      "classification_loss": 0.675567090511322,
      "epoch": 2.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13287211954593658,
      "orthogonal_weight": 0.1,
      "step": 667,
      "total_loss": 0.6888542771339417,
      "weighted_orthogonal_loss": 0.013287211768329144
    },
    {
      "classification_loss": 0.7040941715240479,
      "epoch": 2.1901639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13315258920192719,
      "orthogonal_weight": 0.1,
      "step": 668,
      "total_loss": 0.7174094319343567,
      "weighted_orthogonal_loss": 0.013315259478986263
    },
    {
      "classification_loss": 0.6608855128288269,
      "epoch": 2.1934426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13345582783222198,
      "orthogonal_weight": 0.1,
      "step": 669,
      "total_loss": 0.6742311120033264,
      "weighted_orthogonal_loss": 0.013345583342015743
    },
    {
      "classification_loss": 0.6971756219863892,
      "epoch": 2.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13375814259052277,
      "orthogonal_weight": 0.1,
      "step": 670,
      "total_loss": 0.7105514407157898,
      "weighted_orthogonal_loss": 0.013375814072787762
    },
    {
      "classification_loss": 0.6448794007301331,
      "epoch": 2.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340400129556656,
      "orthogonal_weight": 0.1,
      "step": 671,
      "total_loss": 0.6582834124565125,
      "weighted_orthogonal_loss": 0.013404001481831074
    },
    {
      "classification_loss": 0.693259596824646,
      "epoch": 2.2032786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1342400312423706,
      "orthogonal_weight": 0.1,
      "step": 672,
      "total_loss": 0.7066835761070251,
      "weighted_orthogonal_loss": 0.01342400349676609
    },
    {
      "classification_loss": 0.6841013431549072,
      "epoch": 2.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13444192707538605,
      "orthogonal_weight": 0.1,
      "step": 673,
      "total_loss": 0.6975455284118652,
      "weighted_orthogonal_loss": 0.013444192707538605
    },
    {
      "classification_loss": 0.682142972946167,
      "epoch": 2.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.134786456823349,
      "orthogonal_weight": 0.1,
      "step": 674,
      "total_loss": 0.6956216096878052,
      "weighted_orthogonal_loss": 0.01347864605486393
    },
    {
      "classification_loss": 0.6104218363761902,
      "epoch": 2.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13508690893650055,
      "orthogonal_weight": 0.1,
      "step": 675,
      "total_loss": 0.6239305138587952,
      "weighted_orthogonal_loss": 0.0135086914524436
    },
    {
      "classification_loss": 0.6623443961143494,
      "epoch": 2.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13531829416751862,
      "orthogonal_weight": 0.1,
      "step": 676,
      "total_loss": 0.6758762001991272,
      "weighted_orthogonal_loss": 0.013531829230487347
    },
    {
      "classification_loss": 0.6833042502403259,
      "epoch": 2.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13556654751300812,
      "orthogonal_weight": 0.1,
      "step": 677,
      "total_loss": 0.6968609094619751,
      "weighted_orthogonal_loss": 0.013556654565036297
    },
    {
      "classification_loss": 0.6507001519203186,
      "epoch": 2.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13581164181232452,
      "orthogonal_weight": 0.1,
      "step": 678,
      "total_loss": 0.6642813086509705,
      "weighted_orthogonal_loss": 0.013581164181232452
    },
    {
      "classification_loss": 0.7093213796615601,
      "epoch": 2.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13603872060775757,
      "orthogonal_weight": 0.1,
      "step": 679,
      "total_loss": 0.7229252457618713,
      "weighted_orthogonal_loss": 0.013603872619569302
    },
    {
      "classification_loss": 0.7039775252342224,
      "epoch": 2.2295081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13629214465618134,
      "orthogonal_weight": 0.1,
      "step": 680,
      "total_loss": 0.7176067233085632,
      "weighted_orthogonal_loss": 0.013629214838147163
    },
    {
      "classification_loss": 0.6764472126960754,
      "epoch": 2.2327868852459014,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13651417195796967,
      "orthogonal_weight": 0.1,
      "step": 681,
      "total_loss": 0.6900986433029175,
      "weighted_orthogonal_loss": 0.013651417568325996
    },
    {
      "classification_loss": 0.6565006375312805,
      "epoch": 2.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13639004528522491,
      "orthogonal_weight": 0.1,
      "step": 682,
      "total_loss": 0.6701396703720093,
      "weighted_orthogonal_loss": 0.013639004901051521
    },
    {
      "classification_loss": 0.6281178593635559,
      "epoch": 2.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13632190227508545,
      "orthogonal_weight": 0.1,
      "step": 683,
      "total_loss": 0.6417500376701355,
      "weighted_orthogonal_loss": 0.01363219041377306
    },
    {
      "classification_loss": 0.6676103472709656,
      "epoch": 2.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13626684248447418,
      "orthogonal_weight": 0.1,
      "step": 684,
      "total_loss": 0.6812370419502258,
      "weighted_orthogonal_loss": 0.013626684434711933
    },
    {
      "classification_loss": 0.6787033081054688,
      "epoch": 2.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13623791933059692,
      "orthogonal_weight": 0.1,
      "step": 685,
      "total_loss": 0.692327082157135,
      "weighted_orthogonal_loss": 0.013623791746795177
    },
    {
      "classification_loss": 0.724747359752655,
      "epoch": 2.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1362244039773941,
      "orthogonal_weight": 0.1,
      "step": 686,
      "total_loss": 0.7383698225021362,
      "weighted_orthogonal_loss": 0.01362244039773941
    },
    {
      "classification_loss": 0.6723162531852722,
      "epoch": 2.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13618119060993195,
      "orthogonal_weight": 0.1,
      "step": 687,
      "total_loss": 0.6859343647956848,
      "weighted_orthogonal_loss": 0.013618119060993195
    },
    {
      "classification_loss": 0.6489892601966858,
      "epoch": 2.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13610567152500153,
      "orthogonal_weight": 0.1,
      "step": 688,
      "total_loss": 0.6625998020172119,
      "weighted_orthogonal_loss": 0.013610566966235638
    },
    {
      "classification_loss": 0.6589500308036804,
      "epoch": 2.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13611848652362823,
      "orthogonal_weight": 0.1,
      "step": 689,
      "total_loss": 0.6725618839263916,
      "weighted_orthogonal_loss": 0.013611848466098309
    },
    {
      "classification_loss": 0.7106584906578064,
      "epoch": 2.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13620197772979736,
      "orthogonal_weight": 0.1,
      "step": 690,
      "total_loss": 0.7242786884307861,
      "weighted_orthogonal_loss": 0.013620197772979736
    },
    {
      "classification_loss": 0.6829169392585754,
      "epoch": 2.265573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13627304136753082,
      "orthogonal_weight": 0.1,
      "step": 691,
      "total_loss": 0.6965442299842834,
      "weighted_orthogonal_loss": 0.013627304695546627
    },
    {
      "classification_loss": 0.6879841089248657,
      "epoch": 2.2688524590163937,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1362990140914917,
      "orthogonal_weight": 0.1,
      "step": 692,
      "total_loss": 0.7016140222549438,
      "weighted_orthogonal_loss": 0.013629901222884655
    },
    {
      "classification_loss": 0.6426753997802734,
      "epoch": 2.2721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631261885166168,
      "orthogonal_weight": 0.1,
      "step": 693,
      "total_loss": 0.6563066840171814,
      "weighted_orthogonal_loss": 0.013631261885166168
    },
    {
      "classification_loss": 0.6372926235198975,
      "epoch": 2.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13635016977787018,
      "orthogonal_weight": 0.1,
      "step": 694,
      "total_loss": 0.6509276628494263,
      "weighted_orthogonal_loss": 0.013635016977787018
    },
    {
      "classification_loss": 0.6663371324539185,
      "epoch": 2.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364799588918686,
      "orthogonal_weight": 0.1,
      "step": 695,
      "total_loss": 0.6799851059913635,
      "weighted_orthogonal_loss": 0.013647995889186859
    },
    {
      "classification_loss": 0.6333184242248535,
      "epoch": 2.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13663217425346375,
      "orthogonal_weight": 0.1,
      "step": 696,
      "total_loss": 0.6469816565513611,
      "weighted_orthogonal_loss": 0.013663217425346375
    },
    {
      "classification_loss": 0.6347573399543762,
      "epoch": 2.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.136811763048172,
      "orthogonal_weight": 0.1,
      "step": 697,
      "total_loss": 0.6484385132789612,
      "weighted_orthogonal_loss": 0.013681176118552685
    },
    {
      "classification_loss": 0.7049899101257324,
      "epoch": 2.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1369539052248001,
      "orthogonal_weight": 0.1,
      "step": 698,
      "total_loss": 0.7186853289604187,
      "weighted_orthogonal_loss": 0.01369539089500904
    },
    {
      "classification_loss": 0.7018643021583557,
      "epoch": 2.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13712511956691742,
      "orthogonal_weight": 0.1,
      "step": 699,
      "total_loss": 0.7155768275260925,
      "weighted_orthogonal_loss": 0.013712512329220772
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 29.85932159423828,
      "learning_rate": 0.00018003333333333334,
      "loss": 0.6834,
      "step": 700
    },
    {
      "classification_loss": 0.6500634551048279,
      "epoch": 2.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13731978833675385,
      "orthogonal_weight": 0.1,
      "step": 700,
      "total_loss": 0.6637954115867615,
      "weighted_orthogonal_loss": 0.013731978833675385
    },
    {
      "classification_loss": 0.6840149164199829,
      "epoch": 2.2983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13740283250808716,
      "orthogonal_weight": 0.1,
      "step": 701,
      "total_loss": 0.6977552175521851,
      "weighted_orthogonal_loss": 0.01374028343707323
    },
    {
      "classification_loss": 0.7160877585411072,
      "epoch": 2.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13750162720680237,
      "orthogonal_weight": 0.1,
      "step": 702,
      "total_loss": 0.7298378944396973,
      "weighted_orthogonal_loss": 0.013750162906944752
    },
    {
      "classification_loss": 0.6590107083320618,
      "epoch": 2.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13765904307365417,
      "orthogonal_weight": 0.1,
      "step": 703,
      "total_loss": 0.6727766394615173,
      "weighted_orthogonal_loss": 0.013765904121100903
    },
    {
      "classification_loss": 0.6656896471977234,
      "epoch": 2.3081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378212720155716,
      "orthogonal_weight": 0.1,
      "step": 704,
      "total_loss": 0.6794717907905579,
      "weighted_orthogonal_loss": 0.013782127760350704
    },
    {
      "classification_loss": 0.6958256959915161,
      "epoch": 2.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13788287341594696,
      "orthogonal_weight": 0.1,
      "step": 705,
      "total_loss": 0.7096139788627625,
      "weighted_orthogonal_loss": 0.013788287527859211
    },
    {
      "classification_loss": 0.6539934873580933,
      "epoch": 2.314754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13775943219661713,
      "orthogonal_weight": 0.1,
      "step": 706,
      "total_loss": 0.6677694320678711,
      "weighted_orthogonal_loss": 0.013775943778455257
    },
    {
      "classification_loss": 0.6587193608283997,
      "epoch": 2.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13761484622955322,
      "orthogonal_weight": 0.1,
      "step": 707,
      "total_loss": 0.6724808216094971,
      "weighted_orthogonal_loss": 0.013761484995484352
    },
    {
      "classification_loss": 0.6556830406188965,
      "epoch": 2.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13748089969158173,
      "orthogonal_weight": 0.1,
      "step": 708,
      "total_loss": 0.6694311499595642,
      "weighted_orthogonal_loss": 0.013748089782893658
    },
    {
      "classification_loss": 0.660719633102417,
      "epoch": 2.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13735711574554443,
      "orthogonal_weight": 0.1,
      "step": 709,
      "total_loss": 0.6744553446769714,
      "weighted_orthogonal_loss": 0.013735711574554443
    },
    {
      "classification_loss": 0.6583676934242249,
      "epoch": 2.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717395067214966,
      "orthogonal_weight": 0.1,
      "step": 710,
      "total_loss": 0.6720851063728333,
      "weighted_orthogonal_loss": 0.01371739525347948
    },
    {
      "classification_loss": 0.6685340404510498,
      "epoch": 2.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13704493641853333,
      "orthogonal_weight": 0.1,
      "step": 711,
      "total_loss": 0.6822385191917419,
      "weighted_orthogonal_loss": 0.013704493641853333
    },
    {
      "classification_loss": 0.698114812374115,
      "epoch": 2.3344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13690166175365448,
      "orthogonal_weight": 0.1,
      "step": 712,
      "total_loss": 0.711804986000061,
      "weighted_orthogonal_loss": 0.013690166175365448
    },
    {
      "classification_loss": 0.6755896210670471,
      "epoch": 2.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367313265800476,
      "orthogonal_weight": 0.1,
      "step": 713,
      "total_loss": 0.6892627477645874,
      "weighted_orthogonal_loss": 0.013673133216798306
    },
    {
      "classification_loss": 0.6479446291923523,
      "epoch": 2.3409836065573773,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13653890788555145,
      "orthogonal_weight": 0.1,
      "step": 714,
      "total_loss": 0.6615985035896301,
      "weighted_orthogonal_loss": 0.013653891161084175
    },
    {
      "classification_loss": 0.6302591562271118,
      "epoch": 2.3442622950819674,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1363542526960373,
      "orthogonal_weight": 0.1,
      "step": 715,
      "total_loss": 0.6438945531845093,
      "weighted_orthogonal_loss": 0.013635425828397274
    },
    {
      "classification_loss": 0.6726948022842407,
      "epoch": 2.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13620375096797943,
      "orthogonal_weight": 0.1,
      "step": 716,
      "total_loss": 0.6863151788711548,
      "weighted_orthogonal_loss": 0.013620375655591488
    },
    {
      "classification_loss": 0.6483542919158936,
      "epoch": 2.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602259755134583,
      "orthogonal_weight": 0.1,
      "step": 717,
      "total_loss": 0.6619565486907959,
      "weighted_orthogonal_loss": 0.013602259568870068
    },
    {
      "classification_loss": 0.711586058139801,
      "epoch": 2.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13597945868968964,
      "orthogonal_weight": 0.1,
      "step": 718,
      "total_loss": 0.7251840233802795,
      "weighted_orthogonal_loss": 0.013597945682704449
    },
    {
      "classification_loss": 0.6360405683517456,
      "epoch": 2.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13603802025318146,
      "orthogonal_weight": 0.1,
      "step": 719,
      "total_loss": 0.6496443748474121,
      "weighted_orthogonal_loss": 0.01360380183905363
    },
    {
      "classification_loss": 0.6579926609992981,
      "epoch": 2.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13611911237239838,
      "orthogonal_weight": 0.1,
      "step": 720,
      "total_loss": 0.671604573726654,
      "weighted_orthogonal_loss": 0.013611911796033382
    },
    {
      "classification_loss": 0.6875645518302917,
      "epoch": 2.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13623575866222382,
      "orthogonal_weight": 0.1,
      "step": 721,
      "total_loss": 0.7011881470680237,
      "weighted_orthogonal_loss": 0.013623575679957867
    },
    {
      "classification_loss": 0.6243991851806641,
      "epoch": 2.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13636556267738342,
      "orthogonal_weight": 0.1,
      "step": 722,
      "total_loss": 0.6380357146263123,
      "weighted_orthogonal_loss": 0.013636556454002857
    },
    {
      "classification_loss": 0.6961196660995483,
      "epoch": 2.3704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1363585740327835,
      "orthogonal_weight": 0.1,
      "step": 723,
      "total_loss": 0.709755539894104,
      "weighted_orthogonal_loss": 0.013635857962071896
    },
    {
      "classification_loss": 0.6458069682121277,
      "epoch": 2.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13638970255851746,
      "orthogonal_weight": 0.1,
      "step": 724,
      "total_loss": 0.6594459414482117,
      "weighted_orthogonal_loss": 0.01363897044211626
    },
    {
      "classification_loss": 0.6296140551567078,
      "epoch": 2.3770491803278686,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13634061813354492,
      "orthogonal_weight": 0.1,
      "step": 725,
      "total_loss": 0.6432481408119202,
      "weighted_orthogonal_loss": 0.013634062372148037
    },
    {
      "classification_loss": 0.6389240026473999,
      "epoch": 2.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361386924982071,
      "orthogonal_weight": 0.1,
      "step": 726,
      "total_loss": 0.6525378823280334,
      "weighted_orthogonal_loss": 0.013613869436085224
    },
    {
      "classification_loss": 0.6619734764099121,
      "epoch": 2.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.135803684592247,
      "orthogonal_weight": 0.1,
      "step": 727,
      "total_loss": 0.6755538582801819,
      "weighted_orthogonal_loss": 0.01358036883175373
    },
    {
      "classification_loss": 0.6266179084777832,
      "epoch": 2.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1354946792125702,
      "orthogonal_weight": 0.1,
      "step": 728,
      "total_loss": 0.6401673555374146,
      "weighted_orthogonal_loss": 0.013549468480050564
    },
    {
      "classification_loss": 0.6980639696121216,
      "epoch": 2.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13515490293502808,
      "orthogonal_weight": 0.1,
      "step": 729,
      "total_loss": 0.711579442024231,
      "weighted_orthogonal_loss": 0.013515490107238293
    },
    {
      "classification_loss": 0.6848323941230774,
      "epoch": 2.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13477550446987152,
      "orthogonal_weight": 0.1,
      "step": 730,
      "total_loss": 0.6983099579811096,
      "weighted_orthogonal_loss": 0.013477550819516182
    },
    {
      "classification_loss": 0.6631547212600708,
      "epoch": 2.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13439403474330902,
      "orthogonal_weight": 0.1,
      "step": 731,
      "total_loss": 0.6765941381454468,
      "weighted_orthogonal_loss": 0.013439403846859932
    },
    {
      "classification_loss": 0.6785007119178772,
      "epoch": 2.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13400933146476746,
      "orthogonal_weight": 0.1,
      "step": 732,
      "total_loss": 0.6919016242027283,
      "weighted_orthogonal_loss": 0.01340093370527029
    },
    {
      "classification_loss": 0.6452811360359192,
      "epoch": 2.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13355927169322968,
      "orthogonal_weight": 0.1,
      "step": 733,
      "total_loss": 0.6586370468139648,
      "weighted_orthogonal_loss": 0.013355927541851997
    },
    {
      "classification_loss": 0.6604838371276855,
      "epoch": 2.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133195698261261,
      "orthogonal_weight": 0.1,
      "step": 734,
      "total_loss": 0.6738033890724182,
      "weighted_orthogonal_loss": 0.013319569639861584
    },
    {
      "classification_loss": 0.679711103439331,
      "epoch": 2.4098360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13293345272541046,
      "orthogonal_weight": 0.1,
      "step": 735,
      "total_loss": 0.6930044293403625,
      "weighted_orthogonal_loss": 0.013293345458805561
    },
    {
      "classification_loss": 0.7212545871734619,
      "epoch": 2.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1327354907989502,
      "orthogonal_weight": 0.1,
      "step": 736,
      "total_loss": 0.734528124332428,
      "weighted_orthogonal_loss": 0.013273549266159534
    },
    {
      "classification_loss": 0.6374360918998718,
      "epoch": 2.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13261374831199646,
      "orthogonal_weight": 0.1,
      "step": 737,
      "total_loss": 0.6506974697113037,
      "weighted_orthogonal_loss": 0.013261375017464161
    },
    {
      "classification_loss": 0.6812819838523865,
      "epoch": 2.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13248972594738007,
      "orthogonal_weight": 0.1,
      "step": 738,
      "total_loss": 0.6945309638977051,
      "weighted_orthogonal_loss": 0.013248972594738007
    },
    {
      "classification_loss": 0.6216815710067749,
      "epoch": 2.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238371908664703,
      "orthogonal_weight": 0.1,
      "step": 739,
      "total_loss": 0.6349199414253235,
      "weighted_orthogonal_loss": 0.013238372281193733
    },
    {
      "classification_loss": 0.6721980571746826,
      "epoch": 2.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13228614628314972,
      "orthogonal_weight": 0.1,
      "step": 740,
      "total_loss": 0.685426652431488,
      "weighted_orthogonal_loss": 0.013228614814579487
    },
    {
      "classification_loss": 0.668140709400177,
      "epoch": 2.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1322781890630722,
      "orthogonal_weight": 0.1,
      "step": 741,
      "total_loss": 0.6813685297966003,
      "weighted_orthogonal_loss": 0.013227819465100765
    },
    {
      "classification_loss": 0.6399967670440674,
      "epoch": 2.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13231763243675232,
      "orthogonal_weight": 0.1,
      "step": 742,
      "total_loss": 0.6532285213470459,
      "weighted_orthogonal_loss": 0.013231763616204262
    },
    {
      "classification_loss": 0.6787336468696594,
      "epoch": 2.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238121569156647,
      "orthogonal_weight": 0.1,
      "step": 743,
      "total_loss": 0.6919717788696289,
      "weighted_orthogonal_loss": 0.013238121755421162
    },
    {
      "classification_loss": 0.6694890260696411,
      "epoch": 2.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324678659439087,
      "orthogonal_weight": 0.1,
      "step": 744,
      "total_loss": 0.682735800743103,
      "weighted_orthogonal_loss": 0.013246786780655384
    },
    {
      "classification_loss": 0.6660614609718323,
      "epoch": 2.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324770301580429,
      "orthogonal_weight": 0.1,
      "step": 745,
      "total_loss": 0.6793091893196106,
      "weighted_orthogonal_loss": 0.013247703202068806
    },
    {
      "classification_loss": 0.6732366681098938,
      "epoch": 2.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13244667649269104,
      "orthogonal_weight": 0.1,
      "step": 746,
      "total_loss": 0.6864813566207886,
      "weighted_orthogonal_loss": 0.013244668021798134
    },
    {
      "classification_loss": 0.6724532842636108,
      "epoch": 2.4491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13244278728961945,
      "orthogonal_weight": 0.1,
      "step": 747,
      "total_loss": 0.6856975555419922,
      "weighted_orthogonal_loss": 0.013244278728961945
    },
    {
      "classification_loss": 0.6885054111480713,
      "epoch": 2.4524590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13242574036121368,
      "orthogonal_weight": 0.1,
      "step": 748,
      "total_loss": 0.7017480134963989,
      "weighted_orthogonal_loss": 0.013242574408650398
    },
    {
      "classification_loss": 0.7083278298377991,
      "epoch": 2.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238902390003204,
      "orthogonal_weight": 0.1,
      "step": 749,
      "total_loss": 0.7215667366981506,
      "weighted_orthogonal_loss": 0.01323890220373869
    },
    {
      "classification_loss": 0.6569589972496033,
      "epoch": 2.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13231495022773743,
      "orthogonal_weight": 0.1,
      "step": 750,
      "total_loss": 0.6701905131340027,
      "weighted_orthogonal_loss": 0.013231495395302773
    },
    {
      "classification_loss": 0.6630613207817078,
      "epoch": 2.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1322300136089325,
      "orthogonal_weight": 0.1,
      "step": 751,
      "total_loss": 0.6762843132019043,
      "weighted_orthogonal_loss": 0.01322300173342228
    },
    {
      "classification_loss": 0.6451510190963745,
      "epoch": 2.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13214437663555145,
      "orthogonal_weight": 0.1,
      "step": 752,
      "total_loss": 0.6583654284477234,
      "weighted_orthogonal_loss": 0.01321443822234869
    },
    {
      "classification_loss": 0.6673803925514221,
      "epoch": 2.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13193614780902863,
      "orthogonal_weight": 0.1,
      "step": 753,
      "total_loss": 0.6805739998817444,
      "weighted_orthogonal_loss": 0.013193614780902863
    },
    {
      "classification_loss": 0.6990227103233337,
      "epoch": 2.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316678375005722,
      "orthogonal_weight": 0.1,
      "step": 754,
      "total_loss": 0.7121894955635071,
      "weighted_orthogonal_loss": 0.013166784308850765
    },
    {
      "classification_loss": 0.6536931395530701,
      "epoch": 2.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13150203227996826,
      "orthogonal_weight": 0.1,
      "step": 755,
      "total_loss": 0.6668433547019958,
      "weighted_orthogonal_loss": 0.013150203041732311
    },
    {
      "classification_loss": 0.6988577842712402,
      "epoch": 2.4786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141269981861115,
      "orthogonal_weight": 0.1,
      "step": 756,
      "total_loss": 0.7119990587234497,
      "weighted_orthogonal_loss": 0.0131412697955966
    },
    {
      "classification_loss": 0.6434361934661865,
      "epoch": 2.4819672131147543,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313757449388504,
      "orthogonal_weight": 0.1,
      "step": 757,
      "total_loss": 0.6565737724304199,
      "weighted_orthogonal_loss": 0.013137574307620525
    },
    {
      "classification_loss": 0.6774338483810425,
      "epoch": 2.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313847005367279,
      "orthogonal_weight": 0.1,
      "step": 758,
      "total_loss": 0.6905723214149475,
      "weighted_orthogonal_loss": 0.013138470239937305
    },
    {
      "classification_loss": 0.6602340340614319,
      "epoch": 2.4885245901639346,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1314343959093094,
      "orthogonal_weight": 0.1,
      "step": 759,
      "total_loss": 0.6733774542808533,
      "weighted_orthogonal_loss": 0.013143439777195454
    },
    {
      "classification_loss": 0.6962705254554749,
      "epoch": 2.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141418993473053,
      "orthogonal_weight": 0.1,
      "step": 760,
      "total_loss": 0.7094119191169739,
      "weighted_orthogonal_loss": 0.013141418807208538
    },
    {
      "classification_loss": 0.636605978012085,
      "epoch": 2.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13138720393180847,
      "orthogonal_weight": 0.1,
      "step": 761,
      "total_loss": 0.6497446894645691,
      "weighted_orthogonal_loss": 0.013138720765709877
    },
    {
      "classification_loss": 0.6670777797698975,
      "epoch": 2.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313103586435318,
      "orthogonal_weight": 0.1,
      "step": 762,
      "total_loss": 0.6802088022232056,
      "weighted_orthogonal_loss": 0.013131036423146725
    },
    {
      "classification_loss": 0.6505709290504456,
      "epoch": 2.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13124172389507294,
      "orthogonal_weight": 0.1,
      "step": 763,
      "total_loss": 0.6636950969696045,
      "weighted_orthogonal_loss": 0.013124172575771809
    },
    {
      "classification_loss": 0.6777225136756897,
      "epoch": 2.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13122008740901947,
      "orthogonal_weight": 0.1,
      "step": 764,
      "total_loss": 0.6908445358276367,
      "weighted_orthogonal_loss": 0.013122009113430977
    },
    {
      "classification_loss": 0.6795657277107239,
      "epoch": 2.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13118313252925873,
      "orthogonal_weight": 0.1,
      "step": 765,
      "total_loss": 0.6926840543746948,
      "weighted_orthogonal_loss": 0.013118313625454903
    },
    {
      "classification_loss": 0.6445077657699585,
      "epoch": 2.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13103891909122467,
      "orthogonal_weight": 0.1,
      "step": 766,
      "total_loss": 0.6576116681098938,
      "weighted_orthogonal_loss": 0.013103892095386982
    },
    {
      "classification_loss": 0.6639549136161804,
      "epoch": 2.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1309681236743927,
      "orthogonal_weight": 0.1,
      "step": 767,
      "total_loss": 0.6770517230033875,
      "weighted_orthogonal_loss": 0.013096812181174755
    },
    {
      "classification_loss": 0.6825442910194397,
      "epoch": 2.5180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13093623518943787,
      "orthogonal_weight": 0.1,
      "step": 768,
      "total_loss": 0.6956379413604736,
      "weighted_orthogonal_loss": 0.013093623332679272
    },
    {
      "classification_loss": 0.6683477163314819,
      "epoch": 2.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13094571232795715,
      "orthogonal_weight": 0.1,
      "step": 769,
      "total_loss": 0.6814422607421875,
      "weighted_orthogonal_loss": 0.01309457141906023
    },
    {
      "classification_loss": 0.6675499081611633,
      "epoch": 2.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13099037110805511,
      "orthogonal_weight": 0.1,
      "step": 770,
      "total_loss": 0.680648922920227,
      "weighted_orthogonal_loss": 0.013099037110805511
    },
    {
      "classification_loss": 0.6366527080535889,
      "epoch": 2.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13100089132785797,
      "orthogonal_weight": 0.1,
      "step": 771,
      "total_loss": 0.6497527956962585,
      "weighted_orthogonal_loss": 0.013100089505314827
    },
    {
      "classification_loss": 0.6881991028785706,
      "epoch": 2.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104188442230225,
      "orthogonal_weight": 0.1,
      "step": 772,
      "total_loss": 0.7013033032417297,
      "weighted_orthogonal_loss": 0.01310418825596571
    },
    {
      "classification_loss": 0.6647322773933411,
      "epoch": 2.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1311519742012024,
      "orthogonal_weight": 0.1,
      "step": 773,
      "total_loss": 0.6778475046157837,
      "weighted_orthogonal_loss": 0.01311519742012024
    },
    {
      "classification_loss": 0.6433978080749512,
      "epoch": 2.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13130128383636475,
      "orthogonal_weight": 0.1,
      "step": 774,
      "total_loss": 0.6565279364585876,
      "weighted_orthogonal_loss": 0.013130128383636475
    },
    {
      "classification_loss": 0.6302614212036133,
      "epoch": 2.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1312216967344284,
      "orthogonal_weight": 0.1,
      "step": 775,
      "total_loss": 0.6433835625648499,
      "weighted_orthogonal_loss": 0.013122170232236385
    },
    {
      "classification_loss": 0.7025690078735352,
      "epoch": 2.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13119018077850342,
      "orthogonal_weight": 0.1,
      "step": 776,
      "total_loss": 0.7156880497932434,
      "weighted_orthogonal_loss": 0.013119018636643887
    },
    {
      "classification_loss": 0.7370193600654602,
      "epoch": 2.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13122737407684326,
      "orthogonal_weight": 0.1,
      "step": 777,
      "total_loss": 0.7501420974731445,
      "weighted_orthogonal_loss": 0.013122737407684326
    },
    {
      "classification_loss": 0.6912404894828796,
      "epoch": 2.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13128028810024261,
      "orthogonal_weight": 0.1,
      "step": 778,
      "total_loss": 0.704368531703949,
      "weighted_orthogonal_loss": 0.013128029182553291
    },
    {
      "classification_loss": 0.6493831276893616,
      "epoch": 2.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313227415084839,
      "orthogonal_weight": 0.1,
      "step": 779,
      "total_loss": 0.66251540184021,
      "weighted_orthogonal_loss": 0.013132274150848389
    },
    {
      "classification_loss": 0.7050805687904358,
      "epoch": 2.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141733407974243,
      "orthogonal_weight": 0.1,
      "step": 780,
      "total_loss": 0.7182223200798035,
      "weighted_orthogonal_loss": 0.013141733594238758
    },
    {
      "classification_loss": 0.6615415811538696,
      "epoch": 2.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1315409243106842,
      "orthogonal_weight": 0.1,
      "step": 781,
      "total_loss": 0.6746956706047058,
      "weighted_orthogonal_loss": 0.013154092244803905
    },
    {
      "classification_loss": 0.7201828956604004,
      "epoch": 2.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13167054951190948,
      "orthogonal_weight": 0.1,
      "step": 782,
      "total_loss": 0.7333499789237976,
      "weighted_orthogonal_loss": 0.013167055323719978
    },
    {
      "classification_loss": 0.6431984305381775,
      "epoch": 2.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.131600022315979,
      "orthogonal_weight": 0.1,
      "step": 783,
      "total_loss": 0.6563584208488464,
      "weighted_orthogonal_loss": 0.013160002417862415
    },
    {
      "classification_loss": 0.6847642660140991,
      "epoch": 2.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13152295351028442,
      "orthogonal_weight": 0.1,
      "step": 784,
      "total_loss": 0.697916567325592,
      "weighted_orthogonal_loss": 0.013152295723557472
    },
    {
      "classification_loss": 0.6438998579978943,
      "epoch": 2.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13152875006198883,
      "orthogonal_weight": 0.1,
      "step": 785,
      "total_loss": 0.657052755355835,
      "weighted_orthogonal_loss": 0.013152875006198883
    },
    {
      "classification_loss": 0.6583815217018127,
      "epoch": 2.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13146920502185822,
      "orthogonal_weight": 0.1,
      "step": 786,
      "total_loss": 0.6715284585952759,
      "weighted_orthogonal_loss": 0.013146921060979366
    },
    {
      "classification_loss": 0.6631061434745789,
      "epoch": 2.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13146454095840454,
      "orthogonal_weight": 0.1,
      "step": 787,
      "total_loss": 0.6762526035308838,
      "weighted_orthogonal_loss": 0.013146454468369484
    },
    {
      "classification_loss": 0.6878953576087952,
      "epoch": 2.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316032111644745,
      "orthogonal_weight": 0.1,
      "step": 788,
      "total_loss": 0.7010557055473328,
      "weighted_orthogonal_loss": 0.013160320930182934
    },
    {
      "classification_loss": 0.6670450568199158,
      "epoch": 2.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316634863615036,
      "orthogonal_weight": 0.1,
      "step": 789,
      "total_loss": 0.6802114248275757,
      "weighted_orthogonal_loss": 0.013166348449885845
    },
    {
      "classification_loss": 0.6824669241905212,
      "epoch": 2.5901639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1317044198513031,
      "orthogonal_weight": 0.1,
      "step": 790,
      "total_loss": 0.6956373453140259,
      "weighted_orthogonal_loss": 0.013170442543923855
    },
    {
      "classification_loss": 0.7044404149055481,
      "epoch": 2.5934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13174213469028473,
      "orthogonal_weight": 0.1,
      "step": 791,
      "total_loss": 0.7176146507263184,
      "weighted_orthogonal_loss": 0.013174213469028473
    },
    {
      "classification_loss": 0.6775110363960266,
      "epoch": 2.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13179944455623627,
      "orthogonal_weight": 0.1,
      "step": 792,
      "total_loss": 0.6906909942626953,
      "weighted_orthogonal_loss": 0.013179944828152657
    },
    {
      "classification_loss": 0.6186367869377136,
      "epoch": 2.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13196128606796265,
      "orthogonal_weight": 0.1,
      "step": 793,
      "total_loss": 0.6318328976631165,
      "weighted_orthogonal_loss": 0.01319612842053175
    },
    {
      "classification_loss": 0.6577016115188599,
      "epoch": 2.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13215209543704987,
      "orthogonal_weight": 0.1,
      "step": 794,
      "total_loss": 0.6709167957305908,
      "weighted_orthogonal_loss": 0.013215209357440472
    },
    {
      "classification_loss": 0.6138888001441956,
      "epoch": 2.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13239513337612152,
      "orthogonal_weight": 0.1,
      "step": 795,
      "total_loss": 0.6271283030509949,
      "weighted_orthogonal_loss": 0.013239513151347637
    },
    {
      "classification_loss": 0.6095708012580872,
      "epoch": 2.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13262568414211273,
      "orthogonal_weight": 0.1,
      "step": 796,
      "total_loss": 0.6228333711624146,
      "weighted_orthogonal_loss": 0.013262568973004818
    },
    {
      "classification_loss": 0.6437855362892151,
      "epoch": 2.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13301894068717957,
      "orthogonal_weight": 0.1,
      "step": 797,
      "total_loss": 0.6570874452590942,
      "weighted_orthogonal_loss": 0.013301894068717957
    },
    {
      "classification_loss": 0.7236654758453369,
      "epoch": 2.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13340318202972412,
      "orthogonal_weight": 0.1,
      "step": 798,
      "total_loss": 0.7370057702064514,
      "weighted_orthogonal_loss": 0.013340318575501442
    },
    {
      "classification_loss": 0.6494996547698975,
      "epoch": 2.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133793443441391,
      "orthogonal_weight": 0.1,
      "step": 799,
      "total_loss": 0.6628789901733398,
      "weighted_orthogonal_loss": 0.013379344716668129
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 4.363560676574707,
      "learning_rate": 0.00017669999999999999,
      "loss": 0.6802,
      "step": 800
    },
    {
      "classification_loss": 0.6421718597412109,
      "epoch": 2.6229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13409137725830078,
      "orthogonal_weight": 0.1,
      "step": 800,
      "total_loss": 0.655580997467041,
      "weighted_orthogonal_loss": 0.013409137725830078
    },
    {
      "classification_loss": 0.6574947834014893,
      "epoch": 2.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13442346453666687,
      "orthogonal_weight": 0.1,
      "step": 801,
      "total_loss": 0.6709371209144592,
      "weighted_orthogonal_loss": 0.013442346826195717
    },
    {
      "classification_loss": 0.6738280057907104,
      "epoch": 2.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13473056256771088,
      "orthogonal_weight": 0.1,
      "step": 802,
      "total_loss": 0.6873010396957397,
      "weighted_orthogonal_loss": 0.013473056256771088
    },
    {
      "classification_loss": 0.6693236231803894,
      "epoch": 2.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13510146737098694,
      "orthogonal_weight": 0.1,
      "step": 803,
      "total_loss": 0.6828337907791138,
      "weighted_orthogonal_loss": 0.013510147109627724
    },
    {
      "classification_loss": 0.6527130603790283,
      "epoch": 2.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357375532388687,
      "orthogonal_weight": 0.1,
      "step": 804,
      "total_loss": 0.666286826133728,
      "weighted_orthogonal_loss": 0.013573755510151386
    },
    {
      "classification_loss": 0.6655152440071106,
      "epoch": 2.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13662533462047577,
      "orthogonal_weight": 0.1,
      "step": 805,
      "total_loss": 0.6791777610778809,
      "weighted_orthogonal_loss": 0.013662533834576607
    },
    {
      "classification_loss": 0.6729041337966919,
      "epoch": 2.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13751019537448883,
      "orthogonal_weight": 0.1,
      "step": 806,
      "total_loss": 0.6866551637649536,
      "weighted_orthogonal_loss": 0.013751019723713398
    },
    {
      "classification_loss": 0.7125867605209351,
      "epoch": 2.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.138357475399971,
      "orthogonal_weight": 0.1,
      "step": 807,
      "total_loss": 0.7264224886894226,
      "weighted_orthogonal_loss": 0.013835747726261616
    },
    {
      "classification_loss": 0.6728909611701965,
      "epoch": 2.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1391458958387375,
      "orthogonal_weight": 0.1,
      "step": 808,
      "total_loss": 0.6868055462837219,
      "weighted_orthogonal_loss": 0.013914589770138264
    },
    {
      "classification_loss": 0.6148538589477539,
      "epoch": 2.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13994748890399933,
      "orthogonal_weight": 0.1,
      "step": 809,
      "total_loss": 0.6288486123085022,
      "weighted_orthogonal_loss": 0.013994748704135418
    },
    {
      "classification_loss": 0.6664302945137024,
      "epoch": 2.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14070634543895721,
      "orthogonal_weight": 0.1,
      "step": 810,
      "total_loss": 0.6805009245872498,
      "weighted_orthogonal_loss": 0.014070634730160236
    },
    {
      "classification_loss": 0.6931422352790833,
      "epoch": 2.6590163934426227,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14137808978557587,
      "orthogonal_weight": 0.1,
      "step": 811,
      "total_loss": 0.7072800397872925,
      "weighted_orthogonal_loss": 0.014137809164822102
    },
    {
      "classification_loss": 0.6658143997192383,
      "epoch": 2.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14204499125480652,
      "orthogonal_weight": 0.1,
      "step": 812,
      "total_loss": 0.6800189018249512,
      "weighted_orthogonal_loss": 0.014204499311745167
    },
    {
      "classification_loss": 0.6442660689353943,
      "epoch": 2.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14260706305503845,
      "orthogonal_weight": 0.1,
      "step": 813,
      "total_loss": 0.6585267782211304,
      "weighted_orthogonal_loss": 0.01426070649176836
    },
    {
      "classification_loss": 0.7148667573928833,
      "epoch": 2.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.143210306763649,
      "orthogonal_weight": 0.1,
      "step": 814,
      "total_loss": 0.7291877865791321,
      "weighted_orthogonal_loss": 0.014321031048893929
    },
    {
      "classification_loss": 0.6784195899963379,
      "epoch": 2.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1437629610300064,
      "orthogonal_weight": 0.1,
      "step": 815,
      "total_loss": 0.6927958726882935,
      "weighted_orthogonal_loss": 0.014376296661794186
    },
    {
      "classification_loss": 0.7024468183517456,
      "epoch": 2.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14403021335601807,
      "orthogonal_weight": 0.1,
      "step": 816,
      "total_loss": 0.7168498635292053,
      "weighted_orthogonal_loss": 0.014403021894395351
    },
    {
      "classification_loss": 0.6734247803688049,
      "epoch": 2.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1439918726682663,
      "orthogonal_weight": 0.1,
      "step": 817,
      "total_loss": 0.6878239512443542,
      "weighted_orthogonal_loss": 0.01439918763935566
    },
    {
      "classification_loss": 0.6890404224395752,
      "epoch": 2.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14367111027240753,
      "orthogonal_weight": 0.1,
      "step": 818,
      "total_loss": 0.7034075260162354,
      "weighted_orthogonal_loss": 0.014367111027240753
    },
    {
      "classification_loss": 0.718894898891449,
      "epoch": 2.685245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1434451788663864,
      "orthogonal_weight": 0.1,
      "step": 819,
      "total_loss": 0.7332394123077393,
      "weighted_orthogonal_loss": 0.014344518072903156
    },
    {
      "classification_loss": 0.6805331110954285,
      "epoch": 2.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14324213564395905,
      "orthogonal_weight": 0.1,
      "step": 820,
      "total_loss": 0.6948572993278503,
      "weighted_orthogonal_loss": 0.01432421337813139
    },
    {
      "classification_loss": 0.7090246677398682,
      "epoch": 2.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14313536882400513,
      "orthogonal_weight": 0.1,
      "step": 821,
      "total_loss": 0.7233381867408752,
      "weighted_orthogonal_loss": 0.014313536696135998
    },
    {
      "classification_loss": 0.6762948632240295,
      "epoch": 2.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1433316022157669,
      "orthogonal_weight": 0.1,
      "step": 822,
      "total_loss": 0.6906280517578125,
      "weighted_orthogonal_loss": 0.01433316059410572
    },
    {
      "classification_loss": 0.6647999286651611,
      "epoch": 2.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1435956060886383,
      "orthogonal_weight": 0.1,
      "step": 823,
      "total_loss": 0.6791594624519348,
      "weighted_orthogonal_loss": 0.014359560795128345
    },
    {
      "classification_loss": 0.6442452669143677,
      "epoch": 2.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14390866458415985,
      "orthogonal_weight": 0.1,
      "step": 824,
      "total_loss": 0.6586361527442932,
      "weighted_orthogonal_loss": 0.01439086627215147
    },
    {
      "classification_loss": 0.6751945614814758,
      "epoch": 2.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1442665308713913,
      "orthogonal_weight": 0.1,
      "step": 825,
      "total_loss": 0.6896212100982666,
      "weighted_orthogonal_loss": 0.014426653273403645
    },
    {
      "classification_loss": 0.6509072780609131,
      "epoch": 2.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14489373564720154,
      "orthogonal_weight": 0.1,
      "step": 826,
      "total_loss": 0.6653966307640076,
      "weighted_orthogonal_loss": 0.014489374123513699
    },
    {
      "classification_loss": 0.6488322615623474,
      "epoch": 2.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14557114243507385,
      "orthogonal_weight": 0.1,
      "step": 827,
      "total_loss": 0.6633893847465515,
      "weighted_orthogonal_loss": 0.01455711480230093
    },
    {
      "classification_loss": 0.6886337399482727,
      "epoch": 2.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1461714804172516,
      "orthogonal_weight": 0.1,
      "step": 828,
      "total_loss": 0.7032508850097656,
      "weighted_orthogonal_loss": 0.014617147855460644
    },
    {
      "classification_loss": 0.6759387850761414,
      "epoch": 2.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14670132100582123,
      "orthogonal_weight": 0.1,
      "step": 829,
      "total_loss": 0.6906089186668396,
      "weighted_orthogonal_loss": 0.014670132659375668
    },
    {
      "classification_loss": 0.6716825366020203,
      "epoch": 2.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14707762002944946,
      "orthogonal_weight": 0.1,
      "step": 830,
      "total_loss": 0.6863902807235718,
      "weighted_orthogonal_loss": 0.014707761816680431
    },
    {
      "classification_loss": 0.724100649356842,
      "epoch": 2.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14745457470417023,
      "orthogonal_weight": 0.1,
      "step": 831,
      "total_loss": 0.7388461232185364,
      "weighted_orthogonal_loss": 0.014745458029210567
    },
    {
      "classification_loss": 0.6719219088554382,
      "epoch": 2.7278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1474969983100891,
      "orthogonal_weight": 0.1,
      "step": 832,
      "total_loss": 0.6866716146469116,
      "weighted_orthogonal_loss": 0.014749700203537941
    },
    {
      "classification_loss": 0.6846828460693359,
      "epoch": 2.7311475409836063,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14755405485630035,
      "orthogonal_weight": 0.1,
      "step": 833,
      "total_loss": 0.6994382739067078,
      "weighted_orthogonal_loss": 0.014755405485630035
    },
    {
      "classification_loss": 0.6508368253707886,
      "epoch": 2.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14754410088062286,
      "orthogonal_weight": 0.1,
      "step": 834,
      "total_loss": 0.6655912399291992,
      "weighted_orthogonal_loss": 0.014754409901797771
    },
    {
      "classification_loss": 0.7076286673545837,
      "epoch": 2.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14744248986244202,
      "orthogonal_weight": 0.1,
      "step": 835,
      "total_loss": 0.7223728895187378,
      "weighted_orthogonal_loss": 0.014744249172508717
    },
    {
      "classification_loss": 0.6794479489326477,
      "epoch": 2.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14740104973316193,
      "orthogonal_weight": 0.1,
      "step": 836,
      "total_loss": 0.6941880583763123,
      "weighted_orthogonal_loss": 0.014740104787051678
    },
    {
      "classification_loss": 0.6911559104919434,
      "epoch": 2.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14667461812496185,
      "orthogonal_weight": 0.1,
      "step": 837,
      "total_loss": 0.7058233618736267,
      "weighted_orthogonal_loss": 0.01466746162623167
    },
    {
      "classification_loss": 0.7181549668312073,
      "epoch": 2.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14595386385917664,
      "orthogonal_weight": 0.1,
      "step": 838,
      "total_loss": 0.7327503561973572,
      "weighted_orthogonal_loss": 0.014595386572182178
    },
    {
      "classification_loss": 0.6950059533119202,
      "epoch": 2.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14529913663864136,
      "orthogonal_weight": 0.1,
      "step": 839,
      "total_loss": 0.7095358371734619,
      "weighted_orthogonal_loss": 0.014529913663864136
    },
    {
      "classification_loss": 0.7272698283195496,
      "epoch": 2.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1447432041168213,
      "orthogonal_weight": 0.1,
      "step": 840,
      "total_loss": 0.7417441606521606,
      "weighted_orthogonal_loss": 0.014474320225417614
    },
    {
      "classification_loss": 0.6665177941322327,
      "epoch": 2.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1442888081073761,
      "orthogonal_weight": 0.1,
      "step": 841,
      "total_loss": 0.6809466481208801,
      "weighted_orthogonal_loss": 0.014428880997002125
    },
    {
      "classification_loss": 0.6993705034255981,
      "epoch": 2.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14394256472587585,
      "orthogonal_weight": 0.1,
      "step": 842,
      "total_loss": 0.7137647867202759,
      "weighted_orthogonal_loss": 0.01439425628632307
    },
    {
      "classification_loss": 0.6448401808738708,
      "epoch": 2.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14349260926246643,
      "orthogonal_weight": 0.1,
      "step": 843,
      "total_loss": 0.6591894626617432,
      "weighted_orthogonal_loss": 0.014349261298775673
    },
    {
      "classification_loss": 0.695979654788971,
      "epoch": 2.7672131147540986,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1428927481174469,
      "orthogonal_weight": 0.1,
      "step": 844,
      "total_loss": 0.7102689146995544,
      "weighted_orthogonal_loss": 0.01428927481174469
    },
    {
      "classification_loss": 0.6317330002784729,
      "epoch": 2.7704918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1423775553703308,
      "orthogonal_weight": 0.1,
      "step": 845,
      "total_loss": 0.6459707617759705,
      "weighted_orthogonal_loss": 0.014237755909562111
    },
    {
      "classification_loss": 0.633726954460144,
      "epoch": 2.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14187423884868622,
      "orthogonal_weight": 0.1,
      "step": 846,
      "total_loss": 0.6479143500328064,
      "weighted_orthogonal_loss": 0.014187424443662167
    },
    {
      "classification_loss": 0.6318193078041077,
      "epoch": 2.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14150337874889374,
      "orthogonal_weight": 0.1,
      "step": 847,
      "total_loss": 0.6459696292877197,
      "weighted_orthogonal_loss": 0.014150338247418404
    },
    {
      "classification_loss": 0.6419751048088074,
      "epoch": 2.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14126154780387878,
      "orthogonal_weight": 0.1,
      "step": 848,
      "total_loss": 0.6561012864112854,
      "weighted_orthogonal_loss": 0.014126154594123363
    },
    {
      "classification_loss": 0.6850680708885193,
      "epoch": 2.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14099426567554474,
      "orthogonal_weight": 0.1,
      "step": 849,
      "total_loss": 0.6991674900054932,
      "weighted_orthogonal_loss": 0.014099426567554474
    },
    {
      "classification_loss": 0.6210669875144958,
      "epoch": 2.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14061245322227478,
      "orthogonal_weight": 0.1,
      "step": 850,
      "total_loss": 0.6351282596588135,
      "weighted_orthogonal_loss": 0.014061245135962963
    },
    {
      "classification_loss": 0.643293559551239,
      "epoch": 2.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14035919308662415,
      "orthogonal_weight": 0.1,
      "step": 851,
      "total_loss": 0.6573294997215271,
      "weighted_orthogonal_loss": 0.014035919681191444
    },
    {
      "classification_loss": 0.7176450490951538,
      "epoch": 2.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14016325771808624,
      "orthogonal_weight": 0.1,
      "step": 852,
      "total_loss": 0.7316613793373108,
      "weighted_orthogonal_loss": 0.01401632558554411
    },
    {
      "classification_loss": 0.7004678249359131,
      "epoch": 2.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1399868279695511,
      "orthogonal_weight": 0.1,
      "step": 853,
      "total_loss": 0.7144665122032166,
      "weighted_orthogonal_loss": 0.013998682610690594
    },
    {
      "classification_loss": 0.7024727463722229,
      "epoch": 2.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1396532505750656,
      "orthogonal_weight": 0.1,
      "step": 854,
      "total_loss": 0.7164380550384521,
      "weighted_orthogonal_loss": 0.013965325430035591
    },
    {
      "classification_loss": 0.6604121923446655,
      "epoch": 2.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1391611397266388,
      "orthogonal_weight": 0.1,
      "step": 855,
      "total_loss": 0.6743283271789551,
      "weighted_orthogonal_loss": 0.01391611434519291
    },
    {
      "classification_loss": 0.6929702162742615,
      "epoch": 2.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13879862427711487,
      "orthogonal_weight": 0.1,
      "step": 856,
      "total_loss": 0.7068500518798828,
      "weighted_orthogonal_loss": 0.013879862613976002
    },
    {
      "classification_loss": 0.6521424651145935,
      "epoch": 2.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13852253556251526,
      "orthogonal_weight": 0.1,
      "step": 857,
      "total_loss": 0.6659947037696838,
      "weighted_orthogonal_loss": 0.013852253556251526
    },
    {
      "classification_loss": 0.6440297961235046,
      "epoch": 2.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13816168904304504,
      "orthogonal_weight": 0.1,
      "step": 858,
      "total_loss": 0.6578459739685059,
      "weighted_orthogonal_loss": 0.01381616946309805
    },
    {
      "classification_loss": 0.6651825308799744,
      "epoch": 2.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13793590664863586,
      "orthogonal_weight": 0.1,
      "step": 859,
      "total_loss": 0.6789761185646057,
      "weighted_orthogonal_loss": 0.013793590478599072
    },
    {
      "classification_loss": 0.6417007446289062,
      "epoch": 2.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13772781193256378,
      "orthogonal_weight": 0.1,
      "step": 860,
      "total_loss": 0.655473530292511,
      "weighted_orthogonal_loss": 0.013772781006991863
    },
    {
      "classification_loss": 0.6173883080482483,
      "epoch": 2.822950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376417875289917,
      "orthogonal_weight": 0.1,
      "step": 861,
      "total_loss": 0.6311525106430054,
      "weighted_orthogonal_loss": 0.013764179311692715
    },
    {
      "classification_loss": 0.630244255065918,
      "epoch": 2.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1375746876001358,
      "orthogonal_weight": 0.1,
      "step": 862,
      "total_loss": 0.6440017223358154,
      "weighted_orthogonal_loss": 0.01375746913254261
    },
    {
      "classification_loss": 0.6748905777931213,
      "epoch": 2.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13751280307769775,
      "orthogonal_weight": 0.1,
      "step": 863,
      "total_loss": 0.6886418461799622,
      "weighted_orthogonal_loss": 0.01375128049403429
    },
    {
      "classification_loss": 0.6917154788970947,
      "epoch": 2.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13746412098407745,
      "orthogonal_weight": 0.1,
      "step": 864,
      "total_loss": 0.7054619193077087,
      "weighted_orthogonal_loss": 0.013746412470936775
    },
    {
      "classification_loss": 0.6363663077354431,
      "epoch": 2.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13741987943649292,
      "orthogonal_weight": 0.1,
      "step": 865,
      "total_loss": 0.650108277797699,
      "weighted_orthogonal_loss": 0.013741987757384777
    },
    {
      "classification_loss": 0.6910769939422607,
      "epoch": 2.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374032348394394,
      "orthogonal_weight": 0.1,
      "step": 866,
      "total_loss": 0.7048172950744629,
      "weighted_orthogonal_loss": 0.01374032348394394
    },
    {
      "classification_loss": 0.6239641904830933,
      "epoch": 2.8426229508196723,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13742709159851074,
      "orthogonal_weight": 0.1,
      "step": 867,
      "total_loss": 0.6377068758010864,
      "weighted_orthogonal_loss": 0.013742709532380104
    },
    {
      "classification_loss": 0.6582226157188416,
      "epoch": 2.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374601274728775,
      "orthogonal_weight": 0.1,
      "step": 868,
      "total_loss": 0.6719686388969421,
      "weighted_orthogonal_loss": 0.013746012933552265
    },
    {
      "classification_loss": 0.6380306482315063,
      "epoch": 2.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749299943447113,
      "orthogonal_weight": 0.1,
      "step": 869,
      "total_loss": 0.6517799496650696,
      "weighted_orthogonal_loss": 0.013749300502240658
    },
    {
      "classification_loss": 0.6963013410568237,
      "epoch": 2.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13756461441516876,
      "orthogonal_weight": 0.1,
      "step": 870,
      "total_loss": 0.71005779504776,
      "weighted_orthogonal_loss": 0.013756461441516876
    },
    {
      "classification_loss": 0.6242062449455261,
      "epoch": 2.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13762743771076202,
      "orthogonal_weight": 0.1,
      "step": 871,
      "total_loss": 0.6379690170288086,
      "weighted_orthogonal_loss": 0.013762744143605232
    },
    {
      "classification_loss": 0.6582491397857666,
      "epoch": 2.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13775230944156647,
      "orthogonal_weight": 0.1,
      "step": 872,
      "total_loss": 0.6720243692398071,
      "weighted_orthogonal_loss": 0.013775231316685677
    },
    {
      "classification_loss": 0.6976112127304077,
      "epoch": 2.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13785068690776825,
      "orthogonal_weight": 0.1,
      "step": 873,
      "total_loss": 0.7113962769508362,
      "weighted_orthogonal_loss": 0.01378506887704134
    },
    {
      "classification_loss": 0.6618359684944153,
      "epoch": 2.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13781948387622833,
      "orthogonal_weight": 0.1,
      "step": 874,
      "total_loss": 0.6756179332733154,
      "weighted_orthogonal_loss": 0.013781948946416378
    },
    {
      "classification_loss": 0.6764757037162781,
      "epoch": 2.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378135234117508,
      "orthogonal_weight": 0.1,
      "step": 875,
      "total_loss": 0.6902570724487305,
      "weighted_orthogonal_loss": 0.013781352899968624
    },
    {
      "classification_loss": 0.6648213863372803,
      "epoch": 2.8721311475409834,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378236562013626,
      "orthogonal_weight": 0.1,
      "step": 876,
      "total_loss": 0.6786037683486938,
      "weighted_orthogonal_loss": 0.013782366178929806
    },
    {
      "classification_loss": 0.7148444056510925,
      "epoch": 2.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13783076405525208,
      "orthogonal_weight": 0.1,
      "step": 877,
      "total_loss": 0.7286275029182434,
      "weighted_orthogonal_loss": 0.013783076778054237
    },
    {
      "classification_loss": 0.6933211088180542,
      "epoch": 2.8786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13781718909740448,
      "orthogonal_weight": 0.1,
      "step": 878,
      "total_loss": 0.7071028351783752,
      "weighted_orthogonal_loss": 0.013781718909740448
    },
    {
      "classification_loss": 0.7281890511512756,
      "epoch": 2.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13765178620815277,
      "orthogonal_weight": 0.1,
      "step": 879,
      "total_loss": 0.7419542074203491,
      "weighted_orthogonal_loss": 0.013765178620815277
    },
    {
      "classification_loss": 0.6592651009559631,
      "epoch": 2.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13758832216262817,
      "orthogonal_weight": 0.1,
      "step": 880,
      "total_loss": 0.6730239391326904,
      "weighted_orthogonal_loss": 0.013758832588791847
    },
    {
      "classification_loss": 0.6850625276565552,
      "epoch": 2.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13745801150798798,
      "orthogonal_weight": 0.1,
      "step": 881,
      "total_loss": 0.6988083124160767,
      "weighted_orthogonal_loss": 0.013745801523327827
    },
    {
      "classification_loss": 0.6546766757965088,
      "epoch": 2.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1373404860496521,
      "orthogonal_weight": 0.1,
      "step": 882,
      "total_loss": 0.6684107184410095,
      "weighted_orthogonal_loss": 0.013734049163758755
    },
    {
      "classification_loss": 0.6865067481994629,
      "epoch": 2.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13731399178504944,
      "orthogonal_weight": 0.1,
      "step": 883,
      "total_loss": 0.7002381682395935,
      "weighted_orthogonal_loss": 0.013731399551033974
    },
    {
      "classification_loss": 0.6239107847213745,
      "epoch": 2.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13732662796974182,
      "orthogonal_weight": 0.1,
      "step": 884,
      "total_loss": 0.6376434564590454,
      "weighted_orthogonal_loss": 0.013732663355767727
    },
    {
      "classification_loss": 0.6838407516479492,
      "epoch": 2.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1372617483139038,
      "orthogonal_weight": 0.1,
      "step": 885,
      "total_loss": 0.6975669264793396,
      "weighted_orthogonal_loss": 0.01372617483139038
    },
    {
      "classification_loss": 0.6961337924003601,
      "epoch": 2.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13723142445087433,
      "orthogonal_weight": 0.1,
      "step": 886,
      "total_loss": 0.7098569273948669,
      "weighted_orthogonal_loss": 0.013723142445087433
    },
    {
      "classification_loss": 0.6347160339355469,
      "epoch": 2.9081967213114757,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371781975030899,
      "orthogonal_weight": 0.1,
      "step": 887,
      "total_loss": 0.6484338641166687,
      "weighted_orthogonal_loss": 0.013717819936573505
    },
    {
      "classification_loss": 0.6735032796859741,
      "epoch": 2.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13716979324817657,
      "orthogonal_weight": 0.1,
      "step": 888,
      "total_loss": 0.6872202754020691,
      "weighted_orthogonal_loss": 0.013716979883611202
    },
    {
      "classification_loss": 0.6368300318717957,
      "epoch": 2.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13707570731639862,
      "orthogonal_weight": 0.1,
      "step": 889,
      "total_loss": 0.6505376100540161,
      "weighted_orthogonal_loss": 0.013707570731639862
    },
    {
      "classification_loss": 0.7129632234573364,
      "epoch": 2.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13656336069107056,
      "orthogonal_weight": 0.1,
      "step": 890,
      "total_loss": 0.72661954164505,
      "weighted_orthogonal_loss": 0.01365633588284254
    },
    {
      "classification_loss": 0.6496367454528809,
      "epoch": 2.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361621618270874,
      "orthogonal_weight": 0.1,
      "step": 891,
      "total_loss": 0.6632529497146606,
      "weighted_orthogonal_loss": 0.013616216368973255
    },
    {
      "classification_loss": 0.6428443789482117,
      "epoch": 2.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580596446990967,
      "orthogonal_weight": 0.1,
      "step": 892,
      "total_loss": 0.6564249992370605,
      "weighted_orthogonal_loss": 0.013580597005784512
    },
    {
      "classification_loss": 0.7061206102371216,
      "epoch": 2.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355288028717041,
      "orthogonal_weight": 0.1,
      "step": 893,
      "total_loss": 0.7196735143661499,
      "weighted_orthogonal_loss": 0.013552880845963955
    },
    {
      "classification_loss": 0.6892392039299011,
      "epoch": 2.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1353028565645218,
      "orthogonal_weight": 0.1,
      "step": 894,
      "total_loss": 0.7027695178985596,
      "weighted_orthogonal_loss": 0.013530286028981209
    },
    {
      "classification_loss": 0.7436215281486511,
      "epoch": 2.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1351049691438675,
      "orthogonal_weight": 0.1,
      "step": 895,
      "total_loss": 0.7571320533752441,
      "weighted_orthogonal_loss": 0.013510497286915779
    },
    {
      "classification_loss": 0.7402898669242859,
      "epoch": 2.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13492311537265778,
      "orthogonal_weight": 0.1,
      "step": 896,
      "total_loss": 0.7537821531295776,
      "weighted_orthogonal_loss": 0.013492311351001263
    },
    {
      "classification_loss": 0.6345436573028564,
      "epoch": 2.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13472579419612885,
      "orthogonal_weight": 0.1,
      "step": 897,
      "total_loss": 0.6480162143707275,
      "weighted_orthogonal_loss": 0.013472579419612885
    },
    {
      "classification_loss": 0.6982722282409668,
      "epoch": 2.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1345595270395279,
      "orthogonal_weight": 0.1,
      "step": 898,
      "total_loss": 0.7117281556129456,
      "weighted_orthogonal_loss": 0.013455952517688274
    },
    {
      "classification_loss": 0.6563827395439148,
      "epoch": 2.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1343676745891571,
      "orthogonal_weight": 0.1,
      "step": 899,
      "total_loss": 0.6698195338249207,
      "weighted_orthogonal_loss": 0.013436767272651196
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 7.655550479888916,
      "learning_rate": 0.0001733666666666667,
      "loss": 0.6868,
      "step": 900
    },
    {
      "classification_loss": 0.6516596078872681,
      "epoch": 2.9508196721311473,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13415351510047913,
      "orthogonal_weight": 0.1,
      "step": 900,
      "total_loss": 0.6650749444961548,
      "weighted_orthogonal_loss": 0.013415351510047913
    },
    {
      "classification_loss": 0.6185593605041504,
      "epoch": 2.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340084820985794,
      "orthogonal_weight": 0.1,
      "step": 901,
      "total_loss": 0.6319602131843567,
      "weighted_orthogonal_loss": 0.013400848023593426
    },
    {
      "classification_loss": 0.6346449851989746,
      "epoch": 2.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13388366997241974,
      "orthogonal_weight": 0.1,
      "step": 902,
      "total_loss": 0.6480333805084229,
      "weighted_orthogonal_loss": 0.013388367369771004
    },
    {
      "classification_loss": 0.6796820163726807,
      "epoch": 2.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13375800848007202,
      "orthogonal_weight": 0.1,
      "step": 903,
      "total_loss": 0.6930578351020813,
      "weighted_orthogonal_loss": 0.013375801034271717
    },
    {
      "classification_loss": 0.6618908643722534,
      "epoch": 2.963934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336188018321991,
      "orthogonal_weight": 0.1,
      "step": 904,
      "total_loss": 0.6752527356147766,
      "weighted_orthogonal_loss": 0.01336188055574894
    },
    {
      "classification_loss": 0.6549010276794434,
      "epoch": 2.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13353955745697021,
      "orthogonal_weight": 0.1,
      "step": 905,
      "total_loss": 0.6682549715042114,
      "weighted_orthogonal_loss": 0.013353955931961536
    },
    {
      "classification_loss": 0.7038845419883728,
      "epoch": 2.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13346640765666962,
      "orthogonal_weight": 0.1,
      "step": 906,
      "total_loss": 0.7172311544418335,
      "weighted_orthogonal_loss": 0.013346641324460506
    },
    {
      "classification_loss": 0.6596993803977966,
      "epoch": 2.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13336536288261414,
      "orthogonal_weight": 0.1,
      "step": 907,
      "total_loss": 0.6730359196662903,
      "weighted_orthogonal_loss": 0.013336536474525928
    },
    {
      "classification_loss": 0.6643521189689636,
      "epoch": 2.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13324430584907532,
      "orthogonal_weight": 0.1,
      "step": 908,
      "total_loss": 0.6776765584945679,
      "weighted_orthogonal_loss": 0.013324431143701077
    },
    {
      "classification_loss": 0.700383186340332,
      "epoch": 2.9803278688524593,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1332109421491623,
      "orthogonal_weight": 0.1,
      "step": 909,
      "total_loss": 0.7137042880058289,
      "weighted_orthogonal_loss": 0.01332109421491623
    },
    {
      "classification_loss": 0.6373188495635986,
      "epoch": 2.9836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13295488059520721,
      "orthogonal_weight": 0.1,
      "step": 910,
      "total_loss": 0.650614321231842,
      "weighted_orthogonal_loss": 0.013295488432049751
    },
    {
      "classification_loss": 0.6768724918365479,
      "epoch": 2.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13276943564414978,
      "orthogonal_weight": 0.1,
      "step": 911,
      "total_loss": 0.6901494264602661,
      "weighted_orthogonal_loss": 0.013276943936944008
    },
    {
      "classification_loss": 0.6718534231185913,
      "epoch": 2.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13258062303066254,
      "orthogonal_weight": 0.1,
      "step": 912,
      "total_loss": 0.6851114630699158,
      "weighted_orthogonal_loss": 0.013258062303066254
    },
    {
      "classification_loss": 0.6233301758766174,
      "epoch": 2.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13243211805820465,
      "orthogonal_weight": 0.1,
      "step": 913,
      "total_loss": 0.6365733742713928,
      "weighted_orthogonal_loss": 0.01324321236461401
    },
    {
      "classification_loss": 0.7316129207611084,
      "epoch": 2.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1323181539773941,
      "orthogonal_weight": 0.1,
      "step": 914,
      "total_loss": 0.7448447346687317,
      "weighted_orthogonal_loss": 0.01323181577026844
    },
    {
      "classification_loss": 0.6850863099098206,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6983069777488708,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6994917988777161,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.7127124667167664,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6793655753135681,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6925862431526184,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6831203699111938,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6963410377502441,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6856631636619568,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6988838315010071,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6830475330352783,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6962682008743286,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6757809519767761,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6890016198158264,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.7015624642372131,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.7147831320762634,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.548,
      "eval_f1": 0.6331168831168831,
      "eval_loss": 0.6995022296905518,
      "eval_precision": 0.6403940886699507,
      "eval_recall": 0.6260032102728732,
      "eval_runtime": 6.1599,
      "eval_samples_per_second": 162.34,
      "eval_steps_per_second": 1.299,
      "step": 915
    },
    {
      "classification_loss": 0.6477096080780029,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6609302759170532,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6321674585342407,
      "epoch": 3.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13214422762393951,
      "orthogonal_weight": 0.1,
      "step": 916,
      "total_loss": 0.6453818678855896,
      "weighted_orthogonal_loss": 0.013214423321187496
    },
    {
      "classification_loss": 0.7097901105880737,
      "epoch": 3.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13201601803302765,
      "orthogonal_weight": 0.1,
      "step": 917,
      "total_loss": 0.7229917049407959,
      "weighted_orthogonal_loss": 0.013201601803302765
    },
    {
      "classification_loss": 0.6862433552742004,
      "epoch": 3.0098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13187651336193085,
      "orthogonal_weight": 0.1,
      "step": 918,
      "total_loss": 0.6994310021400452,
      "weighted_orthogonal_loss": 0.0131876515224576
    },
    {
      "classification_loss": 0.6850602030754089,
      "epoch": 3.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13173681497573853,
      "orthogonal_weight": 0.1,
      "step": 919,
      "total_loss": 0.6982339024543762,
      "weighted_orthogonal_loss": 0.013173681683838367
    },
    {
      "classification_loss": 0.5959040522575378,
      "epoch": 3.0163934426229506,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13137459754943848,
      "orthogonal_weight": 0.1,
      "step": 920,
      "total_loss": 0.6090415120124817,
      "weighted_orthogonal_loss": 0.013137459754943848
    },
    {
      "classification_loss": 0.6883159875869751,
      "epoch": 3.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104073703289032,
      "orthogonal_weight": 0.1,
      "step": 921,
      "total_loss": 0.7014200687408447,
      "weighted_orthogonal_loss": 0.013104073703289032
    },
    {
      "classification_loss": 0.6134752631187439,
      "epoch": 3.0229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13078591227531433,
      "orthogonal_weight": 0.1,
      "step": 922,
      "total_loss": 0.6265538334846497,
      "weighted_orthogonal_loss": 0.013078591786324978
    },
    {
      "classification_loss": 0.6603575348854065,
      "epoch": 3.0262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13069376349449158,
      "orthogonal_weight": 0.1,
      "step": 923,
      "total_loss": 0.6734269261360168,
      "weighted_orthogonal_loss": 0.013069376349449158
    },
    {
      "classification_loss": 0.6847029328346252,
      "epoch": 3.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13064999878406525,
      "orthogonal_weight": 0.1,
      "step": 924,
      "total_loss": 0.6977679133415222,
      "weighted_orthogonal_loss": 0.01306500006467104
    },
    {
      "classification_loss": 0.671438455581665,
      "epoch": 3.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1305849552154541,
      "orthogonal_weight": 0.1,
      "step": 925,
      "total_loss": 0.6844969391822815,
      "weighted_orthogonal_loss": 0.013058495707809925
    },
    {
      "classification_loss": 0.6508132219314575,
      "epoch": 3.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13057905435562134,
      "orthogonal_weight": 0.1,
      "step": 926,
      "total_loss": 0.6638711094856262,
      "weighted_orthogonal_loss": 0.013057905249297619
    },
    {
      "classification_loss": 0.6654298305511475,
      "epoch": 3.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13054393231868744,
      "orthogonal_weight": 0.1,
      "step": 927,
      "total_loss": 0.6784842014312744,
      "weighted_orthogonal_loss": 0.013054393231868744
    },
    {
      "classification_loss": 0.6545535922050476,
      "epoch": 3.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1308320313692093,
      "orthogonal_weight": 0.1,
      "step": 928,
      "total_loss": 0.6676368117332458,
      "weighted_orthogonal_loss": 0.013083203695714474
    },
    {
      "classification_loss": 0.6401187777519226,
      "epoch": 3.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104471564292908,
      "orthogonal_weight": 0.1,
      "step": 929,
      "total_loss": 0.6532232761383057,
      "weighted_orthogonal_loss": 0.013104471378028393
    },
    {
      "classification_loss": 0.6693537831306458,
      "epoch": 3.0491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13136835396289825,
      "orthogonal_weight": 0.1,
      "step": 930,
      "total_loss": 0.6824906468391418,
      "weighted_orthogonal_loss": 0.013136835768818855
    },
    {
      "classification_loss": 0.6873430013656616,
      "epoch": 3.0524590163934424,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13178230822086334,
      "orthogonal_weight": 0.1,
      "step": 931,
      "total_loss": 0.7005212306976318,
      "weighted_orthogonal_loss": 0.013178231194615364
    },
    {
      "classification_loss": 0.7204275131225586,
      "epoch": 3.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13219889998435974,
      "orthogonal_weight": 0.1,
      "step": 932,
      "total_loss": 0.7336474061012268,
      "weighted_orthogonal_loss": 0.013219890184700489
    },
    {
      "classification_loss": 0.6325345039367676,
      "epoch": 3.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324281245470047,
      "orthogonal_weight": 0.1,
      "step": 933,
      "total_loss": 0.6457773447036743,
      "weighted_orthogonal_loss": 0.0132428128272295
    },
    {
      "classification_loss": 0.642624020576477,
      "epoch": 3.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13278310000896454,
      "orthogonal_weight": 0.1,
      "step": 934,
      "total_loss": 0.6559023261070251,
      "weighted_orthogonal_loss": 0.013278310187160969
    },
    {
      "classification_loss": 0.6765152812004089,
      "epoch": 3.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13313496112823486,
      "orthogonal_weight": 0.1,
      "step": 935,
      "total_loss": 0.6898287534713745,
      "weighted_orthogonal_loss": 0.013313496485352516
    },
    {
      "classification_loss": 0.6715161800384521,
      "epoch": 3.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13336436450481415,
      "orthogonal_weight": 0.1,
      "step": 936,
      "total_loss": 0.6848526000976562,
      "weighted_orthogonal_loss": 0.013336436823010445
    },
    {
      "classification_loss": 0.6505905985832214,
      "epoch": 3.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13354118168354034,
      "orthogonal_weight": 0.1,
      "step": 937,
      "total_loss": 0.6639447212219238,
      "weighted_orthogonal_loss": 0.01335411798208952
    },
    {
      "classification_loss": 0.6393555998802185,
      "epoch": 3.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13369476795196533,
      "orthogonal_weight": 0.1,
      "step": 938,
      "total_loss": 0.652725100517273,
      "weighted_orthogonal_loss": 0.013369477353990078
    },
    {
      "classification_loss": 0.6459389328956604,
      "epoch": 3.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13388065993785858,
      "orthogonal_weight": 0.1,
      "step": 939,
      "total_loss": 0.65932697057724,
      "weighted_orthogonal_loss": 0.013388066552579403
    },
    {
      "classification_loss": 0.6082014441490173,
      "epoch": 3.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340549886226654,
      "orthogonal_weight": 0.1,
      "step": 940,
      "total_loss": 0.6216069459915161,
      "weighted_orthogonal_loss": 0.013405499048531055
    },
    {
      "classification_loss": 0.651372492313385,
      "epoch": 3.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13417202234268188,
      "orthogonal_weight": 0.1,
      "step": 941,
      "total_loss": 0.6647896766662598,
      "weighted_orthogonal_loss": 0.013417202048003674
    },
    {
      "classification_loss": 0.6560359597206116,
      "epoch": 3.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13418664038181305,
      "orthogonal_weight": 0.1,
      "step": 942,
      "total_loss": 0.6694546341896057,
      "weighted_orthogonal_loss": 0.01341866422444582
    },
    {
      "classification_loss": 0.654608428478241,
      "epoch": 3.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13433967530727386,
      "orthogonal_weight": 0.1,
      "step": 943,
      "total_loss": 0.6680424213409424,
      "weighted_orthogonal_loss": 0.013433967716991901
    },
    {
      "classification_loss": 0.6182647943496704,
      "epoch": 3.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13448785245418549,
      "orthogonal_weight": 0.1,
      "step": 944,
      "total_loss": 0.6317135691642761,
      "weighted_orthogonal_loss": 0.013448785059154034
    },
    {
      "classification_loss": 0.6573328375816345,
      "epoch": 3.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13461290299892426,
      "orthogonal_weight": 0.1,
      "step": 945,
      "total_loss": 0.6707941293716431,
      "weighted_orthogonal_loss": 0.01346129085868597
    },
    {
      "classification_loss": 0.6940430998802185,
      "epoch": 3.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1347406655550003,
      "orthogonal_weight": 0.1,
      "step": 946,
      "total_loss": 0.707517147064209,
      "weighted_orthogonal_loss": 0.013474066741764545
    },
    {
      "classification_loss": 0.6537476181983948,
      "epoch": 3.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13490833342075348,
      "orthogonal_weight": 0.1,
      "step": 947,
      "total_loss": 0.6672384738922119,
      "weighted_orthogonal_loss": 0.013490833342075348
    },
    {
      "classification_loss": 0.7100512981414795,
      "epoch": 3.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1350744515657425,
      "orthogonal_weight": 0.1,
      "step": 948,
      "total_loss": 0.7235587239265442,
      "weighted_orthogonal_loss": 0.013507445342838764
    },
    {
      "classification_loss": 0.6818158626556396,
      "epoch": 3.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1352919638156891,
      "orthogonal_weight": 0.1,
      "step": 949,
      "total_loss": 0.6953450441360474,
      "weighted_orthogonal_loss": 0.013529196381568909
    },
    {
      "classification_loss": 0.6380026340484619,
      "epoch": 3.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13551689684391022,
      "orthogonal_weight": 0.1,
      "step": 950,
      "total_loss": 0.6515543460845947,
      "weighted_orthogonal_loss": 0.013551689684391022
    },
    {
      "classification_loss": 0.639814555644989,
      "epoch": 3.1180327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357669234275818,
      "orthogonal_weight": 0.1,
      "step": 951,
      "total_loss": 0.6533912420272827,
      "weighted_orthogonal_loss": 0.013576692901551723
    },
    {
      "classification_loss": 0.6903493404388428,
      "epoch": 3.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13606227934360504,
      "orthogonal_weight": 0.1,
      "step": 952,
      "total_loss": 0.7039555907249451,
      "weighted_orthogonal_loss": 0.013606227934360504
    },
    {
      "classification_loss": 0.6345198750495911,
      "epoch": 3.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631582260131836,
      "orthogonal_weight": 0.1,
      "step": 953,
      "total_loss": 0.6481514573097229,
      "weighted_orthogonal_loss": 0.013631582260131836
    },
    {
      "classification_loss": 0.6613372564315796,
      "epoch": 3.1278688524590166,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13660413026809692,
      "orthogonal_weight": 0.1,
      "step": 954,
      "total_loss": 0.6749976873397827,
      "weighted_orthogonal_loss": 0.013660413213074207
    },
    {
      "classification_loss": 0.6540759801864624,
      "epoch": 3.1311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13664482533931732,
      "orthogonal_weight": 0.1,
      "step": 955,
      "total_loss": 0.6677404642105103,
      "weighted_orthogonal_loss": 0.013664483092725277
    },
    {
      "classification_loss": 0.6421686410903931,
      "epoch": 3.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1366959661245346,
      "orthogonal_weight": 0.1,
      "step": 956,
      "total_loss": 0.6558382511138916,
      "weighted_orthogonal_loss": 0.01366959698498249
    },
    {
      "classification_loss": 0.6001585125923157,
      "epoch": 3.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13678671419620514,
      "orthogonal_weight": 0.1,
      "step": 957,
      "total_loss": 0.6138371825218201,
      "weighted_orthogonal_loss": 0.013678671792149544
    },
    {
      "classification_loss": 0.6398242712020874,
      "epoch": 3.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13685038685798645,
      "orthogonal_weight": 0.1,
      "step": 958,
      "total_loss": 0.6535093188285828,
      "weighted_orthogonal_loss": 0.01368503924459219
    },
    {
      "classification_loss": 0.6549479961395264,
      "epoch": 3.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13693776726722717,
      "orthogonal_weight": 0.1,
      "step": 959,
      "total_loss": 0.6686417460441589,
      "weighted_orthogonal_loss": 0.013693776912987232
    },
    {
      "classification_loss": 0.6798014640808105,
      "epoch": 3.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371031552553177,
      "orthogonal_weight": 0.1,
      "step": 960,
      "total_loss": 0.6935117840766907,
      "weighted_orthogonal_loss": 0.013710315339267254
    },
    {
      "classification_loss": 0.6741546392440796,
      "epoch": 3.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13723506033420563,
      "orthogonal_weight": 0.1,
      "step": 961,
      "total_loss": 0.6878781318664551,
      "weighted_orthogonal_loss": 0.013723506592214108
    },
    {
      "classification_loss": 0.6198928952217102,
      "epoch": 3.1540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371309608221054,
      "orthogonal_weight": 0.1,
      "step": 962,
      "total_loss": 0.6336060166358948,
      "weighted_orthogonal_loss": 0.013713096268475056
    },
    {
      "classification_loss": 0.6767441034317017,
      "epoch": 3.1573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371006965637207,
      "orthogonal_weight": 0.1,
      "step": 963,
      "total_loss": 0.6904541850090027,
      "weighted_orthogonal_loss": 0.013710069470107555
    },
    {
      "classification_loss": 0.6412035226821899,
      "epoch": 3.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1370914727449417,
      "orthogonal_weight": 0.1,
      "step": 964,
      "total_loss": 0.6549126505851746,
      "weighted_orthogonal_loss": 0.013709147460758686
    },
    {
      "classification_loss": 0.6378623843193054,
      "epoch": 3.1639344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13712355494499207,
      "orthogonal_weight": 0.1,
      "step": 965,
      "total_loss": 0.6515747308731079,
      "weighted_orthogonal_loss": 0.013712355867028236
    },
    {
      "classification_loss": 0.6579567193984985,
      "epoch": 3.1672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717393577098846,
      "orthogonal_weight": 0.1,
      "step": 966,
      "total_loss": 0.6716741323471069,
      "weighted_orthogonal_loss": 0.013717393390834332
    },
    {
      "classification_loss": 0.6192328929901123,
      "epoch": 3.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1372346431016922,
      "orthogonal_weight": 0.1,
      "step": 967,
      "total_loss": 0.6329563856124878,
      "weighted_orthogonal_loss": 0.01372346468269825
    },
    {
      "classification_loss": 0.6666384935379028,
      "epoch": 3.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13733573257923126,
      "orthogonal_weight": 0.1,
      "step": 968,
      "total_loss": 0.6803720593452454,
      "weighted_orthogonal_loss": 0.013733573257923126
    },
    {
      "classification_loss": 0.6563258767127991,
      "epoch": 3.177049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13743789494037628,
      "orthogonal_weight": 0.1,
      "step": 969,
      "total_loss": 0.670069694519043,
      "weighted_orthogonal_loss": 0.013743789866566658
    },
    {
      "classification_loss": 0.646151065826416,
      "epoch": 3.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749854266643524,
      "orthogonal_weight": 0.1,
      "step": 970,
      "total_loss": 0.6599009037017822,
      "weighted_orthogonal_loss": 0.013749854639172554
    },
    {
      "classification_loss": 0.6902819275856018,
      "epoch": 3.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376294046640396,
      "orthogonal_weight": 0.1,
      "step": 971,
      "total_loss": 0.7040448784828186,
      "weighted_orthogonal_loss": 0.013762940652668476
    },
    {
      "classification_loss": 0.6010188460350037,
      "epoch": 3.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13780198991298676,
      "orthogonal_weight": 0.1,
      "step": 972,
      "total_loss": 0.6147990226745605,
      "weighted_orthogonal_loss": 0.013780198991298676
    },
    {
      "classification_loss": 0.6743837594985962,
      "epoch": 3.1901639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13811206817626953,
      "orthogonal_weight": 0.1,
      "step": 973,
      "total_loss": 0.688194990158081,
      "weighted_orthogonal_loss": 0.013811207376420498
    },
    {
      "classification_loss": 0.6004368662834167,
      "epoch": 3.1934426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13842546939849854,
      "orthogonal_weight": 0.1,
      "step": 974,
      "total_loss": 0.6142793893814087,
      "weighted_orthogonal_loss": 0.013842547312378883
    },
    {
      "classification_loss": 0.6734126210212708,
      "epoch": 3.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13868871331214905,
      "orthogonal_weight": 0.1,
      "step": 975,
      "total_loss": 0.6872814893722534,
      "weighted_orthogonal_loss": 0.01386887114495039
    },
    {
      "classification_loss": 0.6442055106163025,
      "epoch": 3.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1389317810535431,
      "orthogonal_weight": 0.1,
      "step": 976,
      "total_loss": 0.6580986976623535,
      "weighted_orthogonal_loss": 0.013893178664147854
    },
    {
      "classification_loss": 0.6403493881225586,
      "epoch": 3.2032786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13917984068393707,
      "orthogonal_weight": 0.1,
      "step": 977,
      "total_loss": 0.6542673707008362,
      "weighted_orthogonal_loss": 0.013917984440922737
    },
    {
      "classification_loss": 0.6741981506347656,
      "epoch": 3.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1393687129020691,
      "orthogonal_weight": 0.1,
      "step": 978,
      "total_loss": 0.688135027885437,
      "weighted_orthogonal_loss": 0.013936871662735939
    },
    {
      "classification_loss": 0.6380749344825745,
      "epoch": 3.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13958795368671417,
      "orthogonal_weight": 0.1,
      "step": 979,
      "total_loss": 0.6520337462425232,
      "weighted_orthogonal_loss": 0.013958795927464962
    },
    {
      "classification_loss": 0.6342712044715881,
      "epoch": 3.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1397451013326645,
      "orthogonal_weight": 0.1,
      "step": 980,
      "total_loss": 0.6482456922531128,
      "weighted_orthogonal_loss": 0.013974510133266449
    },
    {
      "classification_loss": 0.7204321622848511,
      "epoch": 3.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13992691040039062,
      "orthogonal_weight": 0.1,
      "step": 981,
      "total_loss": 0.7344248294830322,
      "weighted_orthogonal_loss": 0.013992691412568092
    },
    {
      "classification_loss": 0.6277929544448853,
      "epoch": 3.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14013764262199402,
      "orthogonal_weight": 0.1,
      "step": 982,
      "total_loss": 0.6418067216873169,
      "weighted_orthogonal_loss": 0.014013764448463917
    },
    {
      "classification_loss": 0.654269814491272,
      "epoch": 3.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1402316391468048,
      "orthogonal_weight": 0.1,
      "step": 983,
      "total_loss": 0.6682929992675781,
      "weighted_orthogonal_loss": 0.01402316428720951
    },
    {
      "classification_loss": 0.7230896353721619,
      "epoch": 3.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1403599977493286,
      "orthogonal_weight": 0.1,
      "step": 984,
      "total_loss": 0.7371256351470947,
      "weighted_orthogonal_loss": 0.014035999774932861
    },
    {
      "classification_loss": 0.6091078519821167,
      "epoch": 3.2295081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14045706391334534,
      "orthogonal_weight": 0.1,
      "step": 985,
      "total_loss": 0.623153567314148,
      "weighted_orthogonal_loss": 0.014045706950128078
    },
    {
      "classification_loss": 0.6315215826034546,
      "epoch": 3.2327868852459014,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14047633111476898,
      "orthogonal_weight": 0.1,
      "step": 986,
      "total_loss": 0.6455692052841187,
      "weighted_orthogonal_loss": 0.014047632925212383
    },
    {
      "classification_loss": 0.7049210667610168,
      "epoch": 3.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14050062000751495,
      "orthogonal_weight": 0.1,
      "step": 987,
      "total_loss": 0.7189711332321167,
      "weighted_orthogonal_loss": 0.01405006181448698
    },
    {
      "classification_loss": 0.6868048906326294,
      "epoch": 3.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.140533909201622,
      "orthogonal_weight": 0.1,
      "step": 988,
      "total_loss": 0.7008582949638367,
      "weighted_orthogonal_loss": 0.01405339129269123
    },
    {
      "classification_loss": 0.6430195569992065,
      "epoch": 3.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1405780166387558,
      "orthogonal_weight": 0.1,
      "step": 989,
      "total_loss": 0.6570773720741272,
      "weighted_orthogonal_loss": 0.01405780203640461
    },
    {
      "classification_loss": 0.6126911044120789,
      "epoch": 3.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406165510416031,
      "orthogonal_weight": 0.1,
      "step": 990,
      "total_loss": 0.6267527341842651,
      "weighted_orthogonal_loss": 0.014061654917895794
    },
    {
      "classification_loss": 0.7152563333511353,
      "epoch": 3.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14066220819950104,
      "orthogonal_weight": 0.1,
      "step": 991,
      "total_loss": 0.7293225526809692,
      "weighted_orthogonal_loss": 0.014066221192479134
    },
    {
      "classification_loss": 0.6327564120292664,
      "epoch": 3.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14074385166168213,
      "orthogonal_weight": 0.1,
      "step": 992,
      "total_loss": 0.6468307971954346,
      "weighted_orthogonal_loss": 0.014074385166168213
    },
    {
      "classification_loss": 0.7078341245651245,
      "epoch": 3.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14083652198314667,
      "orthogonal_weight": 0.1,
      "step": 993,
      "total_loss": 0.7219177484512329,
      "weighted_orthogonal_loss": 0.014083652757108212
    },
    {
      "classification_loss": 0.638905942440033,
      "epoch": 3.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14072902500629425,
      "orthogonal_weight": 0.1,
      "step": 994,
      "total_loss": 0.6529788374900818,
      "weighted_orthogonal_loss": 0.014072902500629425
    },
    {
      "classification_loss": 0.6364955306053162,
      "epoch": 3.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14065606892108917,
      "orthogonal_weight": 0.1,
      "step": 995,
      "total_loss": 0.6505611538887024,
      "weighted_orthogonal_loss": 0.014065607450902462
    },
    {
      "classification_loss": 0.6164757609367371,
      "epoch": 3.265573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14073798060417175,
      "orthogonal_weight": 0.1,
      "step": 996,
      "total_loss": 0.6305495500564575,
      "weighted_orthogonal_loss": 0.014073798432946205
    },
    {
      "classification_loss": 0.6315312385559082,
      "epoch": 3.2688524590163937,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14080023765563965,
      "orthogonal_weight": 0.1,
      "step": 997,
      "total_loss": 0.6456112861633301,
      "weighted_orthogonal_loss": 0.01408002432435751
    },
    {
      "classification_loss": 0.6797311305999756,
      "epoch": 3.2721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14095667004585266,
      "orthogonal_weight": 0.1,
      "step": 998,
      "total_loss": 0.6938267946243286,
      "weighted_orthogonal_loss": 0.014095666818320751
    },
    {
      "classification_loss": 0.6503975987434387,
      "epoch": 3.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1411110907793045,
      "orthogonal_weight": 0.1,
      "step": 999,
      "total_loss": 0.6645087003707886,
      "weighted_orthogonal_loss": 0.01411110907793045
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 7.654499530792236,
      "learning_rate": 0.00017003333333333334,
      "loss": 0.6706,
      "step": 1000
    },
    {
      "classification_loss": 0.6191651821136475,
      "epoch": 3.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14125342667102814,
      "orthogonal_weight": 0.1,
      "step": 1000,
      "total_loss": 0.6332905292510986,
      "weighted_orthogonal_loss": 0.014125342480838299
    },
    {
      "classification_loss": 0.6513949632644653,
      "epoch": 3.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1411789506673813,
      "orthogonal_weight": 0.1,
      "step": 1001,
      "total_loss": 0.6655128598213196,
      "weighted_orthogonal_loss": 0.014117895625531673
    },
    {
      "classification_loss": 0.6781859397888184,
      "epoch": 3.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14087694883346558,
      "orthogonal_weight": 0.1,
      "step": 1002,
      "total_loss": 0.6922736167907715,
      "weighted_orthogonal_loss": 0.014087694697082043
    },
    {
      "classification_loss": 0.6944517493247986,
      "epoch": 3.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406310349702835,
      "orthogonal_weight": 0.1,
      "step": 1003,
      "total_loss": 0.7085148692131042,
      "weighted_orthogonal_loss": 0.014063104055821896
    },
    {
      "classification_loss": 0.6507539749145508,
      "epoch": 3.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14041300117969513,
      "orthogonal_weight": 0.1,
      "step": 1004,
      "total_loss": 0.6647952795028687,
      "weighted_orthogonal_loss": 0.014041299931704998
    },
    {
      "classification_loss": 0.6273910999298096,
      "epoch": 3.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14022056758403778,
      "orthogonal_weight": 0.1,
      "step": 1005,
      "total_loss": 0.641413152217865,
      "weighted_orthogonal_loss": 0.014022056944668293
    },
    {
      "classification_loss": 0.7005413174629211,
      "epoch": 3.2983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1400725096464157,
      "orthogonal_weight": 0.1,
      "step": 1006,
      "total_loss": 0.7145485877990723,
      "weighted_orthogonal_loss": 0.014007250778377056
    },
    {
      "classification_loss": 0.6762268543243408,
      "epoch": 3.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13990361988544464,
      "orthogonal_weight": 0.1,
      "step": 1007,
      "total_loss": 0.6902171969413757,
      "weighted_orthogonal_loss": 0.013990362174808979
    },
    {
      "classification_loss": 0.644727349281311,
      "epoch": 3.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13986971974372864,
      "orthogonal_weight": 0.1,
      "step": 1008,
      "total_loss": 0.6587142944335938,
      "weighted_orthogonal_loss": 0.013986972160637379
    },
    {
      "classification_loss": 0.6663669347763062,
      "epoch": 3.3081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13967908918857574,
      "orthogonal_weight": 0.1,
      "step": 1009,
      "total_loss": 0.6803348660469055,
      "weighted_orthogonal_loss": 0.013967908918857574
    },
    {
      "classification_loss": 0.6922574043273926,
      "epoch": 3.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13948602974414825,
      "orthogonal_weight": 0.1,
      "step": 1010,
      "total_loss": 0.7062060236930847,
      "weighted_orthogonal_loss": 0.01394860353320837
    },
    {
      "classification_loss": 0.6825107336044312,
      "epoch": 3.314754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13927166163921356,
      "orthogonal_weight": 0.1,
      "step": 1011,
      "total_loss": 0.6964378952980042,
      "weighted_orthogonal_loss": 0.013927166350185871
    },
    {
      "classification_loss": 0.6265398263931274,
      "epoch": 3.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390901505947113,
      "orthogonal_weight": 0.1,
      "step": 1012,
      "total_loss": 0.6404488682746887,
      "weighted_orthogonal_loss": 0.013909014873206615
    },
    {
      "classification_loss": 0.6675375699996948,
      "epoch": 3.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388394981622696,
      "orthogonal_weight": 0.1,
      "step": 1013,
      "total_loss": 0.6814215183258057,
      "weighted_orthogonal_loss": 0.013883950188755989
    },
    {
      "classification_loss": 0.6483844518661499,
      "epoch": 3.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13876697421073914,
      "orthogonal_weight": 0.1,
      "step": 1014,
      "total_loss": 0.6622611284255981,
      "weighted_orthogonal_loss": 0.013876697979867458
    },
    {
      "classification_loss": 0.6377015113830566,
      "epoch": 3.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13869747519493103,
      "orthogonal_weight": 0.1,
      "step": 1015,
      "total_loss": 0.6515712738037109,
      "weighted_orthogonal_loss": 0.013869747519493103
    },
    {
      "classification_loss": 0.5941048860549927,
      "epoch": 3.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386825144290924,
      "orthogonal_weight": 0.1,
      "step": 1016,
      "total_loss": 0.6079731583595276,
      "weighted_orthogonal_loss": 0.01386825181543827
    },
    {
      "classification_loss": 0.6161072850227356,
      "epoch": 3.3344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13867513835430145,
      "orthogonal_weight": 0.1,
      "step": 1017,
      "total_loss": 0.6299747824668884,
      "weighted_orthogonal_loss": 0.013867514207959175
    },
    {
      "classification_loss": 0.6267886757850647,
      "epoch": 3.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13872677087783813,
      "orthogonal_weight": 0.1,
      "step": 1018,
      "total_loss": 0.640661358833313,
      "weighted_orthogonal_loss": 0.013872677460312843
    },
    {
      "classification_loss": 0.6988235712051392,
      "epoch": 3.3409836065573773,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13881352543830872,
      "orthogonal_weight": 0.1,
      "step": 1019,
      "total_loss": 0.7127048969268799,
      "weighted_orthogonal_loss": 0.013881352730095387
    },
    {
      "classification_loss": 0.676645040512085,
      "epoch": 3.3442622950819674,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13886518776416779,
      "orthogonal_weight": 0.1,
      "step": 1020,
      "total_loss": 0.6905315518379211,
      "weighted_orthogonal_loss": 0.013886518776416779
    },
    {
      "classification_loss": 0.6767535209655762,
      "epoch": 3.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13882100582122803,
      "orthogonal_weight": 0.1,
      "step": 1021,
      "total_loss": 0.690635621547699,
      "weighted_orthogonal_loss": 0.013882100582122803
    },
    {
      "classification_loss": 0.7252440452575684,
      "epoch": 3.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13886775076389313,
      "orthogonal_weight": 0.1,
      "step": 1022,
      "total_loss": 0.7391307950019836,
      "weighted_orthogonal_loss": 0.013886774890124798
    },
    {
      "classification_loss": 0.6484150886535645,
      "epoch": 3.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13893291354179382,
      "orthogonal_weight": 0.1,
      "step": 1023,
      "total_loss": 0.662308394908905,
      "weighted_orthogonal_loss": 0.013893291354179382
    },
    {
      "classification_loss": 0.6559189558029175,
      "epoch": 3.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386280506849289,
      "orthogonal_weight": 0.1,
      "step": 1024,
      "total_loss": 0.6697817444801331,
      "weighted_orthogonal_loss": 0.01386280544102192
    },
    {
      "classification_loss": 0.6672844290733337,
      "epoch": 3.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13838335871696472,
      "orthogonal_weight": 0.1,
      "step": 1025,
      "total_loss": 0.6811227798461914,
      "weighted_orthogonal_loss": 0.013838335871696472
    },
    {
      "classification_loss": 0.6752216219902039,
      "epoch": 3.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13820643723011017,
      "orthogonal_weight": 0.1,
      "step": 1026,
      "total_loss": 0.6890422701835632,
      "weighted_orthogonal_loss": 0.013820643536746502
    },
    {
      "classification_loss": 0.689396858215332,
      "epoch": 3.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1381242573261261,
      "orthogonal_weight": 0.1,
      "step": 1027,
      "total_loss": 0.7032092809677124,
      "weighted_orthogonal_loss": 0.013812425546348095
    },
    {
      "classification_loss": 0.6453076004981995,
      "epoch": 3.3704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1381722092628479,
      "orthogonal_weight": 0.1,
      "step": 1028,
      "total_loss": 0.6591248512268066,
      "weighted_orthogonal_loss": 0.01381722092628479
    },
    {
      "classification_loss": 0.6765332818031311,
      "epoch": 3.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13826413452625275,
      "orthogonal_weight": 0.1,
      "step": 1029,
      "total_loss": 0.6903597116470337,
      "weighted_orthogonal_loss": 0.01382641401141882
    },
    {
      "classification_loss": 0.6129103302955627,
      "epoch": 3.3770491803278686,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13841603696346283,
      "orthogonal_weight": 0.1,
      "step": 1030,
      "total_loss": 0.6267519593238831,
      "weighted_orthogonal_loss": 0.013841603882610798
    },
    {
      "classification_loss": 0.6298218965530396,
      "epoch": 3.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386304646730423,
      "orthogonal_weight": 0.1,
      "step": 1031,
      "total_loss": 0.6436849236488342,
      "weighted_orthogonal_loss": 0.013863046653568745
    },
    {
      "classification_loss": 0.6449940800666809,
      "epoch": 3.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388632357120514,
      "orthogonal_weight": 0.1,
      "step": 1032,
      "total_loss": 0.6588804125785828,
      "weighted_orthogonal_loss": 0.013886324129998684
    },
    {
      "classification_loss": 0.6037570834159851,
      "epoch": 3.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13900944590568542,
      "orthogonal_weight": 0.1,
      "step": 1033,
      "total_loss": 0.6176580190658569,
      "weighted_orthogonal_loss": 0.013900944963097572
    },
    {
      "classification_loss": 0.6562291383743286,
      "epoch": 3.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920624554157257,
      "orthogonal_weight": 0.1,
      "step": 1034,
      "total_loss": 0.6701497435569763,
      "weighted_orthogonal_loss": 0.013920624740421772
    },
    {
      "classification_loss": 0.7009933590888977,
      "epoch": 3.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13939376175403595,
      "orthogonal_weight": 0.1,
      "step": 1035,
      "total_loss": 0.7149327397346497,
      "weighted_orthogonal_loss": 0.01393937598913908
    },
    {
      "classification_loss": 0.6541226506233215,
      "epoch": 3.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1395602822303772,
      "orthogonal_weight": 0.1,
      "step": 1036,
      "total_loss": 0.6680786609649658,
      "weighted_orthogonal_loss": 0.013956028036773205
    },
    {
      "classification_loss": 0.7284018397331238,
      "epoch": 3.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1397503763437271,
      "orthogonal_weight": 0.1,
      "step": 1037,
      "total_loss": 0.7423768639564514,
      "weighted_orthogonal_loss": 0.013975038193166256
    },
    {
      "classification_loss": 0.6859689950942993,
      "epoch": 3.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13994283974170685,
      "orthogonal_weight": 0.1,
      "step": 1038,
      "total_loss": 0.6999632716178894,
      "weighted_orthogonal_loss": 0.013994283974170685
    },
    {
      "classification_loss": 0.676382839679718,
      "epoch": 3.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14031918346881866,
      "orthogonal_weight": 0.1,
      "step": 1039,
      "total_loss": 0.6904147863388062,
      "weighted_orthogonal_loss": 0.014031918719410896
    },
    {
      "classification_loss": 0.6595774292945862,
      "epoch": 3.4098360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14063377678394318,
      "orthogonal_weight": 0.1,
      "step": 1040,
      "total_loss": 0.673640787601471,
      "weighted_orthogonal_loss": 0.014063377864658833
    },
    {
      "classification_loss": 0.6383638978004456,
      "epoch": 3.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1408020704984665,
      "orthogonal_weight": 0.1,
      "step": 1041,
      "total_loss": 0.6524441242218018,
      "weighted_orthogonal_loss": 0.014080206863582134
    },
    {
      "classification_loss": 0.6562723517417908,
      "epoch": 3.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14072060585021973,
      "orthogonal_weight": 0.1,
      "step": 1042,
      "total_loss": 0.6703444123268127,
      "weighted_orthogonal_loss": 0.014072060585021973
    },
    {
      "classification_loss": 0.6057292819023132,
      "epoch": 3.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14064131677150726,
      "orthogonal_weight": 0.1,
      "step": 1043,
      "total_loss": 0.6197934150695801,
      "weighted_orthogonal_loss": 0.014064132235944271
    },
    {
      "classification_loss": 0.6434441804885864,
      "epoch": 3.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406414657831192,
      "orthogonal_weight": 0.1,
      "step": 1044,
      "total_loss": 0.6575083136558533,
      "weighted_orthogonal_loss": 0.014064147137105465
    },
    {
      "classification_loss": 0.6458033919334412,
      "epoch": 3.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14061889052391052,
      "orthogonal_weight": 0.1,
      "step": 1045,
      "total_loss": 0.6598652601242065,
      "weighted_orthogonal_loss": 0.014061889611184597
    },
    {
      "classification_loss": 0.644622802734375,
      "epoch": 3.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14066772162914276,
      "orthogonal_weight": 0.1,
      "step": 1046,
      "total_loss": 0.658689558506012,
      "weighted_orthogonal_loss": 0.014066772535443306
    },
    {
      "classification_loss": 0.698952853679657,
      "epoch": 3.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14068932831287384,
      "orthogonal_weight": 0.1,
      "step": 1047,
      "total_loss": 0.7130218148231506,
      "weighted_orthogonal_loss": 0.014068933203816414
    },
    {
      "classification_loss": 0.6921736001968384,
      "epoch": 3.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406911313533783,
      "orthogonal_weight": 0.1,
      "step": 1048,
      "total_loss": 0.7062427401542664,
      "weighted_orthogonal_loss": 0.014069112949073315
    },
    {
      "classification_loss": 0.7155394554138184,
      "epoch": 3.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14067214727401733,
      "orthogonal_weight": 0.1,
      "step": 1049,
      "total_loss": 0.7296066880226135,
      "weighted_orthogonal_loss": 0.014067214913666248
    },
    {
      "classification_loss": 0.6380400061607361,
      "epoch": 3.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14062225818634033,
      "orthogonal_weight": 0.1,
      "step": 1050,
      "total_loss": 0.6521022319793701,
      "weighted_orthogonal_loss": 0.014062225818634033
    },
    {
      "classification_loss": 0.6662687659263611,
      "epoch": 3.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406167596578598,
      "orthogonal_weight": 0.1,
      "step": 1051,
      "total_loss": 0.6803304553031921,
      "weighted_orthogonal_loss": 0.01406167633831501
    },
    {
      "classification_loss": 0.6437544822692871,
      "epoch": 3.4491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14057175815105438,
      "orthogonal_weight": 0.1,
      "step": 1052,
      "total_loss": 0.6578116416931152,
      "weighted_orthogonal_loss": 0.014057176187634468
    },
    {
      "classification_loss": 0.6608327627182007,
      "epoch": 3.4524590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14049115777015686,
      "orthogonal_weight": 0.1,
      "step": 1053,
      "total_loss": 0.6748818755149841,
      "weighted_orthogonal_loss": 0.014049115590751171
    },
    {
      "classification_loss": 0.6575770974159241,
      "epoch": 3.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14046122133731842,
      "orthogonal_weight": 0.1,
      "step": 1054,
      "total_loss": 0.6716232299804688,
      "weighted_orthogonal_loss": 0.014046122319996357
    },
    {
      "classification_loss": 0.6264941096305847,
      "epoch": 3.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14040954411029816,
      "orthogonal_weight": 0.1,
      "step": 1055,
      "total_loss": 0.6405350565910339,
      "weighted_orthogonal_loss": 0.014040954411029816
    },
    {
      "classification_loss": 0.661169171333313,
      "epoch": 3.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14024801552295685,
      "orthogonal_weight": 0.1,
      "step": 1056,
      "total_loss": 0.6751939654350281,
      "weighted_orthogonal_loss": 0.014024801552295685
    },
    {
      "classification_loss": 0.7046919465065002,
      "epoch": 3.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.139944389462471,
      "orthogonal_weight": 0.1,
      "step": 1057,
      "total_loss": 0.7186864018440247,
      "weighted_orthogonal_loss": 0.013994439505040646
    },
    {
      "classification_loss": 0.6627988815307617,
      "epoch": 3.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1394421011209488,
      "orthogonal_weight": 0.1,
      "step": 1058,
      "total_loss": 0.6767430901527405,
      "weighted_orthogonal_loss": 0.013944210484623909
    },
    {
      "classification_loss": 0.6677634119987488,
      "epoch": 3.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390584409236908,
      "orthogonal_weight": 0.1,
      "step": 1059,
      "total_loss": 0.6816692352294922,
      "weighted_orthogonal_loss": 0.013905844651162624
    },
    {
      "classification_loss": 0.6419862508773804,
      "epoch": 3.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13869120180606842,
      "orthogonal_weight": 0.1,
      "step": 1060,
      "total_loss": 0.6558553576469421,
      "weighted_orthogonal_loss": 0.013869120739400387
    },
    {
      "classification_loss": 0.623318076133728,
      "epoch": 3.4786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13835744559764862,
      "orthogonal_weight": 0.1,
      "step": 1061,
      "total_loss": 0.6371538043022156,
      "weighted_orthogonal_loss": 0.013835744932293892
    },
    {
      "classification_loss": 0.6046179533004761,
      "epoch": 3.4819672131147543,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13805921375751495,
      "orthogonal_weight": 0.1,
      "step": 1062,
      "total_loss": 0.6184238791465759,
      "weighted_orthogonal_loss": 0.01380592118948698
    },
    {
      "classification_loss": 0.6640592813491821,
      "epoch": 3.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1377640962600708,
      "orthogonal_weight": 0.1,
      "step": 1063,
      "total_loss": 0.6778357028961182,
      "weighted_orthogonal_loss": 0.013776409439742565
    },
    {
      "classification_loss": 0.6753458380699158,
      "epoch": 3.4885245901639346,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13745616376399994,
      "orthogonal_weight": 0.1,
      "step": 1064,
      "total_loss": 0.6890914440155029,
      "weighted_orthogonal_loss": 0.013745616190135479
    },
    {
      "classification_loss": 0.6732324361801147,
      "epoch": 3.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13713431358337402,
      "orthogonal_weight": 0.1,
      "step": 1065,
      "total_loss": 0.6869458556175232,
      "weighted_orthogonal_loss": 0.013713431544601917
    },
    {
      "classification_loss": 0.7454939484596252,
      "epoch": 3.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1368984878063202,
      "orthogonal_weight": 0.1,
      "step": 1066,
      "total_loss": 0.7591838240623474,
      "weighted_orthogonal_loss": 0.013689848594367504
    },
    {
      "classification_loss": 0.7292442321777344,
      "epoch": 3.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367209106683731,
      "orthogonal_weight": 0.1,
      "step": 1067,
      "total_loss": 0.7429163455963135,
      "weighted_orthogonal_loss": 0.01367209106683731
    },
    {
      "classification_loss": 0.6427954435348511,
      "epoch": 3.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13658328354358673,
      "orthogonal_weight": 0.1,
      "step": 1068,
      "total_loss": 0.6564537882804871,
      "weighted_orthogonal_loss": 0.013658328913152218
    },
    {
      "classification_loss": 0.6954324841499329,
      "epoch": 3.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13624919950962067,
      "orthogonal_weight": 0.1,
      "step": 1069,
      "total_loss": 0.7090573906898499,
      "weighted_orthogonal_loss": 0.013624920509755611
    },
    {
      "classification_loss": 0.6397826671600342,
      "epoch": 3.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13598784804344177,
      "orthogonal_weight": 0.1,
      "step": 1070,
      "total_loss": 0.6533814668655396,
      "weighted_orthogonal_loss": 0.013598784804344177
    },
    {
      "classification_loss": 0.6373751163482666,
      "epoch": 3.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355248987674713,
      "orthogonal_weight": 0.1,
      "step": 1071,
      "total_loss": 0.6509276032447815,
      "weighted_orthogonal_loss": 0.013552489690482616
    },
    {
      "classification_loss": 0.6698706150054932,
      "epoch": 3.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13518650829792023,
      "orthogonal_weight": 0.1,
      "step": 1072,
      "total_loss": 0.6833892464637756,
      "weighted_orthogonal_loss": 0.013518651016056538
    },
    {
      "classification_loss": 0.6284856200218201,
      "epoch": 3.5180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1349257081747055,
      "orthogonal_weight": 0.1,
      "step": 1073,
      "total_loss": 0.6419782042503357,
      "weighted_orthogonal_loss": 0.01349257118999958
    },
    {
      "classification_loss": 0.6300276517868042,
      "epoch": 3.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1347011923789978,
      "orthogonal_weight": 0.1,
      "step": 1074,
      "total_loss": 0.6434977650642395,
      "weighted_orthogonal_loss": 0.013470119796693325
    },
    {
      "classification_loss": 0.6360009908676147,
      "epoch": 3.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13459265232086182,
      "orthogonal_weight": 0.1,
      "step": 1075,
      "total_loss": 0.6494602560997009,
      "weighted_orthogonal_loss": 0.013459265232086182
    },
    {
      "classification_loss": 0.6513693332672119,
      "epoch": 3.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13449428975582123,
      "orthogonal_weight": 0.1,
      "step": 1076,
      "total_loss": 0.6648187637329102,
      "weighted_orthogonal_loss": 0.013449429534375668
    },
    {
      "classification_loss": 0.6503164172172546,
      "epoch": 3.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13424637913703918,
      "orthogonal_weight": 0.1,
      "step": 1077,
      "total_loss": 0.6637410521507263,
      "weighted_orthogonal_loss": 0.013424637727439404
    },
    {
      "classification_loss": 0.6753547787666321,
      "epoch": 3.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13405142724514008,
      "orthogonal_weight": 0.1,
      "step": 1078,
      "total_loss": 0.6887599229812622,
      "weighted_orthogonal_loss": 0.013405143283307552
    },
    {
      "classification_loss": 0.6091670989990234,
      "epoch": 3.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1339167058467865,
      "orthogonal_weight": 0.1,
      "step": 1079,
      "total_loss": 0.6225587725639343,
      "weighted_orthogonal_loss": 0.013391670770943165
    },
    {
      "classification_loss": 0.7048548460006714,
      "epoch": 3.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13381361961364746,
      "orthogonal_weight": 0.1,
      "step": 1080,
      "total_loss": 0.7182362079620361,
      "weighted_orthogonal_loss": 0.013381361961364746
    },
    {
      "classification_loss": 0.6308206915855408,
      "epoch": 3.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13366027176380157,
      "orthogonal_weight": 0.1,
      "step": 1081,
      "total_loss": 0.6441867351531982,
      "weighted_orthogonal_loss": 0.013366027735173702
    },
    {
      "classification_loss": 0.6477453708648682,
      "epoch": 3.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13349053263664246,
      "orthogonal_weight": 0.1,
      "step": 1082,
      "total_loss": 0.6610944271087646,
      "weighted_orthogonal_loss": 0.01334905344992876
    },
    {
      "classification_loss": 0.6862356066703796,
      "epoch": 3.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13335376977920532,
      "orthogonal_weight": 0.1,
      "step": 1083,
      "total_loss": 0.6995710134506226,
      "weighted_orthogonal_loss": 0.013335376977920532
    },
    {
      "classification_loss": 0.6451468467712402,
      "epoch": 3.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13320183753967285,
      "orthogonal_weight": 0.1,
      "step": 1084,
      "total_loss": 0.6584670543670654,
      "weighted_orthogonal_loss": 0.01332018431276083
    },
    {
      "classification_loss": 0.6948952674865723,
      "epoch": 3.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331050544977188,
      "orthogonal_weight": 0.1,
      "step": 1085,
      "total_loss": 0.7082057595252991,
      "weighted_orthogonal_loss": 0.013310506008565426
    },
    {
      "classification_loss": 0.66086745262146,
      "epoch": 3.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133036807179451,
      "orthogonal_weight": 0.1,
      "step": 1086,
      "total_loss": 0.6741711497306824,
      "weighted_orthogonal_loss": 0.013303681276738644
    },
    {
      "classification_loss": 0.7043195962905884,
      "epoch": 3.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13307826220989227,
      "orthogonal_weight": 0.1,
      "step": 1087,
      "total_loss": 0.7176274061203003,
      "weighted_orthogonal_loss": 0.013307826593518257
    },
    {
      "classification_loss": 0.7047708034515381,
      "epoch": 3.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13312439620494843,
      "orthogonal_weight": 0.1,
      "step": 1088,
      "total_loss": 0.7180832624435425,
      "weighted_orthogonal_loss": 0.013312439434230328
    },
    {
      "classification_loss": 0.6805914044380188,
      "epoch": 3.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331978738307953,
      "orthogonal_weight": 0.1,
      "step": 1089,
      "total_loss": 0.6939111948013306,
      "weighted_orthogonal_loss": 0.013319787569344044
    },
    {
      "classification_loss": 0.6832306981086731,
      "epoch": 3.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133308544754982,
      "orthogonal_weight": 0.1,
      "step": 1090,
      "total_loss": 0.6965615749359131,
      "weighted_orthogonal_loss": 0.0133308544754982
    },
    {
      "classification_loss": 0.610625684261322,
      "epoch": 3.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13341939449310303,
      "orthogonal_weight": 0.1,
      "step": 1091,
      "total_loss": 0.6239676475524902,
      "weighted_orthogonal_loss": 0.013341940008103848
    },
    {
      "classification_loss": 0.6034817695617676,
      "epoch": 3.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1334773302078247,
      "orthogonal_weight": 0.1,
      "step": 1092,
      "total_loss": 0.616829514503479,
      "weighted_orthogonal_loss": 0.013347732834517956
    },
    {
      "classification_loss": 0.6689616441726685,
      "epoch": 3.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13350063562393188,
      "orthogonal_weight": 0.1,
      "step": 1093,
      "total_loss": 0.6823117136955261,
      "weighted_orthogonal_loss": 0.013350063934922218
    },
    {
      "classification_loss": 0.7294720411300659,
      "epoch": 3.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13353581726551056,
      "orthogonal_weight": 0.1,
      "step": 1094,
      "total_loss": 0.7428256273269653,
      "weighted_orthogonal_loss": 0.013353581540286541
    },
    {
      "classification_loss": 0.6182592511177063,
      "epoch": 3.5901639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336051970720291,
      "orthogonal_weight": 0.1,
      "step": 1095,
      "total_loss": 0.6316197514533997,
      "weighted_orthogonal_loss": 0.013360519893467426
    },
    {
      "classification_loss": 0.7230610251426697,
      "epoch": 3.5934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13376644253730774,
      "orthogonal_weight": 0.1,
      "step": 1096,
      "total_loss": 0.7364376783370972,
      "weighted_orthogonal_loss": 0.013376644812524319
    },
    {
      "classification_loss": 0.6612522602081299,
      "epoch": 3.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13387420773506165,
      "orthogonal_weight": 0.1,
      "step": 1097,
      "total_loss": 0.6746397018432617,
      "weighted_orthogonal_loss": 0.013387421146035194
    },
    {
      "classification_loss": 0.655811071395874,
      "epoch": 3.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13390295207500458,
      "orthogonal_weight": 0.1,
      "step": 1098,
      "total_loss": 0.6692013740539551,
      "weighted_orthogonal_loss": 0.013390295207500458
    },
    {
      "classification_loss": 0.6410961747169495,
      "epoch": 3.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1341472715139389,
      "orthogonal_weight": 0.1,
      "step": 1099,
      "total_loss": 0.6545109152793884,
      "weighted_orthogonal_loss": 0.01341472752392292
    },
    {
      "epoch": 3.6065573770491803,
      "grad_norm": 13.20907974243164,
      "learning_rate": 0.0001667,
      "loss": 0.6748,
      "step": 1100
    },
    {
      "classification_loss": 0.6573832035064697,
      "epoch": 3.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1343528777360916,
      "orthogonal_weight": 0.1,
      "step": 1100,
      "total_loss": 0.6708185076713562,
      "weighted_orthogonal_loss": 0.013435288332402706
    },
    {
      "classification_loss": 0.6767249703407288,
      "epoch": 3.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.134543776512146,
      "orthogonal_weight": 0.1,
      "step": 1101,
      "total_loss": 0.6901793479919434,
      "weighted_orthogonal_loss": 0.0134543776512146
    },
    {
      "classification_loss": 0.6665173172950745,
      "epoch": 3.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13478223979473114,
      "orthogonal_weight": 0.1,
      "step": 1102,
      "total_loss": 0.6799955368041992,
      "weighted_orthogonal_loss": 0.013478224165737629
    },
    {
      "classification_loss": 0.6837193369865417,
      "epoch": 3.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13505098223686218,
      "orthogonal_weight": 0.1,
      "step": 1103,
      "total_loss": 0.6972244381904602,
      "weighted_orthogonal_loss": 0.013505098409950733
    },
    {
      "classification_loss": 0.6715741753578186,
      "epoch": 3.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13534145057201385,
      "orthogonal_weight": 0.1,
      "step": 1104,
      "total_loss": 0.6851083040237427,
      "weighted_orthogonal_loss": 0.013534145429730415
    },
    {
      "classification_loss": 0.6374362111091614,
      "epoch": 3.6229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13564014434814453,
      "orthogonal_weight": 0.1,
      "step": 1105,
      "total_loss": 0.6510002017021179,
      "weighted_orthogonal_loss": 0.013564014807343483
    },
    {
      "classification_loss": 0.7000793218612671,
      "epoch": 3.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13588595390319824,
      "orthogonal_weight": 0.1,
      "step": 1106,
      "total_loss": 0.7136679291725159,
      "weighted_orthogonal_loss": 0.01358859520405531
    },
    {
      "classification_loss": 0.6718406677246094,
      "epoch": 3.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359843760728836,
      "orthogonal_weight": 0.1,
      "step": 1107,
      "total_loss": 0.6854391098022461,
      "weighted_orthogonal_loss": 0.013598437421023846
    },
    {
      "classification_loss": 0.673287034034729,
      "epoch": 3.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13607965409755707,
      "orthogonal_weight": 0.1,
      "step": 1108,
      "total_loss": 0.6868950128555298,
      "weighted_orthogonal_loss": 0.013607965782284737
    },
    {
      "classification_loss": 0.6718699932098389,
      "epoch": 3.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13619600236415863,
      "orthogonal_weight": 0.1,
      "step": 1109,
      "total_loss": 0.6854895949363708,
      "weighted_orthogonal_loss": 0.013619600795209408
    },
    {
      "classification_loss": 0.7264377474784851,
      "epoch": 3.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13633882999420166,
      "orthogonal_weight": 0.1,
      "step": 1110,
      "total_loss": 0.7400716543197632,
      "weighted_orthogonal_loss": 0.01363388355821371
    },
    {
      "classification_loss": 0.6495891213417053,
      "epoch": 3.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13645419478416443,
      "orthogonal_weight": 0.1,
      "step": 1111,
      "total_loss": 0.663234531879425,
      "weighted_orthogonal_loss": 0.013645419850945473
    },
    {
      "classification_loss": 0.6735225915908813,
      "epoch": 3.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13637585937976837,
      "orthogonal_weight": 0.1,
      "step": 1112,
      "total_loss": 0.6871601939201355,
      "weighted_orthogonal_loss": 0.013637586496770382
    },
    {
      "classification_loss": 0.6120544672012329,
      "epoch": 3.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13635879755020142,
      "orthogonal_weight": 0.1,
      "step": 1113,
      "total_loss": 0.6256903409957886,
      "weighted_orthogonal_loss": 0.013635880313813686
    },
    {
      "classification_loss": 0.5798734426498413,
      "epoch": 3.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13628356158733368,
      "orthogonal_weight": 0.1,
      "step": 1114,
      "total_loss": 0.5935018062591553,
      "weighted_orthogonal_loss": 0.013628356158733368
    },
    {
      "classification_loss": 0.6670145988464355,
      "epoch": 3.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361827701330185,
      "orthogonal_weight": 0.1,
      "step": 1115,
      "total_loss": 0.6806328892707825,
      "weighted_orthogonal_loss": 0.01361827738583088
    },
    {
      "classification_loss": 0.7154414057731628,
      "epoch": 3.6590163934426227,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13605324923992157,
      "orthogonal_weight": 0.1,
      "step": 1116,
      "total_loss": 0.7290467023849487,
      "weighted_orthogonal_loss": 0.013605325482785702
    },
    {
      "classification_loss": 0.6279730200767517,
      "epoch": 3.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1360112875699997,
      "orthogonal_weight": 0.1,
      "step": 1117,
      "total_loss": 0.6415741443634033,
      "weighted_orthogonal_loss": 0.013601128943264484
    },
    {
      "classification_loss": 0.6271092891693115,
      "epoch": 3.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13600051403045654,
      "orthogonal_weight": 0.1,
      "step": 1118,
      "total_loss": 0.6407093405723572,
      "weighted_orthogonal_loss": 0.013600051403045654
    },
    {
      "classification_loss": 0.6206109523773193,
      "epoch": 3.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580192625522614,
      "orthogonal_weight": 0.1,
      "step": 1119,
      "total_loss": 0.6341911554336548,
      "weighted_orthogonal_loss": 0.013580192811787128
    },
    {
      "classification_loss": 0.6442127823829651,
      "epoch": 3.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13573332130908966,
      "orthogonal_weight": 0.1,
      "step": 1120,
      "total_loss": 0.6577861309051514,
      "weighted_orthogonal_loss": 0.01357333268970251
    },
    {
      "classification_loss": 0.6872836351394653,
      "epoch": 3.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13572095334529877,
      "orthogonal_weight": 0.1,
      "step": 1121,
      "total_loss": 0.7008557319641113,
      "weighted_orthogonal_loss": 0.013572095893323421
    },
    {
      "classification_loss": 0.6601961255073547,
      "epoch": 3.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13574911653995514,
      "orthogonal_weight": 0.1,
      "step": 1122,
      "total_loss": 0.6737710237503052,
      "weighted_orthogonal_loss": 0.013574912212789059
    },
    {
      "classification_loss": 0.6360697746276855,
      "epoch": 3.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13579542934894562,
      "orthogonal_weight": 0.1,
      "step": 1123,
      "total_loss": 0.6496493220329285,
      "weighted_orthogonal_loss": 0.013579542748630047
    },
    {
      "classification_loss": 0.6564205884933472,
      "epoch": 3.685245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13587452471256256,
      "orthogonal_weight": 0.1,
      "step": 1124,
      "total_loss": 0.6700080633163452,
      "weighted_orthogonal_loss": 0.013587452471256256
    },
    {
      "classification_loss": 0.5845149755477905,
      "epoch": 3.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359485238790512,
      "orthogonal_weight": 0.1,
      "step": 1125,
      "total_loss": 0.5981098413467407,
      "weighted_orthogonal_loss": 0.01359485276043415
    },
    {
      "classification_loss": 0.6543288826942444,
      "epoch": 3.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13599172234535217,
      "orthogonal_weight": 0.1,
      "step": 1126,
      "total_loss": 0.6679280400276184,
      "weighted_orthogonal_loss": 0.013599172234535217
    },
    {
      "classification_loss": 0.6420698761940002,
      "epoch": 3.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602621853351593,
      "orthogonal_weight": 0.1,
      "step": 1127,
      "total_loss": 0.6556724905967712,
      "weighted_orthogonal_loss": 0.013602621853351593
    },
    {
      "classification_loss": 0.6504448652267456,
      "epoch": 3.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13604165613651276,
      "orthogonal_weight": 0.1,
      "step": 1128,
      "total_loss": 0.6640490293502808,
      "weighted_orthogonal_loss": 0.013604165986180305
    },
    {
      "classification_loss": 0.6465320587158203,
      "epoch": 3.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13590271770954132,
      "orthogonal_weight": 0.1,
      "step": 1129,
      "total_loss": 0.6601223349571228,
      "weighted_orthogonal_loss": 0.013590271584689617
    },
    {
      "classification_loss": 0.6491751670837402,
      "epoch": 3.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13579149544239044,
      "orthogonal_weight": 0.1,
      "step": 1130,
      "total_loss": 0.6627542972564697,
      "weighted_orthogonal_loss": 0.013579149730503559
    },
    {
      "classification_loss": 0.6443161368370056,
      "epoch": 3.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13569776713848114,
      "orthogonal_weight": 0.1,
      "step": 1131,
      "total_loss": 0.6578859090805054,
      "weighted_orthogonal_loss": 0.013569776900112629
    },
    {
      "classification_loss": 0.6967812776565552,
      "epoch": 3.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13561394810676575,
      "orthogonal_weight": 0.1,
      "step": 1132,
      "total_loss": 0.7103426456451416,
      "weighted_orthogonal_loss": 0.01356139499694109
    },
    {
      "classification_loss": 0.6292265057563782,
      "epoch": 3.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13549144566059113,
      "orthogonal_weight": 0.1,
      "step": 1133,
      "total_loss": 0.6427756547927856,
      "weighted_orthogonal_loss": 0.013549144379794598
    },
    {
      "classification_loss": 0.6852863430976868,
      "epoch": 3.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1353592872619629,
      "orthogonal_weight": 0.1,
      "step": 1134,
      "total_loss": 0.6988222599029541,
      "weighted_orthogonal_loss": 0.013535928912460804
    },
    {
      "classification_loss": 0.6099441647529602,
      "epoch": 3.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13541704416275024,
      "orthogonal_weight": 0.1,
      "step": 1135,
      "total_loss": 0.6234858632087708,
      "weighted_orthogonal_loss": 0.01354170497506857
    },
    {
      "classification_loss": 0.6371187567710876,
      "epoch": 3.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13549621403217316,
      "orthogonal_weight": 0.1,
      "step": 1136,
      "total_loss": 0.6506683826446533,
      "weighted_orthogonal_loss": 0.0135496212169528
    },
    {
      "classification_loss": 0.7192364931106567,
      "epoch": 3.7278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356373131275177,
      "orthogonal_weight": 0.1,
      "step": 1137,
      "total_loss": 0.7328002452850342,
      "weighted_orthogonal_loss": 0.0135637316852808
    },
    {
      "classification_loss": 0.6303168535232544,
      "epoch": 3.7311475409836063,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13568250834941864,
      "orthogonal_weight": 0.1,
      "step": 1138,
      "total_loss": 0.64388507604599,
      "weighted_orthogonal_loss": 0.013568251393735409
    },
    {
      "classification_loss": 0.6387798190116882,
      "epoch": 3.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13578414916992188,
      "orthogonal_weight": 0.1,
      "step": 1139,
      "total_loss": 0.6523582339286804,
      "weighted_orthogonal_loss": 0.013578414916992188
    },
    {
      "classification_loss": 0.7232140898704529,
      "epoch": 3.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13591501116752625,
      "orthogonal_weight": 0.1,
      "step": 1140,
      "total_loss": 0.7368056178092957,
      "weighted_orthogonal_loss": 0.01359150093048811
    },
    {
      "classification_loss": 0.6516124606132507,
      "epoch": 3.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13586480915546417,
      "orthogonal_weight": 0.1,
      "step": 1141,
      "total_loss": 0.6651989221572876,
      "weighted_orthogonal_loss": 0.013586481101810932
    },
    {
      "classification_loss": 0.6324297785758972,
      "epoch": 3.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13585777580738068,
      "orthogonal_weight": 0.1,
      "step": 1142,
      "total_loss": 0.6460155844688416,
      "weighted_orthogonal_loss": 0.013585777953267097
    },
    {
      "classification_loss": 0.638968825340271,
      "epoch": 3.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13582883775234222,
      "orthogonal_weight": 0.1,
      "step": 1143,
      "total_loss": 0.6525517106056213,
      "weighted_orthogonal_loss": 0.013582884334027767
    },
    {
      "classification_loss": 0.620896577835083,
      "epoch": 3.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571304082870483,
      "orthogonal_weight": 0.1,
      "step": 1144,
      "total_loss": 0.6344678997993469,
      "weighted_orthogonal_loss": 0.013571304269134998
    },
    {
      "classification_loss": 0.6436833143234253,
      "epoch": 3.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13570846617221832,
      "orthogonal_weight": 0.1,
      "step": 1145,
      "total_loss": 0.657254159450531,
      "weighted_orthogonal_loss": 0.013570846989750862
    },
    {
      "classification_loss": 0.6697224378585815,
      "epoch": 3.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571257889270782,
      "orthogonal_weight": 0.1,
      "step": 1146,
      "total_loss": 0.6832937002182007,
      "weighted_orthogonal_loss": 0.013571257703006268
    },
    {
      "classification_loss": 0.651709794998169,
      "epoch": 3.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13570040464401245,
      "orthogonal_weight": 0.1,
      "step": 1147,
      "total_loss": 0.6652798652648926,
      "weighted_orthogonal_loss": 0.013570040464401245
    },
    {
      "classification_loss": 0.6801875233650208,
      "epoch": 3.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356620341539383,
      "orthogonal_weight": 0.1,
      "step": 1148,
      "total_loss": 0.693753719329834,
      "weighted_orthogonal_loss": 0.01356620341539383
    },
    {
      "classification_loss": 0.701396107673645,
      "epoch": 3.7672131147540986,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571710884571075,
      "orthogonal_weight": 0.1,
      "step": 1149,
      "total_loss": 0.7149678468704224,
      "weighted_orthogonal_loss": 0.013571711257100105
    },
    {
      "classification_loss": 0.6747404932975769,
      "epoch": 3.7704918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13574758172035217,
      "orthogonal_weight": 0.1,
      "step": 1150,
      "total_loss": 0.6883152723312378,
      "weighted_orthogonal_loss": 0.013574758544564247
    },
    {
      "classification_loss": 0.5912339687347412,
      "epoch": 3.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13581113517284393,
      "orthogonal_weight": 0.1,
      "step": 1151,
      "total_loss": 0.6048150658607483,
      "weighted_orthogonal_loss": 0.013581113889813423
    },
    {
      "classification_loss": 0.7060593366622925,
      "epoch": 3.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13586468994617462,
      "orthogonal_weight": 0.1,
      "step": 1152,
      "total_loss": 0.7196457982063293,
      "weighted_orthogonal_loss": 0.013586468994617462
    },
    {
      "classification_loss": 0.7130844593048096,
      "epoch": 3.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13584184646606445,
      "orthogonal_weight": 0.1,
      "step": 1153,
      "total_loss": 0.726668655872345,
      "weighted_orthogonal_loss": 0.01358418446034193
    },
    {
      "classification_loss": 0.6732979416847229,
      "epoch": 3.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1358024775981903,
      "orthogonal_weight": 0.1,
      "step": 1154,
      "total_loss": 0.6868782043457031,
      "weighted_orthogonal_loss": 0.01358024775981903
    },
    {
      "classification_loss": 0.6442986130714417,
      "epoch": 3.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13575243949890137,
      "orthogonal_weight": 0.1,
      "step": 1155,
      "total_loss": 0.6578738689422607,
      "weighted_orthogonal_loss": 0.013575243763625622
    },
    {
      "classification_loss": 0.6774621605873108,
      "epoch": 3.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13568925857543945,
      "orthogonal_weight": 0.1,
      "step": 1156,
      "total_loss": 0.6910310983657837,
      "weighted_orthogonal_loss": 0.01356892567127943
    },
    {
      "classification_loss": 0.6321474313735962,
      "epoch": 3.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13566358387470245,
      "orthogonal_weight": 0.1,
      "step": 1157,
      "total_loss": 0.6457138061523438,
      "weighted_orthogonal_loss": 0.01356635894626379
    },
    {
      "classification_loss": 0.6974793076515198,
      "epoch": 3.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13565750420093536,
      "orthogonal_weight": 0.1,
      "step": 1158,
      "total_loss": 0.7110450863838196,
      "weighted_orthogonal_loss": 0.013565750792622566
    },
    {
      "classification_loss": 0.6796658039093018,
      "epoch": 3.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357065737247467,
      "orthogonal_weight": 0.1,
      "step": 1159,
      "total_loss": 0.6932364702224731,
      "weighted_orthogonal_loss": 0.013570657931268215
    },
    {
      "classification_loss": 0.6480728387832642,
      "epoch": 3.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13577890396118164,
      "orthogonal_weight": 0.1,
      "step": 1160,
      "total_loss": 0.6616507172584534,
      "weighted_orthogonal_loss": 0.013577890582382679
    },
    {
      "classification_loss": 0.6389527916908264,
      "epoch": 3.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1358620673418045,
      "orthogonal_weight": 0.1,
      "step": 1161,
      "total_loss": 0.6525390148162842,
      "weighted_orthogonal_loss": 0.013586207292973995
    },
    {
      "classification_loss": 0.6434983611106873,
      "epoch": 3.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13593216240406036,
      "orthogonal_weight": 0.1,
      "step": 1162,
      "total_loss": 0.6570915579795837,
      "weighted_orthogonal_loss": 0.013593216426670551
    },
    {
      "classification_loss": 0.6289777755737305,
      "epoch": 3.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602657616138458,
      "orthogonal_weight": 0.1,
      "step": 1163,
      "total_loss": 0.6425804495811462,
      "weighted_orthogonal_loss": 0.013602658174932003
    },
    {
      "classification_loss": 0.7664755582809448,
      "epoch": 3.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13617844879627228,
      "orthogonal_weight": 0.1,
      "step": 1164,
      "total_loss": 0.7800934314727783,
      "weighted_orthogonal_loss": 0.013617845252156258
    },
    {
      "classification_loss": 0.6059860587120056,
      "epoch": 3.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631077110767365,
      "orthogonal_weight": 0.1,
      "step": 1165,
      "total_loss": 0.6196171641349792,
      "weighted_orthogonal_loss": 0.013631077483296394
    },
    {
      "classification_loss": 0.7044680714607239,
      "epoch": 3.822950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364843249320984,
      "orthogonal_weight": 0.1,
      "step": 1166,
      "total_loss": 0.7181165218353271,
      "weighted_orthogonal_loss": 0.013648432679474354
    },
    {
      "classification_loss": 0.667748749256134,
      "epoch": 3.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13665732741355896,
      "orthogonal_weight": 0.1,
      "step": 1167,
      "total_loss": 0.6814144849777222,
      "weighted_orthogonal_loss": 0.013665732927620411
    },
    {
      "classification_loss": 0.6642449498176575,
      "epoch": 3.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13710170984268188,
      "orthogonal_weight": 0.1,
      "step": 1168,
      "total_loss": 0.677955150604248,
      "weighted_orthogonal_loss": 0.013710170984268188
    },
    {
      "classification_loss": 0.6726369857788086,
      "epoch": 3.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13763301074504852,
      "orthogonal_weight": 0.1,
      "step": 1169,
      "total_loss": 0.686400294303894,
      "weighted_orthogonal_loss": 0.013763301074504852
    },
    {
      "classification_loss": 0.6195160150527954,
      "epoch": 3.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13818565011024475,
      "orthogonal_weight": 0.1,
      "step": 1170,
      "total_loss": 0.6333345770835876,
      "weighted_orthogonal_loss": 0.01381856482475996
    },
    {
      "classification_loss": 0.6794761419296265,
      "epoch": 3.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388096809387207,
      "orthogonal_weight": 0.1,
      "step": 1171,
      "total_loss": 0.6933571100234985,
      "weighted_orthogonal_loss": 0.01388096809387207
    },
    {
      "classification_loss": 0.6557620763778687,
      "epoch": 3.8426229508196723,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13945572078227997,
      "orthogonal_weight": 0.1,
      "step": 1172,
      "total_loss": 0.6697076559066772,
      "weighted_orthogonal_loss": 0.013945572078227997
    },
    {
      "classification_loss": 0.6691179871559143,
      "epoch": 3.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14021828770637512,
      "orthogonal_weight": 0.1,
      "step": 1173,
      "total_loss": 0.6831398010253906,
      "weighted_orthogonal_loss": 0.014021828770637512
    },
    {
      "classification_loss": 0.643416702747345,
      "epoch": 3.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14081786572933197,
      "orthogonal_weight": 0.1,
      "step": 1174,
      "total_loss": 0.6574984788894653,
      "weighted_orthogonal_loss": 0.014081786386668682
    },
    {
      "classification_loss": 0.6381855607032776,
      "epoch": 3.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1413557231426239,
      "orthogonal_weight": 0.1,
      "step": 1175,
      "total_loss": 0.6523211598396301,
      "weighted_orthogonal_loss": 0.014135572127997875
    },
    {
      "classification_loss": 0.6832534670829773,
      "epoch": 3.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14188320934772491,
      "orthogonal_weight": 0.1,
      "step": 1176,
      "total_loss": 0.697441816329956,
      "weighted_orthogonal_loss": 0.014188321307301521
    },
    {
      "classification_loss": 0.6793800592422485,
      "epoch": 3.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14234744012355804,
      "orthogonal_weight": 0.1,
      "step": 1177,
      "total_loss": 0.6936147809028625,
      "weighted_orthogonal_loss": 0.014234744012355804
    },
    {
      "classification_loss": 0.6708959341049194,
      "epoch": 3.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1427045613527298,
      "orthogonal_weight": 0.1,
      "step": 1178,
      "total_loss": 0.6851664185523987,
      "weighted_orthogonal_loss": 0.01427045650780201
    },
    {
      "classification_loss": 0.6557443737983704,
      "epoch": 3.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1429564356803894,
      "orthogonal_weight": 0.1,
      "step": 1179,
      "total_loss": 0.6700400114059448,
      "weighted_orthogonal_loss": 0.014295644126832485
    },
    {
      "classification_loss": 0.6602676510810852,
      "epoch": 3.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14312979578971863,
      "orthogonal_weight": 0.1,
      "step": 1180,
      "total_loss": 0.6745806336402893,
      "weighted_orthogonal_loss": 0.014312979765236378
    },
    {
      "classification_loss": 0.6912751793861389,
      "epoch": 3.8721311475409834,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14321592450141907,
      "orthogonal_weight": 0.1,
      "step": 1181,
      "total_loss": 0.7055967450141907,
      "weighted_orthogonal_loss": 0.014321592636406422
    },
    {
      "classification_loss": 0.6797897815704346,
      "epoch": 3.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14326177537441254,
      "orthogonal_weight": 0.1,
      "step": 1182,
      "total_loss": 0.694115936756134,
      "weighted_orthogonal_loss": 0.014326177537441254
    },
    {
      "classification_loss": 0.696867823600769,
      "epoch": 3.8786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14333269000053406,
      "orthogonal_weight": 0.1,
      "step": 1183,
      "total_loss": 0.7112010717391968,
      "weighted_orthogonal_loss": 0.01433326955884695
    },
    {
      "classification_loss": 0.6462583541870117,
      "epoch": 3.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14342178404331207,
      "orthogonal_weight": 0.1,
      "step": 1184,
      "total_loss": 0.6606005430221558,
      "weighted_orthogonal_loss": 0.014342178590595722
    },
    {
      "classification_loss": 0.6421692967414856,
      "epoch": 3.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14323391020298004,
      "orthogonal_weight": 0.1,
      "step": 1185,
      "total_loss": 0.6564927101135254,
      "weighted_orthogonal_loss": 0.014323391020298004
    },
    {
      "classification_loss": 0.6656418442726135,
      "epoch": 3.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14308853447437286,
      "orthogonal_weight": 0.1,
      "step": 1186,
      "total_loss": 0.6799507141113281,
      "weighted_orthogonal_loss": 0.014308854006230831
    },
    {
      "classification_loss": 0.7137123942375183,
      "epoch": 3.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1430402249097824,
      "orthogonal_weight": 0.1,
      "step": 1187,
      "total_loss": 0.7280164361000061,
      "weighted_orthogonal_loss": 0.014304022304713726
    },
    {
      "classification_loss": 0.6863676309585571,
      "epoch": 3.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1431010514497757,
      "orthogonal_weight": 0.1,
      "step": 1188,
      "total_loss": 0.700677752494812,
      "weighted_orthogonal_loss": 0.014310105703771114
    },
    {
      "classification_loss": 0.6358268857002258,
      "epoch": 3.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14316299557685852,
      "orthogonal_weight": 0.1,
      "step": 1189,
      "total_loss": 0.6501432061195374,
      "weighted_orthogonal_loss": 0.014316299930214882
    },
    {
      "classification_loss": 0.6349239945411682,
      "epoch": 3.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14332760870456696,
      "orthogonal_weight": 0.1,
      "step": 1190,
      "total_loss": 0.6492567658424377,
      "weighted_orthogonal_loss": 0.01433276105672121
    },
    {
      "classification_loss": 0.661159873008728,
      "epoch": 3.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14347046613693237,
      "orthogonal_weight": 0.1,
      "step": 1191,
      "total_loss": 0.6755069494247437,
      "weighted_orthogonal_loss": 0.014347046613693237
    },
    {
      "classification_loss": 0.6388386487960815,
      "epoch": 3.9081967213114757,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14363664388656616,
      "orthogonal_weight": 0.1,
      "step": 1192,
      "total_loss": 0.6532022953033447,
      "weighted_orthogonal_loss": 0.014363664202392101
    },
    {
      "classification_loss": 0.6526786088943481,
      "epoch": 3.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14376747608184814,
      "orthogonal_weight": 0.1,
      "step": 1193,
      "total_loss": 0.6670553684234619,
      "weighted_orthogonal_loss": 0.0143767474219203
    },
    {
      "classification_loss": 0.6432422399520874,
      "epoch": 3.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14383944869041443,
      "orthogonal_weight": 0.1,
      "step": 1194,
      "total_loss": 0.657626211643219,
      "weighted_orthogonal_loss": 0.014383944682776928
    },
    {
      "classification_loss": 0.620512843132019,
      "epoch": 3.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14393053948879242,
      "orthogonal_weight": 0.1,
      "step": 1195,
      "total_loss": 0.6349058747291565,
      "weighted_orthogonal_loss": 0.014393053948879242
    },
    {
      "classification_loss": 0.6214340925216675,
      "epoch": 3.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1439485102891922,
      "orthogonal_weight": 0.1,
      "step": 1196,
      "total_loss": 0.635828971862793,
      "weighted_orthogonal_loss": 0.01439485140144825
    },
    {
      "classification_loss": 0.6851385831832886,
      "epoch": 3.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14387039840221405,
      "orthogonal_weight": 0.1,
      "step": 1197,
      "total_loss": 0.6995255947113037,
      "weighted_orthogonal_loss": 0.01438704039901495
    },
    {
      "classification_loss": 0.6931920647621155,
      "epoch": 3.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14371395111083984,
      "orthogonal_weight": 0.1,
      "step": 1198,
      "total_loss": 0.7075634598731995,
      "weighted_orthogonal_loss": 0.014371395111083984
    },
    {
      "classification_loss": 0.6738126873970032,
      "epoch": 3.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14360886812210083,
      "orthogonal_weight": 0.1,
      "step": 1199,
      "total_loss": 0.6881735920906067,
      "weighted_orthogonal_loss": 0.014360886998474598
    },
    {
      "epoch": 3.9344262295081966,
      "grad_norm": 9.023319244384766,
      "learning_rate": 0.00016336666666666666,
      "loss": 0.6737,
      "step": 1200
    },
    {
      "classification_loss": 0.6568059325218201,
      "epoch": 3.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14359577000141144,
      "orthogonal_weight": 0.1,
      "step": 1200,
      "total_loss": 0.6711655259132385,
      "weighted_orthogonal_loss": 0.014359577558934689
    },
    {
      "classification_loss": 0.6197920441627502,
      "epoch": 3.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.143479585647583,
      "orthogonal_weight": 0.1,
      "step": 1201,
      "total_loss": 0.6341400146484375,
      "weighted_orthogonal_loss": 0.014347958378493786
    },
    {
      "classification_loss": 0.6463282704353333,
      "epoch": 3.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14343112707138062,
      "orthogonal_weight": 0.1,
      "step": 1202,
      "total_loss": 0.6606713533401489,
      "weighted_orthogonal_loss": 0.014343112707138062
    },
    {
      "classification_loss": 0.6682015061378479,
      "epoch": 3.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14338889718055725,
      "orthogonal_weight": 0.1,
      "step": 1203,
      "total_loss": 0.6825404167175293,
      "weighted_orthogonal_loss": 0.014338890090584755
    },
    {
      "classification_loss": 0.6624066233634949,
      "epoch": 3.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14332863688468933,
      "orthogonal_weight": 0.1,
      "step": 1204,
      "total_loss": 0.676739513874054,
      "weighted_orthogonal_loss": 0.014332863502204418
    },
    {
      "classification_loss": 0.7047706842422485,
      "epoch": 3.9508196721311473,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14331728219985962,
      "orthogonal_weight": 0.1,
      "step": 1205,
      "total_loss": 0.7191023826599121,
      "weighted_orthogonal_loss": 0.014331728219985962
    },
    {
      "classification_loss": 0.650040864944458,
      "epoch": 3.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14340408146381378,
      "orthogonal_weight": 0.1,
      "step": 1206,
      "total_loss": 0.6643812656402588,
      "weighted_orthogonal_loss": 0.014340408146381378
    },
    {
      "classification_loss": 0.6800167560577393,
      "epoch": 3.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14376865327358246,
      "orthogonal_weight": 0.1,
      "step": 1207,
      "total_loss": 0.6943936347961426,
      "weighted_orthogonal_loss": 0.014376865699887276
    },
    {
      "classification_loss": 0.6714193820953369,
      "epoch": 3.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14416615664958954,
      "orthogonal_weight": 0.1,
      "step": 1208,
      "total_loss": 0.6858360171318054,
      "weighted_orthogonal_loss": 0.014416615478694439
    },
    {
      "classification_loss": 0.6638668775558472,
      "epoch": 3.963934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1445968598127365,
      "orthogonal_weight": 0.1,
      "step": 1209,
      "total_loss": 0.6783265471458435,
      "weighted_orthogonal_loss": 0.014459686353802681
    },
    {
      "classification_loss": 0.6774362325668335,
      "epoch": 3.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.145023912191391,
      "orthogonal_weight": 0.1,
      "step": 1210,
      "total_loss": 0.6919386386871338,
      "weighted_orthogonal_loss": 0.014502391219139099
    },
    {
      "classification_loss": 0.6705294847488403,
      "epoch": 3.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1455083042383194,
      "orthogonal_weight": 0.1,
      "step": 1211,
      "total_loss": 0.6850802898406982,
      "weighted_orthogonal_loss": 0.014550830237567425
    },
    {
      "classification_loss": 0.6215112209320068,
      "epoch": 3.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14592385292053223,
      "orthogonal_weight": 0.1,
      "step": 1212,
      "total_loss": 0.636103630065918,
      "weighted_orthogonal_loss": 0.014592385850846767
    },
    {
      "classification_loss": 0.7313960790634155,
      "epoch": 3.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14625851809978485,
      "orthogonal_weight": 0.1,
      "step": 1213,
      "total_loss": 0.7460219264030457,
      "weighted_orthogonal_loss": 0.014625851996243
    },
    {
      "classification_loss": 0.6844817399978638,
      "epoch": 3.9803278688524593,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1465526670217514,
      "orthogonal_weight": 0.1,
      "step": 1214,
      "total_loss": 0.6991370320320129,
      "weighted_orthogonal_loss": 0.014655266888439655
    },
    {
      "classification_loss": 0.5839546918869019,
      "epoch": 3.9836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14685574173927307,
      "orthogonal_weight": 0.1,
      "step": 1215,
      "total_loss": 0.5986402630805969,
      "weighted_orthogonal_loss": 0.014685573987662792
    },
    {
      "classification_loss": 0.7238724827766418,
      "epoch": 3.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1470704823732376,
      "orthogonal_weight": 0.1,
      "step": 1216,
      "total_loss": 0.738579511642456,
      "weighted_orthogonal_loss": 0.014707048423588276
    },
    {
      "classification_loss": 0.6547387838363647,
      "epoch": 3.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14725153148174286,
      "orthogonal_weight": 0.1,
      "step": 1217,
      "total_loss": 0.6694639325141907,
      "weighted_orthogonal_loss": 0.0147251533344388
    },
    {
      "classification_loss": 0.6478078365325928,
      "epoch": 3.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14736725389957428,
      "orthogonal_weight": 0.1,
      "step": 1218,
      "total_loss": 0.6625445485115051,
      "weighted_orthogonal_loss": 0.014736725948750973
    },
    {
      "classification_loss": 0.6531200408935547,
      "epoch": 3.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14757369458675385,
      "orthogonal_weight": 0.1,
      "step": 1219,
      "total_loss": 0.6678774356842041,
      "weighted_orthogonal_loss": 0.0147573696449399
    },
    {
      "classification_loss": 0.6901799440383911,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7049605250358582,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6988438367843628,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7136244177818298,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6838398575782776,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6986204385757446,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6856641173362732,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7004446983337402,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6917171478271484,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7064977288246155,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6830896735191345,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6978702545166016,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.677711546421051,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6924921274185181,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6995068192481995,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7142874002456665,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.537,
      "eval_f1": 0.6125523012552301,
      "eval_loss": 0.7033432126045227,
      "eval_precision": 0.6398601398601399,
      "eval_recall": 0.5874799357945425,
      "eval_runtime": 6.1244,
      "eval_samples_per_second": 163.281,
      "eval_steps_per_second": 1.306,
      "step": 1220
    },
    {
      "classification_loss": 0.5998678803443909,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6146484613418579,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.5744839310646057,
      "epoch": 4.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14812417328357697,
      "orthogonal_weight": 0.1,
      "step": 1221,
      "total_loss": 0.5892963409423828,
      "weighted_orthogonal_loss": 0.014812417328357697
    },
    {
      "classification_loss": 0.6563880443572998,
      "epoch": 4.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14836406707763672,
      "orthogonal_weight": 0.1,
      "step": 1222,
      "total_loss": 0.6712244749069214,
      "weighted_orthogonal_loss": 0.014836407266557217
    },
    {
      "classification_loss": 0.6887218952178955,
      "epoch": 4.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14849045872688293,
      "orthogonal_weight": 0.1,
      "step": 1223,
      "total_loss": 0.7035709619522095,
      "weighted_orthogonal_loss": 0.014849046245217323
    },
    {
      "classification_loss": 0.6399936676025391,
      "epoch": 4.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14858755469322205,
      "orthogonal_weight": 0.1,
      "step": 1224,
      "total_loss": 0.6548524498939514,
      "weighted_orthogonal_loss": 0.01485875528305769
    },
    {
      "classification_loss": 0.6597457528114319,
      "epoch": 4.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.148751363158226,
      "orthogonal_weight": 0.1,
      "step": 1225,
      "total_loss": 0.6746208667755127,
      "weighted_orthogonal_loss": 0.014875136315822601
    },
    {
      "classification_loss": 0.6436300277709961,
      "epoch": 4.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14880771934986115,
      "orthogonal_weight": 0.1,
      "step": 1226,
      "total_loss": 0.6585108041763306,
      "weighted_orthogonal_loss": 0.0148807717487216
    },
    {
      "classification_loss": 0.6938890814781189,
      "epoch": 4.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14870227873325348,
      "orthogonal_weight": 0.1,
      "step": 1227,
      "total_loss": 0.7087593078613281,
      "weighted_orthogonal_loss": 0.014870228245854378
    },
    {
      "classification_loss": 0.7007462382316589,
      "epoch": 4.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14871327579021454,
      "orthogonal_weight": 0.1,
      "step": 1228,
      "total_loss": 0.7156175374984741,
      "weighted_orthogonal_loss": 0.014871328137814999
    },
    {
      "classification_loss": 0.6771746873855591,
      "epoch": 4.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14873336255550385,
      "orthogonal_weight": 0.1,
      "step": 1229,
      "total_loss": 0.6920480132102966,
      "weighted_orthogonal_loss": 0.01487333606928587
    },
    {
      "classification_loss": 0.6486720442771912,
      "epoch": 4.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14881618320941925,
      "orthogonal_weight": 0.1,
      "step": 1230,
      "total_loss": 0.6635536551475525,
      "weighted_orthogonal_loss": 0.014881618320941925
    },
    {
      "classification_loss": 0.6872904896736145,
      "epoch": 4.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1488446444272995,
      "orthogonal_weight": 0.1,
      "step": 1231,
      "total_loss": 0.702174961566925,
      "weighted_orthogonal_loss": 0.01488446444272995
    },
    {
      "classification_loss": 0.6683569550514221,
      "epoch": 4.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1491578370332718,
      "orthogonal_weight": 0.1,
      "step": 1232,
      "total_loss": 0.6832727193832397,
      "weighted_orthogonal_loss": 0.014915783889591694
    },
    {
      "classification_loss": 0.6014142036437988,
      "epoch": 4.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14954817295074463,
      "orthogonal_weight": 0.1,
      "step": 1233,
      "total_loss": 0.6163690090179443,
      "weighted_orthogonal_loss": 0.014954817481338978
    },
    {
      "classification_loss": 0.6910938620567322,
      "epoch": 4.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499718874692917,
      "orthogonal_weight": 0.1,
      "step": 1234,
      "total_loss": 0.706091046333313,
      "weighted_orthogonal_loss": 0.014997188933193684
    },
    {
      "classification_loss": 0.6739314198493958,
      "epoch": 4.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15036045014858246,
      "orthogonal_weight": 0.1,
      "step": 1235,
      "total_loss": 0.6889674663543701,
      "weighted_orthogonal_loss": 0.01503604557365179
    },
    {
      "classification_loss": 0.6825968623161316,
      "epoch": 4.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15064339339733124,
      "orthogonal_weight": 0.1,
      "step": 1236,
      "total_loss": 0.6976612210273743,
      "weighted_orthogonal_loss": 0.015064339153468609
    },
    {
      "classification_loss": 0.6502292156219482,
      "epoch": 4.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15082746744155884,
      "orthogonal_weight": 0.1,
      "step": 1237,
      "total_loss": 0.6653119325637817,
      "weighted_orthogonal_loss": 0.015082746744155884
    },
    {
      "classification_loss": 0.6951660513877869,
      "epoch": 4.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15098287165164948,
      "orthogonal_weight": 0.1,
      "step": 1238,
      "total_loss": 0.7102643251419067,
      "weighted_orthogonal_loss": 0.015098287723958492
    },
    {
      "classification_loss": 0.6744672060012817,
      "epoch": 4.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15116387605667114,
      "orthogonal_weight": 0.1,
      "step": 1239,
      "total_loss": 0.6895835995674133,
      "weighted_orthogonal_loss": 0.015116387978196144
    },
    {
      "classification_loss": 0.69454425573349,
      "epoch": 4.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15129996836185455,
      "orthogonal_weight": 0.1,
      "step": 1240,
      "total_loss": 0.7096742391586304,
      "weighted_orthogonal_loss": 0.015129997394979
    },
    {
      "classification_loss": 0.6708171963691711,
      "epoch": 4.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15139420330524445,
      "orthogonal_weight": 0.1,
      "step": 1241,
      "total_loss": 0.685956597328186,
      "weighted_orthogonal_loss": 0.01513942051678896
    },
    {
      "classification_loss": 0.6314129829406738,
      "epoch": 4.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15150143206119537,
      "orthogonal_weight": 0.1,
      "step": 1242,
      "total_loss": 0.6465631127357483,
      "weighted_orthogonal_loss": 0.015150143764913082
    },
    {
      "classification_loss": 0.6691681742668152,
      "epoch": 4.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1516183465719223,
      "orthogonal_weight": 0.1,
      "step": 1243,
      "total_loss": 0.6843299865722656,
      "weighted_orthogonal_loss": 0.01516183465719223
    },
    {
      "classification_loss": 0.6510121822357178,
      "epoch": 4.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15167678892612457,
      "orthogonal_weight": 0.1,
      "step": 1244,
      "total_loss": 0.6661798357963562,
      "weighted_orthogonal_loss": 0.015167678706347942
    },
    {
      "classification_loss": 0.6018947958946228,
      "epoch": 4.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1515996754169464,
      "orthogonal_weight": 0.1,
      "step": 1245,
      "total_loss": 0.6170547604560852,
      "weighted_orthogonal_loss": 0.015159967355430126
    },
    {
      "classification_loss": 0.6763842105865479,
      "epoch": 4.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15163086354732513,
      "orthogonal_weight": 0.1,
      "step": 1246,
      "total_loss": 0.6915472745895386,
      "weighted_orthogonal_loss": 0.015163086354732513
    },
    {
      "classification_loss": 0.6242621541023254,
      "epoch": 4.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15158367156982422,
      "orthogonal_weight": 0.1,
      "step": 1247,
      "total_loss": 0.6394205093383789,
      "weighted_orthogonal_loss": 0.015158367343246937
    },
    {
      "classification_loss": 0.6323555707931519,
      "epoch": 4.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15144841372966766,
      "orthogonal_weight": 0.1,
      "step": 1248,
      "total_loss": 0.6475003957748413,
      "weighted_orthogonal_loss": 0.015144841745495796
    },
    {
      "classification_loss": 0.6955482363700867,
      "epoch": 4.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1510457545518875,
      "orthogonal_weight": 0.1,
      "step": 1249,
      "total_loss": 0.7106528282165527,
      "weighted_orthogonal_loss": 0.015104576013982296
    },
    {
      "classification_loss": 0.6417747735977173,
      "epoch": 4.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15075929462909698,
      "orthogonal_weight": 0.1,
      "step": 1250,
      "total_loss": 0.6568506956100464,
      "weighted_orthogonal_loss": 0.015075929462909698
    },
    {
      "classification_loss": 0.7069224715232849,
      "epoch": 4.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15055452287197113,
      "orthogonal_weight": 0.1,
      "step": 1251,
      "total_loss": 0.721977949142456,
      "weighted_orthogonal_loss": 0.015055452473461628
    },
    {
      "classification_loss": 0.7394046783447266,
      "epoch": 4.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15041060745716095,
      "orthogonal_weight": 0.1,
      "step": 1252,
      "total_loss": 0.7544457316398621,
      "weighted_orthogonal_loss": 0.015041060745716095
    },
    {
      "classification_loss": 0.6147974133491516,
      "epoch": 4.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.150356724858284,
      "orthogonal_weight": 0.1,
      "step": 1253,
      "total_loss": 0.6298331022262573,
      "weighted_orthogonal_loss": 0.015035673044621944
    },
    {
      "classification_loss": 0.7141934037208557,
      "epoch": 4.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1503552347421646,
      "orthogonal_weight": 0.1,
      "step": 1254,
      "total_loss": 0.7292289137840271,
      "weighted_orthogonal_loss": 0.015035524033010006
    },
    {
      "classification_loss": 0.6828650236129761,
      "epoch": 4.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15039359033107758,
      "orthogonal_weight": 0.1,
      "step": 1255,
      "total_loss": 0.6979044079780579,
      "weighted_orthogonal_loss": 0.015039359219372272
    },
    {
      "classification_loss": 0.6909834146499634,
      "epoch": 4.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15004296600818634,
      "orthogonal_weight": 0.1,
      "step": 1256,
      "total_loss": 0.7059876918792725,
      "weighted_orthogonal_loss": 0.015004296787083149
    },
    {
      "classification_loss": 0.701716959476471,
      "epoch": 4.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14970572292804718,
      "orthogonal_weight": 0.1,
      "step": 1257,
      "total_loss": 0.7166875600814819,
      "weighted_orthogonal_loss": 0.014970572665333748
    },
    {
      "classification_loss": 0.6459123492240906,
      "epoch": 4.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494712382555008,
      "orthogonal_weight": 0.1,
      "step": 1258,
      "total_loss": 0.6608594655990601,
      "weighted_orthogonal_loss": 0.01494712382555008
    },
    {
      "classification_loss": 0.628384530544281,
      "epoch": 4.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14938963949680328,
      "orthogonal_weight": 0.1,
      "step": 1259,
      "total_loss": 0.6433234810829163,
      "weighted_orthogonal_loss": 0.014938964508473873
    },
    {
      "classification_loss": 0.6845828890800476,
      "epoch": 4.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14944036304950714,
      "orthogonal_weight": 0.1,
      "step": 1260,
      "total_loss": 0.6995269060134888,
      "weighted_orthogonal_loss": 0.014944036491215229
    },
    {
      "classification_loss": 0.6271683573722839,
      "epoch": 4.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14961321651935577,
      "orthogonal_weight": 0.1,
      "step": 1261,
      "total_loss": 0.64212965965271,
      "weighted_orthogonal_loss": 0.014961321838200092
    },
    {
      "classification_loss": 0.7355252504348755,
      "epoch": 4.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15011920034885406,
      "orthogonal_weight": 0.1,
      "step": 1262,
      "total_loss": 0.7505371570587158,
      "weighted_orthogonal_loss": 0.015011920593678951
    },
    {
      "classification_loss": 0.6089141964912415,
      "epoch": 4.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15065829455852509,
      "orthogonal_weight": 0.1,
      "step": 1263,
      "total_loss": 0.6239800453186035,
      "weighted_orthogonal_loss": 0.015065829269587994
    },
    {
      "classification_loss": 0.6953480839729309,
      "epoch": 4.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15127679705619812,
      "orthogonal_weight": 0.1,
      "step": 1264,
      "total_loss": 0.710475742816925,
      "weighted_orthogonal_loss": 0.015127680264413357
    },
    {
      "classification_loss": 0.628812313079834,
      "epoch": 4.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1519385576248169,
      "orthogonal_weight": 0.1,
      "step": 1265,
      "total_loss": 0.6440061926841736,
      "weighted_orthogonal_loss": 0.015193856321275234
    },
    {
      "classification_loss": 0.6963565349578857,
      "epoch": 4.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15260225534439087,
      "orthogonal_weight": 0.1,
      "step": 1266,
      "total_loss": 0.7116167545318604,
      "weighted_orthogonal_loss": 0.015260226093232632
    },
    {
      "classification_loss": 0.6388574838638306,
      "epoch": 4.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15316565334796906,
      "orthogonal_weight": 0.1,
      "step": 1267,
      "total_loss": 0.6541740298271179,
      "weighted_orthogonal_loss": 0.01531656552106142
    },
    {
      "classification_loss": 0.6182760000228882,
      "epoch": 4.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1536547690629959,
      "orthogonal_weight": 0.1,
      "step": 1268,
      "total_loss": 0.6336414813995361,
      "weighted_orthogonal_loss": 0.015365476720035076
    },
    {
      "classification_loss": 0.6476873159408569,
      "epoch": 4.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1541132777929306,
      "orthogonal_weight": 0.1,
      "step": 1269,
      "total_loss": 0.6630986332893372,
      "weighted_orthogonal_loss": 0.015411327593028545
    },
    {
      "classification_loss": 0.6950529217720032,
      "epoch": 4.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15419326722621918,
      "orthogonal_weight": 0.1,
      "step": 1270,
      "total_loss": 0.7104722261428833,
      "weighted_orthogonal_loss": 0.015419326722621918
    },
    {
      "classification_loss": 0.617751955986023,
      "epoch": 4.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15424981713294983,
      "orthogonal_weight": 0.1,
      "step": 1271,
      "total_loss": 0.6331769227981567,
      "weighted_orthogonal_loss": 0.015424981713294983
    },
    {
      "classification_loss": 0.6660133004188538,
      "epoch": 4.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15417590737342834,
      "orthogonal_weight": 0.1,
      "step": 1272,
      "total_loss": 0.6814308762550354,
      "weighted_orthogonal_loss": 0.015417590737342834
    },
    {
      "classification_loss": 0.6784980893135071,
      "epoch": 4.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15402743220329285,
      "orthogonal_weight": 0.1,
      "step": 1273,
      "total_loss": 0.6939008235931396,
      "weighted_orthogonal_loss": 0.015402743592858315
    },
    {
      "classification_loss": 0.6510933637619019,
      "epoch": 4.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1536777764558792,
      "orthogonal_weight": 0.1,
      "step": 1274,
      "total_loss": 0.666461169719696,
      "weighted_orthogonal_loss": 0.015367778018116951
    },
    {
      "classification_loss": 0.6181250810623169,
      "epoch": 4.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15338240563869476,
      "orthogonal_weight": 0.1,
      "step": 1275,
      "total_loss": 0.6334633231163025,
      "weighted_orthogonal_loss": 0.015338241122663021
    },
    {
      "classification_loss": 0.6804776191711426,
      "epoch": 4.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15296997129917145,
      "orthogonal_weight": 0.1,
      "step": 1276,
      "total_loss": 0.6957746148109436,
      "weighted_orthogonal_loss": 0.015296997502446175
    },
    {
      "classification_loss": 0.5984258055686951,
      "epoch": 4.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1522321105003357,
      "orthogonal_weight": 0.1,
      "step": 1277,
      "total_loss": 0.6136490106582642,
      "weighted_orthogonal_loss": 0.015223211608827114
    },
    {
      "classification_loss": 0.699318528175354,
      "epoch": 4.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15162400901317596,
      "orthogonal_weight": 0.1,
      "step": 1278,
      "total_loss": 0.7144809365272522,
      "weighted_orthogonal_loss": 0.015162400901317596
    },
    {
      "classification_loss": 0.6190447807312012,
      "epoch": 4.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15098650753498077,
      "orthogonal_weight": 0.1,
      "step": 1279,
      "total_loss": 0.6341434121131897,
      "weighted_orthogonal_loss": 0.015098650939762592
    },
    {
      "classification_loss": 0.6521959900856018,
      "epoch": 4.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1503978818655014,
      "orthogonal_weight": 0.1,
      "step": 1280,
      "total_loss": 0.667235791683197,
      "weighted_orthogonal_loss": 0.01503978855907917
    },
    {
      "classification_loss": 0.6549248695373535,
      "epoch": 4.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14990217983722687,
      "orthogonal_weight": 0.1,
      "step": 1281,
      "total_loss": 0.6699150800704956,
      "weighted_orthogonal_loss": 0.014990217983722687
    },
    {
      "classification_loss": 0.5899795889854431,
      "epoch": 4.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1496463268995285,
      "orthogonal_weight": 0.1,
      "step": 1282,
      "total_loss": 0.6049442291259766,
      "weighted_orthogonal_loss": 0.01496463268995285
    },
    {
      "classification_loss": 0.6372601389884949,
      "epoch": 4.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494617611169815,
      "orthogonal_weight": 0.1,
      "step": 1283,
      "total_loss": 0.652206301689148,
      "weighted_orthogonal_loss": 0.014946176670491695
    },
    {
      "classification_loss": 0.7110028862953186,
      "epoch": 4.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14926530420780182,
      "orthogonal_weight": 0.1,
      "step": 1284,
      "total_loss": 0.7259294390678406,
      "weighted_orthogonal_loss": 0.014926530420780182
    },
    {
      "classification_loss": 0.6565192341804504,
      "epoch": 4.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14920873939990997,
      "orthogonal_weight": 0.1,
      "step": 1285,
      "total_loss": 0.6714401245117188,
      "weighted_orthogonal_loss": 0.014920874498784542
    },
    {
      "classification_loss": 0.6925484538078308,
      "epoch": 4.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1493033617734909,
      "orthogonal_weight": 0.1,
      "step": 1286,
      "total_loss": 0.7074787616729736,
      "weighted_orthogonal_loss": 0.014930336736142635
    },
    {
      "classification_loss": 0.6742262244224548,
      "epoch": 4.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494809240102768,
      "orthogonal_weight": 0.1,
      "step": 1287,
      "total_loss": 0.6891742944717407,
      "weighted_orthogonal_loss": 0.01494809240102768
    },
    {
      "classification_loss": 0.5960389375686646,
      "epoch": 4.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1497172862291336,
      "orthogonal_weight": 0.1,
      "step": 1288,
      "total_loss": 0.6110106706619263,
      "weighted_orthogonal_loss": 0.014971728436648846
    },
    {
      "classification_loss": 0.6293666362762451,
      "epoch": 4.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499769538640976,
      "orthogonal_weight": 0.1,
      "step": 1289,
      "total_loss": 0.6443643569946289,
      "weighted_orthogonal_loss": 0.014997695572674274
    },
    {
      "classification_loss": 0.6897199153900146,
      "epoch": 4.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.150308758020401,
      "orthogonal_weight": 0.1,
      "step": 1290,
      "total_loss": 0.7047507762908936,
      "weighted_orthogonal_loss": 0.0150308758020401
    },
    {
      "classification_loss": 0.6689807176589966,
      "epoch": 4.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15067143738269806,
      "orthogonal_weight": 0.1,
      "step": 1291,
      "total_loss": 0.6840478777885437,
      "weighted_orthogonal_loss": 0.01506714429706335
    },
    {
      "classification_loss": 0.661568820476532,
      "epoch": 4.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1510459929704666,
      "orthogonal_weight": 0.1,
      "step": 1292,
      "total_loss": 0.676673412322998,
      "weighted_orthogonal_loss": 0.015104599297046661
    },
    {
      "classification_loss": 0.5925696492195129,
      "epoch": 4.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15141704678535461,
      "orthogonal_weight": 0.1,
      "step": 1293,
      "total_loss": 0.6077113747596741,
      "weighted_orthogonal_loss": 0.015141705051064491
    },
    {
      "classification_loss": 0.6074570417404175,
      "epoch": 4.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1519877165555954,
      "orthogonal_weight": 0.1,
      "step": 1294,
      "total_loss": 0.6226558089256287,
      "weighted_orthogonal_loss": 0.015198771841824055
    },
    {
      "classification_loss": 0.6749505400657654,
      "epoch": 4.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15263134241104126,
      "orthogonal_weight": 0.1,
      "step": 1295,
      "total_loss": 0.690213680267334,
      "weighted_orthogonal_loss": 0.015263134613633156
    },
    {
      "classification_loss": 0.6499187350273132,
      "epoch": 4.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15321972966194153,
      "orthogonal_weight": 0.1,
      "step": 1296,
      "total_loss": 0.6652407050132751,
      "weighted_orthogonal_loss": 0.015321972779929638
    },
    {
      "classification_loss": 0.6757082343101501,
      "epoch": 4.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1537681370973587,
      "orthogonal_weight": 0.1,
      "step": 1297,
      "total_loss": 0.6910850405693054,
      "weighted_orthogonal_loss": 0.01537681370973587
    },
    {
      "classification_loss": 0.6590983867645264,
      "epoch": 4.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15427306294441223,
      "orthogonal_weight": 0.1,
      "step": 1298,
      "total_loss": 0.6745256781578064,
      "weighted_orthogonal_loss": 0.015427306294441223
    },
    {
      "classification_loss": 0.669353187084198,
      "epoch": 4.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1547136902809143,
      "orthogonal_weight": 0.1,
      "step": 1299,
      "total_loss": 0.6848245859146118,
      "weighted_orthogonal_loss": 0.01547136902809143
    },
    {
      "epoch": 4.262295081967213,
      "grad_norm": 9.857251167297363,
      "learning_rate": 0.00016003333333333334,
      "loss": 0.6744,
      "step": 1300
    },
    {
      "classification_loss": 0.7176656126976013,
      "epoch": 4.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15501612424850464,
      "orthogonal_weight": 0.1,
      "step": 1300,
      "total_loss": 0.7331672310829163,
      "weighted_orthogonal_loss": 0.015501612797379494
    },
    {
      "classification_loss": 0.6172221302986145,
      "epoch": 4.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15522465109825134,
      "orthogonal_weight": 0.1,
      "step": 1301,
      "total_loss": 0.6327446103096008,
      "weighted_orthogonal_loss": 0.015522465109825134
    },
    {
      "classification_loss": 0.6642361283302307,
      "epoch": 4.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15538029372692108,
      "orthogonal_weight": 0.1,
      "step": 1302,
      "total_loss": 0.6797741651535034,
      "weighted_orthogonal_loss": 0.015538029372692108
    },
    {
      "classification_loss": 0.6805179715156555,
      "epoch": 4.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15544399619102478,
      "orthogonal_weight": 0.1,
      "step": 1303,
      "total_loss": 0.6960623860359192,
      "weighted_orthogonal_loss": 0.015544399619102478
    },
    {
      "classification_loss": 0.6574046015739441,
      "epoch": 4.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555679738521576,
      "orthogonal_weight": 0.1,
      "step": 1304,
      "total_loss": 0.672961413860321,
      "weighted_orthogonal_loss": 0.01555679738521576
    },
    {
      "classification_loss": 0.640835702419281,
      "epoch": 4.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555391401052475,
      "orthogonal_weight": 0.1,
      "step": 1305,
      "total_loss": 0.656389594078064,
      "weighted_orthogonal_loss": 0.01555391401052475
    },
    {
      "classification_loss": 0.6682197451591492,
      "epoch": 4.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15540090203285217,
      "orthogonal_weight": 0.1,
      "step": 1306,
      "total_loss": 0.6837598085403442,
      "weighted_orthogonal_loss": 0.015540090389549732
    },
    {
      "classification_loss": 0.6420177221298218,
      "epoch": 4.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15527980029582977,
      "orthogonal_weight": 0.1,
      "step": 1307,
      "total_loss": 0.6575456857681274,
      "weighted_orthogonal_loss": 0.015527980402112007
    },
    {
      "classification_loss": 0.64291912317276,
      "epoch": 4.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.155020073056221,
      "orthogonal_weight": 0.1,
      "step": 1308,
      "total_loss": 0.6584211587905884,
      "weighted_orthogonal_loss": 0.01550200767815113
    },
    {
      "classification_loss": 0.6178680658340454,
      "epoch": 4.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15493318438529968,
      "orthogonal_weight": 0.1,
      "step": 1309,
      "total_loss": 0.6333613991737366,
      "weighted_orthogonal_loss": 0.015493318438529968
    },
    {
      "classification_loss": 0.6741845607757568,
      "epoch": 4.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15490126609802246,
      "orthogonal_weight": 0.1,
      "step": 1310,
      "total_loss": 0.6896746754646301,
      "weighted_orthogonal_loss": 0.015490126796066761
    },
    {
      "classification_loss": 0.7258294224739075,
      "epoch": 4.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15488074719905853,
      "orthogonal_weight": 0.1,
      "step": 1311,
      "total_loss": 0.7413175106048584,
      "weighted_orthogonal_loss": 0.015488075092434883
    },
    {
      "classification_loss": 0.6443691849708557,
      "epoch": 4.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15500040352344513,
      "orthogonal_weight": 0.1,
      "step": 1312,
      "total_loss": 0.6598692536354065,
      "weighted_orthogonal_loss": 0.015500040724873543
    },
    {
      "classification_loss": 0.632379412651062,
      "epoch": 4.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15519212186336517,
      "orthogonal_weight": 0.1,
      "step": 1313,
      "total_loss": 0.6478986144065857,
      "weighted_orthogonal_loss": 0.015519212000072002
    },
    {
      "classification_loss": 0.6392847895622253,
      "epoch": 4.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15541958808898926,
      "orthogonal_weight": 0.1,
      "step": 1314,
      "total_loss": 0.6548267602920532,
      "weighted_orthogonal_loss": 0.01554195862263441
    },
    {
      "classification_loss": 0.6505799889564514,
      "epoch": 4.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15572042763233185,
      "orthogonal_weight": 0.1,
      "step": 1315,
      "total_loss": 0.6661520600318909,
      "weighted_orthogonal_loss": 0.015572043135762215
    },
    {
      "classification_loss": 0.5772559642791748,
      "epoch": 4.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15574856102466583,
      "orthogonal_weight": 0.1,
      "step": 1316,
      "total_loss": 0.5928308367729187,
      "weighted_orthogonal_loss": 0.015574856661260128
    },
    {
      "classification_loss": 0.6929086446762085,
      "epoch": 4.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1557340919971466,
      "orthogonal_weight": 0.1,
      "step": 1317,
      "total_loss": 0.708482027053833,
      "weighted_orthogonal_loss": 0.015573409385979176
    },
    {
      "classification_loss": 0.6335832476615906,
      "epoch": 4.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15581916272640228,
      "orthogonal_weight": 0.1,
      "step": 1318,
      "total_loss": 0.649165153503418,
      "weighted_orthogonal_loss": 0.015581916086375713
    },
    {
      "classification_loss": 0.686934769153595,
      "epoch": 4.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558832824230194,
      "orthogonal_weight": 0.1,
      "step": 1319,
      "total_loss": 0.7025231122970581,
      "weighted_orthogonal_loss": 0.015588328242301941
    },
    {
      "classification_loss": 0.6962559223175049,
      "epoch": 4.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558980941772461,
      "orthogonal_weight": 0.1,
      "step": 1320,
      "total_loss": 0.7118457555770874,
      "weighted_orthogonal_loss": 0.015589809976518154
    },
    {
      "classification_loss": 0.6666792631149292,
      "epoch": 4.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15588656067848206,
      "orthogonal_weight": 0.1,
      "step": 1321,
      "total_loss": 0.6822679042816162,
      "weighted_orthogonal_loss": 0.015588656067848206
    },
    {
      "classification_loss": 0.5904728770256042,
      "epoch": 4.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15601296722888947,
      "orthogonal_weight": 0.1,
      "step": 1322,
      "total_loss": 0.6060741543769836,
      "weighted_orthogonal_loss": 0.015601296909153461
    },
    {
      "classification_loss": 0.6241541504859924,
      "epoch": 4.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15641352534294128,
      "orthogonal_weight": 0.1,
      "step": 1323,
      "total_loss": 0.6397954821586609,
      "weighted_orthogonal_loss": 0.0156413521617651
    },
    {
      "classification_loss": 0.609052836894989,
      "epoch": 4.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1565762162208557,
      "orthogonal_weight": 0.1,
      "step": 1324,
      "total_loss": 0.6247104406356812,
      "weighted_orthogonal_loss": 0.01565762236714363
    },
    {
      "classification_loss": 0.6450024247169495,
      "epoch": 4.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1570163518190384,
      "orthogonal_weight": 0.1,
      "step": 1325,
      "total_loss": 0.6607040762901306,
      "weighted_orthogonal_loss": 0.01570163480937481
    },
    {
      "classification_loss": 0.6423370838165283,
      "epoch": 4.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1573300063610077,
      "orthogonal_weight": 0.1,
      "step": 1326,
      "total_loss": 0.6580700874328613,
      "weighted_orthogonal_loss": 0.01573300175368786
    },
    {
      "classification_loss": 0.6566990613937378,
      "epoch": 4.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15755172073841095,
      "orthogonal_weight": 0.1,
      "step": 1327,
      "total_loss": 0.6724542379379272,
      "weighted_orthogonal_loss": 0.015755172818899155
    },
    {
      "classification_loss": 0.6302844882011414,
      "epoch": 4.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15783733129501343,
      "orthogonal_weight": 0.1,
      "step": 1328,
      "total_loss": 0.6460682153701782,
      "weighted_orthogonal_loss": 0.015783732756972313
    },
    {
      "classification_loss": 0.664823055267334,
      "epoch": 4.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15817603468894958,
      "orthogonal_weight": 0.1,
      "step": 1329,
      "total_loss": 0.6806406378746033,
      "weighted_orthogonal_loss": 0.01581760309636593
    },
    {
      "classification_loss": 0.647558331489563,
      "epoch": 4.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15828891098499298,
      "orthogonal_weight": 0.1,
      "step": 1330,
      "total_loss": 0.6633872389793396,
      "weighted_orthogonal_loss": 0.015828890725970268
    },
    {
      "classification_loss": 0.6614573001861572,
      "epoch": 4.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15831232070922852,
      "orthogonal_weight": 0.1,
      "step": 1331,
      "total_loss": 0.6772885322570801,
      "weighted_orthogonal_loss": 0.01583123207092285
    },
    {
      "classification_loss": 0.6666790843009949,
      "epoch": 4.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15836839377880096,
      "orthogonal_weight": 0.1,
      "step": 1332,
      "total_loss": 0.6825159192085266,
      "weighted_orthogonal_loss": 0.015836840495467186
    },
    {
      "classification_loss": 0.5865113735198975,
      "epoch": 4.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1584608405828476,
      "orthogonal_weight": 0.1,
      "step": 1333,
      "total_loss": 0.6023574471473694,
      "weighted_orthogonal_loss": 0.01584608480334282
    },
    {
      "classification_loss": 0.6847401857376099,
      "epoch": 4.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15857471525669098,
      "orthogonal_weight": 0.1,
      "step": 1334,
      "total_loss": 0.7005976438522339,
      "weighted_orthogonal_loss": 0.015857471153140068
    },
    {
      "classification_loss": 0.6516042351722717,
      "epoch": 4.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15854449570178986,
      "orthogonal_weight": 0.1,
      "step": 1335,
      "total_loss": 0.667458713054657,
      "weighted_orthogonal_loss": 0.015854449942708015
    },
    {
      "classification_loss": 0.7242960929870605,
      "epoch": 4.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15861184895038605,
      "orthogonal_weight": 0.1,
      "step": 1336,
      "total_loss": 0.7401573061943054,
      "weighted_orthogonal_loss": 0.015861185267567635
    },
    {
      "classification_loss": 0.5812488198280334,
      "epoch": 4.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15877774357795715,
      "orthogonal_weight": 0.1,
      "step": 1337,
      "total_loss": 0.5971266031265259,
      "weighted_orthogonal_loss": 0.015877773985266685
    },
    {
      "classification_loss": 0.7263808846473694,
      "epoch": 4.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15899813175201416,
      "orthogonal_weight": 0.1,
      "step": 1338,
      "total_loss": 0.7422807216644287,
      "weighted_orthogonal_loss": 0.015899812802672386
    },
    {
      "classification_loss": 0.6536728739738464,
      "epoch": 4.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1591382473707199,
      "orthogonal_weight": 0.1,
      "step": 1339,
      "total_loss": 0.669586718082428,
      "weighted_orthogonal_loss": 0.01591382548213005
    },
    {
      "classification_loss": 0.6741515398025513,
      "epoch": 4.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1592869758605957,
      "orthogonal_weight": 0.1,
      "step": 1340,
      "total_loss": 0.6900802254676819,
      "weighted_orthogonal_loss": 0.01592869870364666
    },
    {
      "classification_loss": 0.6532382369041443,
      "epoch": 4.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594415307044983,
      "orthogonal_weight": 0.1,
      "step": 1341,
      "total_loss": 0.6691824197769165,
      "weighted_orthogonal_loss": 0.01594415307044983
    },
    {
      "classification_loss": 0.7189680933952332,
      "epoch": 4.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15960082411766052,
      "orthogonal_weight": 0.1,
      "step": 1342,
      "total_loss": 0.7349281907081604,
      "weighted_orthogonal_loss": 0.015960082411766052
    },
    {
      "classification_loss": 0.6550760865211487,
      "epoch": 4.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15972788631916046,
      "orthogonal_weight": 0.1,
      "step": 1343,
      "total_loss": 0.6710488796234131,
      "weighted_orthogonal_loss": 0.015972789376974106
    },
    {
      "classification_loss": 0.6827874183654785,
      "epoch": 4.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1598009616136551,
      "orthogonal_weight": 0.1,
      "step": 1344,
      "total_loss": 0.6987675428390503,
      "weighted_orthogonal_loss": 0.01598009653389454
    },
    {
      "classification_loss": 0.692090630531311,
      "epoch": 4.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15995624661445618,
      "orthogonal_weight": 0.1,
      "step": 1345,
      "total_loss": 0.7080862522125244,
      "weighted_orthogonal_loss": 0.015995625406503677
    },
    {
      "classification_loss": 0.6388406753540039,
      "epoch": 4.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005674004554749,
      "orthogonal_weight": 0.1,
      "step": 1346,
      "total_loss": 0.6548463702201843,
      "weighted_orthogonal_loss": 0.01600567437708378
    },
    {
      "classification_loss": 0.6915161609649658,
      "epoch": 4.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1604161113500595,
      "orthogonal_weight": 0.1,
      "step": 1347,
      "total_loss": 0.7075577974319458,
      "weighted_orthogonal_loss": 0.01604161225259304
    },
    {
      "classification_loss": 0.6578476428985596,
      "epoch": 4.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16071178019046783,
      "orthogonal_weight": 0.1,
      "step": 1348,
      "total_loss": 0.6739188432693481,
      "weighted_orthogonal_loss": 0.016071178019046783
    },
    {
      "classification_loss": 0.6550754308700562,
      "epoch": 4.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076290607452393,
      "orthogonal_weight": 0.1,
      "step": 1349,
      "total_loss": 0.6711516976356506,
      "weighted_orthogonal_loss": 0.016076290979981422
    },
    {
      "classification_loss": 0.5924491286277771,
      "epoch": 4.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16082051396369934,
      "orthogonal_weight": 0.1,
      "step": 1350,
      "total_loss": 0.6085311770439148,
      "weighted_orthogonal_loss": 0.016082052141427994
    },
    {
      "classification_loss": 0.6456282734870911,
      "epoch": 4.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16095948219299316,
      "orthogonal_weight": 0.1,
      "step": 1351,
      "total_loss": 0.6617242097854614,
      "weighted_orthogonal_loss": 0.016095949336886406
    },
    {
      "classification_loss": 0.6496489644050598,
      "epoch": 4.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16110442578792572,
      "orthogonal_weight": 0.1,
      "step": 1352,
      "total_loss": 0.6657593846321106,
      "weighted_orthogonal_loss": 0.016110442578792572
    },
    {
      "classification_loss": 0.674422562122345,
      "epoch": 4.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1611093282699585,
      "orthogonal_weight": 0.1,
      "step": 1353,
      "total_loss": 0.6905335187911987,
      "weighted_orthogonal_loss": 0.01611093245446682
    },
    {
      "classification_loss": 0.6574134826660156,
      "epoch": 4.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094215214252472,
      "orthogonal_weight": 0.1,
      "step": 1354,
      "total_loss": 0.6735076904296875,
      "weighted_orthogonal_loss": 0.016094215214252472
    },
    {
      "classification_loss": 0.6323578953742981,
      "epoch": 4.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606404334306717,
      "orthogonal_weight": 0.1,
      "step": 1355,
      "total_loss": 0.6484219431877136,
      "weighted_orthogonal_loss": 0.01606404408812523
    },
    {
      "classification_loss": 0.6334190964698792,
      "epoch": 4.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16009262204170227,
      "orthogonal_weight": 0.1,
      "step": 1356,
      "total_loss": 0.6494283676147461,
      "weighted_orthogonal_loss": 0.016009261831641197
    },
    {
      "classification_loss": 0.6198131442070007,
      "epoch": 4.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15969052910804749,
      "orthogonal_weight": 0.1,
      "step": 1357,
      "total_loss": 0.6357821822166443,
      "weighted_orthogonal_loss": 0.01596905291080475
    },
    {
      "classification_loss": 0.5997548699378967,
      "epoch": 4.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594022959470749,
      "orthogonal_weight": 0.1,
      "step": 1358,
      "total_loss": 0.6156951189041138,
      "weighted_orthogonal_loss": 0.01594023033976555
    },
    {
      "classification_loss": 0.5886200070381165,
      "epoch": 4.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15905924141407013,
      "orthogonal_weight": 0.1,
      "step": 1359,
      "total_loss": 0.6045259237289429,
      "weighted_orthogonal_loss": 0.015905924141407013
    },
    {
      "classification_loss": 0.6705406904220581,
      "epoch": 4.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15879598259925842,
      "orthogonal_weight": 0.1,
      "step": 1360,
      "total_loss": 0.6864202618598938,
      "weighted_orthogonal_loss": 0.015879599377512932
    },
    {
      "classification_loss": 0.6077595949172974,
      "epoch": 4.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15858164429664612,
      "orthogonal_weight": 0.1,
      "step": 1361,
      "total_loss": 0.6236177682876587,
      "weighted_orthogonal_loss": 0.015858164057135582
    },
    {
      "classification_loss": 0.636627733707428,
      "epoch": 4.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1584199219942093,
      "orthogonal_weight": 0.1,
      "step": 1362,
      "total_loss": 0.6524697542190552,
      "weighted_orthogonal_loss": 0.01584199257194996
    },
    {
      "classification_loss": 0.6654642224311829,
      "epoch": 4.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15824124217033386,
      "orthogonal_weight": 0.1,
      "step": 1363,
      "total_loss": 0.6812883615493774,
      "weighted_orthogonal_loss": 0.015824124217033386
    },
    {
      "classification_loss": 0.7129784226417542,
      "epoch": 4.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1581178903579712,
      "orthogonal_weight": 0.1,
      "step": 1364,
      "total_loss": 0.7287902235984802,
      "weighted_orthogonal_loss": 0.01581178978085518
    },
    {
      "classification_loss": 0.6561727523803711,
      "epoch": 4.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15797676146030426,
      "orthogonal_weight": 0.1,
      "step": 1365,
      "total_loss": 0.6719704270362854,
      "weighted_orthogonal_loss": 0.015797676518559456
    },
    {
      "classification_loss": 0.699998676776886,
      "epoch": 4.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1579168289899826,
      "orthogonal_weight": 0.1,
      "step": 1366,
      "total_loss": 0.715790331363678,
      "weighted_orthogonal_loss": 0.01579168252646923
    },
    {
      "classification_loss": 0.6373482346534729,
      "epoch": 4.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1578896939754486,
      "orthogonal_weight": 0.1,
      "step": 1367,
      "total_loss": 0.65313720703125,
      "weighted_orthogonal_loss": 0.01578897051513195
    },
    {
      "classification_loss": 0.6269160509109497,
      "epoch": 4.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15788573026657104,
      "orthogonal_weight": 0.1,
      "step": 1368,
      "total_loss": 0.6427046060562134,
      "weighted_orthogonal_loss": 0.015788573771715164
    },
    {
      "classification_loss": 0.683957040309906,
      "epoch": 4.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15791891515254974,
      "orthogonal_weight": 0.1,
      "step": 1369,
      "total_loss": 0.6997489333152771,
      "weighted_orthogonal_loss": 0.015791891142725945
    },
    {
      "classification_loss": 0.6025124788284302,
      "epoch": 4.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15794892609119415,
      "orthogonal_weight": 0.1,
      "step": 1370,
      "total_loss": 0.61830735206604,
      "weighted_orthogonal_loss": 0.015794893726706505
    },
    {
      "classification_loss": 0.6287629008293152,
      "epoch": 4.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15801112353801727,
      "orthogonal_weight": 0.1,
      "step": 1371,
      "total_loss": 0.6445640325546265,
      "weighted_orthogonal_loss": 0.015801113098859787
    },
    {
      "classification_loss": 0.6400355696678162,
      "epoch": 4.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15812402963638306,
      "orthogonal_weight": 0.1,
      "step": 1372,
      "total_loss": 0.65584796667099,
      "weighted_orthogonal_loss": 0.015812402591109276
    },
    {
      "classification_loss": 0.6318203806877136,
      "epoch": 4.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15762412548065186,
      "orthogonal_weight": 0.1,
      "step": 1373,
      "total_loss": 0.6475827693939209,
      "weighted_orthogonal_loss": 0.015762412920594215
    },
    {
      "classification_loss": 0.6169257164001465,
      "epoch": 4.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15706324577331543,
      "orthogonal_weight": 0.1,
      "step": 1374,
      "total_loss": 0.6326320171356201,
      "weighted_orthogonal_loss": 0.015706324949860573
    },
    {
      "classification_loss": 0.7025241851806641,
      "epoch": 4.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15661904215812683,
      "orthogonal_weight": 0.1,
      "step": 1375,
      "total_loss": 0.71818608045578,
      "weighted_orthogonal_loss": 0.015661904588341713
    },
    {
      "classification_loss": 0.6562328934669495,
      "epoch": 4.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15624818205833435,
      "orthogonal_weight": 0.1,
      "step": 1376,
      "total_loss": 0.6718577146530151,
      "weighted_orthogonal_loss": 0.01562481839209795
    },
    {
      "classification_loss": 0.6375946998596191,
      "epoch": 4.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15591634809970856,
      "orthogonal_weight": 0.1,
      "step": 1377,
      "total_loss": 0.6531863212585449,
      "weighted_orthogonal_loss": 0.0155916353687644
    },
    {
      "classification_loss": 0.6258719563484192,
      "epoch": 4.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1556696742773056,
      "orthogonal_weight": 0.1,
      "step": 1378,
      "total_loss": 0.641438901424408,
      "weighted_orthogonal_loss": 0.01556696742773056
    },
    {
      "classification_loss": 0.6302405595779419,
      "epoch": 4.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1553889811038971,
      "orthogonal_weight": 0.1,
      "step": 1379,
      "total_loss": 0.6457794308662415,
      "weighted_orthogonal_loss": 0.015538898296654224
    },
    {
      "classification_loss": 0.605266273021698,
      "epoch": 4.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1552104949951172,
      "orthogonal_weight": 0.1,
      "step": 1380,
      "total_loss": 0.6207873225212097,
      "weighted_orthogonal_loss": 0.015521049499511719
    },
    {
      "classification_loss": 0.6524943113327026,
      "epoch": 4.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15502388775348663,
      "orthogonal_weight": 0.1,
      "step": 1381,
      "total_loss": 0.6679967045783997,
      "weighted_orthogonal_loss": 0.015502388589084148
    },
    {
      "classification_loss": 0.6358174681663513,
      "epoch": 4.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15488122403621674,
      "orthogonal_weight": 0.1,
      "step": 1382,
      "total_loss": 0.651305615901947,
      "weighted_orthogonal_loss": 0.015488122589886189
    },
    {
      "classification_loss": 0.6833968758583069,
      "epoch": 4.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15477095544338226,
      "orthogonal_weight": 0.1,
      "step": 1383,
      "total_loss": 0.6988739967346191,
      "weighted_orthogonal_loss": 0.015477095730602741
    },
    {
      "classification_loss": 0.6687356233596802,
      "epoch": 4.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15462620556354523,
      "orthogonal_weight": 0.1,
      "step": 1384,
      "total_loss": 0.684198260307312,
      "weighted_orthogonal_loss": 0.015462621115148067
    },
    {
      "classification_loss": 0.692470371723175,
      "epoch": 4.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15453515946865082,
      "orthogonal_weight": 0.1,
      "step": 1385,
      "total_loss": 0.7079238891601562,
      "weighted_orthogonal_loss": 0.015453516505658627
    },
    {
      "classification_loss": 0.682770848274231,
      "epoch": 4.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15448904037475586,
      "orthogonal_weight": 0.1,
      "step": 1386,
      "total_loss": 0.6982197761535645,
      "weighted_orthogonal_loss": 0.01544890459626913
    },
    {
      "classification_loss": 0.6588405966758728,
      "epoch": 4.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15443308651447296,
      "orthogonal_weight": 0.1,
      "step": 1387,
      "total_loss": 0.6742839217185974,
      "weighted_orthogonal_loss": 0.015443309210240841
    },
    {
      "classification_loss": 0.7043523788452148,
      "epoch": 4.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15452887117862701,
      "orthogonal_weight": 0.1,
      "step": 1388,
      "total_loss": 0.7198052406311035,
      "weighted_orthogonal_loss": 0.015452886931598186
    },
    {
      "classification_loss": 0.6981882452964783,
      "epoch": 4.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15460903942584991,
      "orthogonal_weight": 0.1,
      "step": 1389,
      "total_loss": 0.7136491537094116,
      "weighted_orthogonal_loss": 0.015460903756320477
    },
    {
      "classification_loss": 0.6107158660888672,
      "epoch": 4.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15473736822605133,
      "orthogonal_weight": 0.1,
      "step": 1390,
      "total_loss": 0.6261895895004272,
      "weighted_orthogonal_loss": 0.015473737381398678
    },
    {
      "classification_loss": 0.6415083408355713,
      "epoch": 4.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484337508678436,
      "orthogonal_weight": 0.1,
      "step": 1391,
      "total_loss": 0.6569926738739014,
      "weighted_orthogonal_loss": 0.015484337694942951
    },
    {
      "classification_loss": 0.6880971193313599,
      "epoch": 4.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484167635440826,
      "orthogonal_weight": 0.1,
      "step": 1392,
      "total_loss": 0.7035812735557556,
      "weighted_orthogonal_loss": 0.015484168194234371
    },
    {
      "classification_loss": 0.6272070407867432,
      "epoch": 4.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15471485257148743,
      "orthogonal_weight": 0.1,
      "step": 1393,
      "total_loss": 0.6426784992218018,
      "weighted_orthogonal_loss": 0.015471485443413258
    },
    {
      "classification_loss": 0.6958292126655579,
      "epoch": 4.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15467463433742523,
      "orthogonal_weight": 0.1,
      "step": 1394,
      "total_loss": 0.7112966775894165,
      "weighted_orthogonal_loss": 0.015467463992536068
    },
    {
      "classification_loss": 0.7146279811859131,
      "epoch": 4.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1546410620212555,
      "orthogonal_weight": 0.1,
      "step": 1395,
      "total_loss": 0.7300921082496643,
      "weighted_orthogonal_loss": 0.01546410657465458
    },
    {
      "classification_loss": 0.6874127388000488,
      "epoch": 4.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15467870235443115,
      "orthogonal_weight": 0.1,
      "step": 1396,
      "total_loss": 0.7028806209564209,
      "weighted_orthogonal_loss": 0.0154678700491786
    },
    {
      "classification_loss": 0.6166510581970215,
      "epoch": 4.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1546775847673416,
      "orthogonal_weight": 0.1,
      "step": 1397,
      "total_loss": 0.632118821144104,
      "weighted_orthogonal_loss": 0.015467758290469646
    },
    {
      "classification_loss": 0.6611372828483582,
      "epoch": 4.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15473084151744843,
      "orthogonal_weight": 0.1,
      "step": 1398,
      "total_loss": 0.6766103506088257,
      "weighted_orthogonal_loss": 0.015473084524273872
    },
    {
      "classification_loss": 0.7127747535705566,
      "epoch": 4.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1548168957233429,
      "orthogonal_weight": 0.1,
      "step": 1399,
      "total_loss": 0.7282564640045166,
      "weighted_orthogonal_loss": 0.01548168994486332
    },
    {
      "epoch": 4.590163934426229,
      "grad_norm": 11.888660430908203,
      "learning_rate": 0.00015670000000000001,
      "loss": 0.6701,
      "step": 1400
    },
    {
      "classification_loss": 0.6121160984039307,
      "epoch": 4.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484189987182617,
      "orthogonal_weight": 0.1,
      "step": 1400,
      "total_loss": 0.6276003122329712,
      "weighted_orthogonal_loss": 0.015484190545976162
    },
    {
      "classification_loss": 0.6223638653755188,
      "epoch": 4.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.154870867729187,
      "orthogonal_weight": 0.1,
      "step": 1401,
      "total_loss": 0.6378509402275085,
      "weighted_orthogonal_loss": 0.015487086959183216
    },
    {
      "classification_loss": 0.6133044362068176,
      "epoch": 4.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15494726598262787,
      "orthogonal_weight": 0.1,
      "step": 1402,
      "total_loss": 0.6287991404533386,
      "weighted_orthogonal_loss": 0.015494726598262787
    },
    {
      "classification_loss": 0.6712417006492615,
      "epoch": 4.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1550394743680954,
      "orthogonal_weight": 0.1,
      "step": 1403,
      "total_loss": 0.6867456436157227,
      "weighted_orthogonal_loss": 0.015503947623074055
    },
    {
      "classification_loss": 0.6961161494255066,
      "epoch": 4.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15509440004825592,
      "orthogonal_weight": 0.1,
      "step": 1404,
      "total_loss": 0.7116255760192871,
      "weighted_orthogonal_loss": 0.015509440563619137
    },
    {
      "classification_loss": 0.7444257736206055,
      "epoch": 4.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15507705509662628,
      "orthogonal_weight": 0.1,
      "step": 1405,
      "total_loss": 0.7599334716796875,
      "weighted_orthogonal_loss": 0.015507705509662628
    },
    {
      "classification_loss": 0.6625195145606995,
      "epoch": 4.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15504272282123566,
      "orthogonal_weight": 0.1,
      "step": 1406,
      "total_loss": 0.6780238151550293,
      "weighted_orthogonal_loss": 0.015504272654652596
    },
    {
      "classification_loss": 0.7175401449203491,
      "epoch": 4.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15498954057693481,
      "orthogonal_weight": 0.1,
      "step": 1407,
      "total_loss": 0.7330390810966492,
      "weighted_orthogonal_loss": 0.015498953871428967
    },
    {
      "classification_loss": 0.5995871424674988,
      "epoch": 4.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1549326628446579,
      "orthogonal_weight": 0.1,
      "step": 1408,
      "total_loss": 0.6150804162025452,
      "weighted_orthogonal_loss": 0.01549326628446579
    },
    {
      "classification_loss": 0.6674622297286987,
      "epoch": 4.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15481188893318176,
      "orthogonal_weight": 0.1,
      "step": 1409,
      "total_loss": 0.6829434037208557,
      "weighted_orthogonal_loss": 0.015481188893318176
    },
    {
      "classification_loss": 0.5947529673576355,
      "epoch": 4.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15465764701366425,
      "orthogonal_weight": 0.1,
      "step": 1410,
      "total_loss": 0.6102187037467957,
      "weighted_orthogonal_loss": 0.01546576526015997
    },
    {
      "classification_loss": 0.7004451155662537,
      "epoch": 4.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15475846827030182,
      "orthogonal_weight": 0.1,
      "step": 1411,
      "total_loss": 0.7159209847450256,
      "weighted_orthogonal_loss": 0.015475846827030182
    },
    {
      "classification_loss": 0.6710326671600342,
      "epoch": 4.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15498656034469604,
      "orthogonal_weight": 0.1,
      "step": 1412,
      "total_loss": 0.6865313053131104,
      "weighted_orthogonal_loss": 0.01549865584820509
    },
    {
      "classification_loss": 0.6975085735321045,
      "epoch": 4.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1550527811050415,
      "orthogonal_weight": 0.1,
      "step": 1413,
      "total_loss": 0.7130138278007507,
      "weighted_orthogonal_loss": 0.01550527848303318
    },
    {
      "classification_loss": 0.6288013458251953,
      "epoch": 4.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15509070456027985,
      "orthogonal_weight": 0.1,
      "step": 1414,
      "total_loss": 0.6443104147911072,
      "weighted_orthogonal_loss": 0.015509070828557014
    },
    {
      "classification_loss": 0.7221802473068237,
      "epoch": 4.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1551409661769867,
      "orthogonal_weight": 0.1,
      "step": 1415,
      "total_loss": 0.7376943230628967,
      "weighted_orthogonal_loss": 0.015514097176492214
    },
    {
      "classification_loss": 0.5888633728027344,
      "epoch": 4.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1551973521709442,
      "orthogonal_weight": 0.1,
      "step": 1416,
      "total_loss": 0.604383111000061,
      "weighted_orthogonal_loss": 0.015519735403358936
    },
    {
      "classification_loss": 0.6676875948905945,
      "epoch": 4.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15525034070014954,
      "orthogonal_weight": 0.1,
      "step": 1417,
      "total_loss": 0.6832126379013062,
      "weighted_orthogonal_loss": 0.015525034628808498
    },
    {
      "classification_loss": 0.6483368873596191,
      "epoch": 4.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1553320437669754,
      "orthogonal_weight": 0.1,
      "step": 1418,
      "total_loss": 0.663870096206665,
      "weighted_orthogonal_loss": 0.015533204190433025
    },
    {
      "classification_loss": 0.6685481667518616,
      "epoch": 4.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15545141696929932,
      "orthogonal_weight": 0.1,
      "step": 1419,
      "total_loss": 0.6840932965278625,
      "weighted_orthogonal_loss": 0.015545141883194447
    },
    {
      "classification_loss": 0.6344210505485535,
      "epoch": 4.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15552054345607758,
      "orthogonal_weight": 0.1,
      "step": 1420,
      "total_loss": 0.6499730944633484,
      "weighted_orthogonal_loss": 0.015552054159343243
    },
    {
      "classification_loss": 0.61649090051651,
      "epoch": 4.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15564846992492676,
      "orthogonal_weight": 0.1,
      "step": 1421,
      "total_loss": 0.6320557594299316,
      "weighted_orthogonal_loss": 0.01556484680622816
    },
    {
      "classification_loss": 0.6755267977714539,
      "epoch": 4.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15568991005420685,
      "orthogonal_weight": 0.1,
      "step": 1422,
      "total_loss": 0.691095769405365,
      "weighted_orthogonal_loss": 0.0155689911916852
    },
    {
      "classification_loss": 0.5978356599807739,
      "epoch": 4.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15579438209533691,
      "orthogonal_weight": 0.1,
      "step": 1423,
      "total_loss": 0.6134151220321655,
      "weighted_orthogonal_loss": 0.015579438768327236
    },
    {
      "classification_loss": 0.6638016700744629,
      "epoch": 4.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15569859743118286,
      "orthogonal_weight": 0.1,
      "step": 1424,
      "total_loss": 0.6793715357780457,
      "weighted_orthogonal_loss": 0.015569860115647316
    },
    {
      "classification_loss": 0.6431722044944763,
      "epoch": 4.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15566609799861908,
      "orthogonal_weight": 0.1,
      "step": 1425,
      "total_loss": 0.6587387919425964,
      "weighted_orthogonal_loss": 0.015566609799861908
    },
    {
      "classification_loss": 0.6626684665679932,
      "epoch": 4.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15554609894752502,
      "orthogonal_weight": 0.1,
      "step": 1426,
      "total_loss": 0.6782230734825134,
      "weighted_orthogonal_loss": 0.015554609708487988
    },
    {
      "classification_loss": 0.6343839764595032,
      "epoch": 4.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15542879700660706,
      "orthogonal_weight": 0.1,
      "step": 1427,
      "total_loss": 0.6499268412590027,
      "weighted_orthogonal_loss": 0.015542879700660706
    },
    {
      "classification_loss": 0.6781035661697388,
      "epoch": 4.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555076241493225,
      "orthogonal_weight": 0.1,
      "step": 1428,
      "total_loss": 0.6936542987823486,
      "weighted_orthogonal_loss": 0.015550762414932251
    },
    {
      "classification_loss": 0.6452721953392029,
      "epoch": 4.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15559905767440796,
      "orthogonal_weight": 0.1,
      "step": 1429,
      "total_loss": 0.6608321070671082,
      "weighted_orthogonal_loss": 0.015559906139969826
    },
    {
      "classification_loss": 0.6511845588684082,
      "epoch": 4.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1556841880083084,
      "orthogonal_weight": 0.1,
      "step": 1430,
      "total_loss": 0.6667529940605164,
      "weighted_orthogonal_loss": 0.015568419359624386
    },
    {
      "classification_loss": 0.7071987986564636,
      "epoch": 4.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15579883754253387,
      "orthogonal_weight": 0.1,
      "step": 1431,
      "total_loss": 0.7227786779403687,
      "weighted_orthogonal_loss": 0.015579883940517902
    },
    {
      "classification_loss": 0.6194230318069458,
      "epoch": 4.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15591676533222198,
      "orthogonal_weight": 0.1,
      "step": 1432,
      "total_loss": 0.6350147128105164,
      "weighted_orthogonal_loss": 0.015591676346957684
    },
    {
      "classification_loss": 0.645447313785553,
      "epoch": 4.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15600650012493134,
      "orthogonal_weight": 0.1,
      "step": 1433,
      "total_loss": 0.6610479354858398,
      "weighted_orthogonal_loss": 0.015600650571286678
    },
    {
      "classification_loss": 0.6618567705154419,
      "epoch": 4.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1560433954000473,
      "orthogonal_weight": 0.1,
      "step": 1434,
      "total_loss": 0.6774610877037048,
      "weighted_orthogonal_loss": 0.01560433954000473
    },
    {
      "classification_loss": 0.6039794683456421,
      "epoch": 4.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1559796780347824,
      "orthogonal_weight": 0.1,
      "step": 1435,
      "total_loss": 0.6195774078369141,
      "weighted_orthogonal_loss": 0.015597968362271786
    },
    {
      "classification_loss": 0.6481812000274658,
      "epoch": 4.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15595155954360962,
      "orthogonal_weight": 0.1,
      "step": 1436,
      "total_loss": 0.6637763381004333,
      "weighted_orthogonal_loss": 0.015595155768096447
    },
    {
      "classification_loss": 0.6498655080795288,
      "epoch": 4.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558162122964859,
      "orthogonal_weight": 0.1,
      "step": 1437,
      "total_loss": 0.6654471158981323,
      "weighted_orthogonal_loss": 0.015581621788442135
    },
    {
      "classification_loss": 0.5744182467460632,
      "epoch": 4.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15568359196186066,
      "orthogonal_weight": 0.1,
      "step": 1438,
      "total_loss": 0.5899866223335266,
      "weighted_orthogonal_loss": 0.01556835975497961
    },
    {
      "classification_loss": 0.6474694609642029,
      "epoch": 4.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15571151673793793,
      "orthogonal_weight": 0.1,
      "step": 1439,
      "total_loss": 0.6630406379699707,
      "weighted_orthogonal_loss": 0.015571151860058308
    },
    {
      "classification_loss": 0.6430646777153015,
      "epoch": 4.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15581867098808289,
      "orthogonal_weight": 0.1,
      "step": 1440,
      "total_loss": 0.6586465239524841,
      "weighted_orthogonal_loss": 0.015581867657601833
    },
    {
      "classification_loss": 0.6239941120147705,
      "epoch": 4.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15607869625091553,
      "orthogonal_weight": 0.1,
      "step": 1441,
      "total_loss": 0.63960200548172,
      "weighted_orthogonal_loss": 0.015607870183885098
    },
    {
      "classification_loss": 0.6321794986724854,
      "epoch": 4.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15634950995445251,
      "orthogonal_weight": 0.1,
      "step": 1442,
      "total_loss": 0.6478144526481628,
      "weighted_orthogonal_loss": 0.01563495211303234
    },
    {
      "classification_loss": 0.6579461097717285,
      "epoch": 4.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1567116528749466,
      "orthogonal_weight": 0.1,
      "step": 1443,
      "total_loss": 0.6736173033714294,
      "weighted_orthogonal_loss": 0.01567116566002369
    },
    {
      "classification_loss": 0.7166414856910706,
      "epoch": 4.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15685804188251495,
      "orthogonal_weight": 0.1,
      "step": 1444,
      "total_loss": 0.7323272824287415,
      "weighted_orthogonal_loss": 0.015685804188251495
    },
    {
      "classification_loss": 0.7089932560920715,
      "epoch": 4.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1570115089416504,
      "orthogonal_weight": 0.1,
      "step": 1445,
      "total_loss": 0.7246944308280945,
      "weighted_orthogonal_loss": 0.01570115052163601
    },
    {
      "classification_loss": 0.6239246129989624,
      "epoch": 4.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15720611810684204,
      "orthogonal_weight": 0.1,
      "step": 1446,
      "total_loss": 0.6396452188491821,
      "weighted_orthogonal_loss": 0.015720611438155174
    },
    {
      "classification_loss": 0.6371151208877563,
      "epoch": 4.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15735004842281342,
      "orthogonal_weight": 0.1,
      "step": 1447,
      "total_loss": 0.6528501510620117,
      "weighted_orthogonal_loss": 0.01573500595986843
    },
    {
      "classification_loss": 0.618298351764679,
      "epoch": 4.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1575428694486618,
      "orthogonal_weight": 0.1,
      "step": 1448,
      "total_loss": 0.6340526342391968,
      "weighted_orthogonal_loss": 0.01575428806245327
    },
    {
      "classification_loss": 0.6687033176422119,
      "epoch": 4.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15775783360004425,
      "orthogonal_weight": 0.1,
      "step": 1449,
      "total_loss": 0.6844791173934937,
      "weighted_orthogonal_loss": 0.015775782987475395
    },
    {
      "classification_loss": 0.6222862005233765,
      "epoch": 4.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15794257819652557,
      "orthogonal_weight": 0.1,
      "step": 1450,
      "total_loss": 0.6380804777145386,
      "weighted_orthogonal_loss": 0.015794258564710617
    },
    {
      "classification_loss": 0.5690356492996216,
      "epoch": 4.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1582002341747284,
      "orthogonal_weight": 0.1,
      "step": 1451,
      "total_loss": 0.5848556756973267,
      "weighted_orthogonal_loss": 0.01582002453505993
    },
    {
      "classification_loss": 0.5923902988433838,
      "epoch": 4.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15851055085659027,
      "orthogonal_weight": 0.1,
      "step": 1452,
      "total_loss": 0.6082413792610168,
      "weighted_orthogonal_loss": 0.015851056203246117
    },
    {
      "classification_loss": 0.6758062839508057,
      "epoch": 4.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15889589488506317,
      "orthogonal_weight": 0.1,
      "step": 1453,
      "total_loss": 0.6916958689689636,
      "weighted_orthogonal_loss": 0.015889590606093407
    },
    {
      "classification_loss": 0.6292574405670166,
      "epoch": 4.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15918602049350739,
      "orthogonal_weight": 0.1,
      "step": 1454,
      "total_loss": 0.6451760530471802,
      "weighted_orthogonal_loss": 0.015918603166937828
    },
    {
      "classification_loss": 0.7031468152999878,
      "epoch": 4.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15940983593463898,
      "orthogonal_weight": 0.1,
      "step": 1455,
      "total_loss": 0.7190877795219421,
      "weighted_orthogonal_loss": 0.015940984711050987
    },
    {
      "classification_loss": 0.6762414574623108,
      "epoch": 4.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15985970199108124,
      "orthogonal_weight": 0.1,
      "step": 1456,
      "total_loss": 0.6922274231910706,
      "weighted_orthogonal_loss": 0.015985971316695213
    },
    {
      "classification_loss": 0.5659582614898682,
      "epoch": 4.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005976498126984,
      "orthogonal_weight": 0.1,
      "step": 1457,
      "total_loss": 0.5819642543792725,
      "weighted_orthogonal_loss": 0.016005976125597954
    },
    {
      "classification_loss": 0.6961497068405151,
      "epoch": 4.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16029949486255646,
      "orthogonal_weight": 0.1,
      "step": 1458,
      "total_loss": 0.7121796607971191,
      "weighted_orthogonal_loss": 0.016029950231313705
    },
    {
      "classification_loss": 0.657265841960907,
      "epoch": 4.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16048520803451538,
      "orthogonal_weight": 0.1,
      "step": 1459,
      "total_loss": 0.6733143329620361,
      "weighted_orthogonal_loss": 0.016048520803451538
    },
    {
      "classification_loss": 0.6198829412460327,
      "epoch": 4.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16039785742759705,
      "orthogonal_weight": 0.1,
      "step": 1460,
      "total_loss": 0.6359227299690247,
      "weighted_orthogonal_loss": 0.016039786860346794
    },
    {
      "classification_loss": 0.6550878882408142,
      "epoch": 4.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16039608418941498,
      "orthogonal_weight": 0.1,
      "step": 1461,
      "total_loss": 0.6711274981498718,
      "weighted_orthogonal_loss": 0.016039608046412468
    },
    {
      "classification_loss": 0.660058856010437,
      "epoch": 4.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16037581861019135,
      "orthogonal_weight": 0.1,
      "step": 1462,
      "total_loss": 0.6760964393615723,
      "weighted_orthogonal_loss": 0.016037581488490105
    },
    {
      "classification_loss": 0.6396600008010864,
      "epoch": 4.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16044525802135468,
      "orthogonal_weight": 0.1,
      "step": 1463,
      "total_loss": 0.6557044982910156,
      "weighted_orthogonal_loss": 0.016044525429606438
    },
    {
      "classification_loss": 0.6517943739891052,
      "epoch": 4.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16056998074054718,
      "orthogonal_weight": 0.1,
      "step": 1464,
      "total_loss": 0.6678513884544373,
      "weighted_orthogonal_loss": 0.016056997701525688
    },
    {
      "classification_loss": 0.7245147824287415,
      "epoch": 4.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606999784708023,
      "orthogonal_weight": 0.1,
      "step": 1465,
      "total_loss": 0.7405847907066345,
      "weighted_orthogonal_loss": 0.01606999896466732
    },
    {
      "classification_loss": 0.6738188862800598,
      "epoch": 4.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16084147989749908,
      "orthogonal_weight": 0.1,
      "step": 1466,
      "total_loss": 0.6899030208587646,
      "weighted_orthogonal_loss": 0.01608414761722088
    },
    {
      "classification_loss": 0.6414238810539246,
      "epoch": 4.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1609189659357071,
      "orthogonal_weight": 0.1,
      "step": 1467,
      "total_loss": 0.6575157642364502,
      "weighted_orthogonal_loss": 0.01609189622104168
    },
    {
      "classification_loss": 0.6595363020896912,
      "epoch": 4.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16092757880687714,
      "orthogonal_weight": 0.1,
      "step": 1468,
      "total_loss": 0.6756290793418884,
      "weighted_orthogonal_loss": 0.016092758625745773
    },
    {
      "classification_loss": 0.6911564469337463,
      "epoch": 4.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094684600830078,
      "orthogonal_weight": 0.1,
      "step": 1469,
      "total_loss": 0.7072511315345764,
      "weighted_orthogonal_loss": 0.016094684600830078
    },
    {
      "classification_loss": 0.6610361337661743,
      "epoch": 4.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094954311847687,
      "orthogonal_weight": 0.1,
      "step": 1470,
      "total_loss": 0.6771311163902283,
      "weighted_orthogonal_loss": 0.016094954684376717
    },
    {
      "classification_loss": 0.6915697455406189,
      "epoch": 4.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16099795699119568,
      "orthogonal_weight": 0.1,
      "step": 1471,
      "total_loss": 0.7076695561408997,
      "weighted_orthogonal_loss": 0.016099795699119568
    },
    {
      "classification_loss": 0.6813281178474426,
      "epoch": 4.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16109499335289001,
      "orthogonal_weight": 0.1,
      "step": 1472,
      "total_loss": 0.6974376440048218,
      "weighted_orthogonal_loss": 0.01610950008034706
    },
    {
      "classification_loss": 0.6621844172477722,
      "epoch": 4.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16119880974292755,
      "orthogonal_weight": 0.1,
      "step": 1473,
      "total_loss": 0.6783043146133423,
      "weighted_orthogonal_loss": 0.016119880601763725
    },
    {
      "classification_loss": 0.5887847542762756,
      "epoch": 4.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16119350492954254,
      "orthogonal_weight": 0.1,
      "step": 1474,
      "total_loss": 0.6049041152000427,
      "weighted_orthogonal_loss": 0.016119351610541344
    },
    {
      "classification_loss": 0.7266513109207153,
      "epoch": 4.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1611083298921585,
      "orthogonal_weight": 0.1,
      "step": 1475,
      "total_loss": 0.7427621483802795,
      "weighted_orthogonal_loss": 0.01611083373427391
    },
    {
      "classification_loss": 0.6250806450843811,
      "epoch": 4.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1610046923160553,
      "orthogonal_weight": 0.1,
      "step": 1476,
      "total_loss": 0.6411811113357544,
      "weighted_orthogonal_loss": 0.01610046997666359
    },
    {
      "classification_loss": 0.6287276148796082,
      "epoch": 4.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1609254628419876,
      "orthogonal_weight": 0.1,
      "step": 1477,
      "total_loss": 0.6448201537132263,
      "weighted_orthogonal_loss": 0.01609254628419876
    },
    {
      "classification_loss": 0.6916844844818115,
      "epoch": 4.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1608097106218338,
      "orthogonal_weight": 0.1,
      "step": 1478,
      "total_loss": 0.7077654600143433,
      "weighted_orthogonal_loss": 0.01608097180724144
    },
    {
      "classification_loss": 0.6320834755897522,
      "epoch": 4.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16077162325382233,
      "orthogonal_weight": 0.1,
      "step": 1479,
      "total_loss": 0.6481606364250183,
      "weighted_orthogonal_loss": 0.016077162697911263
    },
    {
      "classification_loss": 0.6004528403282166,
      "epoch": 4.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1608089804649353,
      "orthogonal_weight": 0.1,
      "step": 1480,
      "total_loss": 0.6165337562561035,
      "weighted_orthogonal_loss": 0.01608089916408062
    },
    {
      "classification_loss": 0.6578600406646729,
      "epoch": 4.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16088435053825378,
      "orthogonal_weight": 0.1,
      "step": 1481,
      "total_loss": 0.6739484667778015,
      "weighted_orthogonal_loss": 0.016088435426354408
    },
    {
      "classification_loss": 0.6423474550247192,
      "epoch": 4.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16081589460372925,
      "orthogonal_weight": 0.1,
      "step": 1482,
      "total_loss": 0.6584290266036987,
      "weighted_orthogonal_loss": 0.016081590205430984
    },
    {
      "classification_loss": 0.6156381964683533,
      "epoch": 4.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.160752534866333,
      "orthogonal_weight": 0.1,
      "step": 1483,
      "total_loss": 0.6317134499549866,
      "weighted_orthogonal_loss": 0.0160752534866333
    },
    {
      "classification_loss": 0.6480798721313477,
      "epoch": 4.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16063465178012848,
      "orthogonal_weight": 0.1,
      "step": 1484,
      "total_loss": 0.6641433238983154,
      "weighted_orthogonal_loss": 0.016063464805483818
    },
    {
      "classification_loss": 0.7170490026473999,
      "epoch": 4.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605372130870819,
      "orthogonal_weight": 0.1,
      "step": 1485,
      "total_loss": 0.7331027388572693,
      "weighted_orthogonal_loss": 0.01605372130870819
    },
    {
      "classification_loss": 0.6510683298110962,
      "epoch": 4.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16034096479415894,
      "orthogonal_weight": 0.1,
      "step": 1486,
      "total_loss": 0.6671024560928345,
      "weighted_orthogonal_loss": 0.016034096479415894
    },
    {
      "classification_loss": 0.6580278873443604,
      "epoch": 4.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16022387146949768,
      "orthogonal_weight": 0.1,
      "step": 1487,
      "total_loss": 0.6740502715110779,
      "weighted_orthogonal_loss": 0.016022387892007828
    },
    {
      "classification_loss": 0.6337840557098389,
      "epoch": 4.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16009844839572906,
      "orthogonal_weight": 0.1,
      "step": 1488,
      "total_loss": 0.6497939229011536,
      "weighted_orthogonal_loss": 0.016009844839572906
    },
    {
      "classification_loss": 0.660090982913971,
      "epoch": 4.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15991617739200592,
      "orthogonal_weight": 0.1,
      "step": 1489,
      "total_loss": 0.6760826110839844,
      "weighted_orthogonal_loss": 0.01599161885678768
    },
    {
      "classification_loss": 0.6154422760009766,
      "epoch": 4.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15981924533843994,
      "orthogonal_weight": 0.1,
      "step": 1490,
      "total_loss": 0.6314241886138916,
      "weighted_orthogonal_loss": 0.015981925651431084
    },
    {
      "classification_loss": 0.628469705581665,
      "epoch": 4.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15976104140281677,
      "orthogonal_weight": 0.1,
      "step": 1491,
      "total_loss": 0.6444458365440369,
      "weighted_orthogonal_loss": 0.015976104885339737
    },
    {
      "classification_loss": 0.6470010280609131,
      "epoch": 4.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15974874794483185,
      "orthogonal_weight": 0.1,
      "step": 1492,
      "total_loss": 0.6629759073257446,
      "weighted_orthogonal_loss": 0.015974875539541245
    },
    {
      "classification_loss": 0.6329172253608704,
      "epoch": 4.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15973973274230957,
      "orthogonal_weight": 0.1,
      "step": 1493,
      "total_loss": 0.6488912105560303,
      "weighted_orthogonal_loss": 0.015973974019289017
    },
    {
      "classification_loss": 0.6607255935668945,
      "epoch": 4.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15972460806369781,
      "orthogonal_weight": 0.1,
      "step": 1494,
      "total_loss": 0.6766980290412903,
      "weighted_orthogonal_loss": 0.01597246155142784
    },
    {
      "classification_loss": 0.5833823084831238,
      "epoch": 4.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15953156352043152,
      "orthogonal_weight": 0.1,
      "step": 1495,
      "total_loss": 0.5993354916572571,
      "weighted_orthogonal_loss": 0.01595315709710121
    },
    {
      "classification_loss": 0.623370349407196,
      "epoch": 4.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1593804806470871,
      "orthogonal_weight": 0.1,
      "step": 1496,
      "total_loss": 0.6393083930015564,
      "weighted_orthogonal_loss": 0.0159380491822958
    },
    {
      "classification_loss": 0.6957510709762573,
      "epoch": 4.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15927506983280182,
      "orthogonal_weight": 0.1,
      "step": 1497,
      "total_loss": 0.7116785645484924,
      "weighted_orthogonal_loss": 0.015927506610751152
    },
    {
      "classification_loss": 0.5849758982658386,
      "epoch": 4.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15901759266853333,
      "orthogonal_weight": 0.1,
      "step": 1498,
      "total_loss": 0.6008776426315308,
      "weighted_orthogonal_loss": 0.015901759266853333
    },
    {
      "classification_loss": 0.5933552980422974,
      "epoch": 4.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15880842506885529,
      "orthogonal_weight": 0.1,
      "step": 1499,
      "total_loss": 0.6092361211776733,
      "weighted_orthogonal_loss": 0.015880843624472618
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 3.836839437484741,
      "learning_rate": 0.0001533666666666667,
      "loss": 0.6651,
      "step": 1500
    },
    {
      "classification_loss": 0.5532850027084351,
      "epoch": 4.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.158797025680542,
      "orthogonal_weight": 0.1,
      "step": 1500,
      "total_loss": 0.5691646933555603,
      "weighted_orthogonal_loss": 0.01587970368564129
    },
    {
      "classification_loss": 0.707432746887207,
      "epoch": 4.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15883822739124298,
      "orthogonal_weight": 0.1,
      "step": 1501,
      "total_loss": 0.7233165502548218,
      "weighted_orthogonal_loss": 0.015883823856711388
    },
    {
      "classification_loss": 0.7190752625465393,
      "epoch": 4.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15885865688323975,
      "orthogonal_weight": 0.1,
      "step": 1502,
      "total_loss": 0.7349611520767212,
      "weighted_orthogonal_loss": 0.015885865315794945
    },
    {
      "classification_loss": 0.7242637872695923,
      "epoch": 4.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15886160731315613,
      "orthogonal_weight": 0.1,
      "step": 1503,
      "total_loss": 0.740149974822998,
      "weighted_orthogonal_loss": 0.015886161476373672
    },
    {
      "classification_loss": 0.6434782147407532,
      "epoch": 4.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15883079171180725,
      "orthogonal_weight": 0.1,
      "step": 1504,
      "total_loss": 0.6593613028526306,
      "weighted_orthogonal_loss": 0.015883078798651695
    },
    {
      "classification_loss": 0.7234757542610168,
      "epoch": 4.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1588078886270523,
      "orthogonal_weight": 0.1,
      "step": 1505,
      "total_loss": 0.739356517791748,
      "weighted_orthogonal_loss": 0.01588078960776329
    },
    {
      "classification_loss": 0.6456847190856934,
      "epoch": 4.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15876071155071259,
      "orthogonal_weight": 0.1,
      "step": 1506,
      "total_loss": 0.6615607738494873,
      "weighted_orthogonal_loss": 0.01587607152760029
    },
    {
      "classification_loss": 0.6316987872123718,
      "epoch": 4.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15865619480609894,
      "orthogonal_weight": 0.1,
      "step": 1507,
      "total_loss": 0.6475644111633301,
      "weighted_orthogonal_loss": 0.015865620225667953
    },
    {
      "classification_loss": 0.6375907063484192,
      "epoch": 4.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15858444571495056,
      "orthogonal_weight": 0.1,
      "step": 1508,
      "total_loss": 0.6534491777420044,
      "weighted_orthogonal_loss": 0.015858445316553116
    },
    {
      "classification_loss": 0.6385043263435364,
      "epoch": 4.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1585010439157486,
      "orthogonal_weight": 0.1,
      "step": 1509,
      "total_loss": 0.654354453086853,
      "weighted_orthogonal_loss": 0.01585010439157486
    },
    {
      "classification_loss": 0.6037103533744812,
      "epoch": 4.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15847070515155792,
      "orthogonal_weight": 0.1,
      "step": 1510,
      "total_loss": 0.6195574402809143,
      "weighted_orthogonal_loss": 0.015847070142626762
    },
    {
      "classification_loss": 0.6966846585273743,
      "epoch": 4.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1583528071641922,
      "orthogonal_weight": 0.1,
      "step": 1511,
      "total_loss": 0.7125199437141418,
      "weighted_orthogonal_loss": 0.01583528146147728
    },
    {
      "classification_loss": 0.6901640892028809,
      "epoch": 4.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15830767154693604,
      "orthogonal_weight": 0.1,
      "step": 1512,
      "total_loss": 0.7059948444366455,
      "weighted_orthogonal_loss": 0.015830768272280693
    },
    {
      "classification_loss": 0.6457533836364746,
      "epoch": 4.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15827541053295135,
      "orthogonal_weight": 0.1,
      "step": 1513,
      "total_loss": 0.6615809202194214,
      "weighted_orthogonal_loss": 0.015827542170882225
    },
    {
      "classification_loss": 0.6881938576698303,
      "epoch": 4.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1583678275346756,
      "orthogonal_weight": 0.1,
      "step": 1514,
      "total_loss": 0.7040306329727173,
      "weighted_orthogonal_loss": 0.01583678275346756
    },
    {
      "classification_loss": 0.6565508246421814,
      "epoch": 4.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15847985446453094,
      "orthogonal_weight": 0.1,
      "step": 1515,
      "total_loss": 0.6723988056182861,
      "weighted_orthogonal_loss": 0.015847986564040184
    },
    {
      "classification_loss": 0.6441380381584167,
      "epoch": 4.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1586638242006302,
      "orthogonal_weight": 0.1,
      "step": 1516,
      "total_loss": 0.6600044369697571,
      "weighted_orthogonal_loss": 0.01586638204753399
    },
    {
      "classification_loss": 0.5864185690879822,
      "epoch": 4.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15868858993053436,
      "orthogonal_weight": 0.1,
      "step": 1517,
      "total_loss": 0.6022874116897583,
      "weighted_orthogonal_loss": 0.015868859365582466
    },
    {
      "classification_loss": 0.6191779375076294,
      "epoch": 4.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15879788994789124,
      "orthogonal_weight": 0.1,
      "step": 1518,
      "total_loss": 0.6350577473640442,
      "weighted_orthogonal_loss": 0.015879789367318153
    },
    {
      "classification_loss": 0.6906582117080688,
      "epoch": 4.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15898287296295166,
      "orthogonal_weight": 0.1,
      "step": 1519,
      "total_loss": 0.706556499004364,
      "weighted_orthogonal_loss": 0.015898287296295166
    },
    {
      "classification_loss": 0.6435989737510681,
      "epoch": 4.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1592302769422531,
      "orthogonal_weight": 0.1,
      "step": 1520,
      "total_loss": 0.6595219969749451,
      "weighted_orthogonal_loss": 0.0159230288118124
    },
    {
      "classification_loss": 0.6223328709602356,
      "epoch": 4.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594562977552414,
      "orthogonal_weight": 0.1,
      "step": 1521,
      "total_loss": 0.6382784843444824,
      "weighted_orthogonal_loss": 0.01594563014805317
    },
    {
      "classification_loss": 0.6819171905517578,
      "epoch": 4.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15961992740631104,
      "orthogonal_weight": 0.1,
      "step": 1522,
      "total_loss": 0.6978791952133179,
      "weighted_orthogonal_loss": 0.015961993485689163
    },
    {
      "classification_loss": 0.6620699763298035,
      "epoch": 4.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15985943377017975,
      "orthogonal_weight": 0.1,
      "step": 1523,
      "total_loss": 0.6780559420585632,
      "weighted_orthogonal_loss": 0.015985943377017975
    },
    {
      "classification_loss": 0.6095298528671265,
      "epoch": 4.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005951166152954,
      "orthogonal_weight": 0.1,
      "step": 1524,
      "total_loss": 0.625535786151886,
      "weighted_orthogonal_loss": 0.016005951911211014
    },
    {
      "classification_loss": 0.6921144723892212,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7081480026245117,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6981004476547241,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7141339778900146,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6831082105636597,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6991417407989502,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6887901425361633,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7048236727714539,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6922798752784729,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7083134055137634,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6851080656051636,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7011415958404541,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6762381792068481,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6922717094421387,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.7038277387619019,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7198612689971924,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.535,
      "eval_f1": 0.6055979643765903,
      "eval_loss": 0.7056462168693542,
      "eval_precision": 0.6420863309352518,
      "eval_recall": 0.5730337078651685,
      "eval_runtime": 6.1441,
      "eval_samples_per_second": 162.759,
      "eval_steps_per_second": 1.302,
      "step": 1525
    },
    {
      "classification_loss": 0.6203285455703735,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6363620758056641,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.648748517036438,
      "epoch": 5.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606888622045517,
      "orthogonal_weight": 0.1,
      "step": 1526,
      "total_loss": 0.6648173928260803,
      "weighted_orthogonal_loss": 0.01606888696551323
    },
    {
      "classification_loss": 0.6944869160652161,
      "epoch": 5.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16103820502758026,
      "orthogonal_weight": 0.1,
      "step": 1527,
      "total_loss": 0.7105907201766968,
      "weighted_orthogonal_loss": 0.016103820875287056
    },
    {
      "classification_loss": 0.6162133812904358,
      "epoch": 5.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16108664870262146,
      "orthogonal_weight": 0.1,
      "step": 1528,
      "total_loss": 0.6323220729827881,
      "weighted_orthogonal_loss": 0.016108665615320206
    },
    {
      "classification_loss": 0.6833519339561462,
      "epoch": 5.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16114969551563263,
      "orthogonal_weight": 0.1,
      "step": 1529,
      "total_loss": 0.6994668841362,
      "weighted_orthogonal_loss": 0.016114970669150352
    },
    {
      "classification_loss": 0.6260731816291809,
      "epoch": 5.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16122859716415405,
      "orthogonal_weight": 0.1,
      "step": 1530,
      "total_loss": 0.6421960592269897,
      "weighted_orthogonal_loss": 0.016122860834002495
    },
    {
      "classification_loss": 0.6179673075675964,
      "epoch": 5.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1613115519285202,
      "orthogonal_weight": 0.1,
      "step": 1531,
      "total_loss": 0.634098470211029,
      "weighted_orthogonal_loss": 0.01613115519285202
    },
    {
      "classification_loss": 0.6513174772262573,
      "epoch": 5.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16138195991516113,
      "orthogonal_weight": 0.1,
      "step": 1532,
      "total_loss": 0.6674556732177734,
      "weighted_orthogonal_loss": 0.016138195991516113
    },
    {
      "classification_loss": 0.5642306208610535,
      "epoch": 5.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615353226661682,
      "orthogonal_weight": 0.1,
      "step": 1533,
      "total_loss": 0.5803841352462769,
      "weighted_orthogonal_loss": 0.01615353301167488
    },
    {
      "classification_loss": 0.6364272832870483,
      "epoch": 5.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1616889238357544,
      "orthogonal_weight": 0.1,
      "step": 1534,
      "total_loss": 0.6525961756706238,
      "weighted_orthogonal_loss": 0.01616889238357544
    },
    {
      "classification_loss": 0.6110571622848511,
      "epoch": 5.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1618640124797821,
      "orthogonal_weight": 0.1,
      "step": 1535,
      "total_loss": 0.6272435784339905,
      "weighted_orthogonal_loss": 0.01618640124797821
    },
    {
      "classification_loss": 0.5433555841445923,
      "epoch": 5.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1620340645313263,
      "orthogonal_weight": 0.1,
      "step": 1536,
      "total_loss": 0.5595589876174927,
      "weighted_orthogonal_loss": 0.01620340719819069
    },
    {
      "classification_loss": 0.6131851673126221,
      "epoch": 5.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16224412620067596,
      "orthogonal_weight": 0.1,
      "step": 1537,
      "total_loss": 0.6294095516204834,
      "weighted_orthogonal_loss": 0.016224412247538567
    },
    {
      "classification_loss": 0.6582959890365601,
      "epoch": 5.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16246090829372406,
      "orthogonal_weight": 0.1,
      "step": 1538,
      "total_loss": 0.6745420694351196,
      "weighted_orthogonal_loss": 0.016246091574430466
    },
    {
      "classification_loss": 0.6882049441337585,
      "epoch": 5.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625952273607254,
      "orthogonal_weight": 0.1,
      "step": 1539,
      "total_loss": 0.7044644951820374,
      "weighted_orthogonal_loss": 0.01625952310860157
    },
    {
      "classification_loss": 0.640039324760437,
      "epoch": 5.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16274510324001312,
      "orthogonal_weight": 0.1,
      "step": 1540,
      "total_loss": 0.6563138365745544,
      "weighted_orthogonal_loss": 0.016274509951472282
    },
    {
      "classification_loss": 0.6516827940940857,
      "epoch": 5.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16283877193927765,
      "orthogonal_weight": 0.1,
      "step": 1541,
      "total_loss": 0.6679666638374329,
      "weighted_orthogonal_loss": 0.016283877193927765
    },
    {
      "classification_loss": 0.6936156153678894,
      "epoch": 5.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1628841757774353,
      "orthogonal_weight": 0.1,
      "step": 1542,
      "total_loss": 0.7099040150642395,
      "weighted_orthogonal_loss": 0.01628841832280159
    },
    {
      "classification_loss": 0.6493815779685974,
      "epoch": 5.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16283652186393738,
      "orthogonal_weight": 0.1,
      "step": 1543,
      "total_loss": 0.6656652092933655,
      "weighted_orthogonal_loss": 0.016283651813864708
    },
    {
      "classification_loss": 0.6381707787513733,
      "epoch": 5.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16289940476417542,
      "orthogonal_weight": 0.1,
      "step": 1544,
      "total_loss": 0.6544607281684875,
      "weighted_orthogonal_loss": 0.01628994010388851
    },
    {
      "classification_loss": 0.6357731819152832,
      "epoch": 5.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16281498968601227,
      "orthogonal_weight": 0.1,
      "step": 1545,
      "total_loss": 0.6520546674728394,
      "weighted_orthogonal_loss": 0.016281498596072197
    },
    {
      "classification_loss": 0.6707143783569336,
      "epoch": 5.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625424176454544,
      "orthogonal_weight": 0.1,
      "step": 1546,
      "total_loss": 0.6869686245918274,
      "weighted_orthogonal_loss": 0.0162542425096035
    },
    {
      "classification_loss": 0.6763911843299866,
      "epoch": 5.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16226454079151154,
      "orthogonal_weight": 0.1,
      "step": 1547,
      "total_loss": 0.692617654800415,
      "weighted_orthogonal_loss": 0.016226453706622124
    },
    {
      "classification_loss": 0.6309170722961426,
      "epoch": 5.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16212396323680878,
      "orthogonal_weight": 0.1,
      "step": 1548,
      "total_loss": 0.647129476070404,
      "weighted_orthogonal_loss": 0.016212396323680878
    },
    {
      "classification_loss": 0.6638699173927307,
      "epoch": 5.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16206510365009308,
      "orthogonal_weight": 0.1,
      "step": 1549,
      "total_loss": 0.6800764203071594,
      "weighted_orthogonal_loss": 0.016206510365009308
    },
    {
      "classification_loss": 0.6922028660774231,
      "epoch": 5.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1620500683784485,
      "orthogonal_weight": 0.1,
      "step": 1550,
      "total_loss": 0.7084078788757324,
      "weighted_orthogonal_loss": 0.01620500721037388
    },
    {
      "classification_loss": 0.6504302620887756,
      "epoch": 5.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16202856600284576,
      "orthogonal_weight": 0.1,
      "step": 1551,
      "total_loss": 0.666633129119873,
      "weighted_orthogonal_loss": 0.016202857717871666
    },
    {
      "classification_loss": 0.566456139087677,
      "epoch": 5.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16207371652126312,
      "orthogonal_weight": 0.1,
      "step": 1552,
      "total_loss": 0.5826635360717773,
      "weighted_orthogonal_loss": 0.016207372769713402
    },
    {
      "classification_loss": 0.6457269191741943,
      "epoch": 5.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16215740144252777,
      "orthogonal_weight": 0.1,
      "step": 1553,
      "total_loss": 0.6619426608085632,
      "weighted_orthogonal_loss": 0.016215739771723747
    },
    {
      "classification_loss": 0.6141403317451477,
      "epoch": 5.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1622873693704605,
      "orthogonal_weight": 0.1,
      "step": 1554,
      "total_loss": 0.6303690671920776,
      "weighted_orthogonal_loss": 0.01622873730957508
    },
    {
      "classification_loss": 0.6624844074249268,
      "epoch": 5.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16245496273040771,
      "orthogonal_weight": 0.1,
      "step": 1555,
      "total_loss": 0.6787298917770386,
      "weighted_orthogonal_loss": 0.01624549739062786
    },
    {
      "classification_loss": 0.6353470087051392,
      "epoch": 5.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16265511512756348,
      "orthogonal_weight": 0.1,
      "step": 1556,
      "total_loss": 0.6516125202178955,
      "weighted_orthogonal_loss": 0.016265511512756348
    },
    {
      "classification_loss": 0.6379003524780273,
      "epoch": 5.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16282135248184204,
      "orthogonal_weight": 0.1,
      "step": 1557,
      "total_loss": 0.654182493686676,
      "weighted_orthogonal_loss": 0.016282135620713234
    },
    {
      "classification_loss": 0.6501785516738892,
      "epoch": 5.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287121176719666,
      "orthogonal_weight": 0.1,
      "step": 1558,
      "total_loss": 0.666465699672699,
      "weighted_orthogonal_loss": 0.016287121921777725
    },
    {
      "classification_loss": 0.6364973783493042,
      "epoch": 5.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1629895567893982,
      "orthogonal_weight": 0.1,
      "step": 1559,
      "total_loss": 0.6527963280677795,
      "weighted_orthogonal_loss": 0.01629895530641079
    },
    {
      "classification_loss": 0.6348114013671875,
      "epoch": 5.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312353312969208,
      "orthogonal_weight": 0.1,
      "step": 1560,
      "total_loss": 0.6511237621307373,
      "weighted_orthogonal_loss": 0.016312353312969208
    },
    {
      "classification_loss": 0.6355750560760498,
      "epoch": 5.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16326847672462463,
      "orthogonal_weight": 0.1,
      "step": 1561,
      "total_loss": 0.65190190076828,
      "weighted_orthogonal_loss": 0.016326848417520523
    },
    {
      "classification_loss": 0.690966010093689,
      "epoch": 5.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1633804440498352,
      "orthogonal_weight": 0.1,
      "step": 1562,
      "total_loss": 0.707304060459137,
      "weighted_orthogonal_loss": 0.01633804477751255
    },
    {
      "classification_loss": 0.6280898451805115,
      "epoch": 5.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16337426006793976,
      "orthogonal_weight": 0.1,
      "step": 1563,
      "total_loss": 0.6444272994995117,
      "weighted_orthogonal_loss": 0.016337426379323006
    },
    {
      "classification_loss": 0.5863778591156006,
      "epoch": 5.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16338732838630676,
      "orthogonal_weight": 0.1,
      "step": 1564,
      "total_loss": 0.6027165651321411,
      "weighted_orthogonal_loss": 0.016338733956217766
    },
    {
      "classification_loss": 0.6730729341506958,
      "epoch": 5.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16314280033111572,
      "orthogonal_weight": 0.1,
      "step": 1565,
      "total_loss": 0.6893872022628784,
      "weighted_orthogonal_loss": 0.016314281150698662
    },
    {
      "classification_loss": 0.6920182108879089,
      "epoch": 5.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1631152331829071,
      "orthogonal_weight": 0.1,
      "step": 1566,
      "total_loss": 0.7083297371864319,
      "weighted_orthogonal_loss": 0.0163115244358778
    },
    {
      "classification_loss": 0.6267991662025452,
      "epoch": 5.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311565041542053,
      "orthogonal_weight": 0.1,
      "step": 1567,
      "total_loss": 0.6431107521057129,
      "weighted_orthogonal_loss": 0.016311565414071083
    },
    {
      "classification_loss": 0.6135960817337036,
      "epoch": 5.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312746703624725,
      "orthogonal_weight": 0.1,
      "step": 1568,
      "total_loss": 0.6299088001251221,
      "weighted_orthogonal_loss": 0.016312746331095695
    },
    {
      "classification_loss": 0.6161550283432007,
      "epoch": 5.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16308380663394928,
      "orthogonal_weight": 0.1,
      "step": 1569,
      "total_loss": 0.6324633955955505,
      "weighted_orthogonal_loss": 0.016308380290865898
    },
    {
      "classification_loss": 0.6930941939353943,
      "epoch": 5.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287246346473694,
      "orthogonal_weight": 0.1,
      "step": 1570,
      "total_loss": 0.7093814611434937,
      "weighted_orthogonal_loss": 0.016287246719002724
    },
    {
      "classification_loss": 0.6017596125602722,
      "epoch": 5.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1627156138420105,
      "orthogonal_weight": 0.1,
      "step": 1571,
      "total_loss": 0.6180311441421509,
      "weighted_orthogonal_loss": 0.01627156138420105
    },
    {
      "classification_loss": 0.6417525410652161,
      "epoch": 5.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625879853963852,
      "orthogonal_weight": 0.1,
      "step": 1572,
      "total_loss": 0.6580113172531128,
      "weighted_orthogonal_loss": 0.01625879853963852
    },
    {
      "classification_loss": 0.6010831594467163,
      "epoch": 5.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625143587589264,
      "orthogonal_weight": 0.1,
      "step": 1573,
      "total_loss": 0.6173346042633057,
      "weighted_orthogonal_loss": 0.01625143550336361
    },
    {
      "classification_loss": 0.6474691033363342,
      "epoch": 5.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625271588563919,
      "orthogonal_weight": 0.1,
      "step": 1574,
      "total_loss": 0.6637217998504639,
      "weighted_orthogonal_loss": 0.01625271700322628
    },
    {
      "classification_loss": 0.6845181584358215,
      "epoch": 5.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16259247064590454,
      "orthogonal_weight": 0.1,
      "step": 1575,
      "total_loss": 0.7007774114608765,
      "weighted_orthogonal_loss": 0.016259247437119484
    },
    {
      "classification_loss": 0.69020676612854,
      "epoch": 5.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16268908977508545,
      "orthogonal_weight": 0.1,
      "step": 1576,
      "total_loss": 0.7064756751060486,
      "weighted_orthogonal_loss": 0.016268908977508545
    },
    {
      "classification_loss": 0.6483211517333984,
      "epoch": 5.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16275952756404877,
      "orthogonal_weight": 0.1,
      "step": 1577,
      "total_loss": 0.6645970940589905,
      "weighted_orthogonal_loss": 0.016275953501462936
    },
    {
      "classification_loss": 0.6447833776473999,
      "epoch": 5.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1628861129283905,
      "orthogonal_weight": 0.1,
      "step": 1578,
      "total_loss": 0.6610720157623291,
      "weighted_orthogonal_loss": 0.01628861203789711
    },
    {
      "classification_loss": 0.562610387802124,
      "epoch": 5.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1630265712738037,
      "orthogonal_weight": 0.1,
      "step": 1579,
      "total_loss": 0.5789130330085754,
      "weighted_orthogonal_loss": 0.01630265824496746
    },
    {
      "classification_loss": 0.715632438659668,
      "epoch": 5.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16330428421497345,
      "orthogonal_weight": 0.1,
      "step": 1580,
      "total_loss": 0.7319628596305847,
      "weighted_orthogonal_loss": 0.016330428421497345
    },
    {
      "classification_loss": 0.640261173248291,
      "epoch": 5.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16357913613319397,
      "orthogonal_weight": 0.1,
      "step": 1581,
      "total_loss": 0.6566190719604492,
      "weighted_orthogonal_loss": 0.016357913613319397
    },
    {
      "classification_loss": 0.6882398128509521,
      "epoch": 5.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16382664442062378,
      "orthogonal_weight": 0.1,
      "step": 1582,
      "total_loss": 0.7046225070953369,
      "weighted_orthogonal_loss": 0.016382664442062378
    },
    {
      "classification_loss": 0.6642354130744934,
      "epoch": 5.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16414234042167664,
      "orthogonal_weight": 0.1,
      "step": 1583,
      "total_loss": 0.6806496381759644,
      "weighted_orthogonal_loss": 0.016414234414696693
    },
    {
      "classification_loss": 0.6425644159317017,
      "epoch": 5.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16445256769657135,
      "orthogonal_weight": 0.1,
      "step": 1584,
      "total_loss": 0.6590096950531006,
      "weighted_orthogonal_loss": 0.016445256769657135
    },
    {
      "classification_loss": 0.6953269839286804,
      "epoch": 5.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16464893519878387,
      "orthogonal_weight": 0.1,
      "step": 1585,
      "total_loss": 0.7117918729782104,
      "weighted_orthogonal_loss": 0.016464894637465477
    },
    {
      "classification_loss": 0.6180171370506287,
      "epoch": 5.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16481158137321472,
      "orthogonal_weight": 0.1,
      "step": 1586,
      "total_loss": 0.6344982981681824,
      "weighted_orthogonal_loss": 0.01648115925490856
    },
    {
      "classification_loss": 0.7106636166572571,
      "epoch": 5.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16512538492679596,
      "orthogonal_weight": 0.1,
      "step": 1587,
      "total_loss": 0.7271761298179626,
      "weighted_orthogonal_loss": 0.016512539237737656
    },
    {
      "classification_loss": 0.6795002222061157,
      "epoch": 5.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16544054448604584,
      "orthogonal_weight": 0.1,
      "step": 1588,
      "total_loss": 0.6960442662239075,
      "weighted_orthogonal_loss": 0.016544055193662643
    },
    {
      "classification_loss": 0.6151716709136963,
      "epoch": 5.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16574034094810486,
      "orthogonal_weight": 0.1,
      "step": 1589,
      "total_loss": 0.6317456960678101,
      "weighted_orthogonal_loss": 0.016574034467339516
    },
    {
      "classification_loss": 0.6645530462265015,
      "epoch": 5.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1660218983888626,
      "orthogonal_weight": 0.1,
      "step": 1590,
      "total_loss": 0.681155264377594,
      "weighted_orthogonal_loss": 0.01660219021141529
    },
    {
      "classification_loss": 0.6190404295921326,
      "epoch": 5.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16632874310016632,
      "orthogonal_weight": 0.1,
      "step": 1591,
      "total_loss": 0.6356732845306396,
      "weighted_orthogonal_loss": 0.01663287542760372
    },
    {
      "classification_loss": 0.637717068195343,
      "epoch": 5.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1664690524339676,
      "orthogonal_weight": 0.1,
      "step": 1592,
      "total_loss": 0.6543639898300171,
      "weighted_orthogonal_loss": 0.01664690487086773
    },
    {
      "classification_loss": 0.6819107532501221,
      "epoch": 5.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16669106483459473,
      "orthogonal_weight": 0.1,
      "step": 1593,
      "total_loss": 0.6985798478126526,
      "weighted_orthogonal_loss": 0.016669107601046562
    },
    {
      "classification_loss": 0.7156078219413757,
      "epoch": 5.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16686291992664337,
      "orthogonal_weight": 0.1,
      "step": 1594,
      "total_loss": 0.7322941422462463,
      "weighted_orthogonal_loss": 0.016686292365193367
    },
    {
      "classification_loss": 0.6921700239181519,
      "epoch": 5.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16702359914779663,
      "orthogonal_weight": 0.1,
      "step": 1595,
      "total_loss": 0.708872377872467,
      "weighted_orthogonal_loss": 0.016702359542250633
    },
    {
      "classification_loss": 0.5837015509605408,
      "epoch": 5.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16712221503257751,
      "orthogonal_weight": 0.1,
      "step": 1596,
      "total_loss": 0.6004137992858887,
      "weighted_orthogonal_loss": 0.01671222224831581
    },
    {
      "classification_loss": 0.6583158373832703,
      "epoch": 5.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1672486662864685,
      "orthogonal_weight": 0.1,
      "step": 1597,
      "total_loss": 0.6750407218933105,
      "weighted_orthogonal_loss": 0.01672486774623394
    },
    {
      "classification_loss": 0.5992154479026794,
      "epoch": 5.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16750171780586243,
      "orthogonal_weight": 0.1,
      "step": 1598,
      "total_loss": 0.6159656047821045,
      "weighted_orthogonal_loss": 0.016750171780586243
    },
    {
      "classification_loss": 0.6443736553192139,
      "epoch": 5.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16775842010974884,
      "orthogonal_weight": 0.1,
      "step": 1599,
      "total_loss": 0.6611495018005371,
      "weighted_orthogonal_loss": 0.016775842756032944
    },
    {
      "epoch": 5.245901639344262,
      "grad_norm": 15.2339448928833,
      "learning_rate": 0.00015003333333333334,
      "loss": 0.6638,
      "step": 1600
    },
    {
      "classification_loss": 0.660859227180481,
      "epoch": 5.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16801650822162628,
      "orthogonal_weight": 0.1,
      "step": 1600,
      "total_loss": 0.6776608824729919,
      "weighted_orthogonal_loss": 0.016801651567220688
    },
    {
      "classification_loss": 0.5824858546257019,
      "epoch": 5.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682816743850708,
      "orthogonal_weight": 0.1,
      "step": 1601,
      "total_loss": 0.5993140339851379,
      "weighted_orthogonal_loss": 0.01682816818356514
    },
    {
      "classification_loss": 0.5919020771980286,
      "epoch": 5.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687086671590805,
      "orthogonal_weight": 0.1,
      "step": 1602,
      "total_loss": 0.6087729334831238,
      "weighted_orthogonal_loss": 0.01687086746096611
    },
    {
      "classification_loss": 0.6215518712997437,
      "epoch": 5.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16913799941539764,
      "orthogonal_weight": 0.1,
      "step": 1603,
      "total_loss": 0.6384656429290771,
      "weighted_orthogonal_loss": 0.016913799569010735
    },
    {
      "classification_loss": 0.6959013342857361,
      "epoch": 5.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16954763233661652,
      "orthogonal_weight": 0.1,
      "step": 1604,
      "total_loss": 0.712856113910675,
      "weighted_orthogonal_loss": 0.016954762861132622
    },
    {
      "classification_loss": 0.6426951885223389,
      "epoch": 5.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16990172863006592,
      "orthogonal_weight": 0.1,
      "step": 1605,
      "total_loss": 0.6596853733062744,
      "weighted_orthogonal_loss": 0.01699017360806465
    },
    {
      "classification_loss": 0.5827280282974243,
      "epoch": 5.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1702023595571518,
      "orthogonal_weight": 0.1,
      "step": 1606,
      "total_loss": 0.5997482538223267,
      "weighted_orthogonal_loss": 0.01702023670077324
    },
    {
      "classification_loss": 0.619750440120697,
      "epoch": 5.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1704617291688919,
      "orthogonal_weight": 0.1,
      "step": 1607,
      "total_loss": 0.6367965936660767,
      "weighted_orthogonal_loss": 0.01704617403447628
    },
    {
      "classification_loss": 0.6485171914100647,
      "epoch": 5.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17076805233955383,
      "orthogonal_weight": 0.1,
      "step": 1608,
      "total_loss": 0.6655939817428589,
      "weighted_orthogonal_loss": 0.017076805233955383
    },
    {
      "classification_loss": 0.6554890275001526,
      "epoch": 5.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17113053798675537,
      "orthogonal_weight": 0.1,
      "step": 1609,
      "total_loss": 0.6726020574569702,
      "weighted_orthogonal_loss": 0.017113054171204567
    },
    {
      "classification_loss": 0.6939622163772583,
      "epoch": 5.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17130109667778015,
      "orthogonal_weight": 0.1,
      "step": 1610,
      "total_loss": 0.7110923528671265,
      "weighted_orthogonal_loss": 0.017130110412836075
    },
    {
      "classification_loss": 0.6609073877334595,
      "epoch": 5.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17158089578151703,
      "orthogonal_weight": 0.1,
      "step": 1611,
      "total_loss": 0.6780654788017273,
      "weighted_orthogonal_loss": 0.017158089205622673
    },
    {
      "classification_loss": 0.718752384185791,
      "epoch": 5.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17187198996543884,
      "orthogonal_weight": 0.1,
      "step": 1612,
      "total_loss": 0.7359395623207092,
      "weighted_orthogonal_loss": 0.017187198624014854
    },
    {
      "classification_loss": 0.6256684064865112,
      "epoch": 5.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17202046513557434,
      "orthogonal_weight": 0.1,
      "step": 1613,
      "total_loss": 0.6428704261779785,
      "weighted_orthogonal_loss": 0.017202047631144524
    },
    {
      "classification_loss": 0.6421108245849609,
      "epoch": 5.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17226003110408783,
      "orthogonal_weight": 0.1,
      "step": 1614,
      "total_loss": 0.6593368053436279,
      "weighted_orthogonal_loss": 0.017226003110408783
    },
    {
      "classification_loss": 0.6013475656509399,
      "epoch": 5.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17247138917446136,
      "orthogonal_weight": 0.1,
      "step": 1615,
      "total_loss": 0.6185947060585022,
      "weighted_orthogonal_loss": 0.017247138544917107
    },
    {
      "classification_loss": 0.5834155678749084,
      "epoch": 5.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726205199956894,
      "orthogonal_weight": 0.1,
      "step": 1616,
      "total_loss": 0.6006776094436646,
      "weighted_orthogonal_loss": 0.017262052744627
    },
    {
      "classification_loss": 0.6139799356460571,
      "epoch": 5.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17275851964950562,
      "orthogonal_weight": 0.1,
      "step": 1617,
      "total_loss": 0.6312558054924011,
      "weighted_orthogonal_loss": 0.01727585308253765
    },
    {
      "classification_loss": 0.5611152648925781,
      "epoch": 5.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17301274836063385,
      "orthogonal_weight": 0.1,
      "step": 1618,
      "total_loss": 0.5784165263175964,
      "weighted_orthogonal_loss": 0.017301274463534355
    },
    {
      "classification_loss": 0.7048636674880981,
      "epoch": 5.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17348358035087585,
      "orthogonal_weight": 0.1,
      "step": 1619,
      "total_loss": 0.722212016582489,
      "weighted_orthogonal_loss": 0.017348358407616615
    },
    {
      "classification_loss": 0.649937093257904,
      "epoch": 5.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737612783908844,
      "orthogonal_weight": 0.1,
      "step": 1620,
      "total_loss": 0.6673132181167603,
      "weighted_orthogonal_loss": 0.0173761285841465
    },
    {
      "classification_loss": 0.6829912066459656,
      "epoch": 5.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1740584820508957,
      "orthogonal_weight": 0.1,
      "step": 1621,
      "total_loss": 0.7003970742225647,
      "weighted_orthogonal_loss": 0.01740584895014763
    },
    {
      "classification_loss": 0.630784273147583,
      "epoch": 5.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17434054613113403,
      "orthogonal_weight": 0.1,
      "step": 1622,
      "total_loss": 0.6482183337211609,
      "weighted_orthogonal_loss": 0.017434054985642433
    },
    {
      "classification_loss": 0.6386786103248596,
      "epoch": 5.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746213138103485,
      "orthogonal_weight": 0.1,
      "step": 1623,
      "total_loss": 0.6561407446861267,
      "weighted_orthogonal_loss": 0.01746213249862194
    },
    {
      "classification_loss": 0.6791326403617859,
      "epoch": 5.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17498329281806946,
      "orthogonal_weight": 0.1,
      "step": 1624,
      "total_loss": 0.6966309547424316,
      "weighted_orthogonal_loss": 0.017498329281806946
    },
    {
      "classification_loss": 0.6683520674705505,
      "epoch": 5.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17534182965755463,
      "orthogonal_weight": 0.1,
      "step": 1625,
      "total_loss": 0.6858862638473511,
      "weighted_orthogonal_loss": 0.017534183338284492
    },
    {
      "classification_loss": 0.6834380030632019,
      "epoch": 5.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17573779821395874,
      "orthogonal_weight": 0.1,
      "step": 1626,
      "total_loss": 0.7010117769241333,
      "weighted_orthogonal_loss": 0.017573779448866844
    },
    {
      "classification_loss": 0.662335991859436,
      "epoch": 5.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17603975534439087,
      "orthogonal_weight": 0.1,
      "step": 1627,
      "total_loss": 0.6799399852752686,
      "weighted_orthogonal_loss": 0.017603976652026176
    },
    {
      "classification_loss": 0.6126276850700378,
      "epoch": 5.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1763755828142166,
      "orthogonal_weight": 0.1,
      "step": 1628,
      "total_loss": 0.6302652359008789,
      "weighted_orthogonal_loss": 0.01763755828142166
    },
    {
      "classification_loss": 0.6214967370033264,
      "epoch": 5.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17670591175556183,
      "orthogonal_weight": 0.1,
      "step": 1629,
      "total_loss": 0.639167308807373,
      "weighted_orthogonal_loss": 0.017670592293143272
    },
    {
      "classification_loss": 0.6598544716835022,
      "epoch": 5.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1770630031824112,
      "orthogonal_weight": 0.1,
      "step": 1630,
      "total_loss": 0.6775607466697693,
      "weighted_orthogonal_loss": 0.01770630106329918
    },
    {
      "classification_loss": 0.6954964995384216,
      "epoch": 5.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1771446019411087,
      "orthogonal_weight": 0.1,
      "step": 1631,
      "total_loss": 0.713210940361023,
      "weighted_orthogonal_loss": 0.01771446131169796
    },
    {
      "classification_loss": 0.6206545829772949,
      "epoch": 5.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17723149061203003,
      "orthogonal_weight": 0.1,
      "step": 1632,
      "total_loss": 0.6383777260780334,
      "weighted_orthogonal_loss": 0.017723148688673973
    },
    {
      "classification_loss": 0.6150932312011719,
      "epoch": 5.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17730404436588287,
      "orthogonal_weight": 0.1,
      "step": 1633,
      "total_loss": 0.632823646068573,
      "weighted_orthogonal_loss": 0.017730405554175377
    },
    {
      "classification_loss": 0.6542022228240967,
      "epoch": 5.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17749901115894318,
      "orthogonal_weight": 0.1,
      "step": 1634,
      "total_loss": 0.6719521284103394,
      "weighted_orthogonal_loss": 0.017749901860952377
    },
    {
      "classification_loss": 0.624636709690094,
      "epoch": 5.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17763809859752655,
      "orthogonal_weight": 0.1,
      "step": 1635,
      "total_loss": 0.6424005031585693,
      "weighted_orthogonal_loss": 0.017763810232281685
    },
    {
      "classification_loss": 0.6860044598579407,
      "epoch": 5.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1778988242149353,
      "orthogonal_weight": 0.1,
      "step": 1636,
      "total_loss": 0.7037943601608276,
      "weighted_orthogonal_loss": 0.01778988353908062
    },
    {
      "classification_loss": 0.646099865436554,
      "epoch": 5.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17807571589946747,
      "orthogonal_weight": 0.1,
      "step": 1637,
      "total_loss": 0.6639074087142944,
      "weighted_orthogonal_loss": 0.017807571217417717
    },
    {
      "classification_loss": 0.651850700378418,
      "epoch": 5.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1781732141971588,
      "orthogonal_weight": 0.1,
      "step": 1638,
      "total_loss": 0.6696680188179016,
      "weighted_orthogonal_loss": 0.01781732216477394
    },
    {
      "classification_loss": 0.662514865398407,
      "epoch": 5.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17828316986560822,
      "orthogonal_weight": 0.1,
      "step": 1639,
      "total_loss": 0.6803432106971741,
      "weighted_orthogonal_loss": 0.01782831735908985
    },
    {
      "classification_loss": 0.6634156703948975,
      "epoch": 5.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1782938539981842,
      "orthogonal_weight": 0.1,
      "step": 1640,
      "total_loss": 0.6812450289726257,
      "weighted_orthogonal_loss": 0.01782938651740551
    },
    {
      "classification_loss": 0.6781746745109558,
      "epoch": 5.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17823147773742676,
      "orthogonal_weight": 0.1,
      "step": 1641,
      "total_loss": 0.6959978342056274,
      "weighted_orthogonal_loss": 0.017823148518800735
    },
    {
      "classification_loss": 0.6424873471260071,
      "epoch": 5.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17813369631767273,
      "orthogonal_weight": 0.1,
      "step": 1642,
      "total_loss": 0.6603007316589355,
      "weighted_orthogonal_loss": 0.017813369631767273
    },
    {
      "classification_loss": 0.6761037111282349,
      "epoch": 5.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17804184556007385,
      "orthogonal_weight": 0.1,
      "step": 1643,
      "total_loss": 0.6939079165458679,
      "weighted_orthogonal_loss": 0.017804184928536415
    },
    {
      "classification_loss": 0.6524102091789246,
      "epoch": 5.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17792613804340363,
      "orthogonal_weight": 0.1,
      "step": 1644,
      "total_loss": 0.6702028512954712,
      "weighted_orthogonal_loss": 0.017792614176869392
    },
    {
      "classification_loss": 0.6039673089981079,
      "epoch": 5.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17776785790920258,
      "orthogonal_weight": 0.1,
      "step": 1645,
      "total_loss": 0.6217440962791443,
      "weighted_orthogonal_loss": 0.017776785418391228
    },
    {
      "classification_loss": 0.6824022531509399,
      "epoch": 5.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17756304144859314,
      "orthogonal_weight": 0.1,
      "step": 1646,
      "total_loss": 0.7001585364341736,
      "weighted_orthogonal_loss": 0.017756303772330284
    },
    {
      "classification_loss": 0.6268479228019714,
      "epoch": 5.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17732194066047668,
      "orthogonal_weight": 0.1,
      "step": 1647,
      "total_loss": 0.6445801258087158,
      "weighted_orthogonal_loss": 0.01773219369351864
    },
    {
      "classification_loss": 0.6517366170883179,
      "epoch": 5.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17668886482715607,
      "orthogonal_weight": 0.1,
      "step": 1648,
      "total_loss": 0.6694055199623108,
      "weighted_orthogonal_loss": 0.017668886110186577
    },
    {
      "classification_loss": 0.6527358889579773,
      "epoch": 5.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17614392936229706,
      "orthogonal_weight": 0.1,
      "step": 1649,
      "total_loss": 0.6703502535820007,
      "weighted_orthogonal_loss": 0.017614392563700676
    },
    {
      "classification_loss": 0.6722487211227417,
      "epoch": 5.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17540203034877777,
      "orthogonal_weight": 0.1,
      "step": 1650,
      "total_loss": 0.6897889375686646,
      "weighted_orthogonal_loss": 0.017540203407406807
    },
    {
      "classification_loss": 0.7760205864906311,
      "epoch": 5.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17474029958248138,
      "orthogonal_weight": 0.1,
      "step": 1651,
      "total_loss": 0.7934946417808533,
      "weighted_orthogonal_loss": 0.017474031075835228
    },
    {
      "classification_loss": 0.7066853046417236,
      "epoch": 5.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17420725524425507,
      "orthogonal_weight": 0.1,
      "step": 1652,
      "total_loss": 0.7241060137748718,
      "weighted_orthogonal_loss": 0.017420725896954536
    },
    {
      "classification_loss": 0.6498019695281982,
      "epoch": 5.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737682819366455,
      "orthogonal_weight": 0.1,
      "step": 1653,
      "total_loss": 0.6671788096427917,
      "weighted_orthogonal_loss": 0.01737682893872261
    },
    {
      "classification_loss": 0.6353656053543091,
      "epoch": 5.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1733948290348053,
      "orthogonal_weight": 0.1,
      "step": 1654,
      "total_loss": 0.6527050733566284,
      "weighted_orthogonal_loss": 0.01733948290348053
    },
    {
      "classification_loss": 0.6417276859283447,
      "epoch": 5.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1730564683675766,
      "orthogonal_weight": 0.1,
      "step": 1655,
      "total_loss": 0.6590333580970764,
      "weighted_orthogonal_loss": 0.01730564795434475
    },
    {
      "classification_loss": 0.6520147919654846,
      "epoch": 5.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17280863225460052,
      "orthogonal_weight": 0.1,
      "step": 1656,
      "total_loss": 0.6692956686019897,
      "weighted_orthogonal_loss": 0.017280863597989082
    },
    {
      "classification_loss": 0.654247522354126,
      "epoch": 5.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17264150083065033,
      "orthogonal_weight": 0.1,
      "step": 1657,
      "total_loss": 0.6715116500854492,
      "weighted_orthogonal_loss": 0.017264150083065033
    },
    {
      "classification_loss": 0.6663828492164612,
      "epoch": 5.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17254693806171417,
      "orthogonal_weight": 0.1,
      "step": 1658,
      "total_loss": 0.6836375594139099,
      "weighted_orthogonal_loss": 0.017254693433642387
    },
    {
      "classification_loss": 0.6175025701522827,
      "epoch": 5.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17248864471912384,
      "orthogonal_weight": 0.1,
      "step": 1659,
      "total_loss": 0.6347514390945435,
      "weighted_orthogonal_loss": 0.017248865216970444
    },
    {
      "classification_loss": 0.6056497097015381,
      "epoch": 5.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17248326539993286,
      "orthogonal_weight": 0.1,
      "step": 1660,
      "total_loss": 0.6228980422019958,
      "weighted_orthogonal_loss": 0.017248326912522316
    },
    {
      "classification_loss": 0.6721258163452148,
      "epoch": 5.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1724950224161148,
      "orthogonal_weight": 0.1,
      "step": 1661,
      "total_loss": 0.6893753409385681,
      "weighted_orthogonal_loss": 0.01724950224161148
    },
    {
      "classification_loss": 0.6666698455810547,
      "epoch": 5.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17242538928985596,
      "orthogonal_weight": 0.1,
      "step": 1662,
      "total_loss": 0.6839123964309692,
      "weighted_orthogonal_loss": 0.017242539674043655
    },
    {
      "classification_loss": 0.6294615268707275,
      "epoch": 5.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1723916381597519,
      "orthogonal_weight": 0.1,
      "step": 1663,
      "total_loss": 0.6467006802558899,
      "weighted_orthogonal_loss": 0.01723916456103325
    },
    {
      "classification_loss": 0.6228975653648376,
      "epoch": 5.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17245760560035706,
      "orthogonal_weight": 0.1,
      "step": 1664,
      "total_loss": 0.6401433348655701,
      "weighted_orthogonal_loss": 0.017245760187506676
    },
    {
      "classification_loss": 0.6590908765792847,
      "epoch": 5.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17260904610157013,
      "orthogonal_weight": 0.1,
      "step": 1665,
      "total_loss": 0.67635178565979,
      "weighted_orthogonal_loss": 0.017260905355215073
    },
    {
      "classification_loss": 0.687759280204773,
      "epoch": 5.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726001501083374,
      "orthogonal_weight": 0.1,
      "step": 1666,
      "total_loss": 0.7050192952156067,
      "weighted_orthogonal_loss": 0.01726001501083374
    },
    {
      "classification_loss": 0.6281698346138,
      "epoch": 5.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17278191447257996,
      "orthogonal_weight": 0.1,
      "step": 1667,
      "total_loss": 0.6454480290412903,
      "weighted_orthogonal_loss": 0.017278192564845085
    },
    {
      "classification_loss": 0.6097894310951233,
      "epoch": 5.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1728593409061432,
      "orthogonal_weight": 0.1,
      "step": 1668,
      "total_loss": 0.6270753741264343,
      "weighted_orthogonal_loss": 0.01728593371808529
    },
    {
      "classification_loss": 0.6337709426879883,
      "epoch": 5.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17295421659946442,
      "orthogonal_weight": 0.1,
      "step": 1669,
      "total_loss": 0.6510663628578186,
      "weighted_orthogonal_loss": 0.01729542203247547
    },
    {
      "classification_loss": 0.6396743059158325,
      "epoch": 5.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17304454743862152,
      "orthogonal_weight": 0.1,
      "step": 1670,
      "total_loss": 0.6569787859916687,
      "weighted_orthogonal_loss": 0.01730445586144924
    },
    {
      "classification_loss": 0.5604592561721802,
      "epoch": 5.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17309348285198212,
      "orthogonal_weight": 0.1,
      "step": 1671,
      "total_loss": 0.5777686238288879,
      "weighted_orthogonal_loss": 0.01730934903025627
    },
    {
      "classification_loss": 0.6884263753890991,
      "epoch": 5.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17321211099624634,
      "orthogonal_weight": 0.1,
      "step": 1672,
      "total_loss": 0.7057476043701172,
      "weighted_orthogonal_loss": 0.017321212217211723
    },
    {
      "classification_loss": 0.6431223750114441,
      "epoch": 5.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17316527664661407,
      "orthogonal_weight": 0.1,
      "step": 1673,
      "total_loss": 0.6604388952255249,
      "weighted_orthogonal_loss": 0.017316527664661407
    },
    {
      "classification_loss": 0.6320978403091431,
      "epoch": 5.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1731395572423935,
      "orthogonal_weight": 0.1,
      "step": 1674,
      "total_loss": 0.6494117975234985,
      "weighted_orthogonal_loss": 0.01731395535171032
    },
    {
      "classification_loss": 0.5881766676902771,
      "epoch": 5.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17306838929653168,
      "orthogonal_weight": 0.1,
      "step": 1675,
      "total_loss": 0.6054835319519043,
      "weighted_orthogonal_loss": 0.017306840047240257
    },
    {
      "classification_loss": 0.7068535685539246,
      "epoch": 5.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17322811484336853,
      "orthogonal_weight": 0.1,
      "step": 1676,
      "total_loss": 0.7241764068603516,
      "weighted_orthogonal_loss": 0.017322812229394913
    },
    {
      "classification_loss": 0.673700749874115,
      "epoch": 5.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17335578799247742,
      "orthogonal_weight": 0.1,
      "step": 1677,
      "total_loss": 0.6910363435745239,
      "weighted_orthogonal_loss": 0.01733557879924774
    },
    {
      "classification_loss": 0.6665583848953247,
      "epoch": 5.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17353801429271698,
      "orthogonal_weight": 0.1,
      "step": 1678,
      "total_loss": 0.6839121580123901,
      "weighted_orthogonal_loss": 0.017353801056742668
    },
    {
      "classification_loss": 0.6613678336143494,
      "epoch": 5.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1736895591020584,
      "orthogonal_weight": 0.1,
      "step": 1679,
      "total_loss": 0.6787368059158325,
      "weighted_orthogonal_loss": 0.01736895553767681
    },
    {
      "classification_loss": 0.638709545135498,
      "epoch": 5.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17378723621368408,
      "orthogonal_weight": 0.1,
      "step": 1680,
      "total_loss": 0.6560882925987244,
      "weighted_orthogonal_loss": 0.01737872324883938
    },
    {
      "classification_loss": 0.6332820057868958,
      "epoch": 5.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1738370656967163,
      "orthogonal_weight": 0.1,
      "step": 1681,
      "total_loss": 0.6506657004356384,
      "weighted_orthogonal_loss": 0.01738370768725872
    },
    {
      "classification_loss": 0.6734911203384399,
      "epoch": 5.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17394454777240753,
      "orthogonal_weight": 0.1,
      "step": 1682,
      "total_loss": 0.690885603427887,
      "weighted_orthogonal_loss": 0.017394455149769783
    },
    {
      "classification_loss": 0.6503857970237732,
      "epoch": 5.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1740102618932724,
      "orthogonal_weight": 0.1,
      "step": 1683,
      "total_loss": 0.6677868366241455,
      "weighted_orthogonal_loss": 0.01740102656185627
    },
    {
      "classification_loss": 0.6357021331787109,
      "epoch": 5.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17382808029651642,
      "orthogonal_weight": 0.1,
      "step": 1684,
      "total_loss": 0.653084933757782,
      "weighted_orthogonal_loss": 0.017382808029651642
    },
    {
      "classification_loss": 0.6683855652809143,
      "epoch": 5.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737254112958908,
      "orthogonal_weight": 0.1,
      "step": 1685,
      "total_loss": 0.685758113861084,
      "weighted_orthogonal_loss": 0.01737254112958908
    },
    {
      "classification_loss": 0.6495146751403809,
      "epoch": 5.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17352350056171417,
      "orthogonal_weight": 0.1,
      "step": 1686,
      "total_loss": 0.6668670177459717,
      "weighted_orthogonal_loss": 0.017352350056171417
    },
    {
      "classification_loss": 0.6066989302635193,
      "epoch": 5.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17324553430080414,
      "orthogonal_weight": 0.1,
      "step": 1687,
      "total_loss": 0.6240234971046448,
      "weighted_orthogonal_loss": 0.017324553802609444
    },
    {
      "classification_loss": 0.6144248843193054,
      "epoch": 5.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17316870391368866,
      "orthogonal_weight": 0.1,
      "step": 1688,
      "total_loss": 0.6317417621612549,
      "weighted_orthogonal_loss": 0.017316870391368866
    },
    {
      "classification_loss": 0.6688107252120972,
      "epoch": 5.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17319922149181366,
      "orthogonal_weight": 0.1,
      "step": 1689,
      "total_loss": 0.6861306428909302,
      "weighted_orthogonal_loss": 0.017319923266768456
    },
    {
      "classification_loss": 0.5921868681907654,
      "epoch": 5.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17329324781894684,
      "orthogonal_weight": 0.1,
      "step": 1690,
      "total_loss": 0.6095162034034729,
      "weighted_orthogonal_loss": 0.017329325899481773
    },
    {
      "classification_loss": 0.7083170413970947,
      "epoch": 5.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17347829043865204,
      "orthogonal_weight": 0.1,
      "step": 1691,
      "total_loss": 0.7256648540496826,
      "weighted_orthogonal_loss": 0.017347829416394234
    },
    {
      "classification_loss": 0.6623518466949463,
      "epoch": 5.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1735558658838272,
      "orthogonal_weight": 0.1,
      "step": 1692,
      "total_loss": 0.679707407951355,
      "weighted_orthogonal_loss": 0.01735558733344078
    },
    {
      "classification_loss": 0.6139780282974243,
      "epoch": 5.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1735730618238449,
      "orthogonal_weight": 0.1,
      "step": 1693,
      "total_loss": 0.6313353180885315,
      "weighted_orthogonal_loss": 0.01735730655491352
    },
    {
      "classification_loss": 0.6534650325775146,
      "epoch": 5.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1736658364534378,
      "orthogonal_weight": 0.1,
      "step": 1694,
      "total_loss": 0.6708316206932068,
      "weighted_orthogonal_loss": 0.01736658439040184
    },
    {
      "classification_loss": 0.6617529392242432,
      "epoch": 5.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17369626462459564,
      "orthogonal_weight": 0.1,
      "step": 1695,
      "total_loss": 0.6791225671768188,
      "weighted_orthogonal_loss": 0.017369626089930534
    },
    {
      "classification_loss": 0.6414620280265808,
      "epoch": 5.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737355887889862,
      "orthogonal_weight": 0.1,
      "step": 1696,
      "total_loss": 0.6588355898857117,
      "weighted_orthogonal_loss": 0.01737355999648571
    },
    {
      "classification_loss": 0.6753622889518738,
      "epoch": 5.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17383530735969543,
      "orthogonal_weight": 0.1,
      "step": 1697,
      "total_loss": 0.6927458047866821,
      "weighted_orthogonal_loss": 0.017383530735969543
    },
    {
      "classification_loss": 0.5933992862701416,
      "epoch": 5.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1739668846130371,
      "orthogonal_weight": 0.1,
      "step": 1698,
      "total_loss": 0.6107959747314453,
      "weighted_orthogonal_loss": 0.01739668846130371
    },
    {
      "classification_loss": 0.6559333801269531,
      "epoch": 5.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17411823570728302,
      "orthogonal_weight": 0.1,
      "step": 1699,
      "total_loss": 0.6733452081680298,
      "weighted_orthogonal_loss": 0.01741182431578636
    },
    {
      "epoch": 5.573770491803279,
      "grad_norm": 5.8926615715026855,
      "learning_rate": 0.00014670000000000002,
      "loss": 0.6647,
      "step": 1700
    },
    {
      "classification_loss": 0.7129666209220886,
      "epoch": 5.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17431579530239105,
      "orthogonal_weight": 0.1,
      "step": 1700,
      "total_loss": 0.7303981781005859,
      "weighted_orthogonal_loss": 0.017431579530239105
    },
    {
      "classification_loss": 0.6201524138450623,
      "epoch": 5.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17424441874027252,
      "orthogonal_weight": 0.1,
      "step": 1701,
      "total_loss": 0.6375768780708313,
      "weighted_orthogonal_loss": 0.017424441874027252
    },
    {
      "classification_loss": 0.6557439565658569,
      "epoch": 5.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1742108166217804,
      "orthogonal_weight": 0.1,
      "step": 1702,
      "total_loss": 0.6731650233268738,
      "weighted_orthogonal_loss": 0.01742108166217804
    },
    {
      "classification_loss": 0.6206724047660828,
      "epoch": 5.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17449180781841278,
      "orthogonal_weight": 0.1,
      "step": 1703,
      "total_loss": 0.6381216049194336,
      "weighted_orthogonal_loss": 0.017449181526899338
    },
    {
      "classification_loss": 0.6288803815841675,
      "epoch": 5.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746215969324112,
      "orthogonal_weight": 0.1,
      "step": 1704,
      "total_loss": 0.6463425159454346,
      "weighted_orthogonal_loss": 0.01746216043829918
    },
    {
      "classification_loss": 0.6719655990600586,
      "epoch": 5.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1747940629720688,
      "orthogonal_weight": 0.1,
      "step": 1705,
      "total_loss": 0.6894450187683105,
      "weighted_orthogonal_loss": 0.01747940666973591
    },
    {
      "classification_loss": 0.6555918455123901,
      "epoch": 5.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17428375780582428,
      "orthogonal_weight": 0.1,
      "step": 1706,
      "total_loss": 0.6730202436447144,
      "weighted_orthogonal_loss": 0.017428375780582428
    },
    {
      "classification_loss": 0.654662549495697,
      "epoch": 5.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17388418316841125,
      "orthogonal_weight": 0.1,
      "step": 1707,
      "total_loss": 0.672050952911377,
      "weighted_orthogonal_loss": 0.017388418316841125
    },
    {
      "classification_loss": 0.6426043510437012,
      "epoch": 5.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17350348830223083,
      "orthogonal_weight": 0.1,
      "step": 1708,
      "total_loss": 0.6599547266960144,
      "weighted_orthogonal_loss": 0.017350349575281143
    },
    {
      "classification_loss": 0.6049043536186218,
      "epoch": 5.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17310327291488647,
      "orthogonal_weight": 0.1,
      "step": 1709,
      "total_loss": 0.622214674949646,
      "weighted_orthogonal_loss": 0.017310326918959618
    },
    {
      "classification_loss": 0.6650745868682861,
      "epoch": 5.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17275559902191162,
      "orthogonal_weight": 0.1,
      "step": 1710,
      "total_loss": 0.6823501586914062,
      "weighted_orthogonal_loss": 0.017275560647249222
    },
    {
      "classification_loss": 0.65084308385849,
      "epoch": 5.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17243576049804688,
      "orthogonal_weight": 0.1,
      "step": 1711,
      "total_loss": 0.6680866479873657,
      "weighted_orthogonal_loss": 0.017243577167391777
    },
    {
      "classification_loss": 0.712444543838501,
      "epoch": 5.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1715303510427475,
      "orthogonal_weight": 0.1,
      "step": 1712,
      "total_loss": 0.7295975685119629,
      "weighted_orthogonal_loss": 0.01715303584933281
    },
    {
      "classification_loss": 0.612546443939209,
      "epoch": 5.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17077133059501648,
      "orthogonal_weight": 0.1,
      "step": 1713,
      "total_loss": 0.6296235918998718,
      "weighted_orthogonal_loss": 0.017077133059501648
    },
    {
      "classification_loss": 0.6738563179969788,
      "epoch": 5.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17004279792308807,
      "orthogonal_weight": 0.1,
      "step": 1714,
      "total_loss": 0.6908605694770813,
      "weighted_orthogonal_loss": 0.017004279419779778
    },
    {
      "classification_loss": 0.6517181396484375,
      "epoch": 5.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1693735122680664,
      "orthogonal_weight": 0.1,
      "step": 1715,
      "total_loss": 0.668655514717102,
      "weighted_orthogonal_loss": 0.01693735085427761
    },
    {
      "classification_loss": 0.6127737164497375,
      "epoch": 5.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687622368335724,
      "orthogonal_weight": 0.1,
      "step": 1716,
      "total_loss": 0.6296499371528625,
      "weighted_orthogonal_loss": 0.0168762244284153
    },
    {
      "classification_loss": 0.6430842280387878,
      "epoch": 5.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16823318600654602,
      "orthogonal_weight": 0.1,
      "step": 1717,
      "total_loss": 0.6599075198173523,
      "weighted_orthogonal_loss": 0.01682331971824169
    },
    {
      "classification_loss": 0.6516420841217041,
      "epoch": 5.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16746869683265686,
      "orthogonal_weight": 0.1,
      "step": 1718,
      "total_loss": 0.6683889627456665,
      "weighted_orthogonal_loss": 0.016746869310736656
    },
    {
      "classification_loss": 0.6559708714485168,
      "epoch": 5.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16689352691173553,
      "orthogonal_weight": 0.1,
      "step": 1719,
      "total_loss": 0.672660231590271,
      "weighted_orthogonal_loss": 0.016689352691173553
    },
    {
      "classification_loss": 0.6742166876792908,
      "epoch": 5.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16639280319213867,
      "orthogonal_weight": 0.1,
      "step": 1720,
      "total_loss": 0.6908559799194336,
      "weighted_orthogonal_loss": 0.016639281064271927
    },
    {
      "classification_loss": 0.6458649039268494,
      "epoch": 5.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16596420109272003,
      "orthogonal_weight": 0.1,
      "step": 1721,
      "total_loss": 0.6624613404273987,
      "weighted_orthogonal_loss": 0.016596419736742973
    },
    {
      "classification_loss": 0.6022536754608154,
      "epoch": 5.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16557545959949493,
      "orthogonal_weight": 0.1,
      "step": 1722,
      "total_loss": 0.6188112497329712,
      "weighted_orthogonal_loss": 0.016557546332478523
    },
    {
      "classification_loss": 0.6231856942176819,
      "epoch": 5.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16528035700321198,
      "orthogonal_weight": 0.1,
      "step": 1723,
      "total_loss": 0.639713704586029,
      "weighted_orthogonal_loss": 0.016528036445379257
    },
    {
      "classification_loss": 0.6264762282371521,
      "epoch": 5.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16506749391555786,
      "orthogonal_weight": 0.1,
      "step": 1724,
      "total_loss": 0.6429829597473145,
      "weighted_orthogonal_loss": 0.016506750136613846
    },
    {
      "classification_loss": 0.6563029289245605,
      "epoch": 5.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16494391858577728,
      "orthogonal_weight": 0.1,
      "step": 1725,
      "total_loss": 0.6727973222732544,
      "weighted_orthogonal_loss": 0.0164943914860487
    },
    {
      "classification_loss": 0.6293474435806274,
      "epoch": 5.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.164841428399086,
      "orthogonal_weight": 0.1,
      "step": 1726,
      "total_loss": 0.6458315849304199,
      "weighted_orthogonal_loss": 0.01648414321243763
    },
    {
      "classification_loss": 0.6769880652427673,
      "epoch": 5.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16472361981868744,
      "orthogonal_weight": 0.1,
      "step": 1727,
      "total_loss": 0.6934604048728943,
      "weighted_orthogonal_loss": 0.016472361981868744
    },
    {
      "classification_loss": 0.7203363180160522,
      "epoch": 5.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16451802849769592,
      "orthogonal_weight": 0.1,
      "step": 1728,
      "total_loss": 0.7367880940437317,
      "weighted_orthogonal_loss": 0.016451803967356682
    },
    {
      "classification_loss": 0.6462860107421875,
      "epoch": 5.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16432560980319977,
      "orthogonal_weight": 0.1,
      "step": 1729,
      "total_loss": 0.6627185940742493,
      "weighted_orthogonal_loss": 0.016432560980319977
    },
    {
      "classification_loss": 0.667766273021698,
      "epoch": 5.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16421115398406982,
      "orthogonal_weight": 0.1,
      "step": 1730,
      "total_loss": 0.6841874122619629,
      "weighted_orthogonal_loss": 0.016421115025877953
    },
    {
      "classification_loss": 0.6608986854553223,
      "epoch": 5.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16409660875797272,
      "orthogonal_weight": 0.1,
      "step": 1731,
      "total_loss": 0.6773083209991455,
      "weighted_orthogonal_loss": 0.01640966162085533
    },
    {
      "classification_loss": 0.5954743027687073,
      "epoch": 5.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640091985464096,
      "orthogonal_weight": 0.1,
      "step": 1732,
      "total_loss": 0.6118752360343933,
      "weighted_orthogonal_loss": 0.01640092022716999
    },
    {
      "classification_loss": 0.662136435508728,
      "epoch": 5.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16391444206237793,
      "orthogonal_weight": 0.1,
      "step": 1733,
      "total_loss": 0.6785278916358948,
      "weighted_orthogonal_loss": 0.016391444951295853
    },
    {
      "classification_loss": 0.6242172122001648,
      "epoch": 5.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16383050382137299,
      "orthogonal_weight": 0.1,
      "step": 1734,
      "total_loss": 0.6406002640724182,
      "weighted_orthogonal_loss": 0.01638305000960827
    },
    {
      "classification_loss": 0.6372223496437073,
      "epoch": 5.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16372708976268768,
      "orthogonal_weight": 0.1,
      "step": 1735,
      "total_loss": 0.6535950303077698,
      "weighted_orthogonal_loss": 0.01637270860373974
    },
    {
      "classification_loss": 0.6713642477989197,
      "epoch": 5.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1635984629392624,
      "orthogonal_weight": 0.1,
      "step": 1736,
      "total_loss": 0.6877241134643555,
      "weighted_orthogonal_loss": 0.0163598470389843
    },
    {
      "classification_loss": 0.664101243019104,
      "epoch": 5.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16345934569835663,
      "orthogonal_weight": 0.1,
      "step": 1737,
      "total_loss": 0.6804471611976624,
      "weighted_orthogonal_loss": 0.016345934942364693
    },
    {
      "classification_loss": 0.6151992678642273,
      "epoch": 5.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16332152485847473,
      "orthogonal_weight": 0.1,
      "step": 1738,
      "total_loss": 0.6315314173698425,
      "weighted_orthogonal_loss": 0.016332153230905533
    },
    {
      "classification_loss": 0.6450965404510498,
      "epoch": 5.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1632899045944214,
      "orthogonal_weight": 0.1,
      "step": 1739,
      "total_loss": 0.6614255309104919,
      "weighted_orthogonal_loss": 0.01632899045944214
    },
    {
      "classification_loss": 0.6045035123825073,
      "epoch": 5.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16332028806209564,
      "orthogonal_weight": 0.1,
      "step": 1740,
      "total_loss": 0.620835542678833,
      "weighted_orthogonal_loss": 0.016332028433680534
    },
    {
      "classification_loss": 0.701342761516571,
      "epoch": 5.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335757076740265,
      "orthogonal_weight": 0.1,
      "step": 1741,
      "total_loss": 0.7176785469055176,
      "weighted_orthogonal_loss": 0.016335757449269295
    },
    {
      "classification_loss": 0.6428819298744202,
      "epoch": 5.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1632147580385208,
      "orthogonal_weight": 0.1,
      "step": 1742,
      "total_loss": 0.6592034101486206,
      "weighted_orthogonal_loss": 0.01632147654891014
    },
    {
      "classification_loss": 0.6888085007667542,
      "epoch": 5.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16308121383190155,
      "orthogonal_weight": 0.1,
      "step": 1743,
      "total_loss": 0.7051166296005249,
      "weighted_orthogonal_loss": 0.016308121383190155
    },
    {
      "classification_loss": 0.6494780778884888,
      "epoch": 5.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287179291248322,
      "orthogonal_weight": 0.1,
      "step": 1744,
      "total_loss": 0.6657652854919434,
      "weighted_orthogonal_loss": 0.01628717966377735
    },
    {
      "classification_loss": 0.6472167372703552,
      "epoch": 5.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16267578303813934,
      "orthogonal_weight": 0.1,
      "step": 1745,
      "total_loss": 0.6634843349456787,
      "weighted_orthogonal_loss": 0.016267579048871994
    },
    {
      "classification_loss": 0.6392390131950378,
      "epoch": 5.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16250503063201904,
      "orthogonal_weight": 0.1,
      "step": 1746,
      "total_loss": 0.6554895043373108,
      "weighted_orthogonal_loss": 0.016250504180788994
    },
    {
      "classification_loss": 0.6623365879058838,
      "epoch": 5.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16241969168186188,
      "orthogonal_weight": 0.1,
      "step": 1747,
      "total_loss": 0.6785785555839539,
      "weighted_orthogonal_loss": 0.016241969540715218
    },
    {
      "classification_loss": 0.6861165165901184,
      "epoch": 5.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16233548521995544,
      "orthogonal_weight": 0.1,
      "step": 1748,
      "total_loss": 0.7023500800132751,
      "weighted_orthogonal_loss": 0.016233548521995544
    },
    {
      "classification_loss": 0.650903582572937,
      "epoch": 5.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1622048318386078,
      "orthogonal_weight": 0.1,
      "step": 1749,
      "total_loss": 0.6671240925788879,
      "weighted_orthogonal_loss": 0.01622048392891884
    },
    {
      "classification_loss": 0.6529428958892822,
      "epoch": 5.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16204123198986053,
      "orthogonal_weight": 0.1,
      "step": 1750,
      "total_loss": 0.6691470146179199,
      "weighted_orthogonal_loss": 0.016204124316573143
    },
    {
      "classification_loss": 0.6397039890289307,
      "epoch": 5.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16191859543323517,
      "orthogonal_weight": 0.1,
      "step": 1751,
      "total_loss": 0.6558958292007446,
      "weighted_orthogonal_loss": 0.016191860660910606
    },
    {
      "classification_loss": 0.6627450585365295,
      "epoch": 5.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16175192594528198,
      "orthogonal_weight": 0.1,
      "step": 1752,
      "total_loss": 0.6789202690124512,
      "weighted_orthogonal_loss": 0.016175193712115288
    },
    {
      "classification_loss": 0.6446070075035095,
      "epoch": 5.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16163676977157593,
      "orthogonal_weight": 0.1,
      "step": 1753,
      "total_loss": 0.6607706546783447,
      "weighted_orthogonal_loss": 0.016163676977157593
    },
    {
      "classification_loss": 0.6552030444145203,
      "epoch": 5.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615048050880432,
      "orthogonal_weight": 0.1,
      "step": 1754,
      "total_loss": 0.6713535189628601,
      "weighted_orthogonal_loss": 0.01615048013627529
    },
    {
      "classification_loss": 0.676072359085083,
      "epoch": 5.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1613302230834961,
      "orthogonal_weight": 0.1,
      "step": 1755,
      "total_loss": 0.6922053694725037,
      "weighted_orthogonal_loss": 0.0161330234259367
    },
    {
      "classification_loss": 0.6777895092964172,
      "epoch": 5.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1612086296081543,
      "orthogonal_weight": 0.1,
      "step": 1756,
      "total_loss": 0.6939103603363037,
      "weighted_orthogonal_loss": 0.01612086407840252
    },
    {
      "classification_loss": 0.6294226050376892,
      "epoch": 5.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16092318296432495,
      "orthogonal_weight": 0.1,
      "step": 1757,
      "total_loss": 0.6455149054527283,
      "weighted_orthogonal_loss": 0.016092319041490555
    },
    {
      "classification_loss": 0.6189154982566833,
      "epoch": 5.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16070713102817535,
      "orthogonal_weight": 0.1,
      "step": 1758,
      "total_loss": 0.6349862217903137,
      "weighted_orthogonal_loss": 0.016070714220404625
    },
    {
      "classification_loss": 0.6771746277809143,
      "epoch": 5.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16061101853847504,
      "orthogonal_weight": 0.1,
      "step": 1759,
      "total_loss": 0.6932357549667358,
      "weighted_orthogonal_loss": 0.016061102971434593
    },
    {
      "classification_loss": 0.6777815818786621,
      "epoch": 5.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605139970779419,
      "orthogonal_weight": 0.1,
      "step": 1760,
      "total_loss": 0.6938329935073853,
      "weighted_orthogonal_loss": 0.01605140045285225
    },
    {
      "classification_loss": 0.610298216342926,
      "epoch": 5.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16049882769584656,
      "orthogonal_weight": 0.1,
      "step": 1761,
      "total_loss": 0.626348078250885,
      "weighted_orthogonal_loss": 0.016049882397055626
    },
    {
      "classification_loss": 0.6758063435554504,
      "epoch": 5.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16051089763641357,
      "orthogonal_weight": 0.1,
      "step": 1762,
      "total_loss": 0.6918574571609497,
      "weighted_orthogonal_loss": 0.016051089391112328
    },
    {
      "classification_loss": 0.6048843264579773,
      "epoch": 5.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16055722534656525,
      "orthogonal_weight": 0.1,
      "step": 1763,
      "total_loss": 0.6209400296211243,
      "weighted_orthogonal_loss": 0.016055723652243614
    },
    {
      "classification_loss": 0.6638659238815308,
      "epoch": 5.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16061845421791077,
      "orthogonal_weight": 0.1,
      "step": 1764,
      "total_loss": 0.6799277663230896,
      "weighted_orthogonal_loss": 0.016061846166849136
    },
    {
      "classification_loss": 0.6154826879501343,
      "epoch": 5.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16056428849697113,
      "orthogonal_weight": 0.1,
      "step": 1765,
      "total_loss": 0.6315391063690186,
      "weighted_orthogonal_loss": 0.016056429594755173
    },
    {
      "classification_loss": 0.6218284964561462,
      "epoch": 5.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054384410381317,
      "orthogonal_weight": 0.1,
      "step": 1766,
      "total_loss": 0.6378828883171082,
      "weighted_orthogonal_loss": 0.016054384410381317
    },
    {
      "classification_loss": 0.6577534675598145,
      "epoch": 5.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054534912109375,
      "orthogonal_weight": 0.1,
      "step": 1767,
      "total_loss": 0.6738079786300659,
      "weighted_orthogonal_loss": 0.016054535284638405
    },
    {
      "classification_loss": 0.6548505425453186,
      "epoch": 5.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054154932498932,
      "orthogonal_weight": 0.1,
      "step": 1768,
      "total_loss": 0.6709046959877014,
      "weighted_orthogonal_loss": 0.01605415530502796
    },
    {
      "classification_loss": 0.6120320558547974,
      "epoch": 5.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605483740568161,
      "orthogonal_weight": 0.1,
      "step": 1769,
      "total_loss": 0.6280868649482727,
      "weighted_orthogonal_loss": 0.01605483703315258
    },
    {
      "classification_loss": 0.5951954126358032,
      "epoch": 5.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605890542268753,
      "orthogonal_weight": 0.1,
      "step": 1770,
      "total_loss": 0.6112543344497681,
      "weighted_orthogonal_loss": 0.0160589050501585
    },
    {
      "classification_loss": 0.6002973318099976,
      "epoch": 5.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16060644388198853,
      "orthogonal_weight": 0.1,
      "step": 1771,
      "total_loss": 0.6163579821586609,
      "weighted_orthogonal_loss": 0.016060644760727882
    },
    {
      "classification_loss": 0.6777954697608948,
      "epoch": 5.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606632024049759,
      "orthogonal_weight": 0.1,
      "step": 1772,
      "total_loss": 0.6938617825508118,
      "weighted_orthogonal_loss": 0.01606632024049759
    },
    {
      "classification_loss": 0.657680094242096,
      "epoch": 5.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16070033609867096,
      "orthogonal_weight": 0.1,
      "step": 1773,
      "total_loss": 0.673750102519989,
      "weighted_orthogonal_loss": 0.016070034354925156
    },
    {
      "classification_loss": 0.6555195450782776,
      "epoch": 5.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16075806319713593,
      "orthogonal_weight": 0.1,
      "step": 1774,
      "total_loss": 0.6715953350067139,
      "weighted_orthogonal_loss": 0.016075806692242622
    },
    {
      "classification_loss": 0.6390849351882935,
      "epoch": 5.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1607784777879715,
      "orthogonal_weight": 0.1,
      "step": 1775,
      "total_loss": 0.6551628112792969,
      "weighted_orthogonal_loss": 0.01607784815132618
    },
    {
      "classification_loss": 0.6916186809539795,
      "epoch": 5.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076631844043732,
      "orthogonal_weight": 0.1,
      "step": 1776,
      "total_loss": 0.7076953053474426,
      "weighted_orthogonal_loss": 0.01607663184404373
    },
    {
      "classification_loss": 0.6732267737388611,
      "epoch": 5.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076473891735077,
      "orthogonal_weight": 0.1,
      "step": 1777,
      "total_loss": 0.6893032193183899,
      "weighted_orthogonal_loss": 0.016076473519206047
    },
    {
      "classification_loss": 0.6414340734481812,
      "epoch": 5.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16078807413578033,
      "orthogonal_weight": 0.1,
      "step": 1778,
      "total_loss": 0.657512903213501,
      "weighted_orthogonal_loss": 0.016078807413578033
    },
    {
      "classification_loss": 0.5765182971954346,
      "epoch": 5.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16093367338180542,
      "orthogonal_weight": 0.1,
      "step": 1779,
      "total_loss": 0.5926116704940796,
      "weighted_orthogonal_loss": 0.016093367710709572
    },
    {
      "classification_loss": 0.6162099838256836,
      "epoch": 5.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16107511520385742,
      "orthogonal_weight": 0.1,
      "step": 1780,
      "total_loss": 0.6323174834251404,
      "weighted_orthogonal_loss": 0.01610751263797283
    },
    {
      "classification_loss": 0.6412322521209717,
      "epoch": 5.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16126053035259247,
      "orthogonal_weight": 0.1,
      "step": 1781,
      "total_loss": 0.6573582887649536,
      "weighted_orthogonal_loss": 0.016126053407788277
    },
    {
      "classification_loss": 0.6578768491744995,
      "epoch": 5.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615331918001175,
      "orthogonal_weight": 0.1,
      "step": 1782,
      "total_loss": 0.6740301847457886,
      "weighted_orthogonal_loss": 0.01615331880748272
    },
    {
      "classification_loss": 0.6318945288658142,
      "epoch": 5.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1618470698595047,
      "orthogonal_weight": 0.1,
      "step": 1783,
      "total_loss": 0.6480792164802551,
      "weighted_orthogonal_loss": 0.01618470810353756
    },
    {
      "classification_loss": 0.6894680261611938,
      "epoch": 5.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16218434274196625,
      "orthogonal_weight": 0.1,
      "step": 1784,
      "total_loss": 0.7056864500045776,
      "weighted_orthogonal_loss": 0.016218435019254684
    },
    {
      "classification_loss": 0.5970689058303833,
      "epoch": 5.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16238120198249817,
      "orthogonal_weight": 0.1,
      "step": 1785,
      "total_loss": 0.613306999206543,
      "weighted_orthogonal_loss": 0.016238121315836906
    },
    {
      "classification_loss": 0.6623458862304688,
      "epoch": 5.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16257601976394653,
      "orthogonal_weight": 0.1,
      "step": 1786,
      "total_loss": 0.67860347032547,
      "weighted_orthogonal_loss": 0.016257602721452713
    },
    {
      "classification_loss": 0.6074020862579346,
      "epoch": 5.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1627763956785202,
      "orthogonal_weight": 0.1,
      "step": 1787,
      "total_loss": 0.6236796975135803,
      "weighted_orthogonal_loss": 0.01627763919532299
    },
    {
      "classification_loss": 0.6594957709312439,
      "epoch": 5.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16296900808811188,
      "orthogonal_weight": 0.1,
      "step": 1788,
      "total_loss": 0.6757926940917969,
      "weighted_orthogonal_loss": 0.016296900808811188
    },
    {
      "classification_loss": 0.7303141355514526,
      "epoch": 5.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16320161521434784,
      "orthogonal_weight": 0.1,
      "step": 1789,
      "total_loss": 0.746634304523468,
      "weighted_orthogonal_loss": 0.016320161521434784
    },
    {
      "classification_loss": 0.6400453448295593,
      "epoch": 5.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16341429948806763,
      "orthogonal_weight": 0.1,
      "step": 1790,
      "total_loss": 0.6563867926597595,
      "weighted_orthogonal_loss": 0.016341431066393852
    },
    {
      "classification_loss": 0.5974707007408142,
      "epoch": 5.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16360649466514587,
      "orthogonal_weight": 0.1,
      "step": 1791,
      "total_loss": 0.6138313412666321,
      "weighted_orthogonal_loss": 0.016360649839043617
    },
    {
      "classification_loss": 0.6123889088630676,
      "epoch": 5.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1638987809419632,
      "orthogonal_weight": 0.1,
      "step": 1792,
      "total_loss": 0.6287788152694702,
      "weighted_orthogonal_loss": 0.01638987846672535
    },
    {
      "classification_loss": 0.6740556955337524,
      "epoch": 5.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16421133279800415,
      "orthogonal_weight": 0.1,
      "step": 1793,
      "total_loss": 0.6904768347740173,
      "weighted_orthogonal_loss": 0.016421133652329445
    },
    {
      "classification_loss": 0.6541404724121094,
      "epoch": 5.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1644706130027771,
      "orthogonal_weight": 0.1,
      "step": 1794,
      "total_loss": 0.6705875396728516,
      "weighted_orthogonal_loss": 0.01644706167280674
    },
    {
      "classification_loss": 0.673378586769104,
      "epoch": 5.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16462615132331848,
      "orthogonal_weight": 0.1,
      "step": 1795,
      "total_loss": 0.6898412108421326,
      "weighted_orthogonal_loss": 0.01646261475980282
    },
    {
      "classification_loss": 0.6205494999885559,
      "epoch": 5.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1647643744945526,
      "orthogonal_weight": 0.1,
      "step": 1796,
      "total_loss": 0.6370259523391724,
      "weighted_orthogonal_loss": 0.01647643744945526
    },
    {
      "classification_loss": 0.652569055557251,
      "epoch": 5.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16490429639816284,
      "orthogonal_weight": 0.1,
      "step": 1797,
      "total_loss": 0.6690595149993896,
      "weighted_orthogonal_loss": 0.016490429639816284
    },
    {
      "classification_loss": 0.6748897433280945,
      "epoch": 5.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16506072878837585,
      "orthogonal_weight": 0.1,
      "step": 1798,
      "total_loss": 0.6913958191871643,
      "weighted_orthogonal_loss": 0.016506073996424675
    },
    {
      "classification_loss": 0.6346562504768372,
      "epoch": 5.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16524766385555267,
      "orthogonal_weight": 0.1,
      "step": 1799,
      "total_loss": 0.6511810421943665,
      "weighted_orthogonal_loss": 0.016524767503142357
    },
    {
      "epoch": 5.901639344262295,
      "grad_norm": 25.319889068603516,
      "learning_rate": 0.00014336666666666666,
      "loss": 0.6643,
      "step": 1800
    },
    {
      "classification_loss": 0.7190911173820496,
      "epoch": 5.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16539183259010315,
      "orthogonal_weight": 0.1,
      "step": 1800,
      "total_loss": 0.7356302738189697,
      "weighted_orthogonal_loss": 0.016539184376597404
    },
    {
      "classification_loss": 0.6816847324371338,
      "epoch": 5.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16549931466579437,
      "orthogonal_weight": 0.1,
      "step": 1801,
      "total_loss": 0.6982346773147583,
      "weighted_orthogonal_loss": 0.016549931839108467
    },
    {
      "classification_loss": 0.7259564399719238,
      "epoch": 5.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16556622087955475,
      "orthogonal_weight": 0.1,
      "step": 1802,
      "total_loss": 0.7425130605697632,
      "weighted_orthogonal_loss": 0.016556622460484505
    },
    {
      "classification_loss": 0.6898894906044006,
      "epoch": 5.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16543345153331757,
      "orthogonal_weight": 0.1,
      "step": 1803,
      "total_loss": 0.7064328193664551,
      "weighted_orthogonal_loss": 0.016543345525860786
    },
    {
      "classification_loss": 0.6953454613685608,
      "epoch": 5.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16517934203147888,
      "orthogonal_weight": 0.1,
      "step": 1804,
      "total_loss": 0.7118633985519409,
      "weighted_orthogonal_loss": 0.016517935320734978
    },
    {
      "classification_loss": 0.637880265712738,
      "epoch": 5.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16493169963359833,
      "orthogonal_weight": 0.1,
      "step": 1805,
      "total_loss": 0.6543734073638916,
      "weighted_orthogonal_loss": 0.016493169590830803
    },
    {
      "classification_loss": 0.6280145645141602,
      "epoch": 5.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16470710933208466,
      "orthogonal_weight": 0.1,
      "step": 1806,
      "total_loss": 0.6444852948188782,
      "weighted_orthogonal_loss": 0.016470711678266525
    },
    {
      "classification_loss": 0.6531400680541992,
      "epoch": 5.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1645258218050003,
      "orthogonal_weight": 0.1,
      "step": 1807,
      "total_loss": 0.6695926785469055,
      "weighted_orthogonal_loss": 0.01645258255302906
    },
    {
      "classification_loss": 0.6452316045761108,
      "epoch": 5.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.164427250623703,
      "orthogonal_weight": 0.1,
      "step": 1808,
      "total_loss": 0.6616743206977844,
      "weighted_orthogonal_loss": 0.01644272543489933
    },
    {
      "classification_loss": 0.6193230748176575,
      "epoch": 5.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16432620584964752,
      "orthogonal_weight": 0.1,
      "step": 1809,
      "total_loss": 0.635755717754364,
      "weighted_orthogonal_loss": 0.016432620584964752
    },
    {
      "classification_loss": 0.6114850640296936,
      "epoch": 5.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1642528623342514,
      "orthogonal_weight": 0.1,
      "step": 1810,
      "total_loss": 0.6279103755950928,
      "weighted_orthogonal_loss": 0.01642528735101223
    },
    {
      "classification_loss": 0.6831453442573547,
      "epoch": 5.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16420085728168488,
      "orthogonal_weight": 0.1,
      "step": 1811,
      "total_loss": 0.6995654106140137,
      "weighted_orthogonal_loss": 0.016420086845755577
    },
    {
      "classification_loss": 0.6602742671966553,
      "epoch": 5.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16418594121932983,
      "orthogonal_weight": 0.1,
      "step": 1812,
      "total_loss": 0.6766928434371948,
      "weighted_orthogonal_loss": 0.016418594866991043
    },
    {
      "classification_loss": 0.6487450003623962,
      "epoch": 5.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16416291892528534,
      "orthogonal_weight": 0.1,
      "step": 1813,
      "total_loss": 0.6651613116264343,
      "weighted_orthogonal_loss": 0.016416292637586594
    },
    {
      "classification_loss": 0.6365559101104736,
      "epoch": 5.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16410602629184723,
      "orthogonal_weight": 0.1,
      "step": 1814,
      "total_loss": 0.6529664993286133,
      "weighted_orthogonal_loss": 0.016410602256655693
    },
    {
      "classification_loss": 0.6288722157478333,
      "epoch": 5.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640433371067047,
      "orthogonal_weight": 0.1,
      "step": 1815,
      "total_loss": 0.6452765464782715,
      "weighted_orthogonal_loss": 0.01640433445572853
    },
    {
      "classification_loss": 0.6604385375976562,
      "epoch": 5.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16400733590126038,
      "orthogonal_weight": 0.1,
      "step": 1816,
      "total_loss": 0.676839292049408,
      "weighted_orthogonal_loss": 0.016400733962655067
    },
    {
      "classification_loss": 0.6361360549926758,
      "epoch": 5.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16395682096481323,
      "orthogonal_weight": 0.1,
      "step": 1817,
      "total_loss": 0.6525317430496216,
      "weighted_orthogonal_loss": 0.016395682469010353
    },
    {
      "classification_loss": 0.6548715829849243,
      "epoch": 5.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16389010846614838,
      "orthogonal_weight": 0.1,
      "step": 1818,
      "total_loss": 0.6712605953216553,
      "weighted_orthogonal_loss": 0.016389010474085808
    },
    {
      "classification_loss": 0.6450283527374268,
      "epoch": 5.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1637989729642868,
      "orthogonal_weight": 0.1,
      "step": 1819,
      "total_loss": 0.6614082455635071,
      "weighted_orthogonal_loss": 0.01637989841401577
    },
    {
      "classification_loss": 0.6262301802635193,
      "epoch": 5.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16374047100543976,
      "orthogonal_weight": 0.1,
      "step": 1820,
      "total_loss": 0.6426042318344116,
      "weighted_orthogonal_loss": 0.016374047845602036
    },
    {
      "classification_loss": 0.6183348894119263,
      "epoch": 5.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16361744701862335,
      "orthogonal_weight": 0.1,
      "step": 1821,
      "total_loss": 0.6346966624259949,
      "weighted_orthogonal_loss": 0.016361745074391365
    },
    {
      "classification_loss": 0.6447731852531433,
      "epoch": 5.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16352875530719757,
      "orthogonal_weight": 0.1,
      "step": 1822,
      "total_loss": 0.6611260771751404,
      "weighted_orthogonal_loss": 0.016352875158190727
    },
    {
      "classification_loss": 0.6634339690208435,
      "epoch": 5.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16345107555389404,
      "orthogonal_weight": 0.1,
      "step": 1823,
      "total_loss": 0.679779052734375,
      "weighted_orthogonal_loss": 0.016345107927918434
    },
    {
      "classification_loss": 0.5892078280448914,
      "epoch": 5.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16336600482463837,
      "orthogonal_weight": 0.1,
      "step": 1824,
      "total_loss": 0.6055444478988647,
      "weighted_orthogonal_loss": 0.016336601227521896
    },
    {
      "classification_loss": 0.6369319558143616,
      "epoch": 5.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16333475708961487,
      "orthogonal_weight": 0.1,
      "step": 1825,
      "total_loss": 0.6532654166221619,
      "weighted_orthogonal_loss": 0.016333475708961487
    },
    {
      "classification_loss": 0.6340441107749939,
      "epoch": 5.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335101425647736,
      "orthogonal_weight": 0.1,
      "step": 1826,
      "total_loss": 0.6503792405128479,
      "weighted_orthogonal_loss": 0.016335101798176765
    },
    {
      "classification_loss": 0.6232616901397705,
      "epoch": 5.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335968673229218,
      "orthogonal_weight": 0.1,
      "step": 1827,
      "total_loss": 0.6395976543426514,
      "weighted_orthogonal_loss": 0.016335969790816307
    },
    {
      "classification_loss": 0.6094842553138733,
      "epoch": 5.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16325446963310242,
      "orthogonal_weight": 0.1,
      "step": 1828,
      "total_loss": 0.6258097290992737,
      "weighted_orthogonal_loss": 0.0163254477083683
    },
    {
      "classification_loss": 0.6153846979141235,
      "epoch": 5.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312427818775177,
      "orthogonal_weight": 0.1,
      "step": 1829,
      "total_loss": 0.6316971182823181,
      "weighted_orthogonal_loss": 0.016312427818775177
    },
    {
      "classification_loss": 0.6650094985961914,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6813210248947144,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.7064411640167236,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7227526903152466,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.651926577091217,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.66823810338974,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.666741132736206,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.683052659034729,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6847022771835327,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7010138034820557,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6556127071380615,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6719242334365845,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.646679699420929,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6629912257194519,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6954214572906494,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7117329835891724,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.585,
      "eval_f1": 0.7220361687876758,
      "eval_loss": 0.6873058080673218,
      "eval_precision": 0.6195402298850575,
      "eval_recall": 0.8651685393258427,
      "eval_runtime": 6.13,
      "eval_samples_per_second": 163.133,
      "eval_steps_per_second": 1.305,
      "step": 1830
    }
  ],
  "logging_steps": 100,
  "max_steps": 6100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4697322820853760.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
