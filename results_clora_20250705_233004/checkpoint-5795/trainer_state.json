{
  "best_global_step": 1830,
  "best_metric": 0.7220361687876758,
  "best_model_checkpoint": "./results_clora_20250705_233004/checkpoint-1830",
  "epoch": 19.0,
  "eval_steps": 500,
  "global_step": 5795,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "classification_loss": 6.029106140136719,
      "epoch": 0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6689748764038086,
      "orthogonal_weight": 0.1,
      "step": 0,
      "total_loss": 6.296003818511963,
      "weighted_orthogonal_loss": 0.2668974995613098
    },
    {
      "classification_loss": 5.26099967956543,
      "epoch": 0.003278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6689748764038086,
      "orthogonal_weight": 0.1,
      "step": 1,
      "total_loss": 5.527897357940674,
      "weighted_orthogonal_loss": 0.2668974995613098
    },
    {
      "classification_loss": 6.7860026359558105,
      "epoch": 0.006557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6683950424194336,
      "orthogonal_weight": 0.1,
      "step": 2,
      "total_loss": 7.052842140197754,
      "weighted_orthogonal_loss": 0.26683950424194336
    },
    {
      "classification_loss": 6.7634358406066895,
      "epoch": 0.009836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.667250871658325,
      "orthogonal_weight": 0.1,
      "step": 3,
      "total_loss": 7.030160903930664,
      "weighted_orthogonal_loss": 0.266725093126297
    },
    {
      "classification_loss": 7.246151447296143,
      "epoch": 0.013114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.665543556213379,
      "orthogonal_weight": 0.1,
      "step": 4,
      "total_loss": 7.5127058029174805,
      "weighted_orthogonal_loss": 0.2665543556213379
    },
    {
      "classification_loss": 5.674765586853027,
      "epoch": 0.01639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6632893085479736,
      "orthogonal_weight": 0.1,
      "step": 5,
      "total_loss": 5.941094398498535,
      "weighted_orthogonal_loss": 0.26632893085479736
    },
    {
      "classification_loss": 7.140424728393555,
      "epoch": 0.019672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.660460948944092,
      "orthogonal_weight": 0.1,
      "step": 6,
      "total_loss": 7.406470775604248,
      "weighted_orthogonal_loss": 0.26604610681533813
    },
    {
      "classification_loss": 7.132098197937012,
      "epoch": 0.022950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6571168899536133,
      "orthogonal_weight": 0.1,
      "step": 7,
      "total_loss": 7.397809982299805,
      "weighted_orthogonal_loss": 0.2657116949558258
    },
    {
      "classification_loss": 6.112251281738281,
      "epoch": 0.02622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6532886028289795,
      "orthogonal_weight": 0.1,
      "step": 8,
      "total_loss": 6.377580165863037,
      "weighted_orthogonal_loss": 0.26532885432243347
    },
    {
      "classification_loss": 6.752294540405273,
      "epoch": 0.029508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6489667892456055,
      "orthogonal_weight": 0.1,
      "step": 9,
      "total_loss": 7.017191410064697,
      "weighted_orthogonal_loss": 0.2648966908454895
    },
    {
      "classification_loss": 4.769307613372803,
      "epoch": 0.03278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.644219160079956,
      "orthogonal_weight": 0.1,
      "step": 10,
      "total_loss": 5.033729553222656,
      "weighted_orthogonal_loss": 0.26442191004753113
    },
    {
      "classification_loss": 6.934882164001465,
      "epoch": 0.036065573770491806,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6389694213867188,
      "orthogonal_weight": 0.1,
      "step": 11,
      "total_loss": 7.198779106140137,
      "weighted_orthogonal_loss": 0.2638969421386719
    },
    {
      "classification_loss": 6.747993469238281,
      "epoch": 0.03934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6334264278411865,
      "orthogonal_weight": 0.1,
      "step": 12,
      "total_loss": 7.011336326599121,
      "weighted_orthogonal_loss": 0.26334264874458313
    },
    {
      "classification_loss": 7.058483600616455,
      "epoch": 0.04262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.627656936645508,
      "orthogonal_weight": 0.1,
      "step": 13,
      "total_loss": 7.321249485015869,
      "weighted_orthogonal_loss": 0.26276570558547974
    },
    {
      "classification_loss": 6.772679328918457,
      "epoch": 0.04590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.62174129486084,
      "orthogonal_weight": 0.1,
      "step": 14,
      "total_loss": 7.034853458404541,
      "weighted_orthogonal_loss": 0.262174129486084
    },
    {
      "classification_loss": 5.077550411224365,
      "epoch": 0.04918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6157190799713135,
      "orthogonal_weight": 0.1,
      "step": 15,
      "total_loss": 5.339122295379639,
      "weighted_orthogonal_loss": 0.2615719139575958
    },
    {
      "classification_loss": 6.445642471313477,
      "epoch": 0.05245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.609454870223999,
      "orthogonal_weight": 0.1,
      "step": 16,
      "total_loss": 6.706587791442871,
      "weighted_orthogonal_loss": 0.26094549894332886
    },
    {
      "classification_loss": 5.5243353843688965,
      "epoch": 0.05573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6032156944274902,
      "orthogonal_weight": 0.1,
      "step": 17,
      "total_loss": 5.784657001495361,
      "weighted_orthogonal_loss": 0.26032158732414246
    },
    {
      "classification_loss": 7.282344818115234,
      "epoch": 0.05901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.596896171569824,
      "orthogonal_weight": 0.1,
      "step": 18,
      "total_loss": 7.54203462600708,
      "weighted_orthogonal_loss": 0.2596896290779114
    },
    {
      "classification_loss": 6.820548057556152,
      "epoch": 0.06229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5907387733459473,
      "orthogonal_weight": 0.1,
      "step": 19,
      "total_loss": 7.0796217918396,
      "weighted_orthogonal_loss": 0.2590738832950592
    },
    {
      "classification_loss": 6.7228899002075195,
      "epoch": 0.06557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5847160816192627,
      "orthogonal_weight": 0.1,
      "step": 20,
      "total_loss": 6.981361389160156,
      "weighted_orthogonal_loss": 0.25847160816192627
    },
    {
      "classification_loss": 5.326779365539551,
      "epoch": 0.06885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.578901767730713,
      "orthogonal_weight": 0.1,
      "step": 21,
      "total_loss": 5.584669589996338,
      "weighted_orthogonal_loss": 0.2578901946544647
    },
    {
      "classification_loss": 5.278411388397217,
      "epoch": 0.07213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.57309889793396,
      "orthogonal_weight": 0.1,
      "step": 22,
      "total_loss": 5.535721302032471,
      "weighted_orthogonal_loss": 0.2573098838329315
    },
    {
      "classification_loss": 6.287415504455566,
      "epoch": 0.07540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5674164295196533,
      "orthogonal_weight": 0.1,
      "step": 23,
      "total_loss": 6.544157028198242,
      "weighted_orthogonal_loss": 0.25674164295196533
    },
    {
      "classification_loss": 5.367364883422852,
      "epoch": 0.07868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5620079040527344,
      "orthogonal_weight": 0.1,
      "step": 24,
      "total_loss": 5.623565673828125,
      "weighted_orthogonal_loss": 0.25620079040527344
    },
    {
      "classification_loss": 5.69620418548584,
      "epoch": 0.08196721311475409,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.556762933731079,
      "orthogonal_weight": 0.1,
      "step": 25,
      "total_loss": 5.95188045501709,
      "weighted_orthogonal_loss": 0.2556762993335724
    },
    {
      "classification_loss": 5.254683971405029,
      "epoch": 0.08524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.551814556121826,
      "orthogonal_weight": 0.1,
      "step": 26,
      "total_loss": 5.5098652839660645,
      "weighted_orthogonal_loss": 0.2551814615726471
    },
    {
      "classification_loss": 5.507903099060059,
      "epoch": 0.08852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5470831394195557,
      "orthogonal_weight": 0.1,
      "step": 27,
      "total_loss": 5.762611389160156,
      "weighted_orthogonal_loss": 0.25470831990242004
    },
    {
      "classification_loss": 4.623619079589844,
      "epoch": 0.09180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5427157878875732,
      "orthogonal_weight": 0.1,
      "step": 28,
      "total_loss": 4.877890586853027,
      "weighted_orthogonal_loss": 0.25427159667015076
    },
    {
      "classification_loss": 6.627934455871582,
      "epoch": 0.09508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.538606643676758,
      "orthogonal_weight": 0.1,
      "step": 29,
      "total_loss": 6.8817949295043945,
      "weighted_orthogonal_loss": 0.2538606822490692
    },
    {
      "classification_loss": 4.975618839263916,
      "epoch": 0.09836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5349950790405273,
      "orthogonal_weight": 0.1,
      "step": 30,
      "total_loss": 5.229118347167969,
      "weighted_orthogonal_loss": 0.25349950790405273
    },
    {
      "classification_loss": 5.713532447814941,
      "epoch": 0.10163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.531794548034668,
      "orthogonal_weight": 0.1,
      "step": 31,
      "total_loss": 5.96671199798584,
      "weighted_orthogonal_loss": 0.2531794607639313
    },
    {
      "classification_loss": 5.490506649017334,
      "epoch": 0.10491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.529078483581543,
      "orthogonal_weight": 0.1,
      "step": 32,
      "total_loss": 5.743414402008057,
      "weighted_orthogonal_loss": 0.2529078423976898
    },
    {
      "classification_loss": 3.672903299331665,
      "epoch": 0.10819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.526867389678955,
      "orthogonal_weight": 0.1,
      "step": 33,
      "total_loss": 3.9255900382995605,
      "weighted_orthogonal_loss": 0.2526867389678955
    },
    {
      "classification_loss": 4.524785041809082,
      "epoch": 0.11147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5250084400177,
      "orthogonal_weight": 0.1,
      "step": 34,
      "total_loss": 4.777286052703857,
      "weighted_orthogonal_loss": 0.25250086188316345
    },
    {
      "classification_loss": 5.16352653503418,
      "epoch": 0.11475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5236823558807373,
      "orthogonal_weight": 0.1,
      "step": 35,
      "total_loss": 5.415894985198975,
      "weighted_orthogonal_loss": 0.2523682415485382
    },
    {
      "classification_loss": 4.898519515991211,
      "epoch": 0.1180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.522979497909546,
      "orthogonal_weight": 0.1,
      "step": 36,
      "total_loss": 5.150817394256592,
      "weighted_orthogonal_loss": 0.252297967672348
    },
    {
      "classification_loss": 5.681025505065918,
      "epoch": 0.12131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.522891044616699,
      "orthogonal_weight": 0.1,
      "step": 37,
      "total_loss": 5.933314800262451,
      "weighted_orthogonal_loss": 0.2522891163825989
    },
    {
      "classification_loss": 4.990190029144287,
      "epoch": 0.12459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.523538589477539,
      "orthogonal_weight": 0.1,
      "step": 38,
      "total_loss": 5.242543697357178,
      "weighted_orthogonal_loss": 0.25235387682914734
    },
    {
      "classification_loss": 4.978434085845947,
      "epoch": 0.12786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.524894952774048,
      "orthogonal_weight": 0.1,
      "step": 39,
      "total_loss": 5.230923652648926,
      "weighted_orthogonal_loss": 0.25248950719833374
    },
    {
      "classification_loss": 3.8018133640289307,
      "epoch": 0.13114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5269787311553955,
      "orthogonal_weight": 0.1,
      "step": 40,
      "total_loss": 4.054511070251465,
      "weighted_orthogonal_loss": 0.2526978850364685
    },
    {
      "classification_loss": 4.9732465744018555,
      "epoch": 0.13442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5297348499298096,
      "orthogonal_weight": 0.1,
      "step": 41,
      "total_loss": 5.22622013092041,
      "weighted_orthogonal_loss": 0.2529734969139099
    },
    {
      "classification_loss": 3.458460569381714,
      "epoch": 0.1377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5333282947540283,
      "orthogonal_weight": 0.1,
      "step": 42,
      "total_loss": 3.7117934226989746,
      "weighted_orthogonal_loss": 0.25333282351493835
    },
    {
      "classification_loss": 4.225672245025635,
      "epoch": 0.14098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5376477241516113,
      "orthogonal_weight": 0.1,
      "step": 43,
      "total_loss": 4.479436874389648,
      "weighted_orthogonal_loss": 0.2537647783756256
    },
    {
      "classification_loss": 3.6510958671569824,
      "epoch": 0.14426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5428504943847656,
      "orthogonal_weight": 0.1,
      "step": 44,
      "total_loss": 3.905380964279175,
      "weighted_orthogonal_loss": 0.25428506731987
    },
    {
      "classification_loss": 2.6419272422790527,
      "epoch": 0.14754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.548938274383545,
      "orthogonal_weight": 0.1,
      "step": 45,
      "total_loss": 2.8968210220336914,
      "weighted_orthogonal_loss": 0.25489383935928345
    },
    {
      "classification_loss": 3.2036118507385254,
      "epoch": 0.15081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.555878162384033,
      "orthogonal_weight": 0.1,
      "step": 46,
      "total_loss": 3.4591996669769287,
      "weighted_orthogonal_loss": 0.2555878162384033
    },
    {
      "classification_loss": 2.4892373085021973,
      "epoch": 0.1540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5638327598571777,
      "orthogonal_weight": 0.1,
      "step": 47,
      "total_loss": 2.7456204891204834,
      "weighted_orthogonal_loss": 0.2563832700252533
    },
    {
      "classification_loss": 2.441755771636963,
      "epoch": 0.15737704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5727598667144775,
      "orthogonal_weight": 0.1,
      "step": 48,
      "total_loss": 2.6990318298339844,
      "weighted_orthogonal_loss": 0.2572759985923767
    },
    {
      "classification_loss": 2.0744705200195312,
      "epoch": 0.16065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5827181339263916,
      "orthogonal_weight": 0.1,
      "step": 49,
      "total_loss": 2.332742214202881,
      "weighted_orthogonal_loss": 0.25827181339263916
    },
    {
      "classification_loss": 1.9794857501983643,
      "epoch": 0.16393442622950818,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5937271118164062,
      "orthogonal_weight": 0.1,
      "step": 50,
      "total_loss": 2.238858461380005,
      "weighted_orthogonal_loss": 0.2593727111816406
    },
    {
      "classification_loss": 1.3289541006088257,
      "epoch": 0.16721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6057732105255127,
      "orthogonal_weight": 0.1,
      "step": 51,
      "total_loss": 1.589531421661377,
      "weighted_orthogonal_loss": 0.26057732105255127
    },
    {
      "classification_loss": 1.186947226524353,
      "epoch": 0.17049180327868851,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6188149452209473,
      "orthogonal_weight": 0.1,
      "step": 52,
      "total_loss": 1.4488286972045898,
      "weighted_orthogonal_loss": 0.2618815004825592
    },
    {
      "classification_loss": 1.0085456371307373,
      "epoch": 0.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.632462501525879,
      "orthogonal_weight": 0.1,
      "step": 53,
      "total_loss": 1.271791934967041,
      "weighted_orthogonal_loss": 0.2632462680339813
    },
    {
      "classification_loss": 1.037002444267273,
      "epoch": 0.17704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6431357860565186,
      "orthogonal_weight": 0.1,
      "step": 54,
      "total_loss": 1.3013160228729248,
      "weighted_orthogonal_loss": 0.26431357860565186
    },
    {
      "classification_loss": 1.2069694995880127,
      "epoch": 0.18032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.648866653442383,
      "orthogonal_weight": 0.1,
      "step": 55,
      "total_loss": 1.4718561172485352,
      "weighted_orthogonal_loss": 0.26488667726516724
    },
    {
      "classification_loss": 1.1363950967788696,
      "epoch": 0.18360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6489028930664062,
      "orthogonal_weight": 0.1,
      "step": 56,
      "total_loss": 1.4012854099273682,
      "weighted_orthogonal_loss": 0.26489028334617615
    },
    {
      "classification_loss": 1.0314213037490845,
      "epoch": 0.18688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.644852876663208,
      "orthogonal_weight": 0.1,
      "step": 57,
      "total_loss": 1.2959065437316895,
      "weighted_orthogonal_loss": 0.26448529958724976
    },
    {
      "classification_loss": 0.9691781997680664,
      "epoch": 0.1901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6382951736450195,
      "orthogonal_weight": 0.1,
      "step": 58,
      "total_loss": 1.2330076694488525,
      "weighted_orthogonal_loss": 0.2638295292854309
    },
    {
      "classification_loss": 0.8740141987800598,
      "epoch": 0.19344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6283934116363525,
      "orthogonal_weight": 0.1,
      "step": 59,
      "total_loss": 1.136853575706482,
      "weighted_orthogonal_loss": 0.26283934712409973
    },
    {
      "classification_loss": 0.8204762935638428,
      "epoch": 0.19672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6152679920196533,
      "orthogonal_weight": 0.1,
      "step": 60,
      "total_loss": 1.082003116607666,
      "weighted_orthogonal_loss": 0.26152679324150085
    },
    {
      "classification_loss": 1.0283122062683105,
      "epoch": 0.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.6010470390319824,
      "orthogonal_weight": 0.1,
      "step": 61,
      "total_loss": 1.288416862487793,
      "weighted_orthogonal_loss": 0.2601047158241272
    },
    {
      "classification_loss": 1.0024651288986206,
      "epoch": 0.20327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5887563228607178,
      "orthogonal_weight": 0.1,
      "step": 62,
      "total_loss": 1.2613407373428345,
      "weighted_orthogonal_loss": 0.25887563824653625
    },
    {
      "classification_loss": 1.0454679727554321,
      "epoch": 0.20655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5765154361724854,
      "orthogonal_weight": 0.1,
      "step": 63,
      "total_loss": 1.3031195402145386,
      "weighted_orthogonal_loss": 0.25765153765678406
    },
    {
      "classification_loss": 1.1010493040084839,
      "epoch": 0.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5662407875061035,
      "orthogonal_weight": 0.1,
      "step": 64,
      "total_loss": 1.3576734066009521,
      "weighted_orthogonal_loss": 0.2566240727901459
    },
    {
      "classification_loss": 0.9731278419494629,
      "epoch": 0.21311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.556680917739868,
      "orthogonal_weight": 0.1,
      "step": 65,
      "total_loss": 1.2287960052490234,
      "weighted_orthogonal_loss": 0.25566810369491577
    },
    {
      "classification_loss": 1.144801378250122,
      "epoch": 0.21639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.548336982727051,
      "orthogonal_weight": 0.1,
      "step": 66,
      "total_loss": 1.3996350765228271,
      "weighted_orthogonal_loss": 0.2548336982727051
    },
    {
      "classification_loss": 0.9935204386711121,
      "epoch": 0.21967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5415260791778564,
      "orthogonal_weight": 0.1,
      "step": 67,
      "total_loss": 1.2476730346679688,
      "weighted_orthogonal_loss": 0.2541526257991791
    },
    {
      "classification_loss": 0.9687477350234985,
      "epoch": 0.22295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5360910892486572,
      "orthogonal_weight": 0.1,
      "step": 68,
      "total_loss": 1.2223567962646484,
      "weighted_orthogonal_loss": 0.2536091208457947
    },
    {
      "classification_loss": 1.00104820728302,
      "epoch": 0.2262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.531756639480591,
      "orthogonal_weight": 0.1,
      "step": 69,
      "total_loss": 1.2542238235473633,
      "weighted_orthogonal_loss": 0.25317567586898804
    },
    {
      "classification_loss": 0.9809482097625732,
      "epoch": 0.22950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5284628868103027,
      "orthogonal_weight": 0.1,
      "step": 70,
      "total_loss": 1.2337944507598877,
      "weighted_orthogonal_loss": 0.25284630060195923
    },
    {
      "classification_loss": 1.0222573280334473,
      "epoch": 0.23278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5263774394989014,
      "orthogonal_weight": 0.1,
      "step": 71,
      "total_loss": 1.2748950719833374,
      "weighted_orthogonal_loss": 0.25263774394989014
    },
    {
      "classification_loss": 0.773695707321167,
      "epoch": 0.2360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5249032974243164,
      "orthogonal_weight": 0.1,
      "step": 72,
      "total_loss": 1.0261859893798828,
      "weighted_orthogonal_loss": 0.2524903416633606
    },
    {
      "classification_loss": 0.8191356658935547,
      "epoch": 0.23934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.52418851852417,
      "orthogonal_weight": 0.1,
      "step": 73,
      "total_loss": 1.0715545415878296,
      "weighted_orthogonal_loss": 0.2524188458919525
    },
    {
      "classification_loss": 0.8136652112007141,
      "epoch": 0.24262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.519164800643921,
      "orthogonal_weight": 0.1,
      "step": 74,
      "total_loss": 1.0655816793441772,
      "weighted_orthogonal_loss": 0.2519164979457855
    },
    {
      "classification_loss": 0.9791576266288757,
      "epoch": 0.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5093865394592285,
      "orthogonal_weight": 0.1,
      "step": 75,
      "total_loss": 1.2300963401794434,
      "weighted_orthogonal_loss": 0.25093865394592285
    },
    {
      "classification_loss": 0.7410611510276794,
      "epoch": 0.24918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.5000650882720947,
      "orthogonal_weight": 0.1,
      "step": 76,
      "total_loss": 0.99106764793396,
      "weighted_orthogonal_loss": 0.2500065267086029
    },
    {
      "classification_loss": 0.6837482452392578,
      "epoch": 0.25245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4890193939208984,
      "orthogonal_weight": 0.1,
      "step": 77,
      "total_loss": 0.9326502084732056,
      "weighted_orthogonal_loss": 0.24890194833278656
    },
    {
      "classification_loss": 0.8047066926956177,
      "epoch": 0.25573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.475247383117676,
      "orthogonal_weight": 0.1,
      "step": 78,
      "total_loss": 1.0522314310073853,
      "weighted_orthogonal_loss": 0.24752473831176758
    },
    {
      "classification_loss": 0.837968647480011,
      "epoch": 0.25901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4596540927886963,
      "orthogonal_weight": 0.1,
      "step": 79,
      "total_loss": 1.0839340686798096,
      "weighted_orthogonal_loss": 0.2459654062986374
    },
    {
      "classification_loss": 0.788935124874115,
      "epoch": 0.26229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4406421184539795,
      "orthogonal_weight": 0.1,
      "step": 80,
      "total_loss": 1.0329992771148682,
      "weighted_orthogonal_loss": 0.24406421184539795
    },
    {
      "classification_loss": 0.8450242280960083,
      "epoch": 0.26557377049180325,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.4179203510284424,
      "orthogonal_weight": 0.1,
      "step": 81,
      "total_loss": 1.0868163108825684,
      "weighted_orthogonal_loss": 0.24179203808307648
    },
    {
      "classification_loss": 0.766061007976532,
      "epoch": 0.26885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3968160152435303,
      "orthogonal_weight": 0.1,
      "step": 82,
      "total_loss": 1.0057425498962402,
      "weighted_orthogonal_loss": 0.23968160152435303
    },
    {
      "classification_loss": 0.7939802408218384,
      "epoch": 0.2721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3748397827148438,
      "orthogonal_weight": 0.1,
      "step": 83,
      "total_loss": 1.0314642190933228,
      "weighted_orthogonal_loss": 0.23748397827148438
    },
    {
      "classification_loss": 0.7005400657653809,
      "epoch": 0.2754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3529064655303955,
      "orthogonal_weight": 0.1,
      "step": 84,
      "total_loss": 0.9358307123184204,
      "weighted_orthogonal_loss": 0.23529064655303955
    },
    {
      "classification_loss": 0.8697884678840637,
      "epoch": 0.2786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.3332266807556152,
      "orthogonal_weight": 0.1,
      "step": 85,
      "total_loss": 1.1031111478805542,
      "weighted_orthogonal_loss": 0.23332266509532928
    },
    {
      "classification_loss": 0.895841121673584,
      "epoch": 0.2819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.315654754638672,
      "orthogonal_weight": 0.1,
      "step": 86,
      "total_loss": 1.1274065971374512,
      "weighted_orthogonal_loss": 0.2315654754638672
    },
    {
      "classification_loss": 0.8096129894256592,
      "epoch": 0.28524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.300110101699829,
      "orthogonal_weight": 0.1,
      "step": 87,
      "total_loss": 1.0396239757537842,
      "weighted_orthogonal_loss": 0.2300110161304474
    },
    {
      "classification_loss": 0.8452727794647217,
      "epoch": 0.28852459016393445,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.28566312789917,
      "orthogonal_weight": 0.1,
      "step": 88,
      "total_loss": 1.0738390684127808,
      "weighted_orthogonal_loss": 0.22856631875038147
    },
    {
      "classification_loss": 0.8693258166313171,
      "epoch": 0.29180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2725987434387207,
      "orthogonal_weight": 0.1,
      "step": 89,
      "total_loss": 1.096585750579834,
      "weighted_orthogonal_loss": 0.22725987434387207
    },
    {
      "classification_loss": 0.7535688877105713,
      "epoch": 0.29508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2609405517578125,
      "orthogonal_weight": 0.1,
      "step": 90,
      "total_loss": 0.9796629548072815,
      "weighted_orthogonal_loss": 0.226094052195549
    },
    {
      "classification_loss": 0.6669889688491821,
      "epoch": 0.2983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.250796318054199,
      "orthogonal_weight": 0.1,
      "step": 91,
      "total_loss": 0.89206862449646,
      "weighted_orthogonal_loss": 0.22507964074611664
    },
    {
      "classification_loss": 0.902565598487854,
      "epoch": 0.3016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2356839179992676,
      "orthogonal_weight": 0.1,
      "step": 92,
      "total_loss": 1.1261340379714966,
      "weighted_orthogonal_loss": 0.223568394780159
    },
    {
      "classification_loss": 0.8264880180358887,
      "epoch": 0.30491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2209060192108154,
      "orthogonal_weight": 0.1,
      "step": 93,
      "total_loss": 1.0485786199569702,
      "weighted_orthogonal_loss": 0.22209060192108154
    },
    {
      "classification_loss": 0.8139362931251526,
      "epoch": 0.3081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.2047553062438965,
      "orthogonal_weight": 0.1,
      "step": 94,
      "total_loss": 1.0344117879867554,
      "weighted_orthogonal_loss": 0.22047553956508636
    },
    {
      "classification_loss": 0.6911259889602661,
      "epoch": 0.3114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1828343868255615,
      "orthogonal_weight": 0.1,
      "step": 95,
      "total_loss": 0.9094094038009644,
      "weighted_orthogonal_loss": 0.21828344464302063
    },
    {
      "classification_loss": 0.7275919914245605,
      "epoch": 0.31475409836065577,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1578385829925537,
      "orthogonal_weight": 0.1,
      "step": 96,
      "total_loss": 0.943375825881958,
      "weighted_orthogonal_loss": 0.21578386425971985
    },
    {
      "classification_loss": 0.6946571469306946,
      "epoch": 0.3180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.133897542953491,
      "orthogonal_weight": 0.1,
      "step": 97,
      "total_loss": 0.9080469012260437,
      "weighted_orthogonal_loss": 0.21338975429534912
    },
    {
      "classification_loss": 0.7733399271965027,
      "epoch": 0.32131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.1062653064727783,
      "orthogonal_weight": 0.1,
      "step": 98,
      "total_loss": 0.9839664697647095,
      "weighted_orthogonal_loss": 0.2106265276670456
    },
    {
      "classification_loss": 0.6981164216995239,
      "epoch": 0.32459016393442625,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.080247640609741,
      "orthogonal_weight": 0.1,
      "step": 99,
      "total_loss": 0.9061411619186401,
      "weighted_orthogonal_loss": 0.2080247700214386
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 6.185621738433838,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.3925,
      "step": 100
    },
    {
      "classification_loss": 0.7426848411560059,
      "epoch": 0.32786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.055699586868286,
      "orthogonal_weight": 0.1,
      "step": 100,
      "total_loss": 0.9482548236846924,
      "weighted_orthogonal_loss": 0.20556996762752533
    },
    {
      "classification_loss": 0.6891850829124451,
      "epoch": 0.33114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.029672384262085,
      "orthogonal_weight": 0.1,
      "step": 101,
      "total_loss": 0.8921523094177246,
      "weighted_orthogonal_loss": 0.20296724140644073
    },
    {
      "classification_loss": 0.7061011791229248,
      "epoch": 0.3344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 2.0059235095977783,
      "orthogonal_weight": 0.1,
      "step": 102,
      "total_loss": 0.9066935181617737,
      "weighted_orthogonal_loss": 0.20059235394001007
    },
    {
      "classification_loss": 0.7441895008087158,
      "epoch": 0.3377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9799668788909912,
      "orthogonal_weight": 0.1,
      "step": 103,
      "total_loss": 0.942186176776886,
      "weighted_orthogonal_loss": 0.19799669086933136
    },
    {
      "classification_loss": 0.7127572894096375,
      "epoch": 0.34098360655737703,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9559729099273682,
      "orthogonal_weight": 0.1,
      "step": 104,
      "total_loss": 0.9083545804023743,
      "weighted_orthogonal_loss": 0.19559729099273682
    },
    {
      "classification_loss": 0.6998700499534607,
      "epoch": 0.3442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9322149753570557,
      "orthogonal_weight": 0.1,
      "step": 105,
      "total_loss": 0.8930915594100952,
      "weighted_orthogonal_loss": 0.19322149455547333
    },
    {
      "classification_loss": 0.7448074221611023,
      "epoch": 0.3475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.9066753387451172,
      "orthogonal_weight": 0.1,
      "step": 106,
      "total_loss": 0.9354749917984009,
      "weighted_orthogonal_loss": 0.1906675398349762
    },
    {
      "classification_loss": 0.6869522333145142,
      "epoch": 0.35081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8818331956863403,
      "orthogonal_weight": 0.1,
      "step": 107,
      "total_loss": 0.8751355409622192,
      "weighted_orthogonal_loss": 0.18818332254886627
    },
    {
      "classification_loss": 0.6886175870895386,
      "epoch": 0.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8586485385894775,
      "orthogonal_weight": 0.1,
      "step": 108,
      "total_loss": 0.8744824528694153,
      "weighted_orthogonal_loss": 0.18586485087871552
    },
    {
      "classification_loss": 0.7040539979934692,
      "epoch": 0.35737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.835504174232483,
      "orthogonal_weight": 0.1,
      "step": 109,
      "total_loss": 0.8876044154167175,
      "weighted_orthogonal_loss": 0.1835504174232483
    },
    {
      "classification_loss": 0.7814279794692993,
      "epoch": 0.36065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.8076725006103516,
      "orthogonal_weight": 0.1,
      "step": 110,
      "total_loss": 0.9621952176094055,
      "weighted_orthogonal_loss": 0.1807672530412674
    },
    {
      "classification_loss": 0.7390244603157043,
      "epoch": 0.3639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7812973260879517,
      "orthogonal_weight": 0.1,
      "step": 111,
      "total_loss": 0.9171541929244995,
      "weighted_orthogonal_loss": 0.17812973260879517
    },
    {
      "classification_loss": 0.7582592368125916,
      "epoch": 0.36721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7543021440505981,
      "orthogonal_weight": 0.1,
      "step": 112,
      "total_loss": 0.9336894750595093,
      "weighted_orthogonal_loss": 0.17543022334575653
    },
    {
      "classification_loss": 0.7349966764450073,
      "epoch": 0.3704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.7262160778045654,
      "orthogonal_weight": 0.1,
      "step": 113,
      "total_loss": 0.9076182842254639,
      "weighted_orthogonal_loss": 0.17262160778045654
    },
    {
      "classification_loss": 0.7470751404762268,
      "epoch": 0.3737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.697990894317627,
      "orthogonal_weight": 0.1,
      "step": 114,
      "total_loss": 0.9168742299079895,
      "weighted_orthogonal_loss": 0.1697990894317627
    },
    {
      "classification_loss": 0.7774783968925476,
      "epoch": 0.3770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.668585181236267,
      "orthogonal_weight": 0.1,
      "step": 115,
      "total_loss": 0.9443368911743164,
      "weighted_orthogonal_loss": 0.1668585240840912
    },
    {
      "classification_loss": 0.7047059535980225,
      "epoch": 0.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.641814947128296,
      "orthogonal_weight": 0.1,
      "step": 116,
      "total_loss": 0.8688874244689941,
      "weighted_orthogonal_loss": 0.16418150067329407
    },
    {
      "classification_loss": 0.6888832449913025,
      "epoch": 0.3836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.6151257753372192,
      "orthogonal_weight": 0.1,
      "step": 117,
      "total_loss": 0.8503957986831665,
      "weighted_orthogonal_loss": 0.1615125834941864
    },
    {
      "classification_loss": 0.6846457719802856,
      "epoch": 0.38688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5903894901275635,
      "orthogonal_weight": 0.1,
      "step": 118,
      "total_loss": 0.843684732913971,
      "weighted_orthogonal_loss": 0.1590389460325241
    },
    {
      "classification_loss": 0.7355442643165588,
      "epoch": 0.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5673773288726807,
      "orthogonal_weight": 0.1,
      "step": 119,
      "total_loss": 0.8922820091247559,
      "weighted_orthogonal_loss": 0.15673772990703583
    },
    {
      "classification_loss": 0.7269623875617981,
      "epoch": 0.39344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5465493202209473,
      "orthogonal_weight": 0.1,
      "step": 120,
      "total_loss": 0.8816173076629639,
      "weighted_orthogonal_loss": 0.15465493500232697
    },
    {
      "classification_loss": 0.7183887362480164,
      "epoch": 0.39672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5278308391571045,
      "orthogonal_weight": 0.1,
      "step": 121,
      "total_loss": 0.8711718320846558,
      "weighted_orthogonal_loss": 0.1527830809354782
    },
    {
      "classification_loss": 0.7033119797706604,
      "epoch": 0.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.5105900764465332,
      "orthogonal_weight": 0.1,
      "step": 122,
      "total_loss": 0.8543710112571716,
      "weighted_orthogonal_loss": 0.15105901658535004
    },
    {
      "classification_loss": 0.7219618558883667,
      "epoch": 0.40327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4942139387130737,
      "orthogonal_weight": 0.1,
      "step": 123,
      "total_loss": 0.8713832497596741,
      "weighted_orthogonal_loss": 0.14942139387130737
    },
    {
      "classification_loss": 0.7120789289474487,
      "epoch": 0.4065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4757157564163208,
      "orthogonal_weight": 0.1,
      "step": 124,
      "total_loss": 0.8596504926681519,
      "weighted_orthogonal_loss": 0.14757157862186432
    },
    {
      "classification_loss": 0.7315850853919983,
      "epoch": 0.4098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.459177017211914,
      "orthogonal_weight": 0.1,
      "step": 125,
      "total_loss": 0.8775027990341187,
      "weighted_orthogonal_loss": 0.14591769874095917
    },
    {
      "classification_loss": 0.6936371326446533,
      "epoch": 0.4131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4402127265930176,
      "orthogonal_weight": 0.1,
      "step": 126,
      "total_loss": 0.8376584053039551,
      "weighted_orthogonal_loss": 0.14402127265930176
    },
    {
      "classification_loss": 0.718295156955719,
      "epoch": 0.4163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4218240976333618,
      "orthogonal_weight": 0.1,
      "step": 127,
      "total_loss": 0.8604775667190552,
      "weighted_orthogonal_loss": 0.14218240976333618
    },
    {
      "classification_loss": 0.7113460898399353,
      "epoch": 0.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.4018245935440063,
      "orthogonal_weight": 0.1,
      "step": 128,
      "total_loss": 0.851528525352478,
      "weighted_orthogonal_loss": 0.1401824653148651
    },
    {
      "classification_loss": 0.6943801045417786,
      "epoch": 0.42295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3820618391036987,
      "orthogonal_weight": 0.1,
      "step": 129,
      "total_loss": 0.8325862884521484,
      "weighted_orthogonal_loss": 0.13820618391036987
    },
    {
      "classification_loss": 0.7153773903846741,
      "epoch": 0.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3630012273788452,
      "orthogonal_weight": 0.1,
      "step": 130,
      "total_loss": 0.8516775369644165,
      "weighted_orthogonal_loss": 0.13630013167858124
    },
    {
      "classification_loss": 0.7149412631988525,
      "epoch": 0.42950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3447939157485962,
      "orthogonal_weight": 0.1,
      "step": 131,
      "total_loss": 0.8494206666946411,
      "weighted_orthogonal_loss": 0.13447938859462738
    },
    {
      "classification_loss": 0.6908293962478638,
      "epoch": 0.43278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3265150785446167,
      "orthogonal_weight": 0.1,
      "step": 132,
      "total_loss": 0.8234809041023254,
      "weighted_orthogonal_loss": 0.13265150785446167
    },
    {
      "classification_loss": 0.7326231598854065,
      "epoch": 0.4360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.3080021142959595,
      "orthogonal_weight": 0.1,
      "step": 133,
      "total_loss": 0.8634233474731445,
      "weighted_orthogonal_loss": 0.13080021739006042
    },
    {
      "classification_loss": 0.757449746131897,
      "epoch": 0.43934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2909541130065918,
      "orthogonal_weight": 0.1,
      "step": 134,
      "total_loss": 0.8865451812744141,
      "weighted_orthogonal_loss": 0.1290954202413559
    },
    {
      "classification_loss": 0.7170520424842834,
      "epoch": 0.4426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2747467756271362,
      "orthogonal_weight": 0.1,
      "step": 135,
      "total_loss": 0.8445267081260681,
      "weighted_orthogonal_loss": 0.12747468054294586
    },
    {
      "classification_loss": 0.7196593880653381,
      "epoch": 0.4459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2603119611740112,
      "orthogonal_weight": 0.1,
      "step": 136,
      "total_loss": 0.8456906080245972,
      "weighted_orthogonal_loss": 0.12603120505809784
    },
    {
      "classification_loss": 0.712405264377594,
      "epoch": 0.4491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.244301199913025,
      "orthogonal_weight": 0.1,
      "step": 137,
      "total_loss": 0.8368353843688965,
      "weighted_orthogonal_loss": 0.12443011999130249
    },
    {
      "classification_loss": 0.7355287671089172,
      "epoch": 0.4524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2262957096099854,
      "orthogonal_weight": 0.1,
      "step": 138,
      "total_loss": 0.8581583499908447,
      "weighted_orthogonal_loss": 0.1226295754313469
    },
    {
      "classification_loss": 0.7072960734367371,
      "epoch": 0.4557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.2101514339447021,
      "orthogonal_weight": 0.1,
      "step": 139,
      "total_loss": 0.8283112049102783,
      "weighted_orthogonal_loss": 0.12101514637470245
    },
    {
      "classification_loss": 0.6731440424919128,
      "epoch": 0.45901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1936216354370117,
      "orthogonal_weight": 0.1,
      "step": 140,
      "total_loss": 0.792506217956543,
      "weighted_orthogonal_loss": 0.11936216801404953
    },
    {
      "classification_loss": 0.7076795101165771,
      "epoch": 0.46229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.17788565158844,
      "orthogonal_weight": 0.1,
      "step": 141,
      "total_loss": 0.8254680633544922,
      "weighted_orthogonal_loss": 0.11778856813907623
    },
    {
      "classification_loss": 0.7777341604232788,
      "epoch": 0.46557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1615368127822876,
      "orthogonal_weight": 0.1,
      "step": 142,
      "total_loss": 0.8938878178596497,
      "weighted_orthogonal_loss": 0.11615367978811264
    },
    {
      "classification_loss": 0.729986310005188,
      "epoch": 0.46885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1454901695251465,
      "orthogonal_weight": 0.1,
      "step": 143,
      "total_loss": 0.8445353507995605,
      "weighted_orthogonal_loss": 0.11454901844263077
    },
    {
      "classification_loss": 0.7311764359474182,
      "epoch": 0.4721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.129646897315979,
      "orthogonal_weight": 0.1,
      "step": 144,
      "total_loss": 0.8441411256790161,
      "weighted_orthogonal_loss": 0.1129646897315979
    },
    {
      "classification_loss": 0.6491072773933411,
      "epoch": 0.47540983606557374,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.1137056350708008,
      "orthogonal_weight": 0.1,
      "step": 145,
      "total_loss": 0.7604778409004211,
      "weighted_orthogonal_loss": 0.11137056350708008
    },
    {
      "classification_loss": 0.7160710692405701,
      "epoch": 0.4786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.099495530128479,
      "orthogonal_weight": 0.1,
      "step": 146,
      "total_loss": 0.8260205984115601,
      "weighted_orthogonal_loss": 0.10994955152273178
    },
    {
      "classification_loss": 0.727759838104248,
      "epoch": 0.4819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0856809616088867,
      "orthogonal_weight": 0.1,
      "step": 147,
      "total_loss": 0.8363279104232788,
      "weighted_orthogonal_loss": 0.10856809467077255
    },
    {
      "classification_loss": 0.7034668326377869,
      "epoch": 0.4852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0707390308380127,
      "orthogonal_weight": 0.1,
      "step": 148,
      "total_loss": 0.8105407357215881,
      "weighted_orthogonal_loss": 0.10707390308380127
    },
    {
      "classification_loss": 0.7194979190826416,
      "epoch": 0.4885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0541177988052368,
      "orthogonal_weight": 0.1,
      "step": 149,
      "total_loss": 0.8249096870422363,
      "weighted_orthogonal_loss": 0.10541178286075592
    },
    {
      "classification_loss": 0.7147797346115112,
      "epoch": 0.4918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0390430688858032,
      "orthogonal_weight": 0.1,
      "step": 150,
      "total_loss": 0.8186840415000916,
      "weighted_orthogonal_loss": 0.10390430688858032
    },
    {
      "classification_loss": 0.7428256869316101,
      "epoch": 0.49508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0247352123260498,
      "orthogonal_weight": 0.1,
      "step": 151,
      "total_loss": 0.8452991843223572,
      "weighted_orthogonal_loss": 0.10247351974248886
    },
    {
      "classification_loss": 0.7292930483818054,
      "epoch": 0.49836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 1.0122216939926147,
      "orthogonal_weight": 0.1,
      "step": 152,
      "total_loss": 0.8305152058601379,
      "weighted_orthogonal_loss": 0.10122217237949371
    },
    {
      "classification_loss": 0.7249622344970703,
      "epoch": 0.5016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9987656474113464,
      "orthogonal_weight": 0.1,
      "step": 153,
      "total_loss": 0.8248388171195984,
      "weighted_orthogonal_loss": 0.09987656772136688
    },
    {
      "classification_loss": 0.7035542726516724,
      "epoch": 0.5049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9839968085289001,
      "orthogonal_weight": 0.1,
      "step": 154,
      "total_loss": 0.8019539713859558,
      "weighted_orthogonal_loss": 0.09839968383312225
    },
    {
      "classification_loss": 0.6589342355728149,
      "epoch": 0.5081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9711233973503113,
      "orthogonal_weight": 0.1,
      "step": 155,
      "total_loss": 0.7560465931892395,
      "weighted_orthogonal_loss": 0.09711234271526337
    },
    {
      "classification_loss": 0.7039651274681091,
      "epoch": 0.5114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9561624526977539,
      "orthogonal_weight": 0.1,
      "step": 156,
      "total_loss": 0.7995813488960266,
      "weighted_orthogonal_loss": 0.09561624377965927
    },
    {
      "classification_loss": 0.7236469984054565,
      "epoch": 0.5147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9427283406257629,
      "orthogonal_weight": 0.1,
      "step": 157,
      "total_loss": 0.8179198503494263,
      "weighted_orthogonal_loss": 0.09427283704280853
    },
    {
      "classification_loss": 0.7276714444160461,
      "epoch": 0.5180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9287170767784119,
      "orthogonal_weight": 0.1,
      "step": 158,
      "total_loss": 0.8205431699752808,
      "weighted_orthogonal_loss": 0.09287171065807343
    },
    {
      "classification_loss": 0.7140398025512695,
      "epoch": 0.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9148684740066528,
      "orthogonal_weight": 0.1,
      "step": 159,
      "total_loss": 0.8055266737937927,
      "weighted_orthogonal_loss": 0.0914868488907814
    },
    {
      "classification_loss": 0.6990319490432739,
      "epoch": 0.5245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.9020745158195496,
      "orthogonal_weight": 0.1,
      "step": 160,
      "total_loss": 0.7892394065856934,
      "weighted_orthogonal_loss": 0.09020745009183884
    },
    {
      "classification_loss": 0.6984525918960571,
      "epoch": 0.5278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8891884684562683,
      "orthogonal_weight": 0.1,
      "step": 161,
      "total_loss": 0.7873714566230774,
      "weighted_orthogonal_loss": 0.08891884982585907
    },
    {
      "classification_loss": 0.7134472727775574,
      "epoch": 0.5311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8737286925315857,
      "orthogonal_weight": 0.1,
      "step": 162,
      "total_loss": 0.8008201122283936,
      "weighted_orthogonal_loss": 0.08737286925315857
    },
    {
      "classification_loss": 0.7060546875,
      "epoch": 0.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8575027585029602,
      "orthogonal_weight": 0.1,
      "step": 163,
      "total_loss": 0.7918049693107605,
      "weighted_orthogonal_loss": 0.0857502743601799
    },
    {
      "classification_loss": 0.7144131064414978,
      "epoch": 0.5377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8400660753250122,
      "orthogonal_weight": 0.1,
      "step": 164,
      "total_loss": 0.798419713973999,
      "weighted_orthogonal_loss": 0.08400660753250122
    },
    {
      "classification_loss": 0.6880045533180237,
      "epoch": 0.5409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8225589394569397,
      "orthogonal_weight": 0.1,
      "step": 165,
      "total_loss": 0.7702604532241821,
      "weighted_orthogonal_loss": 0.08225589245557785
    },
    {
      "classification_loss": 0.746560275554657,
      "epoch": 0.5442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.8071876168251038,
      "orthogonal_weight": 0.1,
      "step": 166,
      "total_loss": 0.8272790312767029,
      "weighted_orthogonal_loss": 0.0807187631726265
    },
    {
      "classification_loss": 0.7193000316619873,
      "epoch": 0.5475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7937963604927063,
      "orthogonal_weight": 0.1,
      "step": 167,
      "total_loss": 0.7986796498298645,
      "weighted_orthogonal_loss": 0.07937964051961899
    },
    {
      "classification_loss": 0.7028284072875977,
      "epoch": 0.5508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7820057272911072,
      "orthogonal_weight": 0.1,
      "step": 168,
      "total_loss": 0.7810289859771729,
      "weighted_orthogonal_loss": 0.0782005712389946
    },
    {
      "classification_loss": 0.7108005285263062,
      "epoch": 0.5540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7714784145355225,
      "orthogonal_weight": 0.1,
      "step": 169,
      "total_loss": 0.7879483699798584,
      "weighted_orthogonal_loss": 0.07714784145355225
    },
    {
      "classification_loss": 0.7389585971832275,
      "epoch": 0.5573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7616114020347595,
      "orthogonal_weight": 0.1,
      "step": 170,
      "total_loss": 0.815119743347168,
      "weighted_orthogonal_loss": 0.07616113871335983
    },
    {
      "classification_loss": 0.7115561962127686,
      "epoch": 0.5606557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7530691623687744,
      "orthogonal_weight": 0.1,
      "step": 171,
      "total_loss": 0.7868630886077881,
      "weighted_orthogonal_loss": 0.07530691474676132
    },
    {
      "classification_loss": 0.6993051767349243,
      "epoch": 0.5639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7455280423164368,
      "orthogonal_weight": 0.1,
      "step": 172,
      "total_loss": 0.7738579511642456,
      "weighted_orthogonal_loss": 0.07455280423164368
    },
    {
      "classification_loss": 0.7437798380851746,
      "epoch": 0.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7389239072799683,
      "orthogonal_weight": 0.1,
      "step": 173,
      "total_loss": 0.8176722526550293,
      "weighted_orthogonal_loss": 0.07389239221811295
    },
    {
      "classification_loss": 0.6863051652908325,
      "epoch": 0.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7329471707344055,
      "orthogonal_weight": 0.1,
      "step": 174,
      "total_loss": 0.7595998644828796,
      "weighted_orthogonal_loss": 0.07329472154378891
    },
    {
      "classification_loss": 0.7252180576324463,
      "epoch": 0.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7264596223831177,
      "orthogonal_weight": 0.1,
      "step": 175,
      "total_loss": 0.7978640198707581,
      "weighted_orthogonal_loss": 0.07264596223831177
    },
    {
      "classification_loss": 0.7183805704116821,
      "epoch": 0.5770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7172539830207825,
      "orthogonal_weight": 0.1,
      "step": 176,
      "total_loss": 0.790105938911438,
      "weighted_orthogonal_loss": 0.07172539830207825
    },
    {
      "classification_loss": 0.6911704540252686,
      "epoch": 0.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.7079337239265442,
      "orthogonal_weight": 0.1,
      "step": 177,
      "total_loss": 0.7619638442993164,
      "weighted_orthogonal_loss": 0.07079337537288666
    },
    {
      "classification_loss": 0.7050225138664246,
      "epoch": 0.5836065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6988174915313721,
      "orthogonal_weight": 0.1,
      "step": 178,
      "total_loss": 0.7749042510986328,
      "weighted_orthogonal_loss": 0.06988175213336945
    },
    {
      "classification_loss": 0.7067538499832153,
      "epoch": 0.5868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6901066303253174,
      "orthogonal_weight": 0.1,
      "step": 179,
      "total_loss": 0.775764524936676,
      "weighted_orthogonal_loss": 0.0690106675028801
    },
    {
      "classification_loss": 0.6712997555732727,
      "epoch": 0.5901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6827086806297302,
      "orthogonal_weight": 0.1,
      "step": 180,
      "total_loss": 0.7395706176757812,
      "weighted_orthogonal_loss": 0.06827086955308914
    },
    {
      "classification_loss": 0.7013258934020996,
      "epoch": 0.5934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6763409376144409,
      "orthogonal_weight": 0.1,
      "step": 181,
      "total_loss": 0.7689599990844727,
      "weighted_orthogonal_loss": 0.06763409823179245
    },
    {
      "classification_loss": 0.7177046537399292,
      "epoch": 0.5967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6700928211212158,
      "orthogonal_weight": 0.1,
      "step": 182,
      "total_loss": 0.7847139239311218,
      "weighted_orthogonal_loss": 0.06700928509235382
    },
    {
      "classification_loss": 0.6969925761222839,
      "epoch": 0.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6622061729431152,
      "orthogonal_weight": 0.1,
      "step": 183,
      "total_loss": 0.7632132172584534,
      "weighted_orthogonal_loss": 0.06622061878442764
    },
    {
      "classification_loss": 0.713304340839386,
      "epoch": 0.6032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6538342237472534,
      "orthogonal_weight": 0.1,
      "step": 184,
      "total_loss": 0.7786877751350403,
      "weighted_orthogonal_loss": 0.0653834268450737
    },
    {
      "classification_loss": 0.6959580779075623,
      "epoch": 0.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6462763547897339,
      "orthogonal_weight": 0.1,
      "step": 185,
      "total_loss": 0.7605857253074646,
      "weighted_orthogonal_loss": 0.06462763994932175
    },
    {
      "classification_loss": 0.7177587151527405,
      "epoch": 0.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6394720673561096,
      "orthogonal_weight": 0.1,
      "step": 186,
      "total_loss": 0.781705915927887,
      "weighted_orthogonal_loss": 0.06394720822572708
    },
    {
      "classification_loss": 0.7390300035476685,
      "epoch": 0.6131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6332750916481018,
      "orthogonal_weight": 0.1,
      "step": 187,
      "total_loss": 0.8023574948310852,
      "weighted_orthogonal_loss": 0.06332751363515854
    },
    {
      "classification_loss": 0.7136139273643494,
      "epoch": 0.6163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6276147961616516,
      "orthogonal_weight": 0.1,
      "step": 188,
      "total_loss": 0.776375412940979,
      "weighted_orthogonal_loss": 0.06276147812604904
    },
    {
      "classification_loss": 0.7045691609382629,
      "epoch": 0.6196721311475409,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6229007840156555,
      "orthogonal_weight": 0.1,
      "step": 189,
      "total_loss": 0.766859233379364,
      "weighted_orthogonal_loss": 0.06229007989168167
    },
    {
      "classification_loss": 0.7169452905654907,
      "epoch": 0.6229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6183456182479858,
      "orthogonal_weight": 0.1,
      "step": 190,
      "total_loss": 0.7787798643112183,
      "weighted_orthogonal_loss": 0.061834562569856644
    },
    {
      "classification_loss": 0.7381787896156311,
      "epoch": 0.6262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6144683957099915,
      "orthogonal_weight": 0.1,
      "step": 191,
      "total_loss": 0.7996256351470947,
      "weighted_orthogonal_loss": 0.061446841806173325
    },
    {
      "classification_loss": 0.7247123122215271,
      "epoch": 0.6295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6094496846199036,
      "orthogonal_weight": 0.1,
      "step": 192,
      "total_loss": 0.7856572866439819,
      "weighted_orthogonal_loss": 0.060944970697164536
    },
    {
      "classification_loss": 0.6660178303718567,
      "epoch": 0.6327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.6037217378616333,
      "orthogonal_weight": 0.1,
      "step": 193,
      "total_loss": 0.72639000415802,
      "weighted_orthogonal_loss": 0.06037217378616333
    },
    {
      "classification_loss": 0.7119050621986389,
      "epoch": 0.6360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5987588763237,
      "orthogonal_weight": 0.1,
      "step": 194,
      "total_loss": 0.7717809677124023,
      "weighted_orthogonal_loss": 0.059875886887311935
    },
    {
      "classification_loss": 0.7103061079978943,
      "epoch": 0.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5928035974502563,
      "orthogonal_weight": 0.1,
      "step": 195,
      "total_loss": 0.769586443901062,
      "weighted_orthogonal_loss": 0.059280361980199814
    },
    {
      "classification_loss": 0.6347771286964417,
      "epoch": 0.6426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5860375761985779,
      "orthogonal_weight": 0.1,
      "step": 196,
      "total_loss": 0.6933808922767639,
      "weighted_orthogonal_loss": 0.05860375985503197
    },
    {
      "classification_loss": 0.6949501633644104,
      "epoch": 0.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5803974866867065,
      "orthogonal_weight": 0.1,
      "step": 197,
      "total_loss": 0.7529898881912231,
      "weighted_orthogonal_loss": 0.05803975090384483
    },
    {
      "classification_loss": 0.7041467428207397,
      "epoch": 0.6491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5744933485984802,
      "orthogonal_weight": 0.1,
      "step": 198,
      "total_loss": 0.7615960836410522,
      "weighted_orthogonal_loss": 0.0574493370950222
    },
    {
      "classification_loss": 0.7606134414672852,
      "epoch": 0.6524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5679471492767334,
      "orthogonal_weight": 0.1,
      "step": 199,
      "total_loss": 0.8174081444740295,
      "weighted_orthogonal_loss": 0.05679471418261528
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 5.728487968444824,
      "learning_rate": 0.0001967,
      "loss": 0.8273,
      "step": 200
    },
    {
      "classification_loss": 0.7116988897323608,
      "epoch": 0.6557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5610496401786804,
      "orthogonal_weight": 0.1,
      "step": 200,
      "total_loss": 0.7678038477897644,
      "weighted_orthogonal_loss": 0.05610496550798416
    },
    {
      "classification_loss": 0.7220116853713989,
      "epoch": 0.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5541437268257141,
      "orthogonal_weight": 0.1,
      "step": 201,
      "total_loss": 0.7774260640144348,
      "weighted_orthogonal_loss": 0.05541437491774559
    },
    {
      "classification_loss": 0.6721393465995789,
      "epoch": 0.6622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5483297109603882,
      "orthogonal_weight": 0.1,
      "step": 202,
      "total_loss": 0.7269723415374756,
      "weighted_orthogonal_loss": 0.05483297258615494
    },
    {
      "classification_loss": 0.6306853890419006,
      "epoch": 0.6655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5426285862922668,
      "orthogonal_weight": 0.1,
      "step": 203,
      "total_loss": 0.6849482655525208,
      "weighted_orthogonal_loss": 0.054262857884168625
    },
    {
      "classification_loss": 0.709265410900116,
      "epoch": 0.6688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5367624759674072,
      "orthogonal_weight": 0.1,
      "step": 204,
      "total_loss": 0.7629416584968567,
      "weighted_orthogonal_loss": 0.05367624759674072
    },
    {
      "classification_loss": 0.7012773752212524,
      "epoch": 0.6721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5310946702957153,
      "orthogonal_weight": 0.1,
      "step": 205,
      "total_loss": 0.754386842250824,
      "weighted_orthogonal_loss": 0.05310946702957153
    },
    {
      "classification_loss": 0.720333456993103,
      "epoch": 0.6754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5251572132110596,
      "orthogonal_weight": 0.1,
      "step": 206,
      "total_loss": 0.7728492021560669,
      "weighted_orthogonal_loss": 0.052515722811222076
    },
    {
      "classification_loss": 0.7018915414810181,
      "epoch": 0.6786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5191977024078369,
      "orthogonal_weight": 0.1,
      "step": 207,
      "total_loss": 0.7538112998008728,
      "weighted_orthogonal_loss": 0.05191976949572563
    },
    {
      "classification_loss": 0.6653981804847717,
      "epoch": 0.6819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5132253766059875,
      "orthogonal_weight": 0.1,
      "step": 208,
      "total_loss": 0.716720700263977,
      "weighted_orthogonal_loss": 0.051322538405656815
    },
    {
      "classification_loss": 0.6778106093406677,
      "epoch": 0.6852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5067413449287415,
      "orthogonal_weight": 0.1,
      "step": 209,
      "total_loss": 0.7284847497940063,
      "weighted_orthogonal_loss": 0.050674136728048325
    },
    {
      "classification_loss": 0.7002927660942078,
      "epoch": 0.6885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.5006607174873352,
      "orthogonal_weight": 0.1,
      "step": 210,
      "total_loss": 0.7503588199615479,
      "weighted_orthogonal_loss": 0.05006607249379158
    },
    {
      "classification_loss": 0.7151138782501221,
      "epoch": 0.6918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4948391020298004,
      "orthogonal_weight": 0.1,
      "step": 211,
      "total_loss": 0.7645977735519409,
      "weighted_orthogonal_loss": 0.04948391020298004
    },
    {
      "classification_loss": 0.6979647278785706,
      "epoch": 0.6950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4887544810771942,
      "orthogonal_weight": 0.1,
      "step": 212,
      "total_loss": 0.7468401789665222,
      "weighted_orthogonal_loss": 0.04887544736266136
    },
    {
      "classification_loss": 0.6869545578956604,
      "epoch": 0.6983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.48377370834350586,
      "orthogonal_weight": 0.1,
      "step": 213,
      "total_loss": 0.7353319525718689,
      "weighted_orthogonal_loss": 0.048377372324466705
    },
    {
      "classification_loss": 0.7263725399971008,
      "epoch": 0.7016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4793614447116852,
      "orthogonal_weight": 0.1,
      "step": 214,
      "total_loss": 0.7743086814880371,
      "weighted_orthogonal_loss": 0.04793614521622658
    },
    {
      "classification_loss": 0.6604940295219421,
      "epoch": 0.7049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.47478798031806946,
      "orthogonal_weight": 0.1,
      "step": 215,
      "total_loss": 0.7079728245735168,
      "weighted_orthogonal_loss": 0.047478798776865005
    },
    {
      "classification_loss": 0.6522423624992371,
      "epoch": 0.7081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4700516164302826,
      "orthogonal_weight": 0.1,
      "step": 216,
      "total_loss": 0.6992475390434265,
      "weighted_orthogonal_loss": 0.04700516164302826
    },
    {
      "classification_loss": 0.6462717056274414,
      "epoch": 0.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.46474435925483704,
      "orthogonal_weight": 0.1,
      "step": 217,
      "total_loss": 0.6927461624145508,
      "weighted_orthogonal_loss": 0.04647443816065788
    },
    {
      "classification_loss": 0.6989960074424744,
      "epoch": 0.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.45896536111831665,
      "orthogonal_weight": 0.1,
      "step": 218,
      "total_loss": 0.7448925375938416,
      "weighted_orthogonal_loss": 0.045896537601947784
    },
    {
      "classification_loss": 0.715009331703186,
      "epoch": 0.7180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4543754756450653,
      "orthogonal_weight": 0.1,
      "step": 219,
      "total_loss": 0.7604469060897827,
      "weighted_orthogonal_loss": 0.04543754830956459
    },
    {
      "classification_loss": 0.7178640961647034,
      "epoch": 0.7213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4506312906742096,
      "orthogonal_weight": 0.1,
      "step": 220,
      "total_loss": 0.762927234172821,
      "weighted_orthogonal_loss": 0.04506313055753708
    },
    {
      "classification_loss": 0.6671947240829468,
      "epoch": 0.7245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.44750723242759705,
      "orthogonal_weight": 0.1,
      "step": 221,
      "total_loss": 0.7119454741477966,
      "weighted_orthogonal_loss": 0.044750723987817764
    },
    {
      "classification_loss": 0.7280611991882324,
      "epoch": 0.7278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4433830678462982,
      "orthogonal_weight": 0.1,
      "step": 222,
      "total_loss": 0.7723994851112366,
      "weighted_orthogonal_loss": 0.04433830827474594
    },
    {
      "classification_loss": 0.7156656980514526,
      "epoch": 0.7311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4398602545261383,
      "orthogonal_weight": 0.1,
      "step": 223,
      "total_loss": 0.7596517205238342,
      "weighted_orthogonal_loss": 0.04398602619767189
    },
    {
      "classification_loss": 0.6979781985282898,
      "epoch": 0.7344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4366690218448639,
      "orthogonal_weight": 0.1,
      "step": 224,
      "total_loss": 0.741645097732544,
      "weighted_orthogonal_loss": 0.04366690292954445
    },
    {
      "classification_loss": 0.7222327589988708,
      "epoch": 0.7377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.43384334444999695,
      "orthogonal_weight": 0.1,
      "step": 225,
      "total_loss": 0.7656170725822449,
      "weighted_orthogonal_loss": 0.043384335935115814
    },
    {
      "classification_loss": 0.7155141830444336,
      "epoch": 0.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4313594400882721,
      "orthogonal_weight": 0.1,
      "step": 226,
      "total_loss": 0.7586501240730286,
      "weighted_orthogonal_loss": 0.04313594475388527
    },
    {
      "classification_loss": 0.7037650942802429,
      "epoch": 0.7442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.42943400144577026,
      "orthogonal_weight": 0.1,
      "step": 227,
      "total_loss": 0.7467085123062134,
      "weighted_orthogonal_loss": 0.04294339939951897
    },
    {
      "classification_loss": 0.6553806066513062,
      "epoch": 0.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4282200038433075,
      "orthogonal_weight": 0.1,
      "step": 228,
      "total_loss": 0.6982026100158691,
      "weighted_orthogonal_loss": 0.04282199963927269
    },
    {
      "classification_loss": 0.722605288028717,
      "epoch": 0.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.42652979493141174,
      "orthogonal_weight": 0.1,
      "step": 229,
      "total_loss": 0.765258252620697,
      "weighted_orthogonal_loss": 0.042652979493141174
    },
    {
      "classification_loss": 0.6863751411437988,
      "epoch": 0.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4242936670780182,
      "orthogonal_weight": 0.1,
      "step": 230,
      "total_loss": 0.7288045287132263,
      "weighted_orthogonal_loss": 0.042429368942976
    },
    {
      "classification_loss": 0.702657163143158,
      "epoch": 0.7573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.421884685754776,
      "orthogonal_weight": 0.1,
      "step": 231,
      "total_loss": 0.7448456287384033,
      "weighted_orthogonal_loss": 0.04218846932053566
    },
    {
      "classification_loss": 0.6711210012435913,
      "epoch": 0.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.41894879937171936,
      "orthogonal_weight": 0.1,
      "step": 232,
      "total_loss": 0.7130158543586731,
      "weighted_orthogonal_loss": 0.041894879192113876
    },
    {
      "classification_loss": 0.6562107801437378,
      "epoch": 0.7639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4154166579246521,
      "orthogonal_weight": 0.1,
      "step": 233,
      "total_loss": 0.6977524757385254,
      "weighted_orthogonal_loss": 0.04154166579246521
    },
    {
      "classification_loss": 0.6899065971374512,
      "epoch": 0.7672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.4118153154850006,
      "orthogonal_weight": 0.1,
      "step": 234,
      "total_loss": 0.7310881018638611,
      "weighted_orthogonal_loss": 0.041181530803442
    },
    {
      "classification_loss": 0.6890919804573059,
      "epoch": 0.7704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.40810805559158325,
      "orthogonal_weight": 0.1,
      "step": 235,
      "total_loss": 0.7299028038978577,
      "weighted_orthogonal_loss": 0.040810804814100266
    },
    {
      "classification_loss": 0.7369409203529358,
      "epoch": 0.7737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.40386271476745605,
      "orthogonal_weight": 0.1,
      "step": 236,
      "total_loss": 0.7773271799087524,
      "weighted_orthogonal_loss": 0.040386270731687546
    },
    {
      "classification_loss": 0.7048996090888977,
      "epoch": 0.7770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.39908087253570557,
      "orthogonal_weight": 0.1,
      "step": 237,
      "total_loss": 0.7448077201843262,
      "weighted_orthogonal_loss": 0.039908088743686676
    },
    {
      "classification_loss": 0.7355625629425049,
      "epoch": 0.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3949201703071594,
      "orthogonal_weight": 0.1,
      "step": 238,
      "total_loss": 0.7750545740127563,
      "weighted_orthogonal_loss": 0.03949201852083206
    },
    {
      "classification_loss": 0.6937424540519714,
      "epoch": 0.7836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3899405300617218,
      "orthogonal_weight": 0.1,
      "step": 239,
      "total_loss": 0.7327365279197693,
      "weighted_orthogonal_loss": 0.03899405524134636
    },
    {
      "classification_loss": 0.7060497403144836,
      "epoch": 0.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.38490715622901917,
      "orthogonal_weight": 0.1,
      "step": 240,
      "total_loss": 0.7445404529571533,
      "weighted_orthogonal_loss": 0.038490716367959976
    },
    {
      "classification_loss": 0.7354292273521423,
      "epoch": 0.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3800651729106903,
      "orthogonal_weight": 0.1,
      "step": 241,
      "total_loss": 0.7734357714653015,
      "weighted_orthogonal_loss": 0.03800651803612709
    },
    {
      "classification_loss": 0.7072373628616333,
      "epoch": 0.7934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3746589124202728,
      "orthogonal_weight": 0.1,
      "step": 242,
      "total_loss": 0.7447032332420349,
      "weighted_orthogonal_loss": 0.0374658927321434
    },
    {
      "classification_loss": 0.6770834922790527,
      "epoch": 0.7967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3681049048900604,
      "orthogonal_weight": 0.1,
      "step": 243,
      "total_loss": 0.7138940095901489,
      "weighted_orthogonal_loss": 0.0368104912340641
    },
    {
      "classification_loss": 0.6760765314102173,
      "epoch": 0.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.36248090863227844,
      "orthogonal_weight": 0.1,
      "step": 244,
      "total_loss": 0.7123246192932129,
      "weighted_orthogonal_loss": 0.036248091608285904
    },
    {
      "classification_loss": 0.7230172753334045,
      "epoch": 0.8032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35802164673805237,
      "orthogonal_weight": 0.1,
      "step": 245,
      "total_loss": 0.7588194608688354,
      "weighted_orthogonal_loss": 0.035802166908979416
    },
    {
      "classification_loss": 0.6754835844039917,
      "epoch": 0.8065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35427799820899963,
      "orthogonal_weight": 0.1,
      "step": 246,
      "total_loss": 0.7109113931655884,
      "weighted_orthogonal_loss": 0.03542780131101608
    },
    {
      "classification_loss": 0.7139962315559387,
      "epoch": 0.8098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.35121163725852966,
      "orthogonal_weight": 0.1,
      "step": 247,
      "total_loss": 0.749117374420166,
      "weighted_orthogonal_loss": 0.035121165215969086
    },
    {
      "classification_loss": 0.7339947819709778,
      "epoch": 0.8131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3485611379146576,
      "orthogonal_weight": 0.1,
      "step": 248,
      "total_loss": 0.7688509225845337,
      "weighted_orthogonal_loss": 0.03485611453652382
    },
    {
      "classification_loss": 0.6876821517944336,
      "epoch": 0.8163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34651097655296326,
      "orthogonal_weight": 0.1,
      "step": 249,
      "total_loss": 0.7223332524299622,
      "weighted_orthogonal_loss": 0.034651096910238266
    },
    {
      "classification_loss": 0.7027570605278015,
      "epoch": 0.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34494906663894653,
      "orthogonal_weight": 0.1,
      "step": 250,
      "total_loss": 0.7372519969940186,
      "weighted_orthogonal_loss": 0.03449490666389465
    },
    {
      "classification_loss": 0.7102451920509338,
      "epoch": 0.8229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3430878818035126,
      "orthogonal_weight": 0.1,
      "step": 251,
      "total_loss": 0.7445539832115173,
      "weighted_orthogonal_loss": 0.0343087874352932
    },
    {
      "classification_loss": 0.6936730742454529,
      "epoch": 0.8262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.34157025814056396,
      "orthogonal_weight": 0.1,
      "step": 252,
      "total_loss": 0.7278301119804382,
      "weighted_orthogonal_loss": 0.034157026559114456
    },
    {
      "classification_loss": 0.6746993660926819,
      "epoch": 0.8295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3401494324207306,
      "orthogonal_weight": 0.1,
      "step": 253,
      "total_loss": 0.7087143063545227,
      "weighted_orthogonal_loss": 0.03401494398713112
    },
    {
      "classification_loss": 0.702947199344635,
      "epoch": 0.8327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3385455012321472,
      "orthogonal_weight": 0.1,
      "step": 254,
      "total_loss": 0.7368017435073853,
      "weighted_orthogonal_loss": 0.03385455161333084
    },
    {
      "classification_loss": 0.682108998298645,
      "epoch": 0.8360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33690619468688965,
      "orthogonal_weight": 0.1,
      "step": 255,
      "total_loss": 0.7157996296882629,
      "weighted_orthogonal_loss": 0.033690620213747025
    },
    {
      "classification_loss": 0.7020871639251709,
      "epoch": 0.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3358319401741028,
      "orthogonal_weight": 0.1,
      "step": 256,
      "total_loss": 0.7356703281402588,
      "weighted_orthogonal_loss": 0.03358319401741028
    },
    {
      "classification_loss": 0.6923204064369202,
      "epoch": 0.8426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33521562814712524,
      "orthogonal_weight": 0.1,
      "step": 257,
      "total_loss": 0.7258419990539551,
      "weighted_orthogonal_loss": 0.033521562814712524
    },
    {
      "classification_loss": 0.6896883249282837,
      "epoch": 0.8459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3348219096660614,
      "orthogonal_weight": 0.1,
      "step": 258,
      "total_loss": 0.7231705188751221,
      "weighted_orthogonal_loss": 0.03348219022154808
    },
    {
      "classification_loss": 0.7251152992248535,
      "epoch": 0.8491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3347092866897583,
      "orthogonal_weight": 0.1,
      "step": 259,
      "total_loss": 0.7585862278938293,
      "weighted_orthogonal_loss": 0.03347092866897583
    },
    {
      "classification_loss": 0.7211924195289612,
      "epoch": 0.8524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.334046870470047,
      "orthogonal_weight": 0.1,
      "step": 260,
      "total_loss": 0.7545971274375916,
      "weighted_orthogonal_loss": 0.03340468928217888
    },
    {
      "classification_loss": 0.690490186214447,
      "epoch": 0.8557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33374887704849243,
      "orthogonal_weight": 0.1,
      "step": 261,
      "total_loss": 0.7238650918006897,
      "weighted_orthogonal_loss": 0.033374886959791183
    },
    {
      "classification_loss": 0.6625384092330933,
      "epoch": 0.8590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3333245813846588,
      "orthogonal_weight": 0.1,
      "step": 262,
      "total_loss": 0.6958708763122559,
      "weighted_orthogonal_loss": 0.033332459628582
    },
    {
      "classification_loss": 0.686402440071106,
      "epoch": 0.8622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33239856362342834,
      "orthogonal_weight": 0.1,
      "step": 263,
      "total_loss": 0.7196422815322876,
      "weighted_orthogonal_loss": 0.033239856362342834
    },
    {
      "classification_loss": 0.704214870929718,
      "epoch": 0.8655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.33172574639320374,
      "orthogonal_weight": 0.1,
      "step": 264,
      "total_loss": 0.7373874187469482,
      "weighted_orthogonal_loss": 0.033172573894262314
    },
    {
      "classification_loss": 0.7487438321113586,
      "epoch": 0.8688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3311729431152344,
      "orthogonal_weight": 0.1,
      "step": 265,
      "total_loss": 0.7818611264228821,
      "weighted_orthogonal_loss": 0.03311729431152344
    },
    {
      "classification_loss": 0.6932242512702942,
      "epoch": 0.8721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3302973210811615,
      "orthogonal_weight": 0.1,
      "step": 266,
      "total_loss": 0.7262539863586426,
      "weighted_orthogonal_loss": 0.03302973136305809
    },
    {
      "classification_loss": 0.6740738153457642,
      "epoch": 0.8754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3285060524940491,
      "orthogonal_weight": 0.1,
      "step": 267,
      "total_loss": 0.7069244384765625,
      "weighted_orthogonal_loss": 0.03285060450434685
    },
    {
      "classification_loss": 0.6913735270500183,
      "epoch": 0.8786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3267294466495514,
      "orthogonal_weight": 0.1,
      "step": 268,
      "total_loss": 0.7240464687347412,
      "weighted_orthogonal_loss": 0.0326729454100132
    },
    {
      "classification_loss": 0.6990469694137573,
      "epoch": 0.8819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.325399249792099,
      "orthogonal_weight": 0.1,
      "step": 269,
      "total_loss": 0.7315868735313416,
      "weighted_orthogonal_loss": 0.03253992646932602
    },
    {
      "classification_loss": 0.682963490486145,
      "epoch": 0.8852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3239305913448334,
      "orthogonal_weight": 0.1,
      "step": 270,
      "total_loss": 0.7153565287590027,
      "weighted_orthogonal_loss": 0.03239306062459946
    },
    {
      "classification_loss": 0.6843394041061401,
      "epoch": 0.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3226834237575531,
      "orthogonal_weight": 0.1,
      "step": 271,
      "total_loss": 0.7166077494621277,
      "weighted_orthogonal_loss": 0.03226834163069725
    },
    {
      "classification_loss": 0.6777904033660889,
      "epoch": 0.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.32093891501426697,
      "orthogonal_weight": 0.1,
      "step": 272,
      "total_loss": 0.7098842859268188,
      "weighted_orthogonal_loss": 0.032093893736600876
    },
    {
      "classification_loss": 0.6715376377105713,
      "epoch": 0.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31853845715522766,
      "orthogonal_weight": 0.1,
      "step": 273,
      "total_loss": 0.7033914923667908,
      "weighted_orthogonal_loss": 0.031853847205638885
    },
    {
      "classification_loss": 0.6627050042152405,
      "epoch": 0.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31624945998191833,
      "orthogonal_weight": 0.1,
      "step": 274,
      "total_loss": 0.6943299770355225,
      "weighted_orthogonal_loss": 0.03162494674324989
    },
    {
      "classification_loss": 0.676760196685791,
      "epoch": 0.9016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3136797845363617,
      "orthogonal_weight": 0.1,
      "step": 275,
      "total_loss": 0.7081281542778015,
      "weighted_orthogonal_loss": 0.03136797994375229
    },
    {
      "classification_loss": 0.7003521919250488,
      "epoch": 0.9049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.31109386682510376,
      "orthogonal_weight": 0.1,
      "step": 276,
      "total_loss": 0.7314615845680237,
      "weighted_orthogonal_loss": 0.031109387055039406
    },
    {
      "classification_loss": 0.7159556746482849,
      "epoch": 0.9081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3090585768222809,
      "orthogonal_weight": 0.1,
      "step": 277,
      "total_loss": 0.7468615174293518,
      "weighted_orthogonal_loss": 0.03090585768222809
    },
    {
      "classification_loss": 0.6953652501106262,
      "epoch": 0.9114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3072658181190491,
      "orthogonal_weight": 0.1,
      "step": 278,
      "total_loss": 0.7260918617248535,
      "weighted_orthogonal_loss": 0.030726581811904907
    },
    {
      "classification_loss": 0.7143878936767578,
      "epoch": 0.9147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.30486053228378296,
      "orthogonal_weight": 0.1,
      "step": 279,
      "total_loss": 0.7448739409446716,
      "weighted_orthogonal_loss": 0.030486052855849266
    },
    {
      "classification_loss": 0.6829066276550293,
      "epoch": 0.9180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.30287325382232666,
      "orthogonal_weight": 0.1,
      "step": 280,
      "total_loss": 0.713193953037262,
      "weighted_orthogonal_loss": 0.030287325382232666
    },
    {
      "classification_loss": 0.6761268973350525,
      "epoch": 0.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.3009670078754425,
      "orthogonal_weight": 0.1,
      "step": 281,
      "total_loss": 0.7062236070632935,
      "weighted_orthogonal_loss": 0.03009670041501522
    },
    {
      "classification_loss": 0.6428988575935364,
      "epoch": 0.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2989319860935211,
      "orthogonal_weight": 0.1,
      "step": 282,
      "total_loss": 0.6727920770645142,
      "weighted_orthogonal_loss": 0.02989319898188114
    },
    {
      "classification_loss": 0.6993380784988403,
      "epoch": 0.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2969207465648651,
      "orthogonal_weight": 0.1,
      "step": 283,
      "total_loss": 0.7290301322937012,
      "weighted_orthogonal_loss": 0.02969207428395748
    },
    {
      "classification_loss": 0.699422299861908,
      "epoch": 0.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2955167293548584,
      "orthogonal_weight": 0.1,
      "step": 284,
      "total_loss": 0.7289739847183228,
      "weighted_orthogonal_loss": 0.0295516736805439
    },
    {
      "classification_loss": 0.6834523677825928,
      "epoch": 0.9344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.29412275552749634,
      "orthogonal_weight": 0.1,
      "step": 285,
      "total_loss": 0.7128646373748779,
      "weighted_orthogonal_loss": 0.029412275180220604
    },
    {
      "classification_loss": 0.7117388844490051,
      "epoch": 0.9377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.29269206523895264,
      "orthogonal_weight": 0.1,
      "step": 286,
      "total_loss": 0.7410081028938293,
      "weighted_orthogonal_loss": 0.029269207268953323
    },
    {
      "classification_loss": 0.6747452616691589,
      "epoch": 0.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2909381687641144,
      "orthogonal_weight": 0.1,
      "step": 287,
      "total_loss": 0.7038390636444092,
      "weighted_orthogonal_loss": 0.029093816876411438
    },
    {
      "classification_loss": 0.6852865219116211,
      "epoch": 0.9442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2891594469547272,
      "orthogonal_weight": 0.1,
      "step": 288,
      "total_loss": 0.7142024636268616,
      "weighted_orthogonal_loss": 0.028915945440530777
    },
    {
      "classification_loss": 0.6936940550804138,
      "epoch": 0.9475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2878511846065521,
      "orthogonal_weight": 0.1,
      "step": 289,
      "total_loss": 0.7224791646003723,
      "weighted_orthogonal_loss": 0.028785118833184242
    },
    {
      "classification_loss": 0.707270085811615,
      "epoch": 0.9508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28675803542137146,
      "orthogonal_weight": 0.1,
      "step": 290,
      "total_loss": 0.7359458804130554,
      "weighted_orthogonal_loss": 0.028675803914666176
    },
    {
      "classification_loss": 0.7036523818969727,
      "epoch": 0.9540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28540727496147156,
      "orthogonal_weight": 0.1,
      "step": 291,
      "total_loss": 0.732193112373352,
      "weighted_orthogonal_loss": 0.028540728613734245
    },
    {
      "classification_loss": 0.6904401183128357,
      "epoch": 0.9573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28368279337882996,
      "orthogonal_weight": 0.1,
      "step": 292,
      "total_loss": 0.7188084125518799,
      "weighted_orthogonal_loss": 0.028368279337882996
    },
    {
      "classification_loss": 0.6631379127502441,
      "epoch": 0.9606557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.28198614716529846,
      "orthogonal_weight": 0.1,
      "step": 293,
      "total_loss": 0.6913365125656128,
      "weighted_orthogonal_loss": 0.028198614716529846
    },
    {
      "classification_loss": 0.7169894576072693,
      "epoch": 0.9639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2804989516735077,
      "orthogonal_weight": 0.1,
      "step": 294,
      "total_loss": 0.7450393438339233,
      "weighted_orthogonal_loss": 0.0280498955398798
    },
    {
      "classification_loss": 0.7204880714416504,
      "epoch": 0.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27930310368537903,
      "orthogonal_weight": 0.1,
      "step": 295,
      "total_loss": 0.748418390750885,
      "weighted_orthogonal_loss": 0.027930309996008873
    },
    {
      "classification_loss": 0.6865708827972412,
      "epoch": 0.9704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27766022086143494,
      "orthogonal_weight": 0.1,
      "step": 296,
      "total_loss": 0.7143369317054749,
      "weighted_orthogonal_loss": 0.027766022831201553
    },
    {
      "classification_loss": 0.6753189563751221,
      "epoch": 0.9737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27612653374671936,
      "orthogonal_weight": 0.1,
      "step": 297,
      "total_loss": 0.7029315829277039,
      "weighted_orthogonal_loss": 0.027612654492259026
    },
    {
      "classification_loss": 0.6865256428718567,
      "epoch": 0.9770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2745974659919739,
      "orthogonal_weight": 0.1,
      "step": 298,
      "total_loss": 0.7139853835105896,
      "weighted_orthogonal_loss": 0.027459746226668358
    },
    {
      "classification_loss": 0.6472933888435364,
      "epoch": 0.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2729785740375519,
      "orthogonal_weight": 0.1,
      "step": 299,
      "total_loss": 0.6745912432670593,
      "weighted_orthogonal_loss": 0.027297858148813248
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 1.6842888593673706,
      "learning_rate": 0.0001933666666666667,
      "loss": 0.7322,
      "step": 300
    },
    {
      "classification_loss": 0.7104954719543457,
      "epoch": 0.9836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.27099910378456116,
      "orthogonal_weight": 0.1,
      "step": 300,
      "total_loss": 0.7375953793525696,
      "weighted_orthogonal_loss": 0.027099911123514175
    },
    {
      "classification_loss": 0.6617653369903564,
      "epoch": 0.9868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2692602872848511,
      "orthogonal_weight": 0.1,
      "step": 301,
      "total_loss": 0.6886913776397705,
      "weighted_orthogonal_loss": 0.026926029473543167
    },
    {
      "classification_loss": 0.6774289608001709,
      "epoch": 0.9901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2675319314002991,
      "orthogonal_weight": 0.1,
      "step": 302,
      "total_loss": 0.7041821479797363,
      "weighted_orthogonal_loss": 0.026753192767500877
    },
    {
      "classification_loss": 0.7033531665802002,
      "epoch": 0.9934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2659913897514343,
      "orthogonal_weight": 0.1,
      "step": 303,
      "total_loss": 0.729952335357666,
      "weighted_orthogonal_loss": 0.026599138975143433
    },
    {
      "classification_loss": 0.6561520099639893,
      "epoch": 0.9967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.26472708582878113,
      "orthogonal_weight": 0.1,
      "step": 304,
      "total_loss": 0.6826246976852417,
      "weighted_orthogonal_loss": 0.026472708210349083
    },
    {
      "classification_loss": 0.7586381435394287,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.784975528717041,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7098091840744019,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7361465692520142,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7640462517738342,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7903836369514465,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7550459504127502,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7813833355903625,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7194478511810303,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7457852363586426,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7673956155776978,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7937330007553101,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7585721015930176,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7849094867706299,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7495399713516235,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7758773565292358,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.397,
      "eval_f1": 0.12481857764876633,
      "eval_loss": 0.774107813835144,
      "eval_precision": 0.6515151515151515,
      "eval_recall": 0.06902086677367576,
      "eval_runtime": 8.1845,
      "eval_samples_per_second": 122.182,
      "eval_steps_per_second": 0.977,
      "step": 305
    },
    {
      "classification_loss": 0.6760485172271729,
      "epoch": 1.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2633739113807678,
      "orthogonal_weight": 0.1,
      "step": 305,
      "total_loss": 0.7023859024047852,
      "weighted_orthogonal_loss": 0.026337390765547752
    },
    {
      "classification_loss": 0.7126295566558838,
      "epoch": 1.0032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2619192898273468,
      "orthogonal_weight": 0.1,
      "step": 306,
      "total_loss": 0.7388215065002441,
      "weighted_orthogonal_loss": 0.02619192935526371
    },
    {
      "classification_loss": 0.7062454223632812,
      "epoch": 1.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.26080402731895447,
      "orthogonal_weight": 0.1,
      "step": 307,
      "total_loss": 0.7323258519172668,
      "weighted_orthogonal_loss": 0.026080403476953506
    },
    {
      "classification_loss": 0.6753818988800049,
      "epoch": 1.0098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25991737842559814,
      "orthogonal_weight": 0.1,
      "step": 308,
      "total_loss": 0.7013736367225647,
      "weighted_orthogonal_loss": 0.025991737842559814
    },
    {
      "classification_loss": 0.7051671743392944,
      "epoch": 1.0131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25883716344833374,
      "orthogonal_weight": 0.1,
      "step": 309,
      "total_loss": 0.7310509085655212,
      "weighted_orthogonal_loss": 0.025883717462420464
    },
    {
      "classification_loss": 0.6903932690620422,
      "epoch": 1.0163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2579008638858795,
      "orthogonal_weight": 0.1,
      "step": 310,
      "total_loss": 0.7161833643913269,
      "weighted_orthogonal_loss": 0.025790086016058922
    },
    {
      "classification_loss": 0.7038006782531738,
      "epoch": 1.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2571604549884796,
      "orthogonal_weight": 0.1,
      "step": 311,
      "total_loss": 0.7295167446136475,
      "weighted_orthogonal_loss": 0.02571604587137699
    },
    {
      "classification_loss": 0.6735870242118835,
      "epoch": 1.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2565362751483917,
      "orthogonal_weight": 0.1,
      "step": 312,
      "total_loss": 0.6992406249046326,
      "weighted_orthogonal_loss": 0.025653628632426262
    },
    {
      "classification_loss": 0.6625359058380127,
      "epoch": 1.0262295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2562583386898041,
      "orthogonal_weight": 0.1,
      "step": 313,
      "total_loss": 0.6881617307662964,
      "weighted_orthogonal_loss": 0.025625834241509438
    },
    {
      "classification_loss": 0.6659154891967773,
      "epoch": 1.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25571343302726746,
      "orthogonal_weight": 0.1,
      "step": 314,
      "total_loss": 0.6914868354797363,
      "weighted_orthogonal_loss": 0.025571344420313835
    },
    {
      "classification_loss": 0.6828592419624329,
      "epoch": 1.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2551187574863434,
      "orthogonal_weight": 0.1,
      "step": 315,
      "total_loss": 0.708371102809906,
      "weighted_orthogonal_loss": 0.02551187574863434
    },
    {
      "classification_loss": 0.7066404223442078,
      "epoch": 1.0360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2545590400695801,
      "orthogonal_weight": 0.1,
      "step": 316,
      "total_loss": 0.7320963144302368,
      "weighted_orthogonal_loss": 0.025455905124545097
    },
    {
      "classification_loss": 0.6811386942863464,
      "epoch": 1.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2541184425354004,
      "orthogonal_weight": 0.1,
      "step": 317,
      "total_loss": 0.7065505385398865,
      "weighted_orthogonal_loss": 0.02541184425354004
    },
    {
      "classification_loss": 0.6844079494476318,
      "epoch": 1.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25375205278396606,
      "orthogonal_weight": 0.1,
      "step": 318,
      "total_loss": 0.709783136844635,
      "weighted_orthogonal_loss": 0.025375206023454666
    },
    {
      "classification_loss": 0.7242345809936523,
      "epoch": 1.0459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2534180283546448,
      "orthogonal_weight": 0.1,
      "step": 319,
      "total_loss": 0.7495763897895813,
      "weighted_orthogonal_loss": 0.025341803207993507
    },
    {
      "classification_loss": 0.7201464772224426,
      "epoch": 1.0491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25268611311912537,
      "orthogonal_weight": 0.1,
      "step": 320,
      "total_loss": 0.7454150915145874,
      "weighted_orthogonal_loss": 0.025268612429499626
    },
    {
      "classification_loss": 0.6628994345664978,
      "epoch": 1.0524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25221168994903564,
      "orthogonal_weight": 0.1,
      "step": 321,
      "total_loss": 0.6881206035614014,
      "weighted_orthogonal_loss": 0.025221168994903564
    },
    {
      "classification_loss": 0.6726695895195007,
      "epoch": 1.0557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2513557970523834,
      "orthogonal_weight": 0.1,
      "step": 322,
      "total_loss": 0.6978051662445068,
      "weighted_orthogonal_loss": 0.025135580450296402
    },
    {
      "classification_loss": 0.6924920678138733,
      "epoch": 1.0590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.25038012862205505,
      "orthogonal_weight": 0.1,
      "step": 323,
      "total_loss": 0.7175300717353821,
      "weighted_orthogonal_loss": 0.025038013234734535
    },
    {
      "classification_loss": 0.7081001400947571,
      "epoch": 1.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24958749115467072,
      "orthogonal_weight": 0.1,
      "step": 324,
      "total_loss": 0.7330588698387146,
      "weighted_orthogonal_loss": 0.02495875023305416
    },
    {
      "classification_loss": 0.6917634010314941,
      "epoch": 1.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24864427745342255,
      "orthogonal_weight": 0.1,
      "step": 325,
      "total_loss": 0.716627836227417,
      "weighted_orthogonal_loss": 0.024864427745342255
    },
    {
      "classification_loss": 0.6682489514350891,
      "epoch": 1.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24746115505695343,
      "orthogonal_weight": 0.1,
      "step": 326,
      "total_loss": 0.6929950714111328,
      "weighted_orthogonal_loss": 0.024746116250753403
    },
    {
      "classification_loss": 0.6603385806083679,
      "epoch": 1.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24605976045131683,
      "orthogonal_weight": 0.1,
      "step": 327,
      "total_loss": 0.6849445700645447,
      "weighted_orthogonal_loss": 0.024605976417660713
    },
    {
      "classification_loss": 0.6837171912193298,
      "epoch": 1.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2445550560951233,
      "orthogonal_weight": 0.1,
      "step": 328,
      "total_loss": 0.7081726789474487,
      "weighted_orthogonal_loss": 0.02445550635457039
    },
    {
      "classification_loss": 0.6548986434936523,
      "epoch": 1.0786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.242965966463089,
      "orthogonal_weight": 0.1,
      "step": 329,
      "total_loss": 0.6791952252388,
      "weighted_orthogonal_loss": 0.0242965966463089
    },
    {
      "classification_loss": 0.6678162217140198,
      "epoch": 1.0819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.24151889979839325,
      "orthogonal_weight": 0.1,
      "step": 330,
      "total_loss": 0.6919680833816528,
      "weighted_orthogonal_loss": 0.024151889607310295
    },
    {
      "classification_loss": 0.7265428304672241,
      "epoch": 1.0852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23989789187908173,
      "orthogonal_weight": 0.1,
      "step": 331,
      "total_loss": 0.7505326271057129,
      "weighted_orthogonal_loss": 0.023989789187908173
    },
    {
      "classification_loss": 0.6921221613883972,
      "epoch": 1.0885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23853611946105957,
      "orthogonal_weight": 0.1,
      "step": 332,
      "total_loss": 0.7159757614135742,
      "weighted_orthogonal_loss": 0.023853613063693047
    },
    {
      "classification_loss": 0.7118532061576843,
      "epoch": 1.0918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23719435930252075,
      "orthogonal_weight": 0.1,
      "step": 333,
      "total_loss": 0.7355726361274719,
      "weighted_orthogonal_loss": 0.023719435557723045
    },
    {
      "classification_loss": 0.7200711965560913,
      "epoch": 1.0950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23590455949306488,
      "orthogonal_weight": 0.1,
      "step": 334,
      "total_loss": 0.743661642074585,
      "weighted_orthogonal_loss": 0.023590456694364548
    },
    {
      "classification_loss": 0.7556063532829285,
      "epoch": 1.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23463289439678192,
      "orthogonal_weight": 0.1,
      "step": 335,
      "total_loss": 0.7790696620941162,
      "weighted_orthogonal_loss": 0.023463290184736252
    },
    {
      "classification_loss": 0.7305862307548523,
      "epoch": 1.1016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23346887528896332,
      "orthogonal_weight": 0.1,
      "step": 336,
      "total_loss": 0.7539331316947937,
      "weighted_orthogonal_loss": 0.02334688790142536
    },
    {
      "classification_loss": 0.67507404088974,
      "epoch": 1.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23229748010635376,
      "orthogonal_weight": 0.1,
      "step": 337,
      "total_loss": 0.6983038187026978,
      "weighted_orthogonal_loss": 0.023229748010635376
    },
    {
      "classification_loss": 0.6927985548973083,
      "epoch": 1.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2317238450050354,
      "orthogonal_weight": 0.1,
      "step": 338,
      "total_loss": 0.7159709334373474,
      "weighted_orthogonal_loss": 0.02317238412797451
    },
    {
      "classification_loss": 0.7131684422492981,
      "epoch": 1.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23110826313495636,
      "orthogonal_weight": 0.1,
      "step": 339,
      "total_loss": 0.7362792491912842,
      "weighted_orthogonal_loss": 0.023110827431082726
    },
    {
      "classification_loss": 0.6603859066963196,
      "epoch": 1.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.23047961294651031,
      "orthogonal_weight": 0.1,
      "step": 340,
      "total_loss": 0.6834338903427124,
      "weighted_orthogonal_loss": 0.02304796129465103
    },
    {
      "classification_loss": 0.7127755284309387,
      "epoch": 1.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22975431382656097,
      "orthogonal_weight": 0.1,
      "step": 341,
      "total_loss": 0.7357509732246399,
      "weighted_orthogonal_loss": 0.022975431755185127
    },
    {
      "classification_loss": 0.6814512014389038,
      "epoch": 1.1213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22878728806972504,
      "orthogonal_weight": 0.1,
      "step": 342,
      "total_loss": 0.7043299078941345,
      "weighted_orthogonal_loss": 0.022878728806972504
    },
    {
      "classification_loss": 0.6962905526161194,
      "epoch": 1.1245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22793176770210266,
      "orthogonal_weight": 0.1,
      "step": 343,
      "total_loss": 0.7190837264060974,
      "weighted_orthogonal_loss": 0.022793177515268326
    },
    {
      "classification_loss": 0.6649888157844543,
      "epoch": 1.1278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22697816789150238,
      "orthogonal_weight": 0.1,
      "step": 344,
      "total_loss": 0.6876866221427917,
      "weighted_orthogonal_loss": 0.022697817534208298
    },
    {
      "classification_loss": 0.6876322031021118,
      "epoch": 1.1311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22612686455249786,
      "orthogonal_weight": 0.1,
      "step": 345,
      "total_loss": 0.71024489402771,
      "weighted_orthogonal_loss": 0.022612687200307846
    },
    {
      "classification_loss": 0.680931568145752,
      "epoch": 1.1344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.225213423371315,
      "orthogonal_weight": 0.1,
      "step": 346,
      "total_loss": 0.7034528851509094,
      "weighted_orthogonal_loss": 0.02252134308218956
    },
    {
      "classification_loss": 0.6928059458732605,
      "epoch": 1.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.224138081073761,
      "orthogonal_weight": 0.1,
      "step": 347,
      "total_loss": 0.7152197360992432,
      "weighted_orthogonal_loss": 0.02241380885243416
    },
    {
      "classification_loss": 0.7037478089332581,
      "epoch": 1.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2234186828136444,
      "orthogonal_weight": 0.1,
      "step": 348,
      "total_loss": 0.7260896563529968,
      "weighted_orthogonal_loss": 0.02234186790883541
    },
    {
      "classification_loss": 0.6988489031791687,
      "epoch": 1.1442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22254525125026703,
      "orthogonal_weight": 0.1,
      "step": 349,
      "total_loss": 0.7211034297943115,
      "weighted_orthogonal_loss": 0.022254524752497673
    },
    {
      "classification_loss": 0.6351805925369263,
      "epoch": 1.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22204752266407013,
      "orthogonal_weight": 0.1,
      "step": 350,
      "total_loss": 0.6573853492736816,
      "weighted_orthogonal_loss": 0.022204753011465073
    },
    {
      "classification_loss": 0.6750702261924744,
      "epoch": 1.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.22062623500823975,
      "orthogonal_weight": 0.1,
      "step": 351,
      "total_loss": 0.6971328258514404,
      "weighted_orthogonal_loss": 0.022062623873353004
    },
    {
      "classification_loss": 0.693098783493042,
      "epoch": 1.1540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21890169382095337,
      "orthogonal_weight": 0.1,
      "step": 352,
      "total_loss": 0.7149889469146729,
      "weighted_orthogonal_loss": 0.021890169009566307
    },
    {
      "classification_loss": 0.6444952487945557,
      "epoch": 1.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21752937138080597,
      "orthogonal_weight": 0.1,
      "step": 353,
      "total_loss": 0.6662482023239136,
      "weighted_orthogonal_loss": 0.021752936765551567
    },
    {
      "classification_loss": 0.6842991709709167,
      "epoch": 1.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2158692479133606,
      "orthogonal_weight": 0.1,
      "step": 354,
      "total_loss": 0.7058861255645752,
      "weighted_orthogonal_loss": 0.02158692479133606
    },
    {
      "classification_loss": 0.6565185785293579,
      "epoch": 1.1639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21479228138923645,
      "orthogonal_weight": 0.1,
      "step": 355,
      "total_loss": 0.6779978275299072,
      "weighted_orthogonal_loss": 0.021479228511452675
    },
    {
      "classification_loss": 0.6757163405418396,
      "epoch": 1.1672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2138439565896988,
      "orthogonal_weight": 0.1,
      "step": 356,
      "total_loss": 0.6971007585525513,
      "weighted_orthogonal_loss": 0.02138439565896988
    },
    {
      "classification_loss": 0.6578404903411865,
      "epoch": 1.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2133059948682785,
      "orthogonal_weight": 0.1,
      "step": 357,
      "total_loss": 0.679171085357666,
      "weighted_orthogonal_loss": 0.02133060060441494
    },
    {
      "classification_loss": 0.6937738656997681,
      "epoch": 1.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21287782490253448,
      "orthogonal_weight": 0.1,
      "step": 358,
      "total_loss": 0.7150616645812988,
      "weighted_orthogonal_loss": 0.02128778211772442
    },
    {
      "classification_loss": 0.6706214547157288,
      "epoch": 1.1770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21231801807880402,
      "orthogonal_weight": 0.1,
      "step": 359,
      "total_loss": 0.6918532848358154,
      "weighted_orthogonal_loss": 0.02123180218040943
    },
    {
      "classification_loss": 0.6946905255317688,
      "epoch": 1.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21176491677761078,
      "orthogonal_weight": 0.1,
      "step": 360,
      "total_loss": 0.7158670425415039,
      "weighted_orthogonal_loss": 0.021176492795348167
    },
    {
      "classification_loss": 0.7009189128875732,
      "epoch": 1.1836065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21143463253974915,
      "orthogonal_weight": 0.1,
      "step": 361,
      "total_loss": 0.722062349319458,
      "weighted_orthogonal_loss": 0.021143464371562004
    },
    {
      "classification_loss": 0.691291093826294,
      "epoch": 1.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113853543996811,
      "orthogonal_weight": 0.1,
      "step": 362,
      "total_loss": 0.7124296426773071,
      "weighted_orthogonal_loss": 0.02113853581249714
    },
    {
      "classification_loss": 0.6869188547134399,
      "epoch": 1.1901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21133418381214142,
      "orthogonal_weight": 0.1,
      "step": 363,
      "total_loss": 0.7080522775650024,
      "weighted_orthogonal_loss": 0.0211334191262722
    },
    {
      "classification_loss": 0.6407412886619568,
      "epoch": 1.1934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099312603473663,
      "orthogonal_weight": 0.1,
      "step": 364,
      "total_loss": 0.6618406176567078,
      "weighted_orthogonal_loss": 0.021099312230944633
    },
    {
      "classification_loss": 0.7371107339859009,
      "epoch": 1.1967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21058566868305206,
      "orthogonal_weight": 0.1,
      "step": 365,
      "total_loss": 0.7581692934036255,
      "weighted_orthogonal_loss": 0.021058566868305206
    },
    {
      "classification_loss": 0.6989250779151917,
      "epoch": 1.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21007034182548523,
      "orthogonal_weight": 0.1,
      "step": 366,
      "total_loss": 0.7199321389198303,
      "weighted_orthogonal_loss": 0.021007034927606583
    },
    {
      "classification_loss": 0.6605021953582764,
      "epoch": 1.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20950500667095184,
      "orthogonal_weight": 0.1,
      "step": 367,
      "total_loss": 0.6814526915550232,
      "weighted_orthogonal_loss": 0.020950501784682274
    },
    {
      "classification_loss": 0.7338178753852844,
      "epoch": 1.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092246562242508,
      "orthogonal_weight": 0.1,
      "step": 368,
      "total_loss": 0.7547403573989868,
      "weighted_orthogonal_loss": 0.02092246524989605
    },
    {
      "classification_loss": 0.6947116851806641,
      "epoch": 1.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20880532264709473,
      "orthogonal_weight": 0.1,
      "step": 369,
      "total_loss": 0.7155922055244446,
      "weighted_orthogonal_loss": 0.020880533382296562
    },
    {
      "classification_loss": 0.6464808583259583,
      "epoch": 1.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086644470691681,
      "orthogonal_weight": 0.1,
      "step": 370,
      "total_loss": 0.6673473119735718,
      "weighted_orthogonal_loss": 0.02086644433438778
    },
    {
      "classification_loss": 0.6603268384933472,
      "epoch": 1.2163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20871475338935852,
      "orthogonal_weight": 0.1,
      "step": 371,
      "total_loss": 0.6811982989311218,
      "weighted_orthogonal_loss": 0.020871475338935852
    },
    {
      "classification_loss": 0.7224637866020203,
      "epoch": 1.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087203413248062,
      "orthogonal_weight": 0.1,
      "step": 372,
      "total_loss": 0.7433358430862427,
      "weighted_orthogonal_loss": 0.02087203413248062
    },
    {
      "classification_loss": 0.7160760164260864,
      "epoch": 1.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20881342887878418,
      "orthogonal_weight": 0.1,
      "step": 373,
      "total_loss": 0.7369573712348938,
      "weighted_orthogonal_loss": 0.020881343632936478
    },
    {
      "classification_loss": 0.6603718996047974,
      "epoch": 1.2262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867934823036194,
      "orthogonal_weight": 0.1,
      "step": 374,
      "total_loss": 0.6812398433685303,
      "weighted_orthogonal_loss": 0.020867934450507164
    },
    {
      "classification_loss": 0.707343339920044,
      "epoch": 1.2295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20831549167633057,
      "orthogonal_weight": 0.1,
      "step": 375,
      "total_loss": 0.7281748652458191,
      "weighted_orthogonal_loss": 0.020831549540162086
    },
    {
      "classification_loss": 0.6637990474700928,
      "epoch": 1.2327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20814068615436554,
      "orthogonal_weight": 0.1,
      "step": 376,
      "total_loss": 0.6846131086349487,
      "weighted_orthogonal_loss": 0.020814068615436554
    },
    {
      "classification_loss": 0.6992805004119873,
      "epoch": 1.2360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20656615495681763,
      "orthogonal_weight": 0.1,
      "step": 377,
      "total_loss": 0.7199370861053467,
      "weighted_orthogonal_loss": 0.020656615495681763
    },
    {
      "classification_loss": 0.6749974489212036,
      "epoch": 1.2393442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20476697385311127,
      "orthogonal_weight": 0.1,
      "step": 378,
      "total_loss": 0.6954741477966309,
      "weighted_orthogonal_loss": 0.020476697012782097
    },
    {
      "classification_loss": 0.6727122068405151,
      "epoch": 1.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306670665740967,
      "orthogonal_weight": 0.1,
      "step": 379,
      "total_loss": 0.6930188536643982,
      "weighted_orthogonal_loss": 0.020306671038269997
    },
    {
      "classification_loss": 0.6686294674873352,
      "epoch": 1.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20184336602687836,
      "orthogonal_weight": 0.1,
      "step": 380,
      "total_loss": 0.6888138055801392,
      "weighted_orthogonal_loss": 0.020184336230158806
    },
    {
      "classification_loss": 0.7060471773147583,
      "epoch": 1.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2008264809846878,
      "orthogonal_weight": 0.1,
      "step": 381,
      "total_loss": 0.7261298298835754,
      "weighted_orthogonal_loss": 0.02008264884352684
    },
    {
      "classification_loss": 0.6292046308517456,
      "epoch": 1.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2000742107629776,
      "orthogonal_weight": 0.1,
      "step": 382,
      "total_loss": 0.6492120623588562,
      "weighted_orthogonal_loss": 0.02000742219388485
    },
    {
      "classification_loss": 0.6614510416984558,
      "epoch": 1.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19913014769554138,
      "orthogonal_weight": 0.1,
      "step": 383,
      "total_loss": 0.6813640594482422,
      "weighted_orthogonal_loss": 0.019913015887141228
    },
    {
      "classification_loss": 0.7295617461204529,
      "epoch": 1.2590163934426228,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19836504757404327,
      "orthogonal_weight": 0.1,
      "step": 384,
      "total_loss": 0.7493982315063477,
      "weighted_orthogonal_loss": 0.019836505874991417
    },
    {
      "classification_loss": 0.653960108757019,
      "epoch": 1.2622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19769173860549927,
      "orthogonal_weight": 0.1,
      "step": 385,
      "total_loss": 0.6737293004989624,
      "weighted_orthogonal_loss": 0.019769174978137016
    },
    {
      "classification_loss": 0.7309483289718628,
      "epoch": 1.2655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19716045260429382,
      "orthogonal_weight": 0.1,
      "step": 386,
      "total_loss": 0.7506643533706665,
      "weighted_orthogonal_loss": 0.019716044887900352
    },
    {
      "classification_loss": 0.6260085105895996,
      "epoch": 1.2688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19669222831726074,
      "orthogonal_weight": 0.1,
      "step": 387,
      "total_loss": 0.6456777453422546,
      "weighted_orthogonal_loss": 0.019669223576784134
    },
    {
      "classification_loss": 0.6501620411872864,
      "epoch": 1.2721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19645285606384277,
      "orthogonal_weight": 0.1,
      "step": 388,
      "total_loss": 0.6698073148727417,
      "weighted_orthogonal_loss": 0.019645286723971367
    },
    {
      "classification_loss": 0.6825761795043945,
      "epoch": 1.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19600921869277954,
      "orthogonal_weight": 0.1,
      "step": 389,
      "total_loss": 0.702177107334137,
      "weighted_orthogonal_loss": 0.019600922241806984
    },
    {
      "classification_loss": 0.7074939608573914,
      "epoch": 1.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19559258222579956,
      "orthogonal_weight": 0.1,
      "step": 390,
      "total_loss": 0.7270532250404358,
      "weighted_orthogonal_loss": 0.019559258595108986
    },
    {
      "classification_loss": 0.6679697036743164,
      "epoch": 1.2819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19518104195594788,
      "orthogonal_weight": 0.1,
      "step": 391,
      "total_loss": 0.687487781047821,
      "weighted_orthogonal_loss": 0.019518105313181877
    },
    {
      "classification_loss": 0.6675586700439453,
      "epoch": 1.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1944340318441391,
      "orthogonal_weight": 0.1,
      "step": 392,
      "total_loss": 0.6870020627975464,
      "weighted_orthogonal_loss": 0.01944340392947197
    },
    {
      "classification_loss": 0.7105339765548706,
      "epoch": 1.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.193699911236763,
      "orthogonal_weight": 0.1,
      "step": 393,
      "total_loss": 0.7299039959907532,
      "weighted_orthogonal_loss": 0.01936999149620533
    },
    {
      "classification_loss": 0.6982964277267456,
      "epoch": 1.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1929759681224823,
      "orthogonal_weight": 0.1,
      "step": 394,
      "total_loss": 0.7175940275192261,
      "weighted_orthogonal_loss": 0.01929759792983532
    },
    {
      "classification_loss": 0.6925759315490723,
      "epoch": 1.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1922474205493927,
      "orthogonal_weight": 0.1,
      "step": 395,
      "total_loss": 0.7118006944656372,
      "weighted_orthogonal_loss": 0.0192247424274683
    },
    {
      "classification_loss": 0.6858789324760437,
      "epoch": 1.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19115379452705383,
      "orthogonal_weight": 0.1,
      "step": 396,
      "total_loss": 0.7049943208694458,
      "weighted_orthogonal_loss": 0.019115379080176353
    },
    {
      "classification_loss": 0.6950842142105103,
      "epoch": 1.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19025449454784393,
      "orthogonal_weight": 0.1,
      "step": 397,
      "total_loss": 0.7141096591949463,
      "weighted_orthogonal_loss": 0.019025450572371483
    },
    {
      "classification_loss": 0.7008205652236938,
      "epoch": 1.3049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18919292092323303,
      "orthogonal_weight": 0.1,
      "step": 398,
      "total_loss": 0.7197398543357849,
      "weighted_orthogonal_loss": 0.018919292837381363
    },
    {
      "classification_loss": 0.716442883014679,
      "epoch": 1.3081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1879114955663681,
      "orthogonal_weight": 0.1,
      "step": 399,
      "total_loss": 0.7352340221405029,
      "weighted_orthogonal_loss": 0.01879115030169487
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 3.5166385173797607,
      "learning_rate": 0.00019003333333333336,
      "loss": 0.7093,
      "step": 400
    },
    {
      "classification_loss": 0.7023847103118896,
      "epoch": 1.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1867154985666275,
      "orthogonal_weight": 0.1,
      "step": 400,
      "total_loss": 0.7210562825202942,
      "weighted_orthogonal_loss": 0.01867154985666275
    },
    {
      "classification_loss": 0.6966331601142883,
      "epoch": 1.3147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18561314046382904,
      "orthogonal_weight": 0.1,
      "step": 401,
      "total_loss": 0.7151944637298584,
      "weighted_orthogonal_loss": 0.018561314791440964
    },
    {
      "classification_loss": 0.6615169048309326,
      "epoch": 1.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18448621034622192,
      "orthogonal_weight": 0.1,
      "step": 402,
      "total_loss": 0.6799654960632324,
      "weighted_orthogonal_loss": 0.018448621034622192
    },
    {
      "classification_loss": 0.6886668801307678,
      "epoch": 1.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18355810642242432,
      "orthogonal_weight": 0.1,
      "step": 403,
      "total_loss": 0.7070226669311523,
      "weighted_orthogonal_loss": 0.01835581101477146
    },
    {
      "classification_loss": 0.6691579818725586,
      "epoch": 1.3245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18270279467105865,
      "orthogonal_weight": 0.1,
      "step": 404,
      "total_loss": 0.6874282360076904,
      "weighted_orthogonal_loss": 0.018270280212163925
    },
    {
      "classification_loss": 0.7182741165161133,
      "epoch": 1.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18182948231697083,
      "orthogonal_weight": 0.1,
      "step": 405,
      "total_loss": 0.7364570498466492,
      "weighted_orthogonal_loss": 0.018182948231697083
    },
    {
      "classification_loss": 0.6815933585166931,
      "epoch": 1.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18094505369663239,
      "orthogonal_weight": 0.1,
      "step": 406,
      "total_loss": 0.6996878385543823,
      "weighted_orthogonal_loss": 0.018094506114721298
    },
    {
      "classification_loss": 0.7136009931564331,
      "epoch": 1.3344262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18006837368011475,
      "orthogonal_weight": 0.1,
      "step": 407,
      "total_loss": 0.7316078543663025,
      "weighted_orthogonal_loss": 0.018006836995482445
    },
    {
      "classification_loss": 0.6581984162330627,
      "epoch": 1.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17931456863880157,
      "orthogonal_weight": 0.1,
      "step": 408,
      "total_loss": 0.6761298775672913,
      "weighted_orthogonal_loss": 0.017931457608938217
    },
    {
      "classification_loss": 0.6597433686256409,
      "epoch": 1.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1786605417728424,
      "orthogonal_weight": 0.1,
      "step": 409,
      "total_loss": 0.6776094436645508,
      "weighted_orthogonal_loss": 0.01786605454981327
    },
    {
      "classification_loss": 0.6578325033187866,
      "epoch": 1.3442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17808100581169128,
      "orthogonal_weight": 0.1,
      "step": 410,
      "total_loss": 0.6756405830383301,
      "weighted_orthogonal_loss": 0.0178081002086401
    },
    {
      "classification_loss": 0.6972450017929077,
      "epoch": 1.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17726559937000275,
      "orthogonal_weight": 0.1,
      "step": 411,
      "total_loss": 0.7149715423583984,
      "weighted_orthogonal_loss": 0.017726561054587364
    },
    {
      "classification_loss": 0.7191892862319946,
      "epoch": 1.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17663680016994476,
      "orthogonal_weight": 0.1,
      "step": 412,
      "total_loss": 0.7368529438972473,
      "weighted_orthogonal_loss": 0.017663680016994476
    },
    {
      "classification_loss": 0.7038128972053528,
      "epoch": 1.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1761375218629837,
      "orthogonal_weight": 0.1,
      "step": 413,
      "total_loss": 0.7214266657829285,
      "weighted_orthogonal_loss": 0.01761375181376934
    },
    {
      "classification_loss": 0.73073810338974,
      "epoch": 1.3573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17577716708183289,
      "orthogonal_weight": 0.1,
      "step": 414,
      "total_loss": 0.7483158111572266,
      "weighted_orthogonal_loss": 0.01757771708071232
    },
    {
      "classification_loss": 0.6523041725158691,
      "epoch": 1.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1755356788635254,
      "orthogonal_weight": 0.1,
      "step": 415,
      "total_loss": 0.6698577404022217,
      "weighted_orthogonal_loss": 0.01755356788635254
    },
    {
      "classification_loss": 0.697857141494751,
      "epoch": 1.3639344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17538869380950928,
      "orthogonal_weight": 0.1,
      "step": 416,
      "total_loss": 0.715395987033844,
      "weighted_orthogonal_loss": 0.017538869753479958
    },
    {
      "classification_loss": 0.6723056435585022,
      "epoch": 1.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17528767883777618,
      "orthogonal_weight": 0.1,
      "step": 417,
      "total_loss": 0.6898344159126282,
      "weighted_orthogonal_loss": 0.017528768628835678
    },
    {
      "classification_loss": 0.6879700422286987,
      "epoch": 1.3704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752515435218811,
      "orthogonal_weight": 0.1,
      "step": 418,
      "total_loss": 0.7054951786994934,
      "weighted_orthogonal_loss": 0.01752515509724617
    },
    {
      "classification_loss": 0.6672960519790649,
      "epoch": 1.3737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17517590522766113,
      "orthogonal_weight": 0.1,
      "step": 419,
      "total_loss": 0.6848136186599731,
      "weighted_orthogonal_loss": 0.017517590895295143
    },
    {
      "classification_loss": 0.6645621657371521,
      "epoch": 1.3770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17516350746154785,
      "orthogonal_weight": 0.1,
      "step": 420,
      "total_loss": 0.6820785403251648,
      "weighted_orthogonal_loss": 0.017516350373625755
    },
    {
      "classification_loss": 0.654904842376709,
      "epoch": 1.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17510023713111877,
      "orthogonal_weight": 0.1,
      "step": 421,
      "total_loss": 0.6724148392677307,
      "weighted_orthogonal_loss": 0.017510024830698967
    },
    {
      "classification_loss": 0.6455605030059814,
      "epoch": 1.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746787577867508,
      "orthogonal_weight": 0.1,
      "step": 422,
      "total_loss": 0.663028359413147,
      "weighted_orthogonal_loss": 0.01746787689626217
    },
    {
      "classification_loss": 0.697586178779602,
      "epoch": 1.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17437441647052765,
      "orthogonal_weight": 0.1,
      "step": 423,
      "total_loss": 0.7150236368179321,
      "weighted_orthogonal_loss": 0.017437441274523735
    },
    {
      "classification_loss": 0.6837738752365112,
      "epoch": 1.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17383024096488953,
      "orthogonal_weight": 0.1,
      "step": 424,
      "total_loss": 0.7011569142341614,
      "weighted_orthogonal_loss": 0.017383024096488953
    },
    {
      "classification_loss": 0.6789612770080566,
      "epoch": 1.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17335140705108643,
      "orthogonal_weight": 0.1,
      "step": 425,
      "total_loss": 0.6962963938713074,
      "weighted_orthogonal_loss": 0.017335141077637672
    },
    {
      "classification_loss": 0.6729797124862671,
      "epoch": 1.3967213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17292919754981995,
      "orthogonal_weight": 0.1,
      "step": 426,
      "total_loss": 0.6902726292610168,
      "weighted_orthogonal_loss": 0.017292920500040054
    },
    {
      "classification_loss": 0.6355559229850769,
      "epoch": 1.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726539433002472,
      "orthogonal_weight": 0.1,
      "step": 427,
      "total_loss": 0.6528213024139404,
      "weighted_orthogonal_loss": 0.01726539433002472
    },
    {
      "classification_loss": 0.7157954573631287,
      "epoch": 1.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17239733040332794,
      "orthogonal_weight": 0.1,
      "step": 428,
      "total_loss": 0.7330352067947388,
      "weighted_orthogonal_loss": 0.017239732667803764
    },
    {
      "classification_loss": 0.6634870767593384,
      "epoch": 1.4065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17215056717395782,
      "orthogonal_weight": 0.1,
      "step": 429,
      "total_loss": 0.6807021498680115,
      "weighted_orthogonal_loss": 0.017215056344866753
    },
    {
      "classification_loss": 0.6395498514175415,
      "epoch": 1.4098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17164736986160278,
      "orthogonal_weight": 0.1,
      "step": 430,
      "total_loss": 0.6567145586013794,
      "weighted_orthogonal_loss": 0.01716473698616028
    },
    {
      "classification_loss": 0.7211899161338806,
      "epoch": 1.4131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17108888924121857,
      "orthogonal_weight": 0.1,
      "step": 431,
      "total_loss": 0.7382988333702087,
      "weighted_orthogonal_loss": 0.017108889296650887
    },
    {
      "classification_loss": 0.679692804813385,
      "epoch": 1.4163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17060372233390808,
      "orthogonal_weight": 0.1,
      "step": 432,
      "total_loss": 0.696753203868866,
      "weighted_orthogonal_loss": 0.017060372978448868
    },
    {
      "classification_loss": 0.6816567778587341,
      "epoch": 1.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17020975053310394,
      "orthogonal_weight": 0.1,
      "step": 433,
      "total_loss": 0.6986777782440186,
      "weighted_orthogonal_loss": 0.017020976170897484
    },
    {
      "classification_loss": 0.6598649621009827,
      "epoch": 1.4229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1695837527513504,
      "orthogonal_weight": 0.1,
      "step": 434,
      "total_loss": 0.6768233180046082,
      "weighted_orthogonal_loss": 0.01695837639272213
    },
    {
      "classification_loss": 0.7216187715530396,
      "epoch": 1.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16904012858867645,
      "orthogonal_weight": 0.1,
      "step": 435,
      "total_loss": 0.7385227680206299,
      "weighted_orthogonal_loss": 0.016904013231396675
    },
    {
      "classification_loss": 0.6686830520629883,
      "epoch": 1.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16885380446910858,
      "orthogonal_weight": 0.1,
      "step": 436,
      "total_loss": 0.6855684518814087,
      "weighted_orthogonal_loss": 0.016885381191968918
    },
    {
      "classification_loss": 0.6622757911682129,
      "epoch": 1.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687709540128708,
      "orthogonal_weight": 0.1,
      "step": 437,
      "total_loss": 0.6791529059410095,
      "weighted_orthogonal_loss": 0.01687709614634514
    },
    {
      "classification_loss": 0.7167749404907227,
      "epoch": 1.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1688273698091507,
      "orthogonal_weight": 0.1,
      "step": 438,
      "total_loss": 0.7336576581001282,
      "weighted_orthogonal_loss": 0.01688273809850216
    },
    {
      "classification_loss": 0.6775994300842285,
      "epoch": 1.4393442622950818,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16891181468963623,
      "orthogonal_weight": 0.1,
      "step": 439,
      "total_loss": 0.6944906115531921,
      "weighted_orthogonal_loss": 0.016891181468963623
    },
    {
      "classification_loss": 0.6316713690757751,
      "epoch": 1.4426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16898831725120544,
      "orthogonal_weight": 0.1,
      "step": 440,
      "total_loss": 0.64857017993927,
      "weighted_orthogonal_loss": 0.016898831352591515
    },
    {
      "classification_loss": 0.7247359752655029,
      "epoch": 1.4459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16900552809238434,
      "orthogonal_weight": 0.1,
      "step": 441,
      "total_loss": 0.7416365146636963,
      "weighted_orthogonal_loss": 0.016900552436709404
    },
    {
      "classification_loss": 0.6699919700622559,
      "epoch": 1.4491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1689058095216751,
      "orthogonal_weight": 0.1,
      "step": 442,
      "total_loss": 0.6868825554847717,
      "weighted_orthogonal_loss": 0.01689058169722557
    },
    {
      "classification_loss": 0.6843569874763489,
      "epoch": 1.4524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687161773443222,
      "orthogonal_weight": 0.1,
      "step": 443,
      "total_loss": 0.7012286186218262,
      "weighted_orthogonal_loss": 0.01687161810696125
    },
    {
      "classification_loss": 0.7133574485778809,
      "epoch": 1.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16855983436107635,
      "orthogonal_weight": 0.1,
      "step": 444,
      "total_loss": 0.7302134037017822,
      "weighted_orthogonal_loss": 0.016855983063578606
    },
    {
      "classification_loss": 0.6527412533760071,
      "epoch": 1.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16847673058509827,
      "orthogonal_weight": 0.1,
      "step": 445,
      "total_loss": 0.6695889234542847,
      "weighted_orthogonal_loss": 0.016847673803567886
    },
    {
      "classification_loss": 0.7041845321655273,
      "epoch": 1.4622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16840772330760956,
      "orthogonal_weight": 0.1,
      "step": 446,
      "total_loss": 0.721025288105011,
      "weighted_orthogonal_loss": 0.016840772703289986
    },
    {
      "classification_loss": 0.6711299419403076,
      "epoch": 1.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16834130883216858,
      "orthogonal_weight": 0.1,
      "step": 447,
      "total_loss": 0.6879640817642212,
      "weighted_orthogonal_loss": 0.016834130510687828
    },
    {
      "classification_loss": 0.6618975400924683,
      "epoch": 1.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682841181755066,
      "orthogonal_weight": 0.1,
      "step": 448,
      "total_loss": 0.6787259578704834,
      "weighted_orthogonal_loss": 0.01682841219007969
    },
    {
      "classification_loss": 0.7346258163452148,
      "epoch": 1.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16827106475830078,
      "orthogonal_weight": 0.1,
      "step": 449,
      "total_loss": 0.7514529228210449,
      "weighted_orthogonal_loss": 0.016827106475830078
    },
    {
      "classification_loss": 0.6776800155639648,
      "epoch": 1.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682426780462265,
      "orthogonal_weight": 0.1,
      "step": 450,
      "total_loss": 0.6945042610168457,
      "weighted_orthogonal_loss": 0.01682426780462265
    },
    {
      "classification_loss": 0.7116441130638123,
      "epoch": 1.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682754009962082,
      "orthogonal_weight": 0.1,
      "step": 451,
      "total_loss": 0.7284716367721558,
      "weighted_orthogonal_loss": 0.01682754047214985
    },
    {
      "classification_loss": 0.6829038858413696,
      "epoch": 1.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16835613548755646,
      "orthogonal_weight": 0.1,
      "step": 452,
      "total_loss": 0.6997395157814026,
      "weighted_orthogonal_loss": 0.016835613176226616
    },
    {
      "classification_loss": 0.6859257221221924,
      "epoch": 1.4852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1686127483844757,
      "orthogonal_weight": 0.1,
      "step": 453,
      "total_loss": 0.7027869820594788,
      "weighted_orthogonal_loss": 0.01686127483844757
    },
    {
      "classification_loss": 0.7086890935897827,
      "epoch": 1.4885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16889937222003937,
      "orthogonal_weight": 0.1,
      "step": 454,
      "total_loss": 0.725579023361206,
      "weighted_orthogonal_loss": 0.016889937222003937
    },
    {
      "classification_loss": 0.7025039196014404,
      "epoch": 1.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691422015428543,
      "orthogonal_weight": 0.1,
      "step": 455,
      "total_loss": 0.7194181680679321,
      "weighted_orthogonal_loss": 0.01691422052681446
    },
    {
      "classification_loss": 0.6664518713951111,
      "epoch": 1.4950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16924826800823212,
      "orthogonal_weight": 0.1,
      "step": 456,
      "total_loss": 0.683376669883728,
      "weighted_orthogonal_loss": 0.016924826428294182
    },
    {
      "classification_loss": 0.6821839213371277,
      "epoch": 1.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691545844078064,
      "orthogonal_weight": 0.1,
      "step": 457,
      "total_loss": 0.6990993618965149,
      "weighted_orthogonal_loss": 0.0169154591858387
    },
    {
      "classification_loss": 0.6638921499252319,
      "epoch": 1.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16912803053855896,
      "orthogonal_weight": 0.1,
      "step": 458,
      "total_loss": 0.680804967880249,
      "weighted_orthogonal_loss": 0.016912803053855896
    },
    {
      "classification_loss": 0.7036628127098083,
      "epoch": 1.5049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1691640168428421,
      "orthogonal_weight": 0.1,
      "step": 459,
      "total_loss": 0.720579206943512,
      "weighted_orthogonal_loss": 0.01691640168428421
    },
    {
      "classification_loss": 0.703702449798584,
      "epoch": 1.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1692972183227539,
      "orthogonal_weight": 0.1,
      "step": 460,
      "total_loss": 0.7206321954727173,
      "weighted_orthogonal_loss": 0.01692972145974636
    },
    {
      "classification_loss": 0.6953514814376831,
      "epoch": 1.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16950930655002594,
      "orthogonal_weight": 0.1,
      "step": 461,
      "total_loss": 0.7123023867607117,
      "weighted_orthogonal_loss": 0.016950931400060654
    },
    {
      "classification_loss": 0.667876124382019,
      "epoch": 1.5147540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1699363738298416,
      "orthogonal_weight": 0.1,
      "step": 462,
      "total_loss": 0.6848697662353516,
      "weighted_orthogonal_loss": 0.01699363812804222
    },
    {
      "classification_loss": 0.6868926286697388,
      "epoch": 1.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1703789085149765,
      "orthogonal_weight": 0.1,
      "step": 463,
      "total_loss": 0.7039304971694946,
      "weighted_orthogonal_loss": 0.01703789085149765
    },
    {
      "classification_loss": 0.6933236718177795,
      "epoch": 1.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17079584300518036,
      "orthogonal_weight": 0.1,
      "step": 464,
      "total_loss": 0.7104032635688782,
      "weighted_orthogonal_loss": 0.017079584300518036
    },
    {
      "classification_loss": 0.6643062829971313,
      "epoch": 1.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17119818925857544,
      "orthogonal_weight": 0.1,
      "step": 465,
      "total_loss": 0.6814261078834534,
      "weighted_orthogonal_loss": 0.017119819298386574
    },
    {
      "classification_loss": 0.6985829472541809,
      "epoch": 1.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17155137658119202,
      "orthogonal_weight": 0.1,
      "step": 466,
      "total_loss": 0.71573805809021,
      "weighted_orthogonal_loss": 0.01715513877570629
    },
    {
      "classification_loss": 0.6831623315811157,
      "epoch": 1.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1718934178352356,
      "orthogonal_weight": 0.1,
      "step": 467,
      "total_loss": 0.7003516554832458,
      "weighted_orthogonal_loss": 0.01718934252858162
    },
    {
      "classification_loss": 0.6757249236106873,
      "epoch": 1.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17181284725666046,
      "orthogonal_weight": 0.1,
      "step": 468,
      "total_loss": 0.6929062008857727,
      "weighted_orthogonal_loss": 0.017181284725666046
    },
    {
      "classification_loss": 0.654961884021759,
      "epoch": 1.5377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17169158160686493,
      "orthogonal_weight": 0.1,
      "step": 469,
      "total_loss": 0.6721310615539551,
      "weighted_orthogonal_loss": 0.017169158905744553
    },
    {
      "classification_loss": 0.6669833660125732,
      "epoch": 1.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17143896222114563,
      "orthogonal_weight": 0.1,
      "step": 470,
      "total_loss": 0.6841272711753845,
      "weighted_orthogonal_loss": 0.017143895849585533
    },
    {
      "classification_loss": 0.7055588364601135,
      "epoch": 1.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17138071358203888,
      "orthogonal_weight": 0.1,
      "step": 471,
      "total_loss": 0.7226969003677368,
      "weighted_orthogonal_loss": 0.017138071358203888
    },
    {
      "classification_loss": 0.6933652758598328,
      "epoch": 1.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17086918652057648,
      "orthogonal_weight": 0.1,
      "step": 472,
      "total_loss": 0.7104521989822388,
      "weighted_orthogonal_loss": 0.017086919397115707
    },
    {
      "classification_loss": 0.6704497337341309,
      "epoch": 1.5508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1703992635011673,
      "orthogonal_weight": 0.1,
      "step": 473,
      "total_loss": 0.6874896883964539,
      "weighted_orthogonal_loss": 0.01703992672264576
    },
    {
      "classification_loss": 0.668506383895874,
      "epoch": 1.5540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17016953229904175,
      "orthogonal_weight": 0.1,
      "step": 474,
      "total_loss": 0.6855233311653137,
      "weighted_orthogonal_loss": 0.017016952857375145
    },
    {
      "classification_loss": 0.6590902805328369,
      "epoch": 1.5573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16992521286010742,
      "orthogonal_weight": 0.1,
      "step": 475,
      "total_loss": 0.6760827898979187,
      "weighted_orthogonal_loss": 0.01699252240359783
    },
    {
      "classification_loss": 0.7076919078826904,
      "epoch": 1.5606557377049182,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16996431350708008,
      "orthogonal_weight": 0.1,
      "step": 476,
      "total_loss": 0.7246883511543274,
      "weighted_orthogonal_loss": 0.016996432095766068
    },
    {
      "classification_loss": 0.6784491539001465,
      "epoch": 1.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16998516023159027,
      "orthogonal_weight": 0.1,
      "step": 477,
      "total_loss": 0.6954476833343506,
      "weighted_orthogonal_loss": 0.016998516395688057
    },
    {
      "classification_loss": 0.6775699257850647,
      "epoch": 1.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16965825855731964,
      "orthogonal_weight": 0.1,
      "step": 478,
      "total_loss": 0.6945357322692871,
      "weighted_orthogonal_loss": 0.016965826973319054
    },
    {
      "classification_loss": 0.6925027370452881,
      "epoch": 1.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1693854182958603,
      "orthogonal_weight": 0.1,
      "step": 479,
      "total_loss": 0.7094413042068481,
      "weighted_orthogonal_loss": 0.01693854294717312
    },
    {
      "classification_loss": 0.6549202799797058,
      "epoch": 1.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16915912926197052,
      "orthogonal_weight": 0.1,
      "step": 480,
      "total_loss": 0.6718361973762512,
      "weighted_orthogonal_loss": 0.01691591367125511
    },
    {
      "classification_loss": 0.6731011271476746,
      "epoch": 1.5770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16865593194961548,
      "orthogonal_weight": 0.1,
      "step": 481,
      "total_loss": 0.6899667382240295,
      "weighted_orthogonal_loss": 0.016865594312548637
    },
    {
      "classification_loss": 0.6873932480812073,
      "epoch": 1.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16816414892673492,
      "orthogonal_weight": 0.1,
      "step": 482,
      "total_loss": 0.7042096853256226,
      "weighted_orthogonal_loss": 0.016816414892673492
    },
    {
      "classification_loss": 0.6888163685798645,
      "epoch": 1.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16774232685565948,
      "orthogonal_weight": 0.1,
      "step": 483,
      "total_loss": 0.7055906057357788,
      "weighted_orthogonal_loss": 0.016774233430624008
    },
    {
      "classification_loss": 0.6565361618995667,
      "epoch": 1.5868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1672513782978058,
      "orthogonal_weight": 0.1,
      "step": 484,
      "total_loss": 0.673261284828186,
      "weighted_orthogonal_loss": 0.01672513782978058
    },
    {
      "classification_loss": 0.7030242085456848,
      "epoch": 1.5901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16683293879032135,
      "orthogonal_weight": 0.1,
      "step": 485,
      "total_loss": 0.7197074890136719,
      "weighted_orthogonal_loss": 0.016683293506503105
    },
    {
      "classification_loss": 0.6840543150901794,
      "epoch": 1.5934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16646428406238556,
      "orthogonal_weight": 0.1,
      "step": 486,
      "total_loss": 0.7007007598876953,
      "weighted_orthogonal_loss": 0.016646428033709526
    },
    {
      "classification_loss": 0.6683555245399475,
      "epoch": 1.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16617460548877716,
      "orthogonal_weight": 0.1,
      "step": 487,
      "total_loss": 0.6849730014801025,
      "weighted_orthogonal_loss": 0.016617460176348686
    },
    {
      "classification_loss": 0.7317874431610107,
      "epoch": 1.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16597981750965118,
      "orthogonal_weight": 0.1,
      "step": 488,
      "total_loss": 0.7483854293823242,
      "weighted_orthogonal_loss": 0.016597982496023178
    },
    {
      "classification_loss": 0.650676429271698,
      "epoch": 1.6032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16595511138439178,
      "orthogonal_weight": 0.1,
      "step": 489,
      "total_loss": 0.6672719120979309,
      "weighted_orthogonal_loss": 0.01659551076591015
    },
    {
      "classification_loss": 0.7491114735603333,
      "epoch": 1.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16564880311489105,
      "orthogonal_weight": 0.1,
      "step": 490,
      "total_loss": 0.7656763792037964,
      "weighted_orthogonal_loss": 0.016564881429076195
    },
    {
      "classification_loss": 0.6435094475746155,
      "epoch": 1.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16523857414722443,
      "orthogonal_weight": 0.1,
      "step": 491,
      "total_loss": 0.6600332856178284,
      "weighted_orthogonal_loss": 0.016523858532309532
    },
    {
      "classification_loss": 0.6761810779571533,
      "epoch": 1.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.165061816573143,
      "orthogonal_weight": 0.1,
      "step": 492,
      "total_loss": 0.6926872730255127,
      "weighted_orthogonal_loss": 0.01650618202984333
    },
    {
      "classification_loss": 0.715707540512085,
      "epoch": 1.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16473327577114105,
      "orthogonal_weight": 0.1,
      "step": 493,
      "total_loss": 0.7321808934211731,
      "weighted_orthogonal_loss": 0.016473328694701195
    },
    {
      "classification_loss": 0.7353987693786621,
      "epoch": 1.6196721311475408,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16453559696674347,
      "orthogonal_weight": 0.1,
      "step": 494,
      "total_loss": 0.7518523335456848,
      "weighted_orthogonal_loss": 0.016453560441732407
    },
    {
      "classification_loss": 0.6509639024734497,
      "epoch": 1.6229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1643315702676773,
      "orthogonal_weight": 0.1,
      "step": 495,
      "total_loss": 0.6673970818519592,
      "weighted_orthogonal_loss": 0.01643315702676773
    },
    {
      "classification_loss": 0.6864845156669617,
      "epoch": 1.6262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1643032282590866,
      "orthogonal_weight": 0.1,
      "step": 496,
      "total_loss": 0.702914834022522,
      "weighted_orthogonal_loss": 0.01643032394349575
    },
    {
      "classification_loss": 0.688167929649353,
      "epoch": 1.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16412825882434845,
      "orthogonal_weight": 0.1,
      "step": 497,
      "total_loss": 0.7045807838439941,
      "weighted_orthogonal_loss": 0.016412826254963875
    },
    {
      "classification_loss": 0.7271003127098083,
      "epoch": 1.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16406936943531036,
      "orthogonal_weight": 0.1,
      "step": 498,
      "total_loss": 0.7435072660446167,
      "weighted_orthogonal_loss": 0.016406936571002007
    },
    {
      "classification_loss": 0.6969819664955139,
      "epoch": 1.6360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16383953392505646,
      "orthogonal_weight": 0.1,
      "step": 499,
      "total_loss": 0.713365912437439,
      "weighted_orthogonal_loss": 0.016383953392505646
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 15.952454566955566,
      "learning_rate": 0.0001867,
      "loss": 0.7014,
      "step": 500
    },
    {
      "classification_loss": 0.7035514116287231,
      "epoch": 1.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16377432644367218,
      "orthogonal_weight": 0.1,
      "step": 500,
      "total_loss": 0.7199288606643677,
      "weighted_orthogonal_loss": 0.016377432271838188
    },
    {
      "classification_loss": 0.6830261945724487,
      "epoch": 1.6426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16387471556663513,
      "orthogonal_weight": 0.1,
      "step": 501,
      "total_loss": 0.6994136571884155,
      "weighted_orthogonal_loss": 0.016387471929192543
    },
    {
      "classification_loss": 0.6712586283683777,
      "epoch": 1.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16402550041675568,
      "orthogonal_weight": 0.1,
      "step": 502,
      "total_loss": 0.6876611709594727,
      "weighted_orthogonal_loss": 0.016402550041675568
    },
    {
      "classification_loss": 0.6788092255592346,
      "epoch": 1.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1641198992729187,
      "orthogonal_weight": 0.1,
      "step": 503,
      "total_loss": 0.6952211856842041,
      "weighted_orthogonal_loss": 0.01641198992729187
    },
    {
      "classification_loss": 0.6670709252357483,
      "epoch": 1.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16396036744117737,
      "orthogonal_weight": 0.1,
      "step": 504,
      "total_loss": 0.6834669709205627,
      "weighted_orthogonal_loss": 0.016396036371588707
    },
    {
      "classification_loss": 0.7145345211029053,
      "epoch": 1.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16386139392852783,
      "orthogonal_weight": 0.1,
      "step": 505,
      "total_loss": 0.730920672416687,
      "weighted_orthogonal_loss": 0.016386140137910843
    },
    {
      "classification_loss": 0.6637324094772339,
      "epoch": 1.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16389663517475128,
      "orthogonal_weight": 0.1,
      "step": 506,
      "total_loss": 0.6801220774650574,
      "weighted_orthogonal_loss": 0.016389664262533188
    },
    {
      "classification_loss": 0.7109330892562866,
      "epoch": 1.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16396696865558624,
      "orthogonal_weight": 0.1,
      "step": 507,
      "total_loss": 0.7273297905921936,
      "weighted_orthogonal_loss": 0.016396697610616684
    },
    {
      "classification_loss": 0.6600582599639893,
      "epoch": 1.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640256643295288,
      "orthogonal_weight": 0.1,
      "step": 508,
      "total_loss": 0.6764608025550842,
      "weighted_orthogonal_loss": 0.01640256680548191
    },
    {
      "classification_loss": 0.7044861316680908,
      "epoch": 1.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16416285932064056,
      "orthogonal_weight": 0.1,
      "step": 509,
      "total_loss": 0.7209024429321289,
      "weighted_orthogonal_loss": 0.016416287049651146
    },
    {
      "classification_loss": 0.7063079476356506,
      "epoch": 1.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16418243944644928,
      "orthogonal_weight": 0.1,
      "step": 510,
      "total_loss": 0.7227261662483215,
      "weighted_orthogonal_loss": 0.016418244689702988
    },
    {
      "classification_loss": 0.6702702045440674,
      "epoch": 1.6754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16423280537128448,
      "orthogonal_weight": 0.1,
      "step": 511,
      "total_loss": 0.6866934895515442,
      "weighted_orthogonal_loss": 0.016423281282186508
    },
    {
      "classification_loss": 0.6997666358947754,
      "epoch": 1.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16397126019001007,
      "orthogonal_weight": 0.1,
      "step": 512,
      "total_loss": 0.7161637544631958,
      "weighted_orthogonal_loss": 0.016397126019001007
    },
    {
      "classification_loss": 0.6980461478233337,
      "epoch": 1.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16374802589416504,
      "orthogonal_weight": 0.1,
      "step": 513,
      "total_loss": 0.7144209742546082,
      "weighted_orthogonal_loss": 0.016374802216887474
    },
    {
      "classification_loss": 0.6987468600273132,
      "epoch": 1.6852459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16346284747123718,
      "orthogonal_weight": 0.1,
      "step": 514,
      "total_loss": 0.7150931358337402,
      "weighted_orthogonal_loss": 0.016346285119652748
    },
    {
      "classification_loss": 0.6885150671005249,
      "epoch": 1.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1630365550518036,
      "orthogonal_weight": 0.1,
      "step": 515,
      "total_loss": 0.7048187255859375,
      "weighted_orthogonal_loss": 0.01630365662276745
    },
    {
      "classification_loss": 0.6872536540031433,
      "epoch": 1.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16273610293865204,
      "orthogonal_weight": 0.1,
      "step": 516,
      "total_loss": 0.7035272717475891,
      "weighted_orthogonal_loss": 0.016273610293865204
    },
    {
      "classification_loss": 0.6739598512649536,
      "epoch": 1.6950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16216500103473663,
      "orthogonal_weight": 0.1,
      "step": 517,
      "total_loss": 0.6901763677597046,
      "weighted_orthogonal_loss": 0.016216499730944633
    },
    {
      "classification_loss": 0.6817578673362732,
      "epoch": 1.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1617746651172638,
      "orthogonal_weight": 0.1,
      "step": 518,
      "total_loss": 0.6979353427886963,
      "weighted_orthogonal_loss": 0.01617746613919735
    },
    {
      "classification_loss": 0.6485798358917236,
      "epoch": 1.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16133494675159454,
      "orthogonal_weight": 0.1,
      "step": 519,
      "total_loss": 0.6647133231163025,
      "weighted_orthogonal_loss": 0.016133494675159454
    },
    {
      "classification_loss": 0.6742690801620483,
      "epoch": 1.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16085363924503326,
      "orthogonal_weight": 0.1,
      "step": 520,
      "total_loss": 0.6903544664382935,
      "weighted_orthogonal_loss": 0.016085363924503326
    },
    {
      "classification_loss": 0.6976214051246643,
      "epoch": 1.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1604287475347519,
      "orthogonal_weight": 0.1,
      "step": 521,
      "total_loss": 0.7136642932891846,
      "weighted_orthogonal_loss": 0.01604287512600422
    },
    {
      "classification_loss": 0.7529674172401428,
      "epoch": 1.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16012297570705414,
      "orthogonal_weight": 0.1,
      "step": 522,
      "total_loss": 0.7689797282218933,
      "weighted_orthogonal_loss": 0.016012297943234444
    },
    {
      "classification_loss": 0.6413609981536865,
      "epoch": 1.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15988200902938843,
      "orthogonal_weight": 0.1,
      "step": 523,
      "total_loss": 0.6573492288589478,
      "weighted_orthogonal_loss": 0.015988200902938843
    },
    {
      "classification_loss": 0.6290376782417297,
      "epoch": 1.7180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1596118062734604,
      "orthogonal_weight": 0.1,
      "step": 524,
      "total_loss": 0.6449988484382629,
      "weighted_orthogonal_loss": 0.0159611813724041
    },
    {
      "classification_loss": 0.7045848965644836,
      "epoch": 1.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1595068871974945,
      "orthogonal_weight": 0.1,
      "step": 525,
      "total_loss": 0.7205355763435364,
      "weighted_orthogonal_loss": 0.01595068909227848
    },
    {
      "classification_loss": 0.6631888747215271,
      "epoch": 1.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15940093994140625,
      "orthogonal_weight": 0.1,
      "step": 526,
      "total_loss": 0.6791289448738098,
      "weighted_orthogonal_loss": 0.015940094366669655
    },
    {
      "classification_loss": 0.7032192945480347,
      "epoch": 1.7278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15918423235416412,
      "orthogonal_weight": 0.1,
      "step": 527,
      "total_loss": 0.7191377282142639,
      "weighted_orthogonal_loss": 0.015918424353003502
    },
    {
      "classification_loss": 0.6446242332458496,
      "epoch": 1.7311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15885744988918304,
      "orthogonal_weight": 0.1,
      "step": 528,
      "total_loss": 0.6605100035667419,
      "weighted_orthogonal_loss": 0.015885746106505394
    },
    {
      "classification_loss": 0.6340620517730713,
      "epoch": 1.7344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15841656923294067,
      "orthogonal_weight": 0.1,
      "step": 529,
      "total_loss": 0.6499037146568298,
      "weighted_orthogonal_loss": 0.015841657295823097
    },
    {
      "classification_loss": 0.6745927929878235,
      "epoch": 1.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15796461701393127,
      "orthogonal_weight": 0.1,
      "step": 530,
      "total_loss": 0.6903892755508423,
      "weighted_orthogonal_loss": 0.015796462073922157
    },
    {
      "classification_loss": 0.6513535976409912,
      "epoch": 1.7409836065573772,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15751753747463226,
      "orthogonal_weight": 0.1,
      "step": 531,
      "total_loss": 0.6671053767204285,
      "weighted_orthogonal_loss": 0.015751754865050316
    },
    {
      "classification_loss": 0.7154311537742615,
      "epoch": 1.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15708930790424347,
      "orthogonal_weight": 0.1,
      "step": 532,
      "total_loss": 0.7311400771141052,
      "weighted_orthogonal_loss": 0.015708930790424347
    },
    {
      "classification_loss": 0.6916189789772034,
      "epoch": 1.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1566482037305832,
      "orthogonal_weight": 0.1,
      "step": 533,
      "total_loss": 0.7072837948799133,
      "weighted_orthogonal_loss": 0.01566482149064541
    },
    {
      "classification_loss": 0.6954048275947571,
      "epoch": 1.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1561947464942932,
      "orthogonal_weight": 0.1,
      "step": 534,
      "total_loss": 0.711024284362793,
      "weighted_orthogonal_loss": 0.015619474463164806
    },
    {
      "classification_loss": 0.6907498240470886,
      "epoch": 1.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1557590663433075,
      "orthogonal_weight": 0.1,
      "step": 535,
      "total_loss": 0.7063257098197937,
      "weighted_orthogonal_loss": 0.015575907193124294
    },
    {
      "classification_loss": 0.6788167953491211,
      "epoch": 1.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15538795292377472,
      "orthogonal_weight": 0.1,
      "step": 536,
      "total_loss": 0.6943556070327759,
      "weighted_orthogonal_loss": 0.015538795851171017
    },
    {
      "classification_loss": 0.6712943911552429,
      "epoch": 1.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1542268842458725,
      "orthogonal_weight": 0.1,
      "step": 537,
      "total_loss": 0.6867170929908752,
      "weighted_orthogonal_loss": 0.01542268879711628
    },
    {
      "classification_loss": 0.673389196395874,
      "epoch": 1.7639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.153333380818367,
      "orthogonal_weight": 0.1,
      "step": 538,
      "total_loss": 0.688722550868988,
      "weighted_orthogonal_loss": 0.015333338640630245
    },
    {
      "classification_loss": 0.7303884625434875,
      "epoch": 1.7672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15265551209449768,
      "orthogonal_weight": 0.1,
      "step": 539,
      "total_loss": 0.7456539869308472,
      "weighted_orthogonal_loss": 0.015265551395714283
    },
    {
      "classification_loss": 0.7153174877166748,
      "epoch": 1.7704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1521044671535492,
      "orthogonal_weight": 0.1,
      "step": 540,
      "total_loss": 0.730527937412262,
      "weighted_orthogonal_loss": 0.015210446901619434
    },
    {
      "classification_loss": 0.7162790298461914,
      "epoch": 1.7737704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15162280201911926,
      "orthogonal_weight": 0.1,
      "step": 541,
      "total_loss": 0.7314413189888,
      "weighted_orthogonal_loss": 0.015162280760705471
    },
    {
      "classification_loss": 0.6909464597702026,
      "epoch": 1.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.151070237159729,
      "orthogonal_weight": 0.1,
      "step": 542,
      "total_loss": 0.7060534954071045,
      "weighted_orthogonal_loss": 0.015107023529708385
    },
    {
      "classification_loss": 0.6629173159599304,
      "epoch": 1.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1504497230052948,
      "orthogonal_weight": 0.1,
      "step": 543,
      "total_loss": 0.6779623031616211,
      "weighted_orthogonal_loss": 0.01504497230052948
    },
    {
      "classification_loss": 0.6942386627197266,
      "epoch": 1.7836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1501297503709793,
      "orthogonal_weight": 0.1,
      "step": 544,
      "total_loss": 0.7092516422271729,
      "weighted_orthogonal_loss": 0.015012974850833416
    },
    {
      "classification_loss": 0.6623823642730713,
      "epoch": 1.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499616652727127,
      "orthogonal_weight": 0.1,
      "step": 545,
      "total_loss": 0.6773785352706909,
      "weighted_orthogonal_loss": 0.014996166341006756
    },
    {
      "classification_loss": 0.7166447043418884,
      "epoch": 1.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14966797828674316,
      "orthogonal_weight": 0.1,
      "step": 546,
      "total_loss": 0.7316114902496338,
      "weighted_orthogonal_loss": 0.014966798014938831
    },
    {
      "classification_loss": 0.6748201251029968,
      "epoch": 1.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494189351797104,
      "orthogonal_weight": 0.1,
      "step": 547,
      "total_loss": 0.6897619962692261,
      "weighted_orthogonal_loss": 0.014941893517971039
    },
    {
      "classification_loss": 0.6781036853790283,
      "epoch": 1.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14928293228149414,
      "orthogonal_weight": 0.1,
      "step": 548,
      "total_loss": 0.6930319666862488,
      "weighted_orthogonal_loss": 0.014928293414413929
    },
    {
      "classification_loss": 0.6911383867263794,
      "epoch": 1.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14914549887180328,
      "orthogonal_weight": 0.1,
      "step": 549,
      "total_loss": 0.7060529589653015,
      "weighted_orthogonal_loss": 0.014914549887180328
    },
    {
      "classification_loss": 0.6598801016807556,
      "epoch": 1.8032786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1489856094121933,
      "orthogonal_weight": 0.1,
      "step": 550,
      "total_loss": 0.6747786402702332,
      "weighted_orthogonal_loss": 0.01489856094121933
    },
    {
      "classification_loss": 0.687782883644104,
      "epoch": 1.8065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1488451361656189,
      "orthogonal_weight": 0.1,
      "step": 551,
      "total_loss": 0.7026674151420593,
      "weighted_orthogonal_loss": 0.014884513802826405
    },
    {
      "classification_loss": 0.6797230243682861,
      "epoch": 1.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.148699551820755,
      "orthogonal_weight": 0.1,
      "step": 552,
      "total_loss": 0.6945929527282715,
      "weighted_orthogonal_loss": 0.014869955368340015
    },
    {
      "classification_loss": 0.6728688478469849,
      "epoch": 1.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14851832389831543,
      "orthogonal_weight": 0.1,
      "step": 553,
      "total_loss": 0.6877206563949585,
      "weighted_orthogonal_loss": 0.014851832762360573
    },
    {
      "classification_loss": 0.702341616153717,
      "epoch": 1.8163934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14819061756134033,
      "orthogonal_weight": 0.1,
      "step": 554,
      "total_loss": 0.717160701751709,
      "weighted_orthogonal_loss": 0.014819062314927578
    },
    {
      "classification_loss": 0.633303701877594,
      "epoch": 1.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14776109158992767,
      "orthogonal_weight": 0.1,
      "step": 555,
      "total_loss": 0.6480798125267029,
      "weighted_orthogonal_loss": 0.014776109717786312
    },
    {
      "classification_loss": 0.6701069474220276,
      "epoch": 1.8229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14690662920475006,
      "orthogonal_weight": 0.1,
      "step": 556,
      "total_loss": 0.6847975850105286,
      "weighted_orthogonal_loss": 0.014690662734210491
    },
    {
      "classification_loss": 0.6900566816329956,
      "epoch": 1.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1460864096879959,
      "orthogonal_weight": 0.1,
      "step": 557,
      "total_loss": 0.7046653032302856,
      "weighted_orthogonal_loss": 0.014608641155064106
    },
    {
      "classification_loss": 0.678128182888031,
      "epoch": 1.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14554257690906525,
      "orthogonal_weight": 0.1,
      "step": 558,
      "total_loss": 0.6926824450492859,
      "weighted_orthogonal_loss": 0.01455425750464201
    },
    {
      "classification_loss": 0.6623897552490234,
      "epoch": 1.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14503592252731323,
      "orthogonal_weight": 0.1,
      "step": 559,
      "total_loss": 0.6768933534622192,
      "weighted_orthogonal_loss": 0.014503592625260353
    },
    {
      "classification_loss": 0.6897371411323547,
      "epoch": 1.8360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1446065753698349,
      "orthogonal_weight": 0.1,
      "step": 560,
      "total_loss": 0.7041978240013123,
      "weighted_orthogonal_loss": 0.014460657723248005
    },
    {
      "classification_loss": 0.6643086671829224,
      "epoch": 1.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1443159431219101,
      "orthogonal_weight": 0.1,
      "step": 561,
      "total_loss": 0.6787402629852295,
      "weighted_orthogonal_loss": 0.014431594870984554
    },
    {
      "classification_loss": 0.7102059721946716,
      "epoch": 1.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14404208958148956,
      "orthogonal_weight": 0.1,
      "step": 562,
      "total_loss": 0.7246102094650269,
      "weighted_orthogonal_loss": 0.014404209330677986
    },
    {
      "classification_loss": 0.67300945520401,
      "epoch": 1.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14370444416999817,
      "orthogonal_weight": 0.1,
      "step": 563,
      "total_loss": 0.6873798966407776,
      "weighted_orthogonal_loss": 0.014370444230735302
    },
    {
      "classification_loss": 0.6220810413360596,
      "epoch": 1.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14320655167102814,
      "orthogonal_weight": 0.1,
      "step": 564,
      "total_loss": 0.6364017128944397,
      "weighted_orthogonal_loss": 0.014320655725896358
    },
    {
      "classification_loss": 0.6533961296081543,
      "epoch": 1.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14277732372283936,
      "orthogonal_weight": 0.1,
      "step": 565,
      "total_loss": 0.6676738858222961,
      "weighted_orthogonal_loss": 0.01427773293107748
    },
    {
      "classification_loss": 0.6745474338531494,
      "epoch": 1.8557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14240027964115143,
      "orthogonal_weight": 0.1,
      "step": 566,
      "total_loss": 0.6887874603271484,
      "weighted_orthogonal_loss": 0.014240028336644173
    },
    {
      "classification_loss": 0.698609471321106,
      "epoch": 1.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14214394986629486,
      "orthogonal_weight": 0.1,
      "step": 567,
      "total_loss": 0.7128238677978516,
      "weighted_orthogonal_loss": 0.01421439554542303
    },
    {
      "classification_loss": 0.6419087648391724,
      "epoch": 1.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14184780418872833,
      "orthogonal_weight": 0.1,
      "step": 568,
      "total_loss": 0.6560935378074646,
      "weighted_orthogonal_loss": 0.014184780418872833
    },
    {
      "classification_loss": 0.694909393787384,
      "epoch": 1.8655737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14153876900672913,
      "orthogonal_weight": 0.1,
      "step": 569,
      "total_loss": 0.7090632915496826,
      "weighted_orthogonal_loss": 0.014153877273201942
    },
    {
      "classification_loss": 0.6412785649299622,
      "epoch": 1.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14126992225646973,
      "orthogonal_weight": 0.1,
      "step": 570,
      "total_loss": 0.655405580997467,
      "weighted_orthogonal_loss": 0.014126992784440517
    },
    {
      "classification_loss": 0.6837173700332642,
      "epoch": 1.8721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14096276462078094,
      "orthogonal_weight": 0.1,
      "step": 571,
      "total_loss": 0.6978136301040649,
      "weighted_orthogonal_loss": 0.014096276834607124
    },
    {
      "classification_loss": 0.6645664572715759,
      "epoch": 1.8754098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14063993096351624,
      "orthogonal_weight": 0.1,
      "step": 572,
      "total_loss": 0.6786304712295532,
      "weighted_orthogonal_loss": 0.014063993468880653
    },
    {
      "classification_loss": 0.7072283625602722,
      "epoch": 1.8786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1403225213289261,
      "orthogonal_weight": 0.1,
      "step": 573,
      "total_loss": 0.7212606072425842,
      "weighted_orthogonal_loss": 0.014032252132892609
    },
    {
      "classification_loss": 0.6770250797271729,
      "epoch": 1.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1400606632232666,
      "orthogonal_weight": 0.1,
      "step": 574,
      "total_loss": 0.6910311579704285,
      "weighted_orthogonal_loss": 0.014006066136062145
    },
    {
      "classification_loss": 0.6395100355148315,
      "epoch": 1.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13982629776000977,
      "orthogonal_weight": 0.1,
      "step": 575,
      "total_loss": 0.6534926891326904,
      "weighted_orthogonal_loss": 0.013982630334794521
    },
    {
      "classification_loss": 0.7033917307853699,
      "epoch": 1.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13953913748264313,
      "orthogonal_weight": 0.1,
      "step": 576,
      "total_loss": 0.717345654964447,
      "weighted_orthogonal_loss": 0.013953913934528828
    },
    {
      "classification_loss": 0.6750102639198303,
      "epoch": 1.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13926757872104645,
      "orthogonal_weight": 0.1,
      "step": 577,
      "total_loss": 0.6889370083808899,
      "weighted_orthogonal_loss": 0.01392675843089819
    },
    {
      "classification_loss": 0.6576554179191589,
      "epoch": 1.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13851593434810638,
      "orthogonal_weight": 0.1,
      "step": 578,
      "total_loss": 0.6715070009231567,
      "weighted_orthogonal_loss": 0.013851593248546124
    },
    {
      "classification_loss": 0.6514862775802612,
      "epoch": 1.8983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13794907927513123,
      "orthogonal_weight": 0.1,
      "step": 579,
      "total_loss": 0.6652811765670776,
      "weighted_orthogonal_loss": 0.013794908300042152
    },
    {
      "classification_loss": 0.6984235644340515,
      "epoch": 1.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13766491413116455,
      "orthogonal_weight": 0.1,
      "step": 580,
      "total_loss": 0.7121900320053101,
      "weighted_orthogonal_loss": 0.013766491785645485
    },
    {
      "classification_loss": 0.686271071434021,
      "epoch": 1.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13755981624126434,
      "orthogonal_weight": 0.1,
      "step": 581,
      "total_loss": 0.7000270485877991,
      "weighted_orthogonal_loss": 0.01375598181039095
    },
    {
      "classification_loss": 0.6999109983444214,
      "epoch": 1.9081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374008059501648,
      "orthogonal_weight": 0.1,
      "step": 582,
      "total_loss": 0.7136510610580444,
      "weighted_orthogonal_loss": 0.013740080408751965
    },
    {
      "classification_loss": 0.6921502947807312,
      "epoch": 1.9114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13742932677268982,
      "orthogonal_weight": 0.1,
      "step": 583,
      "total_loss": 0.7058932185173035,
      "weighted_orthogonal_loss": 0.013742933049798012
    },
    {
      "classification_loss": 0.6701326370239258,
      "epoch": 1.9147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749286532402039,
      "orthogonal_weight": 0.1,
      "step": 584,
      "total_loss": 0.683881938457489,
      "weighted_orthogonal_loss": 0.013749286532402039
    },
    {
      "classification_loss": 0.7110649943351746,
      "epoch": 1.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13728605210781097,
      "orthogonal_weight": 0.1,
      "step": 585,
      "total_loss": 0.7247936129570007,
      "weighted_orthogonal_loss": 0.013728605583310127
    },
    {
      "classification_loss": 0.708429753780365,
      "epoch": 1.9213114754098362,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13719774782657623,
      "orthogonal_weight": 0.1,
      "step": 586,
      "total_loss": 0.7221495509147644,
      "weighted_orthogonal_loss": 0.013719774782657623
    },
    {
      "classification_loss": 0.6886913776397705,
      "epoch": 1.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13714773952960968,
      "orthogonal_weight": 0.1,
      "step": 587,
      "total_loss": 0.7024061679840088,
      "weighted_orthogonal_loss": 0.013714774511754513
    },
    {
      "classification_loss": 0.6668559312820435,
      "epoch": 1.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717372715473175,
      "orthogonal_weight": 0.1,
      "step": 588,
      "total_loss": 0.6805732846260071,
      "weighted_orthogonal_loss": 0.01371737290173769
    },
    {
      "classification_loss": 0.7039204239845276,
      "epoch": 1.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13724878430366516,
      "orthogonal_weight": 0.1,
      "step": 589,
      "total_loss": 0.7176452875137329,
      "weighted_orthogonal_loss": 0.013724878430366516
    },
    {
      "classification_loss": 0.7200135588645935,
      "epoch": 1.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13761326670646667,
      "orthogonal_weight": 0.1,
      "step": 590,
      "total_loss": 0.7337749004364014,
      "weighted_orthogonal_loss": 0.013761326670646667
    },
    {
      "classification_loss": 0.6630491018295288,
      "epoch": 1.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13779278099536896,
      "orthogonal_weight": 0.1,
      "step": 591,
      "total_loss": 0.6768283843994141,
      "weighted_orthogonal_loss": 0.01377927791327238
    },
    {
      "classification_loss": 0.6379361748695374,
      "epoch": 1.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13794578611850739,
      "orthogonal_weight": 0.1,
      "step": 592,
      "total_loss": 0.6517307758331299,
      "weighted_orthogonal_loss": 0.013794578611850739
    },
    {
      "classification_loss": 0.6700040698051453,
      "epoch": 1.9442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13812491297721863,
      "orthogonal_weight": 0.1,
      "step": 593,
      "total_loss": 0.6838165521621704,
      "weighted_orthogonal_loss": 0.013812491670250893
    },
    {
      "classification_loss": 0.7326921224594116,
      "epoch": 1.9475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1383545696735382,
      "orthogonal_weight": 0.1,
      "step": 594,
      "total_loss": 0.7465275526046753,
      "weighted_orthogonal_loss": 0.013835457153618336
    },
    {
      "classification_loss": 0.7327626347541809,
      "epoch": 1.9508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13847258687019348,
      "orthogonal_weight": 0.1,
      "step": 595,
      "total_loss": 0.7466098666191101,
      "weighted_orthogonal_loss": 0.013847258873283863
    },
    {
      "classification_loss": 0.6691921949386597,
      "epoch": 1.9540983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13859684765338898,
      "orthogonal_weight": 0.1,
      "step": 596,
      "total_loss": 0.6830518841743469,
      "weighted_orthogonal_loss": 0.013859684579074383
    },
    {
      "classification_loss": 0.703101634979248,
      "epoch": 1.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13875575363636017,
      "orthogonal_weight": 0.1,
      "step": 597,
      "total_loss": 0.7169772386550903,
      "weighted_orthogonal_loss": 0.013875575736165047
    },
    {
      "classification_loss": 0.7006300091743469,
      "epoch": 1.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388891637325287,
      "orthogonal_weight": 0.1,
      "step": 598,
      "total_loss": 0.7145189046859741,
      "weighted_orthogonal_loss": 0.013888916932046413
    },
    {
      "classification_loss": 0.6764107346534729,
      "epoch": 1.9639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13902297616004944,
      "orthogonal_weight": 0.1,
      "step": 599,
      "total_loss": 0.6903130412101746,
      "weighted_orthogonal_loss": 0.013902298174798489
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 5.76666259765625,
      "learning_rate": 0.00018336666666666666,
      "loss": 0.6972,
      "step": 600
    },
    {
      "classification_loss": 0.7128793597221375,
      "epoch": 1.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920684158802032,
      "orthogonal_weight": 0.1,
      "step": 600,
      "total_loss": 0.7268000245094299,
      "weighted_orthogonal_loss": 0.013920684345066547
    },
    {
      "classification_loss": 0.7261967062950134,
      "epoch": 1.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13937316834926605,
      "orthogonal_weight": 0.1,
      "step": 601,
      "total_loss": 0.7401340007781982,
      "weighted_orthogonal_loss": 0.013937316834926605
    },
    {
      "classification_loss": 0.6677441000938416,
      "epoch": 1.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13952071964740753,
      "orthogonal_weight": 0.1,
      "step": 602,
      "total_loss": 0.6816961765289307,
      "weighted_orthogonal_loss": 0.013952071778476238
    },
    {
      "classification_loss": 0.6802635788917542,
      "epoch": 1.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13943995535373688,
      "orthogonal_weight": 0.1,
      "step": 603,
      "total_loss": 0.6942075490951538,
      "weighted_orthogonal_loss": 0.013943995349109173
    },
    {
      "classification_loss": 0.6451836824417114,
      "epoch": 1.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13937599956989288,
      "orthogonal_weight": 0.1,
      "step": 604,
      "total_loss": 0.6591212749481201,
      "weighted_orthogonal_loss": 0.013937599956989288
    },
    {
      "classification_loss": 0.6391912698745728,
      "epoch": 1.9836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13938020169734955,
      "orthogonal_weight": 0.1,
      "step": 605,
      "total_loss": 0.6531292796134949,
      "weighted_orthogonal_loss": 0.01393801998347044
    },
    {
      "classification_loss": 0.7171729207038879,
      "epoch": 1.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1393430531024933,
      "orthogonal_weight": 0.1,
      "step": 606,
      "total_loss": 0.731107234954834,
      "weighted_orthogonal_loss": 0.013934305869042873
    },
    {
      "classification_loss": 0.6468100547790527,
      "epoch": 1.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392393857240677,
      "orthogonal_weight": 0.1,
      "step": 607,
      "total_loss": 0.6607339978218079,
      "weighted_orthogonal_loss": 0.013923938386142254
    },
    {
      "classification_loss": 0.6871572136878967,
      "epoch": 1.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13921351730823517,
      "orthogonal_weight": 0.1,
      "step": 608,
      "total_loss": 0.7010785937309265,
      "weighted_orthogonal_loss": 0.013921352103352547
    },
    {
      "classification_loss": 0.7371491193771362,
      "epoch": 1.9967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920044898986816,
      "orthogonal_weight": 0.1,
      "step": 609,
      "total_loss": 0.751069188117981,
      "weighted_orthogonal_loss": 0.013920045457780361
    },
    {
      "classification_loss": 0.6875877380371094,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.701511800289154,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6975090503692627,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.7114331126213074,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6771702170372009,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6910942792892456,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6785628199577332,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6924868822097778,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6814645528793335,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6953886151313782,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.6839240193367004,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6978480815887451,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.676777720451355,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6907017827033997,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.7038714289665222,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.7177954912185669,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.541,
      "eval_f1": 0.6307320997586484,
      "eval_loss": 0.6993502378463745,
      "eval_precision": 0.632258064516129,
      "eval_recall": 0.6292134831460674,
      "eval_runtime": 6.2057,
      "eval_samples_per_second": 161.142,
      "eval_steps_per_second": 1.289,
      "step": 610
    },
    {
      "classification_loss": 0.6631269454956055,
      "epoch": 2.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1392408162355423,
      "orthogonal_weight": 0.1,
      "step": 610,
      "total_loss": 0.6770510077476501,
      "weighted_orthogonal_loss": 0.013924081809818745
    },
    {
      "classification_loss": 0.675663411617279,
      "epoch": 2.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13925881683826447,
      "orthogonal_weight": 0.1,
      "step": 611,
      "total_loss": 0.6895893216133118,
      "weighted_orthogonal_loss": 0.013925882056355476
    },
    {
      "classification_loss": 0.6387726068496704,
      "epoch": 2.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13921406865119934,
      "orthogonal_weight": 0.1,
      "step": 612,
      "total_loss": 0.6526939868927002,
      "weighted_orthogonal_loss": 0.013921407051384449
    },
    {
      "classification_loss": 0.6548963785171509,
      "epoch": 2.0098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390584111213684,
      "orthogonal_weight": 0.1,
      "step": 613,
      "total_loss": 0.6688022017478943,
      "weighted_orthogonal_loss": 0.013905840925872326
    },
    {
      "classification_loss": 0.6407982707023621,
      "epoch": 2.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388881802558899,
      "orthogonal_weight": 0.1,
      "step": 614,
      "total_loss": 0.6546871066093445,
      "weighted_orthogonal_loss": 0.013888818211853504
    },
    {
      "classification_loss": 0.6849182844161987,
      "epoch": 2.0163934426229506,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13884204626083374,
      "orthogonal_weight": 0.1,
      "step": 615,
      "total_loss": 0.6988024711608887,
      "weighted_orthogonal_loss": 0.013884204439818859
    },
    {
      "classification_loss": 0.6662309765815735,
      "epoch": 2.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13867796957492828,
      "orthogonal_weight": 0.1,
      "step": 616,
      "total_loss": 0.6800987720489502,
      "weighted_orthogonal_loss": 0.013867797330021858
    },
    {
      "classification_loss": 0.642135500907898,
      "epoch": 2.0229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13850991427898407,
      "orthogonal_weight": 0.1,
      "step": 617,
      "total_loss": 0.655986487865448,
      "weighted_orthogonal_loss": 0.013850991614162922
    },
    {
      "classification_loss": 0.6575379967689514,
      "epoch": 2.0262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13836674392223358,
      "orthogonal_weight": 0.1,
      "step": 618,
      "total_loss": 0.6713746786117554,
      "weighted_orthogonal_loss": 0.013836674392223358
    },
    {
      "classification_loss": 0.6869693398475647,
      "epoch": 2.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1379912793636322,
      "orthogonal_weight": 0.1,
      "step": 619,
      "total_loss": 0.7007684707641602,
      "weighted_orthogonal_loss": 0.013799128122627735
    },
    {
      "classification_loss": 0.611780047416687,
      "epoch": 2.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376379132270813,
      "orthogonal_weight": 0.1,
      "step": 620,
      "total_loss": 0.6255438327789307,
      "weighted_orthogonal_loss": 0.013763791881501675
    },
    {
      "classification_loss": 0.70892333984375,
      "epoch": 2.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13726922869682312,
      "orthogonal_weight": 0.1,
      "step": 621,
      "total_loss": 0.7226502895355225,
      "weighted_orthogonal_loss": 0.013726922683417797
    },
    {
      "classification_loss": 0.7123057842254639,
      "epoch": 2.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13700713217258453,
      "orthogonal_weight": 0.1,
      "step": 622,
      "total_loss": 0.7260065078735352,
      "weighted_orthogonal_loss": 0.013700713403522968
    },
    {
      "classification_loss": 0.6245718598365784,
      "epoch": 2.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1368894875049591,
      "orthogonal_weight": 0.1,
      "step": 623,
      "total_loss": 0.6382607817649841,
      "weighted_orthogonal_loss": 0.013688948936760426
    },
    {
      "classification_loss": 0.6619150638580322,
      "epoch": 2.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367984414100647,
      "orthogonal_weight": 0.1,
      "step": 624,
      "total_loss": 0.6755949258804321,
      "weighted_orthogonal_loss": 0.013679844327270985
    },
    {
      "classification_loss": 0.6552832722663879,
      "epoch": 2.0491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1366952657699585,
      "orthogonal_weight": 0.1,
      "step": 625,
      "total_loss": 0.6689528226852417,
      "weighted_orthogonal_loss": 0.013669527135789394
    },
    {
      "classification_loss": 0.6902874112129211,
      "epoch": 2.0524590163934424,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13661396503448486,
      "orthogonal_weight": 0.1,
      "step": 626,
      "total_loss": 0.7039487957954407,
      "weighted_orthogonal_loss": 0.013661396689713001
    },
    {
      "classification_loss": 0.6807511448860168,
      "epoch": 2.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364680975675583,
      "orthogonal_weight": 0.1,
      "step": 627,
      "total_loss": 0.6943979263305664,
      "weighted_orthogonal_loss": 0.013646810315549374
    },
    {
      "classification_loss": 0.6690577268600464,
      "epoch": 2.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13634343445301056,
      "orthogonal_weight": 0.1,
      "step": 628,
      "total_loss": 0.6826920509338379,
      "weighted_orthogonal_loss": 0.01363434363156557
    },
    {
      "classification_loss": 0.6825783848762512,
      "epoch": 2.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13626503944396973,
      "orthogonal_weight": 0.1,
      "step": 629,
      "total_loss": 0.6962049007415771,
      "weighted_orthogonal_loss": 0.013626503758132458
    },
    {
      "classification_loss": 0.6807635426521301,
      "epoch": 2.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13629209995269775,
      "orthogonal_weight": 0.1,
      "step": 630,
      "total_loss": 0.694392740726471,
      "weighted_orthogonal_loss": 0.01362921018153429
    },
    {
      "classification_loss": 0.663696825504303,
      "epoch": 2.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13637283444404602,
      "orthogonal_weight": 0.1,
      "step": 631,
      "total_loss": 0.6773341298103333,
      "weighted_orthogonal_loss": 0.013637283816933632
    },
    {
      "classification_loss": 0.6620309352874756,
      "epoch": 2.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13646617531776428,
      "orthogonal_weight": 0.1,
      "step": 632,
      "total_loss": 0.6756775379180908,
      "weighted_orthogonal_loss": 0.013646617531776428
    },
    {
      "classification_loss": 0.6384421586990356,
      "epoch": 2.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13617035746574402,
      "orthogonal_weight": 0.1,
      "step": 633,
      "total_loss": 0.6520591974258423,
      "weighted_orthogonal_loss": 0.013617035932838917
    },
    {
      "classification_loss": 0.6761725544929504,
      "epoch": 2.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359611302614212,
      "orthogonal_weight": 0.1,
      "step": 634,
      "total_loss": 0.6897686719894409,
      "weighted_orthogonal_loss": 0.013596112839877605
    },
    {
      "classification_loss": 0.6678457260131836,
      "epoch": 2.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580960035324097,
      "orthogonal_weight": 0.1,
      "step": 635,
      "total_loss": 0.6814267039299011,
      "weighted_orthogonal_loss": 0.013580960221588612
    },
    {
      "classification_loss": 0.6220820546150208,
      "epoch": 2.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13573512434959412,
      "orthogonal_weight": 0.1,
      "step": 636,
      "total_loss": 0.6356555819511414,
      "weighted_orthogonal_loss": 0.013573512434959412
    },
    {
      "classification_loss": 0.6857736706733704,
      "epoch": 2.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13564720749855042,
      "orthogonal_weight": 0.1,
      "step": 637,
      "total_loss": 0.6993383765220642,
      "weighted_orthogonal_loss": 0.013564720749855042
    },
    {
      "classification_loss": 0.6384184956550598,
      "epoch": 2.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13563299179077148,
      "orthogonal_weight": 0.1,
      "step": 638,
      "total_loss": 0.651981770992279,
      "weighted_orthogonal_loss": 0.013563299551606178
    },
    {
      "classification_loss": 0.6587923765182495,
      "epoch": 2.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13565748929977417,
      "orthogonal_weight": 0.1,
      "step": 639,
      "total_loss": 0.6723581552505493,
      "weighted_orthogonal_loss": 0.013565748929977417
    },
    {
      "classification_loss": 0.6565413475036621,
      "epoch": 2.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356365829706192,
      "orthogonal_weight": 0.1,
      "step": 640,
      "total_loss": 0.67010498046875,
      "weighted_orthogonal_loss": 0.013563658110797405
    },
    {
      "classification_loss": 0.7034303545951843,
      "epoch": 2.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356664001941681,
      "orthogonal_weight": 0.1,
      "step": 641,
      "total_loss": 0.716996967792511,
      "weighted_orthogonal_loss": 0.013566640205681324
    },
    {
      "classification_loss": 0.6701549887657166,
      "epoch": 2.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13556678593158722,
      "orthogonal_weight": 0.1,
      "step": 642,
      "total_loss": 0.6837116479873657,
      "weighted_orthogonal_loss": 0.013556678779423237
    },
    {
      "classification_loss": 0.6694207191467285,
      "epoch": 2.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355249434709549,
      "orthogonal_weight": 0.1,
      "step": 643,
      "total_loss": 0.6829732060432434,
      "weighted_orthogonal_loss": 0.01355249434709549
    },
    {
      "classification_loss": 0.6858741641044617,
      "epoch": 2.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13551096618175507,
      "orthogonal_weight": 0.1,
      "step": 644,
      "total_loss": 0.6994252800941467,
      "weighted_orthogonal_loss": 0.013551096431910992
    },
    {
      "classification_loss": 0.6497952342033386,
      "epoch": 2.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13546089828014374,
      "orthogonal_weight": 0.1,
      "step": 645,
      "total_loss": 0.6633413434028625,
      "weighted_orthogonal_loss": 0.013546089641749859
    },
    {
      "classification_loss": 0.6224135160446167,
      "epoch": 2.1180327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13543754816055298,
      "orthogonal_weight": 0.1,
      "step": 646,
      "total_loss": 0.6359572410583496,
      "weighted_orthogonal_loss": 0.013543754816055298
    },
    {
      "classification_loss": 0.6452400088310242,
      "epoch": 2.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13539569079875946,
      "orthogonal_weight": 0.1,
      "step": 647,
      "total_loss": 0.6587795615196228,
      "weighted_orthogonal_loss": 0.013539569452404976
    },
    {
      "classification_loss": 0.6707666516304016,
      "epoch": 2.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13537713885307312,
      "orthogonal_weight": 0.1,
      "step": 648,
      "total_loss": 0.6843043565750122,
      "weighted_orthogonal_loss": 0.013537714257836342
    },
    {
      "classification_loss": 0.5907464027404785,
      "epoch": 2.1278688524590166,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13520202040672302,
      "orthogonal_weight": 0.1,
      "step": 649,
      "total_loss": 0.6042665839195251,
      "weighted_orthogonal_loss": 0.013520202599465847
    },
    {
      "classification_loss": 0.6476250290870667,
      "epoch": 2.1311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13502950966358185,
      "orthogonal_weight": 0.1,
      "step": 650,
      "total_loss": 0.6611279845237732,
      "weighted_orthogonal_loss": 0.01350295078009367
    },
    {
      "classification_loss": 0.7083233594894409,
      "epoch": 2.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1348603516817093,
      "orthogonal_weight": 0.1,
      "step": 651,
      "total_loss": 0.7218093872070312,
      "weighted_orthogonal_loss": 0.013486035168170929
    },
    {
      "classification_loss": 0.7047362923622131,
      "epoch": 2.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13471588492393494,
      "orthogonal_weight": 0.1,
      "step": 652,
      "total_loss": 0.7182078957557678,
      "weighted_orthogonal_loss": 0.013471588492393494
    },
    {
      "classification_loss": 0.6722798347473145,
      "epoch": 2.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13455533981323242,
      "orthogonal_weight": 0.1,
      "step": 653,
      "total_loss": 0.6857353448867798,
      "weighted_orthogonal_loss": 0.013455534353852272
    },
    {
      "classification_loss": 0.7083224654197693,
      "epoch": 2.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13442426919937134,
      "orthogonal_weight": 0.1,
      "step": 654,
      "total_loss": 0.7217649221420288,
      "weighted_orthogonal_loss": 0.013442426919937134
    },
    {
      "classification_loss": 0.6549153923988342,
      "epoch": 2.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13423489034175873,
      "orthogonal_weight": 0.1,
      "step": 655,
      "total_loss": 0.6683388948440552,
      "weighted_orthogonal_loss": 0.013423489406704903
    },
    {
      "classification_loss": 0.6784593462944031,
      "epoch": 2.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13399028778076172,
      "orthogonal_weight": 0.1,
      "step": 656,
      "total_loss": 0.6918583512306213,
      "weighted_orthogonal_loss": 0.013399029150605202
    },
    {
      "classification_loss": 0.6990267634391785,
      "epoch": 2.1540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336912214756012,
      "orthogonal_weight": 0.1,
      "step": 657,
      "total_loss": 0.7123959064483643,
      "weighted_orthogonal_loss": 0.01336912252008915
    },
    {
      "classification_loss": 0.7076823115348816,
      "epoch": 2.1573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13337381184101105,
      "orthogonal_weight": 0.1,
      "step": 658,
      "total_loss": 0.7210196852684021,
      "weighted_orthogonal_loss": 0.013337381184101105
    },
    {
      "classification_loss": 0.6760309338569641,
      "epoch": 2.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331375688314438,
      "orthogonal_weight": 0.1,
      "step": 659,
      "total_loss": 0.6893447041511536,
      "weighted_orthogonal_loss": 0.013313757255673409
    },
    {
      "classification_loss": 0.6378170847892761,
      "epoch": 2.1639344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13300246000289917,
      "orthogonal_weight": 0.1,
      "step": 660,
      "total_loss": 0.6511173248291016,
      "weighted_orthogonal_loss": 0.013300246559083462
    },
    {
      "classification_loss": 0.6846320033073425,
      "epoch": 2.1672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13282443583011627,
      "orthogonal_weight": 0.1,
      "step": 661,
      "total_loss": 0.6979144215583801,
      "weighted_orthogonal_loss": 0.013282443396747112
    },
    {
      "classification_loss": 0.6763468980789185,
      "epoch": 2.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13267169892787933,
      "orthogonal_weight": 0.1,
      "step": 662,
      "total_loss": 0.6896140575408936,
      "weighted_orthogonal_loss": 0.013267169706523418
    },
    {
      "classification_loss": 0.6610320210456848,
      "epoch": 2.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13266243040561676,
      "orthogonal_weight": 0.1,
      "step": 663,
      "total_loss": 0.6742982864379883,
      "weighted_orthogonal_loss": 0.013266243040561676
    },
    {
      "classification_loss": 0.653738796710968,
      "epoch": 2.177049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13273850083351135,
      "orthogonal_weight": 0.1,
      "step": 664,
      "total_loss": 0.667012631893158,
      "weighted_orthogonal_loss": 0.013273850083351135
    },
    {
      "classification_loss": 0.6513218283653259,
      "epoch": 2.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13276371359825134,
      "orthogonal_weight": 0.1,
      "step": 665,
      "total_loss": 0.6645982265472412,
      "weighted_orthogonal_loss": 0.01327637117356062
    },
    {
      "classification_loss": 0.6487203240394592,
      "epoch": 2.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1327941119670868,
      "orthogonal_weight": 0.1,
      "step": 666,
      "total_loss": 0.6619997620582581,
      "weighted_orthogonal_loss": 0.013279411010444164
    },
    {
      "classification_loss": 0.675567090511322,
      "epoch": 2.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13287211954593658,
      "orthogonal_weight": 0.1,
      "step": 667,
      "total_loss": 0.6888542771339417,
      "weighted_orthogonal_loss": 0.013287211768329144
    },
    {
      "classification_loss": 0.7040941715240479,
      "epoch": 2.1901639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13315258920192719,
      "orthogonal_weight": 0.1,
      "step": 668,
      "total_loss": 0.7174094319343567,
      "weighted_orthogonal_loss": 0.013315259478986263
    },
    {
      "classification_loss": 0.6608855128288269,
      "epoch": 2.1934426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13345582783222198,
      "orthogonal_weight": 0.1,
      "step": 669,
      "total_loss": 0.6742311120033264,
      "weighted_orthogonal_loss": 0.013345583342015743
    },
    {
      "classification_loss": 0.6971756219863892,
      "epoch": 2.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13375814259052277,
      "orthogonal_weight": 0.1,
      "step": 670,
      "total_loss": 0.7105514407157898,
      "weighted_orthogonal_loss": 0.013375814072787762
    },
    {
      "classification_loss": 0.6448794007301331,
      "epoch": 2.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340400129556656,
      "orthogonal_weight": 0.1,
      "step": 671,
      "total_loss": 0.6582834124565125,
      "weighted_orthogonal_loss": 0.013404001481831074
    },
    {
      "classification_loss": 0.693259596824646,
      "epoch": 2.2032786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1342400312423706,
      "orthogonal_weight": 0.1,
      "step": 672,
      "total_loss": 0.7066835761070251,
      "weighted_orthogonal_loss": 0.01342400349676609
    },
    {
      "classification_loss": 0.6841013431549072,
      "epoch": 2.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13444192707538605,
      "orthogonal_weight": 0.1,
      "step": 673,
      "total_loss": 0.6975455284118652,
      "weighted_orthogonal_loss": 0.013444192707538605
    },
    {
      "classification_loss": 0.682142972946167,
      "epoch": 2.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.134786456823349,
      "orthogonal_weight": 0.1,
      "step": 674,
      "total_loss": 0.6956216096878052,
      "weighted_orthogonal_loss": 0.01347864605486393
    },
    {
      "classification_loss": 0.6104218363761902,
      "epoch": 2.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13508690893650055,
      "orthogonal_weight": 0.1,
      "step": 675,
      "total_loss": 0.6239305138587952,
      "weighted_orthogonal_loss": 0.0135086914524436
    },
    {
      "classification_loss": 0.6623443961143494,
      "epoch": 2.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13531829416751862,
      "orthogonal_weight": 0.1,
      "step": 676,
      "total_loss": 0.6758762001991272,
      "weighted_orthogonal_loss": 0.013531829230487347
    },
    {
      "classification_loss": 0.6833042502403259,
      "epoch": 2.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13556654751300812,
      "orthogonal_weight": 0.1,
      "step": 677,
      "total_loss": 0.6968609094619751,
      "weighted_orthogonal_loss": 0.013556654565036297
    },
    {
      "classification_loss": 0.6507001519203186,
      "epoch": 2.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13581164181232452,
      "orthogonal_weight": 0.1,
      "step": 678,
      "total_loss": 0.6642813086509705,
      "weighted_orthogonal_loss": 0.013581164181232452
    },
    {
      "classification_loss": 0.7093213796615601,
      "epoch": 2.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13603872060775757,
      "orthogonal_weight": 0.1,
      "step": 679,
      "total_loss": 0.7229252457618713,
      "weighted_orthogonal_loss": 0.013603872619569302
    },
    {
      "classification_loss": 0.7039775252342224,
      "epoch": 2.2295081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13629214465618134,
      "orthogonal_weight": 0.1,
      "step": 680,
      "total_loss": 0.7176067233085632,
      "weighted_orthogonal_loss": 0.013629214838147163
    },
    {
      "classification_loss": 0.6764472126960754,
      "epoch": 2.2327868852459014,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13651417195796967,
      "orthogonal_weight": 0.1,
      "step": 681,
      "total_loss": 0.6900986433029175,
      "weighted_orthogonal_loss": 0.013651417568325996
    },
    {
      "classification_loss": 0.6565006375312805,
      "epoch": 2.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13639004528522491,
      "orthogonal_weight": 0.1,
      "step": 682,
      "total_loss": 0.6701396703720093,
      "weighted_orthogonal_loss": 0.013639004901051521
    },
    {
      "classification_loss": 0.6281178593635559,
      "epoch": 2.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13632190227508545,
      "orthogonal_weight": 0.1,
      "step": 683,
      "total_loss": 0.6417500376701355,
      "weighted_orthogonal_loss": 0.01363219041377306
    },
    {
      "classification_loss": 0.6676103472709656,
      "epoch": 2.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13626684248447418,
      "orthogonal_weight": 0.1,
      "step": 684,
      "total_loss": 0.6812370419502258,
      "weighted_orthogonal_loss": 0.013626684434711933
    },
    {
      "classification_loss": 0.6787033081054688,
      "epoch": 2.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13623791933059692,
      "orthogonal_weight": 0.1,
      "step": 685,
      "total_loss": 0.692327082157135,
      "weighted_orthogonal_loss": 0.013623791746795177
    },
    {
      "classification_loss": 0.724747359752655,
      "epoch": 2.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1362244039773941,
      "orthogonal_weight": 0.1,
      "step": 686,
      "total_loss": 0.7383698225021362,
      "weighted_orthogonal_loss": 0.01362244039773941
    },
    {
      "classification_loss": 0.6723162531852722,
      "epoch": 2.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13618119060993195,
      "orthogonal_weight": 0.1,
      "step": 687,
      "total_loss": 0.6859343647956848,
      "weighted_orthogonal_loss": 0.013618119060993195
    },
    {
      "classification_loss": 0.6489892601966858,
      "epoch": 2.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13610567152500153,
      "orthogonal_weight": 0.1,
      "step": 688,
      "total_loss": 0.6625998020172119,
      "weighted_orthogonal_loss": 0.013610566966235638
    },
    {
      "classification_loss": 0.6589500308036804,
      "epoch": 2.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13611848652362823,
      "orthogonal_weight": 0.1,
      "step": 689,
      "total_loss": 0.6725618839263916,
      "weighted_orthogonal_loss": 0.013611848466098309
    },
    {
      "classification_loss": 0.7106584906578064,
      "epoch": 2.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13620197772979736,
      "orthogonal_weight": 0.1,
      "step": 690,
      "total_loss": 0.7242786884307861,
      "weighted_orthogonal_loss": 0.013620197772979736
    },
    {
      "classification_loss": 0.6829169392585754,
      "epoch": 2.265573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13627304136753082,
      "orthogonal_weight": 0.1,
      "step": 691,
      "total_loss": 0.6965442299842834,
      "weighted_orthogonal_loss": 0.013627304695546627
    },
    {
      "classification_loss": 0.6879841089248657,
      "epoch": 2.2688524590163937,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1362990140914917,
      "orthogonal_weight": 0.1,
      "step": 692,
      "total_loss": 0.7016140222549438,
      "weighted_orthogonal_loss": 0.013629901222884655
    },
    {
      "classification_loss": 0.6426753997802734,
      "epoch": 2.2721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631261885166168,
      "orthogonal_weight": 0.1,
      "step": 693,
      "total_loss": 0.6563066840171814,
      "weighted_orthogonal_loss": 0.013631261885166168
    },
    {
      "classification_loss": 0.6372926235198975,
      "epoch": 2.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13635016977787018,
      "orthogonal_weight": 0.1,
      "step": 694,
      "total_loss": 0.6509276628494263,
      "weighted_orthogonal_loss": 0.013635016977787018
    },
    {
      "classification_loss": 0.6663371324539185,
      "epoch": 2.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364799588918686,
      "orthogonal_weight": 0.1,
      "step": 695,
      "total_loss": 0.6799851059913635,
      "weighted_orthogonal_loss": 0.013647995889186859
    },
    {
      "classification_loss": 0.6333184242248535,
      "epoch": 2.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13663217425346375,
      "orthogonal_weight": 0.1,
      "step": 696,
      "total_loss": 0.6469816565513611,
      "weighted_orthogonal_loss": 0.013663217425346375
    },
    {
      "classification_loss": 0.6347573399543762,
      "epoch": 2.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.136811763048172,
      "orthogonal_weight": 0.1,
      "step": 697,
      "total_loss": 0.6484385132789612,
      "weighted_orthogonal_loss": 0.013681176118552685
    },
    {
      "classification_loss": 0.7049899101257324,
      "epoch": 2.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1369539052248001,
      "orthogonal_weight": 0.1,
      "step": 698,
      "total_loss": 0.7186853289604187,
      "weighted_orthogonal_loss": 0.01369539089500904
    },
    {
      "classification_loss": 0.7018643021583557,
      "epoch": 2.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13712511956691742,
      "orthogonal_weight": 0.1,
      "step": 699,
      "total_loss": 0.7155768275260925,
      "weighted_orthogonal_loss": 0.013712512329220772
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 29.85932159423828,
      "learning_rate": 0.00018003333333333334,
      "loss": 0.6834,
      "step": 700
    },
    {
      "classification_loss": 0.6500634551048279,
      "epoch": 2.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13731978833675385,
      "orthogonal_weight": 0.1,
      "step": 700,
      "total_loss": 0.6637954115867615,
      "weighted_orthogonal_loss": 0.013731978833675385
    },
    {
      "classification_loss": 0.6840149164199829,
      "epoch": 2.2983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13740283250808716,
      "orthogonal_weight": 0.1,
      "step": 701,
      "total_loss": 0.6977552175521851,
      "weighted_orthogonal_loss": 0.01374028343707323
    },
    {
      "classification_loss": 0.7160877585411072,
      "epoch": 2.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13750162720680237,
      "orthogonal_weight": 0.1,
      "step": 702,
      "total_loss": 0.7298378944396973,
      "weighted_orthogonal_loss": 0.013750162906944752
    },
    {
      "classification_loss": 0.6590107083320618,
      "epoch": 2.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13765904307365417,
      "orthogonal_weight": 0.1,
      "step": 703,
      "total_loss": 0.6727766394615173,
      "weighted_orthogonal_loss": 0.013765904121100903
    },
    {
      "classification_loss": 0.6656896471977234,
      "epoch": 2.3081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378212720155716,
      "orthogonal_weight": 0.1,
      "step": 704,
      "total_loss": 0.6794717907905579,
      "weighted_orthogonal_loss": 0.013782127760350704
    },
    {
      "classification_loss": 0.6958256959915161,
      "epoch": 2.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13788287341594696,
      "orthogonal_weight": 0.1,
      "step": 705,
      "total_loss": 0.7096139788627625,
      "weighted_orthogonal_loss": 0.013788287527859211
    },
    {
      "classification_loss": 0.6539934873580933,
      "epoch": 2.314754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13775943219661713,
      "orthogonal_weight": 0.1,
      "step": 706,
      "total_loss": 0.6677694320678711,
      "weighted_orthogonal_loss": 0.013775943778455257
    },
    {
      "classification_loss": 0.6587193608283997,
      "epoch": 2.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13761484622955322,
      "orthogonal_weight": 0.1,
      "step": 707,
      "total_loss": 0.6724808216094971,
      "weighted_orthogonal_loss": 0.013761484995484352
    },
    {
      "classification_loss": 0.6556830406188965,
      "epoch": 2.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13748089969158173,
      "orthogonal_weight": 0.1,
      "step": 708,
      "total_loss": 0.6694311499595642,
      "weighted_orthogonal_loss": 0.013748089782893658
    },
    {
      "classification_loss": 0.660719633102417,
      "epoch": 2.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13735711574554443,
      "orthogonal_weight": 0.1,
      "step": 709,
      "total_loss": 0.6744553446769714,
      "weighted_orthogonal_loss": 0.013735711574554443
    },
    {
      "classification_loss": 0.6583676934242249,
      "epoch": 2.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717395067214966,
      "orthogonal_weight": 0.1,
      "step": 710,
      "total_loss": 0.6720851063728333,
      "weighted_orthogonal_loss": 0.01371739525347948
    },
    {
      "classification_loss": 0.6685340404510498,
      "epoch": 2.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13704493641853333,
      "orthogonal_weight": 0.1,
      "step": 711,
      "total_loss": 0.6822385191917419,
      "weighted_orthogonal_loss": 0.013704493641853333
    },
    {
      "classification_loss": 0.698114812374115,
      "epoch": 2.3344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13690166175365448,
      "orthogonal_weight": 0.1,
      "step": 712,
      "total_loss": 0.711804986000061,
      "weighted_orthogonal_loss": 0.013690166175365448
    },
    {
      "classification_loss": 0.6755896210670471,
      "epoch": 2.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367313265800476,
      "orthogonal_weight": 0.1,
      "step": 713,
      "total_loss": 0.6892627477645874,
      "weighted_orthogonal_loss": 0.013673133216798306
    },
    {
      "classification_loss": 0.6479446291923523,
      "epoch": 2.3409836065573773,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13653890788555145,
      "orthogonal_weight": 0.1,
      "step": 714,
      "total_loss": 0.6615985035896301,
      "weighted_orthogonal_loss": 0.013653891161084175
    },
    {
      "classification_loss": 0.6302591562271118,
      "epoch": 2.3442622950819674,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1363542526960373,
      "orthogonal_weight": 0.1,
      "step": 715,
      "total_loss": 0.6438945531845093,
      "weighted_orthogonal_loss": 0.013635425828397274
    },
    {
      "classification_loss": 0.6726948022842407,
      "epoch": 2.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13620375096797943,
      "orthogonal_weight": 0.1,
      "step": 716,
      "total_loss": 0.6863151788711548,
      "weighted_orthogonal_loss": 0.013620375655591488
    },
    {
      "classification_loss": 0.6483542919158936,
      "epoch": 2.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602259755134583,
      "orthogonal_weight": 0.1,
      "step": 717,
      "total_loss": 0.6619565486907959,
      "weighted_orthogonal_loss": 0.013602259568870068
    },
    {
      "classification_loss": 0.711586058139801,
      "epoch": 2.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13597945868968964,
      "orthogonal_weight": 0.1,
      "step": 718,
      "total_loss": 0.7251840233802795,
      "weighted_orthogonal_loss": 0.013597945682704449
    },
    {
      "classification_loss": 0.6360405683517456,
      "epoch": 2.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13603802025318146,
      "orthogonal_weight": 0.1,
      "step": 719,
      "total_loss": 0.6496443748474121,
      "weighted_orthogonal_loss": 0.01360380183905363
    },
    {
      "classification_loss": 0.6579926609992981,
      "epoch": 2.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13611911237239838,
      "orthogonal_weight": 0.1,
      "step": 720,
      "total_loss": 0.671604573726654,
      "weighted_orthogonal_loss": 0.013611911796033382
    },
    {
      "classification_loss": 0.6875645518302917,
      "epoch": 2.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13623575866222382,
      "orthogonal_weight": 0.1,
      "step": 721,
      "total_loss": 0.7011881470680237,
      "weighted_orthogonal_loss": 0.013623575679957867
    },
    {
      "classification_loss": 0.6243991851806641,
      "epoch": 2.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13636556267738342,
      "orthogonal_weight": 0.1,
      "step": 722,
      "total_loss": 0.6380357146263123,
      "weighted_orthogonal_loss": 0.013636556454002857
    },
    {
      "classification_loss": 0.6961196660995483,
      "epoch": 2.3704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1363585740327835,
      "orthogonal_weight": 0.1,
      "step": 723,
      "total_loss": 0.709755539894104,
      "weighted_orthogonal_loss": 0.013635857962071896
    },
    {
      "classification_loss": 0.6458069682121277,
      "epoch": 2.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13638970255851746,
      "orthogonal_weight": 0.1,
      "step": 724,
      "total_loss": 0.6594459414482117,
      "weighted_orthogonal_loss": 0.01363897044211626
    },
    {
      "classification_loss": 0.6296140551567078,
      "epoch": 2.3770491803278686,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13634061813354492,
      "orthogonal_weight": 0.1,
      "step": 725,
      "total_loss": 0.6432481408119202,
      "weighted_orthogonal_loss": 0.013634062372148037
    },
    {
      "classification_loss": 0.6389240026473999,
      "epoch": 2.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361386924982071,
      "orthogonal_weight": 0.1,
      "step": 726,
      "total_loss": 0.6525378823280334,
      "weighted_orthogonal_loss": 0.013613869436085224
    },
    {
      "classification_loss": 0.6619734764099121,
      "epoch": 2.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.135803684592247,
      "orthogonal_weight": 0.1,
      "step": 727,
      "total_loss": 0.6755538582801819,
      "weighted_orthogonal_loss": 0.01358036883175373
    },
    {
      "classification_loss": 0.6266179084777832,
      "epoch": 2.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1354946792125702,
      "orthogonal_weight": 0.1,
      "step": 728,
      "total_loss": 0.6401673555374146,
      "weighted_orthogonal_loss": 0.013549468480050564
    },
    {
      "classification_loss": 0.6980639696121216,
      "epoch": 2.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13515490293502808,
      "orthogonal_weight": 0.1,
      "step": 729,
      "total_loss": 0.711579442024231,
      "weighted_orthogonal_loss": 0.013515490107238293
    },
    {
      "classification_loss": 0.6848323941230774,
      "epoch": 2.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13477550446987152,
      "orthogonal_weight": 0.1,
      "step": 730,
      "total_loss": 0.6983099579811096,
      "weighted_orthogonal_loss": 0.013477550819516182
    },
    {
      "classification_loss": 0.6631547212600708,
      "epoch": 2.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13439403474330902,
      "orthogonal_weight": 0.1,
      "step": 731,
      "total_loss": 0.6765941381454468,
      "weighted_orthogonal_loss": 0.013439403846859932
    },
    {
      "classification_loss": 0.6785007119178772,
      "epoch": 2.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13400933146476746,
      "orthogonal_weight": 0.1,
      "step": 732,
      "total_loss": 0.6919016242027283,
      "weighted_orthogonal_loss": 0.01340093370527029
    },
    {
      "classification_loss": 0.6452811360359192,
      "epoch": 2.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13355927169322968,
      "orthogonal_weight": 0.1,
      "step": 733,
      "total_loss": 0.6586370468139648,
      "weighted_orthogonal_loss": 0.013355927541851997
    },
    {
      "classification_loss": 0.6604838371276855,
      "epoch": 2.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133195698261261,
      "orthogonal_weight": 0.1,
      "step": 734,
      "total_loss": 0.6738033890724182,
      "weighted_orthogonal_loss": 0.013319569639861584
    },
    {
      "classification_loss": 0.679711103439331,
      "epoch": 2.4098360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13293345272541046,
      "orthogonal_weight": 0.1,
      "step": 735,
      "total_loss": 0.6930044293403625,
      "weighted_orthogonal_loss": 0.013293345458805561
    },
    {
      "classification_loss": 0.7212545871734619,
      "epoch": 2.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1327354907989502,
      "orthogonal_weight": 0.1,
      "step": 736,
      "total_loss": 0.734528124332428,
      "weighted_orthogonal_loss": 0.013273549266159534
    },
    {
      "classification_loss": 0.6374360918998718,
      "epoch": 2.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13261374831199646,
      "orthogonal_weight": 0.1,
      "step": 737,
      "total_loss": 0.6506974697113037,
      "weighted_orthogonal_loss": 0.013261375017464161
    },
    {
      "classification_loss": 0.6812819838523865,
      "epoch": 2.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13248972594738007,
      "orthogonal_weight": 0.1,
      "step": 738,
      "total_loss": 0.6945309638977051,
      "weighted_orthogonal_loss": 0.013248972594738007
    },
    {
      "classification_loss": 0.6216815710067749,
      "epoch": 2.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238371908664703,
      "orthogonal_weight": 0.1,
      "step": 739,
      "total_loss": 0.6349199414253235,
      "weighted_orthogonal_loss": 0.013238372281193733
    },
    {
      "classification_loss": 0.6721980571746826,
      "epoch": 2.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13228614628314972,
      "orthogonal_weight": 0.1,
      "step": 740,
      "total_loss": 0.685426652431488,
      "weighted_orthogonal_loss": 0.013228614814579487
    },
    {
      "classification_loss": 0.668140709400177,
      "epoch": 2.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1322781890630722,
      "orthogonal_weight": 0.1,
      "step": 741,
      "total_loss": 0.6813685297966003,
      "weighted_orthogonal_loss": 0.013227819465100765
    },
    {
      "classification_loss": 0.6399967670440674,
      "epoch": 2.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13231763243675232,
      "orthogonal_weight": 0.1,
      "step": 742,
      "total_loss": 0.6532285213470459,
      "weighted_orthogonal_loss": 0.013231763616204262
    },
    {
      "classification_loss": 0.6787336468696594,
      "epoch": 2.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238121569156647,
      "orthogonal_weight": 0.1,
      "step": 743,
      "total_loss": 0.6919717788696289,
      "weighted_orthogonal_loss": 0.013238121755421162
    },
    {
      "classification_loss": 0.6694890260696411,
      "epoch": 2.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324678659439087,
      "orthogonal_weight": 0.1,
      "step": 744,
      "total_loss": 0.682735800743103,
      "weighted_orthogonal_loss": 0.013246786780655384
    },
    {
      "classification_loss": 0.6660614609718323,
      "epoch": 2.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324770301580429,
      "orthogonal_weight": 0.1,
      "step": 745,
      "total_loss": 0.6793091893196106,
      "weighted_orthogonal_loss": 0.013247703202068806
    },
    {
      "classification_loss": 0.6732366681098938,
      "epoch": 2.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13244667649269104,
      "orthogonal_weight": 0.1,
      "step": 746,
      "total_loss": 0.6864813566207886,
      "weighted_orthogonal_loss": 0.013244668021798134
    },
    {
      "classification_loss": 0.6724532842636108,
      "epoch": 2.4491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13244278728961945,
      "orthogonal_weight": 0.1,
      "step": 747,
      "total_loss": 0.6856975555419922,
      "weighted_orthogonal_loss": 0.013244278728961945
    },
    {
      "classification_loss": 0.6885054111480713,
      "epoch": 2.4524590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13242574036121368,
      "orthogonal_weight": 0.1,
      "step": 748,
      "total_loss": 0.7017480134963989,
      "weighted_orthogonal_loss": 0.013242574408650398
    },
    {
      "classification_loss": 0.7083278298377991,
      "epoch": 2.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13238902390003204,
      "orthogonal_weight": 0.1,
      "step": 749,
      "total_loss": 0.7215667366981506,
      "weighted_orthogonal_loss": 0.01323890220373869
    },
    {
      "classification_loss": 0.6569589972496033,
      "epoch": 2.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13231495022773743,
      "orthogonal_weight": 0.1,
      "step": 750,
      "total_loss": 0.6701905131340027,
      "weighted_orthogonal_loss": 0.013231495395302773
    },
    {
      "classification_loss": 0.6630613207817078,
      "epoch": 2.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1322300136089325,
      "orthogonal_weight": 0.1,
      "step": 751,
      "total_loss": 0.6762843132019043,
      "weighted_orthogonal_loss": 0.01322300173342228
    },
    {
      "classification_loss": 0.6451510190963745,
      "epoch": 2.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13214437663555145,
      "orthogonal_weight": 0.1,
      "step": 752,
      "total_loss": 0.6583654284477234,
      "weighted_orthogonal_loss": 0.01321443822234869
    },
    {
      "classification_loss": 0.6673803925514221,
      "epoch": 2.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13193614780902863,
      "orthogonal_weight": 0.1,
      "step": 753,
      "total_loss": 0.6805739998817444,
      "weighted_orthogonal_loss": 0.013193614780902863
    },
    {
      "classification_loss": 0.6990227103233337,
      "epoch": 2.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316678375005722,
      "orthogonal_weight": 0.1,
      "step": 754,
      "total_loss": 0.7121894955635071,
      "weighted_orthogonal_loss": 0.013166784308850765
    },
    {
      "classification_loss": 0.6536931395530701,
      "epoch": 2.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13150203227996826,
      "orthogonal_weight": 0.1,
      "step": 755,
      "total_loss": 0.6668433547019958,
      "weighted_orthogonal_loss": 0.013150203041732311
    },
    {
      "classification_loss": 0.6988577842712402,
      "epoch": 2.4786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141269981861115,
      "orthogonal_weight": 0.1,
      "step": 756,
      "total_loss": 0.7119990587234497,
      "weighted_orthogonal_loss": 0.0131412697955966
    },
    {
      "classification_loss": 0.6434361934661865,
      "epoch": 2.4819672131147543,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313757449388504,
      "orthogonal_weight": 0.1,
      "step": 757,
      "total_loss": 0.6565737724304199,
      "weighted_orthogonal_loss": 0.013137574307620525
    },
    {
      "classification_loss": 0.6774338483810425,
      "epoch": 2.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313847005367279,
      "orthogonal_weight": 0.1,
      "step": 758,
      "total_loss": 0.6905723214149475,
      "weighted_orthogonal_loss": 0.013138470239937305
    },
    {
      "classification_loss": 0.6602340340614319,
      "epoch": 2.4885245901639346,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1314343959093094,
      "orthogonal_weight": 0.1,
      "step": 759,
      "total_loss": 0.6733774542808533,
      "weighted_orthogonal_loss": 0.013143439777195454
    },
    {
      "classification_loss": 0.6962705254554749,
      "epoch": 2.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141418993473053,
      "orthogonal_weight": 0.1,
      "step": 760,
      "total_loss": 0.7094119191169739,
      "weighted_orthogonal_loss": 0.013141418807208538
    },
    {
      "classification_loss": 0.636605978012085,
      "epoch": 2.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13138720393180847,
      "orthogonal_weight": 0.1,
      "step": 761,
      "total_loss": 0.6497446894645691,
      "weighted_orthogonal_loss": 0.013138720765709877
    },
    {
      "classification_loss": 0.6670777797698975,
      "epoch": 2.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313103586435318,
      "orthogonal_weight": 0.1,
      "step": 762,
      "total_loss": 0.6802088022232056,
      "weighted_orthogonal_loss": 0.013131036423146725
    },
    {
      "classification_loss": 0.6505709290504456,
      "epoch": 2.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13124172389507294,
      "orthogonal_weight": 0.1,
      "step": 763,
      "total_loss": 0.6636950969696045,
      "weighted_orthogonal_loss": 0.013124172575771809
    },
    {
      "classification_loss": 0.6777225136756897,
      "epoch": 2.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13122008740901947,
      "orthogonal_weight": 0.1,
      "step": 764,
      "total_loss": 0.6908445358276367,
      "weighted_orthogonal_loss": 0.013122009113430977
    },
    {
      "classification_loss": 0.6795657277107239,
      "epoch": 2.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13118313252925873,
      "orthogonal_weight": 0.1,
      "step": 765,
      "total_loss": 0.6926840543746948,
      "weighted_orthogonal_loss": 0.013118313625454903
    },
    {
      "classification_loss": 0.6445077657699585,
      "epoch": 2.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13103891909122467,
      "orthogonal_weight": 0.1,
      "step": 766,
      "total_loss": 0.6576116681098938,
      "weighted_orthogonal_loss": 0.013103892095386982
    },
    {
      "classification_loss": 0.6639549136161804,
      "epoch": 2.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1309681236743927,
      "orthogonal_weight": 0.1,
      "step": 767,
      "total_loss": 0.6770517230033875,
      "weighted_orthogonal_loss": 0.013096812181174755
    },
    {
      "classification_loss": 0.6825442910194397,
      "epoch": 2.5180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13093623518943787,
      "orthogonal_weight": 0.1,
      "step": 768,
      "total_loss": 0.6956379413604736,
      "weighted_orthogonal_loss": 0.013093623332679272
    },
    {
      "classification_loss": 0.6683477163314819,
      "epoch": 2.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13094571232795715,
      "orthogonal_weight": 0.1,
      "step": 769,
      "total_loss": 0.6814422607421875,
      "weighted_orthogonal_loss": 0.01309457141906023
    },
    {
      "classification_loss": 0.6675499081611633,
      "epoch": 2.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13099037110805511,
      "orthogonal_weight": 0.1,
      "step": 770,
      "total_loss": 0.680648922920227,
      "weighted_orthogonal_loss": 0.013099037110805511
    },
    {
      "classification_loss": 0.6366527080535889,
      "epoch": 2.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13100089132785797,
      "orthogonal_weight": 0.1,
      "step": 771,
      "total_loss": 0.6497527956962585,
      "weighted_orthogonal_loss": 0.013100089505314827
    },
    {
      "classification_loss": 0.6881991028785706,
      "epoch": 2.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104188442230225,
      "orthogonal_weight": 0.1,
      "step": 772,
      "total_loss": 0.7013033032417297,
      "weighted_orthogonal_loss": 0.01310418825596571
    },
    {
      "classification_loss": 0.6647322773933411,
      "epoch": 2.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1311519742012024,
      "orthogonal_weight": 0.1,
      "step": 773,
      "total_loss": 0.6778475046157837,
      "weighted_orthogonal_loss": 0.01311519742012024
    },
    {
      "classification_loss": 0.6433978080749512,
      "epoch": 2.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13130128383636475,
      "orthogonal_weight": 0.1,
      "step": 774,
      "total_loss": 0.6565279364585876,
      "weighted_orthogonal_loss": 0.013130128383636475
    },
    {
      "classification_loss": 0.6302614212036133,
      "epoch": 2.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1312216967344284,
      "orthogonal_weight": 0.1,
      "step": 775,
      "total_loss": 0.6433835625648499,
      "weighted_orthogonal_loss": 0.013122170232236385
    },
    {
      "classification_loss": 0.7025690078735352,
      "epoch": 2.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13119018077850342,
      "orthogonal_weight": 0.1,
      "step": 776,
      "total_loss": 0.7156880497932434,
      "weighted_orthogonal_loss": 0.013119018636643887
    },
    {
      "classification_loss": 0.7370193600654602,
      "epoch": 2.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13122737407684326,
      "orthogonal_weight": 0.1,
      "step": 777,
      "total_loss": 0.7501420974731445,
      "weighted_orthogonal_loss": 0.013122737407684326
    },
    {
      "classification_loss": 0.6912404894828796,
      "epoch": 2.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13128028810024261,
      "orthogonal_weight": 0.1,
      "step": 778,
      "total_loss": 0.704368531703949,
      "weighted_orthogonal_loss": 0.013128029182553291
    },
    {
      "classification_loss": 0.6493831276893616,
      "epoch": 2.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1313227415084839,
      "orthogonal_weight": 0.1,
      "step": 779,
      "total_loss": 0.66251540184021,
      "weighted_orthogonal_loss": 0.013132274150848389
    },
    {
      "classification_loss": 0.7050805687904358,
      "epoch": 2.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13141733407974243,
      "orthogonal_weight": 0.1,
      "step": 780,
      "total_loss": 0.7182223200798035,
      "weighted_orthogonal_loss": 0.013141733594238758
    },
    {
      "classification_loss": 0.6615415811538696,
      "epoch": 2.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1315409243106842,
      "orthogonal_weight": 0.1,
      "step": 781,
      "total_loss": 0.6746956706047058,
      "weighted_orthogonal_loss": 0.013154092244803905
    },
    {
      "classification_loss": 0.7201828956604004,
      "epoch": 2.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13167054951190948,
      "orthogonal_weight": 0.1,
      "step": 782,
      "total_loss": 0.7333499789237976,
      "weighted_orthogonal_loss": 0.013167055323719978
    },
    {
      "classification_loss": 0.6431984305381775,
      "epoch": 2.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.131600022315979,
      "orthogonal_weight": 0.1,
      "step": 783,
      "total_loss": 0.6563584208488464,
      "weighted_orthogonal_loss": 0.013160002417862415
    },
    {
      "classification_loss": 0.6847642660140991,
      "epoch": 2.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13152295351028442,
      "orthogonal_weight": 0.1,
      "step": 784,
      "total_loss": 0.697916567325592,
      "weighted_orthogonal_loss": 0.013152295723557472
    },
    {
      "classification_loss": 0.6438998579978943,
      "epoch": 2.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13152875006198883,
      "orthogonal_weight": 0.1,
      "step": 785,
      "total_loss": 0.657052755355835,
      "weighted_orthogonal_loss": 0.013152875006198883
    },
    {
      "classification_loss": 0.6583815217018127,
      "epoch": 2.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13146920502185822,
      "orthogonal_weight": 0.1,
      "step": 786,
      "total_loss": 0.6715284585952759,
      "weighted_orthogonal_loss": 0.013146921060979366
    },
    {
      "classification_loss": 0.6631061434745789,
      "epoch": 2.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13146454095840454,
      "orthogonal_weight": 0.1,
      "step": 787,
      "total_loss": 0.6762526035308838,
      "weighted_orthogonal_loss": 0.013146454468369484
    },
    {
      "classification_loss": 0.6878953576087952,
      "epoch": 2.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316032111644745,
      "orthogonal_weight": 0.1,
      "step": 788,
      "total_loss": 0.7010557055473328,
      "weighted_orthogonal_loss": 0.013160320930182934
    },
    {
      "classification_loss": 0.6670450568199158,
      "epoch": 2.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1316634863615036,
      "orthogonal_weight": 0.1,
      "step": 789,
      "total_loss": 0.6802114248275757,
      "weighted_orthogonal_loss": 0.013166348449885845
    },
    {
      "classification_loss": 0.6824669241905212,
      "epoch": 2.5901639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1317044198513031,
      "orthogonal_weight": 0.1,
      "step": 790,
      "total_loss": 0.6956373453140259,
      "weighted_orthogonal_loss": 0.013170442543923855
    },
    {
      "classification_loss": 0.7044404149055481,
      "epoch": 2.5934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13174213469028473,
      "orthogonal_weight": 0.1,
      "step": 791,
      "total_loss": 0.7176146507263184,
      "weighted_orthogonal_loss": 0.013174213469028473
    },
    {
      "classification_loss": 0.6775110363960266,
      "epoch": 2.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13179944455623627,
      "orthogonal_weight": 0.1,
      "step": 792,
      "total_loss": 0.6906909942626953,
      "weighted_orthogonal_loss": 0.013179944828152657
    },
    {
      "classification_loss": 0.6186367869377136,
      "epoch": 2.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13196128606796265,
      "orthogonal_weight": 0.1,
      "step": 793,
      "total_loss": 0.6318328976631165,
      "weighted_orthogonal_loss": 0.01319612842053175
    },
    {
      "classification_loss": 0.6577016115188599,
      "epoch": 2.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13215209543704987,
      "orthogonal_weight": 0.1,
      "step": 794,
      "total_loss": 0.6709167957305908,
      "weighted_orthogonal_loss": 0.013215209357440472
    },
    {
      "classification_loss": 0.6138888001441956,
      "epoch": 2.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13239513337612152,
      "orthogonal_weight": 0.1,
      "step": 795,
      "total_loss": 0.6271283030509949,
      "weighted_orthogonal_loss": 0.013239513151347637
    },
    {
      "classification_loss": 0.6095708012580872,
      "epoch": 2.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13262568414211273,
      "orthogonal_weight": 0.1,
      "step": 796,
      "total_loss": 0.6228333711624146,
      "weighted_orthogonal_loss": 0.013262568973004818
    },
    {
      "classification_loss": 0.6437855362892151,
      "epoch": 2.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13301894068717957,
      "orthogonal_weight": 0.1,
      "step": 797,
      "total_loss": 0.6570874452590942,
      "weighted_orthogonal_loss": 0.013301894068717957
    },
    {
      "classification_loss": 0.7236654758453369,
      "epoch": 2.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13340318202972412,
      "orthogonal_weight": 0.1,
      "step": 798,
      "total_loss": 0.7370057702064514,
      "weighted_orthogonal_loss": 0.013340318575501442
    },
    {
      "classification_loss": 0.6494996547698975,
      "epoch": 2.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133793443441391,
      "orthogonal_weight": 0.1,
      "step": 799,
      "total_loss": 0.6628789901733398,
      "weighted_orthogonal_loss": 0.013379344716668129
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 4.363560676574707,
      "learning_rate": 0.00017669999999999999,
      "loss": 0.6802,
      "step": 800
    },
    {
      "classification_loss": 0.6421718597412109,
      "epoch": 2.6229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13409137725830078,
      "orthogonal_weight": 0.1,
      "step": 800,
      "total_loss": 0.655580997467041,
      "weighted_orthogonal_loss": 0.013409137725830078
    },
    {
      "classification_loss": 0.6574947834014893,
      "epoch": 2.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13442346453666687,
      "orthogonal_weight": 0.1,
      "step": 801,
      "total_loss": 0.6709371209144592,
      "weighted_orthogonal_loss": 0.013442346826195717
    },
    {
      "classification_loss": 0.6738280057907104,
      "epoch": 2.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13473056256771088,
      "orthogonal_weight": 0.1,
      "step": 802,
      "total_loss": 0.6873010396957397,
      "weighted_orthogonal_loss": 0.013473056256771088
    },
    {
      "classification_loss": 0.6693236231803894,
      "epoch": 2.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13510146737098694,
      "orthogonal_weight": 0.1,
      "step": 803,
      "total_loss": 0.6828337907791138,
      "weighted_orthogonal_loss": 0.013510147109627724
    },
    {
      "classification_loss": 0.6527130603790283,
      "epoch": 2.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357375532388687,
      "orthogonal_weight": 0.1,
      "step": 804,
      "total_loss": 0.666286826133728,
      "weighted_orthogonal_loss": 0.013573755510151386
    },
    {
      "classification_loss": 0.6655152440071106,
      "epoch": 2.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13662533462047577,
      "orthogonal_weight": 0.1,
      "step": 805,
      "total_loss": 0.6791777610778809,
      "weighted_orthogonal_loss": 0.013662533834576607
    },
    {
      "classification_loss": 0.6729041337966919,
      "epoch": 2.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13751019537448883,
      "orthogonal_weight": 0.1,
      "step": 806,
      "total_loss": 0.6866551637649536,
      "weighted_orthogonal_loss": 0.013751019723713398
    },
    {
      "classification_loss": 0.7125867605209351,
      "epoch": 2.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.138357475399971,
      "orthogonal_weight": 0.1,
      "step": 807,
      "total_loss": 0.7264224886894226,
      "weighted_orthogonal_loss": 0.013835747726261616
    },
    {
      "classification_loss": 0.6728909611701965,
      "epoch": 2.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1391458958387375,
      "orthogonal_weight": 0.1,
      "step": 808,
      "total_loss": 0.6868055462837219,
      "weighted_orthogonal_loss": 0.013914589770138264
    },
    {
      "classification_loss": 0.6148538589477539,
      "epoch": 2.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13994748890399933,
      "orthogonal_weight": 0.1,
      "step": 809,
      "total_loss": 0.6288486123085022,
      "weighted_orthogonal_loss": 0.013994748704135418
    },
    {
      "classification_loss": 0.6664302945137024,
      "epoch": 2.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14070634543895721,
      "orthogonal_weight": 0.1,
      "step": 810,
      "total_loss": 0.6805009245872498,
      "weighted_orthogonal_loss": 0.014070634730160236
    },
    {
      "classification_loss": 0.6931422352790833,
      "epoch": 2.6590163934426227,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14137808978557587,
      "orthogonal_weight": 0.1,
      "step": 811,
      "total_loss": 0.7072800397872925,
      "weighted_orthogonal_loss": 0.014137809164822102
    },
    {
      "classification_loss": 0.6658143997192383,
      "epoch": 2.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14204499125480652,
      "orthogonal_weight": 0.1,
      "step": 812,
      "total_loss": 0.6800189018249512,
      "weighted_orthogonal_loss": 0.014204499311745167
    },
    {
      "classification_loss": 0.6442660689353943,
      "epoch": 2.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14260706305503845,
      "orthogonal_weight": 0.1,
      "step": 813,
      "total_loss": 0.6585267782211304,
      "weighted_orthogonal_loss": 0.01426070649176836
    },
    {
      "classification_loss": 0.7148667573928833,
      "epoch": 2.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.143210306763649,
      "orthogonal_weight": 0.1,
      "step": 814,
      "total_loss": 0.7291877865791321,
      "weighted_orthogonal_loss": 0.014321031048893929
    },
    {
      "classification_loss": 0.6784195899963379,
      "epoch": 2.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1437629610300064,
      "orthogonal_weight": 0.1,
      "step": 815,
      "total_loss": 0.6927958726882935,
      "weighted_orthogonal_loss": 0.014376296661794186
    },
    {
      "classification_loss": 0.7024468183517456,
      "epoch": 2.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14403021335601807,
      "orthogonal_weight": 0.1,
      "step": 816,
      "total_loss": 0.7168498635292053,
      "weighted_orthogonal_loss": 0.014403021894395351
    },
    {
      "classification_loss": 0.6734247803688049,
      "epoch": 2.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1439918726682663,
      "orthogonal_weight": 0.1,
      "step": 817,
      "total_loss": 0.6878239512443542,
      "weighted_orthogonal_loss": 0.01439918763935566
    },
    {
      "classification_loss": 0.6890404224395752,
      "epoch": 2.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14367111027240753,
      "orthogonal_weight": 0.1,
      "step": 818,
      "total_loss": 0.7034075260162354,
      "weighted_orthogonal_loss": 0.014367111027240753
    },
    {
      "classification_loss": 0.718894898891449,
      "epoch": 2.685245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1434451788663864,
      "orthogonal_weight": 0.1,
      "step": 819,
      "total_loss": 0.7332394123077393,
      "weighted_orthogonal_loss": 0.014344518072903156
    },
    {
      "classification_loss": 0.6805331110954285,
      "epoch": 2.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14324213564395905,
      "orthogonal_weight": 0.1,
      "step": 820,
      "total_loss": 0.6948572993278503,
      "weighted_orthogonal_loss": 0.01432421337813139
    },
    {
      "classification_loss": 0.7090246677398682,
      "epoch": 2.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14313536882400513,
      "orthogonal_weight": 0.1,
      "step": 821,
      "total_loss": 0.7233381867408752,
      "weighted_orthogonal_loss": 0.014313536696135998
    },
    {
      "classification_loss": 0.6762948632240295,
      "epoch": 2.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1433316022157669,
      "orthogonal_weight": 0.1,
      "step": 822,
      "total_loss": 0.6906280517578125,
      "weighted_orthogonal_loss": 0.01433316059410572
    },
    {
      "classification_loss": 0.6647999286651611,
      "epoch": 2.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1435956060886383,
      "orthogonal_weight": 0.1,
      "step": 823,
      "total_loss": 0.6791594624519348,
      "weighted_orthogonal_loss": 0.014359560795128345
    },
    {
      "classification_loss": 0.6442452669143677,
      "epoch": 2.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14390866458415985,
      "orthogonal_weight": 0.1,
      "step": 824,
      "total_loss": 0.6586361527442932,
      "weighted_orthogonal_loss": 0.01439086627215147
    },
    {
      "classification_loss": 0.6751945614814758,
      "epoch": 2.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1442665308713913,
      "orthogonal_weight": 0.1,
      "step": 825,
      "total_loss": 0.6896212100982666,
      "weighted_orthogonal_loss": 0.014426653273403645
    },
    {
      "classification_loss": 0.6509072780609131,
      "epoch": 2.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14489373564720154,
      "orthogonal_weight": 0.1,
      "step": 826,
      "total_loss": 0.6653966307640076,
      "weighted_orthogonal_loss": 0.014489374123513699
    },
    {
      "classification_loss": 0.6488322615623474,
      "epoch": 2.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14557114243507385,
      "orthogonal_weight": 0.1,
      "step": 827,
      "total_loss": 0.6633893847465515,
      "weighted_orthogonal_loss": 0.01455711480230093
    },
    {
      "classification_loss": 0.6886337399482727,
      "epoch": 2.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1461714804172516,
      "orthogonal_weight": 0.1,
      "step": 828,
      "total_loss": 0.7032508850097656,
      "weighted_orthogonal_loss": 0.014617147855460644
    },
    {
      "classification_loss": 0.6759387850761414,
      "epoch": 2.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14670132100582123,
      "orthogonal_weight": 0.1,
      "step": 829,
      "total_loss": 0.6906089186668396,
      "weighted_orthogonal_loss": 0.014670132659375668
    },
    {
      "classification_loss": 0.6716825366020203,
      "epoch": 2.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14707762002944946,
      "orthogonal_weight": 0.1,
      "step": 830,
      "total_loss": 0.6863902807235718,
      "weighted_orthogonal_loss": 0.014707761816680431
    },
    {
      "classification_loss": 0.724100649356842,
      "epoch": 2.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14745457470417023,
      "orthogonal_weight": 0.1,
      "step": 831,
      "total_loss": 0.7388461232185364,
      "weighted_orthogonal_loss": 0.014745458029210567
    },
    {
      "classification_loss": 0.6719219088554382,
      "epoch": 2.7278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1474969983100891,
      "orthogonal_weight": 0.1,
      "step": 832,
      "total_loss": 0.6866716146469116,
      "weighted_orthogonal_loss": 0.014749700203537941
    },
    {
      "classification_loss": 0.6846828460693359,
      "epoch": 2.7311475409836063,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14755405485630035,
      "orthogonal_weight": 0.1,
      "step": 833,
      "total_loss": 0.6994382739067078,
      "weighted_orthogonal_loss": 0.014755405485630035
    },
    {
      "classification_loss": 0.6508368253707886,
      "epoch": 2.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14754410088062286,
      "orthogonal_weight": 0.1,
      "step": 834,
      "total_loss": 0.6655912399291992,
      "weighted_orthogonal_loss": 0.014754409901797771
    },
    {
      "classification_loss": 0.7076286673545837,
      "epoch": 2.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14744248986244202,
      "orthogonal_weight": 0.1,
      "step": 835,
      "total_loss": 0.7223728895187378,
      "weighted_orthogonal_loss": 0.014744249172508717
    },
    {
      "classification_loss": 0.6794479489326477,
      "epoch": 2.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14740104973316193,
      "orthogonal_weight": 0.1,
      "step": 836,
      "total_loss": 0.6941880583763123,
      "weighted_orthogonal_loss": 0.014740104787051678
    },
    {
      "classification_loss": 0.6911559104919434,
      "epoch": 2.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14667461812496185,
      "orthogonal_weight": 0.1,
      "step": 837,
      "total_loss": 0.7058233618736267,
      "weighted_orthogonal_loss": 0.01466746162623167
    },
    {
      "classification_loss": 0.7181549668312073,
      "epoch": 2.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14595386385917664,
      "orthogonal_weight": 0.1,
      "step": 838,
      "total_loss": 0.7327503561973572,
      "weighted_orthogonal_loss": 0.014595386572182178
    },
    {
      "classification_loss": 0.6950059533119202,
      "epoch": 2.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14529913663864136,
      "orthogonal_weight": 0.1,
      "step": 839,
      "total_loss": 0.7095358371734619,
      "weighted_orthogonal_loss": 0.014529913663864136
    },
    {
      "classification_loss": 0.7272698283195496,
      "epoch": 2.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1447432041168213,
      "orthogonal_weight": 0.1,
      "step": 840,
      "total_loss": 0.7417441606521606,
      "weighted_orthogonal_loss": 0.014474320225417614
    },
    {
      "classification_loss": 0.6665177941322327,
      "epoch": 2.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1442888081073761,
      "orthogonal_weight": 0.1,
      "step": 841,
      "total_loss": 0.6809466481208801,
      "weighted_orthogonal_loss": 0.014428880997002125
    },
    {
      "classification_loss": 0.6993705034255981,
      "epoch": 2.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14394256472587585,
      "orthogonal_weight": 0.1,
      "step": 842,
      "total_loss": 0.7137647867202759,
      "weighted_orthogonal_loss": 0.01439425628632307
    },
    {
      "classification_loss": 0.6448401808738708,
      "epoch": 2.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14349260926246643,
      "orthogonal_weight": 0.1,
      "step": 843,
      "total_loss": 0.6591894626617432,
      "weighted_orthogonal_loss": 0.014349261298775673
    },
    {
      "classification_loss": 0.695979654788971,
      "epoch": 2.7672131147540986,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1428927481174469,
      "orthogonal_weight": 0.1,
      "step": 844,
      "total_loss": 0.7102689146995544,
      "weighted_orthogonal_loss": 0.01428927481174469
    },
    {
      "classification_loss": 0.6317330002784729,
      "epoch": 2.7704918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1423775553703308,
      "orthogonal_weight": 0.1,
      "step": 845,
      "total_loss": 0.6459707617759705,
      "weighted_orthogonal_loss": 0.014237755909562111
    },
    {
      "classification_loss": 0.633726954460144,
      "epoch": 2.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14187423884868622,
      "orthogonal_weight": 0.1,
      "step": 846,
      "total_loss": 0.6479143500328064,
      "weighted_orthogonal_loss": 0.014187424443662167
    },
    {
      "classification_loss": 0.6318193078041077,
      "epoch": 2.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14150337874889374,
      "orthogonal_weight": 0.1,
      "step": 847,
      "total_loss": 0.6459696292877197,
      "weighted_orthogonal_loss": 0.014150338247418404
    },
    {
      "classification_loss": 0.6419751048088074,
      "epoch": 2.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14126154780387878,
      "orthogonal_weight": 0.1,
      "step": 848,
      "total_loss": 0.6561012864112854,
      "weighted_orthogonal_loss": 0.014126154594123363
    },
    {
      "classification_loss": 0.6850680708885193,
      "epoch": 2.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14099426567554474,
      "orthogonal_weight": 0.1,
      "step": 849,
      "total_loss": 0.6991674900054932,
      "weighted_orthogonal_loss": 0.014099426567554474
    },
    {
      "classification_loss": 0.6210669875144958,
      "epoch": 2.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14061245322227478,
      "orthogonal_weight": 0.1,
      "step": 850,
      "total_loss": 0.6351282596588135,
      "weighted_orthogonal_loss": 0.014061245135962963
    },
    {
      "classification_loss": 0.643293559551239,
      "epoch": 2.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14035919308662415,
      "orthogonal_weight": 0.1,
      "step": 851,
      "total_loss": 0.6573294997215271,
      "weighted_orthogonal_loss": 0.014035919681191444
    },
    {
      "classification_loss": 0.7176450490951538,
      "epoch": 2.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14016325771808624,
      "orthogonal_weight": 0.1,
      "step": 852,
      "total_loss": 0.7316613793373108,
      "weighted_orthogonal_loss": 0.01401632558554411
    },
    {
      "classification_loss": 0.7004678249359131,
      "epoch": 2.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1399868279695511,
      "orthogonal_weight": 0.1,
      "step": 853,
      "total_loss": 0.7144665122032166,
      "weighted_orthogonal_loss": 0.013998682610690594
    },
    {
      "classification_loss": 0.7024727463722229,
      "epoch": 2.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1396532505750656,
      "orthogonal_weight": 0.1,
      "step": 854,
      "total_loss": 0.7164380550384521,
      "weighted_orthogonal_loss": 0.013965325430035591
    },
    {
      "classification_loss": 0.6604121923446655,
      "epoch": 2.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1391611397266388,
      "orthogonal_weight": 0.1,
      "step": 855,
      "total_loss": 0.6743283271789551,
      "weighted_orthogonal_loss": 0.01391611434519291
    },
    {
      "classification_loss": 0.6929702162742615,
      "epoch": 2.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13879862427711487,
      "orthogonal_weight": 0.1,
      "step": 856,
      "total_loss": 0.7068500518798828,
      "weighted_orthogonal_loss": 0.013879862613976002
    },
    {
      "classification_loss": 0.6521424651145935,
      "epoch": 2.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13852253556251526,
      "orthogonal_weight": 0.1,
      "step": 857,
      "total_loss": 0.6659947037696838,
      "weighted_orthogonal_loss": 0.013852253556251526
    },
    {
      "classification_loss": 0.6440297961235046,
      "epoch": 2.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13816168904304504,
      "orthogonal_weight": 0.1,
      "step": 858,
      "total_loss": 0.6578459739685059,
      "weighted_orthogonal_loss": 0.01381616946309805
    },
    {
      "classification_loss": 0.6651825308799744,
      "epoch": 2.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13793590664863586,
      "orthogonal_weight": 0.1,
      "step": 859,
      "total_loss": 0.6789761185646057,
      "weighted_orthogonal_loss": 0.013793590478599072
    },
    {
      "classification_loss": 0.6417007446289062,
      "epoch": 2.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13772781193256378,
      "orthogonal_weight": 0.1,
      "step": 860,
      "total_loss": 0.655473530292511,
      "weighted_orthogonal_loss": 0.013772781006991863
    },
    {
      "classification_loss": 0.6173883080482483,
      "epoch": 2.822950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376417875289917,
      "orthogonal_weight": 0.1,
      "step": 861,
      "total_loss": 0.6311525106430054,
      "weighted_orthogonal_loss": 0.013764179311692715
    },
    {
      "classification_loss": 0.630244255065918,
      "epoch": 2.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1375746876001358,
      "orthogonal_weight": 0.1,
      "step": 862,
      "total_loss": 0.6440017223358154,
      "weighted_orthogonal_loss": 0.01375746913254261
    },
    {
      "classification_loss": 0.6748905777931213,
      "epoch": 2.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13751280307769775,
      "orthogonal_weight": 0.1,
      "step": 863,
      "total_loss": 0.6886418461799622,
      "weighted_orthogonal_loss": 0.01375128049403429
    },
    {
      "classification_loss": 0.6917154788970947,
      "epoch": 2.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13746412098407745,
      "orthogonal_weight": 0.1,
      "step": 864,
      "total_loss": 0.7054619193077087,
      "weighted_orthogonal_loss": 0.013746412470936775
    },
    {
      "classification_loss": 0.6363663077354431,
      "epoch": 2.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13741987943649292,
      "orthogonal_weight": 0.1,
      "step": 865,
      "total_loss": 0.650108277797699,
      "weighted_orthogonal_loss": 0.013741987757384777
    },
    {
      "classification_loss": 0.6910769939422607,
      "epoch": 2.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374032348394394,
      "orthogonal_weight": 0.1,
      "step": 866,
      "total_loss": 0.7048172950744629,
      "weighted_orthogonal_loss": 0.01374032348394394
    },
    {
      "classification_loss": 0.6239641904830933,
      "epoch": 2.8426229508196723,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13742709159851074,
      "orthogonal_weight": 0.1,
      "step": 867,
      "total_loss": 0.6377068758010864,
      "weighted_orthogonal_loss": 0.013742709532380104
    },
    {
      "classification_loss": 0.6582226157188416,
      "epoch": 2.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1374601274728775,
      "orthogonal_weight": 0.1,
      "step": 868,
      "total_loss": 0.6719686388969421,
      "weighted_orthogonal_loss": 0.013746012933552265
    },
    {
      "classification_loss": 0.6380306482315063,
      "epoch": 2.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749299943447113,
      "orthogonal_weight": 0.1,
      "step": 869,
      "total_loss": 0.6517799496650696,
      "weighted_orthogonal_loss": 0.013749300502240658
    },
    {
      "classification_loss": 0.6963013410568237,
      "epoch": 2.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13756461441516876,
      "orthogonal_weight": 0.1,
      "step": 870,
      "total_loss": 0.71005779504776,
      "weighted_orthogonal_loss": 0.013756461441516876
    },
    {
      "classification_loss": 0.6242062449455261,
      "epoch": 2.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13762743771076202,
      "orthogonal_weight": 0.1,
      "step": 871,
      "total_loss": 0.6379690170288086,
      "weighted_orthogonal_loss": 0.013762744143605232
    },
    {
      "classification_loss": 0.6582491397857666,
      "epoch": 2.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13775230944156647,
      "orthogonal_weight": 0.1,
      "step": 872,
      "total_loss": 0.6720243692398071,
      "weighted_orthogonal_loss": 0.013775231316685677
    },
    {
      "classification_loss": 0.6976112127304077,
      "epoch": 2.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13785068690776825,
      "orthogonal_weight": 0.1,
      "step": 873,
      "total_loss": 0.7113962769508362,
      "weighted_orthogonal_loss": 0.01378506887704134
    },
    {
      "classification_loss": 0.6618359684944153,
      "epoch": 2.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13781948387622833,
      "orthogonal_weight": 0.1,
      "step": 874,
      "total_loss": 0.6756179332733154,
      "weighted_orthogonal_loss": 0.013781948946416378
    },
    {
      "classification_loss": 0.6764757037162781,
      "epoch": 2.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378135234117508,
      "orthogonal_weight": 0.1,
      "step": 875,
      "total_loss": 0.6902570724487305,
      "weighted_orthogonal_loss": 0.013781352899968624
    },
    {
      "classification_loss": 0.6648213863372803,
      "epoch": 2.8721311475409834,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1378236562013626,
      "orthogonal_weight": 0.1,
      "step": 876,
      "total_loss": 0.6786037683486938,
      "weighted_orthogonal_loss": 0.013782366178929806
    },
    {
      "classification_loss": 0.7148444056510925,
      "epoch": 2.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13783076405525208,
      "orthogonal_weight": 0.1,
      "step": 877,
      "total_loss": 0.7286275029182434,
      "weighted_orthogonal_loss": 0.013783076778054237
    },
    {
      "classification_loss": 0.6933211088180542,
      "epoch": 2.8786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13781718909740448,
      "orthogonal_weight": 0.1,
      "step": 878,
      "total_loss": 0.7071028351783752,
      "weighted_orthogonal_loss": 0.013781718909740448
    },
    {
      "classification_loss": 0.7281890511512756,
      "epoch": 2.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13765178620815277,
      "orthogonal_weight": 0.1,
      "step": 879,
      "total_loss": 0.7419542074203491,
      "weighted_orthogonal_loss": 0.013765178620815277
    },
    {
      "classification_loss": 0.6592651009559631,
      "epoch": 2.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13758832216262817,
      "orthogonal_weight": 0.1,
      "step": 880,
      "total_loss": 0.6730239391326904,
      "weighted_orthogonal_loss": 0.013758832588791847
    },
    {
      "classification_loss": 0.6850625276565552,
      "epoch": 2.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13745801150798798,
      "orthogonal_weight": 0.1,
      "step": 881,
      "total_loss": 0.6988083124160767,
      "weighted_orthogonal_loss": 0.013745801523327827
    },
    {
      "classification_loss": 0.6546766757965088,
      "epoch": 2.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1373404860496521,
      "orthogonal_weight": 0.1,
      "step": 882,
      "total_loss": 0.6684107184410095,
      "weighted_orthogonal_loss": 0.013734049163758755
    },
    {
      "classification_loss": 0.6865067481994629,
      "epoch": 2.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13731399178504944,
      "orthogonal_weight": 0.1,
      "step": 883,
      "total_loss": 0.7002381682395935,
      "weighted_orthogonal_loss": 0.013731399551033974
    },
    {
      "classification_loss": 0.6239107847213745,
      "epoch": 2.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13732662796974182,
      "orthogonal_weight": 0.1,
      "step": 884,
      "total_loss": 0.6376434564590454,
      "weighted_orthogonal_loss": 0.013732663355767727
    },
    {
      "classification_loss": 0.6838407516479492,
      "epoch": 2.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1372617483139038,
      "orthogonal_weight": 0.1,
      "step": 885,
      "total_loss": 0.6975669264793396,
      "weighted_orthogonal_loss": 0.01372617483139038
    },
    {
      "classification_loss": 0.6961337924003601,
      "epoch": 2.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13723142445087433,
      "orthogonal_weight": 0.1,
      "step": 886,
      "total_loss": 0.7098569273948669,
      "weighted_orthogonal_loss": 0.013723142445087433
    },
    {
      "classification_loss": 0.6347160339355469,
      "epoch": 2.9081967213114757,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371781975030899,
      "orthogonal_weight": 0.1,
      "step": 887,
      "total_loss": 0.6484338641166687,
      "weighted_orthogonal_loss": 0.013717819936573505
    },
    {
      "classification_loss": 0.6735032796859741,
      "epoch": 2.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13716979324817657,
      "orthogonal_weight": 0.1,
      "step": 888,
      "total_loss": 0.6872202754020691,
      "weighted_orthogonal_loss": 0.013716979883611202
    },
    {
      "classification_loss": 0.6368300318717957,
      "epoch": 2.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13707570731639862,
      "orthogonal_weight": 0.1,
      "step": 889,
      "total_loss": 0.6505376100540161,
      "weighted_orthogonal_loss": 0.013707570731639862
    },
    {
      "classification_loss": 0.7129632234573364,
      "epoch": 2.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13656336069107056,
      "orthogonal_weight": 0.1,
      "step": 890,
      "total_loss": 0.72661954164505,
      "weighted_orthogonal_loss": 0.01365633588284254
    },
    {
      "classification_loss": 0.6496367454528809,
      "epoch": 2.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361621618270874,
      "orthogonal_weight": 0.1,
      "step": 891,
      "total_loss": 0.6632529497146606,
      "weighted_orthogonal_loss": 0.013616216368973255
    },
    {
      "classification_loss": 0.6428443789482117,
      "epoch": 2.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580596446990967,
      "orthogonal_weight": 0.1,
      "step": 892,
      "total_loss": 0.6564249992370605,
      "weighted_orthogonal_loss": 0.013580597005784512
    },
    {
      "classification_loss": 0.7061206102371216,
      "epoch": 2.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355288028717041,
      "orthogonal_weight": 0.1,
      "step": 893,
      "total_loss": 0.7196735143661499,
      "weighted_orthogonal_loss": 0.013552880845963955
    },
    {
      "classification_loss": 0.6892392039299011,
      "epoch": 2.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1353028565645218,
      "orthogonal_weight": 0.1,
      "step": 894,
      "total_loss": 0.7027695178985596,
      "weighted_orthogonal_loss": 0.013530286028981209
    },
    {
      "classification_loss": 0.7436215281486511,
      "epoch": 2.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1351049691438675,
      "orthogonal_weight": 0.1,
      "step": 895,
      "total_loss": 0.7571320533752441,
      "weighted_orthogonal_loss": 0.013510497286915779
    },
    {
      "classification_loss": 0.7402898669242859,
      "epoch": 2.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13492311537265778,
      "orthogonal_weight": 0.1,
      "step": 896,
      "total_loss": 0.7537821531295776,
      "weighted_orthogonal_loss": 0.013492311351001263
    },
    {
      "classification_loss": 0.6345436573028564,
      "epoch": 2.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13472579419612885,
      "orthogonal_weight": 0.1,
      "step": 897,
      "total_loss": 0.6480162143707275,
      "weighted_orthogonal_loss": 0.013472579419612885
    },
    {
      "classification_loss": 0.6982722282409668,
      "epoch": 2.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1345595270395279,
      "orthogonal_weight": 0.1,
      "step": 898,
      "total_loss": 0.7117281556129456,
      "weighted_orthogonal_loss": 0.013455952517688274
    },
    {
      "classification_loss": 0.6563827395439148,
      "epoch": 2.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1343676745891571,
      "orthogonal_weight": 0.1,
      "step": 899,
      "total_loss": 0.6698195338249207,
      "weighted_orthogonal_loss": 0.013436767272651196
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 7.655550479888916,
      "learning_rate": 0.0001733666666666667,
      "loss": 0.6868,
      "step": 900
    },
    {
      "classification_loss": 0.6516596078872681,
      "epoch": 2.9508196721311473,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13415351510047913,
      "orthogonal_weight": 0.1,
      "step": 900,
      "total_loss": 0.6650749444961548,
      "weighted_orthogonal_loss": 0.013415351510047913
    },
    {
      "classification_loss": 0.6185593605041504,
      "epoch": 2.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340084820985794,
      "orthogonal_weight": 0.1,
      "step": 901,
      "total_loss": 0.6319602131843567,
      "weighted_orthogonal_loss": 0.013400848023593426
    },
    {
      "classification_loss": 0.6346449851989746,
      "epoch": 2.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13388366997241974,
      "orthogonal_weight": 0.1,
      "step": 902,
      "total_loss": 0.6480333805084229,
      "weighted_orthogonal_loss": 0.013388367369771004
    },
    {
      "classification_loss": 0.6796820163726807,
      "epoch": 2.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13375800848007202,
      "orthogonal_weight": 0.1,
      "step": 903,
      "total_loss": 0.6930578351020813,
      "weighted_orthogonal_loss": 0.013375801034271717
    },
    {
      "classification_loss": 0.6618908643722534,
      "epoch": 2.963934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336188018321991,
      "orthogonal_weight": 0.1,
      "step": 904,
      "total_loss": 0.6752527356147766,
      "weighted_orthogonal_loss": 0.01336188055574894
    },
    {
      "classification_loss": 0.6549010276794434,
      "epoch": 2.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13353955745697021,
      "orthogonal_weight": 0.1,
      "step": 905,
      "total_loss": 0.6682549715042114,
      "weighted_orthogonal_loss": 0.013353955931961536
    },
    {
      "classification_loss": 0.7038845419883728,
      "epoch": 2.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13346640765666962,
      "orthogonal_weight": 0.1,
      "step": 906,
      "total_loss": 0.7172311544418335,
      "weighted_orthogonal_loss": 0.013346641324460506
    },
    {
      "classification_loss": 0.6596993803977966,
      "epoch": 2.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13336536288261414,
      "orthogonal_weight": 0.1,
      "step": 907,
      "total_loss": 0.6730359196662903,
      "weighted_orthogonal_loss": 0.013336536474525928
    },
    {
      "classification_loss": 0.6643521189689636,
      "epoch": 2.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13324430584907532,
      "orthogonal_weight": 0.1,
      "step": 908,
      "total_loss": 0.6776765584945679,
      "weighted_orthogonal_loss": 0.013324431143701077
    },
    {
      "classification_loss": 0.700383186340332,
      "epoch": 2.9803278688524593,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1332109421491623,
      "orthogonal_weight": 0.1,
      "step": 909,
      "total_loss": 0.7137042880058289,
      "weighted_orthogonal_loss": 0.01332109421491623
    },
    {
      "classification_loss": 0.6373188495635986,
      "epoch": 2.9836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13295488059520721,
      "orthogonal_weight": 0.1,
      "step": 910,
      "total_loss": 0.650614321231842,
      "weighted_orthogonal_loss": 0.013295488432049751
    },
    {
      "classification_loss": 0.6768724918365479,
      "epoch": 2.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13276943564414978,
      "orthogonal_weight": 0.1,
      "step": 911,
      "total_loss": 0.6901494264602661,
      "weighted_orthogonal_loss": 0.013276943936944008
    },
    {
      "classification_loss": 0.6718534231185913,
      "epoch": 2.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13258062303066254,
      "orthogonal_weight": 0.1,
      "step": 912,
      "total_loss": 0.6851114630699158,
      "weighted_orthogonal_loss": 0.013258062303066254
    },
    {
      "classification_loss": 0.6233301758766174,
      "epoch": 2.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13243211805820465,
      "orthogonal_weight": 0.1,
      "step": 913,
      "total_loss": 0.6365733742713928,
      "weighted_orthogonal_loss": 0.01324321236461401
    },
    {
      "classification_loss": 0.7316129207611084,
      "epoch": 2.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1323181539773941,
      "orthogonal_weight": 0.1,
      "step": 914,
      "total_loss": 0.7448447346687317,
      "weighted_orthogonal_loss": 0.01323181577026844
    },
    {
      "classification_loss": 0.6850863099098206,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6983069777488708,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6994917988777161,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.7127124667167664,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6793655753135681,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6925862431526184,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6831203699111938,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6963410377502441,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6856631636619568,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6988838315010071,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6830475330352783,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6962682008743286,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6757809519767761,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6890016198158264,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.7015624642372131,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.7147831320762634,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.548,
      "eval_f1": 0.6331168831168831,
      "eval_loss": 0.6995022296905518,
      "eval_precision": 0.6403940886699507,
      "eval_recall": 0.6260032102728732,
      "eval_runtime": 6.1599,
      "eval_samples_per_second": 162.34,
      "eval_steps_per_second": 1.299,
      "step": 915
    },
    {
      "classification_loss": 0.6477096080780029,
      "epoch": 3.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13220639526844025,
      "orthogonal_weight": 0.1,
      "step": 915,
      "total_loss": 0.6609302759170532,
      "weighted_orthogonal_loss": 0.013220639899373055
    },
    {
      "classification_loss": 0.6321674585342407,
      "epoch": 3.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13214422762393951,
      "orthogonal_weight": 0.1,
      "step": 916,
      "total_loss": 0.6453818678855896,
      "weighted_orthogonal_loss": 0.013214423321187496
    },
    {
      "classification_loss": 0.7097901105880737,
      "epoch": 3.0065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13201601803302765,
      "orthogonal_weight": 0.1,
      "step": 917,
      "total_loss": 0.7229917049407959,
      "weighted_orthogonal_loss": 0.013201601803302765
    },
    {
      "classification_loss": 0.6862433552742004,
      "epoch": 3.0098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13187651336193085,
      "orthogonal_weight": 0.1,
      "step": 918,
      "total_loss": 0.6994310021400452,
      "weighted_orthogonal_loss": 0.0131876515224576
    },
    {
      "classification_loss": 0.6850602030754089,
      "epoch": 3.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13173681497573853,
      "orthogonal_weight": 0.1,
      "step": 919,
      "total_loss": 0.6982339024543762,
      "weighted_orthogonal_loss": 0.013173681683838367
    },
    {
      "classification_loss": 0.5959040522575378,
      "epoch": 3.0163934426229506,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13137459754943848,
      "orthogonal_weight": 0.1,
      "step": 920,
      "total_loss": 0.6090415120124817,
      "weighted_orthogonal_loss": 0.013137459754943848
    },
    {
      "classification_loss": 0.6883159875869751,
      "epoch": 3.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104073703289032,
      "orthogonal_weight": 0.1,
      "step": 921,
      "total_loss": 0.7014200687408447,
      "weighted_orthogonal_loss": 0.013104073703289032
    },
    {
      "classification_loss": 0.6134752631187439,
      "epoch": 3.0229508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13078591227531433,
      "orthogonal_weight": 0.1,
      "step": 922,
      "total_loss": 0.6265538334846497,
      "weighted_orthogonal_loss": 0.013078591786324978
    },
    {
      "classification_loss": 0.6603575348854065,
      "epoch": 3.0262295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13069376349449158,
      "orthogonal_weight": 0.1,
      "step": 923,
      "total_loss": 0.6734269261360168,
      "weighted_orthogonal_loss": 0.013069376349449158
    },
    {
      "classification_loss": 0.6847029328346252,
      "epoch": 3.0295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13064999878406525,
      "orthogonal_weight": 0.1,
      "step": 924,
      "total_loss": 0.6977679133415222,
      "weighted_orthogonal_loss": 0.01306500006467104
    },
    {
      "classification_loss": 0.671438455581665,
      "epoch": 3.0327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1305849552154541,
      "orthogonal_weight": 0.1,
      "step": 925,
      "total_loss": 0.6844969391822815,
      "weighted_orthogonal_loss": 0.013058495707809925
    },
    {
      "classification_loss": 0.6508132219314575,
      "epoch": 3.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13057905435562134,
      "orthogonal_weight": 0.1,
      "step": 926,
      "total_loss": 0.6638711094856262,
      "weighted_orthogonal_loss": 0.013057905249297619
    },
    {
      "classification_loss": 0.6654298305511475,
      "epoch": 3.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13054393231868744,
      "orthogonal_weight": 0.1,
      "step": 927,
      "total_loss": 0.6784842014312744,
      "weighted_orthogonal_loss": 0.013054393231868744
    },
    {
      "classification_loss": 0.6545535922050476,
      "epoch": 3.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1308320313692093,
      "orthogonal_weight": 0.1,
      "step": 928,
      "total_loss": 0.6676368117332458,
      "weighted_orthogonal_loss": 0.013083203695714474
    },
    {
      "classification_loss": 0.6401187777519226,
      "epoch": 3.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13104471564292908,
      "orthogonal_weight": 0.1,
      "step": 929,
      "total_loss": 0.6532232761383057,
      "weighted_orthogonal_loss": 0.013104471378028393
    },
    {
      "classification_loss": 0.6693537831306458,
      "epoch": 3.0491803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13136835396289825,
      "orthogonal_weight": 0.1,
      "step": 930,
      "total_loss": 0.6824906468391418,
      "weighted_orthogonal_loss": 0.013136835768818855
    },
    {
      "classification_loss": 0.6873430013656616,
      "epoch": 3.0524590163934424,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13178230822086334,
      "orthogonal_weight": 0.1,
      "step": 931,
      "total_loss": 0.7005212306976318,
      "weighted_orthogonal_loss": 0.013178231194615364
    },
    {
      "classification_loss": 0.7204275131225586,
      "epoch": 3.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13219889998435974,
      "orthogonal_weight": 0.1,
      "step": 932,
      "total_loss": 0.7336474061012268,
      "weighted_orthogonal_loss": 0.013219890184700489
    },
    {
      "classification_loss": 0.6325345039367676,
      "epoch": 3.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1324281245470047,
      "orthogonal_weight": 0.1,
      "step": 933,
      "total_loss": 0.6457773447036743,
      "weighted_orthogonal_loss": 0.0132428128272295
    },
    {
      "classification_loss": 0.642624020576477,
      "epoch": 3.0622950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13278310000896454,
      "orthogonal_weight": 0.1,
      "step": 934,
      "total_loss": 0.6559023261070251,
      "weighted_orthogonal_loss": 0.013278310187160969
    },
    {
      "classification_loss": 0.6765152812004089,
      "epoch": 3.0655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13313496112823486,
      "orthogonal_weight": 0.1,
      "step": 935,
      "total_loss": 0.6898287534713745,
      "weighted_orthogonal_loss": 0.013313496485352516
    },
    {
      "classification_loss": 0.6715161800384521,
      "epoch": 3.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13336436450481415,
      "orthogonal_weight": 0.1,
      "step": 936,
      "total_loss": 0.6848526000976562,
      "weighted_orthogonal_loss": 0.013336436823010445
    },
    {
      "classification_loss": 0.6505905985832214,
      "epoch": 3.0721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13354118168354034,
      "orthogonal_weight": 0.1,
      "step": 937,
      "total_loss": 0.6639447212219238,
      "weighted_orthogonal_loss": 0.01335411798208952
    },
    {
      "classification_loss": 0.6393555998802185,
      "epoch": 3.0754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13369476795196533,
      "orthogonal_weight": 0.1,
      "step": 938,
      "total_loss": 0.652725100517273,
      "weighted_orthogonal_loss": 0.013369477353990078
    },
    {
      "classification_loss": 0.6459389328956604,
      "epoch": 3.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13388065993785858,
      "orthogonal_weight": 0.1,
      "step": 939,
      "total_loss": 0.65932697057724,
      "weighted_orthogonal_loss": 0.013388066552579403
    },
    {
      "classification_loss": 0.6082014441490173,
      "epoch": 3.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1340549886226654,
      "orthogonal_weight": 0.1,
      "step": 940,
      "total_loss": 0.6216069459915161,
      "weighted_orthogonal_loss": 0.013405499048531055
    },
    {
      "classification_loss": 0.651372492313385,
      "epoch": 3.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13417202234268188,
      "orthogonal_weight": 0.1,
      "step": 941,
      "total_loss": 0.6647896766662598,
      "weighted_orthogonal_loss": 0.013417202048003674
    },
    {
      "classification_loss": 0.6560359597206116,
      "epoch": 3.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13418664038181305,
      "orthogonal_weight": 0.1,
      "step": 942,
      "total_loss": 0.6694546341896057,
      "weighted_orthogonal_loss": 0.01341866422444582
    },
    {
      "classification_loss": 0.654608428478241,
      "epoch": 3.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13433967530727386,
      "orthogonal_weight": 0.1,
      "step": 943,
      "total_loss": 0.6680424213409424,
      "weighted_orthogonal_loss": 0.013433967716991901
    },
    {
      "classification_loss": 0.6182647943496704,
      "epoch": 3.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13448785245418549,
      "orthogonal_weight": 0.1,
      "step": 944,
      "total_loss": 0.6317135691642761,
      "weighted_orthogonal_loss": 0.013448785059154034
    },
    {
      "classification_loss": 0.6573328375816345,
      "epoch": 3.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13461290299892426,
      "orthogonal_weight": 0.1,
      "step": 945,
      "total_loss": 0.6707941293716431,
      "weighted_orthogonal_loss": 0.01346129085868597
    },
    {
      "classification_loss": 0.6940430998802185,
      "epoch": 3.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1347406655550003,
      "orthogonal_weight": 0.1,
      "step": 946,
      "total_loss": 0.707517147064209,
      "weighted_orthogonal_loss": 0.013474066741764545
    },
    {
      "classification_loss": 0.6537476181983948,
      "epoch": 3.1049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13490833342075348,
      "orthogonal_weight": 0.1,
      "step": 947,
      "total_loss": 0.6672384738922119,
      "weighted_orthogonal_loss": 0.013490833342075348
    },
    {
      "classification_loss": 0.7100512981414795,
      "epoch": 3.1081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1350744515657425,
      "orthogonal_weight": 0.1,
      "step": 948,
      "total_loss": 0.7235587239265442,
      "weighted_orthogonal_loss": 0.013507445342838764
    },
    {
      "classification_loss": 0.6818158626556396,
      "epoch": 3.1114754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1352919638156891,
      "orthogonal_weight": 0.1,
      "step": 949,
      "total_loss": 0.6953450441360474,
      "weighted_orthogonal_loss": 0.013529196381568909
    },
    {
      "classification_loss": 0.6380026340484619,
      "epoch": 3.1147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13551689684391022,
      "orthogonal_weight": 0.1,
      "step": 950,
      "total_loss": 0.6515543460845947,
      "weighted_orthogonal_loss": 0.013551689684391022
    },
    {
      "classification_loss": 0.639814555644989,
      "epoch": 3.1180327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357669234275818,
      "orthogonal_weight": 0.1,
      "step": 951,
      "total_loss": 0.6533912420272827,
      "weighted_orthogonal_loss": 0.013576692901551723
    },
    {
      "classification_loss": 0.6903493404388428,
      "epoch": 3.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13606227934360504,
      "orthogonal_weight": 0.1,
      "step": 952,
      "total_loss": 0.7039555907249451,
      "weighted_orthogonal_loss": 0.013606227934360504
    },
    {
      "classification_loss": 0.6345198750495911,
      "epoch": 3.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631582260131836,
      "orthogonal_weight": 0.1,
      "step": 953,
      "total_loss": 0.6481514573097229,
      "weighted_orthogonal_loss": 0.013631582260131836
    },
    {
      "classification_loss": 0.6613372564315796,
      "epoch": 3.1278688524590166,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13660413026809692,
      "orthogonal_weight": 0.1,
      "step": 954,
      "total_loss": 0.6749976873397827,
      "weighted_orthogonal_loss": 0.013660413213074207
    },
    {
      "classification_loss": 0.6540759801864624,
      "epoch": 3.1311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13664482533931732,
      "orthogonal_weight": 0.1,
      "step": 955,
      "total_loss": 0.6677404642105103,
      "weighted_orthogonal_loss": 0.013664483092725277
    },
    {
      "classification_loss": 0.6421686410903931,
      "epoch": 3.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1366959661245346,
      "orthogonal_weight": 0.1,
      "step": 956,
      "total_loss": 0.6558382511138916,
      "weighted_orthogonal_loss": 0.01366959698498249
    },
    {
      "classification_loss": 0.6001585125923157,
      "epoch": 3.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13678671419620514,
      "orthogonal_weight": 0.1,
      "step": 957,
      "total_loss": 0.6138371825218201,
      "weighted_orthogonal_loss": 0.013678671792149544
    },
    {
      "classification_loss": 0.6398242712020874,
      "epoch": 3.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13685038685798645,
      "orthogonal_weight": 0.1,
      "step": 958,
      "total_loss": 0.6535093188285828,
      "weighted_orthogonal_loss": 0.01368503924459219
    },
    {
      "classification_loss": 0.6549479961395264,
      "epoch": 3.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13693776726722717,
      "orthogonal_weight": 0.1,
      "step": 959,
      "total_loss": 0.6686417460441589,
      "weighted_orthogonal_loss": 0.013693776912987232
    },
    {
      "classification_loss": 0.6798014640808105,
      "epoch": 3.1475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371031552553177,
      "orthogonal_weight": 0.1,
      "step": 960,
      "total_loss": 0.6935117840766907,
      "weighted_orthogonal_loss": 0.013710315339267254
    },
    {
      "classification_loss": 0.6741546392440796,
      "epoch": 3.1508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13723506033420563,
      "orthogonal_weight": 0.1,
      "step": 961,
      "total_loss": 0.6878781318664551,
      "weighted_orthogonal_loss": 0.013723506592214108
    },
    {
      "classification_loss": 0.6198928952217102,
      "epoch": 3.1540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371309608221054,
      "orthogonal_weight": 0.1,
      "step": 962,
      "total_loss": 0.6336060166358948,
      "weighted_orthogonal_loss": 0.013713096268475056
    },
    {
      "classification_loss": 0.6767441034317017,
      "epoch": 3.1573770491803277,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1371006965637207,
      "orthogonal_weight": 0.1,
      "step": 963,
      "total_loss": 0.6904541850090027,
      "weighted_orthogonal_loss": 0.013710069470107555
    },
    {
      "classification_loss": 0.6412035226821899,
      "epoch": 3.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1370914727449417,
      "orthogonal_weight": 0.1,
      "step": 964,
      "total_loss": 0.6549126505851746,
      "weighted_orthogonal_loss": 0.013709147460758686
    },
    {
      "classification_loss": 0.6378623843193054,
      "epoch": 3.1639344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13712355494499207,
      "orthogonal_weight": 0.1,
      "step": 965,
      "total_loss": 0.6515747308731079,
      "weighted_orthogonal_loss": 0.013712355867028236
    },
    {
      "classification_loss": 0.6579567193984985,
      "epoch": 3.1672131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13717393577098846,
      "orthogonal_weight": 0.1,
      "step": 966,
      "total_loss": 0.6716741323471069,
      "weighted_orthogonal_loss": 0.013717393390834332
    },
    {
      "classification_loss": 0.6192328929901123,
      "epoch": 3.1704918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1372346431016922,
      "orthogonal_weight": 0.1,
      "step": 967,
      "total_loss": 0.6329563856124878,
      "weighted_orthogonal_loss": 0.01372346468269825
    },
    {
      "classification_loss": 0.6666384935379028,
      "epoch": 3.1737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13733573257923126,
      "orthogonal_weight": 0.1,
      "step": 968,
      "total_loss": 0.6803720593452454,
      "weighted_orthogonal_loss": 0.013733573257923126
    },
    {
      "classification_loss": 0.6563258767127991,
      "epoch": 3.177049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13743789494037628,
      "orthogonal_weight": 0.1,
      "step": 969,
      "total_loss": 0.670069694519043,
      "weighted_orthogonal_loss": 0.013743789866566658
    },
    {
      "classification_loss": 0.646151065826416,
      "epoch": 3.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13749854266643524,
      "orthogonal_weight": 0.1,
      "step": 970,
      "total_loss": 0.6599009037017822,
      "weighted_orthogonal_loss": 0.013749854639172554
    },
    {
      "classification_loss": 0.6902819275856018,
      "epoch": 3.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1376294046640396,
      "orthogonal_weight": 0.1,
      "step": 971,
      "total_loss": 0.7040448784828186,
      "weighted_orthogonal_loss": 0.013762940652668476
    },
    {
      "classification_loss": 0.6010188460350037,
      "epoch": 3.1868852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13780198991298676,
      "orthogonal_weight": 0.1,
      "step": 972,
      "total_loss": 0.6147990226745605,
      "weighted_orthogonal_loss": 0.013780198991298676
    },
    {
      "classification_loss": 0.6743837594985962,
      "epoch": 3.1901639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13811206817626953,
      "orthogonal_weight": 0.1,
      "step": 973,
      "total_loss": 0.688194990158081,
      "weighted_orthogonal_loss": 0.013811207376420498
    },
    {
      "classification_loss": 0.6004368662834167,
      "epoch": 3.1934426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13842546939849854,
      "orthogonal_weight": 0.1,
      "step": 974,
      "total_loss": 0.6142793893814087,
      "weighted_orthogonal_loss": 0.013842547312378883
    },
    {
      "classification_loss": 0.6734126210212708,
      "epoch": 3.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13868871331214905,
      "orthogonal_weight": 0.1,
      "step": 975,
      "total_loss": 0.6872814893722534,
      "weighted_orthogonal_loss": 0.01386887114495039
    },
    {
      "classification_loss": 0.6442055106163025,
      "epoch": 3.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1389317810535431,
      "orthogonal_weight": 0.1,
      "step": 976,
      "total_loss": 0.6580986976623535,
      "weighted_orthogonal_loss": 0.013893178664147854
    },
    {
      "classification_loss": 0.6403493881225586,
      "epoch": 3.2032786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13917984068393707,
      "orthogonal_weight": 0.1,
      "step": 977,
      "total_loss": 0.6542673707008362,
      "weighted_orthogonal_loss": 0.013917984440922737
    },
    {
      "classification_loss": 0.6741981506347656,
      "epoch": 3.2065573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1393687129020691,
      "orthogonal_weight": 0.1,
      "step": 978,
      "total_loss": 0.688135027885437,
      "weighted_orthogonal_loss": 0.013936871662735939
    },
    {
      "classification_loss": 0.6380749344825745,
      "epoch": 3.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13958795368671417,
      "orthogonal_weight": 0.1,
      "step": 979,
      "total_loss": 0.6520337462425232,
      "weighted_orthogonal_loss": 0.013958795927464962
    },
    {
      "classification_loss": 0.6342712044715881,
      "epoch": 3.2131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1397451013326645,
      "orthogonal_weight": 0.1,
      "step": 980,
      "total_loss": 0.6482456922531128,
      "weighted_orthogonal_loss": 0.013974510133266449
    },
    {
      "classification_loss": 0.7204321622848511,
      "epoch": 3.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13992691040039062,
      "orthogonal_weight": 0.1,
      "step": 981,
      "total_loss": 0.7344248294830322,
      "weighted_orthogonal_loss": 0.013992691412568092
    },
    {
      "classification_loss": 0.6277929544448853,
      "epoch": 3.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14013764262199402,
      "orthogonal_weight": 0.1,
      "step": 982,
      "total_loss": 0.6418067216873169,
      "weighted_orthogonal_loss": 0.014013764448463917
    },
    {
      "classification_loss": 0.654269814491272,
      "epoch": 3.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1402316391468048,
      "orthogonal_weight": 0.1,
      "step": 983,
      "total_loss": 0.6682929992675781,
      "weighted_orthogonal_loss": 0.01402316428720951
    },
    {
      "classification_loss": 0.7230896353721619,
      "epoch": 3.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1403599977493286,
      "orthogonal_weight": 0.1,
      "step": 984,
      "total_loss": 0.7371256351470947,
      "weighted_orthogonal_loss": 0.014035999774932861
    },
    {
      "classification_loss": 0.6091078519821167,
      "epoch": 3.2295081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14045706391334534,
      "orthogonal_weight": 0.1,
      "step": 985,
      "total_loss": 0.623153567314148,
      "weighted_orthogonal_loss": 0.014045706950128078
    },
    {
      "classification_loss": 0.6315215826034546,
      "epoch": 3.2327868852459014,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14047633111476898,
      "orthogonal_weight": 0.1,
      "step": 986,
      "total_loss": 0.6455692052841187,
      "weighted_orthogonal_loss": 0.014047632925212383
    },
    {
      "classification_loss": 0.7049210667610168,
      "epoch": 3.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14050062000751495,
      "orthogonal_weight": 0.1,
      "step": 987,
      "total_loss": 0.7189711332321167,
      "weighted_orthogonal_loss": 0.01405006181448698
    },
    {
      "classification_loss": 0.6868048906326294,
      "epoch": 3.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.140533909201622,
      "orthogonal_weight": 0.1,
      "step": 988,
      "total_loss": 0.7008582949638367,
      "weighted_orthogonal_loss": 0.01405339129269123
    },
    {
      "classification_loss": 0.6430195569992065,
      "epoch": 3.2426229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1405780166387558,
      "orthogonal_weight": 0.1,
      "step": 989,
      "total_loss": 0.6570773720741272,
      "weighted_orthogonal_loss": 0.01405780203640461
    },
    {
      "classification_loss": 0.6126911044120789,
      "epoch": 3.2459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406165510416031,
      "orthogonal_weight": 0.1,
      "step": 990,
      "total_loss": 0.6267527341842651,
      "weighted_orthogonal_loss": 0.014061654917895794
    },
    {
      "classification_loss": 0.7152563333511353,
      "epoch": 3.2491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14066220819950104,
      "orthogonal_weight": 0.1,
      "step": 991,
      "total_loss": 0.7293225526809692,
      "weighted_orthogonal_loss": 0.014066221192479134
    },
    {
      "classification_loss": 0.6327564120292664,
      "epoch": 3.2524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14074385166168213,
      "orthogonal_weight": 0.1,
      "step": 992,
      "total_loss": 0.6468307971954346,
      "weighted_orthogonal_loss": 0.014074385166168213
    },
    {
      "classification_loss": 0.7078341245651245,
      "epoch": 3.2557377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14083652198314667,
      "orthogonal_weight": 0.1,
      "step": 993,
      "total_loss": 0.7219177484512329,
      "weighted_orthogonal_loss": 0.014083652757108212
    },
    {
      "classification_loss": 0.638905942440033,
      "epoch": 3.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14072902500629425,
      "orthogonal_weight": 0.1,
      "step": 994,
      "total_loss": 0.6529788374900818,
      "weighted_orthogonal_loss": 0.014072902500629425
    },
    {
      "classification_loss": 0.6364955306053162,
      "epoch": 3.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14065606892108917,
      "orthogonal_weight": 0.1,
      "step": 995,
      "total_loss": 0.6505611538887024,
      "weighted_orthogonal_loss": 0.014065607450902462
    },
    {
      "classification_loss": 0.6164757609367371,
      "epoch": 3.265573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14073798060417175,
      "orthogonal_weight": 0.1,
      "step": 996,
      "total_loss": 0.6305495500564575,
      "weighted_orthogonal_loss": 0.014073798432946205
    },
    {
      "classification_loss": 0.6315312385559082,
      "epoch": 3.2688524590163937,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14080023765563965,
      "orthogonal_weight": 0.1,
      "step": 997,
      "total_loss": 0.6456112861633301,
      "weighted_orthogonal_loss": 0.01408002432435751
    },
    {
      "classification_loss": 0.6797311305999756,
      "epoch": 3.2721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14095667004585266,
      "orthogonal_weight": 0.1,
      "step": 998,
      "total_loss": 0.6938267946243286,
      "weighted_orthogonal_loss": 0.014095666818320751
    },
    {
      "classification_loss": 0.6503975987434387,
      "epoch": 3.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1411110907793045,
      "orthogonal_weight": 0.1,
      "step": 999,
      "total_loss": 0.6645087003707886,
      "weighted_orthogonal_loss": 0.01411110907793045
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 7.654499530792236,
      "learning_rate": 0.00017003333333333334,
      "loss": 0.6706,
      "step": 1000
    },
    {
      "classification_loss": 0.6191651821136475,
      "epoch": 3.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14125342667102814,
      "orthogonal_weight": 0.1,
      "step": 1000,
      "total_loss": 0.6332905292510986,
      "weighted_orthogonal_loss": 0.014125342480838299
    },
    {
      "classification_loss": 0.6513949632644653,
      "epoch": 3.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1411789506673813,
      "orthogonal_weight": 0.1,
      "step": 1001,
      "total_loss": 0.6655128598213196,
      "weighted_orthogonal_loss": 0.014117895625531673
    },
    {
      "classification_loss": 0.6781859397888184,
      "epoch": 3.2852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14087694883346558,
      "orthogonal_weight": 0.1,
      "step": 1002,
      "total_loss": 0.6922736167907715,
      "weighted_orthogonal_loss": 0.014087694697082043
    },
    {
      "classification_loss": 0.6944517493247986,
      "epoch": 3.2885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406310349702835,
      "orthogonal_weight": 0.1,
      "step": 1003,
      "total_loss": 0.7085148692131042,
      "weighted_orthogonal_loss": 0.014063104055821896
    },
    {
      "classification_loss": 0.6507539749145508,
      "epoch": 3.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14041300117969513,
      "orthogonal_weight": 0.1,
      "step": 1004,
      "total_loss": 0.6647952795028687,
      "weighted_orthogonal_loss": 0.014041299931704998
    },
    {
      "classification_loss": 0.6273910999298096,
      "epoch": 3.2950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14022056758403778,
      "orthogonal_weight": 0.1,
      "step": 1005,
      "total_loss": 0.641413152217865,
      "weighted_orthogonal_loss": 0.014022056944668293
    },
    {
      "classification_loss": 0.7005413174629211,
      "epoch": 3.2983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1400725096464157,
      "orthogonal_weight": 0.1,
      "step": 1006,
      "total_loss": 0.7145485877990723,
      "weighted_orthogonal_loss": 0.014007250778377056
    },
    {
      "classification_loss": 0.6762268543243408,
      "epoch": 3.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13990361988544464,
      "orthogonal_weight": 0.1,
      "step": 1007,
      "total_loss": 0.6902171969413757,
      "weighted_orthogonal_loss": 0.013990362174808979
    },
    {
      "classification_loss": 0.644727349281311,
      "epoch": 3.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13986971974372864,
      "orthogonal_weight": 0.1,
      "step": 1008,
      "total_loss": 0.6587142944335938,
      "weighted_orthogonal_loss": 0.013986972160637379
    },
    {
      "classification_loss": 0.6663669347763062,
      "epoch": 3.3081967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13967908918857574,
      "orthogonal_weight": 0.1,
      "step": 1009,
      "total_loss": 0.6803348660469055,
      "weighted_orthogonal_loss": 0.013967908918857574
    },
    {
      "classification_loss": 0.6922574043273926,
      "epoch": 3.3114754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13948602974414825,
      "orthogonal_weight": 0.1,
      "step": 1010,
      "total_loss": 0.7062060236930847,
      "weighted_orthogonal_loss": 0.01394860353320837
    },
    {
      "classification_loss": 0.6825107336044312,
      "epoch": 3.314754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13927166163921356,
      "orthogonal_weight": 0.1,
      "step": 1011,
      "total_loss": 0.6964378952980042,
      "weighted_orthogonal_loss": 0.013927166350185871
    },
    {
      "classification_loss": 0.6265398263931274,
      "epoch": 3.318032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390901505947113,
      "orthogonal_weight": 0.1,
      "step": 1012,
      "total_loss": 0.6404488682746887,
      "weighted_orthogonal_loss": 0.013909014873206615
    },
    {
      "classification_loss": 0.6675375699996948,
      "epoch": 3.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388394981622696,
      "orthogonal_weight": 0.1,
      "step": 1013,
      "total_loss": 0.6814215183258057,
      "weighted_orthogonal_loss": 0.013883950188755989
    },
    {
      "classification_loss": 0.6483844518661499,
      "epoch": 3.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13876697421073914,
      "orthogonal_weight": 0.1,
      "step": 1014,
      "total_loss": 0.6622611284255981,
      "weighted_orthogonal_loss": 0.013876697979867458
    },
    {
      "classification_loss": 0.6377015113830566,
      "epoch": 3.3278688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13869747519493103,
      "orthogonal_weight": 0.1,
      "step": 1015,
      "total_loss": 0.6515712738037109,
      "weighted_orthogonal_loss": 0.013869747519493103
    },
    {
      "classification_loss": 0.5941048860549927,
      "epoch": 3.3311475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386825144290924,
      "orthogonal_weight": 0.1,
      "step": 1016,
      "total_loss": 0.6079731583595276,
      "weighted_orthogonal_loss": 0.01386825181543827
    },
    {
      "classification_loss": 0.6161072850227356,
      "epoch": 3.3344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13867513835430145,
      "orthogonal_weight": 0.1,
      "step": 1017,
      "total_loss": 0.6299747824668884,
      "weighted_orthogonal_loss": 0.013867514207959175
    },
    {
      "classification_loss": 0.6267886757850647,
      "epoch": 3.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13872677087783813,
      "orthogonal_weight": 0.1,
      "step": 1018,
      "total_loss": 0.640661358833313,
      "weighted_orthogonal_loss": 0.013872677460312843
    },
    {
      "classification_loss": 0.6988235712051392,
      "epoch": 3.3409836065573773,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13881352543830872,
      "orthogonal_weight": 0.1,
      "step": 1019,
      "total_loss": 0.7127048969268799,
      "weighted_orthogonal_loss": 0.013881352730095387
    },
    {
      "classification_loss": 0.676645040512085,
      "epoch": 3.3442622950819674,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13886518776416779,
      "orthogonal_weight": 0.1,
      "step": 1020,
      "total_loss": 0.6905315518379211,
      "weighted_orthogonal_loss": 0.013886518776416779
    },
    {
      "classification_loss": 0.6767535209655762,
      "epoch": 3.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13882100582122803,
      "orthogonal_weight": 0.1,
      "step": 1021,
      "total_loss": 0.690635621547699,
      "weighted_orthogonal_loss": 0.013882100582122803
    },
    {
      "classification_loss": 0.7252440452575684,
      "epoch": 3.3508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13886775076389313,
      "orthogonal_weight": 0.1,
      "step": 1022,
      "total_loss": 0.7391307950019836,
      "weighted_orthogonal_loss": 0.013886774890124798
    },
    {
      "classification_loss": 0.6484150886535645,
      "epoch": 3.3540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13893291354179382,
      "orthogonal_weight": 0.1,
      "step": 1023,
      "total_loss": 0.662308394908905,
      "weighted_orthogonal_loss": 0.013893291354179382
    },
    {
      "classification_loss": 0.6559189558029175,
      "epoch": 3.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386280506849289,
      "orthogonal_weight": 0.1,
      "step": 1024,
      "total_loss": 0.6697817444801331,
      "weighted_orthogonal_loss": 0.01386280544102192
    },
    {
      "classification_loss": 0.6672844290733337,
      "epoch": 3.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13838335871696472,
      "orthogonal_weight": 0.1,
      "step": 1025,
      "total_loss": 0.6811227798461914,
      "weighted_orthogonal_loss": 0.013838335871696472
    },
    {
      "classification_loss": 0.6752216219902039,
      "epoch": 3.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13820643723011017,
      "orthogonal_weight": 0.1,
      "step": 1026,
      "total_loss": 0.6890422701835632,
      "weighted_orthogonal_loss": 0.013820643536746502
    },
    {
      "classification_loss": 0.689396858215332,
      "epoch": 3.3672131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1381242573261261,
      "orthogonal_weight": 0.1,
      "step": 1027,
      "total_loss": 0.7032092809677124,
      "weighted_orthogonal_loss": 0.013812425546348095
    },
    {
      "classification_loss": 0.6453076004981995,
      "epoch": 3.3704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1381722092628479,
      "orthogonal_weight": 0.1,
      "step": 1028,
      "total_loss": 0.6591248512268066,
      "weighted_orthogonal_loss": 0.01381722092628479
    },
    {
      "classification_loss": 0.6765332818031311,
      "epoch": 3.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13826413452625275,
      "orthogonal_weight": 0.1,
      "step": 1029,
      "total_loss": 0.6903597116470337,
      "weighted_orthogonal_loss": 0.01382641401141882
    },
    {
      "classification_loss": 0.6129103302955627,
      "epoch": 3.3770491803278686,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13841603696346283,
      "orthogonal_weight": 0.1,
      "step": 1030,
      "total_loss": 0.6267519593238831,
      "weighted_orthogonal_loss": 0.013841603882610798
    },
    {
      "classification_loss": 0.6298218965530396,
      "epoch": 3.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1386304646730423,
      "orthogonal_weight": 0.1,
      "step": 1031,
      "total_loss": 0.6436849236488342,
      "weighted_orthogonal_loss": 0.013863046653568745
    },
    {
      "classification_loss": 0.6449940800666809,
      "epoch": 3.3836065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388632357120514,
      "orthogonal_weight": 0.1,
      "step": 1032,
      "total_loss": 0.6588804125785828,
      "weighted_orthogonal_loss": 0.013886324129998684
    },
    {
      "classification_loss": 0.6037570834159851,
      "epoch": 3.3868852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13900944590568542,
      "orthogonal_weight": 0.1,
      "step": 1033,
      "total_loss": 0.6176580190658569,
      "weighted_orthogonal_loss": 0.013900944963097572
    },
    {
      "classification_loss": 0.6562291383743286,
      "epoch": 3.3901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13920624554157257,
      "orthogonal_weight": 0.1,
      "step": 1034,
      "total_loss": 0.6701497435569763,
      "weighted_orthogonal_loss": 0.013920624740421772
    },
    {
      "classification_loss": 0.7009933590888977,
      "epoch": 3.3934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13939376175403595,
      "orthogonal_weight": 0.1,
      "step": 1035,
      "total_loss": 0.7149327397346497,
      "weighted_orthogonal_loss": 0.01393937598913908
    },
    {
      "classification_loss": 0.6541226506233215,
      "epoch": 3.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1395602822303772,
      "orthogonal_weight": 0.1,
      "step": 1036,
      "total_loss": 0.6680786609649658,
      "weighted_orthogonal_loss": 0.013956028036773205
    },
    {
      "classification_loss": 0.7284018397331238,
      "epoch": 3.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1397503763437271,
      "orthogonal_weight": 0.1,
      "step": 1037,
      "total_loss": 0.7423768639564514,
      "weighted_orthogonal_loss": 0.013975038193166256
    },
    {
      "classification_loss": 0.6859689950942993,
      "epoch": 3.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13994283974170685,
      "orthogonal_weight": 0.1,
      "step": 1038,
      "total_loss": 0.6999632716178894,
      "weighted_orthogonal_loss": 0.013994283974170685
    },
    {
      "classification_loss": 0.676382839679718,
      "epoch": 3.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14031918346881866,
      "orthogonal_weight": 0.1,
      "step": 1039,
      "total_loss": 0.6904147863388062,
      "weighted_orthogonal_loss": 0.014031918719410896
    },
    {
      "classification_loss": 0.6595774292945862,
      "epoch": 3.4098360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14063377678394318,
      "orthogonal_weight": 0.1,
      "step": 1040,
      "total_loss": 0.673640787601471,
      "weighted_orthogonal_loss": 0.014063377864658833
    },
    {
      "classification_loss": 0.6383638978004456,
      "epoch": 3.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1408020704984665,
      "orthogonal_weight": 0.1,
      "step": 1041,
      "total_loss": 0.6524441242218018,
      "weighted_orthogonal_loss": 0.014080206863582134
    },
    {
      "classification_loss": 0.6562723517417908,
      "epoch": 3.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14072060585021973,
      "orthogonal_weight": 0.1,
      "step": 1042,
      "total_loss": 0.6703444123268127,
      "weighted_orthogonal_loss": 0.014072060585021973
    },
    {
      "classification_loss": 0.6057292819023132,
      "epoch": 3.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14064131677150726,
      "orthogonal_weight": 0.1,
      "step": 1043,
      "total_loss": 0.6197934150695801,
      "weighted_orthogonal_loss": 0.014064132235944271
    },
    {
      "classification_loss": 0.6434441804885864,
      "epoch": 3.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406414657831192,
      "orthogonal_weight": 0.1,
      "step": 1044,
      "total_loss": 0.6575083136558533,
      "weighted_orthogonal_loss": 0.014064147137105465
    },
    {
      "classification_loss": 0.6458033919334412,
      "epoch": 3.4262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14061889052391052,
      "orthogonal_weight": 0.1,
      "step": 1045,
      "total_loss": 0.6598652601242065,
      "weighted_orthogonal_loss": 0.014061889611184597
    },
    {
      "classification_loss": 0.644622802734375,
      "epoch": 3.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14066772162914276,
      "orthogonal_weight": 0.1,
      "step": 1046,
      "total_loss": 0.658689558506012,
      "weighted_orthogonal_loss": 0.014066772535443306
    },
    {
      "classification_loss": 0.698952853679657,
      "epoch": 3.4327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14068932831287384,
      "orthogonal_weight": 0.1,
      "step": 1047,
      "total_loss": 0.7130218148231506,
      "weighted_orthogonal_loss": 0.014068933203816414
    },
    {
      "classification_loss": 0.6921736001968384,
      "epoch": 3.4360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406911313533783,
      "orthogonal_weight": 0.1,
      "step": 1048,
      "total_loss": 0.7062427401542664,
      "weighted_orthogonal_loss": 0.014069112949073315
    },
    {
      "classification_loss": 0.7155394554138184,
      "epoch": 3.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14067214727401733,
      "orthogonal_weight": 0.1,
      "step": 1049,
      "total_loss": 0.7296066880226135,
      "weighted_orthogonal_loss": 0.014067214913666248
    },
    {
      "classification_loss": 0.6380400061607361,
      "epoch": 3.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14062225818634033,
      "orthogonal_weight": 0.1,
      "step": 1050,
      "total_loss": 0.6521022319793701,
      "weighted_orthogonal_loss": 0.014062225818634033
    },
    {
      "classification_loss": 0.6662687659263611,
      "epoch": 3.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1406167596578598,
      "orthogonal_weight": 0.1,
      "step": 1051,
      "total_loss": 0.6803304553031921,
      "weighted_orthogonal_loss": 0.01406167633831501
    },
    {
      "classification_loss": 0.6437544822692871,
      "epoch": 3.4491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14057175815105438,
      "orthogonal_weight": 0.1,
      "step": 1052,
      "total_loss": 0.6578116416931152,
      "weighted_orthogonal_loss": 0.014057176187634468
    },
    {
      "classification_loss": 0.6608327627182007,
      "epoch": 3.4524590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14049115777015686,
      "orthogonal_weight": 0.1,
      "step": 1053,
      "total_loss": 0.6748818755149841,
      "weighted_orthogonal_loss": 0.014049115590751171
    },
    {
      "classification_loss": 0.6575770974159241,
      "epoch": 3.455737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14046122133731842,
      "orthogonal_weight": 0.1,
      "step": 1054,
      "total_loss": 0.6716232299804688,
      "weighted_orthogonal_loss": 0.014046122319996357
    },
    {
      "classification_loss": 0.6264941096305847,
      "epoch": 3.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14040954411029816,
      "orthogonal_weight": 0.1,
      "step": 1055,
      "total_loss": 0.6405350565910339,
      "weighted_orthogonal_loss": 0.014040954411029816
    },
    {
      "classification_loss": 0.661169171333313,
      "epoch": 3.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14024801552295685,
      "orthogonal_weight": 0.1,
      "step": 1056,
      "total_loss": 0.6751939654350281,
      "weighted_orthogonal_loss": 0.014024801552295685
    },
    {
      "classification_loss": 0.7046919465065002,
      "epoch": 3.4655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.139944389462471,
      "orthogonal_weight": 0.1,
      "step": 1057,
      "total_loss": 0.7186864018440247,
      "weighted_orthogonal_loss": 0.013994439505040646
    },
    {
      "classification_loss": 0.6627988815307617,
      "epoch": 3.4688524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1394421011209488,
      "orthogonal_weight": 0.1,
      "step": 1058,
      "total_loss": 0.6767430901527405,
      "weighted_orthogonal_loss": 0.013944210484623909
    },
    {
      "classification_loss": 0.6677634119987488,
      "epoch": 3.4721311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1390584409236908,
      "orthogonal_weight": 0.1,
      "step": 1059,
      "total_loss": 0.6816692352294922,
      "weighted_orthogonal_loss": 0.013905844651162624
    },
    {
      "classification_loss": 0.6419862508773804,
      "epoch": 3.4754098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13869120180606842,
      "orthogonal_weight": 0.1,
      "step": 1060,
      "total_loss": 0.6558553576469421,
      "weighted_orthogonal_loss": 0.013869120739400387
    },
    {
      "classification_loss": 0.623318076133728,
      "epoch": 3.4786885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13835744559764862,
      "orthogonal_weight": 0.1,
      "step": 1061,
      "total_loss": 0.6371538043022156,
      "weighted_orthogonal_loss": 0.013835744932293892
    },
    {
      "classification_loss": 0.6046179533004761,
      "epoch": 3.4819672131147543,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13805921375751495,
      "orthogonal_weight": 0.1,
      "step": 1062,
      "total_loss": 0.6184238791465759,
      "weighted_orthogonal_loss": 0.01380592118948698
    },
    {
      "classification_loss": 0.6640592813491821,
      "epoch": 3.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1377640962600708,
      "orthogonal_weight": 0.1,
      "step": 1063,
      "total_loss": 0.6778357028961182,
      "weighted_orthogonal_loss": 0.013776409439742565
    },
    {
      "classification_loss": 0.6753458380699158,
      "epoch": 3.4885245901639346,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13745616376399994,
      "orthogonal_weight": 0.1,
      "step": 1064,
      "total_loss": 0.6890914440155029,
      "weighted_orthogonal_loss": 0.013745616190135479
    },
    {
      "classification_loss": 0.6732324361801147,
      "epoch": 3.4918032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13713431358337402,
      "orthogonal_weight": 0.1,
      "step": 1065,
      "total_loss": 0.6869458556175232,
      "weighted_orthogonal_loss": 0.013713431544601917
    },
    {
      "classification_loss": 0.7454939484596252,
      "epoch": 3.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1368984878063202,
      "orthogonal_weight": 0.1,
      "step": 1066,
      "total_loss": 0.7591838240623474,
      "weighted_orthogonal_loss": 0.013689848594367504
    },
    {
      "classification_loss": 0.7292442321777344,
      "epoch": 3.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1367209106683731,
      "orthogonal_weight": 0.1,
      "step": 1067,
      "total_loss": 0.7429163455963135,
      "weighted_orthogonal_loss": 0.01367209106683731
    },
    {
      "classification_loss": 0.6427954435348511,
      "epoch": 3.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13658328354358673,
      "orthogonal_weight": 0.1,
      "step": 1068,
      "total_loss": 0.6564537882804871,
      "weighted_orthogonal_loss": 0.013658328913152218
    },
    {
      "classification_loss": 0.6954324841499329,
      "epoch": 3.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13624919950962067,
      "orthogonal_weight": 0.1,
      "step": 1069,
      "total_loss": 0.7090573906898499,
      "weighted_orthogonal_loss": 0.013624920509755611
    },
    {
      "classification_loss": 0.6397826671600342,
      "epoch": 3.5081967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13598784804344177,
      "orthogonal_weight": 0.1,
      "step": 1070,
      "total_loss": 0.6533814668655396,
      "weighted_orthogonal_loss": 0.013598784804344177
    },
    {
      "classification_loss": 0.6373751163482666,
      "epoch": 3.5114754098360654,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1355248987674713,
      "orthogonal_weight": 0.1,
      "step": 1071,
      "total_loss": 0.6509276032447815,
      "weighted_orthogonal_loss": 0.013552489690482616
    },
    {
      "classification_loss": 0.6698706150054932,
      "epoch": 3.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13518650829792023,
      "orthogonal_weight": 0.1,
      "step": 1072,
      "total_loss": 0.6833892464637756,
      "weighted_orthogonal_loss": 0.013518651016056538
    },
    {
      "classification_loss": 0.6284856200218201,
      "epoch": 3.5180327868852457,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1349257081747055,
      "orthogonal_weight": 0.1,
      "step": 1073,
      "total_loss": 0.6419782042503357,
      "weighted_orthogonal_loss": 0.01349257118999958
    },
    {
      "classification_loss": 0.6300276517868042,
      "epoch": 3.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1347011923789978,
      "orthogonal_weight": 0.1,
      "step": 1074,
      "total_loss": 0.6434977650642395,
      "weighted_orthogonal_loss": 0.013470119796693325
    },
    {
      "classification_loss": 0.6360009908676147,
      "epoch": 3.5245901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13459265232086182,
      "orthogonal_weight": 0.1,
      "step": 1075,
      "total_loss": 0.6494602560997009,
      "weighted_orthogonal_loss": 0.013459265232086182
    },
    {
      "classification_loss": 0.6513693332672119,
      "epoch": 3.5278688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13449428975582123,
      "orthogonal_weight": 0.1,
      "step": 1076,
      "total_loss": 0.6648187637329102,
      "weighted_orthogonal_loss": 0.013449429534375668
    },
    {
      "classification_loss": 0.6503164172172546,
      "epoch": 3.5311475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13424637913703918,
      "orthogonal_weight": 0.1,
      "step": 1077,
      "total_loss": 0.6637410521507263,
      "weighted_orthogonal_loss": 0.013424637727439404
    },
    {
      "classification_loss": 0.6753547787666321,
      "epoch": 3.5344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13405142724514008,
      "orthogonal_weight": 0.1,
      "step": 1078,
      "total_loss": 0.6887599229812622,
      "weighted_orthogonal_loss": 0.013405143283307552
    },
    {
      "classification_loss": 0.6091670989990234,
      "epoch": 3.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1339167058467865,
      "orthogonal_weight": 0.1,
      "step": 1079,
      "total_loss": 0.6225587725639343,
      "weighted_orthogonal_loss": 0.013391670770943165
    },
    {
      "classification_loss": 0.7048548460006714,
      "epoch": 3.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13381361961364746,
      "orthogonal_weight": 0.1,
      "step": 1080,
      "total_loss": 0.7182362079620361,
      "weighted_orthogonal_loss": 0.013381361961364746
    },
    {
      "classification_loss": 0.6308206915855408,
      "epoch": 3.544262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13366027176380157,
      "orthogonal_weight": 0.1,
      "step": 1081,
      "total_loss": 0.6441867351531982,
      "weighted_orthogonal_loss": 0.013366027735173702
    },
    {
      "classification_loss": 0.6477453708648682,
      "epoch": 3.5475409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13349053263664246,
      "orthogonal_weight": 0.1,
      "step": 1082,
      "total_loss": 0.6610944271087646,
      "weighted_orthogonal_loss": 0.01334905344992876
    },
    {
      "classification_loss": 0.6862356066703796,
      "epoch": 3.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13335376977920532,
      "orthogonal_weight": 0.1,
      "step": 1083,
      "total_loss": 0.6995710134506226,
      "weighted_orthogonal_loss": 0.013335376977920532
    },
    {
      "classification_loss": 0.6451468467712402,
      "epoch": 3.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13320183753967285,
      "orthogonal_weight": 0.1,
      "step": 1084,
      "total_loss": 0.6584670543670654,
      "weighted_orthogonal_loss": 0.01332018431276083
    },
    {
      "classification_loss": 0.6948952674865723,
      "epoch": 3.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331050544977188,
      "orthogonal_weight": 0.1,
      "step": 1085,
      "total_loss": 0.7082057595252991,
      "weighted_orthogonal_loss": 0.013310506008565426
    },
    {
      "classification_loss": 0.66086745262146,
      "epoch": 3.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133036807179451,
      "orthogonal_weight": 0.1,
      "step": 1086,
      "total_loss": 0.6741711497306824,
      "weighted_orthogonal_loss": 0.013303681276738644
    },
    {
      "classification_loss": 0.7043195962905884,
      "epoch": 3.5639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13307826220989227,
      "orthogonal_weight": 0.1,
      "step": 1087,
      "total_loss": 0.7176274061203003,
      "weighted_orthogonal_loss": 0.013307826593518257
    },
    {
      "classification_loss": 0.7047708034515381,
      "epoch": 3.5672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13312439620494843,
      "orthogonal_weight": 0.1,
      "step": 1088,
      "total_loss": 0.7180832624435425,
      "weighted_orthogonal_loss": 0.013312439434230328
    },
    {
      "classification_loss": 0.6805914044380188,
      "epoch": 3.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1331978738307953,
      "orthogonal_weight": 0.1,
      "step": 1089,
      "total_loss": 0.6939111948013306,
      "weighted_orthogonal_loss": 0.013319787569344044
    },
    {
      "classification_loss": 0.6832306981086731,
      "epoch": 3.5737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.133308544754982,
      "orthogonal_weight": 0.1,
      "step": 1090,
      "total_loss": 0.6965615749359131,
      "weighted_orthogonal_loss": 0.0133308544754982
    },
    {
      "classification_loss": 0.610625684261322,
      "epoch": 3.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13341939449310303,
      "orthogonal_weight": 0.1,
      "step": 1091,
      "total_loss": 0.6239676475524902,
      "weighted_orthogonal_loss": 0.013341940008103848
    },
    {
      "classification_loss": 0.6034817695617676,
      "epoch": 3.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1334773302078247,
      "orthogonal_weight": 0.1,
      "step": 1092,
      "total_loss": 0.616829514503479,
      "weighted_orthogonal_loss": 0.013347732834517956
    },
    {
      "classification_loss": 0.6689616441726685,
      "epoch": 3.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13350063562393188,
      "orthogonal_weight": 0.1,
      "step": 1093,
      "total_loss": 0.6823117136955261,
      "weighted_orthogonal_loss": 0.013350063934922218
    },
    {
      "classification_loss": 0.7294720411300659,
      "epoch": 3.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13353581726551056,
      "orthogonal_weight": 0.1,
      "step": 1094,
      "total_loss": 0.7428256273269653,
      "weighted_orthogonal_loss": 0.013353581540286541
    },
    {
      "classification_loss": 0.6182592511177063,
      "epoch": 3.5901639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1336051970720291,
      "orthogonal_weight": 0.1,
      "step": 1095,
      "total_loss": 0.6316197514533997,
      "weighted_orthogonal_loss": 0.013360519893467426
    },
    {
      "classification_loss": 0.7230610251426697,
      "epoch": 3.5934426229508194,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13376644253730774,
      "orthogonal_weight": 0.1,
      "step": 1096,
      "total_loss": 0.7364376783370972,
      "weighted_orthogonal_loss": 0.013376644812524319
    },
    {
      "classification_loss": 0.6612522602081299,
      "epoch": 3.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13387420773506165,
      "orthogonal_weight": 0.1,
      "step": 1097,
      "total_loss": 0.6746397018432617,
      "weighted_orthogonal_loss": 0.013387421146035194
    },
    {
      "classification_loss": 0.655811071395874,
      "epoch": 3.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13390295207500458,
      "orthogonal_weight": 0.1,
      "step": 1098,
      "total_loss": 0.6692013740539551,
      "weighted_orthogonal_loss": 0.013390295207500458
    },
    {
      "classification_loss": 0.6410961747169495,
      "epoch": 3.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1341472715139389,
      "orthogonal_weight": 0.1,
      "step": 1099,
      "total_loss": 0.6545109152793884,
      "weighted_orthogonal_loss": 0.01341472752392292
    },
    {
      "epoch": 3.6065573770491803,
      "grad_norm": 13.20907974243164,
      "learning_rate": 0.0001667,
      "loss": 0.6748,
      "step": 1100
    },
    {
      "classification_loss": 0.6573832035064697,
      "epoch": 3.6065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1343528777360916,
      "orthogonal_weight": 0.1,
      "step": 1100,
      "total_loss": 0.6708185076713562,
      "weighted_orthogonal_loss": 0.013435288332402706
    },
    {
      "classification_loss": 0.6767249703407288,
      "epoch": 3.6098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.134543776512146,
      "orthogonal_weight": 0.1,
      "step": 1101,
      "total_loss": 0.6901793479919434,
      "weighted_orthogonal_loss": 0.0134543776512146
    },
    {
      "classification_loss": 0.6665173172950745,
      "epoch": 3.6131147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13478223979473114,
      "orthogonal_weight": 0.1,
      "step": 1102,
      "total_loss": 0.6799955368041992,
      "weighted_orthogonal_loss": 0.013478224165737629
    },
    {
      "classification_loss": 0.6837193369865417,
      "epoch": 3.6163934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13505098223686218,
      "orthogonal_weight": 0.1,
      "step": 1103,
      "total_loss": 0.6972244381904602,
      "weighted_orthogonal_loss": 0.013505098409950733
    },
    {
      "classification_loss": 0.6715741753578186,
      "epoch": 3.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13534145057201385,
      "orthogonal_weight": 0.1,
      "step": 1104,
      "total_loss": 0.6851083040237427,
      "weighted_orthogonal_loss": 0.013534145429730415
    },
    {
      "classification_loss": 0.6374362111091614,
      "epoch": 3.6229508196721314,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13564014434814453,
      "orthogonal_weight": 0.1,
      "step": 1105,
      "total_loss": 0.6510002017021179,
      "weighted_orthogonal_loss": 0.013564014807343483
    },
    {
      "classification_loss": 0.7000793218612671,
      "epoch": 3.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13588595390319824,
      "orthogonal_weight": 0.1,
      "step": 1106,
      "total_loss": 0.7136679291725159,
      "weighted_orthogonal_loss": 0.01358859520405531
    },
    {
      "classification_loss": 0.6718406677246094,
      "epoch": 3.6295081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359843760728836,
      "orthogonal_weight": 0.1,
      "step": 1107,
      "total_loss": 0.6854391098022461,
      "weighted_orthogonal_loss": 0.013598437421023846
    },
    {
      "classification_loss": 0.673287034034729,
      "epoch": 3.6327868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13607965409755707,
      "orthogonal_weight": 0.1,
      "step": 1108,
      "total_loss": 0.6868950128555298,
      "weighted_orthogonal_loss": 0.013607965782284737
    },
    {
      "classification_loss": 0.6718699932098389,
      "epoch": 3.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13619600236415863,
      "orthogonal_weight": 0.1,
      "step": 1109,
      "total_loss": 0.6854895949363708,
      "weighted_orthogonal_loss": 0.013619600795209408
    },
    {
      "classification_loss": 0.7264377474784851,
      "epoch": 3.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13633882999420166,
      "orthogonal_weight": 0.1,
      "step": 1110,
      "total_loss": 0.7400716543197632,
      "weighted_orthogonal_loss": 0.01363388355821371
    },
    {
      "classification_loss": 0.6495891213417053,
      "epoch": 3.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13645419478416443,
      "orthogonal_weight": 0.1,
      "step": 1111,
      "total_loss": 0.663234531879425,
      "weighted_orthogonal_loss": 0.013645419850945473
    },
    {
      "classification_loss": 0.6735225915908813,
      "epoch": 3.6459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13637585937976837,
      "orthogonal_weight": 0.1,
      "step": 1112,
      "total_loss": 0.6871601939201355,
      "weighted_orthogonal_loss": 0.013637586496770382
    },
    {
      "classification_loss": 0.6120544672012329,
      "epoch": 3.6491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13635879755020142,
      "orthogonal_weight": 0.1,
      "step": 1113,
      "total_loss": 0.6256903409957886,
      "weighted_orthogonal_loss": 0.013635880313813686
    },
    {
      "classification_loss": 0.5798734426498413,
      "epoch": 3.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13628356158733368,
      "orthogonal_weight": 0.1,
      "step": 1114,
      "total_loss": 0.5935018062591553,
      "weighted_orthogonal_loss": 0.013628356158733368
    },
    {
      "classification_loss": 0.6670145988464355,
      "epoch": 3.6557377049180326,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1361827701330185,
      "orthogonal_weight": 0.1,
      "step": 1115,
      "total_loss": 0.6806328892707825,
      "weighted_orthogonal_loss": 0.01361827738583088
    },
    {
      "classification_loss": 0.7154414057731628,
      "epoch": 3.6590163934426227,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13605324923992157,
      "orthogonal_weight": 0.1,
      "step": 1116,
      "total_loss": 0.7290467023849487,
      "weighted_orthogonal_loss": 0.013605325482785702
    },
    {
      "classification_loss": 0.6279730200767517,
      "epoch": 3.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1360112875699997,
      "orthogonal_weight": 0.1,
      "step": 1117,
      "total_loss": 0.6415741443634033,
      "weighted_orthogonal_loss": 0.013601128943264484
    },
    {
      "classification_loss": 0.6271092891693115,
      "epoch": 3.6655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13600051403045654,
      "orthogonal_weight": 0.1,
      "step": 1118,
      "total_loss": 0.6407093405723572,
      "weighted_orthogonal_loss": 0.013600051403045654
    },
    {
      "classification_loss": 0.6206109523773193,
      "epoch": 3.6688524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13580192625522614,
      "orthogonal_weight": 0.1,
      "step": 1119,
      "total_loss": 0.6341911554336548,
      "weighted_orthogonal_loss": 0.013580192811787128
    },
    {
      "classification_loss": 0.6442127823829651,
      "epoch": 3.6721311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13573332130908966,
      "orthogonal_weight": 0.1,
      "step": 1120,
      "total_loss": 0.6577861309051514,
      "weighted_orthogonal_loss": 0.01357333268970251
    },
    {
      "classification_loss": 0.6872836351394653,
      "epoch": 3.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13572095334529877,
      "orthogonal_weight": 0.1,
      "step": 1121,
      "total_loss": 0.7008557319641113,
      "weighted_orthogonal_loss": 0.013572095893323421
    },
    {
      "classification_loss": 0.6601961255073547,
      "epoch": 3.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13574911653995514,
      "orthogonal_weight": 0.1,
      "step": 1122,
      "total_loss": 0.6737710237503052,
      "weighted_orthogonal_loss": 0.013574912212789059
    },
    {
      "classification_loss": 0.6360697746276855,
      "epoch": 3.681967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13579542934894562,
      "orthogonal_weight": 0.1,
      "step": 1123,
      "total_loss": 0.6496493220329285,
      "weighted_orthogonal_loss": 0.013579542748630047
    },
    {
      "classification_loss": 0.6564205884933472,
      "epoch": 3.685245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13587452471256256,
      "orthogonal_weight": 0.1,
      "step": 1124,
      "total_loss": 0.6700080633163452,
      "weighted_orthogonal_loss": 0.013587452471256256
    },
    {
      "classification_loss": 0.5845149755477905,
      "epoch": 3.6885245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1359485238790512,
      "orthogonal_weight": 0.1,
      "step": 1125,
      "total_loss": 0.5981098413467407,
      "weighted_orthogonal_loss": 0.01359485276043415
    },
    {
      "classification_loss": 0.6543288826942444,
      "epoch": 3.6918032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13599172234535217,
      "orthogonal_weight": 0.1,
      "step": 1126,
      "total_loss": 0.6679280400276184,
      "weighted_orthogonal_loss": 0.013599172234535217
    },
    {
      "classification_loss": 0.6420698761940002,
      "epoch": 3.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602621853351593,
      "orthogonal_weight": 0.1,
      "step": 1127,
      "total_loss": 0.6556724905967712,
      "weighted_orthogonal_loss": 0.013602621853351593
    },
    {
      "classification_loss": 0.6504448652267456,
      "epoch": 3.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13604165613651276,
      "orthogonal_weight": 0.1,
      "step": 1128,
      "total_loss": 0.6640490293502808,
      "weighted_orthogonal_loss": 0.013604165986180305
    },
    {
      "classification_loss": 0.6465320587158203,
      "epoch": 3.7016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13590271770954132,
      "orthogonal_weight": 0.1,
      "step": 1129,
      "total_loss": 0.6601223349571228,
      "weighted_orthogonal_loss": 0.013590271584689617
    },
    {
      "classification_loss": 0.6491751670837402,
      "epoch": 3.7049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13579149544239044,
      "orthogonal_weight": 0.1,
      "step": 1130,
      "total_loss": 0.6627542972564697,
      "weighted_orthogonal_loss": 0.013579149730503559
    },
    {
      "classification_loss": 0.6443161368370056,
      "epoch": 3.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13569776713848114,
      "orthogonal_weight": 0.1,
      "step": 1131,
      "total_loss": 0.6578859090805054,
      "weighted_orthogonal_loss": 0.013569776900112629
    },
    {
      "classification_loss": 0.6967812776565552,
      "epoch": 3.7114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13561394810676575,
      "orthogonal_weight": 0.1,
      "step": 1132,
      "total_loss": 0.7103426456451416,
      "weighted_orthogonal_loss": 0.01356139499694109
    },
    {
      "classification_loss": 0.6292265057563782,
      "epoch": 3.7147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13549144566059113,
      "orthogonal_weight": 0.1,
      "step": 1133,
      "total_loss": 0.6427756547927856,
      "weighted_orthogonal_loss": 0.013549144379794598
    },
    {
      "classification_loss": 0.6852863430976868,
      "epoch": 3.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1353592872619629,
      "orthogonal_weight": 0.1,
      "step": 1134,
      "total_loss": 0.6988222599029541,
      "weighted_orthogonal_loss": 0.013535928912460804
    },
    {
      "classification_loss": 0.6099441647529602,
      "epoch": 3.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13541704416275024,
      "orthogonal_weight": 0.1,
      "step": 1135,
      "total_loss": 0.6234858632087708,
      "weighted_orthogonal_loss": 0.01354170497506857
    },
    {
      "classification_loss": 0.6371187567710876,
      "epoch": 3.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13549621403217316,
      "orthogonal_weight": 0.1,
      "step": 1136,
      "total_loss": 0.6506683826446533,
      "weighted_orthogonal_loss": 0.0135496212169528
    },
    {
      "classification_loss": 0.7192364931106567,
      "epoch": 3.7278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356373131275177,
      "orthogonal_weight": 0.1,
      "step": 1137,
      "total_loss": 0.7328002452850342,
      "weighted_orthogonal_loss": 0.0135637316852808
    },
    {
      "classification_loss": 0.6303168535232544,
      "epoch": 3.7311475409836063,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13568250834941864,
      "orthogonal_weight": 0.1,
      "step": 1138,
      "total_loss": 0.64388507604599,
      "weighted_orthogonal_loss": 0.013568251393735409
    },
    {
      "classification_loss": 0.6387798190116882,
      "epoch": 3.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13578414916992188,
      "orthogonal_weight": 0.1,
      "step": 1139,
      "total_loss": 0.6523582339286804,
      "weighted_orthogonal_loss": 0.013578414916992188
    },
    {
      "classification_loss": 0.7232140898704529,
      "epoch": 3.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13591501116752625,
      "orthogonal_weight": 0.1,
      "step": 1140,
      "total_loss": 0.7368056178092957,
      "weighted_orthogonal_loss": 0.01359150093048811
    },
    {
      "classification_loss": 0.6516124606132507,
      "epoch": 3.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13586480915546417,
      "orthogonal_weight": 0.1,
      "step": 1141,
      "total_loss": 0.6651989221572876,
      "weighted_orthogonal_loss": 0.013586481101810932
    },
    {
      "classification_loss": 0.6324297785758972,
      "epoch": 3.7442622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13585777580738068,
      "orthogonal_weight": 0.1,
      "step": 1142,
      "total_loss": 0.6460155844688416,
      "weighted_orthogonal_loss": 0.013585777953267097
    },
    {
      "classification_loss": 0.638968825340271,
      "epoch": 3.7475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13582883775234222,
      "orthogonal_weight": 0.1,
      "step": 1143,
      "total_loss": 0.6525517106056213,
      "weighted_orthogonal_loss": 0.013582884334027767
    },
    {
      "classification_loss": 0.620896577835083,
      "epoch": 3.7508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571304082870483,
      "orthogonal_weight": 0.1,
      "step": 1144,
      "total_loss": 0.6344678997993469,
      "weighted_orthogonal_loss": 0.013571304269134998
    },
    {
      "classification_loss": 0.6436833143234253,
      "epoch": 3.7540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13570846617221832,
      "orthogonal_weight": 0.1,
      "step": 1145,
      "total_loss": 0.657254159450531,
      "weighted_orthogonal_loss": 0.013570846989750862
    },
    {
      "classification_loss": 0.6697224378585815,
      "epoch": 3.7573770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571257889270782,
      "orthogonal_weight": 0.1,
      "step": 1146,
      "total_loss": 0.6832937002182007,
      "weighted_orthogonal_loss": 0.013571257703006268
    },
    {
      "classification_loss": 0.651709794998169,
      "epoch": 3.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13570040464401245,
      "orthogonal_weight": 0.1,
      "step": 1147,
      "total_loss": 0.6652798652648926,
      "weighted_orthogonal_loss": 0.013570040464401245
    },
    {
      "classification_loss": 0.6801875233650208,
      "epoch": 3.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1356620341539383,
      "orthogonal_weight": 0.1,
      "step": 1148,
      "total_loss": 0.693753719329834,
      "weighted_orthogonal_loss": 0.01356620341539383
    },
    {
      "classification_loss": 0.701396107673645,
      "epoch": 3.7672131147540986,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13571710884571075,
      "orthogonal_weight": 0.1,
      "step": 1149,
      "total_loss": 0.7149678468704224,
      "weighted_orthogonal_loss": 0.013571711257100105
    },
    {
      "classification_loss": 0.6747404932975769,
      "epoch": 3.7704918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13574758172035217,
      "orthogonal_weight": 0.1,
      "step": 1150,
      "total_loss": 0.6883152723312378,
      "weighted_orthogonal_loss": 0.013574758544564247
    },
    {
      "classification_loss": 0.5912339687347412,
      "epoch": 3.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13581113517284393,
      "orthogonal_weight": 0.1,
      "step": 1151,
      "total_loss": 0.6048150658607483,
      "weighted_orthogonal_loss": 0.013581113889813423
    },
    {
      "classification_loss": 0.7060593366622925,
      "epoch": 3.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13586468994617462,
      "orthogonal_weight": 0.1,
      "step": 1152,
      "total_loss": 0.7196457982063293,
      "weighted_orthogonal_loss": 0.013586468994617462
    },
    {
      "classification_loss": 0.7130844593048096,
      "epoch": 3.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13584184646606445,
      "orthogonal_weight": 0.1,
      "step": 1153,
      "total_loss": 0.726668655872345,
      "weighted_orthogonal_loss": 0.01358418446034193
    },
    {
      "classification_loss": 0.6732979416847229,
      "epoch": 3.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1358024775981903,
      "orthogonal_weight": 0.1,
      "step": 1154,
      "total_loss": 0.6868782043457031,
      "weighted_orthogonal_loss": 0.01358024775981903
    },
    {
      "classification_loss": 0.6442986130714417,
      "epoch": 3.7868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13575243949890137,
      "orthogonal_weight": 0.1,
      "step": 1155,
      "total_loss": 0.6578738689422607,
      "weighted_orthogonal_loss": 0.013575243763625622
    },
    {
      "classification_loss": 0.6774621605873108,
      "epoch": 3.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13568925857543945,
      "orthogonal_weight": 0.1,
      "step": 1156,
      "total_loss": 0.6910310983657837,
      "weighted_orthogonal_loss": 0.01356892567127943
    },
    {
      "classification_loss": 0.6321474313735962,
      "epoch": 3.7934426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13566358387470245,
      "orthogonal_weight": 0.1,
      "step": 1157,
      "total_loss": 0.6457138061523438,
      "weighted_orthogonal_loss": 0.01356635894626379
    },
    {
      "classification_loss": 0.6974793076515198,
      "epoch": 3.7967213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13565750420093536,
      "orthogonal_weight": 0.1,
      "step": 1158,
      "total_loss": 0.7110450863838196,
      "weighted_orthogonal_loss": 0.013565750792622566
    },
    {
      "classification_loss": 0.6796658039093018,
      "epoch": 3.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1357065737247467,
      "orthogonal_weight": 0.1,
      "step": 1159,
      "total_loss": 0.6932364702224731,
      "weighted_orthogonal_loss": 0.013570657931268215
    },
    {
      "classification_loss": 0.6480728387832642,
      "epoch": 3.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13577890396118164,
      "orthogonal_weight": 0.1,
      "step": 1160,
      "total_loss": 0.6616507172584534,
      "weighted_orthogonal_loss": 0.013577890582382679
    },
    {
      "classification_loss": 0.6389527916908264,
      "epoch": 3.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1358620673418045,
      "orthogonal_weight": 0.1,
      "step": 1161,
      "total_loss": 0.6525390148162842,
      "weighted_orthogonal_loss": 0.013586207292973995
    },
    {
      "classification_loss": 0.6434983611106873,
      "epoch": 3.8098360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13593216240406036,
      "orthogonal_weight": 0.1,
      "step": 1162,
      "total_loss": 0.6570915579795837,
      "weighted_orthogonal_loss": 0.013593216426670551
    },
    {
      "classification_loss": 0.6289777755737305,
      "epoch": 3.8131147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13602657616138458,
      "orthogonal_weight": 0.1,
      "step": 1163,
      "total_loss": 0.6425804495811462,
      "weighted_orthogonal_loss": 0.013602658174932003
    },
    {
      "classification_loss": 0.7664755582809448,
      "epoch": 3.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13617844879627228,
      "orthogonal_weight": 0.1,
      "step": 1164,
      "total_loss": 0.7800934314727783,
      "weighted_orthogonal_loss": 0.013617845252156258
    },
    {
      "classification_loss": 0.6059860587120056,
      "epoch": 3.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13631077110767365,
      "orthogonal_weight": 0.1,
      "step": 1165,
      "total_loss": 0.6196171641349792,
      "weighted_orthogonal_loss": 0.013631077483296394
    },
    {
      "classification_loss": 0.7044680714607239,
      "epoch": 3.822950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1364843249320984,
      "orthogonal_weight": 0.1,
      "step": 1166,
      "total_loss": 0.7181165218353271,
      "weighted_orthogonal_loss": 0.013648432679474354
    },
    {
      "classification_loss": 0.667748749256134,
      "epoch": 3.8262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13665732741355896,
      "orthogonal_weight": 0.1,
      "step": 1167,
      "total_loss": 0.6814144849777222,
      "weighted_orthogonal_loss": 0.013665732927620411
    },
    {
      "classification_loss": 0.6642449498176575,
      "epoch": 3.8295081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13710170984268188,
      "orthogonal_weight": 0.1,
      "step": 1168,
      "total_loss": 0.677955150604248,
      "weighted_orthogonal_loss": 0.013710170984268188
    },
    {
      "classification_loss": 0.6726369857788086,
      "epoch": 3.8327868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13763301074504852,
      "orthogonal_weight": 0.1,
      "step": 1169,
      "total_loss": 0.686400294303894,
      "weighted_orthogonal_loss": 0.013763301074504852
    },
    {
      "classification_loss": 0.6195160150527954,
      "epoch": 3.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13818565011024475,
      "orthogonal_weight": 0.1,
      "step": 1170,
      "total_loss": 0.6333345770835876,
      "weighted_orthogonal_loss": 0.01381856482475996
    },
    {
      "classification_loss": 0.6794761419296265,
      "epoch": 3.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1388096809387207,
      "orthogonal_weight": 0.1,
      "step": 1171,
      "total_loss": 0.6933571100234985,
      "weighted_orthogonal_loss": 0.01388096809387207
    },
    {
      "classification_loss": 0.6557620763778687,
      "epoch": 3.8426229508196723,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.13945572078227997,
      "orthogonal_weight": 0.1,
      "step": 1172,
      "total_loss": 0.6697076559066772,
      "weighted_orthogonal_loss": 0.013945572078227997
    },
    {
      "classification_loss": 0.6691179871559143,
      "epoch": 3.8459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14021828770637512,
      "orthogonal_weight": 0.1,
      "step": 1173,
      "total_loss": 0.6831398010253906,
      "weighted_orthogonal_loss": 0.014021828770637512
    },
    {
      "classification_loss": 0.643416702747345,
      "epoch": 3.8491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14081786572933197,
      "orthogonal_weight": 0.1,
      "step": 1174,
      "total_loss": 0.6574984788894653,
      "weighted_orthogonal_loss": 0.014081786386668682
    },
    {
      "classification_loss": 0.6381855607032776,
      "epoch": 3.8524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1413557231426239,
      "orthogonal_weight": 0.1,
      "step": 1175,
      "total_loss": 0.6523211598396301,
      "weighted_orthogonal_loss": 0.014135572127997875
    },
    {
      "classification_loss": 0.6832534670829773,
      "epoch": 3.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14188320934772491,
      "orthogonal_weight": 0.1,
      "step": 1176,
      "total_loss": 0.697441816329956,
      "weighted_orthogonal_loss": 0.014188321307301521
    },
    {
      "classification_loss": 0.6793800592422485,
      "epoch": 3.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14234744012355804,
      "orthogonal_weight": 0.1,
      "step": 1177,
      "total_loss": 0.6936147809028625,
      "weighted_orthogonal_loss": 0.014234744012355804
    },
    {
      "classification_loss": 0.6708959341049194,
      "epoch": 3.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1427045613527298,
      "orthogonal_weight": 0.1,
      "step": 1178,
      "total_loss": 0.6851664185523987,
      "weighted_orthogonal_loss": 0.01427045650780201
    },
    {
      "classification_loss": 0.6557443737983704,
      "epoch": 3.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1429564356803894,
      "orthogonal_weight": 0.1,
      "step": 1179,
      "total_loss": 0.6700400114059448,
      "weighted_orthogonal_loss": 0.014295644126832485
    },
    {
      "classification_loss": 0.6602676510810852,
      "epoch": 3.8688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14312979578971863,
      "orthogonal_weight": 0.1,
      "step": 1180,
      "total_loss": 0.6745806336402893,
      "weighted_orthogonal_loss": 0.014312979765236378
    },
    {
      "classification_loss": 0.6912751793861389,
      "epoch": 3.8721311475409834,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14321592450141907,
      "orthogonal_weight": 0.1,
      "step": 1181,
      "total_loss": 0.7055967450141907,
      "weighted_orthogonal_loss": 0.014321592636406422
    },
    {
      "classification_loss": 0.6797897815704346,
      "epoch": 3.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14326177537441254,
      "orthogonal_weight": 0.1,
      "step": 1182,
      "total_loss": 0.694115936756134,
      "weighted_orthogonal_loss": 0.014326177537441254
    },
    {
      "classification_loss": 0.696867823600769,
      "epoch": 3.8786885245901637,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14333269000053406,
      "orthogonal_weight": 0.1,
      "step": 1183,
      "total_loss": 0.7112010717391968,
      "weighted_orthogonal_loss": 0.01433326955884695
    },
    {
      "classification_loss": 0.6462583541870117,
      "epoch": 3.8819672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14342178404331207,
      "orthogonal_weight": 0.1,
      "step": 1184,
      "total_loss": 0.6606005430221558,
      "weighted_orthogonal_loss": 0.014342178590595722
    },
    {
      "classification_loss": 0.6421692967414856,
      "epoch": 3.8852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14323391020298004,
      "orthogonal_weight": 0.1,
      "step": 1185,
      "total_loss": 0.6564927101135254,
      "weighted_orthogonal_loss": 0.014323391020298004
    },
    {
      "classification_loss": 0.6656418442726135,
      "epoch": 3.8885245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14308853447437286,
      "orthogonal_weight": 0.1,
      "step": 1186,
      "total_loss": 0.6799507141113281,
      "weighted_orthogonal_loss": 0.014308854006230831
    },
    {
      "classification_loss": 0.7137123942375183,
      "epoch": 3.8918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1430402249097824,
      "orthogonal_weight": 0.1,
      "step": 1187,
      "total_loss": 0.7280164361000061,
      "weighted_orthogonal_loss": 0.014304022304713726
    },
    {
      "classification_loss": 0.6863676309585571,
      "epoch": 3.8950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1431010514497757,
      "orthogonal_weight": 0.1,
      "step": 1188,
      "total_loss": 0.700677752494812,
      "weighted_orthogonal_loss": 0.014310105703771114
    },
    {
      "classification_loss": 0.6358268857002258,
      "epoch": 3.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14316299557685852,
      "orthogonal_weight": 0.1,
      "step": 1189,
      "total_loss": 0.6501432061195374,
      "weighted_orthogonal_loss": 0.014316299930214882
    },
    {
      "classification_loss": 0.6349239945411682,
      "epoch": 3.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14332760870456696,
      "orthogonal_weight": 0.1,
      "step": 1190,
      "total_loss": 0.6492567658424377,
      "weighted_orthogonal_loss": 0.01433276105672121
    },
    {
      "classification_loss": 0.661159873008728,
      "epoch": 3.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14347046613693237,
      "orthogonal_weight": 0.1,
      "step": 1191,
      "total_loss": 0.6755069494247437,
      "weighted_orthogonal_loss": 0.014347046613693237
    },
    {
      "classification_loss": 0.6388386487960815,
      "epoch": 3.9081967213114757,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14363664388656616,
      "orthogonal_weight": 0.1,
      "step": 1192,
      "total_loss": 0.6532022953033447,
      "weighted_orthogonal_loss": 0.014363664202392101
    },
    {
      "classification_loss": 0.6526786088943481,
      "epoch": 3.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14376747608184814,
      "orthogonal_weight": 0.1,
      "step": 1193,
      "total_loss": 0.6670553684234619,
      "weighted_orthogonal_loss": 0.0143767474219203
    },
    {
      "classification_loss": 0.6432422399520874,
      "epoch": 3.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14383944869041443,
      "orthogonal_weight": 0.1,
      "step": 1194,
      "total_loss": 0.657626211643219,
      "weighted_orthogonal_loss": 0.014383944682776928
    },
    {
      "classification_loss": 0.620512843132019,
      "epoch": 3.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14393053948879242,
      "orthogonal_weight": 0.1,
      "step": 1195,
      "total_loss": 0.6349058747291565,
      "weighted_orthogonal_loss": 0.014393053948879242
    },
    {
      "classification_loss": 0.6214340925216675,
      "epoch": 3.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1439485102891922,
      "orthogonal_weight": 0.1,
      "step": 1196,
      "total_loss": 0.635828971862793,
      "weighted_orthogonal_loss": 0.01439485140144825
    },
    {
      "classification_loss": 0.6851385831832886,
      "epoch": 3.9245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14387039840221405,
      "orthogonal_weight": 0.1,
      "step": 1197,
      "total_loss": 0.6995255947113037,
      "weighted_orthogonal_loss": 0.01438704039901495
    },
    {
      "classification_loss": 0.6931920647621155,
      "epoch": 3.9278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14371395111083984,
      "orthogonal_weight": 0.1,
      "step": 1198,
      "total_loss": 0.7075634598731995,
      "weighted_orthogonal_loss": 0.014371395111083984
    },
    {
      "classification_loss": 0.6738126873970032,
      "epoch": 3.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14360886812210083,
      "orthogonal_weight": 0.1,
      "step": 1199,
      "total_loss": 0.6881735920906067,
      "weighted_orthogonal_loss": 0.014360886998474598
    },
    {
      "epoch": 3.9344262295081966,
      "grad_norm": 9.023319244384766,
      "learning_rate": 0.00016336666666666666,
      "loss": 0.6737,
      "step": 1200
    },
    {
      "classification_loss": 0.6568059325218201,
      "epoch": 3.9344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14359577000141144,
      "orthogonal_weight": 0.1,
      "step": 1200,
      "total_loss": 0.6711655259132385,
      "weighted_orthogonal_loss": 0.014359577558934689
    },
    {
      "classification_loss": 0.6197920441627502,
      "epoch": 3.9377049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.143479585647583,
      "orthogonal_weight": 0.1,
      "step": 1201,
      "total_loss": 0.6341400146484375,
      "weighted_orthogonal_loss": 0.014347958378493786
    },
    {
      "classification_loss": 0.6463282704353333,
      "epoch": 3.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14343112707138062,
      "orthogonal_weight": 0.1,
      "step": 1202,
      "total_loss": 0.6606713533401489,
      "weighted_orthogonal_loss": 0.014343112707138062
    },
    {
      "classification_loss": 0.6682015061378479,
      "epoch": 3.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14338889718055725,
      "orthogonal_weight": 0.1,
      "step": 1203,
      "total_loss": 0.6825404167175293,
      "weighted_orthogonal_loss": 0.014338890090584755
    },
    {
      "classification_loss": 0.6624066233634949,
      "epoch": 3.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14332863688468933,
      "orthogonal_weight": 0.1,
      "step": 1204,
      "total_loss": 0.676739513874054,
      "weighted_orthogonal_loss": 0.014332863502204418
    },
    {
      "classification_loss": 0.7047706842422485,
      "epoch": 3.9508196721311473,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14331728219985962,
      "orthogonal_weight": 0.1,
      "step": 1205,
      "total_loss": 0.7191023826599121,
      "weighted_orthogonal_loss": 0.014331728219985962
    },
    {
      "classification_loss": 0.650040864944458,
      "epoch": 3.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14340408146381378,
      "orthogonal_weight": 0.1,
      "step": 1206,
      "total_loss": 0.6643812656402588,
      "weighted_orthogonal_loss": 0.014340408146381378
    },
    {
      "classification_loss": 0.6800167560577393,
      "epoch": 3.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14376865327358246,
      "orthogonal_weight": 0.1,
      "step": 1207,
      "total_loss": 0.6943936347961426,
      "weighted_orthogonal_loss": 0.014376865699887276
    },
    {
      "classification_loss": 0.6714193820953369,
      "epoch": 3.960655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14416615664958954,
      "orthogonal_weight": 0.1,
      "step": 1208,
      "total_loss": 0.6858360171318054,
      "weighted_orthogonal_loss": 0.014416615478694439
    },
    {
      "classification_loss": 0.6638668775558472,
      "epoch": 3.963934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1445968598127365,
      "orthogonal_weight": 0.1,
      "step": 1209,
      "total_loss": 0.6783265471458435,
      "weighted_orthogonal_loss": 0.014459686353802681
    },
    {
      "classification_loss": 0.6774362325668335,
      "epoch": 3.9672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.145023912191391,
      "orthogonal_weight": 0.1,
      "step": 1210,
      "total_loss": 0.6919386386871338,
      "weighted_orthogonal_loss": 0.014502391219139099
    },
    {
      "classification_loss": 0.6705294847488403,
      "epoch": 3.9704918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1455083042383194,
      "orthogonal_weight": 0.1,
      "step": 1211,
      "total_loss": 0.6850802898406982,
      "weighted_orthogonal_loss": 0.014550830237567425
    },
    {
      "classification_loss": 0.6215112209320068,
      "epoch": 3.9737704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14592385292053223,
      "orthogonal_weight": 0.1,
      "step": 1212,
      "total_loss": 0.636103630065918,
      "weighted_orthogonal_loss": 0.014592385850846767
    },
    {
      "classification_loss": 0.7313960790634155,
      "epoch": 3.9770491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14625851809978485,
      "orthogonal_weight": 0.1,
      "step": 1213,
      "total_loss": 0.7460219264030457,
      "weighted_orthogonal_loss": 0.014625851996243
    },
    {
      "classification_loss": 0.6844817399978638,
      "epoch": 3.9803278688524593,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1465526670217514,
      "orthogonal_weight": 0.1,
      "step": 1214,
      "total_loss": 0.6991370320320129,
      "weighted_orthogonal_loss": 0.014655266888439655
    },
    {
      "classification_loss": 0.5839546918869019,
      "epoch": 3.9836065573770494,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14685574173927307,
      "orthogonal_weight": 0.1,
      "step": 1215,
      "total_loss": 0.5986402630805969,
      "weighted_orthogonal_loss": 0.014685573987662792
    },
    {
      "classification_loss": 0.7238724827766418,
      "epoch": 3.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1470704823732376,
      "orthogonal_weight": 0.1,
      "step": 1216,
      "total_loss": 0.738579511642456,
      "weighted_orthogonal_loss": 0.014707048423588276
    },
    {
      "classification_loss": 0.6547387838363647,
      "epoch": 3.9901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14725153148174286,
      "orthogonal_weight": 0.1,
      "step": 1217,
      "total_loss": 0.6694639325141907,
      "weighted_orthogonal_loss": 0.0147251533344388
    },
    {
      "classification_loss": 0.6478078365325928,
      "epoch": 3.9934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14736725389957428,
      "orthogonal_weight": 0.1,
      "step": 1218,
      "total_loss": 0.6625445485115051,
      "weighted_orthogonal_loss": 0.014736725948750973
    },
    {
      "classification_loss": 0.6531200408935547,
      "epoch": 3.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14757369458675385,
      "orthogonal_weight": 0.1,
      "step": 1219,
      "total_loss": 0.6678774356842041,
      "weighted_orthogonal_loss": 0.0147573696449399
    },
    {
      "classification_loss": 0.6901799440383911,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7049605250358582,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6988438367843628,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7136244177818298,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6838398575782776,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6986204385757446,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6856641173362732,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7004446983337402,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6917171478271484,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7064977288246155,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6830896735191345,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6978702545166016,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.677711546421051,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6924921274185181,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.6995068192481995,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.7142874002456665,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.537,
      "eval_f1": 0.6125523012552301,
      "eval_loss": 0.7033432126045227,
      "eval_precision": 0.6398601398601399,
      "eval_recall": 0.5874799357945425,
      "eval_runtime": 6.1244,
      "eval_samples_per_second": 163.281,
      "eval_steps_per_second": 1.306,
      "step": 1220
    },
    {
      "classification_loss": 0.5998678803443909,
      "epoch": 4.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1478058397769928,
      "orthogonal_weight": 0.1,
      "step": 1220,
      "total_loss": 0.6146484613418579,
      "weighted_orthogonal_loss": 0.014780583791434765
    },
    {
      "classification_loss": 0.5744839310646057,
      "epoch": 4.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14812417328357697,
      "orthogonal_weight": 0.1,
      "step": 1221,
      "total_loss": 0.5892963409423828,
      "weighted_orthogonal_loss": 0.014812417328357697
    },
    {
      "classification_loss": 0.6563880443572998,
      "epoch": 4.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14836406707763672,
      "orthogonal_weight": 0.1,
      "step": 1222,
      "total_loss": 0.6712244749069214,
      "weighted_orthogonal_loss": 0.014836407266557217
    },
    {
      "classification_loss": 0.6887218952178955,
      "epoch": 4.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14849045872688293,
      "orthogonal_weight": 0.1,
      "step": 1223,
      "total_loss": 0.7035709619522095,
      "weighted_orthogonal_loss": 0.014849046245217323
    },
    {
      "classification_loss": 0.6399936676025391,
      "epoch": 4.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14858755469322205,
      "orthogonal_weight": 0.1,
      "step": 1224,
      "total_loss": 0.6548524498939514,
      "weighted_orthogonal_loss": 0.01485875528305769
    },
    {
      "classification_loss": 0.6597457528114319,
      "epoch": 4.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.148751363158226,
      "orthogonal_weight": 0.1,
      "step": 1225,
      "total_loss": 0.6746208667755127,
      "weighted_orthogonal_loss": 0.014875136315822601
    },
    {
      "classification_loss": 0.6436300277709961,
      "epoch": 4.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14880771934986115,
      "orthogonal_weight": 0.1,
      "step": 1226,
      "total_loss": 0.6585108041763306,
      "weighted_orthogonal_loss": 0.0148807717487216
    },
    {
      "classification_loss": 0.6938890814781189,
      "epoch": 4.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14870227873325348,
      "orthogonal_weight": 0.1,
      "step": 1227,
      "total_loss": 0.7087593078613281,
      "weighted_orthogonal_loss": 0.014870228245854378
    },
    {
      "classification_loss": 0.7007462382316589,
      "epoch": 4.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14871327579021454,
      "orthogonal_weight": 0.1,
      "step": 1228,
      "total_loss": 0.7156175374984741,
      "weighted_orthogonal_loss": 0.014871328137814999
    },
    {
      "classification_loss": 0.6771746873855591,
      "epoch": 4.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14873336255550385,
      "orthogonal_weight": 0.1,
      "step": 1229,
      "total_loss": 0.6920480132102966,
      "weighted_orthogonal_loss": 0.01487333606928587
    },
    {
      "classification_loss": 0.6486720442771912,
      "epoch": 4.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14881618320941925,
      "orthogonal_weight": 0.1,
      "step": 1230,
      "total_loss": 0.6635536551475525,
      "weighted_orthogonal_loss": 0.014881618320941925
    },
    {
      "classification_loss": 0.6872904896736145,
      "epoch": 4.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1488446444272995,
      "orthogonal_weight": 0.1,
      "step": 1231,
      "total_loss": 0.702174961566925,
      "weighted_orthogonal_loss": 0.01488446444272995
    },
    {
      "classification_loss": 0.6683569550514221,
      "epoch": 4.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1491578370332718,
      "orthogonal_weight": 0.1,
      "step": 1232,
      "total_loss": 0.6832727193832397,
      "weighted_orthogonal_loss": 0.014915783889591694
    },
    {
      "classification_loss": 0.6014142036437988,
      "epoch": 4.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14954817295074463,
      "orthogonal_weight": 0.1,
      "step": 1233,
      "total_loss": 0.6163690090179443,
      "weighted_orthogonal_loss": 0.014954817481338978
    },
    {
      "classification_loss": 0.6910938620567322,
      "epoch": 4.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499718874692917,
      "orthogonal_weight": 0.1,
      "step": 1234,
      "total_loss": 0.706091046333313,
      "weighted_orthogonal_loss": 0.014997188933193684
    },
    {
      "classification_loss": 0.6739314198493958,
      "epoch": 4.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15036045014858246,
      "orthogonal_weight": 0.1,
      "step": 1235,
      "total_loss": 0.6889674663543701,
      "weighted_orthogonal_loss": 0.01503604557365179
    },
    {
      "classification_loss": 0.6825968623161316,
      "epoch": 4.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15064339339733124,
      "orthogonal_weight": 0.1,
      "step": 1236,
      "total_loss": 0.6976612210273743,
      "weighted_orthogonal_loss": 0.015064339153468609
    },
    {
      "classification_loss": 0.6502292156219482,
      "epoch": 4.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15082746744155884,
      "orthogonal_weight": 0.1,
      "step": 1237,
      "total_loss": 0.6653119325637817,
      "weighted_orthogonal_loss": 0.015082746744155884
    },
    {
      "classification_loss": 0.6951660513877869,
      "epoch": 4.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15098287165164948,
      "orthogonal_weight": 0.1,
      "step": 1238,
      "total_loss": 0.7102643251419067,
      "weighted_orthogonal_loss": 0.015098287723958492
    },
    {
      "classification_loss": 0.6744672060012817,
      "epoch": 4.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15116387605667114,
      "orthogonal_weight": 0.1,
      "step": 1239,
      "total_loss": 0.6895835995674133,
      "weighted_orthogonal_loss": 0.015116387978196144
    },
    {
      "classification_loss": 0.69454425573349,
      "epoch": 4.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15129996836185455,
      "orthogonal_weight": 0.1,
      "step": 1240,
      "total_loss": 0.7096742391586304,
      "weighted_orthogonal_loss": 0.015129997394979
    },
    {
      "classification_loss": 0.6708171963691711,
      "epoch": 4.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15139420330524445,
      "orthogonal_weight": 0.1,
      "step": 1241,
      "total_loss": 0.685956597328186,
      "weighted_orthogonal_loss": 0.01513942051678896
    },
    {
      "classification_loss": 0.6314129829406738,
      "epoch": 4.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15150143206119537,
      "orthogonal_weight": 0.1,
      "step": 1242,
      "total_loss": 0.6465631127357483,
      "weighted_orthogonal_loss": 0.015150143764913082
    },
    {
      "classification_loss": 0.6691681742668152,
      "epoch": 4.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1516183465719223,
      "orthogonal_weight": 0.1,
      "step": 1243,
      "total_loss": 0.6843299865722656,
      "weighted_orthogonal_loss": 0.01516183465719223
    },
    {
      "classification_loss": 0.6510121822357178,
      "epoch": 4.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15167678892612457,
      "orthogonal_weight": 0.1,
      "step": 1244,
      "total_loss": 0.6661798357963562,
      "weighted_orthogonal_loss": 0.015167678706347942
    },
    {
      "classification_loss": 0.6018947958946228,
      "epoch": 4.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1515996754169464,
      "orthogonal_weight": 0.1,
      "step": 1245,
      "total_loss": 0.6170547604560852,
      "weighted_orthogonal_loss": 0.015159967355430126
    },
    {
      "classification_loss": 0.6763842105865479,
      "epoch": 4.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15163086354732513,
      "orthogonal_weight": 0.1,
      "step": 1246,
      "total_loss": 0.6915472745895386,
      "weighted_orthogonal_loss": 0.015163086354732513
    },
    {
      "classification_loss": 0.6242621541023254,
      "epoch": 4.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15158367156982422,
      "orthogonal_weight": 0.1,
      "step": 1247,
      "total_loss": 0.6394205093383789,
      "weighted_orthogonal_loss": 0.015158367343246937
    },
    {
      "classification_loss": 0.6323555707931519,
      "epoch": 4.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15144841372966766,
      "orthogonal_weight": 0.1,
      "step": 1248,
      "total_loss": 0.6475003957748413,
      "weighted_orthogonal_loss": 0.015144841745495796
    },
    {
      "classification_loss": 0.6955482363700867,
      "epoch": 4.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1510457545518875,
      "orthogonal_weight": 0.1,
      "step": 1249,
      "total_loss": 0.7106528282165527,
      "weighted_orthogonal_loss": 0.015104576013982296
    },
    {
      "classification_loss": 0.6417747735977173,
      "epoch": 4.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15075929462909698,
      "orthogonal_weight": 0.1,
      "step": 1250,
      "total_loss": 0.6568506956100464,
      "weighted_orthogonal_loss": 0.015075929462909698
    },
    {
      "classification_loss": 0.7069224715232849,
      "epoch": 4.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15055452287197113,
      "orthogonal_weight": 0.1,
      "step": 1251,
      "total_loss": 0.721977949142456,
      "weighted_orthogonal_loss": 0.015055452473461628
    },
    {
      "classification_loss": 0.7394046783447266,
      "epoch": 4.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15041060745716095,
      "orthogonal_weight": 0.1,
      "step": 1252,
      "total_loss": 0.7544457316398621,
      "weighted_orthogonal_loss": 0.015041060745716095
    },
    {
      "classification_loss": 0.6147974133491516,
      "epoch": 4.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.150356724858284,
      "orthogonal_weight": 0.1,
      "step": 1253,
      "total_loss": 0.6298331022262573,
      "weighted_orthogonal_loss": 0.015035673044621944
    },
    {
      "classification_loss": 0.7141934037208557,
      "epoch": 4.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1503552347421646,
      "orthogonal_weight": 0.1,
      "step": 1254,
      "total_loss": 0.7292289137840271,
      "weighted_orthogonal_loss": 0.015035524033010006
    },
    {
      "classification_loss": 0.6828650236129761,
      "epoch": 4.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15039359033107758,
      "orthogonal_weight": 0.1,
      "step": 1255,
      "total_loss": 0.6979044079780579,
      "weighted_orthogonal_loss": 0.015039359219372272
    },
    {
      "classification_loss": 0.6909834146499634,
      "epoch": 4.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15004296600818634,
      "orthogonal_weight": 0.1,
      "step": 1256,
      "total_loss": 0.7059876918792725,
      "weighted_orthogonal_loss": 0.015004296787083149
    },
    {
      "classification_loss": 0.701716959476471,
      "epoch": 4.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14970572292804718,
      "orthogonal_weight": 0.1,
      "step": 1257,
      "total_loss": 0.7166875600814819,
      "weighted_orthogonal_loss": 0.014970572665333748
    },
    {
      "classification_loss": 0.6459123492240906,
      "epoch": 4.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494712382555008,
      "orthogonal_weight": 0.1,
      "step": 1258,
      "total_loss": 0.6608594655990601,
      "weighted_orthogonal_loss": 0.01494712382555008
    },
    {
      "classification_loss": 0.628384530544281,
      "epoch": 4.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14938963949680328,
      "orthogonal_weight": 0.1,
      "step": 1259,
      "total_loss": 0.6433234810829163,
      "weighted_orthogonal_loss": 0.014938964508473873
    },
    {
      "classification_loss": 0.6845828890800476,
      "epoch": 4.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14944036304950714,
      "orthogonal_weight": 0.1,
      "step": 1260,
      "total_loss": 0.6995269060134888,
      "weighted_orthogonal_loss": 0.014944036491215229
    },
    {
      "classification_loss": 0.6271683573722839,
      "epoch": 4.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14961321651935577,
      "orthogonal_weight": 0.1,
      "step": 1261,
      "total_loss": 0.64212965965271,
      "weighted_orthogonal_loss": 0.014961321838200092
    },
    {
      "classification_loss": 0.7355252504348755,
      "epoch": 4.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15011920034885406,
      "orthogonal_weight": 0.1,
      "step": 1262,
      "total_loss": 0.7505371570587158,
      "weighted_orthogonal_loss": 0.015011920593678951
    },
    {
      "classification_loss": 0.6089141964912415,
      "epoch": 4.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15065829455852509,
      "orthogonal_weight": 0.1,
      "step": 1263,
      "total_loss": 0.6239800453186035,
      "weighted_orthogonal_loss": 0.015065829269587994
    },
    {
      "classification_loss": 0.6953480839729309,
      "epoch": 4.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15127679705619812,
      "orthogonal_weight": 0.1,
      "step": 1264,
      "total_loss": 0.710475742816925,
      "weighted_orthogonal_loss": 0.015127680264413357
    },
    {
      "classification_loss": 0.628812313079834,
      "epoch": 4.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1519385576248169,
      "orthogonal_weight": 0.1,
      "step": 1265,
      "total_loss": 0.6440061926841736,
      "weighted_orthogonal_loss": 0.015193856321275234
    },
    {
      "classification_loss": 0.6963565349578857,
      "epoch": 4.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15260225534439087,
      "orthogonal_weight": 0.1,
      "step": 1266,
      "total_loss": 0.7116167545318604,
      "weighted_orthogonal_loss": 0.015260226093232632
    },
    {
      "classification_loss": 0.6388574838638306,
      "epoch": 4.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15316565334796906,
      "orthogonal_weight": 0.1,
      "step": 1267,
      "total_loss": 0.6541740298271179,
      "weighted_orthogonal_loss": 0.01531656552106142
    },
    {
      "classification_loss": 0.6182760000228882,
      "epoch": 4.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1536547690629959,
      "orthogonal_weight": 0.1,
      "step": 1268,
      "total_loss": 0.6336414813995361,
      "weighted_orthogonal_loss": 0.015365476720035076
    },
    {
      "classification_loss": 0.6476873159408569,
      "epoch": 4.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1541132777929306,
      "orthogonal_weight": 0.1,
      "step": 1269,
      "total_loss": 0.6630986332893372,
      "weighted_orthogonal_loss": 0.015411327593028545
    },
    {
      "classification_loss": 0.6950529217720032,
      "epoch": 4.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15419326722621918,
      "orthogonal_weight": 0.1,
      "step": 1270,
      "total_loss": 0.7104722261428833,
      "weighted_orthogonal_loss": 0.015419326722621918
    },
    {
      "classification_loss": 0.617751955986023,
      "epoch": 4.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15424981713294983,
      "orthogonal_weight": 0.1,
      "step": 1271,
      "total_loss": 0.6331769227981567,
      "weighted_orthogonal_loss": 0.015424981713294983
    },
    {
      "classification_loss": 0.6660133004188538,
      "epoch": 4.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15417590737342834,
      "orthogonal_weight": 0.1,
      "step": 1272,
      "total_loss": 0.6814308762550354,
      "weighted_orthogonal_loss": 0.015417590737342834
    },
    {
      "classification_loss": 0.6784980893135071,
      "epoch": 4.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15402743220329285,
      "orthogonal_weight": 0.1,
      "step": 1273,
      "total_loss": 0.6939008235931396,
      "weighted_orthogonal_loss": 0.015402743592858315
    },
    {
      "classification_loss": 0.6510933637619019,
      "epoch": 4.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1536777764558792,
      "orthogonal_weight": 0.1,
      "step": 1274,
      "total_loss": 0.666461169719696,
      "weighted_orthogonal_loss": 0.015367778018116951
    },
    {
      "classification_loss": 0.6181250810623169,
      "epoch": 4.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15338240563869476,
      "orthogonal_weight": 0.1,
      "step": 1275,
      "total_loss": 0.6334633231163025,
      "weighted_orthogonal_loss": 0.015338241122663021
    },
    {
      "classification_loss": 0.6804776191711426,
      "epoch": 4.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15296997129917145,
      "orthogonal_weight": 0.1,
      "step": 1276,
      "total_loss": 0.6957746148109436,
      "weighted_orthogonal_loss": 0.015296997502446175
    },
    {
      "classification_loss": 0.5984258055686951,
      "epoch": 4.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1522321105003357,
      "orthogonal_weight": 0.1,
      "step": 1277,
      "total_loss": 0.6136490106582642,
      "weighted_orthogonal_loss": 0.015223211608827114
    },
    {
      "classification_loss": 0.699318528175354,
      "epoch": 4.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15162400901317596,
      "orthogonal_weight": 0.1,
      "step": 1278,
      "total_loss": 0.7144809365272522,
      "weighted_orthogonal_loss": 0.015162400901317596
    },
    {
      "classification_loss": 0.6190447807312012,
      "epoch": 4.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15098650753498077,
      "orthogonal_weight": 0.1,
      "step": 1279,
      "total_loss": 0.6341434121131897,
      "weighted_orthogonal_loss": 0.015098650939762592
    },
    {
      "classification_loss": 0.6521959900856018,
      "epoch": 4.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1503978818655014,
      "orthogonal_weight": 0.1,
      "step": 1280,
      "total_loss": 0.667235791683197,
      "weighted_orthogonal_loss": 0.01503978855907917
    },
    {
      "classification_loss": 0.6549248695373535,
      "epoch": 4.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14990217983722687,
      "orthogonal_weight": 0.1,
      "step": 1281,
      "total_loss": 0.6699150800704956,
      "weighted_orthogonal_loss": 0.014990217983722687
    },
    {
      "classification_loss": 0.5899795889854431,
      "epoch": 4.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1496463268995285,
      "orthogonal_weight": 0.1,
      "step": 1282,
      "total_loss": 0.6049442291259766,
      "weighted_orthogonal_loss": 0.01496463268995285
    },
    {
      "classification_loss": 0.6372601389884949,
      "epoch": 4.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494617611169815,
      "orthogonal_weight": 0.1,
      "step": 1283,
      "total_loss": 0.652206301689148,
      "weighted_orthogonal_loss": 0.014946176670491695
    },
    {
      "classification_loss": 0.7110028862953186,
      "epoch": 4.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14926530420780182,
      "orthogonal_weight": 0.1,
      "step": 1284,
      "total_loss": 0.7259294390678406,
      "weighted_orthogonal_loss": 0.014926530420780182
    },
    {
      "classification_loss": 0.6565192341804504,
      "epoch": 4.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.14920873939990997,
      "orthogonal_weight": 0.1,
      "step": 1285,
      "total_loss": 0.6714401245117188,
      "weighted_orthogonal_loss": 0.014920874498784542
    },
    {
      "classification_loss": 0.6925484538078308,
      "epoch": 4.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1493033617734909,
      "orthogonal_weight": 0.1,
      "step": 1286,
      "total_loss": 0.7074787616729736,
      "weighted_orthogonal_loss": 0.014930336736142635
    },
    {
      "classification_loss": 0.6742262244224548,
      "epoch": 4.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1494809240102768,
      "orthogonal_weight": 0.1,
      "step": 1287,
      "total_loss": 0.6891742944717407,
      "weighted_orthogonal_loss": 0.01494809240102768
    },
    {
      "classification_loss": 0.5960389375686646,
      "epoch": 4.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1497172862291336,
      "orthogonal_weight": 0.1,
      "step": 1288,
      "total_loss": 0.6110106706619263,
      "weighted_orthogonal_loss": 0.014971728436648846
    },
    {
      "classification_loss": 0.6293666362762451,
      "epoch": 4.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1499769538640976,
      "orthogonal_weight": 0.1,
      "step": 1289,
      "total_loss": 0.6443643569946289,
      "weighted_orthogonal_loss": 0.014997695572674274
    },
    {
      "classification_loss": 0.6897199153900146,
      "epoch": 4.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.150308758020401,
      "orthogonal_weight": 0.1,
      "step": 1290,
      "total_loss": 0.7047507762908936,
      "weighted_orthogonal_loss": 0.0150308758020401
    },
    {
      "classification_loss": 0.6689807176589966,
      "epoch": 4.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15067143738269806,
      "orthogonal_weight": 0.1,
      "step": 1291,
      "total_loss": 0.6840478777885437,
      "weighted_orthogonal_loss": 0.01506714429706335
    },
    {
      "classification_loss": 0.661568820476532,
      "epoch": 4.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1510459929704666,
      "orthogonal_weight": 0.1,
      "step": 1292,
      "total_loss": 0.676673412322998,
      "weighted_orthogonal_loss": 0.015104599297046661
    },
    {
      "classification_loss": 0.5925696492195129,
      "epoch": 4.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15141704678535461,
      "orthogonal_weight": 0.1,
      "step": 1293,
      "total_loss": 0.6077113747596741,
      "weighted_orthogonal_loss": 0.015141705051064491
    },
    {
      "classification_loss": 0.6074570417404175,
      "epoch": 4.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1519877165555954,
      "orthogonal_weight": 0.1,
      "step": 1294,
      "total_loss": 0.6226558089256287,
      "weighted_orthogonal_loss": 0.015198771841824055
    },
    {
      "classification_loss": 0.6749505400657654,
      "epoch": 4.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15263134241104126,
      "orthogonal_weight": 0.1,
      "step": 1295,
      "total_loss": 0.690213680267334,
      "weighted_orthogonal_loss": 0.015263134613633156
    },
    {
      "classification_loss": 0.6499187350273132,
      "epoch": 4.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15321972966194153,
      "orthogonal_weight": 0.1,
      "step": 1296,
      "total_loss": 0.6652407050132751,
      "weighted_orthogonal_loss": 0.015321972779929638
    },
    {
      "classification_loss": 0.6757082343101501,
      "epoch": 4.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1537681370973587,
      "orthogonal_weight": 0.1,
      "step": 1297,
      "total_loss": 0.6910850405693054,
      "weighted_orthogonal_loss": 0.01537681370973587
    },
    {
      "classification_loss": 0.6590983867645264,
      "epoch": 4.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15427306294441223,
      "orthogonal_weight": 0.1,
      "step": 1298,
      "total_loss": 0.6745256781578064,
      "weighted_orthogonal_loss": 0.015427306294441223
    },
    {
      "classification_loss": 0.669353187084198,
      "epoch": 4.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1547136902809143,
      "orthogonal_weight": 0.1,
      "step": 1299,
      "total_loss": 0.6848245859146118,
      "weighted_orthogonal_loss": 0.01547136902809143
    },
    {
      "epoch": 4.262295081967213,
      "grad_norm": 9.857251167297363,
      "learning_rate": 0.00016003333333333334,
      "loss": 0.6744,
      "step": 1300
    },
    {
      "classification_loss": 0.7176656126976013,
      "epoch": 4.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15501612424850464,
      "orthogonal_weight": 0.1,
      "step": 1300,
      "total_loss": 0.7331672310829163,
      "weighted_orthogonal_loss": 0.015501612797379494
    },
    {
      "classification_loss": 0.6172221302986145,
      "epoch": 4.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15522465109825134,
      "orthogonal_weight": 0.1,
      "step": 1301,
      "total_loss": 0.6327446103096008,
      "weighted_orthogonal_loss": 0.015522465109825134
    },
    {
      "classification_loss": 0.6642361283302307,
      "epoch": 4.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15538029372692108,
      "orthogonal_weight": 0.1,
      "step": 1302,
      "total_loss": 0.6797741651535034,
      "weighted_orthogonal_loss": 0.015538029372692108
    },
    {
      "classification_loss": 0.6805179715156555,
      "epoch": 4.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15544399619102478,
      "orthogonal_weight": 0.1,
      "step": 1303,
      "total_loss": 0.6960623860359192,
      "weighted_orthogonal_loss": 0.015544399619102478
    },
    {
      "classification_loss": 0.6574046015739441,
      "epoch": 4.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555679738521576,
      "orthogonal_weight": 0.1,
      "step": 1304,
      "total_loss": 0.672961413860321,
      "weighted_orthogonal_loss": 0.01555679738521576
    },
    {
      "classification_loss": 0.640835702419281,
      "epoch": 4.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555391401052475,
      "orthogonal_weight": 0.1,
      "step": 1305,
      "total_loss": 0.656389594078064,
      "weighted_orthogonal_loss": 0.01555391401052475
    },
    {
      "classification_loss": 0.6682197451591492,
      "epoch": 4.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15540090203285217,
      "orthogonal_weight": 0.1,
      "step": 1306,
      "total_loss": 0.6837598085403442,
      "weighted_orthogonal_loss": 0.015540090389549732
    },
    {
      "classification_loss": 0.6420177221298218,
      "epoch": 4.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15527980029582977,
      "orthogonal_weight": 0.1,
      "step": 1307,
      "total_loss": 0.6575456857681274,
      "weighted_orthogonal_loss": 0.015527980402112007
    },
    {
      "classification_loss": 0.64291912317276,
      "epoch": 4.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.155020073056221,
      "orthogonal_weight": 0.1,
      "step": 1308,
      "total_loss": 0.6584211587905884,
      "weighted_orthogonal_loss": 0.01550200767815113
    },
    {
      "classification_loss": 0.6178680658340454,
      "epoch": 4.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15493318438529968,
      "orthogonal_weight": 0.1,
      "step": 1309,
      "total_loss": 0.6333613991737366,
      "weighted_orthogonal_loss": 0.015493318438529968
    },
    {
      "classification_loss": 0.6741845607757568,
      "epoch": 4.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15490126609802246,
      "orthogonal_weight": 0.1,
      "step": 1310,
      "total_loss": 0.6896746754646301,
      "weighted_orthogonal_loss": 0.015490126796066761
    },
    {
      "classification_loss": 0.7258294224739075,
      "epoch": 4.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15488074719905853,
      "orthogonal_weight": 0.1,
      "step": 1311,
      "total_loss": 0.7413175106048584,
      "weighted_orthogonal_loss": 0.015488075092434883
    },
    {
      "classification_loss": 0.6443691849708557,
      "epoch": 4.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15500040352344513,
      "orthogonal_weight": 0.1,
      "step": 1312,
      "total_loss": 0.6598692536354065,
      "weighted_orthogonal_loss": 0.015500040724873543
    },
    {
      "classification_loss": 0.632379412651062,
      "epoch": 4.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15519212186336517,
      "orthogonal_weight": 0.1,
      "step": 1313,
      "total_loss": 0.6478986144065857,
      "weighted_orthogonal_loss": 0.015519212000072002
    },
    {
      "classification_loss": 0.6392847895622253,
      "epoch": 4.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15541958808898926,
      "orthogonal_weight": 0.1,
      "step": 1314,
      "total_loss": 0.6548267602920532,
      "weighted_orthogonal_loss": 0.01554195862263441
    },
    {
      "classification_loss": 0.6505799889564514,
      "epoch": 4.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15572042763233185,
      "orthogonal_weight": 0.1,
      "step": 1315,
      "total_loss": 0.6661520600318909,
      "weighted_orthogonal_loss": 0.015572043135762215
    },
    {
      "classification_loss": 0.5772559642791748,
      "epoch": 4.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15574856102466583,
      "orthogonal_weight": 0.1,
      "step": 1316,
      "total_loss": 0.5928308367729187,
      "weighted_orthogonal_loss": 0.015574856661260128
    },
    {
      "classification_loss": 0.6929086446762085,
      "epoch": 4.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1557340919971466,
      "orthogonal_weight": 0.1,
      "step": 1317,
      "total_loss": 0.708482027053833,
      "weighted_orthogonal_loss": 0.015573409385979176
    },
    {
      "classification_loss": 0.6335832476615906,
      "epoch": 4.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15581916272640228,
      "orthogonal_weight": 0.1,
      "step": 1318,
      "total_loss": 0.649165153503418,
      "weighted_orthogonal_loss": 0.015581916086375713
    },
    {
      "classification_loss": 0.686934769153595,
      "epoch": 4.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558832824230194,
      "orthogonal_weight": 0.1,
      "step": 1319,
      "total_loss": 0.7025231122970581,
      "weighted_orthogonal_loss": 0.015588328242301941
    },
    {
      "classification_loss": 0.6962559223175049,
      "epoch": 4.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558980941772461,
      "orthogonal_weight": 0.1,
      "step": 1320,
      "total_loss": 0.7118457555770874,
      "weighted_orthogonal_loss": 0.015589809976518154
    },
    {
      "classification_loss": 0.6666792631149292,
      "epoch": 4.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15588656067848206,
      "orthogonal_weight": 0.1,
      "step": 1321,
      "total_loss": 0.6822679042816162,
      "weighted_orthogonal_loss": 0.015588656067848206
    },
    {
      "classification_loss": 0.5904728770256042,
      "epoch": 4.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15601296722888947,
      "orthogonal_weight": 0.1,
      "step": 1322,
      "total_loss": 0.6060741543769836,
      "weighted_orthogonal_loss": 0.015601296909153461
    },
    {
      "classification_loss": 0.6241541504859924,
      "epoch": 4.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15641352534294128,
      "orthogonal_weight": 0.1,
      "step": 1323,
      "total_loss": 0.6397954821586609,
      "weighted_orthogonal_loss": 0.0156413521617651
    },
    {
      "classification_loss": 0.609052836894989,
      "epoch": 4.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1565762162208557,
      "orthogonal_weight": 0.1,
      "step": 1324,
      "total_loss": 0.6247104406356812,
      "weighted_orthogonal_loss": 0.01565762236714363
    },
    {
      "classification_loss": 0.6450024247169495,
      "epoch": 4.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1570163518190384,
      "orthogonal_weight": 0.1,
      "step": 1325,
      "total_loss": 0.6607040762901306,
      "weighted_orthogonal_loss": 0.01570163480937481
    },
    {
      "classification_loss": 0.6423370838165283,
      "epoch": 4.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1573300063610077,
      "orthogonal_weight": 0.1,
      "step": 1326,
      "total_loss": 0.6580700874328613,
      "weighted_orthogonal_loss": 0.01573300175368786
    },
    {
      "classification_loss": 0.6566990613937378,
      "epoch": 4.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15755172073841095,
      "orthogonal_weight": 0.1,
      "step": 1327,
      "total_loss": 0.6724542379379272,
      "weighted_orthogonal_loss": 0.015755172818899155
    },
    {
      "classification_loss": 0.6302844882011414,
      "epoch": 4.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15783733129501343,
      "orthogonal_weight": 0.1,
      "step": 1328,
      "total_loss": 0.6460682153701782,
      "weighted_orthogonal_loss": 0.015783732756972313
    },
    {
      "classification_loss": 0.664823055267334,
      "epoch": 4.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15817603468894958,
      "orthogonal_weight": 0.1,
      "step": 1329,
      "total_loss": 0.6806406378746033,
      "weighted_orthogonal_loss": 0.01581760309636593
    },
    {
      "classification_loss": 0.647558331489563,
      "epoch": 4.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15828891098499298,
      "orthogonal_weight": 0.1,
      "step": 1330,
      "total_loss": 0.6633872389793396,
      "weighted_orthogonal_loss": 0.015828890725970268
    },
    {
      "classification_loss": 0.6614573001861572,
      "epoch": 4.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15831232070922852,
      "orthogonal_weight": 0.1,
      "step": 1331,
      "total_loss": 0.6772885322570801,
      "weighted_orthogonal_loss": 0.01583123207092285
    },
    {
      "classification_loss": 0.6666790843009949,
      "epoch": 4.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15836839377880096,
      "orthogonal_weight": 0.1,
      "step": 1332,
      "total_loss": 0.6825159192085266,
      "weighted_orthogonal_loss": 0.015836840495467186
    },
    {
      "classification_loss": 0.5865113735198975,
      "epoch": 4.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1584608405828476,
      "orthogonal_weight": 0.1,
      "step": 1333,
      "total_loss": 0.6023574471473694,
      "weighted_orthogonal_loss": 0.01584608480334282
    },
    {
      "classification_loss": 0.6847401857376099,
      "epoch": 4.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15857471525669098,
      "orthogonal_weight": 0.1,
      "step": 1334,
      "total_loss": 0.7005976438522339,
      "weighted_orthogonal_loss": 0.015857471153140068
    },
    {
      "classification_loss": 0.6516042351722717,
      "epoch": 4.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15854449570178986,
      "orthogonal_weight": 0.1,
      "step": 1335,
      "total_loss": 0.667458713054657,
      "weighted_orthogonal_loss": 0.015854449942708015
    },
    {
      "classification_loss": 0.7242960929870605,
      "epoch": 4.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15861184895038605,
      "orthogonal_weight": 0.1,
      "step": 1336,
      "total_loss": 0.7401573061943054,
      "weighted_orthogonal_loss": 0.015861185267567635
    },
    {
      "classification_loss": 0.5812488198280334,
      "epoch": 4.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15877774357795715,
      "orthogonal_weight": 0.1,
      "step": 1337,
      "total_loss": 0.5971266031265259,
      "weighted_orthogonal_loss": 0.015877773985266685
    },
    {
      "classification_loss": 0.7263808846473694,
      "epoch": 4.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15899813175201416,
      "orthogonal_weight": 0.1,
      "step": 1338,
      "total_loss": 0.7422807216644287,
      "weighted_orthogonal_loss": 0.015899812802672386
    },
    {
      "classification_loss": 0.6536728739738464,
      "epoch": 4.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1591382473707199,
      "orthogonal_weight": 0.1,
      "step": 1339,
      "total_loss": 0.669586718082428,
      "weighted_orthogonal_loss": 0.01591382548213005
    },
    {
      "classification_loss": 0.6741515398025513,
      "epoch": 4.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1592869758605957,
      "orthogonal_weight": 0.1,
      "step": 1340,
      "total_loss": 0.6900802254676819,
      "weighted_orthogonal_loss": 0.01592869870364666
    },
    {
      "classification_loss": 0.6532382369041443,
      "epoch": 4.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594415307044983,
      "orthogonal_weight": 0.1,
      "step": 1341,
      "total_loss": 0.6691824197769165,
      "weighted_orthogonal_loss": 0.01594415307044983
    },
    {
      "classification_loss": 0.7189680933952332,
      "epoch": 4.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15960082411766052,
      "orthogonal_weight": 0.1,
      "step": 1342,
      "total_loss": 0.7349281907081604,
      "weighted_orthogonal_loss": 0.015960082411766052
    },
    {
      "classification_loss": 0.6550760865211487,
      "epoch": 4.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15972788631916046,
      "orthogonal_weight": 0.1,
      "step": 1343,
      "total_loss": 0.6710488796234131,
      "weighted_orthogonal_loss": 0.015972789376974106
    },
    {
      "classification_loss": 0.6827874183654785,
      "epoch": 4.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1598009616136551,
      "orthogonal_weight": 0.1,
      "step": 1344,
      "total_loss": 0.6987675428390503,
      "weighted_orthogonal_loss": 0.01598009653389454
    },
    {
      "classification_loss": 0.692090630531311,
      "epoch": 4.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15995624661445618,
      "orthogonal_weight": 0.1,
      "step": 1345,
      "total_loss": 0.7080862522125244,
      "weighted_orthogonal_loss": 0.015995625406503677
    },
    {
      "classification_loss": 0.6388406753540039,
      "epoch": 4.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005674004554749,
      "orthogonal_weight": 0.1,
      "step": 1346,
      "total_loss": 0.6548463702201843,
      "weighted_orthogonal_loss": 0.01600567437708378
    },
    {
      "classification_loss": 0.6915161609649658,
      "epoch": 4.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1604161113500595,
      "orthogonal_weight": 0.1,
      "step": 1347,
      "total_loss": 0.7075577974319458,
      "weighted_orthogonal_loss": 0.01604161225259304
    },
    {
      "classification_loss": 0.6578476428985596,
      "epoch": 4.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16071178019046783,
      "orthogonal_weight": 0.1,
      "step": 1348,
      "total_loss": 0.6739188432693481,
      "weighted_orthogonal_loss": 0.016071178019046783
    },
    {
      "classification_loss": 0.6550754308700562,
      "epoch": 4.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076290607452393,
      "orthogonal_weight": 0.1,
      "step": 1349,
      "total_loss": 0.6711516976356506,
      "weighted_orthogonal_loss": 0.016076290979981422
    },
    {
      "classification_loss": 0.5924491286277771,
      "epoch": 4.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16082051396369934,
      "orthogonal_weight": 0.1,
      "step": 1350,
      "total_loss": 0.6085311770439148,
      "weighted_orthogonal_loss": 0.016082052141427994
    },
    {
      "classification_loss": 0.6456282734870911,
      "epoch": 4.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16095948219299316,
      "orthogonal_weight": 0.1,
      "step": 1351,
      "total_loss": 0.6617242097854614,
      "weighted_orthogonal_loss": 0.016095949336886406
    },
    {
      "classification_loss": 0.6496489644050598,
      "epoch": 4.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16110442578792572,
      "orthogonal_weight": 0.1,
      "step": 1352,
      "total_loss": 0.6657593846321106,
      "weighted_orthogonal_loss": 0.016110442578792572
    },
    {
      "classification_loss": 0.674422562122345,
      "epoch": 4.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1611093282699585,
      "orthogonal_weight": 0.1,
      "step": 1353,
      "total_loss": 0.6905335187911987,
      "weighted_orthogonal_loss": 0.01611093245446682
    },
    {
      "classification_loss": 0.6574134826660156,
      "epoch": 4.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094215214252472,
      "orthogonal_weight": 0.1,
      "step": 1354,
      "total_loss": 0.6735076904296875,
      "weighted_orthogonal_loss": 0.016094215214252472
    },
    {
      "classification_loss": 0.6323578953742981,
      "epoch": 4.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606404334306717,
      "orthogonal_weight": 0.1,
      "step": 1355,
      "total_loss": 0.6484219431877136,
      "weighted_orthogonal_loss": 0.01606404408812523
    },
    {
      "classification_loss": 0.6334190964698792,
      "epoch": 4.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16009262204170227,
      "orthogonal_weight": 0.1,
      "step": 1356,
      "total_loss": 0.6494283676147461,
      "weighted_orthogonal_loss": 0.016009261831641197
    },
    {
      "classification_loss": 0.6198131442070007,
      "epoch": 4.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15969052910804749,
      "orthogonal_weight": 0.1,
      "step": 1357,
      "total_loss": 0.6357821822166443,
      "weighted_orthogonal_loss": 0.01596905291080475
    },
    {
      "classification_loss": 0.5997548699378967,
      "epoch": 4.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594022959470749,
      "orthogonal_weight": 0.1,
      "step": 1358,
      "total_loss": 0.6156951189041138,
      "weighted_orthogonal_loss": 0.01594023033976555
    },
    {
      "classification_loss": 0.5886200070381165,
      "epoch": 4.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15905924141407013,
      "orthogonal_weight": 0.1,
      "step": 1359,
      "total_loss": 0.6045259237289429,
      "weighted_orthogonal_loss": 0.015905924141407013
    },
    {
      "classification_loss": 0.6705406904220581,
      "epoch": 4.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15879598259925842,
      "orthogonal_weight": 0.1,
      "step": 1360,
      "total_loss": 0.6864202618598938,
      "weighted_orthogonal_loss": 0.015879599377512932
    },
    {
      "classification_loss": 0.6077595949172974,
      "epoch": 4.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15858164429664612,
      "orthogonal_weight": 0.1,
      "step": 1361,
      "total_loss": 0.6236177682876587,
      "weighted_orthogonal_loss": 0.015858164057135582
    },
    {
      "classification_loss": 0.636627733707428,
      "epoch": 4.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1584199219942093,
      "orthogonal_weight": 0.1,
      "step": 1362,
      "total_loss": 0.6524697542190552,
      "weighted_orthogonal_loss": 0.01584199257194996
    },
    {
      "classification_loss": 0.6654642224311829,
      "epoch": 4.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15824124217033386,
      "orthogonal_weight": 0.1,
      "step": 1363,
      "total_loss": 0.6812883615493774,
      "weighted_orthogonal_loss": 0.015824124217033386
    },
    {
      "classification_loss": 0.7129784226417542,
      "epoch": 4.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1581178903579712,
      "orthogonal_weight": 0.1,
      "step": 1364,
      "total_loss": 0.7287902235984802,
      "weighted_orthogonal_loss": 0.01581178978085518
    },
    {
      "classification_loss": 0.6561727523803711,
      "epoch": 4.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15797676146030426,
      "orthogonal_weight": 0.1,
      "step": 1365,
      "total_loss": 0.6719704270362854,
      "weighted_orthogonal_loss": 0.015797676518559456
    },
    {
      "classification_loss": 0.699998676776886,
      "epoch": 4.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1579168289899826,
      "orthogonal_weight": 0.1,
      "step": 1366,
      "total_loss": 0.715790331363678,
      "weighted_orthogonal_loss": 0.01579168252646923
    },
    {
      "classification_loss": 0.6373482346534729,
      "epoch": 4.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1578896939754486,
      "orthogonal_weight": 0.1,
      "step": 1367,
      "total_loss": 0.65313720703125,
      "weighted_orthogonal_loss": 0.01578897051513195
    },
    {
      "classification_loss": 0.6269160509109497,
      "epoch": 4.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15788573026657104,
      "orthogonal_weight": 0.1,
      "step": 1368,
      "total_loss": 0.6427046060562134,
      "weighted_orthogonal_loss": 0.015788573771715164
    },
    {
      "classification_loss": 0.683957040309906,
      "epoch": 4.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15791891515254974,
      "orthogonal_weight": 0.1,
      "step": 1369,
      "total_loss": 0.6997489333152771,
      "weighted_orthogonal_loss": 0.015791891142725945
    },
    {
      "classification_loss": 0.6025124788284302,
      "epoch": 4.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15794892609119415,
      "orthogonal_weight": 0.1,
      "step": 1370,
      "total_loss": 0.61830735206604,
      "weighted_orthogonal_loss": 0.015794893726706505
    },
    {
      "classification_loss": 0.6287629008293152,
      "epoch": 4.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15801112353801727,
      "orthogonal_weight": 0.1,
      "step": 1371,
      "total_loss": 0.6445640325546265,
      "weighted_orthogonal_loss": 0.015801113098859787
    },
    {
      "classification_loss": 0.6400355696678162,
      "epoch": 4.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15812402963638306,
      "orthogonal_weight": 0.1,
      "step": 1372,
      "total_loss": 0.65584796667099,
      "weighted_orthogonal_loss": 0.015812402591109276
    },
    {
      "classification_loss": 0.6318203806877136,
      "epoch": 4.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15762412548065186,
      "orthogonal_weight": 0.1,
      "step": 1373,
      "total_loss": 0.6475827693939209,
      "weighted_orthogonal_loss": 0.015762412920594215
    },
    {
      "classification_loss": 0.6169257164001465,
      "epoch": 4.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15706324577331543,
      "orthogonal_weight": 0.1,
      "step": 1374,
      "total_loss": 0.6326320171356201,
      "weighted_orthogonal_loss": 0.015706324949860573
    },
    {
      "classification_loss": 0.7025241851806641,
      "epoch": 4.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15661904215812683,
      "orthogonal_weight": 0.1,
      "step": 1375,
      "total_loss": 0.71818608045578,
      "weighted_orthogonal_loss": 0.015661904588341713
    },
    {
      "classification_loss": 0.6562328934669495,
      "epoch": 4.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15624818205833435,
      "orthogonal_weight": 0.1,
      "step": 1376,
      "total_loss": 0.6718577146530151,
      "weighted_orthogonal_loss": 0.01562481839209795
    },
    {
      "classification_loss": 0.6375946998596191,
      "epoch": 4.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15591634809970856,
      "orthogonal_weight": 0.1,
      "step": 1377,
      "total_loss": 0.6531863212585449,
      "weighted_orthogonal_loss": 0.0155916353687644
    },
    {
      "classification_loss": 0.6258719563484192,
      "epoch": 4.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1556696742773056,
      "orthogonal_weight": 0.1,
      "step": 1378,
      "total_loss": 0.641438901424408,
      "weighted_orthogonal_loss": 0.01556696742773056
    },
    {
      "classification_loss": 0.6302405595779419,
      "epoch": 4.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1553889811038971,
      "orthogonal_weight": 0.1,
      "step": 1379,
      "total_loss": 0.6457794308662415,
      "weighted_orthogonal_loss": 0.015538898296654224
    },
    {
      "classification_loss": 0.605266273021698,
      "epoch": 4.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1552104949951172,
      "orthogonal_weight": 0.1,
      "step": 1380,
      "total_loss": 0.6207873225212097,
      "weighted_orthogonal_loss": 0.015521049499511719
    },
    {
      "classification_loss": 0.6524943113327026,
      "epoch": 4.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15502388775348663,
      "orthogonal_weight": 0.1,
      "step": 1381,
      "total_loss": 0.6679967045783997,
      "weighted_orthogonal_loss": 0.015502388589084148
    },
    {
      "classification_loss": 0.6358174681663513,
      "epoch": 4.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15488122403621674,
      "orthogonal_weight": 0.1,
      "step": 1382,
      "total_loss": 0.651305615901947,
      "weighted_orthogonal_loss": 0.015488122589886189
    },
    {
      "classification_loss": 0.6833968758583069,
      "epoch": 4.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15477095544338226,
      "orthogonal_weight": 0.1,
      "step": 1383,
      "total_loss": 0.6988739967346191,
      "weighted_orthogonal_loss": 0.015477095730602741
    },
    {
      "classification_loss": 0.6687356233596802,
      "epoch": 4.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15462620556354523,
      "orthogonal_weight": 0.1,
      "step": 1384,
      "total_loss": 0.684198260307312,
      "weighted_orthogonal_loss": 0.015462621115148067
    },
    {
      "classification_loss": 0.692470371723175,
      "epoch": 4.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15453515946865082,
      "orthogonal_weight": 0.1,
      "step": 1385,
      "total_loss": 0.7079238891601562,
      "weighted_orthogonal_loss": 0.015453516505658627
    },
    {
      "classification_loss": 0.682770848274231,
      "epoch": 4.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15448904037475586,
      "orthogonal_weight": 0.1,
      "step": 1386,
      "total_loss": 0.6982197761535645,
      "weighted_orthogonal_loss": 0.01544890459626913
    },
    {
      "classification_loss": 0.6588405966758728,
      "epoch": 4.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15443308651447296,
      "orthogonal_weight": 0.1,
      "step": 1387,
      "total_loss": 0.6742839217185974,
      "weighted_orthogonal_loss": 0.015443309210240841
    },
    {
      "classification_loss": 0.7043523788452148,
      "epoch": 4.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15452887117862701,
      "orthogonal_weight": 0.1,
      "step": 1388,
      "total_loss": 0.7198052406311035,
      "weighted_orthogonal_loss": 0.015452886931598186
    },
    {
      "classification_loss": 0.6981882452964783,
      "epoch": 4.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15460903942584991,
      "orthogonal_weight": 0.1,
      "step": 1389,
      "total_loss": 0.7136491537094116,
      "weighted_orthogonal_loss": 0.015460903756320477
    },
    {
      "classification_loss": 0.6107158660888672,
      "epoch": 4.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15473736822605133,
      "orthogonal_weight": 0.1,
      "step": 1390,
      "total_loss": 0.6261895895004272,
      "weighted_orthogonal_loss": 0.015473737381398678
    },
    {
      "classification_loss": 0.6415083408355713,
      "epoch": 4.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484337508678436,
      "orthogonal_weight": 0.1,
      "step": 1391,
      "total_loss": 0.6569926738739014,
      "weighted_orthogonal_loss": 0.015484337694942951
    },
    {
      "classification_loss": 0.6880971193313599,
      "epoch": 4.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484167635440826,
      "orthogonal_weight": 0.1,
      "step": 1392,
      "total_loss": 0.7035812735557556,
      "weighted_orthogonal_loss": 0.015484168194234371
    },
    {
      "classification_loss": 0.6272070407867432,
      "epoch": 4.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15471485257148743,
      "orthogonal_weight": 0.1,
      "step": 1393,
      "total_loss": 0.6426784992218018,
      "weighted_orthogonal_loss": 0.015471485443413258
    },
    {
      "classification_loss": 0.6958292126655579,
      "epoch": 4.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15467463433742523,
      "orthogonal_weight": 0.1,
      "step": 1394,
      "total_loss": 0.7112966775894165,
      "weighted_orthogonal_loss": 0.015467463992536068
    },
    {
      "classification_loss": 0.7146279811859131,
      "epoch": 4.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1546410620212555,
      "orthogonal_weight": 0.1,
      "step": 1395,
      "total_loss": 0.7300921082496643,
      "weighted_orthogonal_loss": 0.01546410657465458
    },
    {
      "classification_loss": 0.6874127388000488,
      "epoch": 4.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15467870235443115,
      "orthogonal_weight": 0.1,
      "step": 1396,
      "total_loss": 0.7028806209564209,
      "weighted_orthogonal_loss": 0.0154678700491786
    },
    {
      "classification_loss": 0.6166510581970215,
      "epoch": 4.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1546775847673416,
      "orthogonal_weight": 0.1,
      "step": 1397,
      "total_loss": 0.632118821144104,
      "weighted_orthogonal_loss": 0.015467758290469646
    },
    {
      "classification_loss": 0.6611372828483582,
      "epoch": 4.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15473084151744843,
      "orthogonal_weight": 0.1,
      "step": 1398,
      "total_loss": 0.6766103506088257,
      "weighted_orthogonal_loss": 0.015473084524273872
    },
    {
      "classification_loss": 0.7127747535705566,
      "epoch": 4.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1548168957233429,
      "orthogonal_weight": 0.1,
      "step": 1399,
      "total_loss": 0.7282564640045166,
      "weighted_orthogonal_loss": 0.01548168994486332
    },
    {
      "epoch": 4.590163934426229,
      "grad_norm": 11.888660430908203,
      "learning_rate": 0.00015670000000000001,
      "loss": 0.6701,
      "step": 1400
    },
    {
      "classification_loss": 0.6121160984039307,
      "epoch": 4.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15484189987182617,
      "orthogonal_weight": 0.1,
      "step": 1400,
      "total_loss": 0.6276003122329712,
      "weighted_orthogonal_loss": 0.015484190545976162
    },
    {
      "classification_loss": 0.6223638653755188,
      "epoch": 4.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.154870867729187,
      "orthogonal_weight": 0.1,
      "step": 1401,
      "total_loss": 0.6378509402275085,
      "weighted_orthogonal_loss": 0.015487086959183216
    },
    {
      "classification_loss": 0.6133044362068176,
      "epoch": 4.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15494726598262787,
      "orthogonal_weight": 0.1,
      "step": 1402,
      "total_loss": 0.6287991404533386,
      "weighted_orthogonal_loss": 0.015494726598262787
    },
    {
      "classification_loss": 0.6712417006492615,
      "epoch": 4.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1550394743680954,
      "orthogonal_weight": 0.1,
      "step": 1403,
      "total_loss": 0.6867456436157227,
      "weighted_orthogonal_loss": 0.015503947623074055
    },
    {
      "classification_loss": 0.6961161494255066,
      "epoch": 4.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15509440004825592,
      "orthogonal_weight": 0.1,
      "step": 1404,
      "total_loss": 0.7116255760192871,
      "weighted_orthogonal_loss": 0.015509440563619137
    },
    {
      "classification_loss": 0.7444257736206055,
      "epoch": 4.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15507705509662628,
      "orthogonal_weight": 0.1,
      "step": 1405,
      "total_loss": 0.7599334716796875,
      "weighted_orthogonal_loss": 0.015507705509662628
    },
    {
      "classification_loss": 0.6625195145606995,
      "epoch": 4.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15504272282123566,
      "orthogonal_weight": 0.1,
      "step": 1406,
      "total_loss": 0.6780238151550293,
      "weighted_orthogonal_loss": 0.015504272654652596
    },
    {
      "classification_loss": 0.7175401449203491,
      "epoch": 4.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15498954057693481,
      "orthogonal_weight": 0.1,
      "step": 1407,
      "total_loss": 0.7330390810966492,
      "weighted_orthogonal_loss": 0.015498953871428967
    },
    {
      "classification_loss": 0.5995871424674988,
      "epoch": 4.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1549326628446579,
      "orthogonal_weight": 0.1,
      "step": 1408,
      "total_loss": 0.6150804162025452,
      "weighted_orthogonal_loss": 0.01549326628446579
    },
    {
      "classification_loss": 0.6674622297286987,
      "epoch": 4.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15481188893318176,
      "orthogonal_weight": 0.1,
      "step": 1409,
      "total_loss": 0.6829434037208557,
      "weighted_orthogonal_loss": 0.015481188893318176
    },
    {
      "classification_loss": 0.5947529673576355,
      "epoch": 4.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15465764701366425,
      "orthogonal_weight": 0.1,
      "step": 1410,
      "total_loss": 0.6102187037467957,
      "weighted_orthogonal_loss": 0.01546576526015997
    },
    {
      "classification_loss": 0.7004451155662537,
      "epoch": 4.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15475846827030182,
      "orthogonal_weight": 0.1,
      "step": 1411,
      "total_loss": 0.7159209847450256,
      "weighted_orthogonal_loss": 0.015475846827030182
    },
    {
      "classification_loss": 0.6710326671600342,
      "epoch": 4.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15498656034469604,
      "orthogonal_weight": 0.1,
      "step": 1412,
      "total_loss": 0.6865313053131104,
      "weighted_orthogonal_loss": 0.01549865584820509
    },
    {
      "classification_loss": 0.6975085735321045,
      "epoch": 4.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1550527811050415,
      "orthogonal_weight": 0.1,
      "step": 1413,
      "total_loss": 0.7130138278007507,
      "weighted_orthogonal_loss": 0.01550527848303318
    },
    {
      "classification_loss": 0.6288013458251953,
      "epoch": 4.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15509070456027985,
      "orthogonal_weight": 0.1,
      "step": 1414,
      "total_loss": 0.6443104147911072,
      "weighted_orthogonal_loss": 0.015509070828557014
    },
    {
      "classification_loss": 0.7221802473068237,
      "epoch": 4.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1551409661769867,
      "orthogonal_weight": 0.1,
      "step": 1415,
      "total_loss": 0.7376943230628967,
      "weighted_orthogonal_loss": 0.015514097176492214
    },
    {
      "classification_loss": 0.5888633728027344,
      "epoch": 4.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1551973521709442,
      "orthogonal_weight": 0.1,
      "step": 1416,
      "total_loss": 0.604383111000061,
      "weighted_orthogonal_loss": 0.015519735403358936
    },
    {
      "classification_loss": 0.6676875948905945,
      "epoch": 4.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15525034070014954,
      "orthogonal_weight": 0.1,
      "step": 1417,
      "total_loss": 0.6832126379013062,
      "weighted_orthogonal_loss": 0.015525034628808498
    },
    {
      "classification_loss": 0.6483368873596191,
      "epoch": 4.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1553320437669754,
      "orthogonal_weight": 0.1,
      "step": 1418,
      "total_loss": 0.663870096206665,
      "weighted_orthogonal_loss": 0.015533204190433025
    },
    {
      "classification_loss": 0.6685481667518616,
      "epoch": 4.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15545141696929932,
      "orthogonal_weight": 0.1,
      "step": 1419,
      "total_loss": 0.6840932965278625,
      "weighted_orthogonal_loss": 0.015545141883194447
    },
    {
      "classification_loss": 0.6344210505485535,
      "epoch": 4.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15552054345607758,
      "orthogonal_weight": 0.1,
      "step": 1420,
      "total_loss": 0.6499730944633484,
      "weighted_orthogonal_loss": 0.015552054159343243
    },
    {
      "classification_loss": 0.61649090051651,
      "epoch": 4.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15564846992492676,
      "orthogonal_weight": 0.1,
      "step": 1421,
      "total_loss": 0.6320557594299316,
      "weighted_orthogonal_loss": 0.01556484680622816
    },
    {
      "classification_loss": 0.6755267977714539,
      "epoch": 4.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15568991005420685,
      "orthogonal_weight": 0.1,
      "step": 1422,
      "total_loss": 0.691095769405365,
      "weighted_orthogonal_loss": 0.0155689911916852
    },
    {
      "classification_loss": 0.5978356599807739,
      "epoch": 4.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15579438209533691,
      "orthogonal_weight": 0.1,
      "step": 1423,
      "total_loss": 0.6134151220321655,
      "weighted_orthogonal_loss": 0.015579438768327236
    },
    {
      "classification_loss": 0.6638016700744629,
      "epoch": 4.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15569859743118286,
      "orthogonal_weight": 0.1,
      "step": 1424,
      "total_loss": 0.6793715357780457,
      "weighted_orthogonal_loss": 0.015569860115647316
    },
    {
      "classification_loss": 0.6431722044944763,
      "epoch": 4.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15566609799861908,
      "orthogonal_weight": 0.1,
      "step": 1425,
      "total_loss": 0.6587387919425964,
      "weighted_orthogonal_loss": 0.015566609799861908
    },
    {
      "classification_loss": 0.6626684665679932,
      "epoch": 4.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15554609894752502,
      "orthogonal_weight": 0.1,
      "step": 1426,
      "total_loss": 0.6782230734825134,
      "weighted_orthogonal_loss": 0.015554609708487988
    },
    {
      "classification_loss": 0.6343839764595032,
      "epoch": 4.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15542879700660706,
      "orthogonal_weight": 0.1,
      "step": 1427,
      "total_loss": 0.6499268412590027,
      "weighted_orthogonal_loss": 0.015542879700660706
    },
    {
      "classification_loss": 0.6781035661697388,
      "epoch": 4.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1555076241493225,
      "orthogonal_weight": 0.1,
      "step": 1428,
      "total_loss": 0.6936542987823486,
      "weighted_orthogonal_loss": 0.015550762414932251
    },
    {
      "classification_loss": 0.6452721953392029,
      "epoch": 4.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15559905767440796,
      "orthogonal_weight": 0.1,
      "step": 1429,
      "total_loss": 0.6608321070671082,
      "weighted_orthogonal_loss": 0.015559906139969826
    },
    {
      "classification_loss": 0.6511845588684082,
      "epoch": 4.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1556841880083084,
      "orthogonal_weight": 0.1,
      "step": 1430,
      "total_loss": 0.6667529940605164,
      "weighted_orthogonal_loss": 0.015568419359624386
    },
    {
      "classification_loss": 0.7071987986564636,
      "epoch": 4.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15579883754253387,
      "orthogonal_weight": 0.1,
      "step": 1431,
      "total_loss": 0.7227786779403687,
      "weighted_orthogonal_loss": 0.015579883940517902
    },
    {
      "classification_loss": 0.6194230318069458,
      "epoch": 4.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15591676533222198,
      "orthogonal_weight": 0.1,
      "step": 1432,
      "total_loss": 0.6350147128105164,
      "weighted_orthogonal_loss": 0.015591676346957684
    },
    {
      "classification_loss": 0.645447313785553,
      "epoch": 4.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15600650012493134,
      "orthogonal_weight": 0.1,
      "step": 1433,
      "total_loss": 0.6610479354858398,
      "weighted_orthogonal_loss": 0.015600650571286678
    },
    {
      "classification_loss": 0.6618567705154419,
      "epoch": 4.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1560433954000473,
      "orthogonal_weight": 0.1,
      "step": 1434,
      "total_loss": 0.6774610877037048,
      "weighted_orthogonal_loss": 0.01560433954000473
    },
    {
      "classification_loss": 0.6039794683456421,
      "epoch": 4.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1559796780347824,
      "orthogonal_weight": 0.1,
      "step": 1435,
      "total_loss": 0.6195774078369141,
      "weighted_orthogonal_loss": 0.015597968362271786
    },
    {
      "classification_loss": 0.6481812000274658,
      "epoch": 4.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15595155954360962,
      "orthogonal_weight": 0.1,
      "step": 1436,
      "total_loss": 0.6637763381004333,
      "weighted_orthogonal_loss": 0.015595155768096447
    },
    {
      "classification_loss": 0.6498655080795288,
      "epoch": 4.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1558162122964859,
      "orthogonal_weight": 0.1,
      "step": 1437,
      "total_loss": 0.6654471158981323,
      "weighted_orthogonal_loss": 0.015581621788442135
    },
    {
      "classification_loss": 0.5744182467460632,
      "epoch": 4.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15568359196186066,
      "orthogonal_weight": 0.1,
      "step": 1438,
      "total_loss": 0.5899866223335266,
      "weighted_orthogonal_loss": 0.01556835975497961
    },
    {
      "classification_loss": 0.6474694609642029,
      "epoch": 4.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15571151673793793,
      "orthogonal_weight": 0.1,
      "step": 1439,
      "total_loss": 0.6630406379699707,
      "weighted_orthogonal_loss": 0.015571151860058308
    },
    {
      "classification_loss": 0.6430646777153015,
      "epoch": 4.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15581867098808289,
      "orthogonal_weight": 0.1,
      "step": 1440,
      "total_loss": 0.6586465239524841,
      "weighted_orthogonal_loss": 0.015581867657601833
    },
    {
      "classification_loss": 0.6239941120147705,
      "epoch": 4.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15607869625091553,
      "orthogonal_weight": 0.1,
      "step": 1441,
      "total_loss": 0.63960200548172,
      "weighted_orthogonal_loss": 0.015607870183885098
    },
    {
      "classification_loss": 0.6321794986724854,
      "epoch": 4.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15634950995445251,
      "orthogonal_weight": 0.1,
      "step": 1442,
      "total_loss": 0.6478144526481628,
      "weighted_orthogonal_loss": 0.01563495211303234
    },
    {
      "classification_loss": 0.6579461097717285,
      "epoch": 4.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1567116528749466,
      "orthogonal_weight": 0.1,
      "step": 1443,
      "total_loss": 0.6736173033714294,
      "weighted_orthogonal_loss": 0.01567116566002369
    },
    {
      "classification_loss": 0.7166414856910706,
      "epoch": 4.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15685804188251495,
      "orthogonal_weight": 0.1,
      "step": 1444,
      "total_loss": 0.7323272824287415,
      "weighted_orthogonal_loss": 0.015685804188251495
    },
    {
      "classification_loss": 0.7089932560920715,
      "epoch": 4.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1570115089416504,
      "orthogonal_weight": 0.1,
      "step": 1445,
      "total_loss": 0.7246944308280945,
      "weighted_orthogonal_loss": 0.01570115052163601
    },
    {
      "classification_loss": 0.6239246129989624,
      "epoch": 4.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15720611810684204,
      "orthogonal_weight": 0.1,
      "step": 1446,
      "total_loss": 0.6396452188491821,
      "weighted_orthogonal_loss": 0.015720611438155174
    },
    {
      "classification_loss": 0.6371151208877563,
      "epoch": 4.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15735004842281342,
      "orthogonal_weight": 0.1,
      "step": 1447,
      "total_loss": 0.6528501510620117,
      "weighted_orthogonal_loss": 0.01573500595986843
    },
    {
      "classification_loss": 0.618298351764679,
      "epoch": 4.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1575428694486618,
      "orthogonal_weight": 0.1,
      "step": 1448,
      "total_loss": 0.6340526342391968,
      "weighted_orthogonal_loss": 0.01575428806245327
    },
    {
      "classification_loss": 0.6687033176422119,
      "epoch": 4.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15775783360004425,
      "orthogonal_weight": 0.1,
      "step": 1449,
      "total_loss": 0.6844791173934937,
      "weighted_orthogonal_loss": 0.015775782987475395
    },
    {
      "classification_loss": 0.6222862005233765,
      "epoch": 4.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15794257819652557,
      "orthogonal_weight": 0.1,
      "step": 1450,
      "total_loss": 0.6380804777145386,
      "weighted_orthogonal_loss": 0.015794258564710617
    },
    {
      "classification_loss": 0.5690356492996216,
      "epoch": 4.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1582002341747284,
      "orthogonal_weight": 0.1,
      "step": 1451,
      "total_loss": 0.5848556756973267,
      "weighted_orthogonal_loss": 0.01582002453505993
    },
    {
      "classification_loss": 0.5923902988433838,
      "epoch": 4.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15851055085659027,
      "orthogonal_weight": 0.1,
      "step": 1452,
      "total_loss": 0.6082413792610168,
      "weighted_orthogonal_loss": 0.015851056203246117
    },
    {
      "classification_loss": 0.6758062839508057,
      "epoch": 4.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15889589488506317,
      "orthogonal_weight": 0.1,
      "step": 1453,
      "total_loss": 0.6916958689689636,
      "weighted_orthogonal_loss": 0.015889590606093407
    },
    {
      "classification_loss": 0.6292574405670166,
      "epoch": 4.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15918602049350739,
      "orthogonal_weight": 0.1,
      "step": 1454,
      "total_loss": 0.6451760530471802,
      "weighted_orthogonal_loss": 0.015918603166937828
    },
    {
      "classification_loss": 0.7031468152999878,
      "epoch": 4.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15940983593463898,
      "orthogonal_weight": 0.1,
      "step": 1455,
      "total_loss": 0.7190877795219421,
      "weighted_orthogonal_loss": 0.015940984711050987
    },
    {
      "classification_loss": 0.6762414574623108,
      "epoch": 4.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15985970199108124,
      "orthogonal_weight": 0.1,
      "step": 1456,
      "total_loss": 0.6922274231910706,
      "weighted_orthogonal_loss": 0.015985971316695213
    },
    {
      "classification_loss": 0.5659582614898682,
      "epoch": 4.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005976498126984,
      "orthogonal_weight": 0.1,
      "step": 1457,
      "total_loss": 0.5819642543792725,
      "weighted_orthogonal_loss": 0.016005976125597954
    },
    {
      "classification_loss": 0.6961497068405151,
      "epoch": 4.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16029949486255646,
      "orthogonal_weight": 0.1,
      "step": 1458,
      "total_loss": 0.7121796607971191,
      "weighted_orthogonal_loss": 0.016029950231313705
    },
    {
      "classification_loss": 0.657265841960907,
      "epoch": 4.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16048520803451538,
      "orthogonal_weight": 0.1,
      "step": 1459,
      "total_loss": 0.6733143329620361,
      "weighted_orthogonal_loss": 0.016048520803451538
    },
    {
      "classification_loss": 0.6198829412460327,
      "epoch": 4.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16039785742759705,
      "orthogonal_weight": 0.1,
      "step": 1460,
      "total_loss": 0.6359227299690247,
      "weighted_orthogonal_loss": 0.016039786860346794
    },
    {
      "classification_loss": 0.6550878882408142,
      "epoch": 4.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16039608418941498,
      "orthogonal_weight": 0.1,
      "step": 1461,
      "total_loss": 0.6711274981498718,
      "weighted_orthogonal_loss": 0.016039608046412468
    },
    {
      "classification_loss": 0.660058856010437,
      "epoch": 4.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16037581861019135,
      "orthogonal_weight": 0.1,
      "step": 1462,
      "total_loss": 0.6760964393615723,
      "weighted_orthogonal_loss": 0.016037581488490105
    },
    {
      "classification_loss": 0.6396600008010864,
      "epoch": 4.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16044525802135468,
      "orthogonal_weight": 0.1,
      "step": 1463,
      "total_loss": 0.6557044982910156,
      "weighted_orthogonal_loss": 0.016044525429606438
    },
    {
      "classification_loss": 0.6517943739891052,
      "epoch": 4.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16056998074054718,
      "orthogonal_weight": 0.1,
      "step": 1464,
      "total_loss": 0.6678513884544373,
      "weighted_orthogonal_loss": 0.016056997701525688
    },
    {
      "classification_loss": 0.7245147824287415,
      "epoch": 4.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606999784708023,
      "orthogonal_weight": 0.1,
      "step": 1465,
      "total_loss": 0.7405847907066345,
      "weighted_orthogonal_loss": 0.01606999896466732
    },
    {
      "classification_loss": 0.6738188862800598,
      "epoch": 4.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16084147989749908,
      "orthogonal_weight": 0.1,
      "step": 1466,
      "total_loss": 0.6899030208587646,
      "weighted_orthogonal_loss": 0.01608414761722088
    },
    {
      "classification_loss": 0.6414238810539246,
      "epoch": 4.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1609189659357071,
      "orthogonal_weight": 0.1,
      "step": 1467,
      "total_loss": 0.6575157642364502,
      "weighted_orthogonal_loss": 0.01609189622104168
    },
    {
      "classification_loss": 0.6595363020896912,
      "epoch": 4.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16092757880687714,
      "orthogonal_weight": 0.1,
      "step": 1468,
      "total_loss": 0.6756290793418884,
      "weighted_orthogonal_loss": 0.016092758625745773
    },
    {
      "classification_loss": 0.6911564469337463,
      "epoch": 4.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094684600830078,
      "orthogonal_weight": 0.1,
      "step": 1469,
      "total_loss": 0.7072511315345764,
      "weighted_orthogonal_loss": 0.016094684600830078
    },
    {
      "classification_loss": 0.6610361337661743,
      "epoch": 4.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16094954311847687,
      "orthogonal_weight": 0.1,
      "step": 1470,
      "total_loss": 0.6771311163902283,
      "weighted_orthogonal_loss": 0.016094954684376717
    },
    {
      "classification_loss": 0.6915697455406189,
      "epoch": 4.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16099795699119568,
      "orthogonal_weight": 0.1,
      "step": 1471,
      "total_loss": 0.7076695561408997,
      "weighted_orthogonal_loss": 0.016099795699119568
    },
    {
      "classification_loss": 0.6813281178474426,
      "epoch": 4.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16109499335289001,
      "orthogonal_weight": 0.1,
      "step": 1472,
      "total_loss": 0.6974376440048218,
      "weighted_orthogonal_loss": 0.01610950008034706
    },
    {
      "classification_loss": 0.6621844172477722,
      "epoch": 4.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16119880974292755,
      "orthogonal_weight": 0.1,
      "step": 1473,
      "total_loss": 0.6783043146133423,
      "weighted_orthogonal_loss": 0.016119880601763725
    },
    {
      "classification_loss": 0.5887847542762756,
      "epoch": 4.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16119350492954254,
      "orthogonal_weight": 0.1,
      "step": 1474,
      "total_loss": 0.6049041152000427,
      "weighted_orthogonal_loss": 0.016119351610541344
    },
    {
      "classification_loss": 0.7266513109207153,
      "epoch": 4.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1611083298921585,
      "orthogonal_weight": 0.1,
      "step": 1475,
      "total_loss": 0.7427621483802795,
      "weighted_orthogonal_loss": 0.01611083373427391
    },
    {
      "classification_loss": 0.6250806450843811,
      "epoch": 4.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1610046923160553,
      "orthogonal_weight": 0.1,
      "step": 1476,
      "total_loss": 0.6411811113357544,
      "weighted_orthogonal_loss": 0.01610046997666359
    },
    {
      "classification_loss": 0.6287276148796082,
      "epoch": 4.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1609254628419876,
      "orthogonal_weight": 0.1,
      "step": 1477,
      "total_loss": 0.6448201537132263,
      "weighted_orthogonal_loss": 0.01609254628419876
    },
    {
      "classification_loss": 0.6916844844818115,
      "epoch": 4.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1608097106218338,
      "orthogonal_weight": 0.1,
      "step": 1478,
      "total_loss": 0.7077654600143433,
      "weighted_orthogonal_loss": 0.01608097180724144
    },
    {
      "classification_loss": 0.6320834755897522,
      "epoch": 4.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16077162325382233,
      "orthogonal_weight": 0.1,
      "step": 1479,
      "total_loss": 0.6481606364250183,
      "weighted_orthogonal_loss": 0.016077162697911263
    },
    {
      "classification_loss": 0.6004528403282166,
      "epoch": 4.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1608089804649353,
      "orthogonal_weight": 0.1,
      "step": 1480,
      "total_loss": 0.6165337562561035,
      "weighted_orthogonal_loss": 0.01608089916408062
    },
    {
      "classification_loss": 0.6578600406646729,
      "epoch": 4.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16088435053825378,
      "orthogonal_weight": 0.1,
      "step": 1481,
      "total_loss": 0.6739484667778015,
      "weighted_orthogonal_loss": 0.016088435426354408
    },
    {
      "classification_loss": 0.6423474550247192,
      "epoch": 4.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16081589460372925,
      "orthogonal_weight": 0.1,
      "step": 1482,
      "total_loss": 0.6584290266036987,
      "weighted_orthogonal_loss": 0.016081590205430984
    },
    {
      "classification_loss": 0.6156381964683533,
      "epoch": 4.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.160752534866333,
      "orthogonal_weight": 0.1,
      "step": 1483,
      "total_loss": 0.6317134499549866,
      "weighted_orthogonal_loss": 0.0160752534866333
    },
    {
      "classification_loss": 0.6480798721313477,
      "epoch": 4.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16063465178012848,
      "orthogonal_weight": 0.1,
      "step": 1484,
      "total_loss": 0.6641433238983154,
      "weighted_orthogonal_loss": 0.016063464805483818
    },
    {
      "classification_loss": 0.7170490026473999,
      "epoch": 4.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605372130870819,
      "orthogonal_weight": 0.1,
      "step": 1485,
      "total_loss": 0.7331027388572693,
      "weighted_orthogonal_loss": 0.01605372130870819
    },
    {
      "classification_loss": 0.6510683298110962,
      "epoch": 4.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16034096479415894,
      "orthogonal_weight": 0.1,
      "step": 1486,
      "total_loss": 0.6671024560928345,
      "weighted_orthogonal_loss": 0.016034096479415894
    },
    {
      "classification_loss": 0.6580278873443604,
      "epoch": 4.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16022387146949768,
      "orthogonal_weight": 0.1,
      "step": 1487,
      "total_loss": 0.6740502715110779,
      "weighted_orthogonal_loss": 0.016022387892007828
    },
    {
      "classification_loss": 0.6337840557098389,
      "epoch": 4.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16009844839572906,
      "orthogonal_weight": 0.1,
      "step": 1488,
      "total_loss": 0.6497939229011536,
      "weighted_orthogonal_loss": 0.016009844839572906
    },
    {
      "classification_loss": 0.660090982913971,
      "epoch": 4.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15991617739200592,
      "orthogonal_weight": 0.1,
      "step": 1489,
      "total_loss": 0.6760826110839844,
      "weighted_orthogonal_loss": 0.01599161885678768
    },
    {
      "classification_loss": 0.6154422760009766,
      "epoch": 4.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15981924533843994,
      "orthogonal_weight": 0.1,
      "step": 1490,
      "total_loss": 0.6314241886138916,
      "weighted_orthogonal_loss": 0.015981925651431084
    },
    {
      "classification_loss": 0.628469705581665,
      "epoch": 4.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15976104140281677,
      "orthogonal_weight": 0.1,
      "step": 1491,
      "total_loss": 0.6444458365440369,
      "weighted_orthogonal_loss": 0.015976104885339737
    },
    {
      "classification_loss": 0.6470010280609131,
      "epoch": 4.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15974874794483185,
      "orthogonal_weight": 0.1,
      "step": 1492,
      "total_loss": 0.6629759073257446,
      "weighted_orthogonal_loss": 0.015974875539541245
    },
    {
      "classification_loss": 0.6329172253608704,
      "epoch": 4.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15973973274230957,
      "orthogonal_weight": 0.1,
      "step": 1493,
      "total_loss": 0.6488912105560303,
      "weighted_orthogonal_loss": 0.015973974019289017
    },
    {
      "classification_loss": 0.6607255935668945,
      "epoch": 4.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15972460806369781,
      "orthogonal_weight": 0.1,
      "step": 1494,
      "total_loss": 0.6766980290412903,
      "weighted_orthogonal_loss": 0.01597246155142784
    },
    {
      "classification_loss": 0.5833823084831238,
      "epoch": 4.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15953156352043152,
      "orthogonal_weight": 0.1,
      "step": 1495,
      "total_loss": 0.5993354916572571,
      "weighted_orthogonal_loss": 0.01595315709710121
    },
    {
      "classification_loss": 0.623370349407196,
      "epoch": 4.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1593804806470871,
      "orthogonal_weight": 0.1,
      "step": 1496,
      "total_loss": 0.6393083930015564,
      "weighted_orthogonal_loss": 0.0159380491822958
    },
    {
      "classification_loss": 0.6957510709762573,
      "epoch": 4.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15927506983280182,
      "orthogonal_weight": 0.1,
      "step": 1497,
      "total_loss": 0.7116785645484924,
      "weighted_orthogonal_loss": 0.015927506610751152
    },
    {
      "classification_loss": 0.5849758982658386,
      "epoch": 4.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15901759266853333,
      "orthogonal_weight": 0.1,
      "step": 1498,
      "total_loss": 0.6008776426315308,
      "weighted_orthogonal_loss": 0.015901759266853333
    },
    {
      "classification_loss": 0.5933552980422974,
      "epoch": 4.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15880842506885529,
      "orthogonal_weight": 0.1,
      "step": 1499,
      "total_loss": 0.6092361211776733,
      "weighted_orthogonal_loss": 0.015880843624472618
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 3.836839437484741,
      "learning_rate": 0.0001533666666666667,
      "loss": 0.6651,
      "step": 1500
    },
    {
      "classification_loss": 0.5532850027084351,
      "epoch": 4.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.158797025680542,
      "orthogonal_weight": 0.1,
      "step": 1500,
      "total_loss": 0.5691646933555603,
      "weighted_orthogonal_loss": 0.01587970368564129
    },
    {
      "classification_loss": 0.707432746887207,
      "epoch": 4.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15883822739124298,
      "orthogonal_weight": 0.1,
      "step": 1501,
      "total_loss": 0.7233165502548218,
      "weighted_orthogonal_loss": 0.015883823856711388
    },
    {
      "classification_loss": 0.7190752625465393,
      "epoch": 4.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15885865688323975,
      "orthogonal_weight": 0.1,
      "step": 1502,
      "total_loss": 0.7349611520767212,
      "weighted_orthogonal_loss": 0.015885865315794945
    },
    {
      "classification_loss": 0.7242637872695923,
      "epoch": 4.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15886160731315613,
      "orthogonal_weight": 0.1,
      "step": 1503,
      "total_loss": 0.740149974822998,
      "weighted_orthogonal_loss": 0.015886161476373672
    },
    {
      "classification_loss": 0.6434782147407532,
      "epoch": 4.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15883079171180725,
      "orthogonal_weight": 0.1,
      "step": 1504,
      "total_loss": 0.6593613028526306,
      "weighted_orthogonal_loss": 0.015883078798651695
    },
    {
      "classification_loss": 0.7234757542610168,
      "epoch": 4.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1588078886270523,
      "orthogonal_weight": 0.1,
      "step": 1505,
      "total_loss": 0.739356517791748,
      "weighted_orthogonal_loss": 0.01588078960776329
    },
    {
      "classification_loss": 0.6456847190856934,
      "epoch": 4.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15876071155071259,
      "orthogonal_weight": 0.1,
      "step": 1506,
      "total_loss": 0.6615607738494873,
      "weighted_orthogonal_loss": 0.01587607152760029
    },
    {
      "classification_loss": 0.6316987872123718,
      "epoch": 4.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15865619480609894,
      "orthogonal_weight": 0.1,
      "step": 1507,
      "total_loss": 0.6475644111633301,
      "weighted_orthogonal_loss": 0.015865620225667953
    },
    {
      "classification_loss": 0.6375907063484192,
      "epoch": 4.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15858444571495056,
      "orthogonal_weight": 0.1,
      "step": 1508,
      "total_loss": 0.6534491777420044,
      "weighted_orthogonal_loss": 0.015858445316553116
    },
    {
      "classification_loss": 0.6385043263435364,
      "epoch": 4.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1585010439157486,
      "orthogonal_weight": 0.1,
      "step": 1509,
      "total_loss": 0.654354453086853,
      "weighted_orthogonal_loss": 0.01585010439157486
    },
    {
      "classification_loss": 0.6037103533744812,
      "epoch": 4.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15847070515155792,
      "orthogonal_weight": 0.1,
      "step": 1510,
      "total_loss": 0.6195574402809143,
      "weighted_orthogonal_loss": 0.015847070142626762
    },
    {
      "classification_loss": 0.6966846585273743,
      "epoch": 4.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1583528071641922,
      "orthogonal_weight": 0.1,
      "step": 1511,
      "total_loss": 0.7125199437141418,
      "weighted_orthogonal_loss": 0.01583528146147728
    },
    {
      "classification_loss": 0.6901640892028809,
      "epoch": 4.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15830767154693604,
      "orthogonal_weight": 0.1,
      "step": 1512,
      "total_loss": 0.7059948444366455,
      "weighted_orthogonal_loss": 0.015830768272280693
    },
    {
      "classification_loss": 0.6457533836364746,
      "epoch": 4.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15827541053295135,
      "orthogonal_weight": 0.1,
      "step": 1513,
      "total_loss": 0.6615809202194214,
      "weighted_orthogonal_loss": 0.015827542170882225
    },
    {
      "classification_loss": 0.6881938576698303,
      "epoch": 4.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1583678275346756,
      "orthogonal_weight": 0.1,
      "step": 1514,
      "total_loss": 0.7040306329727173,
      "weighted_orthogonal_loss": 0.01583678275346756
    },
    {
      "classification_loss": 0.6565508246421814,
      "epoch": 4.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15847985446453094,
      "orthogonal_weight": 0.1,
      "step": 1515,
      "total_loss": 0.6723988056182861,
      "weighted_orthogonal_loss": 0.015847986564040184
    },
    {
      "classification_loss": 0.6441380381584167,
      "epoch": 4.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1586638242006302,
      "orthogonal_weight": 0.1,
      "step": 1516,
      "total_loss": 0.6600044369697571,
      "weighted_orthogonal_loss": 0.01586638204753399
    },
    {
      "classification_loss": 0.5864185690879822,
      "epoch": 4.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15868858993053436,
      "orthogonal_weight": 0.1,
      "step": 1517,
      "total_loss": 0.6022874116897583,
      "weighted_orthogonal_loss": 0.015868859365582466
    },
    {
      "classification_loss": 0.6191779375076294,
      "epoch": 4.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15879788994789124,
      "orthogonal_weight": 0.1,
      "step": 1518,
      "total_loss": 0.6350577473640442,
      "weighted_orthogonal_loss": 0.015879789367318153
    },
    {
      "classification_loss": 0.6906582117080688,
      "epoch": 4.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15898287296295166,
      "orthogonal_weight": 0.1,
      "step": 1519,
      "total_loss": 0.706556499004364,
      "weighted_orthogonal_loss": 0.015898287296295166
    },
    {
      "classification_loss": 0.6435989737510681,
      "epoch": 4.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1592302769422531,
      "orthogonal_weight": 0.1,
      "step": 1520,
      "total_loss": 0.6595219969749451,
      "weighted_orthogonal_loss": 0.0159230288118124
    },
    {
      "classification_loss": 0.6223328709602356,
      "epoch": 4.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1594562977552414,
      "orthogonal_weight": 0.1,
      "step": 1521,
      "total_loss": 0.6382784843444824,
      "weighted_orthogonal_loss": 0.01594563014805317
    },
    {
      "classification_loss": 0.6819171905517578,
      "epoch": 4.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15961992740631104,
      "orthogonal_weight": 0.1,
      "step": 1522,
      "total_loss": 0.6978791952133179,
      "weighted_orthogonal_loss": 0.015961993485689163
    },
    {
      "classification_loss": 0.6620699763298035,
      "epoch": 4.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.15985943377017975,
      "orthogonal_weight": 0.1,
      "step": 1523,
      "total_loss": 0.6780559420585632,
      "weighted_orthogonal_loss": 0.015985943377017975
    },
    {
      "classification_loss": 0.6095298528671265,
      "epoch": 4.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16005951166152954,
      "orthogonal_weight": 0.1,
      "step": 1524,
      "total_loss": 0.625535786151886,
      "weighted_orthogonal_loss": 0.016005951911211014
    },
    {
      "classification_loss": 0.6921144723892212,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7081480026245117,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6981004476547241,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7141339778900146,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6831082105636597,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6991417407989502,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6887901425361633,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7048236727714539,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6922798752784729,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7083134055137634,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6851080656051636,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7011415958404541,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.6762381792068481,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6922717094421387,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.7038277387619019,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.7198612689971924,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.535,
      "eval_f1": 0.6055979643765903,
      "eval_loss": 0.7056462168693542,
      "eval_precision": 0.6420863309352518,
      "eval_recall": 0.5730337078651685,
      "eval_runtime": 6.1441,
      "eval_samples_per_second": 162.759,
      "eval_steps_per_second": 1.302,
      "step": 1525
    },
    {
      "classification_loss": 0.6203285455703735,
      "epoch": 5.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1603354960680008,
      "orthogonal_weight": 0.1,
      "step": 1525,
      "total_loss": 0.6363620758056641,
      "weighted_orthogonal_loss": 0.01603355072438717
    },
    {
      "classification_loss": 0.648748517036438,
      "epoch": 5.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606888622045517,
      "orthogonal_weight": 0.1,
      "step": 1526,
      "total_loss": 0.6648173928260803,
      "weighted_orthogonal_loss": 0.01606888696551323
    },
    {
      "classification_loss": 0.6944869160652161,
      "epoch": 5.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16103820502758026,
      "orthogonal_weight": 0.1,
      "step": 1527,
      "total_loss": 0.7105907201766968,
      "weighted_orthogonal_loss": 0.016103820875287056
    },
    {
      "classification_loss": 0.6162133812904358,
      "epoch": 5.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16108664870262146,
      "orthogonal_weight": 0.1,
      "step": 1528,
      "total_loss": 0.6323220729827881,
      "weighted_orthogonal_loss": 0.016108665615320206
    },
    {
      "classification_loss": 0.6833519339561462,
      "epoch": 5.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16114969551563263,
      "orthogonal_weight": 0.1,
      "step": 1529,
      "total_loss": 0.6994668841362,
      "weighted_orthogonal_loss": 0.016114970669150352
    },
    {
      "classification_loss": 0.6260731816291809,
      "epoch": 5.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16122859716415405,
      "orthogonal_weight": 0.1,
      "step": 1530,
      "total_loss": 0.6421960592269897,
      "weighted_orthogonal_loss": 0.016122860834002495
    },
    {
      "classification_loss": 0.6179673075675964,
      "epoch": 5.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1613115519285202,
      "orthogonal_weight": 0.1,
      "step": 1531,
      "total_loss": 0.634098470211029,
      "weighted_orthogonal_loss": 0.01613115519285202
    },
    {
      "classification_loss": 0.6513174772262573,
      "epoch": 5.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16138195991516113,
      "orthogonal_weight": 0.1,
      "step": 1532,
      "total_loss": 0.6674556732177734,
      "weighted_orthogonal_loss": 0.016138195991516113
    },
    {
      "classification_loss": 0.5642306208610535,
      "epoch": 5.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615353226661682,
      "orthogonal_weight": 0.1,
      "step": 1533,
      "total_loss": 0.5803841352462769,
      "weighted_orthogonal_loss": 0.01615353301167488
    },
    {
      "classification_loss": 0.6364272832870483,
      "epoch": 5.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1616889238357544,
      "orthogonal_weight": 0.1,
      "step": 1534,
      "total_loss": 0.6525961756706238,
      "weighted_orthogonal_loss": 0.01616889238357544
    },
    {
      "classification_loss": 0.6110571622848511,
      "epoch": 5.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1618640124797821,
      "orthogonal_weight": 0.1,
      "step": 1535,
      "total_loss": 0.6272435784339905,
      "weighted_orthogonal_loss": 0.01618640124797821
    },
    {
      "classification_loss": 0.5433555841445923,
      "epoch": 5.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1620340645313263,
      "orthogonal_weight": 0.1,
      "step": 1536,
      "total_loss": 0.5595589876174927,
      "weighted_orthogonal_loss": 0.01620340719819069
    },
    {
      "classification_loss": 0.6131851673126221,
      "epoch": 5.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16224412620067596,
      "orthogonal_weight": 0.1,
      "step": 1537,
      "total_loss": 0.6294095516204834,
      "weighted_orthogonal_loss": 0.016224412247538567
    },
    {
      "classification_loss": 0.6582959890365601,
      "epoch": 5.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16246090829372406,
      "orthogonal_weight": 0.1,
      "step": 1538,
      "total_loss": 0.6745420694351196,
      "weighted_orthogonal_loss": 0.016246091574430466
    },
    {
      "classification_loss": 0.6882049441337585,
      "epoch": 5.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625952273607254,
      "orthogonal_weight": 0.1,
      "step": 1539,
      "total_loss": 0.7044644951820374,
      "weighted_orthogonal_loss": 0.01625952310860157
    },
    {
      "classification_loss": 0.640039324760437,
      "epoch": 5.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16274510324001312,
      "orthogonal_weight": 0.1,
      "step": 1540,
      "total_loss": 0.6563138365745544,
      "weighted_orthogonal_loss": 0.016274509951472282
    },
    {
      "classification_loss": 0.6516827940940857,
      "epoch": 5.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16283877193927765,
      "orthogonal_weight": 0.1,
      "step": 1541,
      "total_loss": 0.6679666638374329,
      "weighted_orthogonal_loss": 0.016283877193927765
    },
    {
      "classification_loss": 0.6936156153678894,
      "epoch": 5.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1628841757774353,
      "orthogonal_weight": 0.1,
      "step": 1542,
      "total_loss": 0.7099040150642395,
      "weighted_orthogonal_loss": 0.01628841832280159
    },
    {
      "classification_loss": 0.6493815779685974,
      "epoch": 5.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16283652186393738,
      "orthogonal_weight": 0.1,
      "step": 1543,
      "total_loss": 0.6656652092933655,
      "weighted_orthogonal_loss": 0.016283651813864708
    },
    {
      "classification_loss": 0.6381707787513733,
      "epoch": 5.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16289940476417542,
      "orthogonal_weight": 0.1,
      "step": 1544,
      "total_loss": 0.6544607281684875,
      "weighted_orthogonal_loss": 0.01628994010388851
    },
    {
      "classification_loss": 0.6357731819152832,
      "epoch": 5.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16281498968601227,
      "orthogonal_weight": 0.1,
      "step": 1545,
      "total_loss": 0.6520546674728394,
      "weighted_orthogonal_loss": 0.016281498596072197
    },
    {
      "classification_loss": 0.6707143783569336,
      "epoch": 5.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625424176454544,
      "orthogonal_weight": 0.1,
      "step": 1546,
      "total_loss": 0.6869686245918274,
      "weighted_orthogonal_loss": 0.0162542425096035
    },
    {
      "classification_loss": 0.6763911843299866,
      "epoch": 5.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16226454079151154,
      "orthogonal_weight": 0.1,
      "step": 1547,
      "total_loss": 0.692617654800415,
      "weighted_orthogonal_loss": 0.016226453706622124
    },
    {
      "classification_loss": 0.6309170722961426,
      "epoch": 5.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16212396323680878,
      "orthogonal_weight": 0.1,
      "step": 1548,
      "total_loss": 0.647129476070404,
      "weighted_orthogonal_loss": 0.016212396323680878
    },
    {
      "classification_loss": 0.6638699173927307,
      "epoch": 5.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16206510365009308,
      "orthogonal_weight": 0.1,
      "step": 1549,
      "total_loss": 0.6800764203071594,
      "weighted_orthogonal_loss": 0.016206510365009308
    },
    {
      "classification_loss": 0.6922028660774231,
      "epoch": 5.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1620500683784485,
      "orthogonal_weight": 0.1,
      "step": 1550,
      "total_loss": 0.7084078788757324,
      "weighted_orthogonal_loss": 0.01620500721037388
    },
    {
      "classification_loss": 0.6504302620887756,
      "epoch": 5.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16202856600284576,
      "orthogonal_weight": 0.1,
      "step": 1551,
      "total_loss": 0.666633129119873,
      "weighted_orthogonal_loss": 0.016202857717871666
    },
    {
      "classification_loss": 0.566456139087677,
      "epoch": 5.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16207371652126312,
      "orthogonal_weight": 0.1,
      "step": 1552,
      "total_loss": 0.5826635360717773,
      "weighted_orthogonal_loss": 0.016207372769713402
    },
    {
      "classification_loss": 0.6457269191741943,
      "epoch": 5.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16215740144252777,
      "orthogonal_weight": 0.1,
      "step": 1553,
      "total_loss": 0.6619426608085632,
      "weighted_orthogonal_loss": 0.016215739771723747
    },
    {
      "classification_loss": 0.6141403317451477,
      "epoch": 5.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1622873693704605,
      "orthogonal_weight": 0.1,
      "step": 1554,
      "total_loss": 0.6303690671920776,
      "weighted_orthogonal_loss": 0.01622873730957508
    },
    {
      "classification_loss": 0.6624844074249268,
      "epoch": 5.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16245496273040771,
      "orthogonal_weight": 0.1,
      "step": 1555,
      "total_loss": 0.6787298917770386,
      "weighted_orthogonal_loss": 0.01624549739062786
    },
    {
      "classification_loss": 0.6353470087051392,
      "epoch": 5.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16265511512756348,
      "orthogonal_weight": 0.1,
      "step": 1556,
      "total_loss": 0.6516125202178955,
      "weighted_orthogonal_loss": 0.016265511512756348
    },
    {
      "classification_loss": 0.6379003524780273,
      "epoch": 5.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16282135248184204,
      "orthogonal_weight": 0.1,
      "step": 1557,
      "total_loss": 0.654182493686676,
      "weighted_orthogonal_loss": 0.016282135620713234
    },
    {
      "classification_loss": 0.6501785516738892,
      "epoch": 5.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287121176719666,
      "orthogonal_weight": 0.1,
      "step": 1558,
      "total_loss": 0.666465699672699,
      "weighted_orthogonal_loss": 0.016287121921777725
    },
    {
      "classification_loss": 0.6364973783493042,
      "epoch": 5.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1629895567893982,
      "orthogonal_weight": 0.1,
      "step": 1559,
      "total_loss": 0.6527963280677795,
      "weighted_orthogonal_loss": 0.01629895530641079
    },
    {
      "classification_loss": 0.6348114013671875,
      "epoch": 5.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312353312969208,
      "orthogonal_weight": 0.1,
      "step": 1560,
      "total_loss": 0.6511237621307373,
      "weighted_orthogonal_loss": 0.016312353312969208
    },
    {
      "classification_loss": 0.6355750560760498,
      "epoch": 5.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16326847672462463,
      "orthogonal_weight": 0.1,
      "step": 1561,
      "total_loss": 0.65190190076828,
      "weighted_orthogonal_loss": 0.016326848417520523
    },
    {
      "classification_loss": 0.690966010093689,
      "epoch": 5.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1633804440498352,
      "orthogonal_weight": 0.1,
      "step": 1562,
      "total_loss": 0.707304060459137,
      "weighted_orthogonal_loss": 0.01633804477751255
    },
    {
      "classification_loss": 0.6280898451805115,
      "epoch": 5.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16337426006793976,
      "orthogonal_weight": 0.1,
      "step": 1563,
      "total_loss": 0.6444272994995117,
      "weighted_orthogonal_loss": 0.016337426379323006
    },
    {
      "classification_loss": 0.5863778591156006,
      "epoch": 5.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16338732838630676,
      "orthogonal_weight": 0.1,
      "step": 1564,
      "total_loss": 0.6027165651321411,
      "weighted_orthogonal_loss": 0.016338733956217766
    },
    {
      "classification_loss": 0.6730729341506958,
      "epoch": 5.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16314280033111572,
      "orthogonal_weight": 0.1,
      "step": 1565,
      "total_loss": 0.6893872022628784,
      "weighted_orthogonal_loss": 0.016314281150698662
    },
    {
      "classification_loss": 0.6920182108879089,
      "epoch": 5.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1631152331829071,
      "orthogonal_weight": 0.1,
      "step": 1566,
      "total_loss": 0.7083297371864319,
      "weighted_orthogonal_loss": 0.0163115244358778
    },
    {
      "classification_loss": 0.6267991662025452,
      "epoch": 5.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311565041542053,
      "orthogonal_weight": 0.1,
      "step": 1567,
      "total_loss": 0.6431107521057129,
      "weighted_orthogonal_loss": 0.016311565414071083
    },
    {
      "classification_loss": 0.6135960817337036,
      "epoch": 5.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312746703624725,
      "orthogonal_weight": 0.1,
      "step": 1568,
      "total_loss": 0.6299088001251221,
      "weighted_orthogonal_loss": 0.016312746331095695
    },
    {
      "classification_loss": 0.6161550283432007,
      "epoch": 5.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16308380663394928,
      "orthogonal_weight": 0.1,
      "step": 1569,
      "total_loss": 0.6324633955955505,
      "weighted_orthogonal_loss": 0.016308380290865898
    },
    {
      "classification_loss": 0.6930941939353943,
      "epoch": 5.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287246346473694,
      "orthogonal_weight": 0.1,
      "step": 1570,
      "total_loss": 0.7093814611434937,
      "weighted_orthogonal_loss": 0.016287246719002724
    },
    {
      "classification_loss": 0.6017596125602722,
      "epoch": 5.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1627156138420105,
      "orthogonal_weight": 0.1,
      "step": 1571,
      "total_loss": 0.6180311441421509,
      "weighted_orthogonal_loss": 0.01627156138420105
    },
    {
      "classification_loss": 0.6417525410652161,
      "epoch": 5.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625879853963852,
      "orthogonal_weight": 0.1,
      "step": 1572,
      "total_loss": 0.6580113172531128,
      "weighted_orthogonal_loss": 0.01625879853963852
    },
    {
      "classification_loss": 0.6010831594467163,
      "epoch": 5.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625143587589264,
      "orthogonal_weight": 0.1,
      "step": 1573,
      "total_loss": 0.6173346042633057,
      "weighted_orthogonal_loss": 0.01625143550336361
    },
    {
      "classification_loss": 0.6474691033363342,
      "epoch": 5.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1625271588563919,
      "orthogonal_weight": 0.1,
      "step": 1574,
      "total_loss": 0.6637217998504639,
      "weighted_orthogonal_loss": 0.01625271700322628
    },
    {
      "classification_loss": 0.6845181584358215,
      "epoch": 5.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16259247064590454,
      "orthogonal_weight": 0.1,
      "step": 1575,
      "total_loss": 0.7007774114608765,
      "weighted_orthogonal_loss": 0.016259247437119484
    },
    {
      "classification_loss": 0.69020676612854,
      "epoch": 5.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16268908977508545,
      "orthogonal_weight": 0.1,
      "step": 1576,
      "total_loss": 0.7064756751060486,
      "weighted_orthogonal_loss": 0.016268908977508545
    },
    {
      "classification_loss": 0.6483211517333984,
      "epoch": 5.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16275952756404877,
      "orthogonal_weight": 0.1,
      "step": 1577,
      "total_loss": 0.6645970940589905,
      "weighted_orthogonal_loss": 0.016275953501462936
    },
    {
      "classification_loss": 0.6447833776473999,
      "epoch": 5.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1628861129283905,
      "orthogonal_weight": 0.1,
      "step": 1578,
      "total_loss": 0.6610720157623291,
      "weighted_orthogonal_loss": 0.01628861203789711
    },
    {
      "classification_loss": 0.562610387802124,
      "epoch": 5.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1630265712738037,
      "orthogonal_weight": 0.1,
      "step": 1579,
      "total_loss": 0.5789130330085754,
      "weighted_orthogonal_loss": 0.01630265824496746
    },
    {
      "classification_loss": 0.715632438659668,
      "epoch": 5.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16330428421497345,
      "orthogonal_weight": 0.1,
      "step": 1580,
      "total_loss": 0.7319628596305847,
      "weighted_orthogonal_loss": 0.016330428421497345
    },
    {
      "classification_loss": 0.640261173248291,
      "epoch": 5.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16357913613319397,
      "orthogonal_weight": 0.1,
      "step": 1581,
      "total_loss": 0.6566190719604492,
      "weighted_orthogonal_loss": 0.016357913613319397
    },
    {
      "classification_loss": 0.6882398128509521,
      "epoch": 5.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16382664442062378,
      "orthogonal_weight": 0.1,
      "step": 1582,
      "total_loss": 0.7046225070953369,
      "weighted_orthogonal_loss": 0.016382664442062378
    },
    {
      "classification_loss": 0.6642354130744934,
      "epoch": 5.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16414234042167664,
      "orthogonal_weight": 0.1,
      "step": 1583,
      "total_loss": 0.6806496381759644,
      "weighted_orthogonal_loss": 0.016414234414696693
    },
    {
      "classification_loss": 0.6425644159317017,
      "epoch": 5.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16445256769657135,
      "orthogonal_weight": 0.1,
      "step": 1584,
      "total_loss": 0.6590096950531006,
      "weighted_orthogonal_loss": 0.016445256769657135
    },
    {
      "classification_loss": 0.6953269839286804,
      "epoch": 5.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16464893519878387,
      "orthogonal_weight": 0.1,
      "step": 1585,
      "total_loss": 0.7117918729782104,
      "weighted_orthogonal_loss": 0.016464894637465477
    },
    {
      "classification_loss": 0.6180171370506287,
      "epoch": 5.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16481158137321472,
      "orthogonal_weight": 0.1,
      "step": 1586,
      "total_loss": 0.6344982981681824,
      "weighted_orthogonal_loss": 0.01648115925490856
    },
    {
      "classification_loss": 0.7106636166572571,
      "epoch": 5.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16512538492679596,
      "orthogonal_weight": 0.1,
      "step": 1587,
      "total_loss": 0.7271761298179626,
      "weighted_orthogonal_loss": 0.016512539237737656
    },
    {
      "classification_loss": 0.6795002222061157,
      "epoch": 5.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16544054448604584,
      "orthogonal_weight": 0.1,
      "step": 1588,
      "total_loss": 0.6960442662239075,
      "weighted_orthogonal_loss": 0.016544055193662643
    },
    {
      "classification_loss": 0.6151716709136963,
      "epoch": 5.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16574034094810486,
      "orthogonal_weight": 0.1,
      "step": 1589,
      "total_loss": 0.6317456960678101,
      "weighted_orthogonal_loss": 0.016574034467339516
    },
    {
      "classification_loss": 0.6645530462265015,
      "epoch": 5.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1660218983888626,
      "orthogonal_weight": 0.1,
      "step": 1590,
      "total_loss": 0.681155264377594,
      "weighted_orthogonal_loss": 0.01660219021141529
    },
    {
      "classification_loss": 0.6190404295921326,
      "epoch": 5.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16632874310016632,
      "orthogonal_weight": 0.1,
      "step": 1591,
      "total_loss": 0.6356732845306396,
      "weighted_orthogonal_loss": 0.01663287542760372
    },
    {
      "classification_loss": 0.637717068195343,
      "epoch": 5.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1664690524339676,
      "orthogonal_weight": 0.1,
      "step": 1592,
      "total_loss": 0.6543639898300171,
      "weighted_orthogonal_loss": 0.01664690487086773
    },
    {
      "classification_loss": 0.6819107532501221,
      "epoch": 5.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16669106483459473,
      "orthogonal_weight": 0.1,
      "step": 1593,
      "total_loss": 0.6985798478126526,
      "weighted_orthogonal_loss": 0.016669107601046562
    },
    {
      "classification_loss": 0.7156078219413757,
      "epoch": 5.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16686291992664337,
      "orthogonal_weight": 0.1,
      "step": 1594,
      "total_loss": 0.7322941422462463,
      "weighted_orthogonal_loss": 0.016686292365193367
    },
    {
      "classification_loss": 0.6921700239181519,
      "epoch": 5.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16702359914779663,
      "orthogonal_weight": 0.1,
      "step": 1595,
      "total_loss": 0.708872377872467,
      "weighted_orthogonal_loss": 0.016702359542250633
    },
    {
      "classification_loss": 0.5837015509605408,
      "epoch": 5.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16712221503257751,
      "orthogonal_weight": 0.1,
      "step": 1596,
      "total_loss": 0.6004137992858887,
      "weighted_orthogonal_loss": 0.01671222224831581
    },
    {
      "classification_loss": 0.6583158373832703,
      "epoch": 5.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1672486662864685,
      "orthogonal_weight": 0.1,
      "step": 1597,
      "total_loss": 0.6750407218933105,
      "weighted_orthogonal_loss": 0.01672486774623394
    },
    {
      "classification_loss": 0.5992154479026794,
      "epoch": 5.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16750171780586243,
      "orthogonal_weight": 0.1,
      "step": 1598,
      "total_loss": 0.6159656047821045,
      "weighted_orthogonal_loss": 0.016750171780586243
    },
    {
      "classification_loss": 0.6443736553192139,
      "epoch": 5.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16775842010974884,
      "orthogonal_weight": 0.1,
      "step": 1599,
      "total_loss": 0.6611495018005371,
      "weighted_orthogonal_loss": 0.016775842756032944
    },
    {
      "epoch": 5.245901639344262,
      "grad_norm": 15.2339448928833,
      "learning_rate": 0.00015003333333333334,
      "loss": 0.6638,
      "step": 1600
    },
    {
      "classification_loss": 0.660859227180481,
      "epoch": 5.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16801650822162628,
      "orthogonal_weight": 0.1,
      "step": 1600,
      "total_loss": 0.6776608824729919,
      "weighted_orthogonal_loss": 0.016801651567220688
    },
    {
      "classification_loss": 0.5824858546257019,
      "epoch": 5.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1682816743850708,
      "orthogonal_weight": 0.1,
      "step": 1601,
      "total_loss": 0.5993140339851379,
      "weighted_orthogonal_loss": 0.01682816818356514
    },
    {
      "classification_loss": 0.5919020771980286,
      "epoch": 5.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687086671590805,
      "orthogonal_weight": 0.1,
      "step": 1602,
      "total_loss": 0.6087729334831238,
      "weighted_orthogonal_loss": 0.01687086746096611
    },
    {
      "classification_loss": 0.6215518712997437,
      "epoch": 5.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16913799941539764,
      "orthogonal_weight": 0.1,
      "step": 1603,
      "total_loss": 0.6384656429290771,
      "weighted_orthogonal_loss": 0.016913799569010735
    },
    {
      "classification_loss": 0.6959013342857361,
      "epoch": 5.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16954763233661652,
      "orthogonal_weight": 0.1,
      "step": 1604,
      "total_loss": 0.712856113910675,
      "weighted_orthogonal_loss": 0.016954762861132622
    },
    {
      "classification_loss": 0.6426951885223389,
      "epoch": 5.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16990172863006592,
      "orthogonal_weight": 0.1,
      "step": 1605,
      "total_loss": 0.6596853733062744,
      "weighted_orthogonal_loss": 0.01699017360806465
    },
    {
      "classification_loss": 0.5827280282974243,
      "epoch": 5.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1702023595571518,
      "orthogonal_weight": 0.1,
      "step": 1606,
      "total_loss": 0.5997482538223267,
      "weighted_orthogonal_loss": 0.01702023670077324
    },
    {
      "classification_loss": 0.619750440120697,
      "epoch": 5.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1704617291688919,
      "orthogonal_weight": 0.1,
      "step": 1607,
      "total_loss": 0.6367965936660767,
      "weighted_orthogonal_loss": 0.01704617403447628
    },
    {
      "classification_loss": 0.6485171914100647,
      "epoch": 5.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17076805233955383,
      "orthogonal_weight": 0.1,
      "step": 1608,
      "total_loss": 0.6655939817428589,
      "weighted_orthogonal_loss": 0.017076805233955383
    },
    {
      "classification_loss": 0.6554890275001526,
      "epoch": 5.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17113053798675537,
      "orthogonal_weight": 0.1,
      "step": 1609,
      "total_loss": 0.6726020574569702,
      "weighted_orthogonal_loss": 0.017113054171204567
    },
    {
      "classification_loss": 0.6939622163772583,
      "epoch": 5.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17130109667778015,
      "orthogonal_weight": 0.1,
      "step": 1610,
      "total_loss": 0.7110923528671265,
      "weighted_orthogonal_loss": 0.017130110412836075
    },
    {
      "classification_loss": 0.6609073877334595,
      "epoch": 5.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17158089578151703,
      "orthogonal_weight": 0.1,
      "step": 1611,
      "total_loss": 0.6780654788017273,
      "weighted_orthogonal_loss": 0.017158089205622673
    },
    {
      "classification_loss": 0.718752384185791,
      "epoch": 5.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17187198996543884,
      "orthogonal_weight": 0.1,
      "step": 1612,
      "total_loss": 0.7359395623207092,
      "weighted_orthogonal_loss": 0.017187198624014854
    },
    {
      "classification_loss": 0.6256684064865112,
      "epoch": 5.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17202046513557434,
      "orthogonal_weight": 0.1,
      "step": 1613,
      "total_loss": 0.6428704261779785,
      "weighted_orthogonal_loss": 0.017202047631144524
    },
    {
      "classification_loss": 0.6421108245849609,
      "epoch": 5.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17226003110408783,
      "orthogonal_weight": 0.1,
      "step": 1614,
      "total_loss": 0.6593368053436279,
      "weighted_orthogonal_loss": 0.017226003110408783
    },
    {
      "classification_loss": 0.6013475656509399,
      "epoch": 5.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17247138917446136,
      "orthogonal_weight": 0.1,
      "step": 1615,
      "total_loss": 0.6185947060585022,
      "weighted_orthogonal_loss": 0.017247138544917107
    },
    {
      "classification_loss": 0.5834155678749084,
      "epoch": 5.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726205199956894,
      "orthogonal_weight": 0.1,
      "step": 1616,
      "total_loss": 0.6006776094436646,
      "weighted_orthogonal_loss": 0.017262052744627
    },
    {
      "classification_loss": 0.6139799356460571,
      "epoch": 5.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17275851964950562,
      "orthogonal_weight": 0.1,
      "step": 1617,
      "total_loss": 0.6312558054924011,
      "weighted_orthogonal_loss": 0.01727585308253765
    },
    {
      "classification_loss": 0.5611152648925781,
      "epoch": 5.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17301274836063385,
      "orthogonal_weight": 0.1,
      "step": 1618,
      "total_loss": 0.5784165263175964,
      "weighted_orthogonal_loss": 0.017301274463534355
    },
    {
      "classification_loss": 0.7048636674880981,
      "epoch": 5.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17348358035087585,
      "orthogonal_weight": 0.1,
      "step": 1619,
      "total_loss": 0.722212016582489,
      "weighted_orthogonal_loss": 0.017348358407616615
    },
    {
      "classification_loss": 0.649937093257904,
      "epoch": 5.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737612783908844,
      "orthogonal_weight": 0.1,
      "step": 1620,
      "total_loss": 0.6673132181167603,
      "weighted_orthogonal_loss": 0.0173761285841465
    },
    {
      "classification_loss": 0.6829912066459656,
      "epoch": 5.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1740584820508957,
      "orthogonal_weight": 0.1,
      "step": 1621,
      "total_loss": 0.7003970742225647,
      "weighted_orthogonal_loss": 0.01740584895014763
    },
    {
      "classification_loss": 0.630784273147583,
      "epoch": 5.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17434054613113403,
      "orthogonal_weight": 0.1,
      "step": 1622,
      "total_loss": 0.6482183337211609,
      "weighted_orthogonal_loss": 0.017434054985642433
    },
    {
      "classification_loss": 0.6386786103248596,
      "epoch": 5.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746213138103485,
      "orthogonal_weight": 0.1,
      "step": 1623,
      "total_loss": 0.6561407446861267,
      "weighted_orthogonal_loss": 0.01746213249862194
    },
    {
      "classification_loss": 0.6791326403617859,
      "epoch": 5.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17498329281806946,
      "orthogonal_weight": 0.1,
      "step": 1624,
      "total_loss": 0.6966309547424316,
      "weighted_orthogonal_loss": 0.017498329281806946
    },
    {
      "classification_loss": 0.6683520674705505,
      "epoch": 5.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17534182965755463,
      "orthogonal_weight": 0.1,
      "step": 1625,
      "total_loss": 0.6858862638473511,
      "weighted_orthogonal_loss": 0.017534183338284492
    },
    {
      "classification_loss": 0.6834380030632019,
      "epoch": 5.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17573779821395874,
      "orthogonal_weight": 0.1,
      "step": 1626,
      "total_loss": 0.7010117769241333,
      "weighted_orthogonal_loss": 0.017573779448866844
    },
    {
      "classification_loss": 0.662335991859436,
      "epoch": 5.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17603975534439087,
      "orthogonal_weight": 0.1,
      "step": 1627,
      "total_loss": 0.6799399852752686,
      "weighted_orthogonal_loss": 0.017603976652026176
    },
    {
      "classification_loss": 0.6126276850700378,
      "epoch": 5.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1763755828142166,
      "orthogonal_weight": 0.1,
      "step": 1628,
      "total_loss": 0.6302652359008789,
      "weighted_orthogonal_loss": 0.01763755828142166
    },
    {
      "classification_loss": 0.6214967370033264,
      "epoch": 5.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17670591175556183,
      "orthogonal_weight": 0.1,
      "step": 1629,
      "total_loss": 0.639167308807373,
      "weighted_orthogonal_loss": 0.017670592293143272
    },
    {
      "classification_loss": 0.6598544716835022,
      "epoch": 5.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1770630031824112,
      "orthogonal_weight": 0.1,
      "step": 1630,
      "total_loss": 0.6775607466697693,
      "weighted_orthogonal_loss": 0.01770630106329918
    },
    {
      "classification_loss": 0.6954964995384216,
      "epoch": 5.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1771446019411087,
      "orthogonal_weight": 0.1,
      "step": 1631,
      "total_loss": 0.713210940361023,
      "weighted_orthogonal_loss": 0.01771446131169796
    },
    {
      "classification_loss": 0.6206545829772949,
      "epoch": 5.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17723149061203003,
      "orthogonal_weight": 0.1,
      "step": 1632,
      "total_loss": 0.6383777260780334,
      "weighted_orthogonal_loss": 0.017723148688673973
    },
    {
      "classification_loss": 0.6150932312011719,
      "epoch": 5.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17730404436588287,
      "orthogonal_weight": 0.1,
      "step": 1633,
      "total_loss": 0.632823646068573,
      "weighted_orthogonal_loss": 0.017730405554175377
    },
    {
      "classification_loss": 0.6542022228240967,
      "epoch": 5.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17749901115894318,
      "orthogonal_weight": 0.1,
      "step": 1634,
      "total_loss": 0.6719521284103394,
      "weighted_orthogonal_loss": 0.017749901860952377
    },
    {
      "classification_loss": 0.624636709690094,
      "epoch": 5.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17763809859752655,
      "orthogonal_weight": 0.1,
      "step": 1635,
      "total_loss": 0.6424005031585693,
      "weighted_orthogonal_loss": 0.017763810232281685
    },
    {
      "classification_loss": 0.6860044598579407,
      "epoch": 5.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1778988242149353,
      "orthogonal_weight": 0.1,
      "step": 1636,
      "total_loss": 0.7037943601608276,
      "weighted_orthogonal_loss": 0.01778988353908062
    },
    {
      "classification_loss": 0.646099865436554,
      "epoch": 5.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17807571589946747,
      "orthogonal_weight": 0.1,
      "step": 1637,
      "total_loss": 0.6639074087142944,
      "weighted_orthogonal_loss": 0.017807571217417717
    },
    {
      "classification_loss": 0.651850700378418,
      "epoch": 5.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1781732141971588,
      "orthogonal_weight": 0.1,
      "step": 1638,
      "total_loss": 0.6696680188179016,
      "weighted_orthogonal_loss": 0.01781732216477394
    },
    {
      "classification_loss": 0.662514865398407,
      "epoch": 5.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17828316986560822,
      "orthogonal_weight": 0.1,
      "step": 1639,
      "total_loss": 0.6803432106971741,
      "weighted_orthogonal_loss": 0.01782831735908985
    },
    {
      "classification_loss": 0.6634156703948975,
      "epoch": 5.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1782938539981842,
      "orthogonal_weight": 0.1,
      "step": 1640,
      "total_loss": 0.6812450289726257,
      "weighted_orthogonal_loss": 0.01782938651740551
    },
    {
      "classification_loss": 0.6781746745109558,
      "epoch": 5.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17823147773742676,
      "orthogonal_weight": 0.1,
      "step": 1641,
      "total_loss": 0.6959978342056274,
      "weighted_orthogonal_loss": 0.017823148518800735
    },
    {
      "classification_loss": 0.6424873471260071,
      "epoch": 5.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17813369631767273,
      "orthogonal_weight": 0.1,
      "step": 1642,
      "total_loss": 0.6603007316589355,
      "weighted_orthogonal_loss": 0.017813369631767273
    },
    {
      "classification_loss": 0.6761037111282349,
      "epoch": 5.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17804184556007385,
      "orthogonal_weight": 0.1,
      "step": 1643,
      "total_loss": 0.6939079165458679,
      "weighted_orthogonal_loss": 0.017804184928536415
    },
    {
      "classification_loss": 0.6524102091789246,
      "epoch": 5.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17792613804340363,
      "orthogonal_weight": 0.1,
      "step": 1644,
      "total_loss": 0.6702028512954712,
      "weighted_orthogonal_loss": 0.017792614176869392
    },
    {
      "classification_loss": 0.6039673089981079,
      "epoch": 5.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17776785790920258,
      "orthogonal_weight": 0.1,
      "step": 1645,
      "total_loss": 0.6217440962791443,
      "weighted_orthogonal_loss": 0.017776785418391228
    },
    {
      "classification_loss": 0.6824022531509399,
      "epoch": 5.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17756304144859314,
      "orthogonal_weight": 0.1,
      "step": 1646,
      "total_loss": 0.7001585364341736,
      "weighted_orthogonal_loss": 0.017756303772330284
    },
    {
      "classification_loss": 0.6268479228019714,
      "epoch": 5.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17732194066047668,
      "orthogonal_weight": 0.1,
      "step": 1647,
      "total_loss": 0.6445801258087158,
      "weighted_orthogonal_loss": 0.01773219369351864
    },
    {
      "classification_loss": 0.6517366170883179,
      "epoch": 5.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17668886482715607,
      "orthogonal_weight": 0.1,
      "step": 1648,
      "total_loss": 0.6694055199623108,
      "weighted_orthogonal_loss": 0.017668886110186577
    },
    {
      "classification_loss": 0.6527358889579773,
      "epoch": 5.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17614392936229706,
      "orthogonal_weight": 0.1,
      "step": 1649,
      "total_loss": 0.6703502535820007,
      "weighted_orthogonal_loss": 0.017614392563700676
    },
    {
      "classification_loss": 0.6722487211227417,
      "epoch": 5.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17540203034877777,
      "orthogonal_weight": 0.1,
      "step": 1650,
      "total_loss": 0.6897889375686646,
      "weighted_orthogonal_loss": 0.017540203407406807
    },
    {
      "classification_loss": 0.7760205864906311,
      "epoch": 5.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17474029958248138,
      "orthogonal_weight": 0.1,
      "step": 1651,
      "total_loss": 0.7934946417808533,
      "weighted_orthogonal_loss": 0.017474031075835228
    },
    {
      "classification_loss": 0.7066853046417236,
      "epoch": 5.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17420725524425507,
      "orthogonal_weight": 0.1,
      "step": 1652,
      "total_loss": 0.7241060137748718,
      "weighted_orthogonal_loss": 0.017420725896954536
    },
    {
      "classification_loss": 0.6498019695281982,
      "epoch": 5.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737682819366455,
      "orthogonal_weight": 0.1,
      "step": 1653,
      "total_loss": 0.6671788096427917,
      "weighted_orthogonal_loss": 0.01737682893872261
    },
    {
      "classification_loss": 0.6353656053543091,
      "epoch": 5.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1733948290348053,
      "orthogonal_weight": 0.1,
      "step": 1654,
      "total_loss": 0.6527050733566284,
      "weighted_orthogonal_loss": 0.01733948290348053
    },
    {
      "classification_loss": 0.6417276859283447,
      "epoch": 5.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1730564683675766,
      "orthogonal_weight": 0.1,
      "step": 1655,
      "total_loss": 0.6590333580970764,
      "weighted_orthogonal_loss": 0.01730564795434475
    },
    {
      "classification_loss": 0.6520147919654846,
      "epoch": 5.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17280863225460052,
      "orthogonal_weight": 0.1,
      "step": 1656,
      "total_loss": 0.6692956686019897,
      "weighted_orthogonal_loss": 0.017280863597989082
    },
    {
      "classification_loss": 0.654247522354126,
      "epoch": 5.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17264150083065033,
      "orthogonal_weight": 0.1,
      "step": 1657,
      "total_loss": 0.6715116500854492,
      "weighted_orthogonal_loss": 0.017264150083065033
    },
    {
      "classification_loss": 0.6663828492164612,
      "epoch": 5.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17254693806171417,
      "orthogonal_weight": 0.1,
      "step": 1658,
      "total_loss": 0.6836375594139099,
      "weighted_orthogonal_loss": 0.017254693433642387
    },
    {
      "classification_loss": 0.6175025701522827,
      "epoch": 5.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17248864471912384,
      "orthogonal_weight": 0.1,
      "step": 1659,
      "total_loss": 0.6347514390945435,
      "weighted_orthogonal_loss": 0.017248865216970444
    },
    {
      "classification_loss": 0.6056497097015381,
      "epoch": 5.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17248326539993286,
      "orthogonal_weight": 0.1,
      "step": 1660,
      "total_loss": 0.6228980422019958,
      "weighted_orthogonal_loss": 0.017248326912522316
    },
    {
      "classification_loss": 0.6721258163452148,
      "epoch": 5.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1724950224161148,
      "orthogonal_weight": 0.1,
      "step": 1661,
      "total_loss": 0.6893753409385681,
      "weighted_orthogonal_loss": 0.01724950224161148
    },
    {
      "classification_loss": 0.6666698455810547,
      "epoch": 5.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17242538928985596,
      "orthogonal_weight": 0.1,
      "step": 1662,
      "total_loss": 0.6839123964309692,
      "weighted_orthogonal_loss": 0.017242539674043655
    },
    {
      "classification_loss": 0.6294615268707275,
      "epoch": 5.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1723916381597519,
      "orthogonal_weight": 0.1,
      "step": 1663,
      "total_loss": 0.6467006802558899,
      "weighted_orthogonal_loss": 0.01723916456103325
    },
    {
      "classification_loss": 0.6228975653648376,
      "epoch": 5.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17245760560035706,
      "orthogonal_weight": 0.1,
      "step": 1664,
      "total_loss": 0.6401433348655701,
      "weighted_orthogonal_loss": 0.017245760187506676
    },
    {
      "classification_loss": 0.6590908765792847,
      "epoch": 5.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17260904610157013,
      "orthogonal_weight": 0.1,
      "step": 1665,
      "total_loss": 0.67635178565979,
      "weighted_orthogonal_loss": 0.017260905355215073
    },
    {
      "classification_loss": 0.687759280204773,
      "epoch": 5.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1726001501083374,
      "orthogonal_weight": 0.1,
      "step": 1666,
      "total_loss": 0.7050192952156067,
      "weighted_orthogonal_loss": 0.01726001501083374
    },
    {
      "classification_loss": 0.6281698346138,
      "epoch": 5.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17278191447257996,
      "orthogonal_weight": 0.1,
      "step": 1667,
      "total_loss": 0.6454480290412903,
      "weighted_orthogonal_loss": 0.017278192564845085
    },
    {
      "classification_loss": 0.6097894310951233,
      "epoch": 5.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1728593409061432,
      "orthogonal_weight": 0.1,
      "step": 1668,
      "total_loss": 0.6270753741264343,
      "weighted_orthogonal_loss": 0.01728593371808529
    },
    {
      "classification_loss": 0.6337709426879883,
      "epoch": 5.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17295421659946442,
      "orthogonal_weight": 0.1,
      "step": 1669,
      "total_loss": 0.6510663628578186,
      "weighted_orthogonal_loss": 0.01729542203247547
    },
    {
      "classification_loss": 0.6396743059158325,
      "epoch": 5.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17304454743862152,
      "orthogonal_weight": 0.1,
      "step": 1670,
      "total_loss": 0.6569787859916687,
      "weighted_orthogonal_loss": 0.01730445586144924
    },
    {
      "classification_loss": 0.5604592561721802,
      "epoch": 5.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17309348285198212,
      "orthogonal_weight": 0.1,
      "step": 1671,
      "total_loss": 0.5777686238288879,
      "weighted_orthogonal_loss": 0.01730934903025627
    },
    {
      "classification_loss": 0.6884263753890991,
      "epoch": 5.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17321211099624634,
      "orthogonal_weight": 0.1,
      "step": 1672,
      "total_loss": 0.7057476043701172,
      "weighted_orthogonal_loss": 0.017321212217211723
    },
    {
      "classification_loss": 0.6431223750114441,
      "epoch": 5.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17316527664661407,
      "orthogonal_weight": 0.1,
      "step": 1673,
      "total_loss": 0.6604388952255249,
      "weighted_orthogonal_loss": 0.017316527664661407
    },
    {
      "classification_loss": 0.6320978403091431,
      "epoch": 5.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1731395572423935,
      "orthogonal_weight": 0.1,
      "step": 1674,
      "total_loss": 0.6494117975234985,
      "weighted_orthogonal_loss": 0.01731395535171032
    },
    {
      "classification_loss": 0.5881766676902771,
      "epoch": 5.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17306838929653168,
      "orthogonal_weight": 0.1,
      "step": 1675,
      "total_loss": 0.6054835319519043,
      "weighted_orthogonal_loss": 0.017306840047240257
    },
    {
      "classification_loss": 0.7068535685539246,
      "epoch": 5.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17322811484336853,
      "orthogonal_weight": 0.1,
      "step": 1676,
      "total_loss": 0.7241764068603516,
      "weighted_orthogonal_loss": 0.017322812229394913
    },
    {
      "classification_loss": 0.673700749874115,
      "epoch": 5.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17335578799247742,
      "orthogonal_weight": 0.1,
      "step": 1677,
      "total_loss": 0.6910363435745239,
      "weighted_orthogonal_loss": 0.01733557879924774
    },
    {
      "classification_loss": 0.6665583848953247,
      "epoch": 5.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17353801429271698,
      "orthogonal_weight": 0.1,
      "step": 1678,
      "total_loss": 0.6839121580123901,
      "weighted_orthogonal_loss": 0.017353801056742668
    },
    {
      "classification_loss": 0.6613678336143494,
      "epoch": 5.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1736895591020584,
      "orthogonal_weight": 0.1,
      "step": 1679,
      "total_loss": 0.6787368059158325,
      "weighted_orthogonal_loss": 0.01736895553767681
    },
    {
      "classification_loss": 0.638709545135498,
      "epoch": 5.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17378723621368408,
      "orthogonal_weight": 0.1,
      "step": 1680,
      "total_loss": 0.6560882925987244,
      "weighted_orthogonal_loss": 0.01737872324883938
    },
    {
      "classification_loss": 0.6332820057868958,
      "epoch": 5.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1738370656967163,
      "orthogonal_weight": 0.1,
      "step": 1681,
      "total_loss": 0.6506657004356384,
      "weighted_orthogonal_loss": 0.01738370768725872
    },
    {
      "classification_loss": 0.6734911203384399,
      "epoch": 5.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17394454777240753,
      "orthogonal_weight": 0.1,
      "step": 1682,
      "total_loss": 0.690885603427887,
      "weighted_orthogonal_loss": 0.017394455149769783
    },
    {
      "classification_loss": 0.6503857970237732,
      "epoch": 5.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1740102618932724,
      "orthogonal_weight": 0.1,
      "step": 1683,
      "total_loss": 0.6677868366241455,
      "weighted_orthogonal_loss": 0.01740102656185627
    },
    {
      "classification_loss": 0.6357021331787109,
      "epoch": 5.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17382808029651642,
      "orthogonal_weight": 0.1,
      "step": 1684,
      "total_loss": 0.653084933757782,
      "weighted_orthogonal_loss": 0.017382808029651642
    },
    {
      "classification_loss": 0.6683855652809143,
      "epoch": 5.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737254112958908,
      "orthogonal_weight": 0.1,
      "step": 1685,
      "total_loss": 0.685758113861084,
      "weighted_orthogonal_loss": 0.01737254112958908
    },
    {
      "classification_loss": 0.6495146751403809,
      "epoch": 5.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17352350056171417,
      "orthogonal_weight": 0.1,
      "step": 1686,
      "total_loss": 0.6668670177459717,
      "weighted_orthogonal_loss": 0.017352350056171417
    },
    {
      "classification_loss": 0.6066989302635193,
      "epoch": 5.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17324553430080414,
      "orthogonal_weight": 0.1,
      "step": 1687,
      "total_loss": 0.6240234971046448,
      "weighted_orthogonal_loss": 0.017324553802609444
    },
    {
      "classification_loss": 0.6144248843193054,
      "epoch": 5.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17316870391368866,
      "orthogonal_weight": 0.1,
      "step": 1688,
      "total_loss": 0.6317417621612549,
      "weighted_orthogonal_loss": 0.017316870391368866
    },
    {
      "classification_loss": 0.6688107252120972,
      "epoch": 5.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17319922149181366,
      "orthogonal_weight": 0.1,
      "step": 1689,
      "total_loss": 0.6861306428909302,
      "weighted_orthogonal_loss": 0.017319923266768456
    },
    {
      "classification_loss": 0.5921868681907654,
      "epoch": 5.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17329324781894684,
      "orthogonal_weight": 0.1,
      "step": 1690,
      "total_loss": 0.6095162034034729,
      "weighted_orthogonal_loss": 0.017329325899481773
    },
    {
      "classification_loss": 0.7083170413970947,
      "epoch": 5.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17347829043865204,
      "orthogonal_weight": 0.1,
      "step": 1691,
      "total_loss": 0.7256648540496826,
      "weighted_orthogonal_loss": 0.017347829416394234
    },
    {
      "classification_loss": 0.6623518466949463,
      "epoch": 5.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1735558658838272,
      "orthogonal_weight": 0.1,
      "step": 1692,
      "total_loss": 0.679707407951355,
      "weighted_orthogonal_loss": 0.01735558733344078
    },
    {
      "classification_loss": 0.6139780282974243,
      "epoch": 5.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1735730618238449,
      "orthogonal_weight": 0.1,
      "step": 1693,
      "total_loss": 0.6313353180885315,
      "weighted_orthogonal_loss": 0.01735730655491352
    },
    {
      "classification_loss": 0.6534650325775146,
      "epoch": 5.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1736658364534378,
      "orthogonal_weight": 0.1,
      "step": 1694,
      "total_loss": 0.6708316206932068,
      "weighted_orthogonal_loss": 0.01736658439040184
    },
    {
      "classification_loss": 0.6617529392242432,
      "epoch": 5.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17369626462459564,
      "orthogonal_weight": 0.1,
      "step": 1695,
      "total_loss": 0.6791225671768188,
      "weighted_orthogonal_loss": 0.017369626089930534
    },
    {
      "classification_loss": 0.6414620280265808,
      "epoch": 5.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1737355887889862,
      "orthogonal_weight": 0.1,
      "step": 1696,
      "total_loss": 0.6588355898857117,
      "weighted_orthogonal_loss": 0.01737355999648571
    },
    {
      "classification_loss": 0.6753622889518738,
      "epoch": 5.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17383530735969543,
      "orthogonal_weight": 0.1,
      "step": 1697,
      "total_loss": 0.6927458047866821,
      "weighted_orthogonal_loss": 0.017383530735969543
    },
    {
      "classification_loss": 0.5933992862701416,
      "epoch": 5.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1739668846130371,
      "orthogonal_weight": 0.1,
      "step": 1698,
      "total_loss": 0.6107959747314453,
      "weighted_orthogonal_loss": 0.01739668846130371
    },
    {
      "classification_loss": 0.6559333801269531,
      "epoch": 5.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17411823570728302,
      "orthogonal_weight": 0.1,
      "step": 1699,
      "total_loss": 0.6733452081680298,
      "weighted_orthogonal_loss": 0.01741182431578636
    },
    {
      "epoch": 5.573770491803279,
      "grad_norm": 5.8926615715026855,
      "learning_rate": 0.00014670000000000002,
      "loss": 0.6647,
      "step": 1700
    },
    {
      "classification_loss": 0.7129666209220886,
      "epoch": 5.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17431579530239105,
      "orthogonal_weight": 0.1,
      "step": 1700,
      "total_loss": 0.7303981781005859,
      "weighted_orthogonal_loss": 0.017431579530239105
    },
    {
      "classification_loss": 0.6201524138450623,
      "epoch": 5.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17424441874027252,
      "orthogonal_weight": 0.1,
      "step": 1701,
      "total_loss": 0.6375768780708313,
      "weighted_orthogonal_loss": 0.017424441874027252
    },
    {
      "classification_loss": 0.6557439565658569,
      "epoch": 5.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1742108166217804,
      "orthogonal_weight": 0.1,
      "step": 1702,
      "total_loss": 0.6731650233268738,
      "weighted_orthogonal_loss": 0.01742108166217804
    },
    {
      "classification_loss": 0.6206724047660828,
      "epoch": 5.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17449180781841278,
      "orthogonal_weight": 0.1,
      "step": 1703,
      "total_loss": 0.6381216049194336,
      "weighted_orthogonal_loss": 0.017449181526899338
    },
    {
      "classification_loss": 0.6288803815841675,
      "epoch": 5.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746215969324112,
      "orthogonal_weight": 0.1,
      "step": 1704,
      "total_loss": 0.6463425159454346,
      "weighted_orthogonal_loss": 0.01746216043829918
    },
    {
      "classification_loss": 0.6719655990600586,
      "epoch": 5.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1747940629720688,
      "orthogonal_weight": 0.1,
      "step": 1705,
      "total_loss": 0.6894450187683105,
      "weighted_orthogonal_loss": 0.01747940666973591
    },
    {
      "classification_loss": 0.6555918455123901,
      "epoch": 5.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17428375780582428,
      "orthogonal_weight": 0.1,
      "step": 1706,
      "total_loss": 0.6730202436447144,
      "weighted_orthogonal_loss": 0.017428375780582428
    },
    {
      "classification_loss": 0.654662549495697,
      "epoch": 5.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17388418316841125,
      "orthogonal_weight": 0.1,
      "step": 1707,
      "total_loss": 0.672050952911377,
      "weighted_orthogonal_loss": 0.017388418316841125
    },
    {
      "classification_loss": 0.6426043510437012,
      "epoch": 5.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17350348830223083,
      "orthogonal_weight": 0.1,
      "step": 1708,
      "total_loss": 0.6599547266960144,
      "weighted_orthogonal_loss": 0.017350349575281143
    },
    {
      "classification_loss": 0.6049043536186218,
      "epoch": 5.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17310327291488647,
      "orthogonal_weight": 0.1,
      "step": 1709,
      "total_loss": 0.622214674949646,
      "weighted_orthogonal_loss": 0.017310326918959618
    },
    {
      "classification_loss": 0.6650745868682861,
      "epoch": 5.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17275559902191162,
      "orthogonal_weight": 0.1,
      "step": 1710,
      "total_loss": 0.6823501586914062,
      "weighted_orthogonal_loss": 0.017275560647249222
    },
    {
      "classification_loss": 0.65084308385849,
      "epoch": 5.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17243576049804688,
      "orthogonal_weight": 0.1,
      "step": 1711,
      "total_loss": 0.6680866479873657,
      "weighted_orthogonal_loss": 0.017243577167391777
    },
    {
      "classification_loss": 0.712444543838501,
      "epoch": 5.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1715303510427475,
      "orthogonal_weight": 0.1,
      "step": 1712,
      "total_loss": 0.7295975685119629,
      "weighted_orthogonal_loss": 0.01715303584933281
    },
    {
      "classification_loss": 0.612546443939209,
      "epoch": 5.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17077133059501648,
      "orthogonal_weight": 0.1,
      "step": 1713,
      "total_loss": 0.6296235918998718,
      "weighted_orthogonal_loss": 0.017077133059501648
    },
    {
      "classification_loss": 0.6738563179969788,
      "epoch": 5.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17004279792308807,
      "orthogonal_weight": 0.1,
      "step": 1714,
      "total_loss": 0.6908605694770813,
      "weighted_orthogonal_loss": 0.017004279419779778
    },
    {
      "classification_loss": 0.6517181396484375,
      "epoch": 5.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1693735122680664,
      "orthogonal_weight": 0.1,
      "step": 1715,
      "total_loss": 0.668655514717102,
      "weighted_orthogonal_loss": 0.01693735085427761
    },
    {
      "classification_loss": 0.6127737164497375,
      "epoch": 5.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1687622368335724,
      "orthogonal_weight": 0.1,
      "step": 1716,
      "total_loss": 0.6296499371528625,
      "weighted_orthogonal_loss": 0.0168762244284153
    },
    {
      "classification_loss": 0.6430842280387878,
      "epoch": 5.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16823318600654602,
      "orthogonal_weight": 0.1,
      "step": 1717,
      "total_loss": 0.6599075198173523,
      "weighted_orthogonal_loss": 0.01682331971824169
    },
    {
      "classification_loss": 0.6516420841217041,
      "epoch": 5.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16746869683265686,
      "orthogonal_weight": 0.1,
      "step": 1718,
      "total_loss": 0.6683889627456665,
      "weighted_orthogonal_loss": 0.016746869310736656
    },
    {
      "classification_loss": 0.6559708714485168,
      "epoch": 5.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16689352691173553,
      "orthogonal_weight": 0.1,
      "step": 1719,
      "total_loss": 0.672660231590271,
      "weighted_orthogonal_loss": 0.016689352691173553
    },
    {
      "classification_loss": 0.6742166876792908,
      "epoch": 5.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16639280319213867,
      "orthogonal_weight": 0.1,
      "step": 1720,
      "total_loss": 0.6908559799194336,
      "weighted_orthogonal_loss": 0.016639281064271927
    },
    {
      "classification_loss": 0.6458649039268494,
      "epoch": 5.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16596420109272003,
      "orthogonal_weight": 0.1,
      "step": 1721,
      "total_loss": 0.6624613404273987,
      "weighted_orthogonal_loss": 0.016596419736742973
    },
    {
      "classification_loss": 0.6022536754608154,
      "epoch": 5.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16557545959949493,
      "orthogonal_weight": 0.1,
      "step": 1722,
      "total_loss": 0.6188112497329712,
      "weighted_orthogonal_loss": 0.016557546332478523
    },
    {
      "classification_loss": 0.6231856942176819,
      "epoch": 5.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16528035700321198,
      "orthogonal_weight": 0.1,
      "step": 1723,
      "total_loss": 0.639713704586029,
      "weighted_orthogonal_loss": 0.016528036445379257
    },
    {
      "classification_loss": 0.6264762282371521,
      "epoch": 5.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16506749391555786,
      "orthogonal_weight": 0.1,
      "step": 1724,
      "total_loss": 0.6429829597473145,
      "weighted_orthogonal_loss": 0.016506750136613846
    },
    {
      "classification_loss": 0.6563029289245605,
      "epoch": 5.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16494391858577728,
      "orthogonal_weight": 0.1,
      "step": 1725,
      "total_loss": 0.6727973222732544,
      "weighted_orthogonal_loss": 0.0164943914860487
    },
    {
      "classification_loss": 0.6293474435806274,
      "epoch": 5.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.164841428399086,
      "orthogonal_weight": 0.1,
      "step": 1726,
      "total_loss": 0.6458315849304199,
      "weighted_orthogonal_loss": 0.01648414321243763
    },
    {
      "classification_loss": 0.6769880652427673,
      "epoch": 5.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16472361981868744,
      "orthogonal_weight": 0.1,
      "step": 1727,
      "total_loss": 0.6934604048728943,
      "weighted_orthogonal_loss": 0.016472361981868744
    },
    {
      "classification_loss": 0.7203363180160522,
      "epoch": 5.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16451802849769592,
      "orthogonal_weight": 0.1,
      "step": 1728,
      "total_loss": 0.7367880940437317,
      "weighted_orthogonal_loss": 0.016451803967356682
    },
    {
      "classification_loss": 0.6462860107421875,
      "epoch": 5.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16432560980319977,
      "orthogonal_weight": 0.1,
      "step": 1729,
      "total_loss": 0.6627185940742493,
      "weighted_orthogonal_loss": 0.016432560980319977
    },
    {
      "classification_loss": 0.667766273021698,
      "epoch": 5.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16421115398406982,
      "orthogonal_weight": 0.1,
      "step": 1730,
      "total_loss": 0.6841874122619629,
      "weighted_orthogonal_loss": 0.016421115025877953
    },
    {
      "classification_loss": 0.6608986854553223,
      "epoch": 5.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16409660875797272,
      "orthogonal_weight": 0.1,
      "step": 1731,
      "total_loss": 0.6773083209991455,
      "weighted_orthogonal_loss": 0.01640966162085533
    },
    {
      "classification_loss": 0.5954743027687073,
      "epoch": 5.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640091985464096,
      "orthogonal_weight": 0.1,
      "step": 1732,
      "total_loss": 0.6118752360343933,
      "weighted_orthogonal_loss": 0.01640092022716999
    },
    {
      "classification_loss": 0.662136435508728,
      "epoch": 5.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16391444206237793,
      "orthogonal_weight": 0.1,
      "step": 1733,
      "total_loss": 0.6785278916358948,
      "weighted_orthogonal_loss": 0.016391444951295853
    },
    {
      "classification_loss": 0.6242172122001648,
      "epoch": 5.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16383050382137299,
      "orthogonal_weight": 0.1,
      "step": 1734,
      "total_loss": 0.6406002640724182,
      "weighted_orthogonal_loss": 0.01638305000960827
    },
    {
      "classification_loss": 0.6372223496437073,
      "epoch": 5.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16372708976268768,
      "orthogonal_weight": 0.1,
      "step": 1735,
      "total_loss": 0.6535950303077698,
      "weighted_orthogonal_loss": 0.01637270860373974
    },
    {
      "classification_loss": 0.6713642477989197,
      "epoch": 5.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1635984629392624,
      "orthogonal_weight": 0.1,
      "step": 1736,
      "total_loss": 0.6877241134643555,
      "weighted_orthogonal_loss": 0.0163598470389843
    },
    {
      "classification_loss": 0.664101243019104,
      "epoch": 5.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16345934569835663,
      "orthogonal_weight": 0.1,
      "step": 1737,
      "total_loss": 0.6804471611976624,
      "weighted_orthogonal_loss": 0.016345934942364693
    },
    {
      "classification_loss": 0.6151992678642273,
      "epoch": 5.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16332152485847473,
      "orthogonal_weight": 0.1,
      "step": 1738,
      "total_loss": 0.6315314173698425,
      "weighted_orthogonal_loss": 0.016332153230905533
    },
    {
      "classification_loss": 0.6450965404510498,
      "epoch": 5.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1632899045944214,
      "orthogonal_weight": 0.1,
      "step": 1739,
      "total_loss": 0.6614255309104919,
      "weighted_orthogonal_loss": 0.01632899045944214
    },
    {
      "classification_loss": 0.6045035123825073,
      "epoch": 5.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16332028806209564,
      "orthogonal_weight": 0.1,
      "step": 1740,
      "total_loss": 0.620835542678833,
      "weighted_orthogonal_loss": 0.016332028433680534
    },
    {
      "classification_loss": 0.701342761516571,
      "epoch": 5.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335757076740265,
      "orthogonal_weight": 0.1,
      "step": 1741,
      "total_loss": 0.7176785469055176,
      "weighted_orthogonal_loss": 0.016335757449269295
    },
    {
      "classification_loss": 0.6428819298744202,
      "epoch": 5.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1632147580385208,
      "orthogonal_weight": 0.1,
      "step": 1742,
      "total_loss": 0.6592034101486206,
      "weighted_orthogonal_loss": 0.01632147654891014
    },
    {
      "classification_loss": 0.6888085007667542,
      "epoch": 5.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16308121383190155,
      "orthogonal_weight": 0.1,
      "step": 1743,
      "total_loss": 0.7051166296005249,
      "weighted_orthogonal_loss": 0.016308121383190155
    },
    {
      "classification_loss": 0.6494780778884888,
      "epoch": 5.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16287179291248322,
      "orthogonal_weight": 0.1,
      "step": 1744,
      "total_loss": 0.6657652854919434,
      "weighted_orthogonal_loss": 0.01628717966377735
    },
    {
      "classification_loss": 0.6472167372703552,
      "epoch": 5.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16267578303813934,
      "orthogonal_weight": 0.1,
      "step": 1745,
      "total_loss": 0.6634843349456787,
      "weighted_orthogonal_loss": 0.016267579048871994
    },
    {
      "classification_loss": 0.6392390131950378,
      "epoch": 5.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16250503063201904,
      "orthogonal_weight": 0.1,
      "step": 1746,
      "total_loss": 0.6554895043373108,
      "weighted_orthogonal_loss": 0.016250504180788994
    },
    {
      "classification_loss": 0.6623365879058838,
      "epoch": 5.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16241969168186188,
      "orthogonal_weight": 0.1,
      "step": 1747,
      "total_loss": 0.6785785555839539,
      "weighted_orthogonal_loss": 0.016241969540715218
    },
    {
      "classification_loss": 0.6861165165901184,
      "epoch": 5.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16233548521995544,
      "orthogonal_weight": 0.1,
      "step": 1748,
      "total_loss": 0.7023500800132751,
      "weighted_orthogonal_loss": 0.016233548521995544
    },
    {
      "classification_loss": 0.650903582572937,
      "epoch": 5.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1622048318386078,
      "orthogonal_weight": 0.1,
      "step": 1749,
      "total_loss": 0.6671240925788879,
      "weighted_orthogonal_loss": 0.01622048392891884
    },
    {
      "classification_loss": 0.6529428958892822,
      "epoch": 5.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16204123198986053,
      "orthogonal_weight": 0.1,
      "step": 1750,
      "total_loss": 0.6691470146179199,
      "weighted_orthogonal_loss": 0.016204124316573143
    },
    {
      "classification_loss": 0.6397039890289307,
      "epoch": 5.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16191859543323517,
      "orthogonal_weight": 0.1,
      "step": 1751,
      "total_loss": 0.6558958292007446,
      "weighted_orthogonal_loss": 0.016191860660910606
    },
    {
      "classification_loss": 0.6627450585365295,
      "epoch": 5.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16175192594528198,
      "orthogonal_weight": 0.1,
      "step": 1752,
      "total_loss": 0.6789202690124512,
      "weighted_orthogonal_loss": 0.016175193712115288
    },
    {
      "classification_loss": 0.6446070075035095,
      "epoch": 5.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16163676977157593,
      "orthogonal_weight": 0.1,
      "step": 1753,
      "total_loss": 0.6607706546783447,
      "weighted_orthogonal_loss": 0.016163676977157593
    },
    {
      "classification_loss": 0.6552030444145203,
      "epoch": 5.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615048050880432,
      "orthogonal_weight": 0.1,
      "step": 1754,
      "total_loss": 0.6713535189628601,
      "weighted_orthogonal_loss": 0.01615048013627529
    },
    {
      "classification_loss": 0.676072359085083,
      "epoch": 5.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1613302230834961,
      "orthogonal_weight": 0.1,
      "step": 1755,
      "total_loss": 0.6922053694725037,
      "weighted_orthogonal_loss": 0.0161330234259367
    },
    {
      "classification_loss": 0.6777895092964172,
      "epoch": 5.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1612086296081543,
      "orthogonal_weight": 0.1,
      "step": 1756,
      "total_loss": 0.6939103603363037,
      "weighted_orthogonal_loss": 0.01612086407840252
    },
    {
      "classification_loss": 0.6294226050376892,
      "epoch": 5.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16092318296432495,
      "orthogonal_weight": 0.1,
      "step": 1757,
      "total_loss": 0.6455149054527283,
      "weighted_orthogonal_loss": 0.016092319041490555
    },
    {
      "classification_loss": 0.6189154982566833,
      "epoch": 5.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16070713102817535,
      "orthogonal_weight": 0.1,
      "step": 1758,
      "total_loss": 0.6349862217903137,
      "weighted_orthogonal_loss": 0.016070714220404625
    },
    {
      "classification_loss": 0.6771746277809143,
      "epoch": 5.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16061101853847504,
      "orthogonal_weight": 0.1,
      "step": 1759,
      "total_loss": 0.6932357549667358,
      "weighted_orthogonal_loss": 0.016061102971434593
    },
    {
      "classification_loss": 0.6777815818786621,
      "epoch": 5.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605139970779419,
      "orthogonal_weight": 0.1,
      "step": 1760,
      "total_loss": 0.6938329935073853,
      "weighted_orthogonal_loss": 0.01605140045285225
    },
    {
      "classification_loss": 0.610298216342926,
      "epoch": 5.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16049882769584656,
      "orthogonal_weight": 0.1,
      "step": 1761,
      "total_loss": 0.626348078250885,
      "weighted_orthogonal_loss": 0.016049882397055626
    },
    {
      "classification_loss": 0.6758063435554504,
      "epoch": 5.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16051089763641357,
      "orthogonal_weight": 0.1,
      "step": 1762,
      "total_loss": 0.6918574571609497,
      "weighted_orthogonal_loss": 0.016051089391112328
    },
    {
      "classification_loss": 0.6048843264579773,
      "epoch": 5.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16055722534656525,
      "orthogonal_weight": 0.1,
      "step": 1763,
      "total_loss": 0.6209400296211243,
      "weighted_orthogonal_loss": 0.016055723652243614
    },
    {
      "classification_loss": 0.6638659238815308,
      "epoch": 5.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16061845421791077,
      "orthogonal_weight": 0.1,
      "step": 1764,
      "total_loss": 0.6799277663230896,
      "weighted_orthogonal_loss": 0.016061846166849136
    },
    {
      "classification_loss": 0.6154826879501343,
      "epoch": 5.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16056428849697113,
      "orthogonal_weight": 0.1,
      "step": 1765,
      "total_loss": 0.6315391063690186,
      "weighted_orthogonal_loss": 0.016056429594755173
    },
    {
      "classification_loss": 0.6218284964561462,
      "epoch": 5.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054384410381317,
      "orthogonal_weight": 0.1,
      "step": 1766,
      "total_loss": 0.6378828883171082,
      "weighted_orthogonal_loss": 0.016054384410381317
    },
    {
      "classification_loss": 0.6577534675598145,
      "epoch": 5.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054534912109375,
      "orthogonal_weight": 0.1,
      "step": 1767,
      "total_loss": 0.6738079786300659,
      "weighted_orthogonal_loss": 0.016054535284638405
    },
    {
      "classification_loss": 0.6548505425453186,
      "epoch": 5.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16054154932498932,
      "orthogonal_weight": 0.1,
      "step": 1768,
      "total_loss": 0.6709046959877014,
      "weighted_orthogonal_loss": 0.01605415530502796
    },
    {
      "classification_loss": 0.6120320558547974,
      "epoch": 5.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605483740568161,
      "orthogonal_weight": 0.1,
      "step": 1769,
      "total_loss": 0.6280868649482727,
      "weighted_orthogonal_loss": 0.01605483703315258
    },
    {
      "classification_loss": 0.5951954126358032,
      "epoch": 5.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1605890542268753,
      "orthogonal_weight": 0.1,
      "step": 1770,
      "total_loss": 0.6112543344497681,
      "weighted_orthogonal_loss": 0.0160589050501585
    },
    {
      "classification_loss": 0.6002973318099976,
      "epoch": 5.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16060644388198853,
      "orthogonal_weight": 0.1,
      "step": 1771,
      "total_loss": 0.6163579821586609,
      "weighted_orthogonal_loss": 0.016060644760727882
    },
    {
      "classification_loss": 0.6777954697608948,
      "epoch": 5.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1606632024049759,
      "orthogonal_weight": 0.1,
      "step": 1772,
      "total_loss": 0.6938617825508118,
      "weighted_orthogonal_loss": 0.01606632024049759
    },
    {
      "classification_loss": 0.657680094242096,
      "epoch": 5.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16070033609867096,
      "orthogonal_weight": 0.1,
      "step": 1773,
      "total_loss": 0.673750102519989,
      "weighted_orthogonal_loss": 0.016070034354925156
    },
    {
      "classification_loss": 0.6555195450782776,
      "epoch": 5.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16075806319713593,
      "orthogonal_weight": 0.1,
      "step": 1774,
      "total_loss": 0.6715953350067139,
      "weighted_orthogonal_loss": 0.016075806692242622
    },
    {
      "classification_loss": 0.6390849351882935,
      "epoch": 5.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1607784777879715,
      "orthogonal_weight": 0.1,
      "step": 1775,
      "total_loss": 0.6551628112792969,
      "weighted_orthogonal_loss": 0.01607784815132618
    },
    {
      "classification_loss": 0.6916186809539795,
      "epoch": 5.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076631844043732,
      "orthogonal_weight": 0.1,
      "step": 1776,
      "total_loss": 0.7076953053474426,
      "weighted_orthogonal_loss": 0.01607663184404373
    },
    {
      "classification_loss": 0.6732267737388611,
      "epoch": 5.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16076473891735077,
      "orthogonal_weight": 0.1,
      "step": 1777,
      "total_loss": 0.6893032193183899,
      "weighted_orthogonal_loss": 0.016076473519206047
    },
    {
      "classification_loss": 0.6414340734481812,
      "epoch": 5.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16078807413578033,
      "orthogonal_weight": 0.1,
      "step": 1778,
      "total_loss": 0.657512903213501,
      "weighted_orthogonal_loss": 0.016078807413578033
    },
    {
      "classification_loss": 0.5765182971954346,
      "epoch": 5.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16093367338180542,
      "orthogonal_weight": 0.1,
      "step": 1779,
      "total_loss": 0.5926116704940796,
      "weighted_orthogonal_loss": 0.016093367710709572
    },
    {
      "classification_loss": 0.6162099838256836,
      "epoch": 5.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16107511520385742,
      "orthogonal_weight": 0.1,
      "step": 1780,
      "total_loss": 0.6323174834251404,
      "weighted_orthogonal_loss": 0.01610751263797283
    },
    {
      "classification_loss": 0.6412322521209717,
      "epoch": 5.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16126053035259247,
      "orthogonal_weight": 0.1,
      "step": 1781,
      "total_loss": 0.6573582887649536,
      "weighted_orthogonal_loss": 0.016126053407788277
    },
    {
      "classification_loss": 0.6578768491744995,
      "epoch": 5.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1615331918001175,
      "orthogonal_weight": 0.1,
      "step": 1782,
      "total_loss": 0.6740301847457886,
      "weighted_orthogonal_loss": 0.01615331880748272
    },
    {
      "classification_loss": 0.6318945288658142,
      "epoch": 5.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1618470698595047,
      "orthogonal_weight": 0.1,
      "step": 1783,
      "total_loss": 0.6480792164802551,
      "weighted_orthogonal_loss": 0.01618470810353756
    },
    {
      "classification_loss": 0.6894680261611938,
      "epoch": 5.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16218434274196625,
      "orthogonal_weight": 0.1,
      "step": 1784,
      "total_loss": 0.7056864500045776,
      "weighted_orthogonal_loss": 0.016218435019254684
    },
    {
      "classification_loss": 0.5970689058303833,
      "epoch": 5.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16238120198249817,
      "orthogonal_weight": 0.1,
      "step": 1785,
      "total_loss": 0.613306999206543,
      "weighted_orthogonal_loss": 0.016238121315836906
    },
    {
      "classification_loss": 0.6623458862304688,
      "epoch": 5.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16257601976394653,
      "orthogonal_weight": 0.1,
      "step": 1786,
      "total_loss": 0.67860347032547,
      "weighted_orthogonal_loss": 0.016257602721452713
    },
    {
      "classification_loss": 0.6074020862579346,
      "epoch": 5.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1627763956785202,
      "orthogonal_weight": 0.1,
      "step": 1787,
      "total_loss": 0.6236796975135803,
      "weighted_orthogonal_loss": 0.01627763919532299
    },
    {
      "classification_loss": 0.6594957709312439,
      "epoch": 5.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16296900808811188,
      "orthogonal_weight": 0.1,
      "step": 1788,
      "total_loss": 0.6757926940917969,
      "weighted_orthogonal_loss": 0.016296900808811188
    },
    {
      "classification_loss": 0.7303141355514526,
      "epoch": 5.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16320161521434784,
      "orthogonal_weight": 0.1,
      "step": 1789,
      "total_loss": 0.746634304523468,
      "weighted_orthogonal_loss": 0.016320161521434784
    },
    {
      "classification_loss": 0.6400453448295593,
      "epoch": 5.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16341429948806763,
      "orthogonal_weight": 0.1,
      "step": 1790,
      "total_loss": 0.6563867926597595,
      "weighted_orthogonal_loss": 0.016341431066393852
    },
    {
      "classification_loss": 0.5974707007408142,
      "epoch": 5.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16360649466514587,
      "orthogonal_weight": 0.1,
      "step": 1791,
      "total_loss": 0.6138313412666321,
      "weighted_orthogonal_loss": 0.016360649839043617
    },
    {
      "classification_loss": 0.6123889088630676,
      "epoch": 5.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1638987809419632,
      "orthogonal_weight": 0.1,
      "step": 1792,
      "total_loss": 0.6287788152694702,
      "weighted_orthogonal_loss": 0.01638987846672535
    },
    {
      "classification_loss": 0.6740556955337524,
      "epoch": 5.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16421133279800415,
      "orthogonal_weight": 0.1,
      "step": 1793,
      "total_loss": 0.6904768347740173,
      "weighted_orthogonal_loss": 0.016421133652329445
    },
    {
      "classification_loss": 0.6541404724121094,
      "epoch": 5.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1644706130027771,
      "orthogonal_weight": 0.1,
      "step": 1794,
      "total_loss": 0.6705875396728516,
      "weighted_orthogonal_loss": 0.01644706167280674
    },
    {
      "classification_loss": 0.673378586769104,
      "epoch": 5.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16462615132331848,
      "orthogonal_weight": 0.1,
      "step": 1795,
      "total_loss": 0.6898412108421326,
      "weighted_orthogonal_loss": 0.01646261475980282
    },
    {
      "classification_loss": 0.6205494999885559,
      "epoch": 5.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1647643744945526,
      "orthogonal_weight": 0.1,
      "step": 1796,
      "total_loss": 0.6370259523391724,
      "weighted_orthogonal_loss": 0.01647643744945526
    },
    {
      "classification_loss": 0.652569055557251,
      "epoch": 5.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16490429639816284,
      "orthogonal_weight": 0.1,
      "step": 1797,
      "total_loss": 0.6690595149993896,
      "weighted_orthogonal_loss": 0.016490429639816284
    },
    {
      "classification_loss": 0.6748897433280945,
      "epoch": 5.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16506072878837585,
      "orthogonal_weight": 0.1,
      "step": 1798,
      "total_loss": 0.6913958191871643,
      "weighted_orthogonal_loss": 0.016506073996424675
    },
    {
      "classification_loss": 0.6346562504768372,
      "epoch": 5.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16524766385555267,
      "orthogonal_weight": 0.1,
      "step": 1799,
      "total_loss": 0.6511810421943665,
      "weighted_orthogonal_loss": 0.016524767503142357
    },
    {
      "epoch": 5.901639344262295,
      "grad_norm": 25.319889068603516,
      "learning_rate": 0.00014336666666666666,
      "loss": 0.6643,
      "step": 1800
    },
    {
      "classification_loss": 0.7190911173820496,
      "epoch": 5.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16539183259010315,
      "orthogonal_weight": 0.1,
      "step": 1800,
      "total_loss": 0.7356302738189697,
      "weighted_orthogonal_loss": 0.016539184376597404
    },
    {
      "classification_loss": 0.6816847324371338,
      "epoch": 5.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16549931466579437,
      "orthogonal_weight": 0.1,
      "step": 1801,
      "total_loss": 0.6982346773147583,
      "weighted_orthogonal_loss": 0.016549931839108467
    },
    {
      "classification_loss": 0.7259564399719238,
      "epoch": 5.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16556622087955475,
      "orthogonal_weight": 0.1,
      "step": 1802,
      "total_loss": 0.7425130605697632,
      "weighted_orthogonal_loss": 0.016556622460484505
    },
    {
      "classification_loss": 0.6898894906044006,
      "epoch": 5.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16543345153331757,
      "orthogonal_weight": 0.1,
      "step": 1803,
      "total_loss": 0.7064328193664551,
      "weighted_orthogonal_loss": 0.016543345525860786
    },
    {
      "classification_loss": 0.6953454613685608,
      "epoch": 5.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16517934203147888,
      "orthogonal_weight": 0.1,
      "step": 1804,
      "total_loss": 0.7118633985519409,
      "weighted_orthogonal_loss": 0.016517935320734978
    },
    {
      "classification_loss": 0.637880265712738,
      "epoch": 5.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16493169963359833,
      "orthogonal_weight": 0.1,
      "step": 1805,
      "total_loss": 0.6543734073638916,
      "weighted_orthogonal_loss": 0.016493169590830803
    },
    {
      "classification_loss": 0.6280145645141602,
      "epoch": 5.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16470710933208466,
      "orthogonal_weight": 0.1,
      "step": 1806,
      "total_loss": 0.6444852948188782,
      "weighted_orthogonal_loss": 0.016470711678266525
    },
    {
      "classification_loss": 0.6531400680541992,
      "epoch": 5.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1645258218050003,
      "orthogonal_weight": 0.1,
      "step": 1807,
      "total_loss": 0.6695926785469055,
      "weighted_orthogonal_loss": 0.01645258255302906
    },
    {
      "classification_loss": 0.6452316045761108,
      "epoch": 5.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.164427250623703,
      "orthogonal_weight": 0.1,
      "step": 1808,
      "total_loss": 0.6616743206977844,
      "weighted_orthogonal_loss": 0.01644272543489933
    },
    {
      "classification_loss": 0.6193230748176575,
      "epoch": 5.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16432620584964752,
      "orthogonal_weight": 0.1,
      "step": 1809,
      "total_loss": 0.635755717754364,
      "weighted_orthogonal_loss": 0.016432620584964752
    },
    {
      "classification_loss": 0.6114850640296936,
      "epoch": 5.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1642528623342514,
      "orthogonal_weight": 0.1,
      "step": 1810,
      "total_loss": 0.6279103755950928,
      "weighted_orthogonal_loss": 0.01642528735101223
    },
    {
      "classification_loss": 0.6831453442573547,
      "epoch": 5.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16420085728168488,
      "orthogonal_weight": 0.1,
      "step": 1811,
      "total_loss": 0.6995654106140137,
      "weighted_orthogonal_loss": 0.016420086845755577
    },
    {
      "classification_loss": 0.6602742671966553,
      "epoch": 5.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16418594121932983,
      "orthogonal_weight": 0.1,
      "step": 1812,
      "total_loss": 0.6766928434371948,
      "weighted_orthogonal_loss": 0.016418594866991043
    },
    {
      "classification_loss": 0.6487450003623962,
      "epoch": 5.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16416291892528534,
      "orthogonal_weight": 0.1,
      "step": 1813,
      "total_loss": 0.6651613116264343,
      "weighted_orthogonal_loss": 0.016416292637586594
    },
    {
      "classification_loss": 0.6365559101104736,
      "epoch": 5.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16410602629184723,
      "orthogonal_weight": 0.1,
      "step": 1814,
      "total_loss": 0.6529664993286133,
      "weighted_orthogonal_loss": 0.016410602256655693
    },
    {
      "classification_loss": 0.6288722157478333,
      "epoch": 5.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1640433371067047,
      "orthogonal_weight": 0.1,
      "step": 1815,
      "total_loss": 0.6452765464782715,
      "weighted_orthogonal_loss": 0.01640433445572853
    },
    {
      "classification_loss": 0.6604385375976562,
      "epoch": 5.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16400733590126038,
      "orthogonal_weight": 0.1,
      "step": 1816,
      "total_loss": 0.676839292049408,
      "weighted_orthogonal_loss": 0.016400733962655067
    },
    {
      "classification_loss": 0.6361360549926758,
      "epoch": 5.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16395682096481323,
      "orthogonal_weight": 0.1,
      "step": 1817,
      "total_loss": 0.6525317430496216,
      "weighted_orthogonal_loss": 0.016395682469010353
    },
    {
      "classification_loss": 0.6548715829849243,
      "epoch": 5.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16389010846614838,
      "orthogonal_weight": 0.1,
      "step": 1818,
      "total_loss": 0.6712605953216553,
      "weighted_orthogonal_loss": 0.016389010474085808
    },
    {
      "classification_loss": 0.6450283527374268,
      "epoch": 5.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1637989729642868,
      "orthogonal_weight": 0.1,
      "step": 1819,
      "total_loss": 0.6614082455635071,
      "weighted_orthogonal_loss": 0.01637989841401577
    },
    {
      "classification_loss": 0.6262301802635193,
      "epoch": 5.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16374047100543976,
      "orthogonal_weight": 0.1,
      "step": 1820,
      "total_loss": 0.6426042318344116,
      "weighted_orthogonal_loss": 0.016374047845602036
    },
    {
      "classification_loss": 0.6183348894119263,
      "epoch": 5.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16361744701862335,
      "orthogonal_weight": 0.1,
      "step": 1821,
      "total_loss": 0.6346966624259949,
      "weighted_orthogonal_loss": 0.016361745074391365
    },
    {
      "classification_loss": 0.6447731852531433,
      "epoch": 5.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16352875530719757,
      "orthogonal_weight": 0.1,
      "step": 1822,
      "total_loss": 0.6611260771751404,
      "weighted_orthogonal_loss": 0.016352875158190727
    },
    {
      "classification_loss": 0.6634339690208435,
      "epoch": 5.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16345107555389404,
      "orthogonal_weight": 0.1,
      "step": 1823,
      "total_loss": 0.679779052734375,
      "weighted_orthogonal_loss": 0.016345107927918434
    },
    {
      "classification_loss": 0.5892078280448914,
      "epoch": 5.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16336600482463837,
      "orthogonal_weight": 0.1,
      "step": 1824,
      "total_loss": 0.6055444478988647,
      "weighted_orthogonal_loss": 0.016336601227521896
    },
    {
      "classification_loss": 0.6369319558143616,
      "epoch": 5.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16333475708961487,
      "orthogonal_weight": 0.1,
      "step": 1825,
      "total_loss": 0.6532654166221619,
      "weighted_orthogonal_loss": 0.016333475708961487
    },
    {
      "classification_loss": 0.6340441107749939,
      "epoch": 5.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335101425647736,
      "orthogonal_weight": 0.1,
      "step": 1826,
      "total_loss": 0.6503792405128479,
      "weighted_orthogonal_loss": 0.016335101798176765
    },
    {
      "classification_loss": 0.6232616901397705,
      "epoch": 5.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16335968673229218,
      "orthogonal_weight": 0.1,
      "step": 1827,
      "total_loss": 0.6395976543426514,
      "weighted_orthogonal_loss": 0.016335969790816307
    },
    {
      "classification_loss": 0.6094842553138733,
      "epoch": 5.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16325446963310242,
      "orthogonal_weight": 0.1,
      "step": 1828,
      "total_loss": 0.6258097290992737,
      "weighted_orthogonal_loss": 0.0163254477083683
    },
    {
      "classification_loss": 0.6153846979141235,
      "epoch": 5.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312427818775177,
      "orthogonal_weight": 0.1,
      "step": 1829,
      "total_loss": 0.6316971182823181,
      "weighted_orthogonal_loss": 0.016312427818775177
    },
    {
      "classification_loss": 0.6650094985961914,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6813210248947144,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.7064411640167236,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7227526903152466,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.651926577091217,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.66823810338974,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.666741132736206,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.683052659034729,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6847022771835327,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7010138034820557,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6556127071380615,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6719242334365845,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.646679699420929,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6629912257194519,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6954214572906494,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.7117329835891724,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.585,
      "eval_f1": 0.7220361687876758,
      "eval_loss": 0.6873058080673218,
      "eval_precision": 0.6195402298850575,
      "eval_recall": 0.8651685393258427,
      "eval_runtime": 6.13,
      "eval_samples_per_second": 163.133,
      "eval_steps_per_second": 1.305,
      "step": 1830
    },
    {
      "classification_loss": 0.5971869826316833,
      "epoch": 6.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16311535239219666,
      "orthogonal_weight": 0.1,
      "step": 1830,
      "total_loss": 0.6134985089302063,
      "weighted_orthogonal_loss": 0.016311535611748695
    },
    {
      "classification_loss": 0.6316569447517395,
      "epoch": 6.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16323454678058624,
      "orthogonal_weight": 0.1,
      "step": 1831,
      "total_loss": 0.6479803919792175,
      "weighted_orthogonal_loss": 0.016323454678058624
    },
    {
      "classification_loss": 0.6667070984840393,
      "epoch": 6.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16338461637496948,
      "orthogonal_weight": 0.1,
      "step": 1832,
      "total_loss": 0.6830455660820007,
      "weighted_orthogonal_loss": 0.016338462010025978
    },
    {
      "classification_loss": 0.5950259566307068,
      "epoch": 6.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16347843408584595,
      "orthogonal_weight": 0.1,
      "step": 1833,
      "total_loss": 0.611373782157898,
      "weighted_orthogonal_loss": 0.016347844153642654
    },
    {
      "classification_loss": 0.642166018486023,
      "epoch": 6.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16345156729221344,
      "orthogonal_weight": 0.1,
      "step": 1834,
      "total_loss": 0.6585111618041992,
      "weighted_orthogonal_loss": 0.016345156356692314
    },
    {
      "classification_loss": 0.5595749020576477,
      "epoch": 6.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16350913047790527,
      "orthogonal_weight": 0.1,
      "step": 1835,
      "total_loss": 0.5759258270263672,
      "weighted_orthogonal_loss": 0.016350913792848587
    },
    {
      "classification_loss": 0.6642190217971802,
      "epoch": 6.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16328608989715576,
      "orthogonal_weight": 0.1,
      "step": 1836,
      "total_loss": 0.6805476546287537,
      "weighted_orthogonal_loss": 0.016328608617186546
    },
    {
      "classification_loss": 0.6661124229431152,
      "epoch": 6.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16316913068294525,
      "orthogonal_weight": 0.1,
      "step": 1837,
      "total_loss": 0.682429313659668,
      "weighted_orthogonal_loss": 0.016316913068294525
    },
    {
      "classification_loss": 0.6384445428848267,
      "epoch": 6.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16309192776679993,
      "orthogonal_weight": 0.1,
      "step": 1838,
      "total_loss": 0.6547537446022034,
      "weighted_orthogonal_loss": 0.016309192404150963
    },
    {
      "classification_loss": 0.6477526426315308,
      "epoch": 6.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16306951642036438,
      "orthogonal_weight": 0.1,
      "step": 1839,
      "total_loss": 0.664059579372406,
      "weighted_orthogonal_loss": 0.016306951642036438
    },
    {
      "classification_loss": 0.5645502209663391,
      "epoch": 6.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16312570869922638,
      "orthogonal_weight": 0.1,
      "step": 1840,
      "total_loss": 0.580862820148468,
      "weighted_orthogonal_loss": 0.016312571242451668
    },
    {
      "classification_loss": 0.6196790933609009,
      "epoch": 6.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16334083676338196,
      "orthogonal_weight": 0.1,
      "step": 1841,
      "total_loss": 0.6360131502151489,
      "weighted_orthogonal_loss": 0.016334084793925285
    },
    {
      "classification_loss": 0.5813987851142883,
      "epoch": 6.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16365741193294525,
      "orthogonal_weight": 0.1,
      "step": 1842,
      "total_loss": 0.5977645516395569,
      "weighted_orthogonal_loss": 0.016365742310881615
    },
    {
      "classification_loss": 0.6343774199485779,
      "epoch": 6.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16396988928318024,
      "orthogonal_weight": 0.1,
      "step": 1843,
      "total_loss": 0.6507744193077087,
      "weighted_orthogonal_loss": 0.016396990045905113
    },
    {
      "classification_loss": 0.5971928834915161,
      "epoch": 6.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16433991491794586,
      "orthogonal_weight": 0.1,
      "step": 1844,
      "total_loss": 0.6136268973350525,
      "weighted_orthogonal_loss": 0.016433991491794586
    },
    {
      "classification_loss": 0.6693387627601624,
      "epoch": 6.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1645411252975464,
      "orthogonal_weight": 0.1,
      "step": 1845,
      "total_loss": 0.685792863368988,
      "weighted_orthogonal_loss": 0.016454113647341728
    },
    {
      "classification_loss": 0.6008636355400085,
      "epoch": 6.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16477473080158234,
      "orthogonal_weight": 0.1,
      "step": 1846,
      "total_loss": 0.6173411011695862,
      "weighted_orthogonal_loss": 0.016477473080158234
    },
    {
      "classification_loss": 0.5989946722984314,
      "epoch": 6.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16508081555366516,
      "orthogonal_weight": 0.1,
      "step": 1847,
      "total_loss": 0.6155027747154236,
      "weighted_orthogonal_loss": 0.016508081927895546
    },
    {
      "classification_loss": 0.6539355516433716,
      "epoch": 6.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16536717116832733,
      "orthogonal_weight": 0.1,
      "step": 1848,
      "total_loss": 0.670472264289856,
      "weighted_orthogonal_loss": 0.016536718234419823
    },
    {
      "classification_loss": 0.6690412759780884,
      "epoch": 6.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1652836948633194,
      "orthogonal_weight": 0.1,
      "step": 1849,
      "total_loss": 0.6855696439743042,
      "weighted_orthogonal_loss": 0.01652836985886097
    },
    {
      "classification_loss": 0.6692716479301453,
      "epoch": 6.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16530734300613403,
      "orthogonal_weight": 0.1,
      "step": 1850,
      "total_loss": 0.6858024001121521,
      "weighted_orthogonal_loss": 0.016530735418200493
    },
    {
      "classification_loss": 0.6624391674995422,
      "epoch": 6.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1651546210050583,
      "orthogonal_weight": 0.1,
      "step": 1851,
      "total_loss": 0.6789546012878418,
      "weighted_orthogonal_loss": 0.0165154617279768
    },
    {
      "classification_loss": 0.6469647288322449,
      "epoch": 6.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16503824293613434,
      "orthogonal_weight": 0.1,
      "step": 1852,
      "total_loss": 0.6634685397148132,
      "weighted_orthogonal_loss": 0.016503823921084404
    },
    {
      "classification_loss": 0.692416787147522,
      "epoch": 6.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16493947803974152,
      "orthogonal_weight": 0.1,
      "step": 1853,
      "total_loss": 0.7089107632637024,
      "weighted_orthogonal_loss": 0.01649394817650318
    },
    {
      "classification_loss": 0.6743099093437195,
      "epoch": 6.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1649012565612793,
      "orthogonal_weight": 0.1,
      "step": 1854,
      "total_loss": 0.6908000111579895,
      "weighted_orthogonal_loss": 0.01649012602865696
    },
    {
      "classification_loss": 0.6429284811019897,
      "epoch": 6.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16514495015144348,
      "orthogonal_weight": 0.1,
      "step": 1855,
      "total_loss": 0.6594429612159729,
      "weighted_orthogonal_loss": 0.016514495015144348
    },
    {
      "classification_loss": 0.5999487638473511,
      "epoch": 6.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16530150175094604,
      "orthogonal_weight": 0.1,
      "step": 1856,
      "total_loss": 0.6164789199829102,
      "weighted_orthogonal_loss": 0.016530150547623634
    },
    {
      "classification_loss": 0.639011561870575,
      "epoch": 6.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16545403003692627,
      "orthogonal_weight": 0.1,
      "step": 1857,
      "total_loss": 0.6555569767951965,
      "weighted_orthogonal_loss": 0.016545403748750687
    },
    {
      "classification_loss": 0.6841905117034912,
      "epoch": 6.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16559909284114838,
      "orthogonal_weight": 0.1,
      "step": 1858,
      "total_loss": 0.7007504105567932,
      "weighted_orthogonal_loss": 0.016559910029172897
    },
    {
      "classification_loss": 0.6767187118530273,
      "epoch": 6.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16582055389881134,
      "orthogonal_weight": 0.1,
      "step": 1859,
      "total_loss": 0.6933007836341858,
      "weighted_orthogonal_loss": 0.016582055017352104
    },
    {
      "classification_loss": 0.5979872941970825,
      "epoch": 6.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16604502499103546,
      "orthogonal_weight": 0.1,
      "step": 1860,
      "total_loss": 0.6145917773246765,
      "weighted_orthogonal_loss": 0.016604503616690636
    },
    {
      "classification_loss": 0.641880989074707,
      "epoch": 6.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1662774235010147,
      "orthogonal_weight": 0.1,
      "step": 1861,
      "total_loss": 0.6585087180137634,
      "weighted_orthogonal_loss": 0.01662774197757244
    },
    {
      "classification_loss": 0.641706109046936,
      "epoch": 6.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16646628081798553,
      "orthogonal_weight": 0.1,
      "step": 1862,
      "total_loss": 0.6583527326583862,
      "weighted_orthogonal_loss": 0.016646629199385643
    },
    {
      "classification_loss": 0.6880235075950623,
      "epoch": 6.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.166620671749115,
      "orthogonal_weight": 0.1,
      "step": 1863,
      "total_loss": 0.7046855688095093,
      "weighted_orthogonal_loss": 0.01666206680238247
    },
    {
      "classification_loss": 0.7052350640296936,
      "epoch": 6.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16677042841911316,
      "orthogonal_weight": 0.1,
      "step": 1864,
      "total_loss": 0.7219120860099792,
      "weighted_orthogonal_loss": 0.016677042469382286
    },
    {
      "classification_loss": 0.6058843731880188,
      "epoch": 6.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1669851690530777,
      "orthogonal_weight": 0.1,
      "step": 1865,
      "total_loss": 0.6225829124450684,
      "weighted_orthogonal_loss": 0.01669851690530777
    },
    {
      "classification_loss": 0.6923655867576599,
      "epoch": 6.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1672307699918747,
      "orthogonal_weight": 0.1,
      "step": 1866,
      "total_loss": 0.7090886831283569,
      "weighted_orthogonal_loss": 0.01672307774424553
    },
    {
      "classification_loss": 0.6805179715156555,
      "epoch": 6.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16746506094932556,
      "orthogonal_weight": 0.1,
      "step": 1867,
      "total_loss": 0.6972644925117493,
      "weighted_orthogonal_loss": 0.016746506094932556
    },
    {
      "classification_loss": 0.6151593327522278,
      "epoch": 6.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1679098755121231,
      "orthogonal_weight": 0.1,
      "step": 1868,
      "total_loss": 0.631950318813324,
      "weighted_orthogonal_loss": 0.01679098792374134
    },
    {
      "classification_loss": 0.6095526218414307,
      "epoch": 6.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1683872491121292,
      "orthogonal_weight": 0.1,
      "step": 1869,
      "total_loss": 0.6263913512229919,
      "weighted_orthogonal_loss": 0.01683872565627098
    },
    {
      "classification_loss": 0.6093600988388062,
      "epoch": 6.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.16900984942913055,
      "orthogonal_weight": 0.1,
      "step": 1870,
      "total_loss": 0.6262610554695129,
      "weighted_orthogonal_loss": 0.016900984570384026
    },
    {
      "classification_loss": 0.6026008725166321,
      "epoch": 6.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1697147786617279,
      "orthogonal_weight": 0.1,
      "step": 1871,
      "total_loss": 0.6195723414421082,
      "weighted_orthogonal_loss": 0.01697147823870182
    },
    {
      "classification_loss": 0.6339771747589111,
      "epoch": 6.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1703948676586151,
      "orthogonal_weight": 0.1,
      "step": 1872,
      "total_loss": 0.6510166525840759,
      "weighted_orthogonal_loss": 0.01703948713839054
    },
    {
      "classification_loss": 0.6203567981719971,
      "epoch": 6.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17110119760036469,
      "orthogonal_weight": 0.1,
      "step": 1873,
      "total_loss": 0.6374669075012207,
      "weighted_orthogonal_loss": 0.017110120505094528
    },
    {
      "classification_loss": 0.6885861158370972,
      "epoch": 6.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17173536121845245,
      "orthogonal_weight": 0.1,
      "step": 1874,
      "total_loss": 0.7057596445083618,
      "weighted_orthogonal_loss": 0.017173536121845245
    },
    {
      "classification_loss": 0.6436152458190918,
      "epoch": 6.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17234419286251068,
      "orthogonal_weight": 0.1,
      "step": 1875,
      "total_loss": 0.6608496904373169,
      "weighted_orthogonal_loss": 0.017234420403838158
    },
    {
      "classification_loss": 0.61094731092453,
      "epoch": 6.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1729816049337387,
      "orthogonal_weight": 0.1,
      "step": 1876,
      "total_loss": 0.62824547290802,
      "weighted_orthogonal_loss": 0.01729816012084484
    },
    {
      "classification_loss": 0.5825111269950867,
      "epoch": 6.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17360398173332214,
      "orthogonal_weight": 0.1,
      "step": 1877,
      "total_loss": 0.5998715162277222,
      "weighted_orthogonal_loss": 0.017360398545861244
    },
    {
      "classification_loss": 0.6355075240135193,
      "epoch": 6.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.174120232462883,
      "orthogonal_weight": 0.1,
      "step": 1878,
      "total_loss": 0.6529195308685303,
      "weighted_orthogonal_loss": 0.01741202361881733
    },
    {
      "classification_loss": 0.594417154788971,
      "epoch": 6.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1744661182165146,
      "orthogonal_weight": 0.1,
      "step": 1879,
      "total_loss": 0.6118637919425964,
      "weighted_orthogonal_loss": 0.01744661293923855
    },
    {
      "classification_loss": 0.6080118417739868,
      "epoch": 6.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1746518760919571,
      "orthogonal_weight": 0.1,
      "step": 1880,
      "total_loss": 0.6254770159721375,
      "weighted_orthogonal_loss": 0.01746518723666668
    },
    {
      "classification_loss": 0.626721203327179,
      "epoch": 6.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1748361885547638,
      "orthogonal_weight": 0.1,
      "step": 1881,
      "total_loss": 0.6442047953605652,
      "weighted_orthogonal_loss": 0.01748361997306347
    },
    {
      "classification_loss": 0.6668256521224976,
      "epoch": 6.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1749992072582245,
      "orthogonal_weight": 0.1,
      "step": 1882,
      "total_loss": 0.6843255758285522,
      "weighted_orthogonal_loss": 0.01749992184340954
    },
    {
      "classification_loss": 0.6069297194480896,
      "epoch": 6.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17520609498023987,
      "orthogonal_weight": 0.1,
      "step": 1883,
      "total_loss": 0.6244503259658813,
      "weighted_orthogonal_loss": 0.017520610243082047
    },
    {
      "classification_loss": 0.6145405173301697,
      "epoch": 6.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17540638148784637,
      "orthogonal_weight": 0.1,
      "step": 1884,
      "total_loss": 0.632081151008606,
      "weighted_orthogonal_loss": 0.017540639266371727
    },
    {
      "classification_loss": 0.676875114440918,
      "epoch": 6.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1755921095609665,
      "orthogonal_weight": 0.1,
      "step": 1885,
      "total_loss": 0.6944343447685242,
      "weighted_orthogonal_loss": 0.01755921170115471
    },
    {
      "classification_loss": 0.6100844740867615,
      "epoch": 6.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17573966085910797,
      "orthogonal_weight": 0.1,
      "step": 1886,
      "total_loss": 0.6276584267616272,
      "weighted_orthogonal_loss": 0.017573965713381767
    },
    {
      "classification_loss": 0.590112030506134,
      "epoch": 6.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17581596970558167,
      "orthogonal_weight": 0.1,
      "step": 1887,
      "total_loss": 0.607693612575531,
      "weighted_orthogonal_loss": 0.017581596970558167
    },
    {
      "classification_loss": 0.6180295348167419,
      "epoch": 6.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17584456503391266,
      "orthogonal_weight": 0.1,
      "step": 1888,
      "total_loss": 0.6356139779090881,
      "weighted_orthogonal_loss": 0.017584456130862236
    },
    {
      "classification_loss": 0.6360020637512207,
      "epoch": 6.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17583072185516357,
      "orthogonal_weight": 0.1,
      "step": 1889,
      "total_loss": 0.6535851359367371,
      "weighted_orthogonal_loss": 0.017583072185516357
    },
    {
      "classification_loss": 0.5760915875434875,
      "epoch": 6.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17583400011062622,
      "orthogonal_weight": 0.1,
      "step": 1890,
      "total_loss": 0.5936750173568726,
      "weighted_orthogonal_loss": 0.017583400011062622
    },
    {
      "classification_loss": 0.6801167726516724,
      "epoch": 6.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17584502696990967,
      "orthogonal_weight": 0.1,
      "step": 1891,
      "total_loss": 0.6977012753486633,
      "weighted_orthogonal_loss": 0.017584502696990967
    },
    {
      "classification_loss": 0.6746433973312378,
      "epoch": 6.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1758577674627304,
      "orthogonal_weight": 0.1,
      "step": 1892,
      "total_loss": 0.692229151725769,
      "weighted_orthogonal_loss": 0.01758577674627304
    },
    {
      "classification_loss": 0.6657814383506775,
      "epoch": 6.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1758996993303299,
      "orthogonal_weight": 0.1,
      "step": 1893,
      "total_loss": 0.6833714246749878,
      "weighted_orthogonal_loss": 0.01758996956050396
    },
    {
      "classification_loss": 0.6308029294013977,
      "epoch": 6.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17594611644744873,
      "orthogonal_weight": 0.1,
      "step": 1894,
      "total_loss": 0.6483975648880005,
      "weighted_orthogonal_loss": 0.017594611272215843
    },
    {
      "classification_loss": 0.6090569496154785,
      "epoch": 6.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1759396195411682,
      "orthogonal_weight": 0.1,
      "step": 1895,
      "total_loss": 0.6266509294509888,
      "weighted_orthogonal_loss": 0.01759396307170391
    },
    {
      "classification_loss": 0.6225066781044006,
      "epoch": 6.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17598050832748413,
      "orthogonal_weight": 0.1,
      "step": 1896,
      "total_loss": 0.6401047110557556,
      "weighted_orthogonal_loss": 0.017598051577806473
    },
    {
      "classification_loss": 0.6318709254264832,
      "epoch": 6.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17606432735919952,
      "orthogonal_weight": 0.1,
      "step": 1897,
      "total_loss": 0.6494773626327515,
      "weighted_orthogonal_loss": 0.017606433480978012
    },
    {
      "classification_loss": 0.6250585317611694,
      "epoch": 6.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17617757618427277,
      "orthogonal_weight": 0.1,
      "step": 1898,
      "total_loss": 0.6426762938499451,
      "weighted_orthogonal_loss": 0.017617758363485336
    },
    {
      "classification_loss": 0.65045565366745,
      "epoch": 6.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1761177033185959,
      "orthogonal_weight": 0.1,
      "step": 1899,
      "total_loss": 0.6680673956871033,
      "weighted_orthogonal_loss": 0.01761176995933056
    },
    {
      "epoch": 6.229508196721311,
      "grad_norm": 6.616621017456055,
      "learning_rate": 0.00014003333333333334,
      "loss": 0.6551,
      "step": 1900
    },
    {
      "classification_loss": 0.6700274348258972,
      "epoch": 6.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17603656649589539,
      "orthogonal_weight": 0.1,
      "step": 1900,
      "total_loss": 0.6876310706138611,
      "weighted_orthogonal_loss": 0.01760365627706051
    },
    {
      "classification_loss": 0.6178076267242432,
      "epoch": 6.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17596659064292908,
      "orthogonal_weight": 0.1,
      "step": 1901,
      "total_loss": 0.6354042887687683,
      "weighted_orthogonal_loss": 0.017596660181879997
    },
    {
      "classification_loss": 0.6385064721107483,
      "epoch": 6.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1759074181318283,
      "orthogonal_weight": 0.1,
      "step": 1902,
      "total_loss": 0.6560972332954407,
      "weighted_orthogonal_loss": 0.01759074255824089
    },
    {
      "classification_loss": 0.5965954661369324,
      "epoch": 6.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17582231760025024,
      "orthogonal_weight": 0.1,
      "step": 1903,
      "total_loss": 0.6141777038574219,
      "weighted_orthogonal_loss": 0.017582232132554054
    },
    {
      "classification_loss": 0.6522999405860901,
      "epoch": 6.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17567408084869385,
      "orthogonal_weight": 0.1,
      "step": 1904,
      "total_loss": 0.6698673367500305,
      "weighted_orthogonal_loss": 0.017567409202456474
    },
    {
      "classification_loss": 0.6178790330886841,
      "epoch": 6.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17547708749771118,
      "orthogonal_weight": 0.1,
      "step": 1905,
      "total_loss": 0.6354267597198486,
      "weighted_orthogonal_loss": 0.017547709867358208
    },
    {
      "classification_loss": 0.62631756067276,
      "epoch": 6.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17526055872440338,
      "orthogonal_weight": 0.1,
      "step": 1906,
      "total_loss": 0.6438435912132263,
      "weighted_orthogonal_loss": 0.017526056617498398
    },
    {
      "classification_loss": 0.5812749266624451,
      "epoch": 6.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.175025075674057,
      "orthogonal_weight": 0.1,
      "step": 1907,
      "total_loss": 0.5987774133682251,
      "weighted_orthogonal_loss": 0.01750250719487667
    },
    {
      "classification_loss": 0.6282244324684143,
      "epoch": 6.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17455263435840607,
      "orthogonal_weight": 0.1,
      "step": 1908,
      "total_loss": 0.6456797122955322,
      "weighted_orthogonal_loss": 0.017455263063311577
    },
    {
      "classification_loss": 0.6363826990127563,
      "epoch": 6.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.174242302775383,
      "orthogonal_weight": 0.1,
      "step": 1909,
      "total_loss": 0.6538069248199463,
      "weighted_orthogonal_loss": 0.01742423139512539
    },
    {
      "classification_loss": 0.6301106214523315,
      "epoch": 6.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17399199306964874,
      "orthogonal_weight": 0.1,
      "step": 1910,
      "total_loss": 0.6475098133087158,
      "weighted_orthogonal_loss": 0.017399199306964874
    },
    {
      "classification_loss": 0.647537887096405,
      "epoch": 6.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17383122444152832,
      "orthogonal_weight": 0.1,
      "step": 1911,
      "total_loss": 0.6649209856987,
      "weighted_orthogonal_loss": 0.017383122816681862
    },
    {
      "classification_loss": 0.6400195956230164,
      "epoch": 6.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17377807199954987,
      "orthogonal_weight": 0.1,
      "step": 1912,
      "total_loss": 0.6573973894119263,
      "weighted_orthogonal_loss": 0.017377806827425957
    },
    {
      "classification_loss": 0.6221169233322144,
      "epoch": 6.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17361626029014587,
      "orthogonal_weight": 0.1,
      "step": 1913,
      "total_loss": 0.6394785642623901,
      "weighted_orthogonal_loss": 0.017361626029014587
    },
    {
      "classification_loss": 0.5739860534667969,
      "epoch": 6.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17355309426784515,
      "orthogonal_weight": 0.1,
      "step": 1914,
      "total_loss": 0.5913413763046265,
      "weighted_orthogonal_loss": 0.017355309799313545
    },
    {
      "classification_loss": 0.5534604787826538,
      "epoch": 6.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17360475659370422,
      "orthogonal_weight": 0.1,
      "step": 1915,
      "total_loss": 0.5708209276199341,
      "weighted_orthogonal_loss": 0.017360476776957512
    },
    {
      "classification_loss": 0.6881675124168396,
      "epoch": 6.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1738515943288803,
      "orthogonal_weight": 0.1,
      "step": 1916,
      "total_loss": 0.7055526971817017,
      "weighted_orthogonal_loss": 0.01738516055047512
    },
    {
      "classification_loss": 0.7399901747703552,
      "epoch": 6.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17409628629684448,
      "orthogonal_weight": 0.1,
      "step": 1917,
      "total_loss": 0.7573997974395752,
      "weighted_orthogonal_loss": 0.01740962825715542
    },
    {
      "classification_loss": 0.5843390226364136,
      "epoch": 6.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17448072135448456,
      "orthogonal_weight": 0.1,
      "step": 1918,
      "total_loss": 0.6017870903015137,
      "weighted_orthogonal_loss": 0.017448073253035545
    },
    {
      "classification_loss": 0.6664127111434937,
      "epoch": 6.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17491716146469116,
      "orthogonal_weight": 0.1,
      "step": 1919,
      "total_loss": 0.6839044094085693,
      "weighted_orthogonal_loss": 0.017491716891527176
    },
    {
      "classification_loss": 0.6137518286705017,
      "epoch": 6.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752471774816513,
      "orthogonal_weight": 0.1,
      "step": 1920,
      "total_loss": 0.631276547908783,
      "weighted_orthogonal_loss": 0.0175247173756361
    },
    {
      "classification_loss": 0.5870035886764526,
      "epoch": 6.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17563042044639587,
      "orthogonal_weight": 0.1,
      "step": 1921,
      "total_loss": 0.6045666337013245,
      "weighted_orthogonal_loss": 0.017563043162226677
    },
    {
      "classification_loss": 0.6271048188209534,
      "epoch": 6.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1760038435459137,
      "orthogonal_weight": 0.1,
      "step": 1922,
      "total_loss": 0.6447051763534546,
      "weighted_orthogonal_loss": 0.01760038547217846
    },
    {
      "classification_loss": 0.6482730507850647,
      "epoch": 6.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17629693448543549,
      "orthogonal_weight": 0.1,
      "step": 1923,
      "total_loss": 0.6659027338027954,
      "weighted_orthogonal_loss": 0.01762969419360161
    },
    {
      "classification_loss": 0.68864506483078,
      "epoch": 6.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1766289472579956,
      "orthogonal_weight": 0.1,
      "step": 1924,
      "total_loss": 0.7063079476356506,
      "weighted_orthogonal_loss": 0.01766289584338665
    },
    {
      "classification_loss": 0.5929071307182312,
      "epoch": 6.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17673344910144806,
      "orthogonal_weight": 0.1,
      "step": 1925,
      "total_loss": 0.6105805039405823,
      "weighted_orthogonal_loss": 0.017673345282673836
    },
    {
      "classification_loss": 0.6604601740837097,
      "epoch": 6.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17699360847473145,
      "orthogonal_weight": 0.1,
      "step": 1926,
      "total_loss": 0.6781595349311829,
      "weighted_orthogonal_loss": 0.017699360847473145
    },
    {
      "classification_loss": 0.6941739320755005,
      "epoch": 6.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17733284831047058,
      "orthogonal_weight": 0.1,
      "step": 1927,
      "total_loss": 0.7119072079658508,
      "weighted_orthogonal_loss": 0.017733285203576088
    },
    {
      "classification_loss": 0.6041587591171265,
      "epoch": 6.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1776956170797348,
      "orthogonal_weight": 0.1,
      "step": 1928,
      "total_loss": 0.621928334236145,
      "weighted_orthogonal_loss": 0.01776956208050251
    },
    {
      "classification_loss": 0.6177642941474915,
      "epoch": 6.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17818120121955872,
      "orthogonal_weight": 0.1,
      "step": 1929,
      "total_loss": 0.6355823874473572,
      "weighted_orthogonal_loss": 0.01781812123954296
    },
    {
      "classification_loss": 0.7078342437744141,
      "epoch": 6.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1786649525165558,
      "orthogonal_weight": 0.1,
      "step": 1930,
      "total_loss": 0.7257007360458374,
      "weighted_orthogonal_loss": 0.01786649599671364
    },
    {
      "classification_loss": 0.6990167498588562,
      "epoch": 6.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1790461242198944,
      "orthogonal_weight": 0.1,
      "step": 1931,
      "total_loss": 0.7169213891029358,
      "weighted_orthogonal_loss": 0.0179046131670475
    },
    {
      "classification_loss": 0.6323781609535217,
      "epoch": 6.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17916005849838257,
      "orthogonal_weight": 0.1,
      "step": 1932,
      "total_loss": 0.6502941846847534,
      "weighted_orthogonal_loss": 0.017916006967425346
    },
    {
      "classification_loss": 0.6213756799697876,
      "epoch": 6.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1792818307876587,
      "orthogonal_weight": 0.1,
      "step": 1933,
      "total_loss": 0.6393038630485535,
      "weighted_orthogonal_loss": 0.01792818307876587
    },
    {
      "classification_loss": 0.6179437637329102,
      "epoch": 6.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1795363873243332,
      "orthogonal_weight": 0.1,
      "step": 1934,
      "total_loss": 0.6358973979949951,
      "weighted_orthogonal_loss": 0.01795363985002041
    },
    {
      "classification_loss": 0.6914888024330139,
      "epoch": 6.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17974384129047394,
      "orthogonal_weight": 0.1,
      "step": 1935,
      "total_loss": 0.7094631791114807,
      "weighted_orthogonal_loss": 0.017974384129047394
    },
    {
      "classification_loss": 0.6506186127662659,
      "epoch": 6.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17987969517707825,
      "orthogonal_weight": 0.1,
      "step": 1936,
      "total_loss": 0.6686065793037415,
      "weighted_orthogonal_loss": 0.017987970262765884
    },
    {
      "classification_loss": 0.7210357189178467,
      "epoch": 6.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17980195581912994,
      "orthogonal_weight": 0.1,
      "step": 1937,
      "total_loss": 0.7390159368515015,
      "weighted_orthogonal_loss": 0.017980195581912994
    },
    {
      "classification_loss": 0.607692539691925,
      "epoch": 6.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1796877533197403,
      "orthogonal_weight": 0.1,
      "step": 1938,
      "total_loss": 0.625661313533783,
      "weighted_orthogonal_loss": 0.01796877570450306
    },
    {
      "classification_loss": 0.6885244250297546,
      "epoch": 6.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17992308735847473,
      "orthogonal_weight": 0.1,
      "step": 1939,
      "total_loss": 0.7065167427062988,
      "weighted_orthogonal_loss": 0.017992308363318443
    },
    {
      "classification_loss": 0.5876247882843018,
      "epoch": 6.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1798272728919983,
      "orthogonal_weight": 0.1,
      "step": 1940,
      "total_loss": 0.6056075096130371,
      "weighted_orthogonal_loss": 0.0179827269166708
    },
    {
      "classification_loss": 0.6261847615242004,
      "epoch": 6.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17980048060417175,
      "orthogonal_weight": 0.1,
      "step": 1941,
      "total_loss": 0.6441648006439209,
      "weighted_orthogonal_loss": 0.017980048432946205
    },
    {
      "classification_loss": 0.7070494294166565,
      "epoch": 6.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17977993190288544,
      "orthogonal_weight": 0.1,
      "step": 1942,
      "total_loss": 0.7250274419784546,
      "weighted_orthogonal_loss": 0.017977993935346603
    },
    {
      "classification_loss": 0.6396864056587219,
      "epoch": 6.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17947274446487427,
      "orthogonal_weight": 0.1,
      "step": 1943,
      "total_loss": 0.6576336622238159,
      "weighted_orthogonal_loss": 0.017947275191545486
    },
    {
      "classification_loss": 0.7261257767677307,
      "epoch": 6.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1792813390493393,
      "orthogonal_weight": 0.1,
      "step": 1944,
      "total_loss": 0.7440539002418518,
      "weighted_orthogonal_loss": 0.01792813464999199
    },
    {
      "classification_loss": 0.5980513095855713,
      "epoch": 6.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17911562323570251,
      "orthogonal_weight": 0.1,
      "step": 1945,
      "total_loss": 0.6159628629684448,
      "weighted_orthogonal_loss": 0.01791156269609928
    },
    {
      "classification_loss": 0.6687729954719543,
      "epoch": 6.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17894361913204193,
      "orthogonal_weight": 0.1,
      "step": 1946,
      "total_loss": 0.6866673827171326,
      "weighted_orthogonal_loss": 0.017894363030791283
    },
    {
      "classification_loss": 0.5858516693115234,
      "epoch": 6.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788148134946823,
      "orthogonal_weight": 0.1,
      "step": 1947,
      "total_loss": 0.6037331223487854,
      "weighted_orthogonal_loss": 0.0178814809769392
    },
    {
      "classification_loss": 0.6672080159187317,
      "epoch": 6.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17881667613983154,
      "orthogonal_weight": 0.1,
      "step": 1948,
      "total_loss": 0.6850897073745728,
      "weighted_orthogonal_loss": 0.017881667241454124
    },
    {
      "classification_loss": 0.5950353145599365,
      "epoch": 6.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17885828018188477,
      "orthogonal_weight": 0.1,
      "step": 1949,
      "total_loss": 0.6129211187362671,
      "weighted_orthogonal_loss": 0.017885828390717506
    },
    {
      "classification_loss": 0.5645700097084045,
      "epoch": 6.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17881135642528534,
      "orthogonal_weight": 0.1,
      "step": 1950,
      "total_loss": 0.5824511647224426,
      "weighted_orthogonal_loss": 0.017881136387586594
    },
    {
      "classification_loss": 0.6394694447517395,
      "epoch": 6.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17876036465168,
      "orthogonal_weight": 0.1,
      "step": 1951,
      "total_loss": 0.6573454737663269,
      "weighted_orthogonal_loss": 0.017876036465168
    },
    {
      "classification_loss": 0.6700668931007385,
      "epoch": 6.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17875075340270996,
      "orthogonal_weight": 0.1,
      "step": 1952,
      "total_loss": 0.6879419684410095,
      "weighted_orthogonal_loss": 0.017875075340270996
    },
    {
      "classification_loss": 0.657333493232727,
      "epoch": 6.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788085699081421,
      "orthogonal_weight": 0.1,
      "step": 1953,
      "total_loss": 0.6752143502235413,
      "weighted_orthogonal_loss": 0.01788085699081421
    },
    {
      "classification_loss": 0.6830074191093445,
      "epoch": 6.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1787426471710205,
      "orthogonal_weight": 0.1,
      "step": 1954,
      "total_loss": 0.7008816599845886,
      "weighted_orthogonal_loss": 0.01787426508963108
    },
    {
      "classification_loss": 0.7073534727096558,
      "epoch": 6.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17862628400325775,
      "orthogonal_weight": 0.1,
      "step": 1955,
      "total_loss": 0.7252160906791687,
      "weighted_orthogonal_loss": 0.017862629145383835
    },
    {
      "classification_loss": 0.6938972473144531,
      "epoch": 6.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17855112254619598,
      "orthogonal_weight": 0.1,
      "step": 1956,
      "total_loss": 0.7117523550987244,
      "weighted_orthogonal_loss": 0.017855113372206688
    },
    {
      "classification_loss": 0.6481748819351196,
      "epoch": 6.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17853935062885284,
      "orthogonal_weight": 0.1,
      "step": 1957,
      "total_loss": 0.6660287976264954,
      "weighted_orthogonal_loss": 0.017853936180472374
    },
    {
      "classification_loss": 0.6719669103622437,
      "epoch": 6.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17853331565856934,
      "orthogonal_weight": 0.1,
      "step": 1958,
      "total_loss": 0.6898202300071716,
      "weighted_orthogonal_loss": 0.017853332683444023
    },
    {
      "classification_loss": 0.679162323474884,
      "epoch": 6.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17843037843704224,
      "orthogonal_weight": 0.1,
      "step": 1959,
      "total_loss": 0.6970053911209106,
      "weighted_orthogonal_loss": 0.017843037843704224
    },
    {
      "classification_loss": 0.6400140523910522,
      "epoch": 6.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1782722920179367,
      "orthogonal_weight": 0.1,
      "step": 1960,
      "total_loss": 0.6578412652015686,
      "weighted_orthogonal_loss": 0.0178272295743227
    },
    {
      "classification_loss": 0.6035797595977783,
      "epoch": 6.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17806346714496613,
      "orthogonal_weight": 0.1,
      "step": 1961,
      "total_loss": 0.6213861107826233,
      "weighted_orthogonal_loss": 0.017806347459554672
    },
    {
      "classification_loss": 0.5776118040084839,
      "epoch": 6.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1779094636440277,
      "orthogonal_weight": 0.1,
      "step": 1962,
      "total_loss": 0.5954027771949768,
      "weighted_orthogonal_loss": 0.01779094710946083
    },
    {
      "classification_loss": 0.6224751472473145,
      "epoch": 6.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17781572043895721,
      "orthogonal_weight": 0.1,
      "step": 1963,
      "total_loss": 0.6402567028999329,
      "weighted_orthogonal_loss": 0.01778157241642475
    },
    {
      "classification_loss": 0.6533632278442383,
      "epoch": 6.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17773152887821198,
      "orthogonal_weight": 0.1,
      "step": 1964,
      "total_loss": 0.6711363792419434,
      "weighted_orthogonal_loss": 0.017773153260350227
    },
    {
      "classification_loss": 0.6965363025665283,
      "epoch": 6.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1775800734758377,
      "orthogonal_weight": 0.1,
      "step": 1965,
      "total_loss": 0.7142943143844604,
      "weighted_orthogonal_loss": 0.01775800809264183
    },
    {
      "classification_loss": 0.6748583912849426,
      "epoch": 6.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1773941069841385,
      "orthogonal_weight": 0.1,
      "step": 1966,
      "total_loss": 0.6925978064537048,
      "weighted_orthogonal_loss": 0.01773941144347191
    },
    {
      "classification_loss": 0.5976960062980652,
      "epoch": 6.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1771906614303589,
      "orthogonal_weight": 0.1,
      "step": 1967,
      "total_loss": 0.615415096282959,
      "weighted_orthogonal_loss": 0.01771906577050686
    },
    {
      "classification_loss": 0.5977126955986023,
      "epoch": 6.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1768769472837448,
      "orthogonal_weight": 0.1,
      "step": 1968,
      "total_loss": 0.6154003739356995,
      "weighted_orthogonal_loss": 0.01768769510090351
    },
    {
      "classification_loss": 0.6655173897743225,
      "epoch": 6.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1766330748796463,
      "orthogonal_weight": 0.1,
      "step": 1969,
      "total_loss": 0.6831806898117065,
      "weighted_orthogonal_loss": 0.01766330748796463
    },
    {
      "classification_loss": 0.6875767707824707,
      "epoch": 6.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1765342503786087,
      "orthogonal_weight": 0.1,
      "step": 1970,
      "total_loss": 0.705230176448822,
      "weighted_orthogonal_loss": 0.01765342615544796
    },
    {
      "classification_loss": 0.6115390062332153,
      "epoch": 6.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17652197182178497,
      "orthogonal_weight": 0.1,
      "step": 1971,
      "total_loss": 0.6291912198066711,
      "weighted_orthogonal_loss": 0.017652196809649467
    },
    {
      "classification_loss": 0.6561174392700195,
      "epoch": 6.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17655989527702332,
      "orthogonal_weight": 0.1,
      "step": 1972,
      "total_loss": 0.6737734079360962,
      "weighted_orthogonal_loss": 0.0176559891551733
    },
    {
      "classification_loss": 0.645172119140625,
      "epoch": 6.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17659766972064972,
      "orthogonal_weight": 0.1,
      "step": 1973,
      "total_loss": 0.6628319025039673,
      "weighted_orthogonal_loss": 0.017659766599535942
    },
    {
      "classification_loss": 0.6327540278434753,
      "epoch": 6.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17674656212329865,
      "orthogonal_weight": 0.1,
      "step": 1974,
      "total_loss": 0.6504287123680115,
      "weighted_orthogonal_loss": 0.017674656584858894
    },
    {
      "classification_loss": 0.6007413268089294,
      "epoch": 6.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1769566535949707,
      "orthogonal_weight": 0.1,
      "step": 1975,
      "total_loss": 0.6184369921684265,
      "weighted_orthogonal_loss": 0.01769566535949707
    },
    {
      "classification_loss": 0.6379496455192566,
      "epoch": 6.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17746369540691376,
      "orthogonal_weight": 0.1,
      "step": 1976,
      "total_loss": 0.6556960344314575,
      "weighted_orthogonal_loss": 0.017746370285749435
    },
    {
      "classification_loss": 0.5722396373748779,
      "epoch": 6.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1780339926481247,
      "orthogonal_weight": 0.1,
      "step": 1977,
      "total_loss": 0.5900430083274841,
      "weighted_orthogonal_loss": 0.01780339889228344
    },
    {
      "classification_loss": 0.710381805896759,
      "epoch": 6.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17868350446224213,
      "orthogonal_weight": 0.1,
      "step": 1978,
      "total_loss": 0.7282501459121704,
      "weighted_orthogonal_loss": 0.017868351191282272
    },
    {
      "classification_loss": 0.5746939182281494,
      "epoch": 6.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17917722463607788,
      "orthogonal_weight": 0.1,
      "step": 1979,
      "total_loss": 0.5926116704940796,
      "weighted_orthogonal_loss": 0.017917722463607788
    },
    {
      "classification_loss": 0.5948243141174316,
      "epoch": 6.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17969468235969543,
      "orthogonal_weight": 0.1,
      "step": 1980,
      "total_loss": 0.6127938032150269,
      "weighted_orthogonal_loss": 0.017969468608498573
    },
    {
      "classification_loss": 0.6653790473937988,
      "epoch": 6.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18019838631153107,
      "orthogonal_weight": 0.1,
      "step": 1981,
      "total_loss": 0.6833989024162292,
      "weighted_orthogonal_loss": 0.018019838258624077
    },
    {
      "classification_loss": 0.6245875954627991,
      "epoch": 6.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18071599304676056,
      "orthogonal_weight": 0.1,
      "step": 1982,
      "total_loss": 0.6426591873168945,
      "weighted_orthogonal_loss": 0.018071599304676056
    },
    {
      "classification_loss": 0.6382209062576294,
      "epoch": 6.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18104763329029083,
      "orthogonal_weight": 0.1,
      "step": 1983,
      "total_loss": 0.6563256978988647,
      "weighted_orthogonal_loss": 0.018104763701558113
    },
    {
      "classification_loss": 0.6913641095161438,
      "epoch": 6.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18140093982219696,
      "orthogonal_weight": 0.1,
      "step": 1984,
      "total_loss": 0.7095041871070862,
      "weighted_orthogonal_loss": 0.018140094354748726
    },
    {
      "classification_loss": 0.5852491855621338,
      "epoch": 6.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18142341077327728,
      "orthogonal_weight": 0.1,
      "step": 1985,
      "total_loss": 0.6033915281295776,
      "weighted_orthogonal_loss": 0.0181423407047987
    },
    {
      "classification_loss": 0.6298424601554871,
      "epoch": 6.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18145249783992767,
      "orthogonal_weight": 0.1,
      "step": 1986,
      "total_loss": 0.6479877233505249,
      "weighted_orthogonal_loss": 0.018145250156521797
    },
    {
      "classification_loss": 0.6299476623535156,
      "epoch": 6.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18153373897075653,
      "orthogonal_weight": 0.1,
      "step": 1987,
      "total_loss": 0.6481010317802429,
      "weighted_orthogonal_loss": 0.018153375014662743
    },
    {
      "classification_loss": 0.7191600799560547,
      "epoch": 6.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18156293034553528,
      "orthogonal_weight": 0.1,
      "step": 1988,
      "total_loss": 0.737316370010376,
      "weighted_orthogonal_loss": 0.018156293779611588
    },
    {
      "classification_loss": 0.58255934715271,
      "epoch": 6.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18157528340816498,
      "orthogonal_weight": 0.1,
      "step": 1989,
      "total_loss": 0.6007168889045715,
      "weighted_orthogonal_loss": 0.018157528713345528
    },
    {
      "classification_loss": 0.5800284743309021,
      "epoch": 6.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1815996766090393,
      "orthogonal_weight": 0.1,
      "step": 1990,
      "total_loss": 0.5981884598731995,
      "weighted_orthogonal_loss": 0.01815996877849102
    },
    {
      "classification_loss": 0.5262662172317505,
      "epoch": 6.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18159738183021545,
      "orthogonal_weight": 0.1,
      "step": 1991,
      "total_loss": 0.5444259643554688,
      "weighted_orthogonal_loss": 0.018159737810492516
    },
    {
      "classification_loss": 0.5740049481391907,
      "epoch": 6.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18166157603263855,
      "orthogonal_weight": 0.1,
      "step": 1992,
      "total_loss": 0.5921711325645447,
      "weighted_orthogonal_loss": 0.018166158348321915
    },
    {
      "classification_loss": 0.686650812625885,
      "epoch": 6.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1817205399274826,
      "orthogonal_weight": 0.1,
      "step": 1993,
      "total_loss": 0.704822838306427,
      "weighted_orthogonal_loss": 0.01817205362021923
    },
    {
      "classification_loss": 0.657177746295929,
      "epoch": 6.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1814115345478058,
      "orthogonal_weight": 0.1,
      "step": 1994,
      "total_loss": 0.6753188967704773,
      "weighted_orthogonal_loss": 0.01814115419983864
    },
    {
      "classification_loss": 0.6184468269348145,
      "epoch": 6.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.181134432554245,
      "orthogonal_weight": 0.1,
      "step": 1995,
      "total_loss": 0.6365602612495422,
      "weighted_orthogonal_loss": 0.01811344362795353
    },
    {
      "classification_loss": 0.5958802700042725,
      "epoch": 6.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18096834421157837,
      "orthogonal_weight": 0.1,
      "step": 1996,
      "total_loss": 0.6139770746231079,
      "weighted_orthogonal_loss": 0.018096834421157837
    },
    {
      "classification_loss": 0.6663170456886292,
      "epoch": 6.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1808163970708847,
      "orthogonal_weight": 0.1,
      "step": 1997,
      "total_loss": 0.6843987107276917,
      "weighted_orthogonal_loss": 0.01808164082467556
    },
    {
      "classification_loss": 0.6901257634162903,
      "epoch": 6.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18073564767837524,
      "orthogonal_weight": 0.1,
      "step": 1998,
      "total_loss": 0.7081993222236633,
      "weighted_orthogonal_loss": 0.018073564395308495
    },
    {
      "classification_loss": 0.6896013617515564,
      "epoch": 6.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1806352734565735,
      "orthogonal_weight": 0.1,
      "step": 1999,
      "total_loss": 0.7076649069786072,
      "weighted_orthogonal_loss": 0.018063528463244438
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 6.772825717926025,
      "learning_rate": 0.00013670000000000002,
      "loss": 0.6568,
      "step": 2000
    },
    {
      "classification_loss": 0.7132785320281982,
      "epoch": 6.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18038836121559143,
      "orthogonal_weight": 0.1,
      "step": 2000,
      "total_loss": 0.7313173413276672,
      "weighted_orthogonal_loss": 0.018038837239146233
    },
    {
      "classification_loss": 0.6431593298912048,
      "epoch": 6.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18010970950126648,
      "orthogonal_weight": 0.1,
      "step": 2001,
      "total_loss": 0.6611703038215637,
      "weighted_orthogonal_loss": 0.018010972067713737
    },
    {
      "classification_loss": 0.6665683388710022,
      "epoch": 6.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17988687753677368,
      "orthogonal_weight": 0.1,
      "step": 2002,
      "total_loss": 0.6845570206642151,
      "weighted_orthogonal_loss": 0.01798868738114834
    },
    {
      "classification_loss": 0.6372905969619751,
      "epoch": 6.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17971646785736084,
      "orthogonal_weight": 0.1,
      "step": 2003,
      "total_loss": 0.6552622318267822,
      "weighted_orthogonal_loss": 0.017971647903323174
    },
    {
      "classification_loss": 0.6598080992698669,
      "epoch": 6.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17953595519065857,
      "orthogonal_weight": 0.1,
      "step": 2004,
      "total_loss": 0.6777616739273071,
      "weighted_orthogonal_loss": 0.017953595146536827
    },
    {
      "classification_loss": 0.655156135559082,
      "epoch": 6.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17935630679130554,
      "orthogonal_weight": 0.1,
      "step": 2005,
      "total_loss": 0.6730917692184448,
      "weighted_orthogonal_loss": 0.017935631796717644
    },
    {
      "classification_loss": 0.6424746513366699,
      "epoch": 6.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17919772863388062,
      "orthogonal_weight": 0.1,
      "step": 2006,
      "total_loss": 0.6603944301605225,
      "weighted_orthogonal_loss": 0.01791977323591709
    },
    {
      "classification_loss": 0.6241015195846558,
      "epoch": 6.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17888367176055908,
      "orthogonal_weight": 0.1,
      "step": 2007,
      "total_loss": 0.6419898867607117,
      "weighted_orthogonal_loss": 0.017888367176055908
    },
    {
      "classification_loss": 0.6517049670219421,
      "epoch": 6.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1786980926990509,
      "orthogonal_weight": 0.1,
      "step": 2008,
      "total_loss": 0.6695747971534729,
      "weighted_orthogonal_loss": 0.01786980964243412
    },
    {
      "classification_loss": 0.6073740124702454,
      "epoch": 6.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1785268485546112,
      "orthogonal_weight": 0.1,
      "step": 2009,
      "total_loss": 0.6252266764640808,
      "weighted_orthogonal_loss": 0.01785268448293209
    },
    {
      "classification_loss": 0.6828882694244385,
      "epoch": 6.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1784559041261673,
      "orthogonal_weight": 0.1,
      "step": 2010,
      "total_loss": 0.7007338404655457,
      "weighted_orthogonal_loss": 0.01784559153020382
    },
    {
      "classification_loss": 0.7218275666236877,
      "epoch": 6.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17843955755233765,
      "orthogonal_weight": 0.1,
      "step": 2011,
      "total_loss": 0.739671528339386,
      "weighted_orthogonal_loss": 0.017843956127762794
    },
    {
      "classification_loss": 0.6784514784812927,
      "epoch": 6.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17844590544700623,
      "orthogonal_weight": 0.1,
      "step": 2012,
      "total_loss": 0.6962960958480835,
      "weighted_orthogonal_loss": 0.017844591289758682
    },
    {
      "classification_loss": 0.6184940934181213,
      "epoch": 6.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17844854295253754,
      "orthogonal_weight": 0.1,
      "step": 2013,
      "total_loss": 0.6363389492034912,
      "weighted_orthogonal_loss": 0.017844853922724724
    },
    {
      "classification_loss": 0.6404114365577698,
      "epoch": 6.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17842762172222137,
      "orthogonal_weight": 0.1,
      "step": 2014,
      "total_loss": 0.6582542061805725,
      "weighted_orthogonal_loss": 0.017842762172222137
    },
    {
      "classification_loss": 0.6906231641769409,
      "epoch": 6.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1783771514892578,
      "orthogonal_weight": 0.1,
      "step": 2015,
      "total_loss": 0.7084608674049377,
      "weighted_orthogonal_loss": 0.01783771626651287
    },
    {
      "classification_loss": 0.6478911638259888,
      "epoch": 6.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17843914031982422,
      "orthogonal_weight": 0.1,
      "step": 2016,
      "total_loss": 0.6657350659370422,
      "weighted_orthogonal_loss": 0.01784391514956951
    },
    {
      "classification_loss": 0.6293700933456421,
      "epoch": 6.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17862248420715332,
      "orthogonal_weight": 0.1,
      "step": 2017,
      "total_loss": 0.6472323536872864,
      "weighted_orthogonal_loss": 0.01786224916577339
    },
    {
      "classification_loss": 0.5866380333900452,
      "epoch": 6.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17887194454669952,
      "orthogonal_weight": 0.1,
      "step": 2018,
      "total_loss": 0.6045252084732056,
      "weighted_orthogonal_loss": 0.017887195572257042
    },
    {
      "classification_loss": 0.7051671147346497,
      "epoch": 6.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17911168932914734,
      "orthogonal_weight": 0.1,
      "step": 2019,
      "total_loss": 0.7230783104896545,
      "weighted_orthogonal_loss": 0.017911169677972794
    },
    {
      "classification_loss": 0.5925130844116211,
      "epoch": 6.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17924170196056366,
      "orthogonal_weight": 0.1,
      "step": 2020,
      "total_loss": 0.610437273979187,
      "weighted_orthogonal_loss": 0.017924170941114426
    },
    {
      "classification_loss": 0.6315765976905823,
      "epoch": 6.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1793745905160904,
      "orthogonal_weight": 0.1,
      "step": 2021,
      "total_loss": 0.6495140790939331,
      "weighted_orthogonal_loss": 0.01793745905160904
    },
    {
      "classification_loss": 0.6670719981193542,
      "epoch": 6.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17946118116378784,
      "orthogonal_weight": 0.1,
      "step": 2022,
      "total_loss": 0.6850181221961975,
      "weighted_orthogonal_loss": 0.017946118488907814
    },
    {
      "classification_loss": 0.6345495581626892,
      "epoch": 6.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1795201599597931,
      "orthogonal_weight": 0.1,
      "step": 2023,
      "total_loss": 0.6525015830993652,
      "weighted_orthogonal_loss": 0.01795201562345028
    },
    {
      "classification_loss": 0.5842967629432678,
      "epoch": 6.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17962439358234406,
      "orthogonal_weight": 0.1,
      "step": 2024,
      "total_loss": 0.6022592186927795,
      "weighted_orthogonal_loss": 0.017962438985705376
    },
    {
      "classification_loss": 0.6053582429885864,
      "epoch": 6.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1796569526195526,
      "orthogonal_weight": 0.1,
      "step": 2025,
      "total_loss": 0.623323917388916,
      "weighted_orthogonal_loss": 0.01796569488942623
    },
    {
      "classification_loss": 0.6089482307434082,
      "epoch": 6.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17967699468135834,
      "orthogonal_weight": 0.1,
      "step": 2026,
      "total_loss": 0.6269159317016602,
      "weighted_orthogonal_loss": 0.017967699095606804
    },
    {
      "classification_loss": 0.6309353709220886,
      "epoch": 6.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17968232929706573,
      "orthogonal_weight": 0.1,
      "step": 2027,
      "total_loss": 0.6489036083221436,
      "weighted_orthogonal_loss": 0.017968233674764633
    },
    {
      "classification_loss": 0.6346573829650879,
      "epoch": 6.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17974509298801422,
      "orthogonal_weight": 0.1,
      "step": 2028,
      "total_loss": 0.6526318788528442,
      "weighted_orthogonal_loss": 0.017974508926272392
    },
    {
      "classification_loss": 0.6778007745742798,
      "epoch": 6.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17977724969387054,
      "orthogonal_weight": 0.1,
      "step": 2029,
      "total_loss": 0.695778489112854,
      "weighted_orthogonal_loss": 0.017977725714445114
    },
    {
      "classification_loss": 0.616216242313385,
      "epoch": 6.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17979024350643158,
      "orthogonal_weight": 0.1,
      "step": 2030,
      "total_loss": 0.6341952681541443,
      "weighted_orthogonal_loss": 0.017979023978114128
    },
    {
      "classification_loss": 0.6546748280525208,
      "epoch": 6.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1797865927219391,
      "orthogonal_weight": 0.1,
      "step": 2031,
      "total_loss": 0.6726534962654114,
      "weighted_orthogonal_loss": 0.01797865889966488
    },
    {
      "classification_loss": 0.6372027397155762,
      "epoch": 6.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17983660101890564,
      "orthogonal_weight": 0.1,
      "step": 2032,
      "total_loss": 0.6551864147186279,
      "weighted_orthogonal_loss": 0.017983660101890564
    },
    {
      "classification_loss": 0.6295471787452698,
      "epoch": 6.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17991675436496735,
      "orthogonal_weight": 0.1,
      "step": 2033,
      "total_loss": 0.6475388407707214,
      "weighted_orthogonal_loss": 0.017991675063967705
    },
    {
      "classification_loss": 0.7121020555496216,
      "epoch": 6.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1800100952386856,
      "orthogonal_weight": 0.1,
      "step": 2034,
      "total_loss": 0.730103075504303,
      "weighted_orthogonal_loss": 0.01800101064145565
    },
    {
      "classification_loss": 0.6855161786079407,
      "epoch": 6.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18006037175655365,
      "orthogonal_weight": 0.1,
      "step": 2035,
      "total_loss": 0.7035222053527832,
      "weighted_orthogonal_loss": 0.018006037920713425
    },
    {
      "classification_loss": 0.6956571340560913,
      "epoch": 6.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1800168752670288,
      "orthogonal_weight": 0.1,
      "step": 2036,
      "total_loss": 0.7136588096618652,
      "weighted_orthogonal_loss": 0.01800168864428997
    },
    {
      "classification_loss": 0.6088207960128784,
      "epoch": 6.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17992913722991943,
      "orthogonal_weight": 0.1,
      "step": 2037,
      "total_loss": 0.6268137097358704,
      "weighted_orthogonal_loss": 0.017992913722991943
    },
    {
      "classification_loss": 0.6414444446563721,
      "epoch": 6.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17988602817058563,
      "orthogonal_weight": 0.1,
      "step": 2038,
      "total_loss": 0.6594330668449402,
      "weighted_orthogonal_loss": 0.017988603562116623
    },
    {
      "classification_loss": 0.638063371181488,
      "epoch": 6.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17984308302402496,
      "orthogonal_weight": 0.1,
      "step": 2039,
      "total_loss": 0.6560477018356323,
      "weighted_orthogonal_loss": 0.017984308302402496
    },
    {
      "classification_loss": 0.6375937461853027,
      "epoch": 6.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17984378337860107,
      "orthogonal_weight": 0.1,
      "step": 2040,
      "total_loss": 0.6555781364440918,
      "weighted_orthogonal_loss": 0.017984379082918167
    },
    {
      "classification_loss": 0.656512975692749,
      "epoch": 6.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1798878312110901,
      "orthogonal_weight": 0.1,
      "step": 2041,
      "total_loss": 0.6745017766952515,
      "weighted_orthogonal_loss": 0.0179887842386961
    },
    {
      "classification_loss": 0.6597017049789429,
      "epoch": 6.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18006631731987,
      "orthogonal_weight": 0.1,
      "step": 2042,
      "total_loss": 0.6777083277702332,
      "weighted_orthogonal_loss": 0.01800663210451603
    },
    {
      "classification_loss": 0.5763224959373474,
      "epoch": 6.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18011604249477386,
      "orthogonal_weight": 0.1,
      "step": 2043,
      "total_loss": 0.5943341255187988,
      "weighted_orthogonal_loss": 0.018011605367064476
    },
    {
      "classification_loss": 0.5964129567146301,
      "epoch": 6.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18015067279338837,
      "orthogonal_weight": 0.1,
      "step": 2044,
      "total_loss": 0.6144280433654785,
      "weighted_orthogonal_loss": 0.018015068024396896
    },
    {
      "classification_loss": 0.6784435510635376,
      "epoch": 6.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18023096024990082,
      "orthogonal_weight": 0.1,
      "step": 2045,
      "total_loss": 0.6964666247367859,
      "weighted_orthogonal_loss": 0.018023096024990082
    },
    {
      "classification_loss": 0.7456566095352173,
      "epoch": 6.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18026503920555115,
      "orthogonal_weight": 0.1,
      "step": 2046,
      "total_loss": 0.7636831402778625,
      "weighted_orthogonal_loss": 0.018026504665613174
    },
    {
      "classification_loss": 0.6870891451835632,
      "epoch": 6.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1802762746810913,
      "orthogonal_weight": 0.1,
      "step": 2047,
      "total_loss": 0.7051167488098145,
      "weighted_orthogonal_loss": 0.01802762784063816
    },
    {
      "classification_loss": 0.6008212566375732,
      "epoch": 6.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18023349344730377,
      "orthogonal_weight": 0.1,
      "step": 2048,
      "total_loss": 0.6188446283340454,
      "weighted_orthogonal_loss": 0.018023349344730377
    },
    {
      "classification_loss": 0.6202854514122009,
      "epoch": 6.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18019872903823853,
      "orthogonal_weight": 0.1,
      "step": 2049,
      "total_loss": 0.6383053064346313,
      "weighted_orthogonal_loss": 0.018019873648881912
    },
    {
      "classification_loss": 0.5653437972068787,
      "epoch": 6.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18014393746852875,
      "orthogonal_weight": 0.1,
      "step": 2050,
      "total_loss": 0.5833581686019897,
      "weighted_orthogonal_loss": 0.018014393746852875
    },
    {
      "classification_loss": 0.6748296618461609,
      "epoch": 6.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18019087612628937,
      "orthogonal_weight": 0.1,
      "step": 2051,
      "total_loss": 0.6928487420082092,
      "weighted_orthogonal_loss": 0.018019087612628937
    },
    {
      "classification_loss": 0.6472477316856384,
      "epoch": 6.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18021531403064728,
      "orthogonal_weight": 0.1,
      "step": 2052,
      "total_loss": 0.6652692556381226,
      "weighted_orthogonal_loss": 0.018021531403064728
    },
    {
      "classification_loss": 0.614690899848938,
      "epoch": 6.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18030110001564026,
      "orthogonal_weight": 0.1,
      "step": 2053,
      "total_loss": 0.6327210068702698,
      "weighted_orthogonal_loss": 0.018030110746622086
    },
    {
      "classification_loss": 0.5959773659706116,
      "epoch": 6.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18026843667030334,
      "orthogonal_weight": 0.1,
      "step": 2054,
      "total_loss": 0.6140041947364807,
      "weighted_orthogonal_loss": 0.018026843667030334
    },
    {
      "classification_loss": 0.6151784062385559,
      "epoch": 6.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18027742207050323,
      "orthogonal_weight": 0.1,
      "step": 2055,
      "total_loss": 0.6332061290740967,
      "weighted_orthogonal_loss": 0.018027743324637413
    },
    {
      "classification_loss": 0.6405766010284424,
      "epoch": 6.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18028825521469116,
      "orthogonal_weight": 0.1,
      "step": 2056,
      "total_loss": 0.6586054563522339,
      "weighted_orthogonal_loss": 0.018028825521469116
    },
    {
      "classification_loss": 0.6706677675247192,
      "epoch": 6.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18016250431537628,
      "orthogonal_weight": 0.1,
      "step": 2057,
      "total_loss": 0.6886840462684631,
      "weighted_orthogonal_loss": 0.018016250804066658
    },
    {
      "classification_loss": 0.6697853207588196,
      "epoch": 6.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17997916042804718,
      "orthogonal_weight": 0.1,
      "step": 2058,
      "total_loss": 0.6877832412719727,
      "weighted_orthogonal_loss": 0.017997916787862778
    },
    {
      "classification_loss": 0.6524063944816589,
      "epoch": 6.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17988331615924835,
      "orthogonal_weight": 0.1,
      "step": 2059,
      "total_loss": 0.6703947186470032,
      "weighted_orthogonal_loss": 0.017988331615924835
    },
    {
      "classification_loss": 0.638941764831543,
      "epoch": 6.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17973428964614868,
      "orthogonal_weight": 0.1,
      "step": 2060,
      "total_loss": 0.6569151878356934,
      "weighted_orthogonal_loss": 0.01797342859208584
    },
    {
      "classification_loss": 0.5830303430557251,
      "epoch": 6.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17954659461975098,
      "orthogonal_weight": 0.1,
      "step": 2061,
      "total_loss": 0.6009849905967712,
      "weighted_orthogonal_loss": 0.017954660579562187
    },
    {
      "classification_loss": 0.6598650813102722,
      "epoch": 6.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17934617400169373,
      "orthogonal_weight": 0.1,
      "step": 2062,
      "total_loss": 0.6777997016906738,
      "weighted_orthogonal_loss": 0.017934618517756462
    },
    {
      "classification_loss": 0.6715194582939148,
      "epoch": 6.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17920896410942078,
      "orthogonal_weight": 0.1,
      "step": 2063,
      "total_loss": 0.6894403696060181,
      "weighted_orthogonal_loss": 0.017920896410942078
    },
    {
      "classification_loss": 0.6549960374832153,
      "epoch": 6.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788702756166458,
      "orthogonal_weight": 0.1,
      "step": 2064,
      "total_loss": 0.6728830933570862,
      "weighted_orthogonal_loss": 0.01788702793419361
    },
    {
      "classification_loss": 0.6771464347839355,
      "epoch": 6.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17861482501029968,
      "orthogonal_weight": 0.1,
      "step": 2065,
      "total_loss": 0.6950079202651978,
      "weighted_orthogonal_loss": 0.017861483618617058
    },
    {
      "classification_loss": 0.6599161624908447,
      "epoch": 6.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17828361690044403,
      "orthogonal_weight": 0.1,
      "step": 2066,
      "total_loss": 0.6777445077896118,
      "weighted_orthogonal_loss": 0.017828362062573433
    },
    {
      "classification_loss": 0.6134910583496094,
      "epoch": 6.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17788270115852356,
      "orthogonal_weight": 0.1,
      "step": 2067,
      "total_loss": 0.6312793493270874,
      "weighted_orthogonal_loss": 0.017788270488381386
    },
    {
      "classification_loss": 0.6010789275169373,
      "epoch": 6.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.177507221698761,
      "orthogonal_weight": 0.1,
      "step": 2068,
      "total_loss": 0.6188296675682068,
      "weighted_orthogonal_loss": 0.017750723287463188
    },
    {
      "classification_loss": 0.6178407073020935,
      "epoch": 6.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17705410718917847,
      "orthogonal_weight": 0.1,
      "step": 2069,
      "total_loss": 0.635546088218689,
      "weighted_orthogonal_loss": 0.017705410718917847
    },
    {
      "classification_loss": 0.6588088274002075,
      "epoch": 6.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1767376959323883,
      "orthogonal_weight": 0.1,
      "step": 2070,
      "total_loss": 0.676482617855072,
      "weighted_orthogonal_loss": 0.01767376996576786
    },
    {
      "classification_loss": 0.6179718971252441,
      "epoch": 6.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1764640510082245,
      "orthogonal_weight": 0.1,
      "step": 2071,
      "total_loss": 0.6356183290481567,
      "weighted_orthogonal_loss": 0.01764640584588051
    },
    {
      "classification_loss": 0.6688675880432129,
      "epoch": 6.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17615988850593567,
      "orthogonal_weight": 0.1,
      "step": 2072,
      "total_loss": 0.6864835619926453,
      "weighted_orthogonal_loss": 0.017615988850593567
    },
    {
      "classification_loss": 0.677891731262207,
      "epoch": 6.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17570851743221283,
      "orthogonal_weight": 0.1,
      "step": 2073,
      "total_loss": 0.6954625844955444,
      "weighted_orthogonal_loss": 0.017570851370692253
    },
    {
      "classification_loss": 0.5952694416046143,
      "epoch": 6.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17535430192947388,
      "orthogonal_weight": 0.1,
      "step": 2074,
      "total_loss": 0.6128048896789551,
      "weighted_orthogonal_loss": 0.017535431310534477
    },
    {
      "classification_loss": 0.6281995177268982,
      "epoch": 6.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17503498494625092,
      "orthogonal_weight": 0.1,
      "step": 2075,
      "total_loss": 0.6457030177116394,
      "weighted_orthogonal_loss": 0.01750349812209606
    },
    {
      "classification_loss": 0.6417206525802612,
      "epoch": 6.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.174796462059021,
      "orthogonal_weight": 0.1,
      "step": 2076,
      "total_loss": 0.6592003107070923,
      "weighted_orthogonal_loss": 0.01747964695096016
    },
    {
      "classification_loss": 0.6187383532524109,
      "epoch": 6.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17459750175476074,
      "orthogonal_weight": 0.1,
      "step": 2077,
      "total_loss": 0.636198103427887,
      "weighted_orthogonal_loss": 0.017459750175476074
    },
    {
      "classification_loss": 0.6485015749931335,
      "epoch": 6.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1743704378604889,
      "orthogonal_weight": 0.1,
      "step": 2078,
      "total_loss": 0.6659386157989502,
      "weighted_orthogonal_loss": 0.01743704453110695
    },
    {
      "classification_loss": 0.7213496565818787,
      "epoch": 6.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1742149144411087,
      "orthogonal_weight": 0.1,
      "step": 2079,
      "total_loss": 0.7387711405754089,
      "weighted_orthogonal_loss": 0.01742149144411087
    },
    {
      "classification_loss": 0.6423169374465942,
      "epoch": 6.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17414243519306183,
      "orthogonal_weight": 0.1,
      "step": 2080,
      "total_loss": 0.6597312092781067,
      "weighted_orthogonal_loss": 0.017414243891835213
    },
    {
      "classification_loss": 0.6499497294425964,
      "epoch": 6.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17412573099136353,
      "orthogonal_weight": 0.1,
      "step": 2081,
      "total_loss": 0.6673623323440552,
      "weighted_orthogonal_loss": 0.017412573099136353
    },
    {
      "classification_loss": 0.6444634795188904,
      "epoch": 6.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1741575449705124,
      "orthogonal_weight": 0.1,
      "step": 2082,
      "total_loss": 0.6618792414665222,
      "weighted_orthogonal_loss": 0.01741575449705124
    },
    {
      "classification_loss": 0.6155734658241272,
      "epoch": 6.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1742178052663803,
      "orthogonal_weight": 0.1,
      "step": 2083,
      "total_loss": 0.6329952478408813,
      "weighted_orthogonal_loss": 0.017421780154109
    },
    {
      "classification_loss": 0.6100101470947266,
      "epoch": 6.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1743171215057373,
      "orthogonal_weight": 0.1,
      "step": 2084,
      "total_loss": 0.6274418830871582,
      "weighted_orthogonal_loss": 0.0174317117780447
    },
    {
      "classification_loss": 0.6679895520210266,
      "epoch": 6.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17439588904380798,
      "orthogonal_weight": 0.1,
      "step": 2085,
      "total_loss": 0.6854291558265686,
      "weighted_orthogonal_loss": 0.0174395889043808
    },
    {
      "classification_loss": 0.612490713596344,
      "epoch": 6.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17462535202503204,
      "orthogonal_weight": 0.1,
      "step": 2086,
      "total_loss": 0.6299532651901245,
      "weighted_orthogonal_loss": 0.017462534829974174
    },
    {
      "classification_loss": 0.6133416891098022,
      "epoch": 6.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17478066682815552,
      "orthogonal_weight": 0.1,
      "step": 2087,
      "total_loss": 0.6308197379112244,
      "weighted_orthogonal_loss": 0.01747806742787361
    },
    {
      "classification_loss": 0.7112920880317688,
      "epoch": 6.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17486700415611267,
      "orthogonal_weight": 0.1,
      "step": 2088,
      "total_loss": 0.7287787795066833,
      "weighted_orthogonal_loss": 0.017486700788140297
    },
    {
      "classification_loss": 0.7319586277008057,
      "epoch": 6.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17500422894954681,
      "orthogonal_weight": 0.1,
      "step": 2089,
      "total_loss": 0.7494590282440186,
      "weighted_orthogonal_loss": 0.01750042289495468
    },
    {
      "classification_loss": 0.6113441586494446,
      "epoch": 6.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.175137460231781,
      "orthogonal_weight": 0.1,
      "step": 2090,
      "total_loss": 0.6288579106330872,
      "weighted_orthogonal_loss": 0.01751374639570713
    },
    {
      "classification_loss": 0.6839994192123413,
      "epoch": 6.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752372533082962,
      "orthogonal_weight": 0.1,
      "step": 2091,
      "total_loss": 0.7015231251716614,
      "weighted_orthogonal_loss": 0.01752372644841671
    },
    {
      "classification_loss": 0.6616232395172119,
      "epoch": 6.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752375364303589,
      "orthogonal_weight": 0.1,
      "step": 2092,
      "total_loss": 0.6791470050811768,
      "weighted_orthogonal_loss": 0.01752375438809395
    },
    {
      "classification_loss": 0.63303542137146,
      "epoch": 6.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17528095841407776,
      "orthogonal_weight": 0.1,
      "step": 2093,
      "total_loss": 0.6505635380744934,
      "weighted_orthogonal_loss": 0.017528096213936806
    },
    {
      "classification_loss": 0.688802182674408,
      "epoch": 6.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17541885375976562,
      "orthogonal_weight": 0.1,
      "step": 2094,
      "total_loss": 0.7063440680503845,
      "weighted_orthogonal_loss": 0.017541885375976562
    },
    {
      "classification_loss": 0.6770018935203552,
      "epoch": 6.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1755901277065277,
      "orthogonal_weight": 0.1,
      "step": 2095,
      "total_loss": 0.6945608854293823,
      "weighted_orthogonal_loss": 0.01755901239812374
    },
    {
      "classification_loss": 0.6102299690246582,
      "epoch": 6.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17580172419548035,
      "orthogonal_weight": 0.1,
      "step": 2096,
      "total_loss": 0.6278101205825806,
      "weighted_orthogonal_loss": 0.017580172047019005
    },
    {
      "classification_loss": 0.6187097430229187,
      "epoch": 6.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17596015334129333,
      "orthogonal_weight": 0.1,
      "step": 2097,
      "total_loss": 0.6363057494163513,
      "weighted_orthogonal_loss": 0.017596015706658363
    },
    {
      "classification_loss": 0.5875527262687683,
      "epoch": 6.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1761089563369751,
      "orthogonal_weight": 0.1,
      "step": 2098,
      "total_loss": 0.6051636338233948,
      "weighted_orthogonal_loss": 0.01761089637875557
    },
    {
      "classification_loss": 0.5897432565689087,
      "epoch": 6.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17627468705177307,
      "orthogonal_weight": 0.1,
      "step": 2099,
      "total_loss": 0.6073707342147827,
      "weighted_orthogonal_loss": 0.017627468332648277
    },
    {
      "epoch": 6.885245901639344,
      "grad_norm": 22.61768913269043,
      "learning_rate": 0.00013336666666666666,
      "loss": 0.6619,
      "step": 2100
    },
    {
      "classification_loss": 0.6078628301620483,
      "epoch": 6.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1764792799949646,
      "orthogonal_weight": 0.1,
      "step": 2100,
      "total_loss": 0.6255107522010803,
      "weighted_orthogonal_loss": 0.01764792762696743
    },
    {
      "classification_loss": 0.6749798059463501,
      "epoch": 6.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17654451727867126,
      "orthogonal_weight": 0.1,
      "step": 2101,
      "total_loss": 0.6926342844963074,
      "weighted_orthogonal_loss": 0.017654452472925186
    },
    {
      "classification_loss": 0.7553433775901794,
      "epoch": 6.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17656674981117249,
      "orthogonal_weight": 0.1,
      "step": 2102,
      "total_loss": 0.7730000615119934,
      "weighted_orthogonal_loss": 0.01765667460858822
    },
    {
      "classification_loss": 0.6388153433799744,
      "epoch": 6.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1765626072883606,
      "orthogonal_weight": 0.1,
      "step": 2103,
      "total_loss": 0.6564716100692749,
      "weighted_orthogonal_loss": 0.01765626110136509
    },
    {
      "classification_loss": 0.6134611368179321,
      "epoch": 6.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1765160858631134,
      "orthogonal_weight": 0.1,
      "step": 2104,
      "total_loss": 0.6311127543449402,
      "weighted_orthogonal_loss": 0.01765160821378231
    },
    {
      "classification_loss": 0.6606574058532715,
      "epoch": 6.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17643897235393524,
      "orthogonal_weight": 0.1,
      "step": 2105,
      "total_loss": 0.6783012747764587,
      "weighted_orthogonal_loss": 0.017643896862864494
    },
    {
      "classification_loss": 0.6762112379074097,
      "epoch": 6.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17628560960292816,
      "orthogonal_weight": 0.1,
      "step": 2106,
      "total_loss": 0.6938397884368896,
      "weighted_orthogonal_loss": 0.017628561705350876
    },
    {
      "classification_loss": 0.678853452205658,
      "epoch": 6.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17620046436786652,
      "orthogonal_weight": 0.1,
      "step": 2107,
      "total_loss": 0.6964734792709351,
      "weighted_orthogonal_loss": 0.01762004755437374
    },
    {
      "classification_loss": 0.6497447490692139,
      "epoch": 6.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17605435848236084,
      "orthogonal_weight": 0.1,
      "step": 2108,
      "total_loss": 0.667350172996521,
      "weighted_orthogonal_loss": 0.017605436965823174
    },
    {
      "classification_loss": 0.6132539510726929,
      "epoch": 6.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17591498792171478,
      "orthogonal_weight": 0.1,
      "step": 2109,
      "total_loss": 0.6308454275131226,
      "weighted_orthogonal_loss": 0.01759149879217148
    },
    {
      "classification_loss": 0.6267503499984741,
      "epoch": 6.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17582717537879944,
      "orthogonal_weight": 0.1,
      "step": 2110,
      "total_loss": 0.6443330645561218,
      "weighted_orthogonal_loss": 0.017582718282938004
    },
    {
      "classification_loss": 0.6465420126914978,
      "epoch": 6.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17572331428527832,
      "orthogonal_weight": 0.1,
      "step": 2111,
      "total_loss": 0.6641143560409546,
      "weighted_orthogonal_loss": 0.01757233217358589
    },
    {
      "classification_loss": 0.6460550427436829,
      "epoch": 6.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17556937038898468,
      "orthogonal_weight": 0.1,
      "step": 2112,
      "total_loss": 0.6636120080947876,
      "weighted_orthogonal_loss": 0.017556937411427498
    },
    {
      "classification_loss": 0.6681658029556274,
      "epoch": 6.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17531633377075195,
      "orthogonal_weight": 0.1,
      "step": 2113,
      "total_loss": 0.6856974363327026,
      "weighted_orthogonal_loss": 0.017531633377075195
    },
    {
      "classification_loss": 0.6014893651008606,
      "epoch": 6.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1750936061143875,
      "orthogonal_weight": 0.1,
      "step": 2114,
      "total_loss": 0.6189987063407898,
      "weighted_orthogonal_loss": 0.01750936172902584
    },
    {
      "classification_loss": 0.6456207036972046,
      "epoch": 6.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17481842637062073,
      "orthogonal_weight": 0.1,
      "step": 2115,
      "total_loss": 0.6631025671958923,
      "weighted_orthogonal_loss": 0.017481843009591103
    },
    {
      "classification_loss": 0.6066544651985168,
      "epoch": 6.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17455777525901794,
      "orthogonal_weight": 0.1,
      "step": 2116,
      "total_loss": 0.624110221862793,
      "weighted_orthogonal_loss": 0.017455777153372765
    },
    {
      "classification_loss": 0.606909453868866,
      "epoch": 6.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17444704473018646,
      "orthogonal_weight": 0.1,
      "step": 2117,
      "total_loss": 0.6243541836738586,
      "weighted_orthogonal_loss": 0.017444705590605736
    },
    {
      "classification_loss": 0.676825761795044,
      "epoch": 6.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1744513213634491,
      "orthogonal_weight": 0.1,
      "step": 2118,
      "total_loss": 0.69427090883255,
      "weighted_orthogonal_loss": 0.01744513213634491
    },
    {
      "classification_loss": 0.7083569765090942,
      "epoch": 6.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17456257343292236,
      "orthogonal_weight": 0.1,
      "step": 2119,
      "total_loss": 0.7258132100105286,
      "weighted_orthogonal_loss": 0.017456257715821266
    },
    {
      "classification_loss": 0.6625191569328308,
      "epoch": 6.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17454805970191956,
      "orthogonal_weight": 0.1,
      "step": 2120,
      "total_loss": 0.6799739599227905,
      "weighted_orthogonal_loss": 0.017454806715250015
    },
    {
      "classification_loss": 0.6501815915107727,
      "epoch": 6.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17453593015670776,
      "orthogonal_weight": 0.1,
      "step": 2121,
      "total_loss": 0.6676352024078369,
      "weighted_orthogonal_loss": 0.017453594133257866
    },
    {
      "classification_loss": 0.6122554540634155,
      "epoch": 6.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17458167672157288,
      "orthogonal_weight": 0.1,
      "step": 2122,
      "total_loss": 0.6297135949134827,
      "weighted_orthogonal_loss": 0.017458168789744377
    },
    {
      "classification_loss": 0.6318325996398926,
      "epoch": 6.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17469348013401031,
      "orthogonal_weight": 0.1,
      "step": 2123,
      "total_loss": 0.6493019461631775,
      "weighted_orthogonal_loss": 0.01746934838593006
    },
    {
      "classification_loss": 0.5857292413711548,
      "epoch": 6.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1748305857181549,
      "orthogonal_weight": 0.1,
      "step": 2124,
      "total_loss": 0.603212296962738,
      "weighted_orthogonal_loss": 0.01748305931687355
    },
    {
      "classification_loss": 0.7039225697517395,
      "epoch": 6.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17501039803028107,
      "orthogonal_weight": 0.1,
      "step": 2125,
      "total_loss": 0.7214236259460449,
      "weighted_orthogonal_loss": 0.017501039430499077
    },
    {
      "classification_loss": 0.6782078146934509,
      "epoch": 6.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17514340579509735,
      "orthogonal_weight": 0.1,
      "step": 2126,
      "total_loss": 0.6957221627235413,
      "weighted_orthogonal_loss": 0.017514340579509735
    },
    {
      "classification_loss": 0.6915395259857178,
      "epoch": 6.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1752299666404724,
      "orthogonal_weight": 0.1,
      "step": 2127,
      "total_loss": 0.7090625166893005,
      "weighted_orthogonal_loss": 0.01752299629151821
    },
    {
      "classification_loss": 0.6253868341445923,
      "epoch": 6.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17529085278511047,
      "orthogonal_weight": 0.1,
      "step": 2128,
      "total_loss": 0.6429159045219421,
      "weighted_orthogonal_loss": 0.017529085278511047
    },
    {
      "classification_loss": 0.6392067074775696,
      "epoch": 6.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17535020411014557,
      "orthogonal_weight": 0.1,
      "step": 2129,
      "total_loss": 0.656741738319397,
      "weighted_orthogonal_loss": 0.017535021528601646
    },
    {
      "classification_loss": 0.5697853565216064,
      "epoch": 6.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17554809153079987,
      "orthogonal_weight": 0.1,
      "step": 2130,
      "total_loss": 0.5873401761054993,
      "weighted_orthogonal_loss": 0.017554810270667076
    },
    {
      "classification_loss": 0.6356841921806335,
      "epoch": 6.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17578643560409546,
      "orthogonal_weight": 0.1,
      "step": 2131,
      "total_loss": 0.6532628536224365,
      "weighted_orthogonal_loss": 0.017578644677996635
    },
    {
      "classification_loss": 0.6269140243530273,
      "epoch": 6.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17607469856739044,
      "orthogonal_weight": 0.1,
      "step": 2132,
      "total_loss": 0.6445214748382568,
      "weighted_orthogonal_loss": 0.017607470974326134
    },
    {
      "classification_loss": 0.6222565174102783,
      "epoch": 6.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17637474834918976,
      "orthogonal_weight": 0.1,
      "step": 2133,
      "total_loss": 0.6398940086364746,
      "weighted_orthogonal_loss": 0.017637474462389946
    },
    {
      "classification_loss": 0.653992772102356,
      "epoch": 6.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17672237753868103,
      "orthogonal_weight": 0.1,
      "step": 2134,
      "total_loss": 0.6716650128364563,
      "weighted_orthogonal_loss": 0.017672238871455193
    },
    {
      "classification_loss": 0.7154814600944519,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.7331845760345459,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.7044795751571655,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.7221826910972595,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.7093873620033264,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.7270904779434204,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.718397319316864,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.736100435256958,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.709381639957428,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.727084755897522,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.7094593644142151,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.7271624803543091,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.705522358417511,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.723225474357605,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.7165278792381287,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.7342309951782227,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.483,
      "eval_f1": 0.4608967674661105,
      "eval_loss": 0.7286520004272461,
      "eval_precision": 0.6577380952380952,
      "eval_recall": 0.3547351524879615,
      "eval_runtime": 6.162,
      "eval_samples_per_second": 162.285,
      "eval_steps_per_second": 1.298,
      "step": 2135
    },
    {
      "classification_loss": 0.614525556564331,
      "epoch": 7.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17703129351139069,
      "orthogonal_weight": 0.1,
      "step": 2135,
      "total_loss": 0.632228672504425,
      "weighted_orthogonal_loss": 0.01770312897861004
    },
    {
      "classification_loss": 0.6606104373931885,
      "epoch": 7.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17742520570755005,
      "orthogonal_weight": 0.1,
      "step": 2136,
      "total_loss": 0.678352952003479,
      "weighted_orthogonal_loss": 0.017742520198225975
    },
    {
      "classification_loss": 0.6660183072090149,
      "epoch": 7.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17775113880634308,
      "orthogonal_weight": 0.1,
      "step": 2137,
      "total_loss": 0.6837934255599976,
      "weighted_orthogonal_loss": 0.017775114625692368
    },
    {
      "classification_loss": 0.6928815245628357,
      "epoch": 7.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17802761495113373,
      "orthogonal_weight": 0.1,
      "step": 2138,
      "total_loss": 0.7106842994689941,
      "weighted_orthogonal_loss": 0.017802761867642403
    },
    {
      "classification_loss": 0.5496508479118347,
      "epoch": 7.0131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17825071513652802,
      "orthogonal_weight": 0.1,
      "step": 2139,
      "total_loss": 0.5674759149551392,
      "weighted_orthogonal_loss": 0.01782507263123989
    },
    {
      "classification_loss": 0.6270414590835571,
      "epoch": 7.016393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17845164239406586,
      "orthogonal_weight": 0.1,
      "step": 2140,
      "total_loss": 0.6448866128921509,
      "weighted_orthogonal_loss": 0.017845164984464645
    },
    {
      "classification_loss": 0.6574358940124512,
      "epoch": 7.019672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17861758172512054,
      "orthogonal_weight": 0.1,
      "step": 2141,
      "total_loss": 0.6752976775169373,
      "weighted_orthogonal_loss": 0.017861759290099144
    },
    {
      "classification_loss": 0.6027835011482239,
      "epoch": 7.022950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17873485386371613,
      "orthogonal_weight": 0.1,
      "step": 2142,
      "total_loss": 0.6206569671630859,
      "weighted_orthogonal_loss": 0.017873486503958702
    },
    {
      "classification_loss": 0.6517918705940247,
      "epoch": 7.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788499504327774,
      "orthogonal_weight": 0.1,
      "step": 2143,
      "total_loss": 0.6696768403053284,
      "weighted_orthogonal_loss": 0.0178849957883358
    },
    {
      "classification_loss": 0.6527222990989685,
      "epoch": 7.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17890676856040955,
      "orthogonal_weight": 0.1,
      "step": 2144,
      "total_loss": 0.6706129908561707,
      "weighted_orthogonal_loss": 0.017890676856040955
    },
    {
      "classification_loss": 0.6037694811820984,
      "epoch": 7.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17890651524066925,
      "orthogonal_weight": 0.1,
      "step": 2145,
      "total_loss": 0.6216601133346558,
      "weighted_orthogonal_loss": 0.017890652641654015
    },
    {
      "classification_loss": 0.6681252717971802,
      "epoch": 7.036065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788787841796875,
      "orthogonal_weight": 0.1,
      "step": 2146,
      "total_loss": 0.6860131621360779,
      "weighted_orthogonal_loss": 0.01788787916302681
    },
    {
      "classification_loss": 0.6392741203308105,
      "epoch": 7.039344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17883466184139252,
      "orthogonal_weight": 0.1,
      "step": 2147,
      "total_loss": 0.6571575999259949,
      "weighted_orthogonal_loss": 0.01788346655666828
    },
    {
      "classification_loss": 0.655506432056427,
      "epoch": 7.0426229508196725,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788780242204666,
      "orthogonal_weight": 0.1,
      "step": 2148,
      "total_loss": 0.6733942627906799,
      "weighted_orthogonal_loss": 0.01788780279457569
    },
    {
      "classification_loss": 0.6361693143844604,
      "epoch": 7.045901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17896345257759094,
      "orthogonal_weight": 0.1,
      "step": 2149,
      "total_loss": 0.6540656685829163,
      "weighted_orthogonal_loss": 0.017896344885230064
    },
    {
      "classification_loss": 0.6369648575782776,
      "epoch": 7.049180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17900897562503815,
      "orthogonal_weight": 0.1,
      "step": 2150,
      "total_loss": 0.6548657417297363,
      "weighted_orthogonal_loss": 0.017900897189974785
    },
    {
      "classification_loss": 0.6327794790267944,
      "epoch": 7.052459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17904527485370636,
      "orthogonal_weight": 0.1,
      "step": 2151,
      "total_loss": 0.6506839990615845,
      "weighted_orthogonal_loss": 0.017904527485370636
    },
    {
      "classification_loss": 0.6417127251625061,
      "epoch": 7.055737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17919093370437622,
      "orthogonal_weight": 0.1,
      "step": 2152,
      "total_loss": 0.6596318483352661,
      "weighted_orthogonal_loss": 0.017919093370437622
    },
    {
      "classification_loss": 0.6001998782157898,
      "epoch": 7.059016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17918707430362701,
      "orthogonal_weight": 0.1,
      "step": 2153,
      "total_loss": 0.6181185841560364,
      "weighted_orthogonal_loss": 0.01791870780289173
    },
    {
      "classification_loss": 0.6783692240715027,
      "epoch": 7.062295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.179158017039299,
      "orthogonal_weight": 0.1,
      "step": 2154,
      "total_loss": 0.6962850093841553,
      "weighted_orthogonal_loss": 0.01791580207645893
    },
    {
      "classification_loss": 0.6639955043792725,
      "epoch": 7.065573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17898470163345337,
      "orthogonal_weight": 0.1,
      "step": 2155,
      "total_loss": 0.6818939447402954,
      "weighted_orthogonal_loss": 0.017898470163345337
    },
    {
      "classification_loss": 0.6090282797813416,
      "epoch": 7.0688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17884701490402222,
      "orthogonal_weight": 0.1,
      "step": 2156,
      "total_loss": 0.6269129514694214,
      "weighted_orthogonal_loss": 0.01788470149040222
    },
    {
      "classification_loss": 0.7518519759178162,
      "epoch": 7.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17877252399921417,
      "orthogonal_weight": 0.1,
      "step": 2157,
      "total_loss": 0.7697292566299438,
      "weighted_orthogonal_loss": 0.017877252772450447
    },
    {
      "classification_loss": 0.6408384442329407,
      "epoch": 7.075409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17875415086746216,
      "orthogonal_weight": 0.1,
      "step": 2158,
      "total_loss": 0.6587138772010803,
      "weighted_orthogonal_loss": 0.017875416204333305
    },
    {
      "classification_loss": 0.7125441431999207,
      "epoch": 7.078688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788100153207779,
      "orthogonal_weight": 0.1,
      "step": 2159,
      "total_loss": 0.7304251194000244,
      "weighted_orthogonal_loss": 0.01788100227713585
    },
    {
      "classification_loss": 0.6333314776420593,
      "epoch": 7.081967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17889830470085144,
      "orthogonal_weight": 0.1,
      "step": 2160,
      "total_loss": 0.6512213349342346,
      "weighted_orthogonal_loss": 0.017889831215143204
    },
    {
      "classification_loss": 0.5855756998062134,
      "epoch": 7.085245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17893631756305695,
      "orthogonal_weight": 0.1,
      "step": 2161,
      "total_loss": 0.6034693121910095,
      "weighted_orthogonal_loss": 0.017893632873892784
    },
    {
      "classification_loss": 0.6388264894485474,
      "epoch": 7.088524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17903593182563782,
      "orthogonal_weight": 0.1,
      "step": 2162,
      "total_loss": 0.656730055809021,
      "weighted_orthogonal_loss": 0.01790359430015087
    },
    {
      "classification_loss": 0.6856175065040588,
      "epoch": 7.091803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17920339107513428,
      "orthogonal_weight": 0.1,
      "step": 2163,
      "total_loss": 0.7035378217697144,
      "weighted_orthogonal_loss": 0.017920339480042458
    },
    {
      "classification_loss": 0.6208317279815674,
      "epoch": 7.0950819672131145,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17941267788410187,
      "orthogonal_weight": 0.1,
      "step": 2164,
      "total_loss": 0.6387730240821838,
      "weighted_orthogonal_loss": 0.017941268160939217
    },
    {
      "classification_loss": 0.6605061888694763,
      "epoch": 7.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17963798344135284,
      "orthogonal_weight": 0.1,
      "step": 2165,
      "total_loss": 0.6784700155258179,
      "weighted_orthogonal_loss": 0.017963798716664314
    },
    {
      "classification_loss": 0.6763266921043396,
      "epoch": 7.101639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17983897030353546,
      "orthogonal_weight": 0.1,
      "step": 2166,
      "total_loss": 0.6943106055259705,
      "weighted_orthogonal_loss": 0.017983896657824516
    },
    {
      "classification_loss": 0.5751644372940063,
      "epoch": 7.104918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18008488416671753,
      "orthogonal_weight": 0.1,
      "step": 2167,
      "total_loss": 0.5931729078292847,
      "weighted_orthogonal_loss": 0.018008489161729813
    },
    {
      "classification_loss": 0.687813937664032,
      "epoch": 7.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18032033741474152,
      "orthogonal_weight": 0.1,
      "step": 2168,
      "total_loss": 0.7058459520339966,
      "weighted_orthogonal_loss": 0.01803203485906124
    },
    {
      "classification_loss": 0.6414082050323486,
      "epoch": 7.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18042659759521484,
      "orthogonal_weight": 0.1,
      "step": 2169,
      "total_loss": 0.659450888633728,
      "weighted_orthogonal_loss": 0.018042659386992455
    },
    {
      "classification_loss": 0.6354622840881348,
      "epoch": 7.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18057045340538025,
      "orthogonal_weight": 0.1,
      "step": 2170,
      "total_loss": 0.653519332408905,
      "weighted_orthogonal_loss": 0.018057046458125114
    },
    {
      "classification_loss": 0.6090387105941772,
      "epoch": 7.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18076953291893005,
      "orthogonal_weight": 0.1,
      "step": 2171,
      "total_loss": 0.6271156668663025,
      "weighted_orthogonal_loss": 0.018076954409480095
    },
    {
      "classification_loss": 0.6030719876289368,
      "epoch": 7.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1809527575969696,
      "orthogonal_weight": 0.1,
      "step": 2172,
      "total_loss": 0.6211672425270081,
      "weighted_orthogonal_loss": 0.01809527538716793
    },
    {
      "classification_loss": 0.6612414121627808,
      "epoch": 7.1245901639344265,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18110933899879456,
      "orthogonal_weight": 0.1,
      "step": 2173,
      "total_loss": 0.679352343082428,
      "weighted_orthogonal_loss": 0.018110934644937515
    },
    {
      "classification_loss": 0.7091822624206543,
      "epoch": 7.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18127389252185822,
      "orthogonal_weight": 0.1,
      "step": 2174,
      "total_loss": 0.7273096442222595,
      "weighted_orthogonal_loss": 0.01812738925218582
    },
    {
      "classification_loss": 0.699819803237915,
      "epoch": 7.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18128308653831482,
      "orthogonal_weight": 0.1,
      "step": 2175,
      "total_loss": 0.7179481387138367,
      "weighted_orthogonal_loss": 0.01812830939888954
    },
    {
      "classification_loss": 0.6275321245193481,
      "epoch": 7.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18127937614917755,
      "orthogonal_weight": 0.1,
      "step": 2176,
      "total_loss": 0.6456600427627563,
      "weighted_orthogonal_loss": 0.018127938732504845
    },
    {
      "classification_loss": 0.6664027571678162,
      "epoch": 7.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18122950196266174,
      "orthogonal_weight": 0.1,
      "step": 2177,
      "total_loss": 0.684525728225708,
      "weighted_orthogonal_loss": 0.018122950568795204
    },
    {
      "classification_loss": 0.6218110918998718,
      "epoch": 7.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1811566799879074,
      "orthogonal_weight": 0.1,
      "step": 2178,
      "total_loss": 0.6399267315864563,
      "weighted_orthogonal_loss": 0.01811566762626171
    },
    {
      "classification_loss": 0.6026541590690613,
      "epoch": 7.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1811026930809021,
      "orthogonal_weight": 0.1,
      "step": 2179,
      "total_loss": 0.620764434337616,
      "weighted_orthogonal_loss": 0.01811026968061924
    },
    {
      "classification_loss": 0.6735646724700928,
      "epoch": 7.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18104210495948792,
      "orthogonal_weight": 0.1,
      "step": 2180,
      "total_loss": 0.6916688680648804,
      "weighted_orthogonal_loss": 0.01810421049594879
    },
    {
      "classification_loss": 0.6444509029388428,
      "epoch": 7.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1809338480234146,
      "orthogonal_weight": 0.1,
      "step": 2181,
      "total_loss": 0.662544310092926,
      "weighted_orthogonal_loss": 0.01809338480234146
    },
    {
      "classification_loss": 0.653367817401886,
      "epoch": 7.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1808292269706726,
      "orthogonal_weight": 0.1,
      "step": 2182,
      "total_loss": 0.6714507341384888,
      "weighted_orthogonal_loss": 0.01808292232453823
    },
    {
      "classification_loss": 0.7108433246612549,
      "epoch": 7.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1807250827550888,
      "orthogonal_weight": 0.1,
      "step": 2183,
      "total_loss": 0.728915810585022,
      "weighted_orthogonal_loss": 0.01807250827550888
    },
    {
      "classification_loss": 0.652475118637085,
      "epoch": 7.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18059365451335907,
      "orthogonal_weight": 0.1,
      "step": 2184,
      "total_loss": 0.6705344915390015,
      "weighted_orthogonal_loss": 0.018059365451335907
    },
    {
      "classification_loss": 0.6769406795501709,
      "epoch": 7.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18045036494731903,
      "orthogonal_weight": 0.1,
      "step": 2185,
      "total_loss": 0.6949856877326965,
      "weighted_orthogonal_loss": 0.018045036122202873
    },
    {
      "classification_loss": 0.6297264695167542,
      "epoch": 7.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1803082972764969,
      "orthogonal_weight": 0.1,
      "step": 2186,
      "total_loss": 0.6477572917938232,
      "weighted_orthogonal_loss": 0.01803082972764969
    },
    {
      "classification_loss": 0.6049527525901794,
      "epoch": 7.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1801813542842865,
      "orthogonal_weight": 0.1,
      "step": 2187,
      "total_loss": 0.6229708790779114,
      "weighted_orthogonal_loss": 0.01801813580095768
    },
    {
      "classification_loss": 0.5803501605987549,
      "epoch": 7.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18008112907409668,
      "orthogonal_weight": 0.1,
      "step": 2188,
      "total_loss": 0.5983582735061646,
      "weighted_orthogonal_loss": 0.018008112907409668
    },
    {
      "classification_loss": 0.6873091459274292,
      "epoch": 7.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17982399463653564,
      "orthogonal_weight": 0.1,
      "step": 2189,
      "total_loss": 0.7052915692329407,
      "weighted_orthogonal_loss": 0.017982399091124535
    },
    {
      "classification_loss": 0.5739543437957764,
      "epoch": 7.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17966412007808685,
      "orthogonal_weight": 0.1,
      "step": 2190,
      "total_loss": 0.5919207334518433,
      "weighted_orthogonal_loss": 0.017966412007808685
    },
    {
      "classification_loss": 0.6005886197090149,
      "epoch": 7.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17953626811504364,
      "orthogonal_weight": 0.1,
      "step": 2191,
      "total_loss": 0.6185422539710999,
      "weighted_orthogonal_loss": 0.017953626811504364
    },
    {
      "classification_loss": 0.5350172519683838,
      "epoch": 7.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17953528463840485,
      "orthogonal_weight": 0.1,
      "step": 2192,
      "total_loss": 0.5529707670211792,
      "weighted_orthogonal_loss": 0.017953528091311455
    },
    {
      "classification_loss": 0.6959661841392517,
      "epoch": 7.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17952902615070343,
      "orthogonal_weight": 0.1,
      "step": 2193,
      "total_loss": 0.7139191031455994,
      "weighted_orthogonal_loss": 0.017952902242541313
    },
    {
      "classification_loss": 0.6095758080482483,
      "epoch": 7.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17941232025623322,
      "orthogonal_weight": 0.1,
      "step": 2194,
      "total_loss": 0.62751704454422,
      "weighted_orthogonal_loss": 0.01794123277068138
    },
    {
      "classification_loss": 0.6395102143287659,
      "epoch": 7.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1791812926530838,
      "orthogonal_weight": 0.1,
      "step": 2195,
      "total_loss": 0.6574283242225647,
      "weighted_orthogonal_loss": 0.01791813038289547
    },
    {
      "classification_loss": 0.6144677996635437,
      "epoch": 7.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1788650006055832,
      "orthogonal_weight": 0.1,
      "step": 2196,
      "total_loss": 0.6323543190956116,
      "weighted_orthogonal_loss": 0.01788650080561638
    },
    {
      "classification_loss": 0.7355090379714966,
      "epoch": 7.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17869527637958527,
      "orthogonal_weight": 0.1,
      "step": 2197,
      "total_loss": 0.7533785700798035,
      "weighted_orthogonal_loss": 0.017869528383016586
    },
    {
      "classification_loss": 0.6589094400405884,
      "epoch": 7.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17844708263874054,
      "orthogonal_weight": 0.1,
      "step": 2198,
      "total_loss": 0.6767541766166687,
      "weighted_orthogonal_loss": 0.017844708636403084
    },
    {
      "classification_loss": 0.6240727305412292,
      "epoch": 7.2098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17840498685836792,
      "orthogonal_weight": 0.1,
      "step": 2199,
      "total_loss": 0.6419132351875305,
      "weighted_orthogonal_loss": 0.017840499058365822
    },
    {
      "epoch": 7.213114754098361,
      "grad_norm": 24.06861686706543,
      "learning_rate": 0.00013003333333333334,
      "loss": 0.6616,
      "step": 2200
    },
    {
      "classification_loss": 0.5979226231575012,
      "epoch": 7.213114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17840991914272308,
      "orthogonal_weight": 0.1,
      "step": 2200,
      "total_loss": 0.6157636046409607,
      "weighted_orthogonal_loss": 0.017840992659330368
    },
    {
      "classification_loss": 0.6414431929588318,
      "epoch": 7.216393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17839625477790833,
      "orthogonal_weight": 0.1,
      "step": 2201,
      "total_loss": 0.6592828035354614,
      "weighted_orthogonal_loss": 0.017839625477790833
    },
    {
      "classification_loss": 0.6163991093635559,
      "epoch": 7.219672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17841875553131104,
      "orthogonal_weight": 0.1,
      "step": 2202,
      "total_loss": 0.634240984916687,
      "weighted_orthogonal_loss": 0.017841875553131104
    },
    {
      "classification_loss": 0.6302142143249512,
      "epoch": 7.222950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1784931868314743,
      "orthogonal_weight": 0.1,
      "step": 2203,
      "total_loss": 0.6480635404586792,
      "weighted_orthogonal_loss": 0.01784931868314743
    },
    {
      "classification_loss": 0.6030008792877197,
      "epoch": 7.226229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17862780392169952,
      "orthogonal_weight": 0.1,
      "step": 2204,
      "total_loss": 0.620863676071167,
      "weighted_orthogonal_loss": 0.017862780019640923
    },
    {
      "classification_loss": 0.6729111671447754,
      "epoch": 7.229508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17878250777721405,
      "orthogonal_weight": 0.1,
      "step": 2205,
      "total_loss": 0.6907894015312195,
      "weighted_orthogonal_loss": 0.017878251150250435
    },
    {
      "classification_loss": 0.6147496700286865,
      "epoch": 7.232786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17895953357219696,
      "orthogonal_weight": 0.1,
      "step": 2206,
      "total_loss": 0.6326456069946289,
      "weighted_orthogonal_loss": 0.017895953729748726
    },
    {
      "classification_loss": 0.663245677947998,
      "epoch": 7.2360655737704915,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17919869720935822,
      "orthogonal_weight": 0.1,
      "step": 2207,
      "total_loss": 0.6811655759811401,
      "weighted_orthogonal_loss": 0.01791987009346485
    },
    {
      "classification_loss": 0.6357490420341492,
      "epoch": 7.239344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17931346595287323,
      "orthogonal_weight": 0.1,
      "step": 2208,
      "total_loss": 0.6536803841590881,
      "weighted_orthogonal_loss": 0.017931347712874413
    },
    {
      "classification_loss": 0.6498217582702637,
      "epoch": 7.242622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1794743835926056,
      "orthogonal_weight": 0.1,
      "step": 2209,
      "total_loss": 0.667769193649292,
      "weighted_orthogonal_loss": 0.01794743910431862
    },
    {
      "classification_loss": 0.6224016547203064,
      "epoch": 7.245901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17961876094341278,
      "orthogonal_weight": 0.1,
      "step": 2210,
      "total_loss": 0.6403635144233704,
      "weighted_orthogonal_loss": 0.017961876466870308
    },
    {
      "classification_loss": 0.6077338457107544,
      "epoch": 7.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1797572821378708,
      "orthogonal_weight": 0.1,
      "step": 2211,
      "total_loss": 0.625709593296051,
      "weighted_orthogonal_loss": 0.01797572895884514
    },
    {
      "classification_loss": 0.69232177734375,
      "epoch": 7.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17983436584472656,
      "orthogonal_weight": 0.1,
      "step": 2212,
      "total_loss": 0.7103052139282227,
      "weighted_orthogonal_loss": 0.017983436584472656
    },
    {
      "classification_loss": 0.6568421721458435,
      "epoch": 7.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1795019954442978,
      "orthogonal_weight": 0.1,
      "step": 2213,
      "total_loss": 0.6747923493385315,
      "weighted_orthogonal_loss": 0.01795019954442978
    },
    {
      "classification_loss": 0.598831295967102,
      "epoch": 7.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17923350632190704,
      "orthogonal_weight": 0.1,
      "step": 2214,
      "total_loss": 0.6167546510696411,
      "weighted_orthogonal_loss": 0.017923351377248764
    },
    {
      "classification_loss": 0.6394935250282288,
      "epoch": 7.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17911547422409058,
      "orthogonal_weight": 0.1,
      "step": 2215,
      "total_loss": 0.6574050784111023,
      "weighted_orthogonal_loss": 0.017911547794938087
    },
    {
      "classification_loss": 0.6103017330169678,
      "epoch": 7.2655737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1790519654750824,
      "orthogonal_weight": 0.1,
      "step": 2216,
      "total_loss": 0.6282069087028503,
      "weighted_orthogonal_loss": 0.01790519617497921
    },
    {
      "classification_loss": 0.5623133778572083,
      "epoch": 7.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1790197789669037,
      "orthogonal_weight": 0.1,
      "step": 2217,
      "total_loss": 0.580215334892273,
      "weighted_orthogonal_loss": 0.01790197752416134
    },
    {
      "classification_loss": 0.6644541621208191,
      "epoch": 7.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17909210920333862,
      "orthogonal_weight": 0.1,
      "step": 2218,
      "total_loss": 0.6823633909225464,
      "weighted_orthogonal_loss": 0.017909212037920952
    },
    {
      "classification_loss": 0.5917354822158813,
      "epoch": 7.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17916777729988098,
      "orthogonal_weight": 0.1,
      "step": 2219,
      "total_loss": 0.6096522808074951,
      "weighted_orthogonal_loss": 0.017916778102517128
    },
    {
      "classification_loss": 0.6778795123100281,
      "epoch": 7.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17940464615821838,
      "orthogonal_weight": 0.1,
      "step": 2220,
      "total_loss": 0.6958199739456177,
      "weighted_orthogonal_loss": 0.017940465360879898
    },
    {
      "classification_loss": 0.6055368781089783,
      "epoch": 7.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17958463728427887,
      "orthogonal_weight": 0.1,
      "step": 2221,
      "total_loss": 0.62349534034729,
      "weighted_orthogonal_loss": 0.017958464100956917
    },
    {
      "classification_loss": 0.6677653193473816,
      "epoch": 7.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17975953221321106,
      "orthogonal_weight": 0.1,
      "step": 2222,
      "total_loss": 0.6857412457466125,
      "weighted_orthogonal_loss": 0.017975954338908195
    },
    {
      "classification_loss": 0.6898952126502991,
      "epoch": 7.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1799585074186325,
      "orthogonal_weight": 0.1,
      "step": 2223,
      "total_loss": 0.707891047000885,
      "weighted_orthogonal_loss": 0.01799585111439228
    },
    {
      "classification_loss": 0.6353424191474915,
      "epoch": 7.2918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1799963265657425,
      "orthogonal_weight": 0.1,
      "step": 2224,
      "total_loss": 0.653342068195343,
      "weighted_orthogonal_loss": 0.01799963228404522
    },
    {
      "classification_loss": 0.65433269739151,
      "epoch": 7.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17995671927928925,
      "orthogonal_weight": 0.1,
      "step": 2225,
      "total_loss": 0.6723283529281616,
      "weighted_orthogonal_loss": 0.017995672300457954
    },
    {
      "classification_loss": 0.5208788514137268,
      "epoch": 7.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17988033592700958,
      "orthogonal_weight": 0.1,
      "step": 2226,
      "total_loss": 0.5388668775558472,
      "weighted_orthogonal_loss": 0.017988033592700958
    },
    {
      "classification_loss": 0.638906717300415,
      "epoch": 7.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.17979250848293304,
      "orthogonal_weight": 0.1,
      "step": 2227,
      "total_loss": 0.6568859815597534,
      "weighted_orthogonal_loss": 0.017979251220822334
    },
    {
      "classification_loss": 0.633287787437439,
      "epoch": 7.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1798596829175949,
      "orthogonal_weight": 0.1,
      "step": 2228,
      "total_loss": 0.6512737274169922,
      "weighted_orthogonal_loss": 0.01798596791923046
    },
    {
      "classification_loss": 0.6473872065544128,
      "epoch": 7.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18040397763252258,
      "orthogonal_weight": 0.1,
      "step": 2229,
      "total_loss": 0.6654276251792908,
      "weighted_orthogonal_loss": 0.018040398135781288
    },
    {
      "classification_loss": 0.6288188695907593,
      "epoch": 7.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18099002540111542,
      "orthogonal_weight": 0.1,
      "step": 2230,
      "total_loss": 0.6469178795814514,
      "weighted_orthogonal_loss": 0.018099002540111542
    },
    {
      "classification_loss": 0.627845287322998,
      "epoch": 7.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18165837228298187,
      "orthogonal_weight": 0.1,
      "step": 2231,
      "total_loss": 0.6460111141204834,
      "weighted_orthogonal_loss": 0.018165837973356247
    },
    {
      "classification_loss": 0.6830258965492249,
      "epoch": 7.3180327868852455,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18235960602760315,
      "orthogonal_weight": 0.1,
      "step": 2232,
      "total_loss": 0.7012618780136108,
      "weighted_orthogonal_loss": 0.018235960975289345
    },
    {
      "classification_loss": 0.6080636978149414,
      "epoch": 7.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18305593729019165,
      "orthogonal_weight": 0.1,
      "step": 2233,
      "total_loss": 0.626369297504425,
      "weighted_orthogonal_loss": 0.018305594101548195
    },
    {
      "classification_loss": 0.6090699434280396,
      "epoch": 7.324590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18374672532081604,
      "orthogonal_weight": 0.1,
      "step": 2234,
      "total_loss": 0.6274446249008179,
      "weighted_orthogonal_loss": 0.018374672159552574
    },
    {
      "classification_loss": 0.6704506278038025,
      "epoch": 7.327868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1844049096107483,
      "orthogonal_weight": 0.1,
      "step": 2235,
      "total_loss": 0.6888911128044128,
      "weighted_orthogonal_loss": 0.0184404905885458
    },
    {
      "classification_loss": 0.5961480140686035,
      "epoch": 7.331147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1849861890077591,
      "orthogonal_weight": 0.1,
      "step": 2236,
      "total_loss": 0.6146466135978699,
      "weighted_orthogonal_loss": 0.018498620018363
    },
    {
      "classification_loss": 0.6276962757110596,
      "epoch": 7.334426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18545962870121002,
      "orthogonal_weight": 0.1,
      "step": 2237,
      "total_loss": 0.6462422609329224,
      "weighted_orthogonal_loss": 0.018545962870121002
    },
    {
      "classification_loss": 0.6373966336250305,
      "epoch": 7.337704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18586833775043488,
      "orthogonal_weight": 0.1,
      "step": 2238,
      "total_loss": 0.6559834480285645,
      "weighted_orthogonal_loss": 0.018586834892630577
    },
    {
      "classification_loss": 0.6589848399162292,
      "epoch": 7.340983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18615323305130005,
      "orthogonal_weight": 0.1,
      "step": 2239,
      "total_loss": 0.6776001453399658,
      "weighted_orthogonal_loss": 0.018615324050188065
    },
    {
      "classification_loss": 0.5783777832984924,
      "epoch": 7.344262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18635255098342896,
      "orthogonal_weight": 0.1,
      "step": 2240,
      "total_loss": 0.5970130562782288,
      "weighted_orthogonal_loss": 0.018635256215929985
    },
    {
      "classification_loss": 0.6699021458625793,
      "epoch": 7.3475409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18655027449131012,
      "orthogonal_weight": 0.1,
      "step": 2241,
      "total_loss": 0.6885571479797363,
      "weighted_orthogonal_loss": 0.01865502819418907
    },
    {
      "classification_loss": 0.7091361880302429,
      "epoch": 7.350819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18626031279563904,
      "orthogonal_weight": 0.1,
      "step": 2242,
      "total_loss": 0.7277622222900391,
      "weighted_orthogonal_loss": 0.018626032397150993
    },
    {
      "classification_loss": 0.5941258072853088,
      "epoch": 7.354098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18578165769577026,
      "orthogonal_weight": 0.1,
      "step": 2243,
      "total_loss": 0.6127039790153503,
      "weighted_orthogonal_loss": 0.018578166142106056
    },
    {
      "classification_loss": 0.6377105712890625,
      "epoch": 7.357377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1852508932352066,
      "orthogonal_weight": 0.1,
      "step": 2244,
      "total_loss": 0.6562356352806091,
      "weighted_orthogonal_loss": 0.01852509006857872
    },
    {
      "classification_loss": 0.6146210432052612,
      "epoch": 7.360655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1847778707742691,
      "orthogonal_weight": 0.1,
      "step": 2245,
      "total_loss": 0.633098840713501,
      "weighted_orthogonal_loss": 0.018477788195014
    },
    {
      "classification_loss": 0.6329611539840698,
      "epoch": 7.363934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1843348890542984,
      "orthogonal_weight": 0.1,
      "step": 2246,
      "total_loss": 0.6513946652412415,
      "weighted_orthogonal_loss": 0.01843348890542984
    },
    {
      "classification_loss": 0.6622601747512817,
      "epoch": 7.367213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18382719159126282,
      "orthogonal_weight": 0.1,
      "step": 2247,
      "total_loss": 0.6806429028511047,
      "weighted_orthogonal_loss": 0.018382718786597252
    },
    {
      "classification_loss": 0.659694492816925,
      "epoch": 7.370491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1834726631641388,
      "orthogonal_weight": 0.1,
      "step": 2248,
      "total_loss": 0.6780417561531067,
      "weighted_orthogonal_loss": 0.01834726706147194
    },
    {
      "classification_loss": 0.6252105236053467,
      "epoch": 7.3737704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18315991759300232,
      "orthogonal_weight": 0.1,
      "step": 2249,
      "total_loss": 0.6435264945030212,
      "weighted_orthogonal_loss": 0.018315991386771202
    },
    {
      "classification_loss": 0.5556633472442627,
      "epoch": 7.377049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18292303383350372,
      "orthogonal_weight": 0.1,
      "step": 2250,
      "total_loss": 0.5739556550979614,
      "weighted_orthogonal_loss": 0.018292304128408432
    },
    {
      "classification_loss": 0.6219235062599182,
      "epoch": 7.380327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.182821124792099,
      "orthogonal_weight": 0.1,
      "step": 2251,
      "total_loss": 0.6402056217193604,
      "weighted_orthogonal_loss": 0.01828211359679699
    },
    {
      "classification_loss": 0.6278442144393921,
      "epoch": 7.383606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1828198879957199,
      "orthogonal_weight": 0.1,
      "step": 2252,
      "total_loss": 0.6461262106895447,
      "weighted_orthogonal_loss": 0.01828198879957199
    },
    {
      "classification_loss": 0.68886399269104,
      "epoch": 7.386885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18288955092430115,
      "orthogonal_weight": 0.1,
      "step": 2253,
      "total_loss": 0.7071529626846313,
      "weighted_orthogonal_loss": 0.018288955092430115
    },
    {
      "classification_loss": 0.7405287027359009,
      "epoch": 7.390163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18285450339317322,
      "orthogonal_weight": 0.1,
      "step": 2254,
      "total_loss": 0.7588141560554504,
      "weighted_orthogonal_loss": 0.01828545145690441
    },
    {
      "classification_loss": 0.6593334078788757,
      "epoch": 7.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18291020393371582,
      "orthogonal_weight": 0.1,
      "step": 2255,
      "total_loss": 0.6776244044303894,
      "weighted_orthogonal_loss": 0.018291020765900612
    },
    {
      "classification_loss": 0.6392789483070374,
      "epoch": 7.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18300314247608185,
      "orthogonal_weight": 0.1,
      "step": 2256,
      "total_loss": 0.657579243183136,
      "weighted_orthogonal_loss": 0.018300315365195274
    },
    {
      "classification_loss": 0.5868589878082275,
      "epoch": 7.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18303120136260986,
      "orthogonal_weight": 0.1,
      "step": 2257,
      "total_loss": 0.6051620841026306,
      "weighted_orthogonal_loss": 0.018303120508790016
    },
    {
      "classification_loss": 0.6202056407928467,
      "epoch": 7.4032786885245905,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18328575789928436,
      "orthogonal_weight": 0.1,
      "step": 2258,
      "total_loss": 0.6385341882705688,
      "weighted_orthogonal_loss": 0.018328575417399406
    },
    {
      "classification_loss": 0.7087169289588928,
      "epoch": 7.406557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18355681002140045,
      "orthogonal_weight": 0.1,
      "step": 2259,
      "total_loss": 0.7270725965499878,
      "weighted_orthogonal_loss": 0.018355680629611015
    },
    {
      "classification_loss": 0.5859968066215515,
      "epoch": 7.409836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18381579220294952,
      "orthogonal_weight": 0.1,
      "step": 2260,
      "total_loss": 0.6043784022331238,
      "weighted_orthogonal_loss": 0.018381578847765923
    },
    {
      "classification_loss": 0.6766533851623535,
      "epoch": 7.413114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.184105783700943,
      "orthogonal_weight": 0.1,
      "step": 2261,
      "total_loss": 0.6950639486312866,
      "weighted_orthogonal_loss": 0.0184105783700943
    },
    {
      "classification_loss": 0.5628964900970459,
      "epoch": 7.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18438312411308289,
      "orthogonal_weight": 0.1,
      "step": 2262,
      "total_loss": 0.5813348293304443,
      "weighted_orthogonal_loss": 0.01843831315636635
    },
    {
      "classification_loss": 0.6687272191047668,
      "epoch": 7.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18459638953208923,
      "orthogonal_weight": 0.1,
      "step": 2263,
      "total_loss": 0.6871868371963501,
      "weighted_orthogonal_loss": 0.018459638580679893
    },
    {
      "classification_loss": 0.6330535411834717,
      "epoch": 7.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18472321331501007,
      "orthogonal_weight": 0.1,
      "step": 2264,
      "total_loss": 0.6515258550643921,
      "weighted_orthogonal_loss": 0.018472321331501007
    },
    {
      "classification_loss": 0.7016780376434326,
      "epoch": 7.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18478015065193176,
      "orthogonal_weight": 0.1,
      "step": 2265,
      "total_loss": 0.7201560735702515,
      "weighted_orthogonal_loss": 0.018478015437722206
    },
    {
      "classification_loss": 0.6359363794326782,
      "epoch": 7.4295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18475735187530518,
      "orthogonal_weight": 0.1,
      "step": 2266,
      "total_loss": 0.6544120907783508,
      "weighted_orthogonal_loss": 0.018475735560059547
    },
    {
      "classification_loss": 0.6855399012565613,
      "epoch": 7.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18471379578113556,
      "orthogonal_weight": 0.1,
      "step": 2267,
      "total_loss": 0.7040112614631653,
      "weighted_orthogonal_loss": 0.018471380695700645
    },
    {
      "classification_loss": 0.5866991281509399,
      "epoch": 7.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1845778524875641,
      "orthogonal_weight": 0.1,
      "step": 2268,
      "total_loss": 0.6051568984985352,
      "weighted_orthogonal_loss": 0.01845778524875641
    },
    {
      "classification_loss": 0.6081616282463074,
      "epoch": 7.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1844244748353958,
      "orthogonal_weight": 0.1,
      "step": 2269,
      "total_loss": 0.6266040802001953,
      "weighted_orthogonal_loss": 0.01844244822859764
    },
    {
      "classification_loss": 0.6507384777069092,
      "epoch": 7.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1842302829027176,
      "orthogonal_weight": 0.1,
      "step": 2270,
      "total_loss": 0.6691614985466003,
      "weighted_orthogonal_loss": 0.01842302829027176
    },
    {
      "classification_loss": 0.6372540593147278,
      "epoch": 7.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1839502900838852,
      "orthogonal_weight": 0.1,
      "step": 2271,
      "total_loss": 0.6556490659713745,
      "weighted_orthogonal_loss": 0.01839502900838852
    },
    {
      "classification_loss": 0.566741943359375,
      "epoch": 7.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18369685113430023,
      "orthogonal_weight": 0.1,
      "step": 2272,
      "total_loss": 0.5851116180419922,
      "weighted_orthogonal_loss": 0.018369685858488083
    },
    {
      "classification_loss": 0.6114648580551147,
      "epoch": 7.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18344879150390625,
      "orthogonal_weight": 0.1,
      "step": 2273,
      "total_loss": 0.6298097372055054,
      "weighted_orthogonal_loss": 0.018344879150390625
    },
    {
      "classification_loss": 0.6177475452423096,
      "epoch": 7.4557377049180324,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1831836998462677,
      "orthogonal_weight": 0.1,
      "step": 2274,
      "total_loss": 0.6360659003257751,
      "weighted_orthogonal_loss": 0.01831836998462677
    },
    {
      "classification_loss": 0.694349467754364,
      "epoch": 7.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18298088014125824,
      "orthogonal_weight": 0.1,
      "step": 2275,
      "total_loss": 0.712647557258606,
      "weighted_orthogonal_loss": 0.018298087641596794
    },
    {
      "classification_loss": 0.5732452273368835,
      "epoch": 7.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18283328413963318,
      "orthogonal_weight": 0.1,
      "step": 2276,
      "total_loss": 0.5915285348892212,
      "weighted_orthogonal_loss": 0.018283328041434288
    },
    {
      "classification_loss": 0.5911779403686523,
      "epoch": 7.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18279071152210236,
      "orthogonal_weight": 0.1,
      "step": 2277,
      "total_loss": 0.6094570159912109,
      "weighted_orthogonal_loss": 0.018279071897268295
    },
    {
      "classification_loss": 0.663355827331543,
      "epoch": 7.468852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18283815681934357,
      "orthogonal_weight": 0.1,
      "step": 2278,
      "total_loss": 0.6816396713256836,
      "weighted_orthogonal_loss": 0.018283816054463387
    },
    {
      "classification_loss": 0.7741991877555847,
      "epoch": 7.472131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1829238086938858,
      "orthogonal_weight": 0.1,
      "step": 2279,
      "total_loss": 0.7924915552139282,
      "weighted_orthogonal_loss": 0.01829238049685955
    },
    {
      "classification_loss": 0.6358034014701843,
      "epoch": 7.475409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1830480545759201,
      "orthogonal_weight": 0.1,
      "step": 2280,
      "total_loss": 0.6541082262992859,
      "weighted_orthogonal_loss": 0.01830480620265007
    },
    {
      "classification_loss": 0.5321868658065796,
      "epoch": 7.478688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18312326073646545,
      "orthogonal_weight": 0.1,
      "step": 2281,
      "total_loss": 0.5504992008209229,
      "weighted_orthogonal_loss": 0.018312325701117516
    },
    {
      "classification_loss": 0.6021329164505005,
      "epoch": 7.481967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1832161247730255,
      "orthogonal_weight": 0.1,
      "step": 2282,
      "total_loss": 0.6204545497894287,
      "weighted_orthogonal_loss": 0.01832161284983158
    },
    {
      "classification_loss": 0.5694252848625183,
      "epoch": 7.4852459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18331678211688995,
      "orthogonal_weight": 0.1,
      "step": 2283,
      "total_loss": 0.5877569913864136,
      "weighted_orthogonal_loss": 0.018331678584218025
    },
    {
      "classification_loss": 0.6408653259277344,
      "epoch": 7.488524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18343980610370636,
      "orthogonal_weight": 0.1,
      "step": 2284,
      "total_loss": 0.6592093110084534,
      "weighted_orthogonal_loss": 0.018343981355428696
    },
    {
      "classification_loss": 0.7280013561248779,
      "epoch": 7.491803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18360188603401184,
      "orthogonal_weight": 0.1,
      "step": 2285,
      "total_loss": 0.7463615536689758,
      "weighted_orthogonal_loss": 0.018360188230872154
    },
    {
      "classification_loss": 0.6186648607254028,
      "epoch": 7.495081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18368728458881378,
      "orthogonal_weight": 0.1,
      "step": 2286,
      "total_loss": 0.6370335817337036,
      "weighted_orthogonal_loss": 0.018368728458881378
    },
    {
      "classification_loss": 0.6767048835754395,
      "epoch": 7.498360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18393629789352417,
      "orthogonal_weight": 0.1,
      "step": 2287,
      "total_loss": 0.6950985193252563,
      "weighted_orthogonal_loss": 0.018393630161881447
    },
    {
      "classification_loss": 0.6323592662811279,
      "epoch": 7.501639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18425162136554718,
      "orthogonal_weight": 0.1,
      "step": 2288,
      "total_loss": 0.650784432888031,
      "weighted_orthogonal_loss": 0.018425162881612778
    },
    {
      "classification_loss": 0.6452491283416748,
      "epoch": 7.504918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1840352565050125,
      "orthogonal_weight": 0.1,
      "step": 2289,
      "total_loss": 0.6636526584625244,
      "weighted_orthogonal_loss": 0.01840352639555931
    },
    {
      "classification_loss": 0.5843256711959839,
      "epoch": 7.508196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1839136928319931,
      "orthogonal_weight": 0.1,
      "step": 2290,
      "total_loss": 0.6027170419692993,
      "weighted_orthogonal_loss": 0.01839136891067028
    },
    {
      "classification_loss": 0.6692761182785034,
      "epoch": 7.511475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18384642899036407,
      "orthogonal_weight": 0.1,
      "step": 2291,
      "total_loss": 0.6876607537269592,
      "weighted_orthogonal_loss": 0.018384642899036407
    },
    {
      "classification_loss": 0.6880089044570923,
      "epoch": 7.5147540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18375514447689056,
      "orthogonal_weight": 0.1,
      "step": 2292,
      "total_loss": 0.7063844203948975,
      "weighted_orthogonal_loss": 0.018375514075160027
    },
    {
      "classification_loss": 0.5988865494728088,
      "epoch": 7.518032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18375016748905182,
      "orthogonal_weight": 0.1,
      "step": 2293,
      "total_loss": 0.6172615885734558,
      "weighted_orthogonal_loss": 0.018375016748905182
    },
    {
      "classification_loss": 0.6191357374191284,
      "epoch": 7.521311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18376874923706055,
      "orthogonal_weight": 0.1,
      "step": 2294,
      "total_loss": 0.6375126242637634,
      "weighted_orthogonal_loss": 0.018376875668764114
    },
    {
      "classification_loss": 0.6747168302536011,
      "epoch": 7.524590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.183778777718544,
      "orthogonal_weight": 0.1,
      "step": 2295,
      "total_loss": 0.6930947303771973,
      "weighted_orthogonal_loss": 0.0183778777718544
    },
    {
      "classification_loss": 0.5438169836997986,
      "epoch": 7.527868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18387135863304138,
      "orthogonal_weight": 0.1,
      "step": 2296,
      "total_loss": 0.562204122543335,
      "weighted_orthogonal_loss": 0.018387136980891228
    },
    {
      "classification_loss": 0.6923498511314392,
      "epoch": 7.531147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18406036496162415,
      "orthogonal_weight": 0.1,
      "step": 2297,
      "total_loss": 0.7107558846473694,
      "weighted_orthogonal_loss": 0.018406037241220474
    },
    {
      "classification_loss": 0.5773051977157593,
      "epoch": 7.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18426395952701569,
      "orthogonal_weight": 0.1,
      "step": 2298,
      "total_loss": 0.5957316160202026,
      "weighted_orthogonal_loss": 0.01842639595270157
    },
    {
      "classification_loss": 0.6221486330032349,
      "epoch": 7.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18455593287944794,
      "orthogonal_weight": 0.1,
      "step": 2299,
      "total_loss": 0.6406041979789734,
      "weighted_orthogonal_loss": 0.018455592915415764
    },
    {
      "epoch": 7.540983606557377,
      "grad_norm": 5.236283779144287,
      "learning_rate": 0.0001267,
      "loss": 0.6523,
      "step": 2300
    },
    {
      "classification_loss": 0.7000764012336731,
      "epoch": 7.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18475337326526642,
      "orthogonal_weight": 0.1,
      "step": 2300,
      "total_loss": 0.718551754951477,
      "weighted_orthogonal_loss": 0.018475336953997612
    },
    {
      "classification_loss": 0.651807963848114,
      "epoch": 7.5442622950819676,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18483871221542358,
      "orthogonal_weight": 0.1,
      "step": 2301,
      "total_loss": 0.6702918410301208,
      "weighted_orthogonal_loss": 0.018483871594071388
    },
    {
      "classification_loss": 0.6232815980911255,
      "epoch": 7.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1849261075258255,
      "orthogonal_weight": 0.1,
      "step": 2302,
      "total_loss": 0.6417742371559143,
      "weighted_orthogonal_loss": 0.01849261112511158
    },
    {
      "classification_loss": 0.595207154750824,
      "epoch": 7.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18503375351428986,
      "orthogonal_weight": 0.1,
      "step": 2303,
      "total_loss": 0.6137105226516724,
      "weighted_orthogonal_loss": 0.018503375351428986
    },
    {
      "classification_loss": 0.5969610810279846,
      "epoch": 7.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18506373465061188,
      "orthogonal_weight": 0.1,
      "step": 2304,
      "total_loss": 0.6154674291610718,
      "weighted_orthogonal_loss": 0.018506374210119247
    },
    {
      "classification_loss": 0.6593775749206543,
      "epoch": 7.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18501770496368408,
      "orthogonal_weight": 0.1,
      "step": 2305,
      "total_loss": 0.6778793334960938,
      "weighted_orthogonal_loss": 0.018501771613955498
    },
    {
      "classification_loss": 0.6505841612815857,
      "epoch": 7.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18498913943767548,
      "orthogonal_weight": 0.1,
      "step": 2306,
      "total_loss": 0.6690830588340759,
      "weighted_orthogonal_loss": 0.018498914316296577
    },
    {
      "classification_loss": 0.6422947645187378,
      "epoch": 7.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1850212961435318,
      "orthogonal_weight": 0.1,
      "step": 2307,
      "total_loss": 0.6607968807220459,
      "weighted_orthogonal_loss": 0.01850212924182415
    },
    {
      "classification_loss": 0.7872114181518555,
      "epoch": 7.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18502621352672577,
      "orthogonal_weight": 0.1,
      "step": 2308,
      "total_loss": 0.8057140111923218,
      "weighted_orthogonal_loss": 0.018502620980143547
    },
    {
      "classification_loss": 0.6689450740814209,
      "epoch": 7.5704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1848936378955841,
      "orthogonal_weight": 0.1,
      "step": 2309,
      "total_loss": 0.6874344348907471,
      "weighted_orthogonal_loss": 0.01848936453461647
    },
    {
      "classification_loss": 0.7327648997306824,
      "epoch": 7.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18474021553993225,
      "orthogonal_weight": 0.1,
      "step": 2310,
      "total_loss": 0.7512389421463013,
      "weighted_orthogonal_loss": 0.018474021926522255
    },
    {
      "classification_loss": 0.6975613832473755,
      "epoch": 7.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18464721739292145,
      "orthogonal_weight": 0.1,
      "step": 2311,
      "total_loss": 0.7160261273384094,
      "weighted_orthogonal_loss": 0.018464721739292145
    },
    {
      "classification_loss": 0.6230834722518921,
      "epoch": 7.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1845201998949051,
      "orthogonal_weight": 0.1,
      "step": 2312,
      "total_loss": 0.6415355205535889,
      "weighted_orthogonal_loss": 0.01845202036201954
    },
    {
      "classification_loss": 0.5973736643791199,
      "epoch": 7.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1844426542520523,
      "orthogonal_weight": 0.1,
      "step": 2313,
      "total_loss": 0.6158179044723511,
      "weighted_orthogonal_loss": 0.01844426617026329
    },
    {
      "classification_loss": 0.6096399426460266,
      "epoch": 7.586885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18432492017745972,
      "orthogonal_weight": 0.1,
      "step": 2314,
      "total_loss": 0.6280724406242371,
      "weighted_orthogonal_loss": 0.018432492390275
    },
    {
      "classification_loss": 0.6360253691673279,
      "epoch": 7.590163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18413083255290985,
      "orthogonal_weight": 0.1,
      "step": 2315,
      "total_loss": 0.6544384360313416,
      "weighted_orthogonal_loss": 0.018413083627820015
    },
    {
      "classification_loss": 0.5653318166732788,
      "epoch": 7.593442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18410338461399078,
      "orthogonal_weight": 0.1,
      "step": 2316,
      "total_loss": 0.5837421417236328,
      "weighted_orthogonal_loss": 0.01841033808887005
    },
    {
      "classification_loss": 0.6284372806549072,
      "epoch": 7.5967213114754095,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1840842217206955,
      "orthogonal_weight": 0.1,
      "step": 2317,
      "total_loss": 0.6468456983566284,
      "weighted_orthogonal_loss": 0.01840842328965664
    },
    {
      "classification_loss": 0.6635791659355164,
      "epoch": 7.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18431292474269867,
      "orthogonal_weight": 0.1,
      "step": 2318,
      "total_loss": 0.6820104718208313,
      "weighted_orthogonal_loss": 0.018431292846798897
    },
    {
      "classification_loss": 0.6267520189285278,
      "epoch": 7.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1843385547399521,
      "orthogonal_weight": 0.1,
      "step": 2319,
      "total_loss": 0.6451858878135681,
      "weighted_orthogonal_loss": 0.01843385584652424
    },
    {
      "classification_loss": 0.5959344506263733,
      "epoch": 7.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1845955103635788,
      "orthogonal_weight": 0.1,
      "step": 2320,
      "total_loss": 0.6143940091133118,
      "weighted_orthogonal_loss": 0.01845955103635788
    },
    {
      "classification_loss": 0.7045235633850098,
      "epoch": 7.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18499580025672913,
      "orthogonal_weight": 0.1,
      "step": 2321,
      "total_loss": 0.7230231165885925,
      "weighted_orthogonal_loss": 0.018499581143260002
    },
    {
      "classification_loss": 0.5802372694015503,
      "epoch": 7.613114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1854114830493927,
      "orthogonal_weight": 0.1,
      "step": 2322,
      "total_loss": 0.5987784266471863,
      "weighted_orthogonal_loss": 0.01854114793241024
    },
    {
      "classification_loss": 0.6298906803131104,
      "epoch": 7.616393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18577955663204193,
      "orthogonal_weight": 0.1,
      "step": 2323,
      "total_loss": 0.6484686136245728,
      "weighted_orthogonal_loss": 0.018577955663204193
    },
    {
      "classification_loss": 0.6031532287597656,
      "epoch": 7.619672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18620005249977112,
      "orthogonal_weight": 0.1,
      "step": 2324,
      "total_loss": 0.6217732429504395,
      "weighted_orthogonal_loss": 0.018620004877448082
    },
    {
      "classification_loss": 0.6927620768547058,
      "epoch": 7.622950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18665680289268494,
      "orthogonal_weight": 0.1,
      "step": 2325,
      "total_loss": 0.7114277482032776,
      "weighted_orthogonal_loss": 0.018665680661797523
    },
    {
      "classification_loss": 0.6591460108757019,
      "epoch": 7.6262295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18707826733589172,
      "orthogonal_weight": 0.1,
      "step": 2326,
      "total_loss": 0.6778538227081299,
      "weighted_orthogonal_loss": 0.018707826733589172
    },
    {
      "classification_loss": 0.6435097455978394,
      "epoch": 7.629508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18741030991077423,
      "orthogonal_weight": 0.1,
      "step": 2327,
      "total_loss": 0.6622507572174072,
      "weighted_orthogonal_loss": 0.018741032108664513
    },
    {
      "classification_loss": 0.6837429404258728,
      "epoch": 7.632786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18748997151851654,
      "orthogonal_weight": 0.1,
      "step": 2328,
      "total_loss": 0.7024919390678406,
      "weighted_orthogonal_loss": 0.018748996779322624
    },
    {
      "classification_loss": 0.5848731398582458,
      "epoch": 7.636065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18770240247249603,
      "orthogonal_weight": 0.1,
      "step": 2329,
      "total_loss": 0.6036433577537537,
      "weighted_orthogonal_loss": 0.018770240247249603
    },
    {
      "classification_loss": 0.6360982656478882,
      "epoch": 7.639344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18795451521873474,
      "orthogonal_weight": 0.1,
      "step": 2330,
      "total_loss": 0.654893696308136,
      "weighted_orthogonal_loss": 0.018795451149344444
    },
    {
      "classification_loss": 0.6568032503128052,
      "epoch": 7.642622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18815091252326965,
      "orthogonal_weight": 0.1,
      "step": 2331,
      "total_loss": 0.6756183505058289,
      "weighted_orthogonal_loss": 0.018815090879797935
    },
    {
      "classification_loss": 0.6025617718696594,
      "epoch": 7.645901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18826447427272797,
      "orthogonal_weight": 0.1,
      "step": 2332,
      "total_loss": 0.6213881969451904,
      "weighted_orthogonal_loss": 0.018826447427272797
    },
    {
      "classification_loss": 0.5861441493034363,
      "epoch": 7.649180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.188379168510437,
      "orthogonal_weight": 0.1,
      "step": 2333,
      "total_loss": 0.6049820780754089,
      "weighted_orthogonal_loss": 0.01883791759610176
    },
    {
      "classification_loss": 0.6218252778053284,
      "epoch": 7.6524590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18855413794517517,
      "orthogonal_weight": 0.1,
      "step": 2334,
      "total_loss": 0.6406806707382202,
      "weighted_orthogonal_loss": 0.018855413421988487
    },
    {
      "classification_loss": 0.6289345622062683,
      "epoch": 7.655737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18879219889640808,
      "orthogonal_weight": 0.1,
      "step": 2335,
      "total_loss": 0.6478137969970703,
      "weighted_orthogonal_loss": 0.018879219889640808
    },
    {
      "classification_loss": 0.6685883402824402,
      "epoch": 7.659016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18913951516151428,
      "orthogonal_weight": 0.1,
      "step": 2336,
      "total_loss": 0.6875022649765015,
      "weighted_orthogonal_loss": 0.018913952633738518
    },
    {
      "classification_loss": 0.576564610004425,
      "epoch": 7.662295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1893867701292038,
      "orthogonal_weight": 0.1,
      "step": 2337,
      "total_loss": 0.5955032706260681,
      "weighted_orthogonal_loss": 0.01893867738544941
    },
    {
      "classification_loss": 0.6683832406997681,
      "epoch": 7.665573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18967148661613464,
      "orthogonal_weight": 0.1,
      "step": 2338,
      "total_loss": 0.6873503923416138,
      "weighted_orthogonal_loss": 0.018967149779200554
    },
    {
      "classification_loss": 0.6207088232040405,
      "epoch": 7.668852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18980173766613007,
      "orthogonal_weight": 0.1,
      "step": 2339,
      "total_loss": 0.6396889686584473,
      "weighted_orthogonal_loss": 0.018980173394083977
    },
    {
      "classification_loss": 0.5820125937461853,
      "epoch": 7.672131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18977494537830353,
      "orthogonal_weight": 0.1,
      "step": 2340,
      "total_loss": 0.6009901165962219,
      "weighted_orthogonal_loss": 0.018977494910359383
    },
    {
      "classification_loss": 0.6924472451210022,
      "epoch": 7.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19014574587345123,
      "orthogonal_weight": 0.1,
      "step": 2341,
      "total_loss": 0.7114618420600891,
      "weighted_orthogonal_loss": 0.019014574587345123
    },
    {
      "classification_loss": 0.5924592614173889,
      "epoch": 7.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.190557599067688,
      "orthogonal_weight": 0.1,
      "step": 2342,
      "total_loss": 0.6115150451660156,
      "weighted_orthogonal_loss": 0.01905575953423977
    },
    {
      "classification_loss": 0.6407398581504822,
      "epoch": 7.6819672131147545,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1910475343465805,
      "orthogonal_weight": 0.1,
      "step": 2343,
      "total_loss": 0.6598446369171143,
      "weighted_orthogonal_loss": 0.01910475455224514
    },
    {
      "classification_loss": 0.6768875122070312,
      "epoch": 7.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19143573939800262,
      "orthogonal_weight": 0.1,
      "step": 2344,
      "total_loss": 0.6960310935974121,
      "weighted_orthogonal_loss": 0.019143573939800262
    },
    {
      "classification_loss": 0.5850021839141846,
      "epoch": 7.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1918366700410843,
      "orthogonal_weight": 0.1,
      "step": 2345,
      "total_loss": 0.6041858792304993,
      "weighted_orthogonal_loss": 0.01918366737663746
    },
    {
      "classification_loss": 0.6537600755691528,
      "epoch": 7.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19229786098003387,
      "orthogonal_weight": 0.1,
      "step": 2346,
      "total_loss": 0.6729898452758789,
      "weighted_orthogonal_loss": 0.019229786470532417
    },
    {
      "classification_loss": 0.6259669661521912,
      "epoch": 7.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19275334477424622,
      "orthogonal_weight": 0.1,
      "step": 2347,
      "total_loss": 0.6452422738075256,
      "weighted_orthogonal_loss": 0.01927533559501171
    },
    {
      "classification_loss": 0.6739698052406311,
      "epoch": 7.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19313545525074005,
      "orthogonal_weight": 0.1,
      "step": 2348,
      "total_loss": 0.6932833790779114,
      "weighted_orthogonal_loss": 0.019313545897603035
    },
    {
      "classification_loss": 0.628503680229187,
      "epoch": 7.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19337695837020874,
      "orthogonal_weight": 0.1,
      "step": 2349,
      "total_loss": 0.6478413939476013,
      "weighted_orthogonal_loss": 0.019337696954607964
    },
    {
      "classification_loss": 0.6736131310462952,
      "epoch": 7.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19358499348163605,
      "orthogonal_weight": 0.1,
      "step": 2350,
      "total_loss": 0.6929716467857361,
      "weighted_orthogonal_loss": 0.019358498975634575
    },
    {
      "classification_loss": 0.5872341990470886,
      "epoch": 7.7081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1936761885881424,
      "orthogonal_weight": 0.1,
      "step": 2351,
      "total_loss": 0.6066018342971802,
      "weighted_orthogonal_loss": 0.01936761848628521
    },
    {
      "classification_loss": 0.6975045800209045,
      "epoch": 7.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1937425434589386,
      "orthogonal_weight": 0.1,
      "step": 2352,
      "total_loss": 0.7168788313865662,
      "weighted_orthogonal_loss": 0.01937425509095192
    },
    {
      "classification_loss": 0.6952360272407532,
      "epoch": 7.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19368720054626465,
      "orthogonal_weight": 0.1,
      "step": 2353,
      "total_loss": 0.7146047353744507,
      "weighted_orthogonal_loss": 0.019368721172213554
    },
    {
      "classification_loss": 0.611583948135376,
      "epoch": 7.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19359898567199707,
      "orthogonal_weight": 0.1,
      "step": 2354,
      "total_loss": 0.6309438347816467,
      "weighted_orthogonal_loss": 0.019359899684786797
    },
    {
      "classification_loss": 0.6767808198928833,
      "epoch": 7.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1935020089149475,
      "orthogonal_weight": 0.1,
      "step": 2355,
      "total_loss": 0.6961309909820557,
      "weighted_orthogonal_loss": 0.01935020089149475
    },
    {
      "classification_loss": 0.602276623249054,
      "epoch": 7.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1933392435312271,
      "orthogonal_weight": 0.1,
      "step": 2356,
      "total_loss": 0.6216105222702026,
      "weighted_orthogonal_loss": 0.01933392509818077
    },
    {
      "classification_loss": 0.6912029385566711,
      "epoch": 7.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19315941631793976,
      "orthogonal_weight": 0.1,
      "step": 2357,
      "total_loss": 0.7105188965797424,
      "weighted_orthogonal_loss": 0.019315941259264946
    },
    {
      "classification_loss": 0.6158969402313232,
      "epoch": 7.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19299452006816864,
      "orthogonal_weight": 0.1,
      "step": 2358,
      "total_loss": 0.6351963877677917,
      "weighted_orthogonal_loss": 0.019299453124403954
    },
    {
      "classification_loss": 0.6148441433906555,
      "epoch": 7.7344262295081965,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19296208024024963,
      "orthogonal_weight": 0.1,
      "step": 2359,
      "total_loss": 0.6341403722763062,
      "weighted_orthogonal_loss": 0.019296208396553993
    },
    {
      "classification_loss": 0.5600780248641968,
      "epoch": 7.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19302792847156525,
      "orthogonal_weight": 0.1,
      "step": 2360,
      "total_loss": 0.5793808102607727,
      "weighted_orthogonal_loss": 0.019302792847156525
    },
    {
      "classification_loss": 0.6698381304740906,
      "epoch": 7.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1933060884475708,
      "orthogonal_weight": 0.1,
      "step": 2361,
      "total_loss": 0.6891687512397766,
      "weighted_orthogonal_loss": 0.01933060958981514
    },
    {
      "classification_loss": 0.6308806538581848,
      "epoch": 7.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1936238557100296,
      "orthogonal_weight": 0.1,
      "step": 2362,
      "total_loss": 0.6502430438995361,
      "weighted_orthogonal_loss": 0.01936238631606102
    },
    {
      "classification_loss": 0.6569700241088867,
      "epoch": 7.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1938386708498001,
      "orthogonal_weight": 0.1,
      "step": 2363,
      "total_loss": 0.6763538718223572,
      "weighted_orthogonal_loss": 0.0193838682025671
    },
    {
      "classification_loss": 0.6980581879615784,
      "epoch": 7.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19396349787712097,
      "orthogonal_weight": 0.1,
      "step": 2364,
      "total_loss": 0.7174545526504517,
      "weighted_orthogonal_loss": 0.019396349787712097
    },
    {
      "classification_loss": 0.6374242901802063,
      "epoch": 7.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19415909051895142,
      "orthogonal_weight": 0.1,
      "step": 2365,
      "total_loss": 0.6568402051925659,
      "weighted_orthogonal_loss": 0.01941590942442417
    },
    {
      "classification_loss": 0.6609383821487427,
      "epoch": 7.757377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19439207017421722,
      "orthogonal_weight": 0.1,
      "step": 2366,
      "total_loss": 0.6803776025772095,
      "weighted_orthogonal_loss": 0.019439207389950752
    },
    {
      "classification_loss": 0.6529837846755981,
      "epoch": 7.760655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1945980340242386,
      "orthogonal_weight": 0.1,
      "step": 2367,
      "total_loss": 0.6724435687065125,
      "weighted_orthogonal_loss": 0.019459804520010948
    },
    {
      "classification_loss": 0.6185885667800903,
      "epoch": 7.7639344262295085,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19461806118488312,
      "orthogonal_weight": 0.1,
      "step": 2368,
      "total_loss": 0.638050377368927,
      "weighted_orthogonal_loss": 0.01946180686354637
    },
    {
      "classification_loss": 0.6234317421913147,
      "epoch": 7.767213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19475267827510834,
      "orthogonal_weight": 0.1,
      "step": 2369,
      "total_loss": 0.6429070234298706,
      "weighted_orthogonal_loss": 0.019475268200039864
    },
    {
      "classification_loss": 0.6261156797409058,
      "epoch": 7.770491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19485262036323547,
      "orthogonal_weight": 0.1,
      "step": 2370,
      "total_loss": 0.6456009149551392,
      "weighted_orthogonal_loss": 0.019485263153910637
    },
    {
      "classification_loss": 0.5806304216384888,
      "epoch": 7.773770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1949835568666458,
      "orthogonal_weight": 0.1,
      "step": 2371,
      "total_loss": 0.6001287698745728,
      "weighted_orthogonal_loss": 0.01949835568666458
    },
    {
      "classification_loss": 0.6832873225212097,
      "epoch": 7.777049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19511623680591583,
      "orthogonal_weight": 0.1,
      "step": 2372,
      "total_loss": 0.7027989625930786,
      "weighted_orthogonal_loss": 0.019511623308062553
    },
    {
      "classification_loss": 0.6311078071594238,
      "epoch": 7.780327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19532839953899384,
      "orthogonal_weight": 0.1,
      "step": 2373,
      "total_loss": 0.6506406664848328,
      "weighted_orthogonal_loss": 0.019532840698957443
    },
    {
      "classification_loss": 0.6481813788414001,
      "epoch": 7.783606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19546571373939514,
      "orthogonal_weight": 0.1,
      "step": 2374,
      "total_loss": 0.6677279472351074,
      "weighted_orthogonal_loss": 0.019546572118997574
    },
    {
      "classification_loss": 0.6016892790794373,
      "epoch": 7.786885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19565120339393616,
      "orthogonal_weight": 0.1,
      "step": 2375,
      "total_loss": 0.6212543845176697,
      "weighted_orthogonal_loss": 0.019565120339393616
    },
    {
      "classification_loss": 0.6927906274795532,
      "epoch": 7.7901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19576898217201233,
      "orthogonal_weight": 0.1,
      "step": 2376,
      "total_loss": 0.7123675346374512,
      "weighted_orthogonal_loss": 0.019576897844672203
    },
    {
      "classification_loss": 0.6385601758956909,
      "epoch": 7.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19596660137176514,
      "orthogonal_weight": 0.1,
      "step": 2377,
      "total_loss": 0.6581568121910095,
      "weighted_orthogonal_loss": 0.019596660509705544
    },
    {
      "classification_loss": 0.6549090147018433,
      "epoch": 7.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19616052508354187,
      "orthogonal_weight": 0.1,
      "step": 2378,
      "total_loss": 0.6745250821113586,
      "weighted_orthogonal_loss": 0.019616052508354187
    },
    {
      "classification_loss": 0.6301420331001282,
      "epoch": 7.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1963886022567749,
      "orthogonal_weight": 0.1,
      "step": 2379,
      "total_loss": 0.6497808694839478,
      "weighted_orthogonal_loss": 0.01963886059820652
    },
    {
      "classification_loss": 0.6556567549705505,
      "epoch": 7.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1966424137353897,
      "orthogonal_weight": 0.1,
      "step": 2380,
      "total_loss": 0.6753209829330444,
      "weighted_orthogonal_loss": 0.01966424100100994
    },
    {
      "classification_loss": 0.699320375919342,
      "epoch": 7.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19688914716243744,
      "orthogonal_weight": 0.1,
      "step": 2381,
      "total_loss": 0.719009280204773,
      "weighted_orthogonal_loss": 0.019688915461301804
    },
    {
      "classification_loss": 0.6075854897499084,
      "epoch": 7.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19707700610160828,
      "orthogonal_weight": 0.1,
      "step": 2382,
      "total_loss": 0.6272931694984436,
      "weighted_orthogonal_loss": 0.019707700237631798
    },
    {
      "classification_loss": 0.6777762770652771,
      "epoch": 7.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19731058180332184,
      "orthogonal_weight": 0.1,
      "step": 2383,
      "total_loss": 0.6975073218345642,
      "weighted_orthogonal_loss": 0.019731057807803154
    },
    {
      "classification_loss": 0.5980860590934753,
      "epoch": 7.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19745178520679474,
      "orthogonal_weight": 0.1,
      "step": 2384,
      "total_loss": 0.6178312301635742,
      "weighted_orthogonal_loss": 0.019745178520679474
    },
    {
      "classification_loss": 0.6782937049865723,
      "epoch": 7.8196721311475414,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1975727677345276,
      "orthogonal_weight": 0.1,
      "step": 2385,
      "total_loss": 0.6980509757995605,
      "weighted_orthogonal_loss": 0.01975727640092373
    },
    {
      "classification_loss": 0.6556960344314575,
      "epoch": 7.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19752462208271027,
      "orthogonal_weight": 0.1,
      "step": 2386,
      "total_loss": 0.675448477268219,
      "weighted_orthogonal_loss": 0.019752463325858116
    },
    {
      "classification_loss": 0.6088144779205322,
      "epoch": 7.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974753588438034,
      "orthogonal_weight": 0.1,
      "step": 2387,
      "total_loss": 0.6285620331764221,
      "weighted_orthogonal_loss": 0.0197475366294384
    },
    {
      "classification_loss": 0.6107051372528076,
      "epoch": 7.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19740010797977448,
      "orthogonal_weight": 0.1,
      "step": 2388,
      "total_loss": 0.630445122718811,
      "weighted_orthogonal_loss": 0.019740011543035507
    },
    {
      "classification_loss": 0.65387362241745,
      "epoch": 7.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19736318290233612,
      "orthogonal_weight": 0.1,
      "step": 2389,
      "total_loss": 0.6736099123954773,
      "weighted_orthogonal_loss": 0.019736317917704582
    },
    {
      "classification_loss": 0.6076144576072693,
      "epoch": 7.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19753588736057281,
      "orthogonal_weight": 0.1,
      "step": 2390,
      "total_loss": 0.6273680329322815,
      "weighted_orthogonal_loss": 0.01975358836352825
    },
    {
      "classification_loss": 0.6077749133110046,
      "epoch": 7.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19770000874996185,
      "orthogonal_weight": 0.1,
      "step": 2391,
      "total_loss": 0.6275449395179749,
      "weighted_orthogonal_loss": 0.019770001992583275
    },
    {
      "classification_loss": 0.6424381732940674,
      "epoch": 7.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19785860180854797,
      "orthogonal_weight": 0.1,
      "step": 2392,
      "total_loss": 0.6622240543365479,
      "weighted_orthogonal_loss": 0.019785860553383827
    },
    {
      "classification_loss": 0.670714259147644,
      "epoch": 7.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979372799396515,
      "orthogonal_weight": 0.1,
      "step": 2393,
      "total_loss": 0.6905080080032349,
      "weighted_orthogonal_loss": 0.01979372836649418
    },
    {
      "classification_loss": 0.6379148364067078,
      "epoch": 7.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19795724749565125,
      "orthogonal_weight": 0.1,
      "step": 2394,
      "total_loss": 0.6577105522155762,
      "weighted_orthogonal_loss": 0.019795725122094154
    },
    {
      "classification_loss": 0.633156418800354,
      "epoch": 7.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19799187779426575,
      "orthogonal_weight": 0.1,
      "step": 2395,
      "total_loss": 0.6529555916786194,
      "weighted_orthogonal_loss": 0.019799187779426575
    },
    {
      "classification_loss": 0.6174256801605225,
      "epoch": 7.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19794794917106628,
      "orthogonal_weight": 0.1,
      "step": 2396,
      "total_loss": 0.6372205018997192,
      "weighted_orthogonal_loss": 0.019794795662164688
    },
    {
      "classification_loss": 0.657690703868866,
      "epoch": 7.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19782981276512146,
      "orthogonal_weight": 0.1,
      "step": 2397,
      "total_loss": 0.6774736642837524,
      "weighted_orthogonal_loss": 0.019782980903983116
    },
    {
      "classification_loss": 0.6326332092285156,
      "epoch": 7.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19770880043506622,
      "orthogonal_weight": 0.1,
      "step": 2398,
      "total_loss": 0.6524040699005127,
      "weighted_orthogonal_loss": 0.019770881161093712
    },
    {
      "classification_loss": 0.6560432314872742,
      "epoch": 7.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1977047324180603,
      "orthogonal_weight": 0.1,
      "step": 2399,
      "total_loss": 0.6758136749267578,
      "weighted_orthogonal_loss": 0.01977047324180603
    },
    {
      "epoch": 7.868852459016393,
      "grad_norm": 37.70566940307617,
      "learning_rate": 0.00012336666666666667,
      "loss": 0.6594,
      "step": 2400
    },
    {
      "classification_loss": 0.6454132795333862,
      "epoch": 7.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19765673577785492,
      "orthogonal_weight": 0.1,
      "step": 2400,
      "total_loss": 0.6651789546012878,
      "weighted_orthogonal_loss": 0.019765673205256462
    },
    {
      "classification_loss": 0.6287621855735779,
      "epoch": 7.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19756494462490082,
      "orthogonal_weight": 0.1,
      "step": 2401,
      "total_loss": 0.6485186815261841,
      "weighted_orthogonal_loss": 0.019756494089961052
    },
    {
      "classification_loss": 0.6556326150894165,
      "epoch": 7.8754098360655735,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19747178256511688,
      "orthogonal_weight": 0.1,
      "step": 2402,
      "total_loss": 0.6753798127174377,
      "weighted_orthogonal_loss": 0.019747179001569748
    },
    {
      "classification_loss": 0.6427311897277832,
      "epoch": 7.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19738899171352386,
      "orthogonal_weight": 0.1,
      "step": 2403,
      "total_loss": 0.6624701023101807,
      "weighted_orthogonal_loss": 0.019738899543881416
    },
    {
      "classification_loss": 0.6176074743270874,
      "epoch": 7.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19680964946746826,
      "orthogonal_weight": 0.1,
      "step": 2404,
      "total_loss": 0.6372884511947632,
      "weighted_orthogonal_loss": 0.019680965691804886
    },
    {
      "classification_loss": 0.6776716709136963,
      "epoch": 7.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19638651609420776,
      "orthogonal_weight": 0.1,
      "step": 2405,
      "total_loss": 0.6973103284835815,
      "weighted_orthogonal_loss": 0.019638651981949806
    },
    {
      "classification_loss": 0.6594141125679016,
      "epoch": 7.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1960316002368927,
      "orthogonal_weight": 0.1,
      "step": 2406,
      "total_loss": 0.6790172457695007,
      "weighted_orthogonal_loss": 0.01960316114127636
    },
    {
      "classification_loss": 0.6641937494277954,
      "epoch": 7.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19577880203723907,
      "orthogonal_weight": 0.1,
      "step": 2407,
      "total_loss": 0.6837716102600098,
      "weighted_orthogonal_loss": 0.019577881321310997
    },
    {
      "classification_loss": 0.6807160377502441,
      "epoch": 7.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19554583728313446,
      "orthogonal_weight": 0.1,
      "step": 2408,
      "total_loss": 0.7002705931663513,
      "weighted_orthogonal_loss": 0.019554583355784416
    },
    {
      "classification_loss": 0.5924404859542847,
      "epoch": 7.898360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19538263976573944,
      "orthogonal_weight": 0.1,
      "step": 2409,
      "total_loss": 0.6119787693023682,
      "weighted_orthogonal_loss": 0.019538264721632004
    },
    {
      "classification_loss": 0.625879168510437,
      "epoch": 7.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19521433115005493,
      "orthogonal_weight": 0.1,
      "step": 2410,
      "total_loss": 0.6454005837440491,
      "weighted_orthogonal_loss": 0.019521433860063553
    },
    {
      "classification_loss": 0.6860738396644592,
      "epoch": 7.9049180327868855,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1947133094072342,
      "orthogonal_weight": 0.1,
      "step": 2411,
      "total_loss": 0.70554518699646,
      "weighted_orthogonal_loss": 0.01947133056819439
    },
    {
      "classification_loss": 0.7134434580802917,
      "epoch": 7.908196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19437988102436066,
      "orthogonal_weight": 0.1,
      "step": 2412,
      "total_loss": 0.7328814268112183,
      "weighted_orthogonal_loss": 0.019437989220023155
    },
    {
      "classification_loss": 0.6119669079780579,
      "epoch": 7.911475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1942150741815567,
      "orthogonal_weight": 0.1,
      "step": 2413,
      "total_loss": 0.6313884258270264,
      "weighted_orthogonal_loss": 0.01942150853574276
    },
    {
      "classification_loss": 0.5823677778244019,
      "epoch": 7.914754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19410072267055511,
      "orthogonal_weight": 0.1,
      "step": 2414,
      "total_loss": 0.6017778515815735,
      "weighted_orthogonal_loss": 0.01941007189452648
    },
    {
      "classification_loss": 0.5762504935264587,
      "epoch": 7.918032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19407880306243896,
      "orthogonal_weight": 0.1,
      "step": 2415,
      "total_loss": 0.5956583619117737,
      "weighted_orthogonal_loss": 0.019407881423830986
    },
    {
      "classification_loss": 0.6228109002113342,
      "epoch": 7.921311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19378826022148132,
      "orthogonal_weight": 0.1,
      "step": 2416,
      "total_loss": 0.6421897411346436,
      "weighted_orthogonal_loss": 0.019378826022148132
    },
    {
      "classification_loss": 0.6734148859977722,
      "epoch": 7.924590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1935267448425293,
      "orthogonal_weight": 0.1,
      "step": 2417,
      "total_loss": 0.6927675604820251,
      "weighted_orthogonal_loss": 0.01935267448425293
    },
    {
      "classification_loss": 0.6439928412437439,
      "epoch": 7.927868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19335246086120605,
      "orthogonal_weight": 0.1,
      "step": 2418,
      "total_loss": 0.6633281111717224,
      "weighted_orthogonal_loss": 0.019335245713591576
    },
    {
      "classification_loss": 0.670875608921051,
      "epoch": 7.9311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19304724037647247,
      "orthogonal_weight": 0.1,
      "step": 2419,
      "total_loss": 0.6901803612709045,
      "weighted_orthogonal_loss": 0.019304724410176277
    },
    {
      "classification_loss": 0.6382008790969849,
      "epoch": 7.934426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19275787472724915,
      "orthogonal_weight": 0.1,
      "step": 2420,
      "total_loss": 0.6574766635894775,
      "weighted_orthogonal_loss": 0.019275788217782974
    },
    {
      "classification_loss": 0.6492177844047546,
      "epoch": 7.937704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19258446991443634,
      "orthogonal_weight": 0.1,
      "step": 2421,
      "total_loss": 0.6684762239456177,
      "weighted_orthogonal_loss": 0.019258446991443634
    },
    {
      "classification_loss": 0.635607898235321,
      "epoch": 7.940983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19243080914020538,
      "orthogonal_weight": 0.1,
      "step": 2422,
      "total_loss": 0.654850959777832,
      "weighted_orthogonal_loss": 0.019243082031607628
    },
    {
      "classification_loss": 0.6298269033432007,
      "epoch": 7.944262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19239123165607452,
      "orthogonal_weight": 0.1,
      "step": 2423,
      "total_loss": 0.6490660309791565,
      "weighted_orthogonal_loss": 0.019239123910665512
    },
    {
      "classification_loss": 0.6186203956604004,
      "epoch": 7.947540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19221343100070953,
      "orthogonal_weight": 0.1,
      "step": 2424,
      "total_loss": 0.6378417611122131,
      "weighted_orthogonal_loss": 0.019221343100070953
    },
    {
      "classification_loss": 0.5828737020492554,
      "epoch": 7.950819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19205880165100098,
      "orthogonal_weight": 0.1,
      "step": 2425,
      "total_loss": 0.6020795702934265,
      "weighted_orthogonal_loss": 0.019205881282687187
    },
    {
      "classification_loss": 0.6265673637390137,
      "epoch": 7.954098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19185474514961243,
      "orthogonal_weight": 0.1,
      "step": 2426,
      "total_loss": 0.6457528471946716,
      "weighted_orthogonal_loss": 0.019185474142432213
    },
    {
      "classification_loss": 0.5787847638130188,
      "epoch": 7.9573770491803275,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19169704616069794,
      "orthogonal_weight": 0.1,
      "step": 2427,
      "total_loss": 0.5979544520378113,
      "weighted_orthogonal_loss": 0.019169704988598824
    },
    {
      "classification_loss": 0.650005042552948,
      "epoch": 7.9606557377049185,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19169892370700836,
      "orthogonal_weight": 0.1,
      "step": 2428,
      "total_loss": 0.6691749095916748,
      "weighted_orthogonal_loss": 0.019169893115758896
    },
    {
      "classification_loss": 0.6327449679374695,
      "epoch": 7.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19170145690441132,
      "orthogonal_weight": 0.1,
      "step": 2429,
      "total_loss": 0.6519151329994202,
      "weighted_orthogonal_loss": 0.01917014643549919
    },
    {
      "classification_loss": 0.6222919225692749,
      "epoch": 7.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19177478551864624,
      "orthogonal_weight": 0.1,
      "step": 2430,
      "total_loss": 0.641469419002533,
      "weighted_orthogonal_loss": 0.019177479669451714
    },
    {
      "classification_loss": 0.6404449343681335,
      "epoch": 7.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19166333973407745,
      "orthogonal_weight": 0.1,
      "step": 2431,
      "total_loss": 0.6596112847328186,
      "weighted_orthogonal_loss": 0.019166333600878716
    },
    {
      "classification_loss": 0.5977450609207153,
      "epoch": 7.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19151362776756287,
      "orthogonal_weight": 0.1,
      "step": 2432,
      "total_loss": 0.6168964505195618,
      "weighted_orthogonal_loss": 0.019151363521814346
    },
    {
      "classification_loss": 0.6559200286865234,
      "epoch": 7.977049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.191420778632164,
      "orthogonal_weight": 0.1,
      "step": 2433,
      "total_loss": 0.6750621199607849,
      "weighted_orthogonal_loss": 0.01914207823574543
    },
    {
      "classification_loss": 0.6583069562911987,
      "epoch": 7.980327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19136103987693787,
      "orthogonal_weight": 0.1,
      "step": 2434,
      "total_loss": 0.6774430871009827,
      "weighted_orthogonal_loss": 0.019136104732751846
    },
    {
      "classification_loss": 0.634731650352478,
      "epoch": 7.983606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19128888845443726,
      "orthogonal_weight": 0.1,
      "step": 2435,
      "total_loss": 0.6538605690002441,
      "weighted_orthogonal_loss": 0.019128888845443726
    },
    {
      "classification_loss": 0.7193273901939392,
      "epoch": 7.9868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19121330976486206,
      "orthogonal_weight": 0.1,
      "step": 2436,
      "total_loss": 0.7384487390518188,
      "weighted_orthogonal_loss": 0.019121332094073296
    },
    {
      "classification_loss": 0.5970052480697632,
      "epoch": 7.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19107946753501892,
      "orthogonal_weight": 0.1,
      "step": 2437,
      "total_loss": 0.6161131858825684,
      "weighted_orthogonal_loss": 0.019107947126030922
    },
    {
      "classification_loss": 0.666504979133606,
      "epoch": 7.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19097986817359924,
      "orthogonal_weight": 0.1,
      "step": 2438,
      "total_loss": 0.6856029629707336,
      "weighted_orthogonal_loss": 0.019097987562417984
    },
    {
      "classification_loss": 0.6352241039276123,
      "epoch": 7.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19090235233306885,
      "orthogonal_weight": 0.1,
      "step": 2439,
      "total_loss": 0.6543143391609192,
      "weighted_orthogonal_loss": 0.019090235233306885
    },
    {
      "classification_loss": 0.7070944905281067,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7261901497840881,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.7000864148139954,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7191820740699768,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.69586181640625,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7149574756622314,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.707272469997406,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7263681292533875,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.7030918598175049,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7221875190734863,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.7016600370407104,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7207556962966919,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.6955385208129883,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7146341800689697,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.7149553894996643,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.7340510487556458,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.512,
      "eval_f1": 0.5252918287937743,
      "eval_loss": 0.722008466720581,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.4333868378812199,
      "eval_runtime": 6.1427,
      "eval_samples_per_second": 162.795,
      "eval_steps_per_second": 1.302,
      "step": 2440
    },
    {
      "classification_loss": 0.6184485554695129,
      "epoch": 8.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19095635414123535,
      "orthogonal_weight": 0.1,
      "step": 2440,
      "total_loss": 0.6375442147254944,
      "weighted_orthogonal_loss": 0.019095635041594505
    },
    {
      "classification_loss": 0.6269955039024353,
      "epoch": 8.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19101092219352722,
      "orthogonal_weight": 0.1,
      "step": 2441,
      "total_loss": 0.6460965871810913,
      "weighted_orthogonal_loss": 0.019101092591881752
    },
    {
      "classification_loss": 0.5931625366210938,
      "epoch": 8.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19104893505573273,
      "orthogonal_weight": 0.1,
      "step": 2442,
      "total_loss": 0.6122674345970154,
      "weighted_orthogonal_loss": 0.019104894250631332
    },
    {
      "classification_loss": 0.6979817748069763,
      "epoch": 8.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1910904198884964,
      "orthogonal_weight": 0.1,
      "step": 2443,
      "total_loss": 0.7170908451080322,
      "weighted_orthogonal_loss": 0.01910904236137867
    },
    {
      "classification_loss": 0.6262066960334778,
      "epoch": 8.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19113044440746307,
      "orthogonal_weight": 0.1,
      "step": 2444,
      "total_loss": 0.6453197598457336,
      "weighted_orthogonal_loss": 0.019113045185804367
    },
    {
      "classification_loss": 0.6575670838356018,
      "epoch": 8.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1911749690771103,
      "orthogonal_weight": 0.1,
      "step": 2445,
      "total_loss": 0.676684558391571,
      "weighted_orthogonal_loss": 0.01911749690771103
    },
    {
      "classification_loss": 0.6490277647972107,
      "epoch": 8.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19125904142856598,
      "orthogonal_weight": 0.1,
      "step": 2446,
      "total_loss": 0.6681536436080933,
      "weighted_orthogonal_loss": 0.019125904887914658
    },
    {
      "classification_loss": 0.6480510830879211,
      "epoch": 8.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1914110779762268,
      "orthogonal_weight": 0.1,
      "step": 2447,
      "total_loss": 0.6671922206878662,
      "weighted_orthogonal_loss": 0.01914110779762268
    },
    {
      "classification_loss": 0.6269969344139099,
      "epoch": 8.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19160650670528412,
      "orthogonal_weight": 0.1,
      "step": 2448,
      "total_loss": 0.6461575627326965,
      "weighted_orthogonal_loss": 0.019160650670528412
    },
    {
      "classification_loss": 0.6145074367523193,
      "epoch": 8.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1918444186449051,
      "orthogonal_weight": 0.1,
      "step": 2449,
      "total_loss": 0.6336919069290161,
      "weighted_orthogonal_loss": 0.01918444223701954
    },
    {
      "classification_loss": 0.6406232714653015,
      "epoch": 8.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19210581481456757,
      "orthogonal_weight": 0.1,
      "step": 2450,
      "total_loss": 0.6598338484764099,
      "weighted_orthogonal_loss": 0.019210582599043846
    },
    {
      "classification_loss": 0.5975569486618042,
      "epoch": 8.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19224320352077484,
      "orthogonal_weight": 0.1,
      "step": 2451,
      "total_loss": 0.6167812943458557,
      "weighted_orthogonal_loss": 0.019224321469664574
    },
    {
      "classification_loss": 0.5789597630500793,
      "epoch": 8.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1921813189983368,
      "orthogonal_weight": 0.1,
      "step": 2452,
      "total_loss": 0.5981779098510742,
      "weighted_orthogonal_loss": 0.01921813189983368
    },
    {
      "classification_loss": 0.6382624506950378,
      "epoch": 8.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19220741093158722,
      "orthogonal_weight": 0.1,
      "step": 2453,
      "total_loss": 0.6574832201004028,
      "weighted_orthogonal_loss": 0.019220741465687752
    },
    {
      "classification_loss": 0.6164553761482239,
      "epoch": 8.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19229763746261597,
      "orthogonal_weight": 0.1,
      "step": 2454,
      "total_loss": 0.63568514585495,
      "weighted_orthogonal_loss": 0.019229764118790627
    },
    {
      "classification_loss": 0.6684137582778931,
      "epoch": 8.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1924007534980774,
      "orthogonal_weight": 0.1,
      "step": 2455,
      "total_loss": 0.6876538395881653,
      "weighted_orthogonal_loss": 0.01924007572233677
    },
    {
      "classification_loss": 0.6496047973632812,
      "epoch": 8.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19239740073680878,
      "orthogonal_weight": 0.1,
      "step": 2456,
      "total_loss": 0.6688445210456848,
      "weighted_orthogonal_loss": 0.019239740446209908
    },
    {
      "classification_loss": 0.6485517024993896,
      "epoch": 8.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19243958592414856,
      "orthogonal_weight": 0.1,
      "step": 2457,
      "total_loss": 0.6677956581115723,
      "weighted_orthogonal_loss": 0.019243959337472916
    },
    {
      "classification_loss": 0.5980973243713379,
      "epoch": 8.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19246315956115723,
      "orthogonal_weight": 0.1,
      "step": 2458,
      "total_loss": 0.6173436641693115,
      "weighted_orthogonal_loss": 0.019246315583586693
    },
    {
      "classification_loss": 0.5903462171554565,
      "epoch": 8.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925254613161087,
      "orthogonal_weight": 0.1,
      "step": 2459,
      "total_loss": 0.6095987558364868,
      "weighted_orthogonal_loss": 0.01925254613161087
    },
    {
      "classification_loss": 0.6251682043075562,
      "epoch": 8.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19255320727825165,
      "orthogonal_weight": 0.1,
      "step": 2460,
      "total_loss": 0.6444235444068909,
      "weighted_orthogonal_loss": 0.019255321472883224
    },
    {
      "classification_loss": 0.6471441388130188,
      "epoch": 8.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19261279702186584,
      "orthogonal_weight": 0.1,
      "step": 2461,
      "total_loss": 0.666405439376831,
      "weighted_orthogonal_loss": 0.019261280074715614
    },
    {
      "classification_loss": 0.6358693242073059,
      "epoch": 8.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19272631406784058,
      "orthogonal_weight": 0.1,
      "step": 2462,
      "total_loss": 0.6551419496536255,
      "weighted_orthogonal_loss": 0.019272631034255028
    },
    {
      "classification_loss": 0.6585547924041748,
      "epoch": 8.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19285695254802704,
      "orthogonal_weight": 0.1,
      "step": 2463,
      "total_loss": 0.6778404712677002,
      "weighted_orthogonal_loss": 0.019285695627331734
    },
    {
      "classification_loss": 0.634567379951477,
      "epoch": 8.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19300849735736847,
      "orthogonal_weight": 0.1,
      "step": 2464,
      "total_loss": 0.6538682579994202,
      "weighted_orthogonal_loss": 0.019300850108265877
    },
    {
      "classification_loss": 0.7170705199241638,
      "epoch": 8.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1931023746728897,
      "orthogonal_weight": 0.1,
      "step": 2465,
      "total_loss": 0.7363807559013367,
      "weighted_orthogonal_loss": 0.019310237839818
    },
    {
      "classification_loss": 0.5911359190940857,
      "epoch": 8.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.193132221698761,
      "orthogonal_weight": 0.1,
      "step": 2466,
      "total_loss": 0.6104491353034973,
      "weighted_orthogonal_loss": 0.01931322179734707
    },
    {
      "classification_loss": 0.6835408806800842,
      "epoch": 8.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1932266652584076,
      "orthogonal_weight": 0.1,
      "step": 2467,
      "total_loss": 0.7028635740280151,
      "weighted_orthogonal_loss": 0.01932266727089882
    },
    {
      "classification_loss": 0.6710431575775146,
      "epoch": 8.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19322501122951508,
      "orthogonal_weight": 0.1,
      "step": 2468,
      "total_loss": 0.6903656721115112,
      "weighted_orthogonal_loss": 0.019322501495480537
    },
    {
      "classification_loss": 0.6580501198768616,
      "epoch": 8.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19330242276191711,
      "orthogonal_weight": 0.1,
      "step": 2469,
      "total_loss": 0.677380383014679,
      "weighted_orthogonal_loss": 0.01933024264872074
    },
    {
      "classification_loss": 0.6402475833892822,
      "epoch": 8.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19322316348552704,
      "orthogonal_weight": 0.1,
      "step": 2470,
      "total_loss": 0.6595699191093445,
      "weighted_orthogonal_loss": 0.019322317093610764
    },
    {
      "classification_loss": 0.6868064999580383,
      "epoch": 8.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19320721924304962,
      "orthogonal_weight": 0.1,
      "step": 2471,
      "total_loss": 0.7061272263526917,
      "weighted_orthogonal_loss": 0.019320722669363022
    },
    {
      "classification_loss": 0.6233064532279968,
      "epoch": 8.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19319041073322296,
      "orthogonal_weight": 0.1,
      "step": 2472,
      "total_loss": 0.6426255106925964,
      "weighted_orthogonal_loss": 0.019319040700793266
    },
    {
      "classification_loss": 0.6619523167610168,
      "epoch": 8.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19314271211624146,
      "orthogonal_weight": 0.1,
      "step": 2473,
      "total_loss": 0.6812666058540344,
      "weighted_orthogonal_loss": 0.019314272329211235
    },
    {
      "classification_loss": 0.5976088643074036,
      "epoch": 8.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19304056465625763,
      "orthogonal_weight": 0.1,
      "step": 2474,
      "total_loss": 0.6169129014015198,
      "weighted_orthogonal_loss": 0.019304057583212852
    },
    {
      "classification_loss": 0.5727381706237793,
      "epoch": 8.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1929437667131424,
      "orthogonal_weight": 0.1,
      "step": 2475,
      "total_loss": 0.5920325517654419,
      "weighted_orthogonal_loss": 0.0192943774163723
    },
    {
      "classification_loss": 0.6461620330810547,
      "epoch": 8.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928337961435318,
      "orthogonal_weight": 0.1,
      "step": 2476,
      "total_loss": 0.6654453873634338,
      "weighted_orthogonal_loss": 0.01928338035941124
    },
    {
      "classification_loss": 0.6107391119003296,
      "epoch": 8.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925393044948578,
      "orthogonal_weight": 0.1,
      "step": 2477,
      "total_loss": 0.6299930214881897,
      "weighted_orthogonal_loss": 0.01925393007695675
    },
    {
      "classification_loss": 0.6518868803977966,
      "epoch": 8.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1923842579126358,
      "orthogonal_weight": 0.1,
      "step": 2478,
      "total_loss": 0.6711252927780151,
      "weighted_orthogonal_loss": 0.01923842541873455
    },
    {
      "classification_loss": 0.627338707447052,
      "epoch": 8.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19225157797336578,
      "orthogonal_weight": 0.1,
      "step": 2479,
      "total_loss": 0.6465638875961304,
      "weighted_orthogonal_loss": 0.01922515779733658
    },
    {
      "classification_loss": 0.623160183429718,
      "epoch": 8.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1918560117483139,
      "orthogonal_weight": 0.1,
      "step": 2480,
      "total_loss": 0.6423457860946655,
      "weighted_orthogonal_loss": 0.01918560080230236
    },
    {
      "classification_loss": 0.6330088973045349,
      "epoch": 8.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19160041213035583,
      "orthogonal_weight": 0.1,
      "step": 2481,
      "total_loss": 0.6521689295768738,
      "weighted_orthogonal_loss": 0.019160041585564613
    },
    {
      "classification_loss": 0.6721398234367371,
      "epoch": 8.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19138997793197632,
      "orthogonal_weight": 0.1,
      "step": 2482,
      "total_loss": 0.6912788152694702,
      "weighted_orthogonal_loss": 0.019138997420668602
    },
    {
      "classification_loss": 0.6216779947280884,
      "epoch": 8.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19127899408340454,
      "orthogonal_weight": 0.1,
      "step": 2483,
      "total_loss": 0.6408059000968933,
      "weighted_orthogonal_loss": 0.019127899780869484
    },
    {
      "classification_loss": 0.6044954657554626,
      "epoch": 8.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19143101572990417,
      "orthogonal_weight": 0.1,
      "step": 2484,
      "total_loss": 0.6236385703086853,
      "weighted_orthogonal_loss": 0.019143102690577507
    },
    {
      "classification_loss": 0.6208570003509521,
      "epoch": 8.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19173574447631836,
      "orthogonal_weight": 0.1,
      "step": 2485,
      "total_loss": 0.640030562877655,
      "weighted_orthogonal_loss": 0.019173575565218925
    },
    {
      "classification_loss": 0.6190385222434998,
      "epoch": 8.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19204500317573547,
      "orthogonal_weight": 0.1,
      "step": 2486,
      "total_loss": 0.6382430195808411,
      "weighted_orthogonal_loss": 0.019204501062631607
    },
    {
      "classification_loss": 0.6090490221977234,
      "epoch": 8.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19224296510219574,
      "orthogonal_weight": 0.1,
      "step": 2487,
      "total_loss": 0.6282733082771301,
      "weighted_orthogonal_loss": 0.019224297255277634
    },
    {
      "classification_loss": 0.663658082485199,
      "epoch": 8.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.192448690533638,
      "orthogonal_weight": 0.1,
      "step": 2488,
      "total_loss": 0.6829029321670532,
      "weighted_orthogonal_loss": 0.01924487017095089
    },
    {
      "classification_loss": 0.6759946346282959,
      "epoch": 8.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925479769706726,
      "orthogonal_weight": 0.1,
      "step": 2489,
      "total_loss": 0.6952494382858276,
      "weighted_orthogonal_loss": 0.01925479806959629
    },
    {
      "classification_loss": 0.6303572654724121,
      "epoch": 8.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19243329763412476,
      "orthogonal_weight": 0.1,
      "step": 2490,
      "total_loss": 0.649600625038147,
      "weighted_orthogonal_loss": 0.019243329763412476
    },
    {
      "classification_loss": 0.6275319457054138,
      "epoch": 8.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19231194257736206,
      "orthogonal_weight": 0.1,
      "step": 2491,
      "total_loss": 0.6467631459236145,
      "weighted_orthogonal_loss": 0.019231194630265236
    },
    {
      "classification_loss": 0.6230758428573608,
      "epoch": 8.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19222116470336914,
      "orthogonal_weight": 0.1,
      "step": 2492,
      "total_loss": 0.6422979831695557,
      "weighted_orthogonal_loss": 0.019222116097807884
    },
    {
      "classification_loss": 0.6438171863555908,
      "epoch": 8.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1920577734708786,
      "orthogonal_weight": 0.1,
      "step": 2493,
      "total_loss": 0.6630229353904724,
      "weighted_orthogonal_loss": 0.01920577697455883
    },
    {
      "classification_loss": 0.6535685658454895,
      "epoch": 8.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19192369282245636,
      "orthogonal_weight": 0.1,
      "step": 2494,
      "total_loss": 0.6727609634399414,
      "weighted_orthogonal_loss": 0.019192369654774666
    },
    {
      "classification_loss": 0.627464234828949,
      "epoch": 8.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19170674681663513,
      "orthogonal_weight": 0.1,
      "step": 2495,
      "total_loss": 0.6466349363327026,
      "weighted_orthogonal_loss": 0.019170675426721573
    },
    {
      "classification_loss": 0.5400266051292419,
      "epoch": 8.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19155406951904297,
      "orthogonal_weight": 0.1,
      "step": 2496,
      "total_loss": 0.5591819882392883,
      "weighted_orthogonal_loss": 0.019155407324433327
    },
    {
      "classification_loss": 0.6400851607322693,
      "epoch": 8.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19145163893699646,
      "orthogonal_weight": 0.1,
      "step": 2497,
      "total_loss": 0.6592303514480591,
      "weighted_orthogonal_loss": 0.019145164638757706
    },
    {
      "classification_loss": 0.7125687003135681,
      "epoch": 8.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1914118081331253,
      "orthogonal_weight": 0.1,
      "step": 2498,
      "total_loss": 0.731709897518158,
      "weighted_orthogonal_loss": 0.0191411804407835
    },
    {
      "classification_loss": 0.6294106245040894,
      "epoch": 8.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19129996001720428,
      "orthogonal_weight": 0.1,
      "step": 2499,
      "total_loss": 0.6485406160354614,
      "weighted_orthogonal_loss": 0.019129997119307518
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 10.798168182373047,
      "learning_rate": 0.00012003333333333333,
      "loss": 0.6557,
      "step": 2500
    },
    {
      "classification_loss": 0.6403653025627136,
      "epoch": 8.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1912951022386551,
      "orthogonal_weight": 0.1,
      "step": 2500,
      "total_loss": 0.6594948172569275,
      "weighted_orthogonal_loss": 0.01912951096892357
    },
    {
      "classification_loss": 0.6118518710136414,
      "epoch": 8.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19129467010498047,
      "orthogonal_weight": 0.1,
      "step": 2501,
      "total_loss": 0.6309813261032104,
      "weighted_orthogonal_loss": 0.019129468128085136
    },
    {
      "classification_loss": 0.6339799761772156,
      "epoch": 8.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19117458164691925,
      "orthogonal_weight": 0.1,
      "step": 2502,
      "total_loss": 0.6530974507331848,
      "weighted_orthogonal_loss": 0.019117457792162895
    },
    {
      "classification_loss": 0.6278811097145081,
      "epoch": 8.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19103173911571503,
      "orthogonal_weight": 0.1,
      "step": 2503,
      "total_loss": 0.6469842791557312,
      "weighted_orthogonal_loss": 0.019103175029158592
    },
    {
      "classification_loss": 0.6150074005126953,
      "epoch": 8.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19100023806095123,
      "orthogonal_weight": 0.1,
      "step": 2504,
      "total_loss": 0.6341074109077454,
      "weighted_orthogonal_loss": 0.019100023433566093
    },
    {
      "classification_loss": 0.6427860856056213,
      "epoch": 8.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19093258678913116,
      "orthogonal_weight": 0.1,
      "step": 2505,
      "total_loss": 0.6618793606758118,
      "weighted_orthogonal_loss": 0.019093258306384087
    },
    {
      "classification_loss": 0.6196147799491882,
      "epoch": 8.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19085374474525452,
      "orthogonal_weight": 0.1,
      "step": 2506,
      "total_loss": 0.6387001276016235,
      "weighted_orthogonal_loss": 0.01908537559211254
    },
    {
      "classification_loss": 0.6063477396965027,
      "epoch": 8.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1908062994480133,
      "orthogonal_weight": 0.1,
      "step": 2507,
      "total_loss": 0.6254283785820007,
      "weighted_orthogonal_loss": 0.0190806295722723
    },
    {
      "classification_loss": 0.5636959671974182,
      "epoch": 8.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19079004228115082,
      "orthogonal_weight": 0.1,
      "step": 2508,
      "total_loss": 0.5827749967575073,
      "weighted_orthogonal_loss": 0.01907900534570217
    },
    {
      "classification_loss": 0.6627574563026428,
      "epoch": 8.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1908247023820877,
      "orthogonal_weight": 0.1,
      "step": 2509,
      "total_loss": 0.6818399429321289,
      "weighted_orthogonal_loss": 0.01908246986567974
    },
    {
      "classification_loss": 0.6166934370994568,
      "epoch": 8.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19058138132095337,
      "orthogonal_weight": 0.1,
      "step": 2510,
      "total_loss": 0.6357516050338745,
      "weighted_orthogonal_loss": 0.019058138132095337
    },
    {
      "classification_loss": 0.6199139356613159,
      "epoch": 8.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19039535522460938,
      "orthogonal_weight": 0.1,
      "step": 2511,
      "total_loss": 0.638953447341919,
      "weighted_orthogonal_loss": 0.019039535894989967
    },
    {
      "classification_loss": 0.6341196894645691,
      "epoch": 8.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19027209281921387,
      "orthogonal_weight": 0.1,
      "step": 2512,
      "total_loss": 0.6531469225883484,
      "weighted_orthogonal_loss": 0.019027208909392357
    },
    {
      "classification_loss": 0.5851768255233765,
      "epoch": 8.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1901819109916687,
      "orthogonal_weight": 0.1,
      "step": 2513,
      "total_loss": 0.6041949987411499,
      "weighted_orthogonal_loss": 0.01901819184422493
    },
    {
      "classification_loss": 0.6046280860900879,
      "epoch": 8.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19008868932724,
      "orthogonal_weight": 0.1,
      "step": 2514,
      "total_loss": 0.6236369609832764,
      "weighted_orthogonal_loss": 0.01900886930525303
    },
    {
      "classification_loss": 0.6557736396789551,
      "epoch": 8.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18999238312244415,
      "orthogonal_weight": 0.1,
      "step": 2515,
      "total_loss": 0.6747728586196899,
      "weighted_orthogonal_loss": 0.018999239429831505
    },
    {
      "classification_loss": 0.5857353806495667,
      "epoch": 8.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.190049946308136,
      "orthogonal_weight": 0.1,
      "step": 2516,
      "total_loss": 0.6047403812408447,
      "weighted_orthogonal_loss": 0.01900499500334263
    },
    {
      "classification_loss": 0.630217969417572,
      "epoch": 8.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19014038145542145,
      "orthogonal_weight": 0.1,
      "step": 2517,
      "total_loss": 0.649232029914856,
      "weighted_orthogonal_loss": 0.019014038145542145
    },
    {
      "classification_loss": 0.6619446873664856,
      "epoch": 8.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19022569060325623,
      "orthogonal_weight": 0.1,
      "step": 2518,
      "total_loss": 0.6809672713279724,
      "weighted_orthogonal_loss": 0.019022569060325623
    },
    {
      "classification_loss": 0.6453121304512024,
      "epoch": 8.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19031138718128204,
      "orthogonal_weight": 0.1,
      "step": 2519,
      "total_loss": 0.6643432974815369,
      "weighted_orthogonal_loss": 0.019031139090657234
    },
    {
      "classification_loss": 0.6888402700424194,
      "epoch": 8.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19045878946781158,
      "orthogonal_weight": 0.1,
      "step": 2520,
      "total_loss": 0.7078861594200134,
      "weighted_orthogonal_loss": 0.019045880064368248
    },
    {
      "classification_loss": 0.6236857175827026,
      "epoch": 8.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1906253844499588,
      "orthogonal_weight": 0.1,
      "step": 2521,
      "total_loss": 0.642748236656189,
      "weighted_orthogonal_loss": 0.01906253956258297
    },
    {
      "classification_loss": 0.6146121621131897,
      "epoch": 8.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1907646209001541,
      "orthogonal_weight": 0.1,
      "step": 2522,
      "total_loss": 0.6336886286735535,
      "weighted_orthogonal_loss": 0.01907646283507347
    },
    {
      "classification_loss": 0.5905495882034302,
      "epoch": 8.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19085915386676788,
      "orthogonal_weight": 0.1,
      "step": 2523,
      "total_loss": 0.6096355319023132,
      "weighted_orthogonal_loss": 0.019085915759205818
    },
    {
      "classification_loss": 0.7320977449417114,
      "epoch": 8.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19096942245960236,
      "orthogonal_weight": 0.1,
      "step": 2524,
      "total_loss": 0.7511947154998779,
      "weighted_orthogonal_loss": 0.019096942618489265
    },
    {
      "classification_loss": 0.664810299873352,
      "epoch": 8.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1910647600889206,
      "orthogonal_weight": 0.1,
      "step": 2525,
      "total_loss": 0.6839167475700378,
      "weighted_orthogonal_loss": 0.01910647563636303
    },
    {
      "classification_loss": 0.5887678265571594,
      "epoch": 8.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19110266864299774,
      "orthogonal_weight": 0.1,
      "step": 2526,
      "total_loss": 0.6078780889511108,
      "weighted_orthogonal_loss": 0.019110267981886864
    },
    {
      "classification_loss": 0.6612291932106018,
      "epoch": 8.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19100414216518402,
      "orthogonal_weight": 0.1,
      "step": 2527,
      "total_loss": 0.6803296208381653,
      "weighted_orthogonal_loss": 0.019100414589047432
    },
    {
      "classification_loss": 0.6467751264572144,
      "epoch": 8.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19094808399677277,
      "orthogonal_weight": 0.1,
      "step": 2528,
      "total_loss": 0.665869951248169,
      "weighted_orthogonal_loss": 0.019094808027148247
    },
    {
      "classification_loss": 0.6775132417678833,
      "epoch": 8.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19091297686100006,
      "orthogonal_weight": 0.1,
      "step": 2529,
      "total_loss": 0.6966045498847961,
      "weighted_orthogonal_loss": 0.019091298803687096
    },
    {
      "classification_loss": 0.6818912029266357,
      "epoch": 8.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19088546931743622,
      "orthogonal_weight": 0.1,
      "step": 2530,
      "total_loss": 0.7009797692298889,
      "weighted_orthogonal_loss": 0.01908854767680168
    },
    {
      "classification_loss": 0.596479594707489,
      "epoch": 8.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1908874362707138,
      "orthogonal_weight": 0.1,
      "step": 2531,
      "total_loss": 0.6155683398246765,
      "weighted_orthogonal_loss": 0.01908874325454235
    },
    {
      "classification_loss": 0.6527469158172607,
      "epoch": 8.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19092918932437897,
      "orthogonal_weight": 0.1,
      "step": 2532,
      "total_loss": 0.6718398332595825,
      "weighted_orthogonal_loss": 0.019092919304966927
    },
    {
      "classification_loss": 0.647059440612793,
      "epoch": 8.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1909146010875702,
      "orthogonal_weight": 0.1,
      "step": 2533,
      "total_loss": 0.6661509275436401,
      "weighted_orthogonal_loss": 0.01909146085381508
    },
    {
      "classification_loss": 0.5978235602378845,
      "epoch": 8.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19089223444461823,
      "orthogonal_weight": 0.1,
      "step": 2534,
      "total_loss": 0.6169127821922302,
      "weighted_orthogonal_loss": 0.019089223816990852
    },
    {
      "classification_loss": 0.6328240036964417,
      "epoch": 8.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19091051816940308,
      "orthogonal_weight": 0.1,
      "step": 2535,
      "total_loss": 0.6519150733947754,
      "weighted_orthogonal_loss": 0.019091052934527397
    },
    {
      "classification_loss": 0.6402074694633484,
      "epoch": 8.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19063863158226013,
      "orthogonal_weight": 0.1,
      "step": 2536,
      "total_loss": 0.6592713594436646,
      "weighted_orthogonal_loss": 0.019063863903284073
    },
    {
      "classification_loss": 0.5911755561828613,
      "epoch": 8.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19045822322368622,
      "orthogonal_weight": 0.1,
      "step": 2537,
      "total_loss": 0.6102213859558105,
      "weighted_orthogonal_loss": 0.019045822322368622
    },
    {
      "classification_loss": 0.6672518849372864,
      "epoch": 8.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19032302498817444,
      "orthogonal_weight": 0.1,
      "step": 2538,
      "total_loss": 0.6862841844558716,
      "weighted_orthogonal_loss": 0.019032303243875504
    },
    {
      "classification_loss": 0.6868391036987305,
      "epoch": 8.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19022366404533386,
      "orthogonal_weight": 0.1,
      "step": 2539,
      "total_loss": 0.7058614492416382,
      "weighted_orthogonal_loss": 0.019022366032004356
    },
    {
      "classification_loss": 0.5867023468017578,
      "epoch": 8.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19014601409435272,
      "orthogonal_weight": 0.1,
      "step": 2540,
      "total_loss": 0.6057169437408447,
      "weighted_orthogonal_loss": 0.019014602527022362
    },
    {
      "classification_loss": 0.5741746425628662,
      "epoch": 8.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19020260870456696,
      "orthogonal_weight": 0.1,
      "step": 2541,
      "total_loss": 0.5931949019432068,
      "weighted_orthogonal_loss": 0.019020261242985725
    },
    {
      "classification_loss": 0.6684460639953613,
      "epoch": 8.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1902172714471817,
      "orthogonal_weight": 0.1,
      "step": 2542,
      "total_loss": 0.6874678134918213,
      "weighted_orthogonal_loss": 0.01902172714471817
    },
    {
      "classification_loss": 0.7193409204483032,
      "epoch": 8.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1902671754360199,
      "orthogonal_weight": 0.1,
      "step": 2543,
      "total_loss": 0.7383676171302795,
      "weighted_orthogonal_loss": 0.01902671717107296
    },
    {
      "classification_loss": 0.6520543098449707,
      "epoch": 8.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1903284788131714,
      "orthogonal_weight": 0.1,
      "step": 2544,
      "total_loss": 0.6710871458053589,
      "weighted_orthogonal_loss": 0.019032848998904228
    },
    {
      "classification_loss": 0.6666229963302612,
      "epoch": 8.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19041985273361206,
      "orthogonal_weight": 0.1,
      "step": 2545,
      "total_loss": 0.6856650114059448,
      "weighted_orthogonal_loss": 0.019041985273361206
    },
    {
      "classification_loss": 0.5990003943443298,
      "epoch": 8.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19050459563732147,
      "orthogonal_weight": 0.1,
      "step": 2546,
      "total_loss": 0.6180508732795715,
      "weighted_orthogonal_loss": 0.019050460308790207
    },
    {
      "classification_loss": 0.5819755792617798,
      "epoch": 8.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19074855744838715,
      "orthogonal_weight": 0.1,
      "step": 2547,
      "total_loss": 0.6010504364967346,
      "weighted_orthogonal_loss": 0.019074855372309685
    },
    {
      "classification_loss": 0.6359670758247375,
      "epoch": 8.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19106027483940125,
      "orthogonal_weight": 0.1,
      "step": 2548,
      "total_loss": 0.6550731062889099,
      "weighted_orthogonal_loss": 0.019106028601527214
    },
    {
      "classification_loss": 0.572509229183197,
      "epoch": 8.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19134175777435303,
      "orthogonal_weight": 0.1,
      "step": 2549,
      "total_loss": 0.5916433930397034,
      "weighted_orthogonal_loss": 0.019134176895022392
    },
    {
      "classification_loss": 0.7348589897155762,
      "epoch": 8.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19158081710338593,
      "orthogonal_weight": 0.1,
      "step": 2550,
      "total_loss": 0.7540170550346375,
      "weighted_orthogonal_loss": 0.019158082082867622
    },
    {
      "classification_loss": 0.6000363826751709,
      "epoch": 8.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.191777765750885,
      "orthogonal_weight": 0.1,
      "step": 2551,
      "total_loss": 0.6192141771316528,
      "weighted_orthogonal_loss": 0.01917777769267559
    },
    {
      "classification_loss": 0.666143536567688,
      "epoch": 8.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19201762974262238,
      "orthogonal_weight": 0.1,
      "step": 2552,
      "total_loss": 0.6853452920913696,
      "weighted_orthogonal_loss": 0.019201762974262238
    },
    {
      "classification_loss": 0.5854765176773071,
      "epoch": 8.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19218888878822327,
      "orthogonal_weight": 0.1,
      "step": 2553,
      "total_loss": 0.6046953797340393,
      "weighted_orthogonal_loss": 0.019218889996409416
    },
    {
      "classification_loss": 0.6190754175186157,
      "epoch": 8.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19252832233905792,
      "orthogonal_weight": 0.1,
      "step": 2554,
      "total_loss": 0.6383282542228699,
      "weighted_orthogonal_loss": 0.019252832978963852
    },
    {
      "classification_loss": 0.623768150806427,
      "epoch": 8.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19283296167850494,
      "orthogonal_weight": 0.1,
      "step": 2555,
      "total_loss": 0.6430514454841614,
      "weighted_orthogonal_loss": 0.019283296540379524
    },
    {
      "classification_loss": 0.6566388010978699,
      "epoch": 8.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19333238899707794,
      "orthogonal_weight": 0.1,
      "step": 2556,
      "total_loss": 0.675972044467926,
      "weighted_orthogonal_loss": 0.019333239644765854
    },
    {
      "classification_loss": 0.5608252882957458,
      "epoch": 8.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19375644624233246,
      "orthogonal_weight": 0.1,
      "step": 2557,
      "total_loss": 0.5802009105682373,
      "weighted_orthogonal_loss": 0.019375644624233246
    },
    {
      "classification_loss": 0.672325849533081,
      "epoch": 8.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19415457546710968,
      "orthogonal_weight": 0.1,
      "step": 2558,
      "total_loss": 0.6917412877082825,
      "weighted_orthogonal_loss": 0.019415458664298058
    },
    {
      "classification_loss": 0.654344916343689,
      "epoch": 8.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1945212334394455,
      "orthogonal_weight": 0.1,
      "step": 2559,
      "total_loss": 0.6737970113754272,
      "weighted_orthogonal_loss": 0.01945212297141552
    },
    {
      "classification_loss": 0.6101554036140442,
      "epoch": 8.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19489140808582306,
      "orthogonal_weight": 0.1,
      "step": 2560,
      "total_loss": 0.6296445727348328,
      "weighted_orthogonal_loss": 0.019489141181111336
    },
    {
      "classification_loss": 0.6702594757080078,
      "epoch": 8.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19514666497707367,
      "orthogonal_weight": 0.1,
      "step": 2561,
      "total_loss": 0.6897741556167603,
      "weighted_orthogonal_loss": 0.019514666870236397
    },
    {
      "classification_loss": 0.6031902432441711,
      "epoch": 8.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19526059925556183,
      "orthogonal_weight": 0.1,
      "step": 2562,
      "total_loss": 0.6227163076400757,
      "weighted_orthogonal_loss": 0.019526060670614243
    },
    {
      "classification_loss": 0.6657183170318604,
      "epoch": 8.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19534383714199066,
      "orthogonal_weight": 0.1,
      "step": 2563,
      "total_loss": 0.6852527260780334,
      "weighted_orthogonal_loss": 0.019534384831786156
    },
    {
      "classification_loss": 0.6903702020645142,
      "epoch": 8.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19555453956127167,
      "orthogonal_weight": 0.1,
      "step": 2564,
      "total_loss": 0.709925651550293,
      "weighted_orthogonal_loss": 0.019555455073714256
    },
    {
      "classification_loss": 0.6203345060348511,
      "epoch": 8.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19575218856334686,
      "orthogonal_weight": 0.1,
      "step": 2565,
      "total_loss": 0.6399097442626953,
      "weighted_orthogonal_loss": 0.019575219601392746
    },
    {
      "classification_loss": 0.656513512134552,
      "epoch": 8.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1959608644247055,
      "orthogonal_weight": 0.1,
      "step": 2566,
      "total_loss": 0.6761096119880676,
      "weighted_orthogonal_loss": 0.01959608681499958
    },
    {
      "classification_loss": 0.6421868801116943,
      "epoch": 8.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19594044983386993,
      "orthogonal_weight": 0.1,
      "step": 2567,
      "total_loss": 0.6617809534072876,
      "weighted_orthogonal_loss": 0.019594045355916023
    },
    {
      "classification_loss": 0.6295050978660583,
      "epoch": 8.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1956331729888916,
      "orthogonal_weight": 0.1,
      "step": 2568,
      "total_loss": 0.6490684151649475,
      "weighted_orthogonal_loss": 0.01956331729888916
    },
    {
      "classification_loss": 0.6385729908943176,
      "epoch": 8.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953316628932953,
      "orthogonal_weight": 0.1,
      "step": 2569,
      "total_loss": 0.6581061482429504,
      "weighted_orthogonal_loss": 0.01953316666185856
    },
    {
      "classification_loss": 0.7060128450393677,
      "epoch": 8.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19513842463493347,
      "orthogonal_weight": 0.1,
      "step": 2570,
      "total_loss": 0.7255266904830933,
      "weighted_orthogonal_loss": 0.019513843581080437
    },
    {
      "classification_loss": 0.6469421982765198,
      "epoch": 8.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19501051306724548,
      "orthogonal_weight": 0.1,
      "step": 2571,
      "total_loss": 0.6664432287216187,
      "weighted_orthogonal_loss": 0.01950105093419552
    },
    {
      "classification_loss": 0.6383594870567322,
      "epoch": 8.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19487889111042023,
      "orthogonal_weight": 0.1,
      "step": 2572,
      "total_loss": 0.6578474044799805,
      "weighted_orthogonal_loss": 0.019487889483571053
    },
    {
      "classification_loss": 0.6125531196594238,
      "epoch": 8.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19476330280303955,
      "orthogonal_weight": 0.1,
      "step": 2573,
      "total_loss": 0.6320294737815857,
      "weighted_orthogonal_loss": 0.019476329907774925
    },
    {
      "classification_loss": 0.5851704478263855,
      "epoch": 8.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19468733668327332,
      "orthogonal_weight": 0.1,
      "step": 2574,
      "total_loss": 0.6046391725540161,
      "weighted_orthogonal_loss": 0.01946873404085636
    },
    {
      "classification_loss": 0.6592136025428772,
      "epoch": 8.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1946464627981186,
      "orthogonal_weight": 0.1,
      "step": 2575,
      "total_loss": 0.6786782741546631,
      "weighted_orthogonal_loss": 0.01946464739739895
    },
    {
      "classification_loss": 0.6049217581748962,
      "epoch": 8.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19471533596515656,
      "orthogonal_weight": 0.1,
      "step": 2576,
      "total_loss": 0.6243932843208313,
      "weighted_orthogonal_loss": 0.019471533596515656
    },
    {
      "classification_loss": 0.6105530858039856,
      "epoch": 8.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19482840597629547,
      "orthogonal_weight": 0.1,
      "step": 2577,
      "total_loss": 0.630035936832428,
      "weighted_orthogonal_loss": 0.019482841715216637
    },
    {
      "classification_loss": 0.602668285369873,
      "epoch": 8.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19496436417102814,
      "orthogonal_weight": 0.1,
      "step": 2578,
      "total_loss": 0.6221647262573242,
      "weighted_orthogonal_loss": 0.019496437162160873
    },
    {
      "classification_loss": 0.6154964566230774,
      "epoch": 8.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19509705901145935,
      "orthogonal_weight": 0.1,
      "step": 2579,
      "total_loss": 0.6350061893463135,
      "weighted_orthogonal_loss": 0.019509706646203995
    },
    {
      "classification_loss": 0.5986380577087402,
      "epoch": 8.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19522476196289062,
      "orthogonal_weight": 0.1,
      "step": 2580,
      "total_loss": 0.6181605458259583,
      "weighted_orthogonal_loss": 0.019522476941347122
    },
    {
      "classification_loss": 0.6115156412124634,
      "epoch": 8.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19529283046722412,
      "orthogonal_weight": 0.1,
      "step": 2581,
      "total_loss": 0.6310449242591858,
      "weighted_orthogonal_loss": 0.019529283046722412
    },
    {
      "classification_loss": 0.6034501791000366,
      "epoch": 8.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1952926516532898,
      "orthogonal_weight": 0.1,
      "step": 2582,
      "total_loss": 0.622979462146759,
      "weighted_orthogonal_loss": 0.01952926628291607
    },
    {
      "classification_loss": 0.5726838707923889,
      "epoch": 8.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19522829353809357,
      "orthogonal_weight": 0.1,
      "step": 2583,
      "total_loss": 0.5922067165374756,
      "weighted_orthogonal_loss": 0.019522828981280327
    },
    {
      "classification_loss": 0.7176041007041931,
      "epoch": 8.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19516241550445557,
      "orthogonal_weight": 0.1,
      "step": 2584,
      "total_loss": 0.7371203303337097,
      "weighted_orthogonal_loss": 0.019516242668032646
    },
    {
      "classification_loss": 0.5450926423072815,
      "epoch": 8.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19512103497982025,
      "orthogonal_weight": 0.1,
      "step": 2585,
      "total_loss": 0.5646047592163086,
      "weighted_orthogonal_loss": 0.019512103870511055
    },
    {
      "classification_loss": 0.6853083968162537,
      "epoch": 8.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19509251415729523,
      "orthogonal_weight": 0.1,
      "step": 2586,
      "total_loss": 0.7048176527023315,
      "weighted_orthogonal_loss": 0.019509252160787582
    },
    {
      "classification_loss": 0.5617456436157227,
      "epoch": 8.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19493718445301056,
      "orthogonal_weight": 0.1,
      "step": 2587,
      "total_loss": 0.5812393426895142,
      "weighted_orthogonal_loss": 0.019493719562888145
    },
    {
      "classification_loss": 0.6098379492759705,
      "epoch": 8.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1948116272687912,
      "orthogonal_weight": 0.1,
      "step": 2588,
      "total_loss": 0.6293191313743591,
      "weighted_orthogonal_loss": 0.01948116347193718
    },
    {
      "classification_loss": 0.6516851782798767,
      "epoch": 8.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19473454356193542,
      "orthogonal_weight": 0.1,
      "step": 2589,
      "total_loss": 0.6711586117744446,
      "weighted_orthogonal_loss": 0.019473453983664513
    },
    {
      "classification_loss": 0.651463508605957,
      "epoch": 8.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19467945396900177,
      "orthogonal_weight": 0.1,
      "step": 2590,
      "total_loss": 0.6709314584732056,
      "weighted_orthogonal_loss": 0.019467946141958237
    },
    {
      "classification_loss": 0.663193941116333,
      "epoch": 8.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19458995759487152,
      "orthogonal_weight": 0.1,
      "step": 2591,
      "total_loss": 0.6826529502868652,
      "weighted_orthogonal_loss": 0.019458996132016182
    },
    {
      "classification_loss": 0.6613516807556152,
      "epoch": 8.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19447404146194458,
      "orthogonal_weight": 0.1,
      "step": 2592,
      "total_loss": 0.6807990670204163,
      "weighted_orthogonal_loss": 0.019447404891252518
    },
    {
      "classification_loss": 0.6611354947090149,
      "epoch": 8.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19435575604438782,
      "orthogonal_weight": 0.1,
      "step": 2593,
      "total_loss": 0.6805710792541504,
      "weighted_orthogonal_loss": 0.019435575231909752
    },
    {
      "classification_loss": 0.5783165097236633,
      "epoch": 8.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1942347288131714,
      "orthogonal_weight": 0.1,
      "step": 2594,
      "total_loss": 0.5977399945259094,
      "weighted_orthogonal_loss": 0.0194234736263752
    },
    {
      "classification_loss": 0.6686057448387146,
      "epoch": 8.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19415800273418427,
      "orthogonal_weight": 0.1,
      "step": 2595,
      "total_loss": 0.6880215406417847,
      "weighted_orthogonal_loss": 0.019415801391005516
    },
    {
      "classification_loss": 0.6400310397148132,
      "epoch": 8.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19407272338867188,
      "orthogonal_weight": 0.1,
      "step": 2596,
      "total_loss": 0.6594383120536804,
      "weighted_orthogonal_loss": 0.019407272338867188
    },
    {
      "classification_loss": 0.6053593754768372,
      "epoch": 8.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19404760003089905,
      "orthogonal_weight": 0.1,
      "step": 2597,
      "total_loss": 0.6247641444206238,
      "weighted_orthogonal_loss": 0.019404759630560875
    },
    {
      "classification_loss": 0.6624887585639954,
      "epoch": 8.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19391195476055145,
      "orthogonal_weight": 0.1,
      "step": 2598,
      "total_loss": 0.6818799376487732,
      "weighted_orthogonal_loss": 0.019391195848584175
    },
    {
      "classification_loss": 0.603531002998352,
      "epoch": 8.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1937953382730484,
      "orthogonal_weight": 0.1,
      "step": 2599,
      "total_loss": 0.6229105591773987,
      "weighted_orthogonal_loss": 0.01937953382730484
    },
    {
      "epoch": 8.524590163934427,
      "grad_norm": 19.239797592163086,
      "learning_rate": 0.0001167,
      "loss": 0.6516,
      "step": 2600
    },
    {
      "classification_loss": 0.6475334167480469,
      "epoch": 8.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19370697438716888,
      "orthogonal_weight": 0.1,
      "step": 2600,
      "total_loss": 0.666904091835022,
      "weighted_orthogonal_loss": 0.01937069743871689
    },
    {
      "classification_loss": 0.6140404343605042,
      "epoch": 8.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1936631202697754,
      "orthogonal_weight": 0.1,
      "step": 2601,
      "total_loss": 0.6334067583084106,
      "weighted_orthogonal_loss": 0.0193663127720356
    },
    {
      "classification_loss": 0.5617052316665649,
      "epoch": 8.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19368329644203186,
      "orthogonal_weight": 0.1,
      "step": 2602,
      "total_loss": 0.5810735821723938,
      "weighted_orthogonal_loss": 0.019368330016732216
    },
    {
      "classification_loss": 0.6381819248199463,
      "epoch": 8.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1936962604522705,
      "orthogonal_weight": 0.1,
      "step": 2603,
      "total_loss": 0.6575515270233154,
      "weighted_orthogonal_loss": 0.01936962641775608
    },
    {
      "classification_loss": 0.5707730054855347,
      "epoch": 8.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19369062781333923,
      "orthogonal_weight": 0.1,
      "step": 2604,
      "total_loss": 0.5901420712471008,
      "weighted_orthogonal_loss": 0.019369063898921013
    },
    {
      "classification_loss": 0.6387328505516052,
      "epoch": 8.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19347132742404938,
      "orthogonal_weight": 0.1,
      "step": 2605,
      "total_loss": 0.658079981803894,
      "weighted_orthogonal_loss": 0.019347133114933968
    },
    {
      "classification_loss": 0.5483119487762451,
      "epoch": 8.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1932658702135086,
      "orthogonal_weight": 0.1,
      "step": 2606,
      "total_loss": 0.5676385164260864,
      "weighted_orthogonal_loss": 0.01932658813893795
    },
    {
      "classification_loss": 0.6374264359474182,
      "epoch": 8.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1931532770395279,
      "orthogonal_weight": 0.1,
      "step": 2607,
      "total_loss": 0.656741738319397,
      "weighted_orthogonal_loss": 0.01931532844901085
    },
    {
      "classification_loss": 0.6339036226272583,
      "epoch": 8.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19309568405151367,
      "orthogonal_weight": 0.1,
      "step": 2608,
      "total_loss": 0.6532132029533386,
      "weighted_orthogonal_loss": 0.019309569150209427
    },
    {
      "classification_loss": 0.6691874861717224,
      "epoch": 8.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19311738014221191,
      "orthogonal_weight": 0.1,
      "step": 2609,
      "total_loss": 0.6884992122650146,
      "weighted_orthogonal_loss": 0.01931173913180828
    },
    {
      "classification_loss": 0.6312699317932129,
      "epoch": 8.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19312793016433716,
      "orthogonal_weight": 0.1,
      "step": 2610,
      "total_loss": 0.6505827307701111,
      "weighted_orthogonal_loss": 0.019312793388962746
    },
    {
      "classification_loss": 0.7055900692939758,
      "epoch": 8.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1930832415819168,
      "orthogonal_weight": 0.1,
      "step": 2611,
      "total_loss": 0.7248983979225159,
      "weighted_orthogonal_loss": 0.01930832490324974
    },
    {
      "classification_loss": 0.6000440120697021,
      "epoch": 8.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19298622012138367,
      "orthogonal_weight": 0.1,
      "step": 2612,
      "total_loss": 0.6193426251411438,
      "weighted_orthogonal_loss": 0.019298622384667397
    },
    {
      "classification_loss": 0.6522172093391418,
      "epoch": 8.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19300156831741333,
      "orthogonal_weight": 0.1,
      "step": 2613,
      "total_loss": 0.6715173721313477,
      "weighted_orthogonal_loss": 0.019300157204270363
    },
    {
      "classification_loss": 0.5901442170143127,
      "epoch": 8.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928974986076355,
      "orthogonal_weight": 0.1,
      "step": 2614,
      "total_loss": 0.6094339489936829,
      "weighted_orthogonal_loss": 0.01928975060582161
    },
    {
      "classification_loss": 0.6567416787147522,
      "epoch": 8.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19281315803527832,
      "orthogonal_weight": 0.1,
      "step": 2615,
      "total_loss": 0.676023006439209,
      "weighted_orthogonal_loss": 0.01928131654858589
    },
    {
      "classification_loss": 0.6941439509391785,
      "epoch": 8.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19267722964286804,
      "orthogonal_weight": 0.1,
      "step": 2616,
      "total_loss": 0.7134116888046265,
      "weighted_orthogonal_loss": 0.019267722964286804
    },
    {
      "classification_loss": 0.6252202391624451,
      "epoch": 8.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19260276854038239,
      "orthogonal_weight": 0.1,
      "step": 2617,
      "total_loss": 0.6444805264472961,
      "weighted_orthogonal_loss": 0.019260277971625328
    },
    {
      "classification_loss": 0.5893414616584778,
      "epoch": 8.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19266611337661743,
      "orthogonal_weight": 0.1,
      "step": 2618,
      "total_loss": 0.608608067035675,
      "weighted_orthogonal_loss": 0.019266610965132713
    },
    {
      "classification_loss": 0.5930071473121643,
      "epoch": 8.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19274182617664337,
      "orthogonal_weight": 0.1,
      "step": 2619,
      "total_loss": 0.612281322479248,
      "weighted_orthogonal_loss": 0.019274182617664337
    },
    {
      "classification_loss": 0.6229773759841919,
      "epoch": 8.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19287611544132233,
      "orthogonal_weight": 0.1,
      "step": 2620,
      "total_loss": 0.6422649621963501,
      "weighted_orthogonal_loss": 0.019287612289190292
    },
    {
      "classification_loss": 0.6285528540611267,
      "epoch": 8.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1930568814277649,
      "orthogonal_weight": 0.1,
      "step": 2621,
      "total_loss": 0.6478585600852966,
      "weighted_orthogonal_loss": 0.01930568926036358
    },
    {
      "classification_loss": 0.6893895864486694,
      "epoch": 8.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19330592453479767,
      "orthogonal_weight": 0.1,
      "step": 2622,
      "total_loss": 0.7087202072143555,
      "weighted_orthogonal_loss": 0.019330592826008797
    },
    {
      "classification_loss": 0.6417662501335144,
      "epoch": 8.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19326737523078918,
      "orthogonal_weight": 0.1,
      "step": 2623,
      "total_loss": 0.66109299659729,
      "weighted_orthogonal_loss": 0.01932673715054989
    },
    {
      "classification_loss": 0.6780213117599487,
      "epoch": 8.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19331595301628113,
      "orthogonal_weight": 0.1,
      "step": 2624,
      "total_loss": 0.6973528861999512,
      "weighted_orthogonal_loss": 0.019331594929099083
    },
    {
      "classification_loss": 0.6589167714118958,
      "epoch": 8.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19337446987628937,
      "orthogonal_weight": 0.1,
      "step": 2625,
      "total_loss": 0.678254246711731,
      "weighted_orthogonal_loss": 0.019337447360157967
    },
    {
      "classification_loss": 0.6356773972511292,
      "epoch": 8.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19343474507331848,
      "orthogonal_weight": 0.1,
      "step": 2626,
      "total_loss": 0.6550208926200867,
      "weighted_orthogonal_loss": 0.019343474879860878
    },
    {
      "classification_loss": 0.6908326148986816,
      "epoch": 8.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19354641437530518,
      "orthogonal_weight": 0.1,
      "step": 2627,
      "total_loss": 0.7101872563362122,
      "weighted_orthogonal_loss": 0.019354641437530518
    },
    {
      "classification_loss": 0.6762746572494507,
      "epoch": 8.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19367291033267975,
      "orthogonal_weight": 0.1,
      "step": 2628,
      "total_loss": 0.6956419348716736,
      "weighted_orthogonal_loss": 0.019367290660738945
    },
    {
      "classification_loss": 0.6429612040519714,
      "epoch": 8.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19377662241458893,
      "orthogonal_weight": 0.1,
      "step": 2629,
      "total_loss": 0.6623388528823853,
      "weighted_orthogonal_loss": 0.019377661868929863
    },
    {
      "classification_loss": 0.6433209776878357,
      "epoch": 8.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19378109276294708,
      "orthogonal_weight": 0.1,
      "step": 2630,
      "total_loss": 0.6626991033554077,
      "weighted_orthogonal_loss": 0.01937810890376568
    },
    {
      "classification_loss": 0.5605498552322388,
      "epoch": 8.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1938757449388504,
      "orthogonal_weight": 0.1,
      "step": 2631,
      "total_loss": 0.5799374580383301,
      "weighted_orthogonal_loss": 0.01938757486641407
    },
    {
      "classification_loss": 0.5671265125274658,
      "epoch": 8.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19402402639389038,
      "orthogonal_weight": 0.1,
      "step": 2632,
      "total_loss": 0.5865288972854614,
      "weighted_orthogonal_loss": 0.019402403384447098
    },
    {
      "classification_loss": 0.7342469692230225,
      "epoch": 8.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19420474767684937,
      "orthogonal_weight": 0.1,
      "step": 2633,
      "total_loss": 0.7536674737930298,
      "weighted_orthogonal_loss": 0.019420474767684937
    },
    {
      "classification_loss": 0.6602013111114502,
      "epoch": 8.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19429278373718262,
      "orthogonal_weight": 0.1,
      "step": 2634,
      "total_loss": 0.6796305775642395,
      "weighted_orthogonal_loss": 0.01942927949130535
    },
    {
      "classification_loss": 0.6233286261558533,
      "epoch": 8.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19436772167682648,
      "orthogonal_weight": 0.1,
      "step": 2635,
      "total_loss": 0.6427654027938843,
      "weighted_orthogonal_loss": 0.019436772912740707
    },
    {
      "classification_loss": 0.7011550664901733,
      "epoch": 8.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1945076286792755,
      "orthogonal_weight": 0.1,
      "step": 2636,
      "total_loss": 0.7206058502197266,
      "weighted_orthogonal_loss": 0.01945076324045658
    },
    {
      "classification_loss": 0.6612306237220764,
      "epoch": 8.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19460701942443848,
      "orthogonal_weight": 0.1,
      "step": 2637,
      "total_loss": 0.6806913018226624,
      "weighted_orthogonal_loss": 0.019460702314972878
    },
    {
      "classification_loss": 0.5887324810028076,
      "epoch": 8.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.194734588265419,
      "orthogonal_weight": 0.1,
      "step": 2638,
      "total_loss": 0.6082059144973755,
      "weighted_orthogonal_loss": 0.01947345957159996
    },
    {
      "classification_loss": 0.6034963130950928,
      "epoch": 8.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19489626586437225,
      "orthogonal_weight": 0.1,
      "step": 2639,
      "total_loss": 0.6229859590530396,
      "weighted_orthogonal_loss": 0.019489627331495285
    },
    {
      "classification_loss": 0.6428759694099426,
      "epoch": 8.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.194968119263649,
      "orthogonal_weight": 0.1,
      "step": 2640,
      "total_loss": 0.6623727679252625,
      "weighted_orthogonal_loss": 0.01949681155383587
    },
    {
      "classification_loss": 0.5899516940116882,
      "epoch": 8.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1950884312391281,
      "orthogonal_weight": 0.1,
      "step": 2641,
      "total_loss": 0.6094605326652527,
      "weighted_orthogonal_loss": 0.0195088442414999
    },
    {
      "classification_loss": 0.5403589010238647,
      "epoch": 8.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19508478045463562,
      "orthogonal_weight": 0.1,
      "step": 2642,
      "total_loss": 0.5598673820495605,
      "weighted_orthogonal_loss": 0.01950847916305065
    },
    {
      "classification_loss": 0.6649196147918701,
      "epoch": 8.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1950838565826416,
      "orthogonal_weight": 0.1,
      "step": 2643,
      "total_loss": 0.6844279766082764,
      "weighted_orthogonal_loss": 0.01950838603079319
    },
    {
      "classification_loss": 0.5847793221473694,
      "epoch": 8.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1952761858701706,
      "orthogonal_weight": 0.1,
      "step": 2644,
      "total_loss": 0.6043069362640381,
      "weighted_orthogonal_loss": 0.01952761970460415
    },
    {
      "classification_loss": 0.5588194131851196,
      "epoch": 8.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19552089273929596,
      "orthogonal_weight": 0.1,
      "step": 2645,
      "total_loss": 0.578371524810791,
      "weighted_orthogonal_loss": 0.019552089273929596
    },
    {
      "classification_loss": 0.6513749957084656,
      "epoch": 8.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19556789100170135,
      "orthogonal_weight": 0.1,
      "step": 2646,
      "total_loss": 0.6709317564964294,
      "weighted_orthogonal_loss": 0.019556788727641106
    },
    {
      "classification_loss": 0.6376433372497559,
      "epoch": 8.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19573472440242767,
      "orthogonal_weight": 0.1,
      "step": 2647,
      "total_loss": 0.6572167873382568,
      "weighted_orthogonal_loss": 0.019573472440242767
    },
    {
      "classification_loss": 0.6648849844932556,
      "epoch": 8.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19595642387866974,
      "orthogonal_weight": 0.1,
      "step": 2648,
      "total_loss": 0.684480607509613,
      "weighted_orthogonal_loss": 0.019595643505454063
    },
    {
      "classification_loss": 0.633585512638092,
      "epoch": 8.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19611287117004395,
      "orthogonal_weight": 0.1,
      "step": 2649,
      "total_loss": 0.6531968116760254,
      "weighted_orthogonal_loss": 0.019611287862062454
    },
    {
      "classification_loss": 0.5850498080253601,
      "epoch": 8.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19622285664081573,
      "orthogonal_weight": 0.1,
      "step": 2650,
      "total_loss": 0.6046720743179321,
      "weighted_orthogonal_loss": 0.019622286781668663
    },
    {
      "classification_loss": 0.6379415392875671,
      "epoch": 8.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19631673395633698,
      "orthogonal_weight": 0.1,
      "step": 2651,
      "total_loss": 0.6575732231140137,
      "weighted_orthogonal_loss": 0.019631674513220787
    },
    {
      "classification_loss": 0.6748817563056946,
      "epoch": 8.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1961163878440857,
      "orthogonal_weight": 0.1,
      "step": 2652,
      "total_loss": 0.6944934129714966,
      "weighted_orthogonal_loss": 0.01961163990199566
    },
    {
      "classification_loss": 0.6853284239768982,
      "epoch": 8.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1958577185869217,
      "orthogonal_weight": 0.1,
      "step": 2653,
      "total_loss": 0.7049142122268677,
      "weighted_orthogonal_loss": 0.01958577148616314
    },
    {
      "classification_loss": 0.6816552877426147,
      "epoch": 8.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19575248658657074,
      "orthogonal_weight": 0.1,
      "step": 2654,
      "total_loss": 0.701230525970459,
      "weighted_orthogonal_loss": 0.019575249403715134
    },
    {
      "classification_loss": 0.6152753233909607,
      "epoch": 8.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19557957351207733,
      "orthogonal_weight": 0.1,
      "step": 2655,
      "total_loss": 0.6348332762718201,
      "weighted_orthogonal_loss": 0.019557958468794823
    },
    {
      "classification_loss": 0.7013141512870789,
      "epoch": 8.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953907161951065,
      "orthogonal_weight": 0.1,
      "step": 2656,
      "total_loss": 0.7208532094955444,
      "weighted_orthogonal_loss": 0.01953907124698162
    },
    {
      "classification_loss": 0.5941558480262756,
      "epoch": 8.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19519169628620148,
      "orthogonal_weight": 0.1,
      "step": 2657,
      "total_loss": 0.6136749982833862,
      "weighted_orthogonal_loss": 0.019519170746207237
    },
    {
      "classification_loss": 0.5952731966972351,
      "epoch": 8.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19491811096668243,
      "orthogonal_weight": 0.1,
      "step": 2658,
      "total_loss": 0.6147649884223938,
      "weighted_orthogonal_loss": 0.019491812214255333
    },
    {
      "classification_loss": 0.5846250653266907,
      "epoch": 8.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19466394186019897,
      "orthogonal_weight": 0.1,
      "step": 2659,
      "total_loss": 0.604091465473175,
      "weighted_orthogonal_loss": 0.019466394558548927
    },
    {
      "classification_loss": 0.5654032826423645,
      "epoch": 8.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1944454312324524,
      "orthogonal_weight": 0.1,
      "step": 2660,
      "total_loss": 0.5848478078842163,
      "weighted_orthogonal_loss": 0.0194445438683033
    },
    {
      "classification_loss": 0.6508111953735352,
      "epoch": 8.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1941976398229599,
      "orthogonal_weight": 0.1,
      "step": 2661,
      "total_loss": 0.6702309846878052,
      "weighted_orthogonal_loss": 0.01941976509988308
    },
    {
      "classification_loss": 0.6653847694396973,
      "epoch": 8.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19401320815086365,
      "orthogonal_weight": 0.1,
      "step": 2662,
      "total_loss": 0.6847860813140869,
      "weighted_orthogonal_loss": 0.019401321187615395
    },
    {
      "classification_loss": 0.6246095895767212,
      "epoch": 8.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19386886060237885,
      "orthogonal_weight": 0.1,
      "step": 2663,
      "total_loss": 0.6439964771270752,
      "weighted_orthogonal_loss": 0.019386885687708855
    },
    {
      "classification_loss": 0.5865443348884583,
      "epoch": 8.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19380617141723633,
      "orthogonal_weight": 0.1,
      "step": 2664,
      "total_loss": 0.6059249639511108,
      "weighted_orthogonal_loss": 0.019380617886781693
    },
    {
      "classification_loss": 0.6390875577926636,
      "epoch": 8.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1937294751405716,
      "orthogonal_weight": 0.1,
      "step": 2665,
      "total_loss": 0.6584604978561401,
      "weighted_orthogonal_loss": 0.01937294751405716
    },
    {
      "classification_loss": 0.5832360982894897,
      "epoch": 8.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19346930086612701,
      "orthogonal_weight": 0.1,
      "step": 2666,
      "total_loss": 0.6025830507278442,
      "weighted_orthogonal_loss": 0.0193469300866127
    },
    {
      "classification_loss": 0.6334862112998962,
      "epoch": 8.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19328290224075317,
      "orthogonal_weight": 0.1,
      "step": 2667,
      "total_loss": 0.652814507484436,
      "weighted_orthogonal_loss": 0.019328290596604347
    },
    {
      "classification_loss": 0.616073489189148,
      "epoch": 8.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19315150380134583,
      "orthogonal_weight": 0.1,
      "step": 2668,
      "total_loss": 0.6353886127471924,
      "weighted_orthogonal_loss": 0.019315151497721672
    },
    {
      "classification_loss": 0.678331196308136,
      "epoch": 8.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19310058653354645,
      "orthogonal_weight": 0.1,
      "step": 2669,
      "total_loss": 0.6976412534713745,
      "weighted_orthogonal_loss": 0.019310059025883675
    },
    {
      "classification_loss": 0.6550416350364685,
      "epoch": 8.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19289667904376984,
      "orthogonal_weight": 0.1,
      "step": 2670,
      "total_loss": 0.6743313074111938,
      "weighted_orthogonal_loss": 0.019289668649435043
    },
    {
      "classification_loss": 0.6267021298408508,
      "epoch": 8.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19276423752307892,
      "orthogonal_weight": 0.1,
      "step": 2671,
      "total_loss": 0.645978569984436,
      "weighted_orthogonal_loss": 0.019276423379778862
    },
    {
      "classification_loss": 0.5244439244270325,
      "epoch": 8.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19272667169570923,
      "orthogonal_weight": 0.1,
      "step": 2672,
      "total_loss": 0.5437166094779968,
      "weighted_orthogonal_loss": 0.019272668287158012
    },
    {
      "classification_loss": 0.6678816080093384,
      "epoch": 8.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19274871051311493,
      "orthogonal_weight": 0.1,
      "step": 2673,
      "total_loss": 0.6871564984321594,
      "weighted_orthogonal_loss": 0.019274871796369553
    },
    {
      "classification_loss": 0.6813902854919434,
      "epoch": 8.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928512305021286,
      "orthogonal_weight": 0.1,
      "step": 2674,
      "total_loss": 0.7006754279136658,
      "weighted_orthogonal_loss": 0.01928512379527092
    },
    {
      "classification_loss": 0.667580246925354,
      "epoch": 8.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19294509291648865,
      "orthogonal_weight": 0.1,
      "step": 2675,
      "total_loss": 0.6868747472763062,
      "weighted_orthogonal_loss": 0.019294509664177895
    },
    {
      "classification_loss": 0.6399338245391846,
      "epoch": 8.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19301968812942505,
      "orthogonal_weight": 0.1,
      "step": 2676,
      "total_loss": 0.6592357754707336,
      "weighted_orthogonal_loss": 0.019301969558000565
    },
    {
      "classification_loss": 0.6749098300933838,
      "epoch": 8.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19317537546157837,
      "orthogonal_weight": 0.1,
      "step": 2677,
      "total_loss": 0.6942273378372192,
      "weighted_orthogonal_loss": 0.019317537546157837
    },
    {
      "classification_loss": 0.5716599225997925,
      "epoch": 8.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19333691895008087,
      "orthogonal_weight": 0.1,
      "step": 2678,
      "total_loss": 0.5909936428070068,
      "weighted_orthogonal_loss": 0.019333692267537117
    },
    {
      "classification_loss": 0.6243952512741089,
      "epoch": 8.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19351987540721893,
      "orthogonal_weight": 0.1,
      "step": 2679,
      "total_loss": 0.6437472105026245,
      "weighted_orthogonal_loss": 0.019351987168192863
    },
    {
      "classification_loss": 0.6011485457420349,
      "epoch": 8.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19367285072803497,
      "orthogonal_weight": 0.1,
      "step": 2680,
      "total_loss": 0.6205158233642578,
      "weighted_orthogonal_loss": 0.019367285072803497
    },
    {
      "classification_loss": 0.637039303779602,
      "epoch": 8.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19375966489315033,
      "orthogonal_weight": 0.1,
      "step": 2681,
      "total_loss": 0.6564152836799622,
      "weighted_orthogonal_loss": 0.019375966861844063
    },
    {
      "classification_loss": 0.6263126730918884,
      "epoch": 8.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1938176453113556,
      "orthogonal_weight": 0.1,
      "step": 2682,
      "total_loss": 0.6456944346427917,
      "weighted_orthogonal_loss": 0.01938176527619362
    },
    {
      "classification_loss": 0.6541990637779236,
      "epoch": 8.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19386117160320282,
      "orthogonal_weight": 0.1,
      "step": 2683,
      "total_loss": 0.6735851764678955,
      "weighted_orthogonal_loss": 0.01938611827790737
    },
    {
      "classification_loss": 0.655929684638977,
      "epoch": 8.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19392110407352448,
      "orthogonal_weight": 0.1,
      "step": 2684,
      "total_loss": 0.6753218173980713,
      "weighted_orthogonal_loss": 0.019392110407352448
    },
    {
      "classification_loss": 0.674744188785553,
      "epoch": 8.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19403189420700073,
      "orthogonal_weight": 0.1,
      "step": 2685,
      "total_loss": 0.6941473484039307,
      "weighted_orthogonal_loss": 0.019403189420700073
    },
    {
      "classification_loss": 0.621898889541626,
      "epoch": 8.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19411161541938782,
      "orthogonal_weight": 0.1,
      "step": 2686,
      "total_loss": 0.6413100361824036,
      "weighted_orthogonal_loss": 0.019411161541938782
    },
    {
      "classification_loss": 0.5809491276741028,
      "epoch": 8.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19401432573795319,
      "orthogonal_weight": 0.1,
      "step": 2687,
      "total_loss": 0.600350558757782,
      "weighted_orthogonal_loss": 0.01940143294632435
    },
    {
      "classification_loss": 0.6740369200706482,
      "epoch": 8.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19403228163719177,
      "orthogonal_weight": 0.1,
      "step": 2688,
      "total_loss": 0.6934401392936707,
      "weighted_orthogonal_loss": 0.019403228536248207
    },
    {
      "classification_loss": 0.6826869249343872,
      "epoch": 8.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1940966695547104,
      "orthogonal_weight": 0.1,
      "step": 2689,
      "total_loss": 0.7020965814590454,
      "weighted_orthogonal_loss": 0.0194096677005291
    },
    {
      "classification_loss": 0.6353159546852112,
      "epoch": 8.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19410032033920288,
      "orthogonal_weight": 0.1,
      "step": 2690,
      "total_loss": 0.654725968837738,
      "weighted_orthogonal_loss": 0.019410032778978348
    },
    {
      "classification_loss": 0.5964749455451965,
      "epoch": 8.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19413425028324127,
      "orthogonal_weight": 0.1,
      "step": 2691,
      "total_loss": 0.6158883571624756,
      "weighted_orthogonal_loss": 0.019413424655795097
    },
    {
      "classification_loss": 0.636838436126709,
      "epoch": 8.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19410201907157898,
      "orthogonal_weight": 0.1,
      "step": 2692,
      "total_loss": 0.6562486290931702,
      "weighted_orthogonal_loss": 0.019410202279686928
    },
    {
      "classification_loss": 0.6133253574371338,
      "epoch": 8.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19407391548156738,
      "orthogonal_weight": 0.1,
      "step": 2693,
      "total_loss": 0.6327327489852905,
      "weighted_orthogonal_loss": 0.01940739154815674
    },
    {
      "classification_loss": 0.6781448721885681,
      "epoch": 8.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1940571367740631,
      "orthogonal_weight": 0.1,
      "step": 2694,
      "total_loss": 0.6975505948066711,
      "weighted_orthogonal_loss": 0.01940571330487728
    },
    {
      "classification_loss": 0.6289817690849304,
      "epoch": 8.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19379356503486633,
      "orthogonal_weight": 0.1,
      "step": 2695,
      "total_loss": 0.6483611464500427,
      "weighted_orthogonal_loss": 0.019379356876015663
    },
    {
      "classification_loss": 0.6107996106147766,
      "epoch": 8.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19355912506580353,
      "orthogonal_weight": 0.1,
      "step": 2696,
      "total_loss": 0.6301555037498474,
      "weighted_orthogonal_loss": 0.019355913624167442
    },
    {
      "classification_loss": 0.637863039970398,
      "epoch": 8.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1933053880929947,
      "orthogonal_weight": 0.1,
      "step": 2697,
      "total_loss": 0.6571936011314392,
      "weighted_orthogonal_loss": 0.01933053880929947
    },
    {
      "classification_loss": 0.6278234124183655,
      "epoch": 8.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19315235316753387,
      "orthogonal_weight": 0.1,
      "step": 2698,
      "total_loss": 0.6471386551856995,
      "weighted_orthogonal_loss": 0.019315235316753387
    },
    {
      "classification_loss": 0.6068838834762573,
      "epoch": 8.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1930994838476181,
      "orthogonal_weight": 0.1,
      "step": 2699,
      "total_loss": 0.6261938214302063,
      "weighted_orthogonal_loss": 0.01930994912981987
    },
    {
      "epoch": 8.852459016393443,
      "grad_norm": 7.227108001708984,
      "learning_rate": 0.00011336666666666667,
      "loss": 0.6513,
      "step": 2700
    },
    {
      "classification_loss": 0.6068527698516846,
      "epoch": 8.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19300051033496857,
      "orthogonal_weight": 0.1,
      "step": 2700,
      "total_loss": 0.6261528134346008,
      "weighted_orthogonal_loss": 0.019300051033496857
    },
    {
      "classification_loss": 0.6348319053649902,
      "epoch": 8.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19294197857379913,
      "orthogonal_weight": 0.1,
      "step": 2701,
      "total_loss": 0.6541261076927185,
      "weighted_orthogonal_loss": 0.019294198602437973
    },
    {
      "classification_loss": 0.5571497082710266,
      "epoch": 8.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19287458062171936,
      "orthogonal_weight": 0.1,
      "step": 2702,
      "total_loss": 0.5764371752738953,
      "weighted_orthogonal_loss": 0.019287457689642906
    },
    {
      "classification_loss": 0.6074188947677612,
      "epoch": 8.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.192793071269989,
      "orthogonal_weight": 0.1,
      "step": 2703,
      "total_loss": 0.6266981959342957,
      "weighted_orthogonal_loss": 0.01927930675446987
    },
    {
      "classification_loss": 0.6876001358032227,
      "epoch": 8.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19282197952270508,
      "orthogonal_weight": 0.1,
      "step": 2704,
      "total_loss": 0.7068823575973511,
      "weighted_orthogonal_loss": 0.019282197579741478
    },
    {
      "classification_loss": 0.64079350233078,
      "epoch": 8.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928556114435196,
      "orthogonal_weight": 0.1,
      "step": 2705,
      "total_loss": 0.6600790619850159,
      "weighted_orthogonal_loss": 0.01928556151688099
    },
    {
      "classification_loss": 0.6507749557495117,
      "epoch": 8.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.192860409617424,
      "orthogonal_weight": 0.1,
      "step": 2706,
      "total_loss": 0.6700609922409058,
      "weighted_orthogonal_loss": 0.01928604207932949
    },
    {
      "classification_loss": 0.6093868017196655,
      "epoch": 8.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19276244938373566,
      "orthogonal_weight": 0.1,
      "step": 2707,
      "total_loss": 0.6286630630493164,
      "weighted_orthogonal_loss": 0.019276244565844536
    },
    {
      "classification_loss": 0.6302871704101562,
      "epoch": 8.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19267228245735168,
      "orthogonal_weight": 0.1,
      "step": 2708,
      "total_loss": 0.6495543718338013,
      "weighted_orthogonal_loss": 0.019267229363322258
    },
    {
      "classification_loss": 0.5525270104408264,
      "epoch": 8.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19239524006843567,
      "orthogonal_weight": 0.1,
      "step": 2709,
      "total_loss": 0.5717665553092957,
      "weighted_orthogonal_loss": 0.019239524379372597
    },
    {
      "classification_loss": 0.7358033061027527,
      "epoch": 8.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19217509031295776,
      "orthogonal_weight": 0.1,
      "step": 2710,
      "total_loss": 0.755020797252655,
      "weighted_orthogonal_loss": 0.019217509776353836
    },
    {
      "classification_loss": 0.6719971895217896,
      "epoch": 8.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1920301765203476,
      "orthogonal_weight": 0.1,
      "step": 2711,
      "total_loss": 0.6912001967430115,
      "weighted_orthogonal_loss": 0.01920301839709282
    },
    {
      "classification_loss": 0.7721284627914429,
      "epoch": 8.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1918921023607254,
      "orthogonal_weight": 0.1,
      "step": 2712,
      "total_loss": 0.7913177013397217,
      "weighted_orthogonal_loss": 0.01918921060860157
    },
    {
      "classification_loss": 0.6770824790000916,
      "epoch": 8.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19178761541843414,
      "orthogonal_weight": 0.1,
      "step": 2713,
      "total_loss": 0.6962612271308899,
      "weighted_orthogonal_loss": 0.019178761169314384
    },
    {
      "classification_loss": 0.5736210942268372,
      "epoch": 8.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19173726439476013,
      "orthogonal_weight": 0.1,
      "step": 2714,
      "total_loss": 0.5927948355674744,
      "weighted_orthogonal_loss": 0.019173726439476013
    },
    {
      "classification_loss": 0.6075097322463989,
      "epoch": 8.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19164617359638214,
      "orthogonal_weight": 0.1,
      "step": 2715,
      "total_loss": 0.6266743540763855,
      "weighted_orthogonal_loss": 0.019164618104696274
    },
    {
      "classification_loss": 0.6349682211875916,
      "epoch": 8.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19153499603271484,
      "orthogonal_weight": 0.1,
      "step": 2716,
      "total_loss": 0.6541216969490051,
      "weighted_orthogonal_loss": 0.019153499975800514
    },
    {
      "classification_loss": 0.6332367658615112,
      "epoch": 8.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19139550626277924,
      "orthogonal_weight": 0.1,
      "step": 2717,
      "total_loss": 0.6523762941360474,
      "weighted_orthogonal_loss": 0.019139550626277924
    },
    {
      "classification_loss": 0.6416477560997009,
      "epoch": 8.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19131667912006378,
      "orthogonal_weight": 0.1,
      "step": 2718,
      "total_loss": 0.6607794165611267,
      "weighted_orthogonal_loss": 0.019131667912006378
    },
    {
      "classification_loss": 0.6835641860961914,
      "epoch": 8.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1913149058818817,
      "orthogonal_weight": 0.1,
      "step": 2719,
      "total_loss": 0.7026956677436829,
      "weighted_orthogonal_loss": 0.0191314909607172
    },
    {
      "classification_loss": 0.6598916053771973,
      "epoch": 8.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1913263499736786,
      "orthogonal_weight": 0.1,
      "step": 2720,
      "total_loss": 0.6790242195129395,
      "weighted_orthogonal_loss": 0.01913263462483883
    },
    {
      "classification_loss": 0.5966859459877014,
      "epoch": 8.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19136257469654083,
      "orthogonal_weight": 0.1,
      "step": 2721,
      "total_loss": 0.6158221960067749,
      "weighted_orthogonal_loss": 0.019136257469654083
    },
    {
      "classification_loss": 0.6019066572189331,
      "epoch": 8.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19145476818084717,
      "orthogonal_weight": 0.1,
      "step": 2722,
      "total_loss": 0.6210521459579468,
      "weighted_orthogonal_loss": 0.019145477563142776
    },
    {
      "classification_loss": 0.6508426070213318,
      "epoch": 8.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1915459781885147,
      "orthogonal_weight": 0.1,
      "step": 2723,
      "total_loss": 0.6699972152709961,
      "weighted_orthogonal_loss": 0.01915459893643856
    },
    {
      "classification_loss": 0.6781529188156128,
      "epoch": 8.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1915593445301056,
      "orthogonal_weight": 0.1,
      "step": 2724,
      "total_loss": 0.6973088383674622,
      "weighted_orthogonal_loss": 0.01915593445301056
    },
    {
      "classification_loss": 0.6375661492347717,
      "epoch": 8.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19155846536159515,
      "orthogonal_weight": 0.1,
      "step": 2725,
      "total_loss": 0.6567220091819763,
      "weighted_orthogonal_loss": 0.019155846908688545
    },
    {
      "classification_loss": 0.6688202023506165,
      "epoch": 8.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.191600501537323,
      "orthogonal_weight": 0.1,
      "step": 2726,
      "total_loss": 0.6879802346229553,
      "weighted_orthogonal_loss": 0.01916005089879036
    },
    {
      "classification_loss": 0.6237558126449585,
      "epoch": 8.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19160671532154083,
      "orthogonal_weight": 0.1,
      "step": 2727,
      "total_loss": 0.6429165005683899,
      "weighted_orthogonal_loss": 0.019160671159625053
    },
    {
      "classification_loss": 0.6463966965675354,
      "epoch": 8.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19162853062152863,
      "orthogonal_weight": 0.1,
      "step": 2728,
      "total_loss": 0.6655595302581787,
      "weighted_orthogonal_loss": 0.019162854179739952
    },
    {
      "classification_loss": 0.7107776999473572,
      "epoch": 8.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19156387448310852,
      "orthogonal_weight": 0.1,
      "step": 2729,
      "total_loss": 0.7299340963363647,
      "weighted_orthogonal_loss": 0.019156387075781822
    },
    {
      "classification_loss": 0.6895482540130615,
      "epoch": 8.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19144034385681152,
      "orthogonal_weight": 0.1,
      "step": 2730,
      "total_loss": 0.7086923122406006,
      "weighted_orthogonal_loss": 0.019144034013152122
    },
    {
      "classification_loss": 0.5760301351547241,
      "epoch": 8.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.191292405128479,
      "orthogonal_weight": 0.1,
      "step": 2731,
      "total_loss": 0.5951593518257141,
      "weighted_orthogonal_loss": 0.01912924088537693
    },
    {
      "classification_loss": 0.6157669425010681,
      "epoch": 8.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1912621408700943,
      "orthogonal_weight": 0.1,
      "step": 2732,
      "total_loss": 0.6348931789398193,
      "weighted_orthogonal_loss": 0.01912621408700943
    },
    {
      "classification_loss": 0.6112846732139587,
      "epoch": 8.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19129958748817444,
      "orthogonal_weight": 0.1,
      "step": 2733,
      "total_loss": 0.630414605140686,
      "weighted_orthogonal_loss": 0.019129959866404533
    },
    {
      "classification_loss": 0.5824934244155884,
      "epoch": 8.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19111528992652893,
      "orthogonal_weight": 0.1,
      "step": 2734,
      "total_loss": 0.6016049385070801,
      "weighted_orthogonal_loss": 0.019111528992652893
    },
    {
      "classification_loss": 0.6306483745574951,
      "epoch": 8.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1909920573234558,
      "orthogonal_weight": 0.1,
      "step": 2735,
      "total_loss": 0.6497476100921631,
      "weighted_orthogonal_loss": 0.01909920573234558
    },
    {
      "classification_loss": 0.5899578332901001,
      "epoch": 8.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19088372588157654,
      "orthogonal_weight": 0.1,
      "step": 2736,
      "total_loss": 0.609046220779419,
      "weighted_orthogonal_loss": 0.019088372588157654
    },
    {
      "classification_loss": 0.6409543752670288,
      "epoch": 8.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19080455601215363,
      "orthogonal_weight": 0.1,
      "step": 2737,
      "total_loss": 0.6600348353385925,
      "weighted_orthogonal_loss": 0.019080456346273422
    },
    {
      "classification_loss": 0.6863626837730408,
      "epoch": 8.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1907627433538437,
      "orthogonal_weight": 0.1,
      "step": 2738,
      "total_loss": 0.7054389715194702,
      "weighted_orthogonal_loss": 0.0190762747079134
    },
    {
      "classification_loss": 0.5731475949287415,
      "epoch": 8.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19071099162101746,
      "orthogonal_weight": 0.1,
      "step": 2739,
      "total_loss": 0.5922186970710754,
      "weighted_orthogonal_loss": 0.019071100279688835
    },
    {
      "classification_loss": 0.6532454490661621,
      "epoch": 8.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19062694907188416,
      "orthogonal_weight": 0.1,
      "step": 2740,
      "total_loss": 0.6723081469535828,
      "weighted_orthogonal_loss": 0.019062696024775505
    },
    {
      "classification_loss": 0.6062203645706177,
      "epoch": 8.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19055140018463135,
      "orthogonal_weight": 0.1,
      "step": 2741,
      "total_loss": 0.6252754926681519,
      "weighted_orthogonal_loss": 0.019055141136050224
    },
    {
      "classification_loss": 0.64870685338974,
      "epoch": 8.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1904776394367218,
      "orthogonal_weight": 0.1,
      "step": 2742,
      "total_loss": 0.667754590511322,
      "weighted_orthogonal_loss": 0.01904776506125927
    },
    {
      "classification_loss": 0.5883920788764954,
      "epoch": 8.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19029374420642853,
      "orthogonal_weight": 0.1,
      "step": 2743,
      "total_loss": 0.6074214577674866,
      "weighted_orthogonal_loss": 0.019029375165700912
    },
    {
      "classification_loss": 0.6054614782333374,
      "epoch": 8.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19010551273822784,
      "orthogonal_weight": 0.1,
      "step": 2744,
      "total_loss": 0.6244720220565796,
      "weighted_orthogonal_loss": 0.019010551273822784
    },
    {
      "classification_loss": 0.6910905838012695,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.7100831866264343,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.699056088924408,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.7180486917495728,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6795112490653992,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.698503851890564,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6987938284873962,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.717786431312561,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6927348971366882,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.711727499961853,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6886212229728699,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.7076138257980347,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6817452907562256,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.7007378935813904,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.7032584547996521,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.7222510576248169,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.528,
      "eval_f1": 0.5938037865748709,
      "eval_loss": 0.7105703353881836,
      "eval_precision": 0.640074211502783,
      "eval_recall": 0.5537720706260032,
      "eval_runtime": 6.1488,
      "eval_samples_per_second": 162.633,
      "eval_steps_per_second": 1.301,
      "step": 2745
    },
    {
      "classification_loss": 0.646277904510498,
      "epoch": 9.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18992574512958527,
      "orthogonal_weight": 0.1,
      "step": 2745,
      "total_loss": 0.6652705073356628,
      "weighted_orthogonal_loss": 0.018992574885487556
    },
    {
      "classification_loss": 0.6599420309066772,
      "epoch": 9.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1896773874759674,
      "orthogonal_weight": 0.1,
      "step": 2746,
      "total_loss": 0.6789097785949707,
      "weighted_orthogonal_loss": 0.01896773837506771
    },
    {
      "classification_loss": 0.6229367256164551,
      "epoch": 9.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18951648473739624,
      "orthogonal_weight": 0.1,
      "step": 2747,
      "total_loss": 0.6418883800506592,
      "weighted_orthogonal_loss": 0.018951648846268654
    },
    {
      "classification_loss": 0.6050189733505249,
      "epoch": 9.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18943117558956146,
      "orthogonal_weight": 0.1,
      "step": 2748,
      "total_loss": 0.6239621043205261,
      "weighted_orthogonal_loss": 0.018943117931485176
    },
    {
      "classification_loss": 0.6540296673774719,
      "epoch": 9.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18946103751659393,
      "orthogonal_weight": 0.1,
      "step": 2749,
      "total_loss": 0.6729757785797119,
      "weighted_orthogonal_loss": 0.018946103751659393
    },
    {
      "classification_loss": 0.6594157814979553,
      "epoch": 9.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18949706852436066,
      "orthogonal_weight": 0.1,
      "step": 2750,
      "total_loss": 0.6783654689788818,
      "weighted_orthogonal_loss": 0.018949707970023155
    },
    {
      "classification_loss": 0.6885918378829956,
      "epoch": 9.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18958480656147003,
      "orthogonal_weight": 0.1,
      "step": 2751,
      "total_loss": 0.7075503468513489,
      "weighted_orthogonal_loss": 0.018958481028676033
    },
    {
      "classification_loss": 0.6476168036460876,
      "epoch": 9.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18963713943958282,
      "orthogonal_weight": 0.1,
      "step": 2752,
      "total_loss": 0.6665804982185364,
      "weighted_orthogonal_loss": 0.018963715061545372
    },
    {
      "classification_loss": 0.5309817790985107,
      "epoch": 9.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.18970993161201477,
      "orthogonal_weight": 0.1,
      "step": 2753,
      "total_loss": 0.5499527454376221,
      "weighted_orthogonal_loss": 0.018970994278788567
    },
    {
      "classification_loss": 0.6609556078910828,
      "epoch": 9.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1897794008255005,
      "orthogonal_weight": 0.1,
      "step": 2754,
      "total_loss": 0.6799335479736328,
      "weighted_orthogonal_loss": 0.01897794008255005
    },
    {
      "classification_loss": 0.6499209403991699,
      "epoch": 9.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1898813247680664,
      "orthogonal_weight": 0.1,
      "step": 2755,
      "total_loss": 0.6689090728759766,
      "weighted_orthogonal_loss": 0.01898813247680664
    },
    {
      "classification_loss": 0.5463072061538696,
      "epoch": 9.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1899745762348175,
      "orthogonal_weight": 0.1,
      "step": 2756,
      "total_loss": 0.5653046369552612,
      "weighted_orthogonal_loss": 0.01899745874106884
    },
    {
      "classification_loss": 0.6528555154800415,
      "epoch": 9.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19022224843502045,
      "orthogonal_weight": 0.1,
      "step": 2757,
      "total_loss": 0.6718777418136597,
      "weighted_orthogonal_loss": 0.019022224470973015
    },
    {
      "classification_loss": 0.7280958890914917,
      "epoch": 9.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19051764905452728,
      "orthogonal_weight": 0.1,
      "step": 2758,
      "total_loss": 0.7471476793289185,
      "weighted_orthogonal_loss": 0.019051766023039818
    },
    {
      "classification_loss": 0.6199318766593933,
      "epoch": 9.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1908143311738968,
      "orthogonal_weight": 0.1,
      "step": 2759,
      "total_loss": 0.6390132904052734,
      "weighted_orthogonal_loss": 0.01908143423497677
    },
    {
      "classification_loss": 0.5880746245384216,
      "epoch": 9.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19110840559005737,
      "orthogonal_weight": 0.1,
      "step": 2760,
      "total_loss": 0.6071854829788208,
      "weighted_orthogonal_loss": 0.019110841676592827
    },
    {
      "classification_loss": 0.5981002449989319,
      "epoch": 9.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19140177965164185,
      "orthogonal_weight": 0.1,
      "step": 2761,
      "total_loss": 0.6172404289245605,
      "weighted_orthogonal_loss": 0.019140178337693214
    },
    {
      "classification_loss": 0.6395959258079529,
      "epoch": 9.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19173353910446167,
      "orthogonal_weight": 0.1,
      "step": 2762,
      "total_loss": 0.6587692499160767,
      "weighted_orthogonal_loss": 0.019173353910446167
    },
    {
      "classification_loss": 0.6235832571983337,
      "epoch": 9.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19209343194961548,
      "orthogonal_weight": 0.1,
      "step": 2763,
      "total_loss": 0.6427925825119019,
      "weighted_orthogonal_loss": 0.019209343940019608
    },
    {
      "classification_loss": 0.5747895240783691,
      "epoch": 9.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19238720834255219,
      "orthogonal_weight": 0.1,
      "step": 2764,
      "total_loss": 0.5940282344818115,
      "weighted_orthogonal_loss": 0.019238721579313278
    },
    {
      "classification_loss": 0.6207389831542969,
      "epoch": 9.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1926768571138382,
      "orthogonal_weight": 0.1,
      "step": 2765,
      "total_loss": 0.6400066614151001,
      "weighted_orthogonal_loss": 0.01926768571138382
    },
    {
      "classification_loss": 0.5834245681762695,
      "epoch": 9.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1929837018251419,
      "orthogonal_weight": 0.1,
      "step": 2766,
      "total_loss": 0.6027229428291321,
      "weighted_orthogonal_loss": 0.01929837092757225
    },
    {
      "classification_loss": 0.6028409600257874,
      "epoch": 9.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19329401850700378,
      "orthogonal_weight": 0.1,
      "step": 2767,
      "total_loss": 0.6221703886985779,
      "weighted_orthogonal_loss": 0.019329402595758438
    },
    {
      "classification_loss": 0.6377720236778259,
      "epoch": 9.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1936093419790268,
      "orthogonal_weight": 0.1,
      "step": 2768,
      "total_loss": 0.6571329832077026,
      "weighted_orthogonal_loss": 0.01936093531548977
    },
    {
      "classification_loss": 0.6019702553749084,
      "epoch": 9.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19388695061206818,
      "orthogonal_weight": 0.1,
      "step": 2769,
      "total_loss": 0.6213589310646057,
      "weighted_orthogonal_loss": 0.019388696178793907
    },
    {
      "classification_loss": 0.6494724154472351,
      "epoch": 9.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1941395252943039,
      "orthogonal_weight": 0.1,
      "step": 2770,
      "total_loss": 0.6688863635063171,
      "weighted_orthogonal_loss": 0.01941395364701748
    },
    {
      "classification_loss": 0.5757189393043518,
      "epoch": 9.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19437749683856964,
      "orthogonal_weight": 0.1,
      "step": 2771,
      "total_loss": 0.5951566696166992,
      "weighted_orthogonal_loss": 0.019437750801444054
    },
    {
      "classification_loss": 0.6254979968070984,
      "epoch": 9.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19463729858398438,
      "orthogonal_weight": 0.1,
      "step": 2772,
      "total_loss": 0.6449617147445679,
      "weighted_orthogonal_loss": 0.019463730975985527
    },
    {
      "classification_loss": 0.6714306473731995,
      "epoch": 9.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19483907520771027,
      "orthogonal_weight": 0.1,
      "step": 2773,
      "total_loss": 0.6909145712852478,
      "weighted_orthogonal_loss": 0.019483907148241997
    },
    {
      "classification_loss": 0.7106853127479553,
      "epoch": 9.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19501197338104248,
      "orthogonal_weight": 0.1,
      "step": 2774,
      "total_loss": 0.7301865220069885,
      "weighted_orthogonal_loss": 0.019501198083162308
    },
    {
      "classification_loss": 0.6541979908943176,
      "epoch": 9.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19513961672782898,
      "orthogonal_weight": 0.1,
      "step": 2775,
      "total_loss": 0.6737119555473328,
      "weighted_orthogonal_loss": 0.019513962790369987
    },
    {
      "classification_loss": 0.5773006081581116,
      "epoch": 9.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19521872699260712,
      "orthogonal_weight": 0.1,
      "step": 2776,
      "total_loss": 0.5968225002288818,
      "weighted_orthogonal_loss": 0.01952187344431877
    },
    {
      "classification_loss": 0.6534721255302429,
      "epoch": 9.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19527596235275269,
      "orthogonal_weight": 0.1,
      "step": 2777,
      "total_loss": 0.6729997396469116,
      "weighted_orthogonal_loss": 0.019527597352862358
    },
    {
      "classification_loss": 0.5707012414932251,
      "epoch": 9.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19530241191387177,
      "orthogonal_weight": 0.1,
      "step": 2778,
      "total_loss": 0.5902314782142639,
      "weighted_orthogonal_loss": 0.019530242308974266
    },
    {
      "classification_loss": 0.6945138573646545,
      "epoch": 9.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953544169664383,
      "orthogonal_weight": 0.1,
      "step": 2779,
      "total_loss": 0.7140492796897888,
      "weighted_orthogonal_loss": 0.01953544281423092
    },
    {
      "classification_loss": 0.5993780493736267,
      "epoch": 9.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953393965959549,
      "orthogonal_weight": 0.1,
      "step": 2780,
      "total_loss": 0.6189119815826416,
      "weighted_orthogonal_loss": 0.01953393965959549
    },
    {
      "classification_loss": 0.6012328863143921,
      "epoch": 9.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19535700976848602,
      "orthogonal_weight": 0.1,
      "step": 2781,
      "total_loss": 0.6207686066627502,
      "weighted_orthogonal_loss": 0.019535701721906662
    },
    {
      "classification_loss": 0.7311568260192871,
      "epoch": 9.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19542275369167328,
      "orthogonal_weight": 0.1,
      "step": 2782,
      "total_loss": 0.7506991028785706,
      "weighted_orthogonal_loss": 0.019542274996638298
    },
    {
      "classification_loss": 0.5834127068519592,
      "epoch": 9.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19545359909534454,
      "orthogonal_weight": 0.1,
      "step": 2783,
      "total_loss": 0.602958083152771,
      "weighted_orthogonal_loss": 0.019545359537005424
    },
    {
      "classification_loss": 0.6184400320053101,
      "epoch": 9.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1955447643995285,
      "orthogonal_weight": 0.1,
      "step": 2784,
      "total_loss": 0.6379945278167725,
      "weighted_orthogonal_loss": 0.01955447718501091
    },
    {
      "classification_loss": 0.5975165367126465,
      "epoch": 9.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19562281668186188,
      "orthogonal_weight": 0.1,
      "step": 2785,
      "total_loss": 0.6170788407325745,
      "weighted_orthogonal_loss": 0.019562281668186188
    },
    {
      "classification_loss": 0.6272020936012268,
      "epoch": 9.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1956014335155487,
      "orthogonal_weight": 0.1,
      "step": 2786,
      "total_loss": 0.6467622518539429,
      "weighted_orthogonal_loss": 0.01956014335155487
    },
    {
      "classification_loss": 0.7225282192230225,
      "epoch": 9.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1951437145471573,
      "orthogonal_weight": 0.1,
      "step": 2787,
      "total_loss": 0.742042601108551,
      "weighted_orthogonal_loss": 0.01951437257230282
    },
    {
      "classification_loss": 0.6125452518463135,
      "epoch": 9.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1944725513458252,
      "orthogonal_weight": 0.1,
      "step": 2788,
      "total_loss": 0.631992518901825,
      "weighted_orthogonal_loss": 0.01944725587964058
    },
    {
      "classification_loss": 0.6359217166900635,
      "epoch": 9.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19390968978405,
      "orthogonal_weight": 0.1,
      "step": 2789,
      "total_loss": 0.6553126573562622,
      "weighted_orthogonal_loss": 0.01939096860587597
    },
    {
      "classification_loss": 0.7014561891555786,
      "epoch": 9.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19344662129878998,
      "orthogonal_weight": 0.1,
      "step": 2790,
      "total_loss": 0.7208008766174316,
      "weighted_orthogonal_loss": 0.019344663247466087
    },
    {
      "classification_loss": 0.6273686289787292,
      "epoch": 9.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19310297071933746,
      "orthogonal_weight": 0.1,
      "step": 2791,
      "total_loss": 0.6466789245605469,
      "weighted_orthogonal_loss": 0.019310297444462776
    },
    {
      "classification_loss": 0.575960636138916,
      "epoch": 9.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928333342075348,
      "orthogonal_weight": 0.1,
      "step": 2792,
      "total_loss": 0.5952439904212952,
      "weighted_orthogonal_loss": 0.01928333379328251
    },
    {
      "classification_loss": 0.5974640250205994,
      "epoch": 9.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19264808297157288,
      "orthogonal_weight": 0.1,
      "step": 2793,
      "total_loss": 0.6167288422584534,
      "weighted_orthogonal_loss": 0.019264807924628258
    },
    {
      "classification_loss": 0.6077924966812134,
      "epoch": 9.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19248534739017487,
      "orthogonal_weight": 0.1,
      "step": 2794,
      "total_loss": 0.6270410418510437,
      "weighted_orthogonal_loss": 0.019248535856604576
    },
    {
      "classification_loss": 0.5752137899398804,
      "epoch": 9.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1923336535692215,
      "orthogonal_weight": 0.1,
      "step": 2795,
      "total_loss": 0.594447135925293,
      "weighted_orthogonal_loss": 0.01923336647450924
    },
    {
      "classification_loss": 0.6074704527854919,
      "epoch": 9.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19219185411930084,
      "orthogonal_weight": 0.1,
      "step": 2796,
      "total_loss": 0.626689612865448,
      "weighted_orthogonal_loss": 0.019219186156988144
    },
    {
      "classification_loss": 0.6690681576728821,
      "epoch": 9.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19211627542972565,
      "orthogonal_weight": 0.1,
      "step": 2797,
      "total_loss": 0.6882798075675964,
      "weighted_orthogonal_loss": 0.019211627542972565
    },
    {
      "classification_loss": 0.6371396780014038,
      "epoch": 9.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1920313537120819,
      "orthogonal_weight": 0.1,
      "step": 2798,
      "total_loss": 0.6563428044319153,
      "weighted_orthogonal_loss": 0.01920313574373722
    },
    {
      "classification_loss": 0.6615257859230042,
      "epoch": 9.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19193266332149506,
      "orthogonal_weight": 0.1,
      "step": 2799,
      "total_loss": 0.6807190775871277,
      "weighted_orthogonal_loss": 0.019193267449736595
    },
    {
      "epoch": 9.180327868852459,
      "grad_norm": 24.821514129638672,
      "learning_rate": 0.00011003333333333334,
      "loss": 0.6512,
      "step": 2800
    },
    {
      "classification_loss": 0.5596503615379333,
      "epoch": 9.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19187316298484802,
      "orthogonal_weight": 0.1,
      "step": 2800,
      "total_loss": 0.5788376927375793,
      "weighted_orthogonal_loss": 0.019187316298484802
    },
    {
      "classification_loss": 0.5664663314819336,
      "epoch": 9.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19184471666812897,
      "orthogonal_weight": 0.1,
      "step": 2801,
      "total_loss": 0.5856508016586304,
      "weighted_orthogonal_loss": 0.019184472039341927
    },
    {
      "classification_loss": 0.5975473523139954,
      "epoch": 9.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19187243282794952,
      "orthogonal_weight": 0.1,
      "step": 2802,
      "total_loss": 0.6167346239089966,
      "weighted_orthogonal_loss": 0.019187243655323982
    },
    {
      "classification_loss": 0.7598612904548645,
      "epoch": 9.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19185152649879456,
      "orthogonal_weight": 0.1,
      "step": 2803,
      "total_loss": 0.7790464162826538,
      "weighted_orthogonal_loss": 0.019185153767466545
    },
    {
      "classification_loss": 0.6597152352333069,
      "epoch": 9.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19163678586483002,
      "orthogonal_weight": 0.1,
      "step": 2804,
      "total_loss": 0.678878903388977,
      "weighted_orthogonal_loss": 0.01916367933154106
    },
    {
      "classification_loss": 0.5555998682975769,
      "epoch": 9.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19152295589447021,
      "orthogonal_weight": 0.1,
      "step": 2805,
      "total_loss": 0.574752151966095,
      "weighted_orthogonal_loss": 0.01915229670703411
    },
    {
      "classification_loss": 0.6696200370788574,
      "epoch": 9.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19150079786777496,
      "orthogonal_weight": 0.1,
      "step": 2806,
      "total_loss": 0.6887701153755188,
      "weighted_orthogonal_loss": 0.019150080159306526
    },
    {
      "classification_loss": 0.5616486668586731,
      "epoch": 9.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19148460030555725,
      "orthogonal_weight": 0.1,
      "step": 2807,
      "total_loss": 0.5807971358299255,
      "weighted_orthogonal_loss": 0.019148459658026695
    },
    {
      "classification_loss": 0.6514676809310913,
      "epoch": 9.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19158464670181274,
      "orthogonal_weight": 0.1,
      "step": 2808,
      "total_loss": 0.670626163482666,
      "weighted_orthogonal_loss": 0.019158465787768364
    },
    {
      "classification_loss": 0.6385848522186279,
      "epoch": 9.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19165530800819397,
      "orthogonal_weight": 0.1,
      "step": 2809,
      "total_loss": 0.6577503681182861,
      "weighted_orthogonal_loss": 0.019165530800819397
    },
    {
      "classification_loss": 0.5900065898895264,
      "epoch": 9.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19166557490825653,
      "orthogonal_weight": 0.1,
      "step": 2810,
      "total_loss": 0.6091731190681458,
      "weighted_orthogonal_loss": 0.019166557118296623
    },
    {
      "classification_loss": 0.6227582693099976,
      "epoch": 9.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19159932434558868,
      "orthogonal_weight": 0.1,
      "step": 2811,
      "total_loss": 0.6419181823730469,
      "weighted_orthogonal_loss": 0.019159933552145958
    },
    {
      "classification_loss": 0.6235426664352417,
      "epoch": 9.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19150276482105255,
      "orthogonal_weight": 0.1,
      "step": 2812,
      "total_loss": 0.6426929235458374,
      "weighted_orthogonal_loss": 0.019150277599692345
    },
    {
      "classification_loss": 0.6298926472663879,
      "epoch": 9.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1914346069097519,
      "orthogonal_weight": 0.1,
      "step": 2813,
      "total_loss": 0.6490361094474792,
      "weighted_orthogonal_loss": 0.01914346031844616
    },
    {
      "classification_loss": 0.6117061376571655,
      "epoch": 9.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1913326233625412,
      "orthogonal_weight": 0.1,
      "step": 2814,
      "total_loss": 0.6308394074440002,
      "weighted_orthogonal_loss": 0.01913326233625412
    },
    {
      "classification_loss": 0.6114575266838074,
      "epoch": 9.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19113633036613464,
      "orthogonal_weight": 0.1,
      "step": 2815,
      "total_loss": 0.630571186542511,
      "weighted_orthogonal_loss": 0.019113633781671524
    },
    {
      "classification_loss": 0.657288134098053,
      "epoch": 9.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19092980027198792,
      "orthogonal_weight": 0.1,
      "step": 2816,
      "total_loss": 0.6763811111450195,
      "weighted_orthogonal_loss": 0.01909298077225685
    },
    {
      "classification_loss": 0.6289913058280945,
      "epoch": 9.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19071513414382935,
      "orthogonal_weight": 0.1,
      "step": 2817,
      "total_loss": 0.6480628252029419,
      "weighted_orthogonal_loss": 0.019071513786911964
    },
    {
      "classification_loss": 0.64680016040802,
      "epoch": 9.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19054335355758667,
      "orthogonal_weight": 0.1,
      "step": 2818,
      "total_loss": 0.6658545136451721,
      "weighted_orthogonal_loss": 0.019054336473345757
    },
    {
      "classification_loss": 0.6276671290397644,
      "epoch": 9.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19039614498615265,
      "orthogonal_weight": 0.1,
      "step": 2819,
      "total_loss": 0.646706759929657,
      "weighted_orthogonal_loss": 0.019039614126086235
    },
    {
      "classification_loss": 0.6200979351997375,
      "epoch": 9.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19029195606708527,
      "orthogonal_weight": 0.1,
      "step": 2820,
      "total_loss": 0.6391271352767944,
      "weighted_orthogonal_loss": 0.019029196351766586
    },
    {
      "classification_loss": 0.6556540131568909,
      "epoch": 9.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19021184742450714,
      "orthogonal_weight": 0.1,
      "step": 2821,
      "total_loss": 0.6746752262115479,
      "weighted_orthogonal_loss": 0.019021185114979744
    },
    {
      "classification_loss": 0.6746930480003357,
      "epoch": 9.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19014424085617065,
      "orthogonal_weight": 0.1,
      "step": 2822,
      "total_loss": 0.6937074661254883,
      "weighted_orthogonal_loss": 0.019014423713088036
    },
    {
      "classification_loss": 0.6790087223052979,
      "epoch": 9.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1901119351387024,
      "orthogonal_weight": 0.1,
      "step": 2823,
      "total_loss": 0.6980199217796326,
      "weighted_orthogonal_loss": 0.01901119388639927
    },
    {
      "classification_loss": 0.648827075958252,
      "epoch": 9.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19012726843357086,
      "orthogonal_weight": 0.1,
      "step": 2824,
      "total_loss": 0.6678398251533508,
      "weighted_orthogonal_loss": 0.019012726843357086
    },
    {
      "classification_loss": 0.6910158395767212,
      "epoch": 9.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19016650319099426,
      "orthogonal_weight": 0.1,
      "step": 2825,
      "total_loss": 0.7100324630737305,
      "weighted_orthogonal_loss": 0.019016651436686516
    },
    {
      "classification_loss": 0.5656795501708984,
      "epoch": 9.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19017954170703888,
      "orthogonal_weight": 0.1,
      "step": 2826,
      "total_loss": 0.5846974849700928,
      "weighted_orthogonal_loss": 0.019017955288290977
    },
    {
      "classification_loss": 0.6064428091049194,
      "epoch": 9.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19023995101451874,
      "orthogonal_weight": 0.1,
      "step": 2827,
      "total_loss": 0.6254668235778809,
      "weighted_orthogonal_loss": 0.019023995846509933
    },
    {
      "classification_loss": 0.6950050592422485,
      "epoch": 9.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19029736518859863,
      "orthogonal_weight": 0.1,
      "step": 2828,
      "total_loss": 0.7140347957611084,
      "weighted_orthogonal_loss": 0.019029736518859863
    },
    {
      "classification_loss": 0.6238461136817932,
      "epoch": 9.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1903362274169922,
      "orthogonal_weight": 0.1,
      "step": 2829,
      "total_loss": 0.6428797245025635,
      "weighted_orthogonal_loss": 0.01903362385928631
    },
    {
      "classification_loss": 0.6914702653884888,
      "epoch": 9.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19064205884933472,
      "orthogonal_weight": 0.1,
      "step": 2830,
      "total_loss": 0.7105344533920288,
      "weighted_orthogonal_loss": 0.01906420662999153
    },
    {
      "classification_loss": 0.6301862001419067,
      "epoch": 9.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1909058690071106,
      "orthogonal_weight": 0.1,
      "step": 2831,
      "total_loss": 0.6492767930030823,
      "weighted_orthogonal_loss": 0.01909058727324009
    },
    {
      "classification_loss": 0.6826000809669495,
      "epoch": 9.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19118095934391022,
      "orthogonal_weight": 0.1,
      "step": 2832,
      "total_loss": 0.7017181515693665,
      "weighted_orthogonal_loss": 0.01911809667944908
    },
    {
      "classification_loss": 0.5571783185005188,
      "epoch": 9.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19154278934001923,
      "orthogonal_weight": 0.1,
      "step": 2833,
      "total_loss": 0.5763325691223145,
      "weighted_orthogonal_loss": 0.019154278561472893
    },
    {
      "classification_loss": 0.6142059564590454,
      "epoch": 9.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1918381303548813,
      "orthogonal_weight": 0.1,
      "step": 2834,
      "total_loss": 0.6333897709846497,
      "weighted_orthogonal_loss": 0.0191838126629591
    },
    {
      "classification_loss": 0.6588463187217712,
      "epoch": 9.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19211162626743317,
      "orthogonal_weight": 0.1,
      "step": 2835,
      "total_loss": 0.6780574917793274,
      "weighted_orthogonal_loss": 0.019211163744330406
    },
    {
      "classification_loss": 0.5624020099639893,
      "epoch": 9.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19230340421199799,
      "orthogonal_weight": 0.1,
      "step": 2836,
      "total_loss": 0.5816323757171631,
      "weighted_orthogonal_loss": 0.019230341538786888
    },
    {
      "classification_loss": 0.6731675267219543,
      "epoch": 9.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925942450761795,
      "orthogonal_weight": 0.1,
      "step": 2837,
      "total_loss": 0.6924269795417786,
      "weighted_orthogonal_loss": 0.01925942488014698
    },
    {
      "classification_loss": 0.5302762389183044,
      "epoch": 9.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1928146928548813,
      "orthogonal_weight": 0.1,
      "step": 2838,
      "total_loss": 0.5495576858520508,
      "weighted_orthogonal_loss": 0.01928146928548813
    },
    {
      "classification_loss": 0.5905643105506897,
      "epoch": 9.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19301578402519226,
      "orthogonal_weight": 0.1,
      "step": 2839,
      "total_loss": 0.6098659038543701,
      "weighted_orthogonal_loss": 0.019301578402519226
    },
    {
      "classification_loss": 0.6178613305091858,
      "epoch": 9.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19316455721855164,
      "orthogonal_weight": 0.1,
      "step": 2840,
      "total_loss": 0.6371777653694153,
      "weighted_orthogonal_loss": 0.019316455349326134
    },
    {
      "classification_loss": 0.6424993872642517,
      "epoch": 9.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1932913213968277,
      "orthogonal_weight": 0.1,
      "step": 2841,
      "total_loss": 0.6618285179138184,
      "weighted_orthogonal_loss": 0.0193291325122118
    },
    {
      "classification_loss": 0.683708906173706,
      "epoch": 9.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19341498613357544,
      "orthogonal_weight": 0.1,
      "step": 2842,
      "total_loss": 0.7030503749847412,
      "weighted_orthogonal_loss": 0.019341498613357544
    },
    {
      "classification_loss": 0.6869034171104431,
      "epoch": 9.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19352693855762482,
      "orthogonal_weight": 0.1,
      "step": 2843,
      "total_loss": 0.706256091594696,
      "weighted_orthogonal_loss": 0.01935269497334957
    },
    {
      "classification_loss": 0.6609945893287659,
      "epoch": 9.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19359658658504486,
      "orthogonal_weight": 0.1,
      "step": 2844,
      "total_loss": 0.6803542375564575,
      "weighted_orthogonal_loss": 0.019359659403562546
    },
    {
      "classification_loss": 0.662425696849823,
      "epoch": 9.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19356146454811096,
      "orthogonal_weight": 0.1,
      "step": 2845,
      "total_loss": 0.6817818284034729,
      "weighted_orthogonal_loss": 0.019356146454811096
    },
    {
      "classification_loss": 0.6611422300338745,
      "epoch": 9.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19349318742752075,
      "orthogonal_weight": 0.1,
      "step": 2846,
      "total_loss": 0.68049156665802,
      "weighted_orthogonal_loss": 0.019349319860339165
    },
    {
      "classification_loss": 0.680874764919281,
      "epoch": 9.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19333899021148682,
      "orthogonal_weight": 0.1,
      "step": 2847,
      "total_loss": 0.7002086639404297,
      "weighted_orthogonal_loss": 0.01933389902114868
    },
    {
      "classification_loss": 0.6536266803741455,
      "epoch": 9.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19317227602005005,
      "orthogonal_weight": 0.1,
      "step": 2848,
      "total_loss": 0.6729438900947571,
      "weighted_orthogonal_loss": 0.019317228347063065
    },
    {
      "classification_loss": 0.6400918364524841,
      "epoch": 9.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1929991990327835,
      "orthogonal_weight": 0.1,
      "step": 2849,
      "total_loss": 0.6593917608261108,
      "weighted_orthogonal_loss": 0.01929992064833641
    },
    {
      "classification_loss": 0.6866549849510193,
      "epoch": 9.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19289013743400574,
      "orthogonal_weight": 0.1,
      "step": 2850,
      "total_loss": 0.7059440016746521,
      "weighted_orthogonal_loss": 0.019289014860987663
    },
    {
      "classification_loss": 0.6296328902244568,
      "epoch": 9.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19279538094997406,
      "orthogonal_weight": 0.1,
      "step": 2851,
      "total_loss": 0.6489124298095703,
      "weighted_orthogonal_loss": 0.019279537722468376
    },
    {
      "classification_loss": 0.6731929183006287,
      "epoch": 9.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1927369385957718,
      "orthogonal_weight": 0.1,
      "step": 2852,
      "total_loss": 0.6924666166305542,
      "weighted_orthogonal_loss": 0.01927369460463524
    },
    {
      "classification_loss": 0.5977701544761658,
      "epoch": 9.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19256645441055298,
      "orthogonal_weight": 0.1,
      "step": 2853,
      "total_loss": 0.6170268058776855,
      "weighted_orthogonal_loss": 0.019256645813584328
    },
    {
      "classification_loss": 0.567943274974823,
      "epoch": 9.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19242797791957855,
      "orthogonal_weight": 0.1,
      "step": 2854,
      "total_loss": 0.5871860980987549,
      "weighted_orthogonal_loss": 0.019242798909544945
    },
    {
      "classification_loss": 0.6402240991592407,
      "epoch": 9.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19238147139549255,
      "orthogonal_weight": 0.1,
      "step": 2855,
      "total_loss": 0.6594622731208801,
      "weighted_orthogonal_loss": 0.019238147884607315
    },
    {
      "classification_loss": 0.6920019388198853,
      "epoch": 9.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19230812788009644,
      "orthogonal_weight": 0.1,
      "step": 2856,
      "total_loss": 0.7112327814102173,
      "weighted_orthogonal_loss": 0.019230812788009644
    },
    {
      "classification_loss": 0.6339433789253235,
      "epoch": 9.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19230619072914124,
      "orthogonal_weight": 0.1,
      "step": 2857,
      "total_loss": 0.6531739830970764,
      "weighted_orthogonal_loss": 0.019230619072914124
    },
    {
      "classification_loss": 0.66779625415802,
      "epoch": 9.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19219553470611572,
      "orthogonal_weight": 0.1,
      "step": 2858,
      "total_loss": 0.6870158314704895,
      "weighted_orthogonal_loss": 0.019219553098082542
    },
    {
      "classification_loss": 0.6029803156852722,
      "epoch": 9.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19208988547325134,
      "orthogonal_weight": 0.1,
      "step": 2859,
      "total_loss": 0.6221892833709717,
      "weighted_orthogonal_loss": 0.019208988174796104
    },
    {
      "classification_loss": 0.5716549158096313,
      "epoch": 9.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19198548793792725,
      "orthogonal_weight": 0.1,
      "step": 2860,
      "total_loss": 0.5908534526824951,
      "weighted_orthogonal_loss": 0.019198549911379814
    },
    {
      "classification_loss": 0.6082595586776733,
      "epoch": 9.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19196178019046783,
      "orthogonal_weight": 0.1,
      "step": 2861,
      "total_loss": 0.6274557113647461,
      "weighted_orthogonal_loss": 0.019196178764104843
    },
    {
      "classification_loss": 0.6383082270622253,
      "epoch": 9.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1919601410627365,
      "orthogonal_weight": 0.1,
      "step": 2862,
      "total_loss": 0.6575042605400085,
      "weighted_orthogonal_loss": 0.01919601485133171
    },
    {
      "classification_loss": 0.646780788898468,
      "epoch": 9.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19197635352611542,
      "orthogonal_weight": 0.1,
      "step": 2863,
      "total_loss": 0.6659784317016602,
      "weighted_orthogonal_loss": 0.019197635352611542
    },
    {
      "classification_loss": 0.699079692363739,
      "epoch": 9.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19195786118507385,
      "orthogonal_weight": 0.1,
      "step": 2864,
      "total_loss": 0.7182754874229431,
      "weighted_orthogonal_loss": 0.019195785745978355
    },
    {
      "classification_loss": 0.6810476779937744,
      "epoch": 9.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19197407364845276,
      "orthogonal_weight": 0.1,
      "step": 2865,
      "total_loss": 0.7002450823783875,
      "weighted_orthogonal_loss": 0.019197408109903336
    },
    {
      "classification_loss": 0.6020922064781189,
      "epoch": 9.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19203044474124908,
      "orthogonal_weight": 0.1,
      "step": 2866,
      "total_loss": 0.6212952733039856,
      "weighted_orthogonal_loss": 0.01920304447412491
    },
    {
      "classification_loss": 0.7144716382026672,
      "epoch": 9.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1921057105064392,
      "orthogonal_weight": 0.1,
      "step": 2867,
      "total_loss": 0.7336822152137756,
      "weighted_orthogonal_loss": 0.01921057142317295
    },
    {
      "classification_loss": 0.5941252112388611,
      "epoch": 9.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1921425759792328,
      "orthogonal_weight": 0.1,
      "step": 2868,
      "total_loss": 0.6133394837379456,
      "weighted_orthogonal_loss": 0.01921425759792328
    },
    {
      "classification_loss": 0.6644353270530701,
      "epoch": 9.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19223760068416595,
      "orthogonal_weight": 0.1,
      "step": 2869,
      "total_loss": 0.6836590766906738,
      "weighted_orthogonal_loss": 0.019223760813474655
    },
    {
      "classification_loss": 0.6325751543045044,
      "epoch": 9.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19232337176799774,
      "orthogonal_weight": 0.1,
      "step": 2870,
      "total_loss": 0.6518074870109558,
      "weighted_orthogonal_loss": 0.019232338294386864
    },
    {
      "classification_loss": 0.6223094463348389,
      "epoch": 9.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19242744147777557,
      "orthogonal_weight": 0.1,
      "step": 2871,
      "total_loss": 0.641552209854126,
      "weighted_orthogonal_loss": 0.019242744892835617
    },
    {
      "classification_loss": 0.5835202932357788,
      "epoch": 9.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925080567598343,
      "orthogonal_weight": 0.1,
      "step": 2872,
      "total_loss": 0.6027711033821106,
      "weighted_orthogonal_loss": 0.01925080642104149
    },
    {
      "classification_loss": 0.5986247658729553,
      "epoch": 9.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1925944834947586,
      "orthogonal_weight": 0.1,
      "step": 2873,
      "total_loss": 0.6178842186927795,
      "weighted_orthogonal_loss": 0.01925944909453392
    },
    {
      "classification_loss": 0.5884696245193481,
      "epoch": 9.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19264517724514008,
      "orthogonal_weight": 0.1,
      "step": 2874,
      "total_loss": 0.6077341437339783,
      "weighted_orthogonal_loss": 0.019264517351984978
    },
    {
      "classification_loss": 0.6113881468772888,
      "epoch": 9.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19262732565402985,
      "orthogonal_weight": 0.1,
      "step": 2875,
      "total_loss": 0.6306508779525757,
      "weighted_orthogonal_loss": 0.019262732937932014
    },
    {
      "classification_loss": 0.5962262153625488,
      "epoch": 9.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19248250126838684,
      "orthogonal_weight": 0.1,
      "step": 2876,
      "total_loss": 0.6154744625091553,
      "weighted_orthogonal_loss": 0.019248250871896744
    },
    {
      "classification_loss": 0.6721013784408569,
      "epoch": 9.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19233974814414978,
      "orthogonal_weight": 0.1,
      "step": 2877,
      "total_loss": 0.6913353800773621,
      "weighted_orthogonal_loss": 0.019233975559473038
    },
    {
      "classification_loss": 0.6148412823677063,
      "epoch": 9.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19215641915798187,
      "orthogonal_weight": 0.1,
      "step": 2878,
      "total_loss": 0.6340569257736206,
      "weighted_orthogonal_loss": 0.019215641543269157
    },
    {
      "classification_loss": 0.5974910259246826,
      "epoch": 9.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1920248568058014,
      "orthogonal_weight": 0.1,
      "step": 2879,
      "total_loss": 0.6166934967041016,
      "weighted_orthogonal_loss": 0.01920248568058014
    },
    {
      "classification_loss": 0.6877079606056213,
      "epoch": 9.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19194401800632477,
      "orthogonal_weight": 0.1,
      "step": 2880,
      "total_loss": 0.7069023847579956,
      "weighted_orthogonal_loss": 0.019194401800632477
    },
    {
      "classification_loss": 0.5968096852302551,
      "epoch": 9.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19185854494571686,
      "orthogonal_weight": 0.1,
      "step": 2881,
      "total_loss": 0.6159955263137817,
      "weighted_orthogonal_loss": 0.019185854122042656
    },
    {
      "classification_loss": 0.6630457043647766,
      "epoch": 9.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19176523387432098,
      "orthogonal_weight": 0.1,
      "step": 2882,
      "total_loss": 0.6822222471237183,
      "weighted_orthogonal_loss": 0.019176524132490158
    },
    {
      "classification_loss": 0.5923819541931152,
      "epoch": 9.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1917157769203186,
      "orthogonal_weight": 0.1,
      "step": 2883,
      "total_loss": 0.6115535497665405,
      "weighted_orthogonal_loss": 0.01917157880961895
    },
    {
      "classification_loss": 0.6407633423805237,
      "epoch": 9.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19166243076324463,
      "orthogonal_weight": 0.1,
      "step": 2884,
      "total_loss": 0.6599295735359192,
      "weighted_orthogonal_loss": 0.019166244193911552
    },
    {
      "classification_loss": 0.5969064235687256,
      "epoch": 9.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1916586309671402,
      "orthogonal_weight": 0.1,
      "step": 2885,
      "total_loss": 0.6160722970962524,
      "weighted_orthogonal_loss": 0.01916586421430111
    },
    {
      "classification_loss": 0.6579570770263672,
      "epoch": 9.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19178320467472076,
      "orthogonal_weight": 0.1,
      "step": 2886,
      "total_loss": 0.6771354079246521,
      "weighted_orthogonal_loss": 0.019178321585059166
    },
    {
      "classification_loss": 0.678083062171936,
      "epoch": 9.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19174739718437195,
      "orthogonal_weight": 0.1,
      "step": 2887,
      "total_loss": 0.6972578167915344,
      "weighted_orthogonal_loss": 0.019174739718437195
    },
    {
      "classification_loss": 0.5929762721061707,
      "epoch": 9.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19173872470855713,
      "orthogonal_weight": 0.1,
      "step": 2888,
      "total_loss": 0.6121501326560974,
      "weighted_orthogonal_loss": 0.019173873588442802
    },
    {
      "classification_loss": 0.6245968341827393,
      "epoch": 9.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1917724609375,
      "orthogonal_weight": 0.1,
      "step": 2889,
      "total_loss": 0.6437740921974182,
      "weighted_orthogonal_loss": 0.01917724683880806
    },
    {
      "classification_loss": 0.6355763077735901,
      "epoch": 9.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19209511578083038,
      "orthogonal_weight": 0.1,
      "step": 2890,
      "total_loss": 0.6547858119010925,
      "weighted_orthogonal_loss": 0.01920951157808304
    },
    {
      "classification_loss": 0.6143614053726196,
      "epoch": 9.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19243377447128296,
      "orthogonal_weight": 0.1,
      "step": 2891,
      "total_loss": 0.6336047649383545,
      "weighted_orthogonal_loss": 0.019243378192186356
    },
    {
      "classification_loss": 0.629715085029602,
      "epoch": 9.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19276486337184906,
      "orthogonal_weight": 0.1,
      "step": 2892,
      "total_loss": 0.648991584777832,
      "weighted_orthogonal_loss": 0.019276486709713936
    },
    {
      "classification_loss": 0.652675986289978,
      "epoch": 9.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19305256009101868,
      "orthogonal_weight": 0.1,
      "step": 2893,
      "total_loss": 0.6719812154769897,
      "weighted_orthogonal_loss": 0.019305257126688957
    },
    {
      "classification_loss": 0.5847000479698181,
      "epoch": 9.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1932724267244339,
      "orthogonal_weight": 0.1,
      "step": 2894,
      "total_loss": 0.604027271270752,
      "weighted_orthogonal_loss": 0.01932724379003048
    },
    {
      "classification_loss": 0.6237853169441223,
      "epoch": 9.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19351421296596527,
      "orthogonal_weight": 0.1,
      "step": 2895,
      "total_loss": 0.643136739730835,
      "weighted_orthogonal_loss": 0.019351420924067497
    },
    {
      "classification_loss": 0.5946758389472961,
      "epoch": 9.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1937493234872818,
      "orthogonal_weight": 0.1,
      "step": 2896,
      "total_loss": 0.6140507459640503,
      "weighted_orthogonal_loss": 0.01937493309378624
    },
    {
      "classification_loss": 0.6188748478889465,
      "epoch": 9.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19398656487464905,
      "orthogonal_weight": 0.1,
      "step": 2897,
      "total_loss": 0.6382734775543213,
      "weighted_orthogonal_loss": 0.019398657605051994
    },
    {
      "classification_loss": 0.6259403824806213,
      "epoch": 9.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1941656768321991,
      "orthogonal_weight": 0.1,
      "step": 2898,
      "total_loss": 0.6453569531440735,
      "weighted_orthogonal_loss": 0.019416568800807
    },
    {
      "classification_loss": 0.5321776270866394,
      "epoch": 9.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19438287615776062,
      "orthogonal_weight": 0.1,
      "step": 2899,
      "total_loss": 0.5516158938407898,
      "weighted_orthogonal_loss": 0.019438287243247032
    },
    {
      "epoch": 9.508196721311476,
      "grad_norm": 4.560136795043945,
      "learning_rate": 0.0001067,
      "loss": 0.6501,
      "step": 2900
    },
    {
      "classification_loss": 0.6112099885940552,
      "epoch": 9.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19463308155536652,
      "orthogonal_weight": 0.1,
      "step": 2900,
      "total_loss": 0.6306732892990112,
      "weighted_orthogonal_loss": 0.01946330815553665
    },
    {
      "classification_loss": 0.5873370170593262,
      "epoch": 9.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19491535425186157,
      "orthogonal_weight": 0.1,
      "step": 2901,
      "total_loss": 0.6068285703659058,
      "weighted_orthogonal_loss": 0.019491536542773247
    },
    {
      "classification_loss": 0.5925697088241577,
      "epoch": 9.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19514372944831848,
      "orthogonal_weight": 0.1,
      "step": 2902,
      "total_loss": 0.6120840907096863,
      "weighted_orthogonal_loss": 0.01951437257230282
    },
    {
      "classification_loss": 0.6352643966674805,
      "epoch": 9.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1954130083322525,
      "orthogonal_weight": 0.1,
      "step": 2903,
      "total_loss": 0.6548057198524475,
      "weighted_orthogonal_loss": 0.01954130083322525
    },
    {
      "classification_loss": 0.534174919128418,
      "epoch": 9.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19548538327217102,
      "orthogonal_weight": 0.1,
      "step": 2904,
      "total_loss": 0.5537234544754028,
      "weighted_orthogonal_loss": 0.019548539072275162
    },
    {
      "classification_loss": 0.608598530292511,
      "epoch": 9.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19541822373867035,
      "orthogonal_weight": 0.1,
      "step": 2905,
      "total_loss": 0.6281403303146362,
      "weighted_orthogonal_loss": 0.019541822373867035
    },
    {
      "classification_loss": 0.6172459125518799,
      "epoch": 9.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19514432549476624,
      "orthogonal_weight": 0.1,
      "step": 2906,
      "total_loss": 0.6367603540420532,
      "weighted_orthogonal_loss": 0.019514432176947594
    },
    {
      "classification_loss": 0.6724601984024048,
      "epoch": 9.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1949029415845871,
      "orthogonal_weight": 0.1,
      "step": 2907,
      "total_loss": 0.6919505000114441,
      "weighted_orthogonal_loss": 0.01949029415845871
    },
    {
      "classification_loss": 0.6318965554237366,
      "epoch": 9.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1947084665298462,
      "orthogonal_weight": 0.1,
      "step": 2908,
      "total_loss": 0.6513674259185791,
      "weighted_orthogonal_loss": 0.01947084628045559
    },
    {
      "classification_loss": 0.6118900775909424,
      "epoch": 9.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19443826377391815,
      "orthogonal_weight": 0.1,
      "step": 2909,
      "total_loss": 0.6313338875770569,
      "weighted_orthogonal_loss": 0.019443826749920845
    },
    {
      "classification_loss": 0.5817776918411255,
      "epoch": 9.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19438929855823517,
      "orthogonal_weight": 0.1,
      "step": 2910,
      "total_loss": 0.6012166142463684,
      "weighted_orthogonal_loss": 0.019438929855823517
    },
    {
      "classification_loss": 0.577698826789856,
      "epoch": 9.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19440969824790955,
      "orthogonal_weight": 0.1,
      "step": 2911,
      "total_loss": 0.5971397757530212,
      "weighted_orthogonal_loss": 0.019440969452261925
    },
    {
      "classification_loss": 0.6337531208992004,
      "epoch": 9.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19446252286434174,
      "orthogonal_weight": 0.1,
      "step": 2912,
      "total_loss": 0.6531993746757507,
      "weighted_orthogonal_loss": 0.019446251913905144
    },
    {
      "classification_loss": 0.5792058706283569,
      "epoch": 9.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1944928914308548,
      "orthogonal_weight": 0.1,
      "step": 2913,
      "total_loss": 0.5986551642417908,
      "weighted_orthogonal_loss": 0.01944928988814354
    },
    {
      "classification_loss": 0.5956040024757385,
      "epoch": 9.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19468209147453308,
      "orthogonal_weight": 0.1,
      "step": 2914,
      "total_loss": 0.6150721907615662,
      "weighted_orthogonal_loss": 0.019468208774924278
    },
    {
      "classification_loss": 0.6404464244842529,
      "epoch": 9.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19489620625972748,
      "orthogonal_weight": 0.1,
      "step": 2915,
      "total_loss": 0.6599360704421997,
      "weighted_orthogonal_loss": 0.019489621743559837
    },
    {
      "classification_loss": 0.6147019863128662,
      "epoch": 9.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19506940245628357,
      "orthogonal_weight": 0.1,
      "step": 2916,
      "total_loss": 0.6342089176177979,
      "weighted_orthogonal_loss": 0.019506940618157387
    },
    {
      "classification_loss": 0.5837992429733276,
      "epoch": 9.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19526799023151398,
      "orthogonal_weight": 0.1,
      "step": 2917,
      "total_loss": 0.6033260226249695,
      "weighted_orthogonal_loss": 0.019526800140738487
    },
    {
      "classification_loss": 0.6458058953285217,
      "epoch": 9.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1954859346151352,
      "orthogonal_weight": 0.1,
      "step": 2918,
      "total_loss": 0.6653544902801514,
      "weighted_orthogonal_loss": 0.01954859308898449
    },
    {
      "classification_loss": 0.6642535924911499,
      "epoch": 9.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19568754732608795,
      "orthogonal_weight": 0.1,
      "step": 2919,
      "total_loss": 0.6838223338127136,
      "weighted_orthogonal_loss": 0.019568754360079765
    },
    {
      "classification_loss": 0.6271281838417053,
      "epoch": 9.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19588270783424377,
      "orthogonal_weight": 0.1,
      "step": 2920,
      "total_loss": 0.6467164754867554,
      "weighted_orthogonal_loss": 0.019588271155953407
    },
    {
      "classification_loss": 0.617337167263031,
      "epoch": 9.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19605368375778198,
      "orthogonal_weight": 0.1,
      "step": 2921,
      "total_loss": 0.6369425058364868,
      "weighted_orthogonal_loss": 0.019605368375778198
    },
    {
      "classification_loss": 0.71783047914505,
      "epoch": 9.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19620366394519806,
      "orthogonal_weight": 0.1,
      "step": 2922,
      "total_loss": 0.7374508380889893,
      "weighted_orthogonal_loss": 0.019620366394519806
    },
    {
      "classification_loss": 0.6704118251800537,
      "epoch": 9.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19629675149917603,
      "orthogonal_weight": 0.1,
      "step": 2923,
      "total_loss": 0.6900414824485779,
      "weighted_orthogonal_loss": 0.019629675894975662
    },
    {
      "classification_loss": 0.5660949945449829,
      "epoch": 9.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1963556706905365,
      "orthogonal_weight": 0.1,
      "step": 2924,
      "total_loss": 0.5857305526733398,
      "weighted_orthogonal_loss": 0.01963556744158268
    },
    {
      "classification_loss": 0.5768566727638245,
      "epoch": 9.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19642598927021027,
      "orthogonal_weight": 0.1,
      "step": 2925,
      "total_loss": 0.5964992642402649,
      "weighted_orthogonal_loss": 0.019642598927021027
    },
    {
      "classification_loss": 0.632785439491272,
      "epoch": 9.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19642607867717743,
      "orthogonal_weight": 0.1,
      "step": 2926,
      "total_loss": 0.6524280309677124,
      "weighted_orthogonal_loss": 0.019642608240246773
    },
    {
      "classification_loss": 0.5704401135444641,
      "epoch": 9.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1964033544063568,
      "orthogonal_weight": 0.1,
      "step": 2927,
      "total_loss": 0.5900804400444031,
      "weighted_orthogonal_loss": 0.01964033581316471
    },
    {
      "classification_loss": 0.6242902874946594,
      "epoch": 9.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19634635746479034,
      "orthogonal_weight": 0.1,
      "step": 2928,
      "total_loss": 0.6439249515533447,
      "weighted_orthogonal_loss": 0.019634636119008064
    },
    {
      "classification_loss": 0.5849907994270325,
      "epoch": 9.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19631345570087433,
      "orthogonal_weight": 0.1,
      "step": 2929,
      "total_loss": 0.6046221256256104,
      "weighted_orthogonal_loss": 0.019631346687674522
    },
    {
      "classification_loss": 0.6149098873138428,
      "epoch": 9.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19633761048316956,
      "orthogonal_weight": 0.1,
      "step": 2930,
      "total_loss": 0.6345436573028564,
      "weighted_orthogonal_loss": 0.019633760675787926
    },
    {
      "classification_loss": 0.6028438210487366,
      "epoch": 9.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19635918736457825,
      "orthogonal_weight": 0.1,
      "step": 2931,
      "total_loss": 0.6224797368049622,
      "weighted_orthogonal_loss": 0.019635919481515884
    },
    {
      "classification_loss": 0.6283906102180481,
      "epoch": 9.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19631831347942352,
      "orthogonal_weight": 0.1,
      "step": 2932,
      "total_loss": 0.6480224132537842,
      "weighted_orthogonal_loss": 0.019631830975413322
    },
    {
      "classification_loss": 0.627106249332428,
      "epoch": 9.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1963215172290802,
      "orthogonal_weight": 0.1,
      "step": 2933,
      "total_loss": 0.6467384099960327,
      "weighted_orthogonal_loss": 0.01963215135037899
    },
    {
      "classification_loss": 0.5680731534957886,
      "epoch": 9.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19638879597187042,
      "orthogonal_weight": 0.1,
      "step": 2934,
      "total_loss": 0.5877120494842529,
      "weighted_orthogonal_loss": 0.019638879224658012
    },
    {
      "classification_loss": 0.6960523724555969,
      "epoch": 9.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19648286700248718,
      "orthogonal_weight": 0.1,
      "step": 2935,
      "total_loss": 0.7157006859779358,
      "weighted_orthogonal_loss": 0.019648287445306778
    },
    {
      "classification_loss": 0.6337921619415283,
      "epoch": 9.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19657553732395172,
      "orthogonal_weight": 0.1,
      "step": 2936,
      "total_loss": 0.6534497141838074,
      "weighted_orthogonal_loss": 0.019657554104924202
    },
    {
      "classification_loss": 0.6265941262245178,
      "epoch": 9.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19668643176555634,
      "orthogonal_weight": 0.1,
      "step": 2937,
      "total_loss": 0.6462627649307251,
      "weighted_orthogonal_loss": 0.019668644294142723
    },
    {
      "classification_loss": 0.5627428293228149,
      "epoch": 9.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19677503407001495,
      "orthogonal_weight": 0.1,
      "step": 2938,
      "total_loss": 0.5824203491210938,
      "weighted_orthogonal_loss": 0.019677503034472466
    },
    {
      "classification_loss": 0.6353676319122314,
      "epoch": 9.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1969180852174759,
      "orthogonal_weight": 0.1,
      "step": 2939,
      "total_loss": 0.6550594568252563,
      "weighted_orthogonal_loss": 0.01969180814921856
    },
    {
      "classification_loss": 0.6697732210159302,
      "epoch": 9.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1970597803592682,
      "orthogonal_weight": 0.1,
      "step": 2940,
      "total_loss": 0.6894791722297668,
      "weighted_orthogonal_loss": 0.01970597915351391
    },
    {
      "classification_loss": 0.6641665101051331,
      "epoch": 9.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19714775681495667,
      "orthogonal_weight": 0.1,
      "step": 2941,
      "total_loss": 0.6838812828063965,
      "weighted_orthogonal_loss": 0.019714776426553726
    },
    {
      "classification_loss": 0.7072545886039734,
      "epoch": 9.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19727125763893127,
      "orthogonal_weight": 0.1,
      "step": 2942,
      "total_loss": 0.7269816994667053,
      "weighted_orthogonal_loss": 0.019727125763893127
    },
    {
      "classification_loss": 0.6359827518463135,
      "epoch": 9.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973741352558136,
      "orthogonal_weight": 0.1,
      "step": 2943,
      "total_loss": 0.6557201743125916,
      "weighted_orthogonal_loss": 0.01973741315305233
    },
    {
      "classification_loss": 0.6970394849777222,
      "epoch": 9.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19745929539203644,
      "orthogonal_weight": 0.1,
      "step": 2944,
      "total_loss": 0.7167854309082031,
      "weighted_orthogonal_loss": 0.019745929166674614
    },
    {
      "classification_loss": 0.5859598517417908,
      "epoch": 9.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19751471281051636,
      "orthogonal_weight": 0.1,
      "step": 2945,
      "total_loss": 0.6057113409042358,
      "weighted_orthogonal_loss": 0.019751472398638725
    },
    {
      "classification_loss": 0.7272718548774719,
      "epoch": 9.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19749118387699127,
      "orthogonal_weight": 0.1,
      "step": 2946,
      "total_loss": 0.747020959854126,
      "weighted_orthogonal_loss": 0.019749118015170097
    },
    {
      "classification_loss": 0.5977588891983032,
      "epoch": 9.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19745174050331116,
      "orthogonal_weight": 0.1,
      "step": 2947,
      "total_loss": 0.6175040602684021,
      "weighted_orthogonal_loss": 0.019745174795389175
    },
    {
      "classification_loss": 0.6431934833526611,
      "epoch": 9.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973765343427658,
      "orthogonal_weight": 0.1,
      "step": 2948,
      "total_loss": 0.6629311442375183,
      "weighted_orthogonal_loss": 0.01973765343427658
    },
    {
      "classification_loss": 0.6316072344779968,
      "epoch": 9.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972760707139969,
      "orthogonal_weight": 0.1,
      "step": 2949,
      "total_loss": 0.651334822177887,
      "weighted_orthogonal_loss": 0.019727608188986778
    },
    {
      "classification_loss": 0.6821766495704651,
      "epoch": 9.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19715352356433868,
      "orthogonal_weight": 0.1,
      "step": 2950,
      "total_loss": 0.7018920183181763,
      "weighted_orthogonal_loss": 0.01971535198390484
    },
    {
      "classification_loss": 0.6383539438247681,
      "epoch": 9.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19711486995220184,
      "orthogonal_weight": 0.1,
      "step": 2951,
      "total_loss": 0.6580654382705688,
      "weighted_orthogonal_loss": 0.019711486995220184
    },
    {
      "classification_loss": 0.6583048701286316,
      "epoch": 9.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1970265954732895,
      "orthogonal_weight": 0.1,
      "step": 2952,
      "total_loss": 0.6780075430870056,
      "weighted_orthogonal_loss": 0.01970265991985798
    },
    {
      "classification_loss": 0.6265640258789062,
      "epoch": 9.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19695062935352325,
      "orthogonal_weight": 0.1,
      "step": 2953,
      "total_loss": 0.646259069442749,
      "weighted_orthogonal_loss": 0.019695064052939415
    },
    {
      "classification_loss": 0.6802421808242798,
      "epoch": 9.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700634479522705,
      "orthogonal_weight": 0.1,
      "step": 2954,
      "total_loss": 0.6999428272247314,
      "weighted_orthogonal_loss": 0.019700635224580765
    },
    {
      "classification_loss": 0.6529843211174011,
      "epoch": 9.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1970834732055664,
      "orthogonal_weight": 0.1,
      "step": 2955,
      "total_loss": 0.6726926565170288,
      "weighted_orthogonal_loss": 0.01970834843814373
    },
    {
      "classification_loss": 0.6462870836257935,
      "epoch": 9.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19719555974006653,
      "orthogonal_weight": 0.1,
      "step": 2956,
      "total_loss": 0.6660066246986389,
      "weighted_orthogonal_loss": 0.019719555974006653
    },
    {
      "classification_loss": 0.5606452226638794,
      "epoch": 9.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972913146018982,
      "orthogonal_weight": 0.1,
      "step": 2957,
      "total_loss": 0.5803743600845337,
      "weighted_orthogonal_loss": 0.01972913183271885
    },
    {
      "classification_loss": 0.676144003868103,
      "epoch": 9.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19734914600849152,
      "orthogonal_weight": 0.1,
      "step": 2958,
      "total_loss": 0.6958789229393005,
      "weighted_orthogonal_loss": 0.01973491534590721
    },
    {
      "classification_loss": 0.6315553188323975,
      "epoch": 9.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974203884601593,
      "orthogonal_weight": 0.1,
      "step": 2959,
      "total_loss": 0.6512973308563232,
      "weighted_orthogonal_loss": 0.01974203996360302
    },
    {
      "classification_loss": 0.6093212366104126,
      "epoch": 9.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974678337574005,
      "orthogonal_weight": 0.1,
      "step": 2960,
      "total_loss": 0.6290680170059204,
      "weighted_orthogonal_loss": 0.01974678412079811
    },
    {
      "classification_loss": 0.5712466835975647,
      "epoch": 9.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19754232466220856,
      "orthogonal_weight": 0.1,
      "step": 2961,
      "total_loss": 0.5910009145736694,
      "weighted_orthogonal_loss": 0.019754232838749886
    },
    {
      "classification_loss": 0.5831770896911621,
      "epoch": 9.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19754548370838165,
      "orthogonal_weight": 0.1,
      "step": 2962,
      "total_loss": 0.6029316186904907,
      "weighted_orthogonal_loss": 0.019754549488425255
    },
    {
      "classification_loss": 0.6635921597480774,
      "epoch": 9.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19756768643856049,
      "orthogonal_weight": 0.1,
      "step": 2963,
      "total_loss": 0.6833489537239075,
      "weighted_orthogonal_loss": 0.019756769761443138
    },
    {
      "classification_loss": 0.6319098472595215,
      "epoch": 9.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19749875366687775,
      "orthogonal_weight": 0.1,
      "step": 2964,
      "total_loss": 0.6516597270965576,
      "weighted_orthogonal_loss": 0.019749876111745834
    },
    {
      "classification_loss": 0.6175659894943237,
      "epoch": 9.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974981725215912,
      "orthogonal_weight": 0.1,
      "step": 2965,
      "total_loss": 0.6373158097267151,
      "weighted_orthogonal_loss": 0.019749818369746208
    },
    {
      "classification_loss": 0.6311249732971191,
      "epoch": 9.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19741351902484894,
      "orthogonal_weight": 0.1,
      "step": 2966,
      "total_loss": 0.6508663296699524,
      "weighted_orthogonal_loss": 0.019741352647542953
    },
    {
      "classification_loss": 0.6355611085891724,
      "epoch": 9.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19732190668582916,
      "orthogonal_weight": 0.1,
      "step": 2967,
      "total_loss": 0.6552932858467102,
      "weighted_orthogonal_loss": 0.019732190296053886
    },
    {
      "classification_loss": 0.6594439744949341,
      "epoch": 9.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972871720790863,
      "orthogonal_weight": 0.1,
      "step": 2968,
      "total_loss": 0.679172694683075,
      "weighted_orthogonal_loss": 0.01972871832549572
    },
    {
      "classification_loss": 0.6158939003944397,
      "epoch": 9.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19730007648468018,
      "orthogonal_weight": 0.1,
      "step": 2969,
      "total_loss": 0.6356239318847656,
      "weighted_orthogonal_loss": 0.019730007275938988
    },
    {
      "classification_loss": 0.6426994800567627,
      "epoch": 9.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19735080003738403,
      "orthogonal_weight": 0.1,
      "step": 2970,
      "total_loss": 0.6624345779418945,
      "weighted_orthogonal_loss": 0.019735081121325493
    },
    {
      "classification_loss": 0.6573774814605713,
      "epoch": 9.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19738073647022247,
      "orthogonal_weight": 0.1,
      "step": 2971,
      "total_loss": 0.6771155595779419,
      "weighted_orthogonal_loss": 0.019738074392080307
    },
    {
      "classification_loss": 0.622027575969696,
      "epoch": 9.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974201202392578,
      "orthogonal_weight": 0.1,
      "step": 2972,
      "total_loss": 0.6417695879936218,
      "weighted_orthogonal_loss": 0.01974201202392578
    },
    {
      "classification_loss": 0.6392124891281128,
      "epoch": 9.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19746512174606323,
      "orthogonal_weight": 0.1,
      "step": 2973,
      "total_loss": 0.6589590311050415,
      "weighted_orthogonal_loss": 0.019746512174606323
    },
    {
      "classification_loss": 0.6174553632736206,
      "epoch": 9.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19745607674121857,
      "orthogonal_weight": 0.1,
      "step": 2974,
      "total_loss": 0.6372009515762329,
      "weighted_orthogonal_loss": 0.019745608791708946
    },
    {
      "classification_loss": 0.6175398230552673,
      "epoch": 9.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197639599442482,
      "orthogonal_weight": 0.1,
      "step": 2975,
      "total_loss": 0.6373037695884705,
      "weighted_orthogonal_loss": 0.01976395957171917
    },
    {
      "classification_loss": 0.5904712080955505,
      "epoch": 9.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1976846158504486,
      "orthogonal_weight": 0.1,
      "step": 2976,
      "total_loss": 0.6102396845817566,
      "weighted_orthogonal_loss": 0.01976846158504486
    },
    {
      "classification_loss": 0.6853303909301758,
      "epoch": 9.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1977088451385498,
      "orthogonal_weight": 0.1,
      "step": 2977,
      "total_loss": 0.7051012516021729,
      "weighted_orthogonal_loss": 0.01977088488638401
    },
    {
      "classification_loss": 0.6621876955032349,
      "epoch": 9.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19775067269802094,
      "orthogonal_weight": 0.1,
      "step": 2978,
      "total_loss": 0.681962788105011,
      "weighted_orthogonal_loss": 0.019775068387389183
    },
    {
      "classification_loss": 0.608599066734314,
      "epoch": 9.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19783256947994232,
      "orthogonal_weight": 0.1,
      "step": 2979,
      "total_loss": 0.6283823251724243,
      "weighted_orthogonal_loss": 0.019783256575465202
    },
    {
      "classification_loss": 0.7267677783966064,
      "epoch": 9.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19792240858078003,
      "orthogonal_weight": 0.1,
      "step": 2980,
      "total_loss": 0.7465600371360779,
      "weighted_orthogonal_loss": 0.019792241975665092
    },
    {
      "classification_loss": 0.616268515586853,
      "epoch": 9.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19790956377983093,
      "orthogonal_weight": 0.1,
      "step": 2981,
      "total_loss": 0.6360594630241394,
      "weighted_orthogonal_loss": 0.019790956750512123
    },
    {
      "classification_loss": 0.6068538427352905,
      "epoch": 9.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19792068004608154,
      "orthogonal_weight": 0.1,
      "step": 2982,
      "total_loss": 0.6266459226608276,
      "weighted_orthogonal_loss": 0.019792068749666214
    },
    {
      "classification_loss": 0.6726717352867126,
      "epoch": 9.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19782109558582306,
      "orthogonal_weight": 0.1,
      "step": 2983,
      "total_loss": 0.6924538612365723,
      "weighted_orthogonal_loss": 0.019782109186053276
    },
    {
      "classification_loss": 0.6219596862792969,
      "epoch": 9.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19770872592926025,
      "orthogonal_weight": 0.1,
      "step": 2984,
      "total_loss": 0.641730546951294,
      "weighted_orthogonal_loss": 0.019770873710513115
    },
    {
      "classification_loss": 0.6485602259635925,
      "epoch": 9.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1976550817489624,
      "orthogonal_weight": 0.1,
      "step": 2985,
      "total_loss": 0.6683257222175598,
      "weighted_orthogonal_loss": 0.01976550929248333
    },
    {
      "classification_loss": 0.6424948573112488,
      "epoch": 9.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19767822325229645,
      "orthogonal_weight": 0.1,
      "step": 2986,
      "total_loss": 0.6622626781463623,
      "weighted_orthogonal_loss": 0.019767822697758675
    },
    {
      "classification_loss": 0.619369387626648,
      "epoch": 9.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19762928783893585,
      "orthogonal_weight": 0.1,
      "step": 2987,
      "total_loss": 0.6391323208808899,
      "weighted_orthogonal_loss": 0.019762929528951645
    },
    {
      "classification_loss": 0.6650226712226868,
      "epoch": 9.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19738854467868805,
      "orthogonal_weight": 0.1,
      "step": 2988,
      "total_loss": 0.6847615242004395,
      "weighted_orthogonal_loss": 0.019738854840397835
    },
    {
      "classification_loss": 0.5642554759979248,
      "epoch": 9.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19716933369636536,
      "orthogonal_weight": 0.1,
      "step": 2989,
      "total_loss": 0.5839723944664001,
      "weighted_orthogonal_loss": 0.019716933369636536
    },
    {
      "classification_loss": 0.6054432988166809,
      "epoch": 9.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1969565600156784,
      "orthogonal_weight": 0.1,
      "step": 2990,
      "total_loss": 0.6251389384269714,
      "weighted_orthogonal_loss": 0.01969565637409687
    },
    {
      "classification_loss": 0.6188374161720276,
      "epoch": 9.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19676581025123596,
      "orthogonal_weight": 0.1,
      "step": 2991,
      "total_loss": 0.63851398229599,
      "weighted_orthogonal_loss": 0.019676581025123596
    },
    {
      "classification_loss": 0.632533609867096,
      "epoch": 9.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19653788208961487,
      "orthogonal_weight": 0.1,
      "step": 2992,
      "total_loss": 0.6521874070167542,
      "weighted_orthogonal_loss": 0.019653787836432457
    },
    {
      "classification_loss": 0.6713915467262268,
      "epoch": 9.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19628822803497314,
      "orthogonal_weight": 0.1,
      "step": 2993,
      "total_loss": 0.6910203695297241,
      "weighted_orthogonal_loss": 0.019628822803497314
    },
    {
      "classification_loss": 0.6545532941818237,
      "epoch": 9.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19608190655708313,
      "orthogonal_weight": 0.1,
      "step": 2994,
      "total_loss": 0.6741614937782288,
      "weighted_orthogonal_loss": 0.019608190283179283
    },
    {
      "classification_loss": 0.6725825667381287,
      "epoch": 9.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19588617980480194,
      "orthogonal_weight": 0.1,
      "step": 2995,
      "total_loss": 0.6921711564064026,
      "weighted_orthogonal_loss": 0.019588617607951164
    },
    {
      "classification_loss": 0.6243250370025635,
      "epoch": 9.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19571764767169952,
      "orthogonal_weight": 0.1,
      "step": 2996,
      "total_loss": 0.6438968181610107,
      "weighted_orthogonal_loss": 0.019571764394640923
    },
    {
      "classification_loss": 0.7041618824005127,
      "epoch": 9.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19552099704742432,
      "orthogonal_weight": 0.1,
      "step": 2997,
      "total_loss": 0.7237139940261841,
      "weighted_orthogonal_loss": 0.01955210044980049
    },
    {
      "classification_loss": 0.7065905332565308,
      "epoch": 9.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953294426202774,
      "orthogonal_weight": 0.1,
      "step": 2998,
      "total_loss": 0.7261234521865845,
      "weighted_orthogonal_loss": 0.0195329450070858
    },
    {
      "classification_loss": 0.6873137354850769,
      "epoch": 9.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19511836767196655,
      "orthogonal_weight": 0.1,
      "step": 2999,
      "total_loss": 0.7068255543708801,
      "weighted_orthogonal_loss": 0.019511837512254715
    },
    {
      "epoch": 9.836065573770492,
      "grad_norm": 14.185626029968262,
      "learning_rate": 0.00010336666666666668,
      "loss": 0.6511,
      "step": 3000
    },
    {
      "classification_loss": 0.6450325846672058,
      "epoch": 9.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19493575394153595,
      "orthogonal_weight": 0.1,
      "step": 3000,
      "total_loss": 0.6645261645317078,
      "weighted_orthogonal_loss": 0.019493576139211655
    },
    {
      "classification_loss": 0.6427070498466492,
      "epoch": 9.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19475121796131134,
      "orthogonal_weight": 0.1,
      "step": 3001,
      "total_loss": 0.6621821522712708,
      "weighted_orthogonal_loss": 0.019475122913718224
    },
    {
      "classification_loss": 0.6059355139732361,
      "epoch": 9.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19486504793167114,
      "orthogonal_weight": 0.1,
      "step": 3002,
      "total_loss": 0.6254220008850098,
      "weighted_orthogonal_loss": 0.019486505538225174
    },
    {
      "classification_loss": 0.643019437789917,
      "epoch": 9.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19504305720329285,
      "orthogonal_weight": 0.1,
      "step": 3003,
      "total_loss": 0.6625237464904785,
      "weighted_orthogonal_loss": 0.019504306837916374
    },
    {
      "classification_loss": 0.6585970520973206,
      "epoch": 9.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19524145126342773,
      "orthogonal_weight": 0.1,
      "step": 3004,
      "total_loss": 0.6781212091445923,
      "weighted_orthogonal_loss": 0.019524145871400833
    },
    {
      "classification_loss": 0.5744994282722473,
      "epoch": 9.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19539418816566467,
      "orthogonal_weight": 0.1,
      "step": 3005,
      "total_loss": 0.5940388441085815,
      "weighted_orthogonal_loss": 0.019539419561624527
    },
    {
      "classification_loss": 0.6724743247032166,
      "epoch": 9.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19547446072101593,
      "orthogonal_weight": 0.1,
      "step": 3006,
      "total_loss": 0.6920217871665955,
      "weighted_orthogonal_loss": 0.019547445699572563
    },
    {
      "classification_loss": 0.597606360912323,
      "epoch": 9.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19552898406982422,
      "orthogonal_weight": 0.1,
      "step": 3007,
      "total_loss": 0.6171592473983765,
      "weighted_orthogonal_loss": 0.01955289952456951
    },
    {
      "classification_loss": 0.5864928960800171,
      "epoch": 9.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19549348950386047,
      "orthogonal_weight": 0.1,
      "step": 3008,
      "total_loss": 0.6060422658920288,
      "weighted_orthogonal_loss": 0.019549349322915077
    },
    {
      "classification_loss": 0.6262190937995911,
      "epoch": 9.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19550113379955292,
      "orthogonal_weight": 0.1,
      "step": 3009,
      "total_loss": 0.6457691788673401,
      "weighted_orthogonal_loss": 0.019550113007426262
    },
    {
      "classification_loss": 0.6053797602653503,
      "epoch": 9.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19538763165473938,
      "orthogonal_weight": 0.1,
      "step": 3010,
      "total_loss": 0.624918520450592,
      "weighted_orthogonal_loss": 0.019538763910531998
    },
    {
      "classification_loss": 0.5411106944084167,
      "epoch": 9.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953912228345871,
      "orthogonal_weight": 0.1,
      "step": 3011,
      "total_loss": 0.5606498122215271,
      "weighted_orthogonal_loss": 0.0195391234010458
    },
    {
      "classification_loss": 0.6604108214378357,
      "epoch": 9.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19566942751407623,
      "orthogonal_weight": 0.1,
      "step": 3012,
      "total_loss": 0.6799777746200562,
      "weighted_orthogonal_loss": 0.019566943868994713
    },
    {
      "classification_loss": 0.6787863969802856,
      "epoch": 9.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19601555168628693,
      "orthogonal_weight": 0.1,
      "step": 3013,
      "total_loss": 0.6983879804611206,
      "weighted_orthogonal_loss": 0.019601555541157722
    },
    {
      "classification_loss": 0.6566139459609985,
      "epoch": 9.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19634564220905304,
      "orthogonal_weight": 0.1,
      "step": 3014,
      "total_loss": 0.6762484908103943,
      "weighted_orthogonal_loss": 0.019634565338492393
    },
    {
      "classification_loss": 0.6101515293121338,
      "epoch": 9.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19676917791366577,
      "orthogonal_weight": 0.1,
      "step": 3015,
      "total_loss": 0.6298284530639648,
      "weighted_orthogonal_loss": 0.019676918163895607
    },
    {
      "classification_loss": 0.5692654252052307,
      "epoch": 9.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972293108701706,
      "orthogonal_weight": 0.1,
      "step": 3016,
      "total_loss": 0.5889883637428284,
      "weighted_orthogonal_loss": 0.01972293108701706
    },
    {
      "classification_loss": 0.6116684675216675,
      "epoch": 9.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19772611558437347,
      "orthogonal_weight": 0.1,
      "step": 3017,
      "total_loss": 0.631441056728363,
      "weighted_orthogonal_loss": 0.019772611558437347
    },
    {
      "classification_loss": 0.5900114178657532,
      "epoch": 9.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.198279470205307,
      "orthogonal_weight": 0.1,
      "step": 3018,
      "total_loss": 0.6098393797874451,
      "weighted_orthogonal_loss": 0.0198279470205307
    },
    {
      "classification_loss": 0.7458769083023071,
      "epoch": 9.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987706869840622,
      "orthogonal_weight": 0.1,
      "step": 3019,
      "total_loss": 0.765753984451294,
      "weighted_orthogonal_loss": 0.01987706869840622
    },
    {
      "classification_loss": 0.6359929442405701,
      "epoch": 9.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19931013882160187,
      "orthogonal_weight": 0.1,
      "step": 3020,
      "total_loss": 0.6559239625930786,
      "weighted_orthogonal_loss": 0.019931014627218246
    },
    {
      "classification_loss": 0.6678285598754883,
      "epoch": 9.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19976690411567688,
      "orthogonal_weight": 0.1,
      "step": 3021,
      "total_loss": 0.6878052353858948,
      "weighted_orthogonal_loss": 0.019976690411567688
    },
    {
      "classification_loss": 0.6064796447753906,
      "epoch": 9.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2001711130142212,
      "orthogonal_weight": 0.1,
      "step": 3022,
      "total_loss": 0.6264967322349548,
      "weighted_orthogonal_loss": 0.02001711167395115
    },
    {
      "classification_loss": 0.6234711408615112,
      "epoch": 9.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20059163868427277,
      "orthogonal_weight": 0.1,
      "step": 3023,
      "total_loss": 0.6435303092002869,
      "weighted_orthogonal_loss": 0.020059164613485336
    },
    {
      "classification_loss": 0.5594378709793091,
      "epoch": 9.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20098398625850677,
      "orthogonal_weight": 0.1,
      "step": 3024,
      "total_loss": 0.5795362591743469,
      "weighted_orthogonal_loss": 0.020098399370908737
    },
    {
      "classification_loss": 0.6683854460716248,
      "epoch": 9.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2014322280883789,
      "orthogonal_weight": 0.1,
      "step": 3025,
      "total_loss": 0.6885286569595337,
      "weighted_orthogonal_loss": 0.02014322392642498
    },
    {
      "classification_loss": 0.6611269116401672,
      "epoch": 9.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20179492235183716,
      "orthogonal_weight": 0.1,
      "step": 3026,
      "total_loss": 0.6813064217567444,
      "weighted_orthogonal_loss": 0.020179493352770805
    },
    {
      "classification_loss": 0.6188849806785583,
      "epoch": 9.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20195476710796356,
      "orthogonal_weight": 0.1,
      "step": 3027,
      "total_loss": 0.6390804648399353,
      "weighted_orthogonal_loss": 0.020195476710796356
    },
    {
      "classification_loss": 0.6780253052711487,
      "epoch": 9.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20213590562343597,
      "orthogonal_weight": 0.1,
      "step": 3028,
      "total_loss": 0.6982389092445374,
      "weighted_orthogonal_loss": 0.020213590934872627
    },
    {
      "classification_loss": 0.6451876163482666,
      "epoch": 9.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20229168236255646,
      "orthogonal_weight": 0.1,
      "step": 3029,
      "total_loss": 0.6654167771339417,
      "weighted_orthogonal_loss": 0.020229168236255646
    },
    {
      "classification_loss": 0.622630774974823,
      "epoch": 9.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2024952471256256,
      "orthogonal_weight": 0.1,
      "step": 3030,
      "total_loss": 0.6428803205490112,
      "weighted_orthogonal_loss": 0.02024952508509159
    },
    {
      "classification_loss": 0.6410051584243774,
      "epoch": 9.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20266437530517578,
      "orthogonal_weight": 0.1,
      "step": 3031,
      "total_loss": 0.6612715721130371,
      "weighted_orthogonal_loss": 0.020266437903046608
    },
    {
      "classification_loss": 0.620151698589325,
      "epoch": 9.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20276972651481628,
      "orthogonal_weight": 0.1,
      "step": 3032,
      "total_loss": 0.6404286623001099,
      "weighted_orthogonal_loss": 0.020276973024010658
    },
    {
      "classification_loss": 0.6522668600082397,
      "epoch": 9.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20295365154743195,
      "orthogonal_weight": 0.1,
      "step": 3033,
      "total_loss": 0.6725622415542603,
      "weighted_orthogonal_loss": 0.020295364782214165
    },
    {
      "classification_loss": 0.7439066171646118,
      "epoch": 9.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20316047966480255,
      "orthogonal_weight": 0.1,
      "step": 3034,
      "total_loss": 0.7642226815223694,
      "weighted_orthogonal_loss": 0.020316047593951225
    },
    {
      "classification_loss": 0.6622327566146851,
      "epoch": 9.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20330974459648132,
      "orthogonal_weight": 0.1,
      "step": 3035,
      "total_loss": 0.6825637221336365,
      "weighted_orthogonal_loss": 0.020330974832177162
    },
    {
      "classification_loss": 0.582292377948761,
      "epoch": 9.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20341886579990387,
      "orthogonal_weight": 0.1,
      "step": 3036,
      "total_loss": 0.6026342511177063,
      "weighted_orthogonal_loss": 0.020341886207461357
    },
    {
      "classification_loss": 0.6773316264152527,
      "epoch": 9.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20346513390541077,
      "orthogonal_weight": 0.1,
      "step": 3037,
      "total_loss": 0.6976781487464905,
      "weighted_orthogonal_loss": 0.020346513018012047
    },
    {
      "classification_loss": 0.6693801879882812,
      "epoch": 9.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20357146859169006,
      "orthogonal_weight": 0.1,
      "step": 3038,
      "total_loss": 0.6897373199462891,
      "weighted_orthogonal_loss": 0.020357146859169006
    },
    {
      "classification_loss": 0.562738835811615,
      "epoch": 9.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20358966290950775,
      "orthogonal_weight": 0.1,
      "step": 3039,
      "total_loss": 0.5830978155136108,
      "weighted_orthogonal_loss": 0.020358966663479805
    },
    {
      "classification_loss": 0.621139645576477,
      "epoch": 9.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2035878598690033,
      "orthogonal_weight": 0.1,
      "step": 3040,
      "total_loss": 0.6414984464645386,
      "weighted_orthogonal_loss": 0.02035878598690033
    },
    {
      "classification_loss": 0.6893167495727539,
      "epoch": 9.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036714106798172,
      "orthogonal_weight": 0.1,
      "step": 3041,
      "total_loss": 0.709683895111084,
      "weighted_orthogonal_loss": 0.02036714181303978
    },
    {
      "classification_loss": 0.5886874198913574,
      "epoch": 9.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037130445241928,
      "orthogonal_weight": 0.1,
      "step": 3042,
      "total_loss": 0.6090587377548218,
      "weighted_orthogonal_loss": 0.02037130482494831
    },
    {
      "classification_loss": 0.6232380867004395,
      "epoch": 9.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20386464893817902,
      "orthogonal_weight": 0.1,
      "step": 3043,
      "total_loss": 0.6436245441436768,
      "weighted_orthogonal_loss": 0.0203864648938179
    },
    {
      "classification_loss": 0.6595494151115417,
      "epoch": 9.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20400400459766388,
      "orthogonal_weight": 0.1,
      "step": 3044,
      "total_loss": 0.6799498200416565,
      "weighted_orthogonal_loss": 0.020400401204824448
    },
    {
      "classification_loss": 0.6413030624389648,
      "epoch": 9.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20418043434619904,
      "orthogonal_weight": 0.1,
      "step": 3045,
      "total_loss": 0.6617211103439331,
      "weighted_orthogonal_loss": 0.020418044179677963
    },
    {
      "classification_loss": 0.6471832990646362,
      "epoch": 9.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20433838665485382,
      "orthogonal_weight": 0.1,
      "step": 3046,
      "total_loss": 0.66761714220047,
      "weighted_orthogonal_loss": 0.020433839410543442
    },
    {
      "classification_loss": 0.5883163809776306,
      "epoch": 9.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20418694615364075,
      "orthogonal_weight": 0.1,
      "step": 3047,
      "total_loss": 0.6087350845336914,
      "weighted_orthogonal_loss": 0.020418694242835045
    },
    {
      "classification_loss": 0.6746444702148438,
      "epoch": 9.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20407119393348694,
      "orthogonal_weight": 0.1,
      "step": 3048,
      "total_loss": 0.6950516104698181,
      "weighted_orthogonal_loss": 0.020407119765877724
    },
    {
      "classification_loss": 0.6329701542854309,
      "epoch": 9.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20392079651355743,
      "orthogonal_weight": 0.1,
      "step": 3049,
      "total_loss": 0.6533622145652771,
      "weighted_orthogonal_loss": 0.020392080768942833
    },
    {
      "classification_loss": 0.668438732624054,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.6888407468795776,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.705883264541626,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.7262852787971497,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6527451276779175,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.6731471419334412,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6747575402259827,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.6951595544815063,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6883509159088135,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.7087529301643372,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6569671630859375,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.6773691773414612,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6500915884971619,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.6704936027526855,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.6995011568069458,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.7199031710624695,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.578,
      "eval_f1": 0.7040673211781207,
      "eval_loss": 0.6943961381912231,
      "eval_precision": 0.6251556662515566,
      "eval_recall": 0.8057784911717496,
      "eval_runtime": 6.2203,
      "eval_samples_per_second": 160.765,
      "eval_steps_per_second": 1.286,
      "step": 3050
    },
    {
      "classification_loss": 0.6349483728408813,
      "epoch": 10.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401997864246368,
      "orthogonal_weight": 0.1,
      "step": 3050,
      "total_loss": 0.655350387096405,
      "weighted_orthogonal_loss": 0.02040199749171734
    },
    {
      "classification_loss": 0.5599677562713623,
      "epoch": 10.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20416291058063507,
      "orthogonal_weight": 0.1,
      "step": 3051,
      "total_loss": 0.5803840756416321,
      "weighted_orthogonal_loss": 0.020416291430592537
    },
    {
      "classification_loss": 0.6192704439163208,
      "epoch": 10.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20442016422748566,
      "orthogonal_weight": 0.1,
      "step": 3052,
      "total_loss": 0.6397124528884888,
      "weighted_orthogonal_loss": 0.020442016422748566
    },
    {
      "classification_loss": 0.6753718852996826,
      "epoch": 10.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20465780794620514,
      "orthogonal_weight": 0.1,
      "step": 3053,
      "total_loss": 0.695837676525116,
      "weighted_orthogonal_loss": 0.020465781912207603
    },
    {
      "classification_loss": 0.6619032025337219,
      "epoch": 10.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20490950345993042,
      "orthogonal_weight": 0.1,
      "step": 3054,
      "total_loss": 0.6823941469192505,
      "weighted_orthogonal_loss": 0.020490949973464012
    },
    {
      "classification_loss": 0.6872556209564209,
      "epoch": 10.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20514999330043793,
      "orthogonal_weight": 0.1,
      "step": 3055,
      "total_loss": 0.7077706456184387,
      "weighted_orthogonal_loss": 0.020515000447630882
    },
    {
      "classification_loss": 0.649285614490509,
      "epoch": 10.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20542162656784058,
      "orthogonal_weight": 0.1,
      "step": 3056,
      "total_loss": 0.6698277592658997,
      "weighted_orthogonal_loss": 0.020542163401842117
    },
    {
      "classification_loss": 0.6285876035690308,
      "epoch": 10.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20571793615818024,
      "orthogonal_weight": 0.1,
      "step": 3057,
      "total_loss": 0.6491593718528748,
      "weighted_orthogonal_loss": 0.020571794360876083
    },
    {
      "classification_loss": 0.5651381611824036,
      "epoch": 10.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059609740972519,
      "orthogonal_weight": 0.1,
      "step": 3058,
      "total_loss": 0.5857342481613159,
      "weighted_orthogonal_loss": 0.02059609815478325
    },
    {
      "classification_loss": 0.6276828050613403,
      "epoch": 10.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20620989799499512,
      "orthogonal_weight": 0.1,
      "step": 3059,
      "total_loss": 0.6483038067817688,
      "weighted_orthogonal_loss": 0.02062099054455757
    },
    {
      "classification_loss": 0.6303408741950989,
      "epoch": 10.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20645852386951447,
      "orthogonal_weight": 0.1,
      "step": 3060,
      "total_loss": 0.6509867310523987,
      "weighted_orthogonal_loss": 0.020645853132009506
    },
    {
      "classification_loss": 0.6198498010635376,
      "epoch": 10.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066539227962494,
      "orthogonal_weight": 0.1,
      "step": 3061,
      "total_loss": 0.6405152082443237,
      "weighted_orthogonal_loss": 0.02066539227962494
    },
    {
      "classification_loss": 0.5677188038825989,
      "epoch": 10.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067302018404007,
      "orthogonal_weight": 0.1,
      "step": 3062,
      "total_loss": 0.5883918404579163,
      "weighted_orthogonal_loss": 0.02067301981151104
    },
    {
      "classification_loss": 0.6113658547401428,
      "epoch": 10.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067718803882599,
      "orthogonal_weight": 0.1,
      "step": 3063,
      "total_loss": 0.6320430636405945,
      "weighted_orthogonal_loss": 0.02067718841135502
    },
    {
      "classification_loss": 0.6313485503196716,
      "epoch": 10.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068605124950409,
      "orthogonal_weight": 0.1,
      "step": 3064,
      "total_loss": 0.65203458070755,
      "weighted_orthogonal_loss": 0.02068605087697506
    },
    {
      "classification_loss": 0.6488903164863586,
      "epoch": 10.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688043534755707,
      "orthogonal_weight": 0.1,
      "step": 3065,
      "total_loss": 0.6695783734321594,
      "weighted_orthogonal_loss": 0.020688043907284737
    },
    {
      "classification_loss": 0.561648964881897,
      "epoch": 10.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20714250206947327,
      "orthogonal_weight": 0.1,
      "step": 3066,
      "total_loss": 0.5823631882667542,
      "weighted_orthogonal_loss": 0.020714251324534416
    },
    {
      "classification_loss": 0.5828707814216614,
      "epoch": 10.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2074781209230423,
      "orthogonal_weight": 0.1,
      "step": 3067,
      "total_loss": 0.6036186218261719,
      "weighted_orthogonal_loss": 0.02074781246483326
    },
    {
      "classification_loss": 0.6098172068595886,
      "epoch": 10.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20774872601032257,
      "orthogonal_weight": 0.1,
      "step": 3068,
      "total_loss": 0.6305921077728271,
      "weighted_orthogonal_loss": 0.020774872973561287
    },
    {
      "classification_loss": 0.7039750814437866,
      "epoch": 10.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20790159702301025,
      "orthogonal_weight": 0.1,
      "step": 3069,
      "total_loss": 0.7247652411460876,
      "weighted_orthogonal_loss": 0.020790159702301025
    },
    {
      "classification_loss": 0.5702188014984131,
      "epoch": 10.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20798827707767487,
      "orthogonal_weight": 0.1,
      "step": 3070,
      "total_loss": 0.5910176038742065,
      "weighted_orthogonal_loss": 0.020798828452825546
    },
    {
      "classification_loss": 0.6117527484893799,
      "epoch": 10.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20806927978992462,
      "orthogonal_weight": 0.1,
      "step": 3071,
      "total_loss": 0.6325596570968628,
      "weighted_orthogonal_loss": 0.02080692909657955
    },
    {
      "classification_loss": 0.6666990518569946,
      "epoch": 10.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20808273553848267,
      "orthogonal_weight": 0.1,
      "step": 3072,
      "total_loss": 0.6875073313713074,
      "weighted_orthogonal_loss": 0.020808273926377296
    },
    {
      "classification_loss": 0.5986499190330505,
      "epoch": 10.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20795588195323944,
      "orthogonal_weight": 0.1,
      "step": 3073,
      "total_loss": 0.6194455027580261,
      "weighted_orthogonal_loss": 0.020795589312911034
    },
    {
      "classification_loss": 0.5982028841972351,
      "epoch": 10.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2076435536146164,
      "orthogonal_weight": 0.1,
      "step": 3074,
      "total_loss": 0.6189672350883484,
      "weighted_orthogonal_loss": 0.02076435647904873
    },
    {
      "classification_loss": 0.6358029246330261,
      "epoch": 10.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2073339968919754,
      "orthogonal_weight": 0.1,
      "step": 3075,
      "total_loss": 0.656536340713501,
      "weighted_orthogonal_loss": 0.02073339931666851
    },
    {
      "classification_loss": 0.6896759271621704,
      "epoch": 10.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2071462720632553,
      "orthogonal_weight": 0.1,
      "step": 3076,
      "total_loss": 0.710390567779541,
      "weighted_orthogonal_loss": 0.02071462757885456
    },
    {
      "classification_loss": 0.5930373072624207,
      "epoch": 10.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2070050835609436,
      "orthogonal_weight": 0.1,
      "step": 3077,
      "total_loss": 0.6137378215789795,
      "weighted_orthogonal_loss": 0.02070050872862339
    },
    {
      "classification_loss": 0.5825970768928528,
      "epoch": 10.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068624347448349,
      "orthogonal_weight": 0.1,
      "step": 3078,
      "total_loss": 0.6032833456993103,
      "weighted_orthogonal_loss": 0.02068624459207058
    },
    {
      "classification_loss": 0.5452213883399963,
      "epoch": 10.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20672984421253204,
      "orthogonal_weight": 0.1,
      "step": 3079,
      "total_loss": 0.565894365310669,
      "weighted_orthogonal_loss": 0.020672984421253204
    },
    {
      "classification_loss": 0.5751047134399414,
      "epoch": 10.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20659799873828888,
      "orthogonal_weight": 0.1,
      "step": 3080,
      "total_loss": 0.5957645177841187,
      "weighted_orthogonal_loss": 0.020659800618886948
    },
    {
      "classification_loss": 0.6927012801170349,
      "epoch": 10.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20658567547798157,
      "orthogonal_weight": 0.1,
      "step": 3081,
      "total_loss": 0.7133598327636719,
      "weighted_orthogonal_loss": 0.020658567547798157
    },
    {
      "classification_loss": 0.5994670987129211,
      "epoch": 10.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20649392902851105,
      "orthogonal_weight": 0.1,
      "step": 3082,
      "total_loss": 0.6201164722442627,
      "weighted_orthogonal_loss": 0.020649394020438194
    },
    {
      "classification_loss": 0.6332622170448303,
      "epoch": 10.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20641592144966125,
      "orthogonal_weight": 0.1,
      "step": 3083,
      "total_loss": 0.6539037823677063,
      "weighted_orthogonal_loss": 0.020641593262553215
    },
    {
      "classification_loss": 0.5254607796669006,
      "epoch": 10.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20637382566928864,
      "orthogonal_weight": 0.1,
      "step": 3084,
      "total_loss": 0.5460981726646423,
      "weighted_orthogonal_loss": 0.020637383684515953
    },
    {
      "classification_loss": 0.6302452683448792,
      "epoch": 10.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20643548667430878,
      "orthogonal_weight": 0.1,
      "step": 3085,
      "total_loss": 0.6508888006210327,
      "weighted_orthogonal_loss": 0.020643549039959908
    },
    {
      "classification_loss": 0.6517614126205444,
      "epoch": 10.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20642217993736267,
      "orthogonal_weight": 0.1,
      "step": 3086,
      "total_loss": 0.6724036335945129,
      "weighted_orthogonal_loss": 0.020642219111323357
    },
    {
      "classification_loss": 0.5679279565811157,
      "epoch": 10.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20638759434223175,
      "orthogonal_weight": 0.1,
      "step": 3087,
      "total_loss": 0.5885667204856873,
      "weighted_orthogonal_loss": 0.020638760179281235
    },
    {
      "classification_loss": 0.6024073362350464,
      "epoch": 10.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20631462335586548,
      "orthogonal_weight": 0.1,
      "step": 3088,
      "total_loss": 0.6230387687683105,
      "weighted_orthogonal_loss": 0.020631462335586548
    },
    {
      "classification_loss": 0.605967104434967,
      "epoch": 10.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20630182325839996,
      "orthogonal_weight": 0.1,
      "step": 3089,
      "total_loss": 0.6265972852706909,
      "weighted_orthogonal_loss": 0.020630182698369026
    },
    {
      "classification_loss": 0.5960022211074829,
      "epoch": 10.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20632313191890717,
      "orthogonal_weight": 0.1,
      "step": 3090,
      "total_loss": 0.6166345477104187,
      "weighted_orthogonal_loss": 0.020632313564419746
    },
    {
      "classification_loss": 0.6423231959342957,
      "epoch": 10.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20638763904571533,
      "orthogonal_weight": 0.1,
      "step": 3091,
      "total_loss": 0.6629619598388672,
      "weighted_orthogonal_loss": 0.020638763904571533
    },
    {
      "classification_loss": 0.6607078909873962,
      "epoch": 10.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20621918141841888,
      "orthogonal_weight": 0.1,
      "step": 3092,
      "total_loss": 0.6813297867774963,
      "weighted_orthogonal_loss": 0.02062191814184189
    },
    {
      "classification_loss": 0.6291764974594116,
      "epoch": 10.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20587840676307678,
      "orthogonal_weight": 0.1,
      "step": 3093,
      "total_loss": 0.649764358997345,
      "weighted_orthogonal_loss": 0.020587841048836708
    },
    {
      "classification_loss": 0.6387723684310913,
      "epoch": 10.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055550068616867,
      "orthogonal_weight": 0.1,
      "step": 3094,
      "total_loss": 0.6593278646469116,
      "weighted_orthogonal_loss": 0.02055550180375576
    },
    {
      "classification_loss": 0.7037675976753235,
      "epoch": 10.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20528782904148102,
      "orthogonal_weight": 0.1,
      "step": 3095,
      "total_loss": 0.7242963910102844,
      "weighted_orthogonal_loss": 0.02052878402173519
    },
    {
      "classification_loss": 0.5812722444534302,
      "epoch": 10.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20500583946704865,
      "orthogonal_weight": 0.1,
      "step": 3096,
      "total_loss": 0.6017728447914124,
      "weighted_orthogonal_loss": 0.020500583574175835
    },
    {
      "classification_loss": 0.6228728890419006,
      "epoch": 10.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20472204685211182,
      "orthogonal_weight": 0.1,
      "step": 3097,
      "total_loss": 0.6433451175689697,
      "weighted_orthogonal_loss": 0.020472204312682152
    },
    {
      "classification_loss": 0.581247091293335,
      "epoch": 10.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20400968194007874,
      "orthogonal_weight": 0.1,
      "step": 3098,
      "total_loss": 0.6016480326652527,
      "weighted_orthogonal_loss": 0.020400969311594963
    },
    {
      "classification_loss": 0.6346874237060547,
      "epoch": 10.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2035619169473648,
      "orthogonal_weight": 0.1,
      "step": 3099,
      "total_loss": 0.6550436019897461,
      "weighted_orthogonal_loss": 0.02035619132220745
    },
    {
      "epoch": 10.163934426229508,
      "grad_norm": 9.408489227294922,
      "learning_rate": 0.00010003333333333333,
      "loss": 0.6466,
      "step": 3100
    },
    {
      "classification_loss": 0.5692530274391174,
      "epoch": 10.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031613141298294,
      "orthogonal_weight": 0.1,
      "step": 3100,
      "total_loss": 0.5895691514015198,
      "weighted_orthogonal_loss": 0.02031613141298294
    },
    {
      "classification_loss": 0.7316930294036865,
      "epoch": 10.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290257036685944,
      "orthogonal_weight": 0.1,
      "step": 3101,
      "total_loss": 0.7519832849502563,
      "weighted_orthogonal_loss": 0.020290257409214973
    },
    {
      "classification_loss": 0.6524590849876404,
      "epoch": 10.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20266711711883545,
      "orthogonal_weight": 0.1,
      "step": 3102,
      "total_loss": 0.6727257966995239,
      "weighted_orthogonal_loss": 0.020266711711883545
    },
    {
      "classification_loss": 0.6253655552864075,
      "epoch": 10.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20249247550964355,
      "orthogonal_weight": 0.1,
      "step": 3103,
      "total_loss": 0.6456148028373718,
      "weighted_orthogonal_loss": 0.020249247550964355
    },
    {
      "classification_loss": 0.5996045470237732,
      "epoch": 10.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20251402258872986,
      "orthogonal_weight": 0.1,
      "step": 3104,
      "total_loss": 0.6198559403419495,
      "weighted_orthogonal_loss": 0.020251402631402016
    },
    {
      "classification_loss": 0.5813260078430176,
      "epoch": 10.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025265246629715,
      "orthogonal_weight": 0.1,
      "step": 3105,
      "total_loss": 0.6015786528587341,
      "weighted_orthogonal_loss": 0.02025265246629715
    },
    {
      "classification_loss": 0.6477816700935364,
      "epoch": 10.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025669813156128,
      "orthogonal_weight": 0.1,
      "step": 3106,
      "total_loss": 0.6680383682250977,
      "weighted_orthogonal_loss": 0.02025669813156128
    },
    {
      "classification_loss": 0.7081825137138367,
      "epoch": 10.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20251114666461945,
      "orthogonal_weight": 0.1,
      "step": 3107,
      "total_loss": 0.7284336090087891,
      "weighted_orthogonal_loss": 0.020251115784049034
    },
    {
      "classification_loss": 0.5711942911148071,
      "epoch": 10.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025022655725479,
      "orthogonal_weight": 0.1,
      "step": 3108,
      "total_loss": 0.5914444923400879,
      "weighted_orthogonal_loss": 0.02025022730231285
    },
    {
      "classification_loss": 0.6885507702827454,
      "epoch": 10.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2024475336074829,
      "orthogonal_weight": 0.1,
      "step": 3109,
      "total_loss": 0.7087955474853516,
      "weighted_orthogonal_loss": 0.02024475298821926
    },
    {
      "classification_loss": 0.6279022097587585,
      "epoch": 10.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20234188437461853,
      "orthogonal_weight": 0.1,
      "step": 3110,
      "total_loss": 0.6481363773345947,
      "weighted_orthogonal_loss": 0.020234188064932823
    },
    {
      "classification_loss": 0.6977742910385132,
      "epoch": 10.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022179663181305,
      "orthogonal_weight": 0.1,
      "step": 3111,
      "total_loss": 0.7179960608482361,
      "weighted_orthogonal_loss": 0.02022179774940014
    },
    {
      "classification_loss": 0.6764634847640991,
      "epoch": 10.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021404504776001,
      "orthogonal_weight": 0.1,
      "step": 3112,
      "total_loss": 0.6966775059700012,
      "weighted_orthogonal_loss": 0.02021404542028904
    },
    {
      "classification_loss": 0.6333106756210327,
      "epoch": 10.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20192332565784454,
      "orthogonal_weight": 0.1,
      "step": 3113,
      "total_loss": 0.6535030007362366,
      "weighted_orthogonal_loss": 0.020192332565784454
    },
    {
      "classification_loss": 0.6699494123458862,
      "epoch": 10.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20171768963336945,
      "orthogonal_weight": 0.1,
      "step": 3114,
      "total_loss": 0.6901211738586426,
      "weighted_orthogonal_loss": 0.020171768963336945
    },
    {
      "classification_loss": 0.5953295826911926,
      "epoch": 10.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20156174898147583,
      "orthogonal_weight": 0.1,
      "step": 3115,
      "total_loss": 0.6154857873916626,
      "weighted_orthogonal_loss": 0.020156174898147583
    },
    {
      "classification_loss": 0.6031952500343323,
      "epoch": 10.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2013867348432541,
      "orthogonal_weight": 0.1,
      "step": 3116,
      "total_loss": 0.6233339309692383,
      "weighted_orthogonal_loss": 0.02013867348432541
    },
    {
      "classification_loss": 0.6530606150627136,
      "epoch": 10.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20128732919692993,
      "orthogonal_weight": 0.1,
      "step": 3117,
      "total_loss": 0.6731893420219421,
      "weighted_orthogonal_loss": 0.020128732547163963
    },
    {
      "classification_loss": 0.6201481223106384,
      "epoch": 10.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2012457400560379,
      "orthogonal_weight": 0.1,
      "step": 3118,
      "total_loss": 0.6402726769447327,
      "weighted_orthogonal_loss": 0.02012457512319088
    },
    {
      "classification_loss": 0.5991849303245544,
      "epoch": 10.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20122826099395752,
      "orthogonal_weight": 0.1,
      "step": 3119,
      "total_loss": 0.6193077564239502,
      "weighted_orthogonal_loss": 0.020122826099395752
    },
    {
      "classification_loss": 0.5797907114028931,
      "epoch": 10.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20127184689044952,
      "orthogonal_weight": 0.1,
      "step": 3120,
      "total_loss": 0.5999178886413574,
      "weighted_orthogonal_loss": 0.020127184689044952
    },
    {
      "classification_loss": 0.6225204467773438,
      "epoch": 10.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20131702721118927,
      "orthogonal_weight": 0.1,
      "step": 3121,
      "total_loss": 0.642652153968811,
      "weighted_orthogonal_loss": 0.020131703466176987
    },
    {
      "classification_loss": 0.5744419097900391,
      "epoch": 10.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20135822892189026,
      "orthogonal_weight": 0.1,
      "step": 3122,
      "total_loss": 0.5945777297019958,
      "weighted_orthogonal_loss": 0.020135823637247086
    },
    {
      "classification_loss": 0.5932689309120178,
      "epoch": 10.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20145730674266815,
      "orthogonal_weight": 0.1,
      "step": 3123,
      "total_loss": 0.6134146451950073,
      "weighted_orthogonal_loss": 0.020145731046795845
    },
    {
      "classification_loss": 0.658213198184967,
      "epoch": 10.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2015867382287979,
      "orthogonal_weight": 0.1,
      "step": 3124,
      "total_loss": 0.6783718466758728,
      "weighted_orthogonal_loss": 0.02015867456793785
    },
    {
      "classification_loss": 0.6057684421539307,
      "epoch": 10.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20175853371620178,
      "orthogonal_weight": 0.1,
      "step": 3125,
      "total_loss": 0.6259443163871765,
      "weighted_orthogonal_loss": 0.020175853744149208
    },
    {
      "classification_loss": 0.6149658560752869,
      "epoch": 10.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20194023847579956,
      "orthogonal_weight": 0.1,
      "step": 3126,
      "total_loss": 0.6351598501205444,
      "weighted_orthogonal_loss": 0.020194023847579956
    },
    {
      "classification_loss": 0.6095269322395325,
      "epoch": 10.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20209312438964844,
      "orthogonal_weight": 0.1,
      "step": 3127,
      "total_loss": 0.6297362446784973,
      "weighted_orthogonal_loss": 0.020209312438964844
    },
    {
      "classification_loss": 0.6911361813545227,
      "epoch": 10.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20221254229545593,
      "orthogonal_weight": 0.1,
      "step": 3128,
      "total_loss": 0.7113574147224426,
      "weighted_orthogonal_loss": 0.020221253857016563
    },
    {
      "classification_loss": 0.5963674783706665,
      "epoch": 10.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20233185589313507,
      "orthogonal_weight": 0.1,
      "step": 3129,
      "total_loss": 0.6166006922721863,
      "weighted_orthogonal_loss": 0.020233185961842537
    },
    {
      "classification_loss": 0.6180344820022583,
      "epoch": 10.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20243218541145325,
      "orthogonal_weight": 0.1,
      "step": 3130,
      "total_loss": 0.6382777094841003,
      "weighted_orthogonal_loss": 0.020243218168616295
    },
    {
      "classification_loss": 0.6457682847976685,
      "epoch": 10.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20253369212150574,
      "orthogonal_weight": 0.1,
      "step": 3131,
      "total_loss": 0.6660216450691223,
      "weighted_orthogonal_loss": 0.020253369584679604
    },
    {
      "classification_loss": 0.6868380904197693,
      "epoch": 10.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20264701545238495,
      "orthogonal_weight": 0.1,
      "step": 3132,
      "total_loss": 0.7071027755737305,
      "weighted_orthogonal_loss": 0.020264701917767525
    },
    {
      "classification_loss": 0.6766498684883118,
      "epoch": 10.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20270510017871857,
      "orthogonal_weight": 0.1,
      "step": 3133,
      "total_loss": 0.6969203948974609,
      "weighted_orthogonal_loss": 0.020270509645342827
    },
    {
      "classification_loss": 0.6643900275230408,
      "epoch": 10.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20274148881435394,
      "orthogonal_weight": 0.1,
      "step": 3134,
      "total_loss": 0.6846641898155212,
      "weighted_orthogonal_loss": 0.020274149253964424
    },
    {
      "classification_loss": 0.617434561252594,
      "epoch": 10.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20275171101093292,
      "orthogonal_weight": 0.1,
      "step": 3135,
      "total_loss": 0.6377097368240356,
      "weighted_orthogonal_loss": 0.020275171846151352
    },
    {
      "classification_loss": 0.622938871383667,
      "epoch": 10.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027745395898819,
      "orthogonal_weight": 0.1,
      "step": 3136,
      "total_loss": 0.6432163119316101,
      "weighted_orthogonal_loss": 0.02027745358645916
    },
    {
      "classification_loss": 0.6568944454193115,
      "epoch": 10.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20282860100269318,
      "orthogonal_weight": 0.1,
      "step": 3137,
      "total_loss": 0.6771773099899292,
      "weighted_orthogonal_loss": 0.020282860845327377
    },
    {
      "classification_loss": 0.6206045150756836,
      "epoch": 10.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027539610862732,
      "orthogonal_weight": 0.1,
      "step": 3138,
      "total_loss": 0.6408799290657043,
      "weighted_orthogonal_loss": 0.02027539722621441
    },
    {
      "classification_loss": 0.6203190088272095,
      "epoch": 10.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20258449018001556,
      "orthogonal_weight": 0.1,
      "step": 3139,
      "total_loss": 0.6405774354934692,
      "weighted_orthogonal_loss": 0.020258449018001556
    },
    {
      "classification_loss": 0.6656374335289001,
      "epoch": 10.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20249712467193604,
      "orthogonal_weight": 0.1,
      "step": 3140,
      "total_loss": 0.6858871579170227,
      "weighted_orthogonal_loss": 0.020249713212251663
    },
    {
      "classification_loss": 0.6057184934616089,
      "epoch": 10.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20239920914173126,
      "orthogonal_weight": 0.1,
      "step": 3141,
      "total_loss": 0.6259584426879883,
      "weighted_orthogonal_loss": 0.020239921286702156
    },
    {
      "classification_loss": 0.6290267109870911,
      "epoch": 10.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20215077698230743,
      "orthogonal_weight": 0.1,
      "step": 3142,
      "total_loss": 0.6492418050765991,
      "weighted_orthogonal_loss": 0.020215077325701714
    },
    {
      "classification_loss": 0.674750030040741,
      "epoch": 10.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2019810527563095,
      "orthogonal_weight": 0.1,
      "step": 3143,
      "total_loss": 0.694948136806488,
      "weighted_orthogonal_loss": 0.02019810490310192
    },
    {
      "classification_loss": 0.6427421569824219,
      "epoch": 10.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20176680386066437,
      "orthogonal_weight": 0.1,
      "step": 3144,
      "total_loss": 0.6629188656806946,
      "weighted_orthogonal_loss": 0.020176680758595467
    },
    {
      "classification_loss": 0.6269310116767883,
      "epoch": 10.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2016691267490387,
      "orthogonal_weight": 0.1,
      "step": 3145,
      "total_loss": 0.6470979452133179,
      "weighted_orthogonal_loss": 0.0201669130474329
    },
    {
      "classification_loss": 0.5986791849136353,
      "epoch": 10.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2016511708498001,
      "orthogonal_weight": 0.1,
      "step": 3146,
      "total_loss": 0.6188443303108215,
      "weighted_orthogonal_loss": 0.02016511745750904
    },
    {
      "classification_loss": 0.6821984052658081,
      "epoch": 10.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20162978768348694,
      "orthogonal_weight": 0.1,
      "step": 3147,
      "total_loss": 0.7023614048957825,
      "weighted_orthogonal_loss": 0.020162979140877724
    },
    {
      "classification_loss": 0.5649563074111938,
      "epoch": 10.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20161552727222443,
      "orthogonal_weight": 0.1,
      "step": 3148,
      "total_loss": 0.5851178765296936,
      "weighted_orthogonal_loss": 0.020161552354693413
    },
    {
      "classification_loss": 0.631797730922699,
      "epoch": 10.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20157784223556519,
      "orthogonal_weight": 0.1,
      "step": 3149,
      "total_loss": 0.6519554853439331,
      "weighted_orthogonal_loss": 0.02015778422355652
    },
    {
      "classification_loss": 0.6240067481994629,
      "epoch": 10.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20150239765644073,
      "orthogonal_weight": 0.1,
      "step": 3150,
      "total_loss": 0.6441569924354553,
      "weighted_orthogonal_loss": 0.020150240510702133
    },
    {
      "classification_loss": 0.6383472084999084,
      "epoch": 10.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20145951211452484,
      "orthogonal_weight": 0.1,
      "step": 3151,
      "total_loss": 0.658493161201477,
      "weighted_orthogonal_loss": 0.020145950838923454
    },
    {
      "classification_loss": 0.5933477878570557,
      "epoch": 10.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2014356255531311,
      "orthogonal_weight": 0.1,
      "step": 3152,
      "total_loss": 0.6134913563728333,
      "weighted_orthogonal_loss": 0.02014356292784214
    },
    {
      "classification_loss": 0.6395550966262817,
      "epoch": 10.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2014540284872055,
      "orthogonal_weight": 0.1,
      "step": 3153,
      "total_loss": 0.6597005128860474,
      "weighted_orthogonal_loss": 0.02014540322124958
    },
    {
      "classification_loss": 0.6470956206321716,
      "epoch": 10.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20148581266403198,
      "orthogonal_weight": 0.1,
      "step": 3154,
      "total_loss": 0.6672441959381104,
      "weighted_orthogonal_loss": 0.02014858089387417
    },
    {
      "classification_loss": 0.6285673379898071,
      "epoch": 10.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2014695554971695,
      "orthogonal_weight": 0.1,
      "step": 3155,
      "total_loss": 0.6487143039703369,
      "weighted_orthogonal_loss": 0.02014695666730404
    },
    {
      "classification_loss": 0.6225083470344543,
      "epoch": 10.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20149485766887665,
      "orthogonal_weight": 0.1,
      "step": 3156,
      "total_loss": 0.6426578164100647,
      "weighted_orthogonal_loss": 0.020149486139416695
    },
    {
      "classification_loss": 0.5765894055366516,
      "epoch": 10.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2015211135149002,
      "orthogonal_weight": 0.1,
      "step": 3157,
      "total_loss": 0.5967414975166321,
      "weighted_orthogonal_loss": 0.02015211246907711
    },
    {
      "classification_loss": 0.6166836619377136,
      "epoch": 10.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20162437856197357,
      "orthogonal_weight": 0.1,
      "step": 3158,
      "total_loss": 0.636846125125885,
      "weighted_orthogonal_loss": 0.020162438973784447
    },
    {
      "classification_loss": 0.6427657604217529,
      "epoch": 10.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20173481106758118,
      "orthogonal_weight": 0.1,
      "step": 3159,
      "total_loss": 0.6629392504692078,
      "weighted_orthogonal_loss": 0.020173480734229088
    },
    {
      "classification_loss": 0.6301843523979187,
      "epoch": 10.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.201786607503891,
      "orthogonal_weight": 0.1,
      "step": 3160,
      "total_loss": 0.650363028049469,
      "weighted_orthogonal_loss": 0.0201786607503891
    },
    {
      "classification_loss": 0.672411322593689,
      "epoch": 10.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2018640786409378,
      "orthogonal_weight": 0.1,
      "step": 3161,
      "total_loss": 0.6925977468490601,
      "weighted_orthogonal_loss": 0.02018640749156475
    },
    {
      "classification_loss": 0.5951796770095825,
      "epoch": 10.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20188312232494354,
      "orthogonal_weight": 0.1,
      "step": 3162,
      "total_loss": 0.6153680086135864,
      "weighted_orthogonal_loss": 0.020188312977552414
    },
    {
      "classification_loss": 0.584385097026825,
      "epoch": 10.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20188215374946594,
      "orthogonal_weight": 0.1,
      "step": 3163,
      "total_loss": 0.6045733094215393,
      "weighted_orthogonal_loss": 0.020188216120004654
    },
    {
      "classification_loss": 0.6261359453201294,
      "epoch": 10.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2018563151359558,
      "orthogonal_weight": 0.1,
      "step": 3164,
      "total_loss": 0.6463215947151184,
      "weighted_orthogonal_loss": 0.02018563263118267
    },
    {
      "classification_loss": 0.6599296927452087,
      "epoch": 10.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2017870396375656,
      "orthogonal_weight": 0.1,
      "step": 3165,
      "total_loss": 0.680108368396759,
      "weighted_orthogonal_loss": 0.02017870359122753
    },
    {
      "classification_loss": 0.6185005307197571,
      "epoch": 10.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20151503384113312,
      "orthogonal_weight": 0.1,
      "step": 3166,
      "total_loss": 0.6386520266532898,
      "weighted_orthogonal_loss": 0.020151503384113312
    },
    {
      "classification_loss": 0.6144201755523682,
      "epoch": 10.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20137740671634674,
      "orthogonal_weight": 0.1,
      "step": 3167,
      "total_loss": 0.6345579028129578,
      "weighted_orthogonal_loss": 0.020137740299105644
    },
    {
      "classification_loss": 0.6227098107337952,
      "epoch": 10.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20128734409809113,
      "orthogonal_weight": 0.1,
      "step": 3168,
      "total_loss": 0.6428385376930237,
      "weighted_orthogonal_loss": 0.020128734409809113
    },
    {
      "classification_loss": 0.5732204914093018,
      "epoch": 10.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20120474696159363,
      "orthogonal_weight": 0.1,
      "step": 3169,
      "total_loss": 0.5933409929275513,
      "weighted_orthogonal_loss": 0.020120475441217422
    },
    {
      "classification_loss": 0.5838765501976013,
      "epoch": 10.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2011401206254959,
      "orthogonal_weight": 0.1,
      "step": 3170,
      "total_loss": 0.6039905548095703,
      "weighted_orthogonal_loss": 0.02011401206254959
    },
    {
      "classification_loss": 0.6357568502426147,
      "epoch": 10.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20110712945461273,
      "orthogonal_weight": 0.1,
      "step": 3171,
      "total_loss": 0.6558675765991211,
      "weighted_orthogonal_loss": 0.020110713317990303
    },
    {
      "classification_loss": 0.6117107272148132,
      "epoch": 10.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20110173523426056,
      "orthogonal_weight": 0.1,
      "step": 3172,
      "total_loss": 0.6318209171295166,
      "weighted_orthogonal_loss": 0.020110173150897026
    },
    {
      "classification_loss": 0.6553312540054321,
      "epoch": 10.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20108680427074432,
      "orthogonal_weight": 0.1,
      "step": 3173,
      "total_loss": 0.6754399538040161,
      "weighted_orthogonal_loss": 0.020108681172132492
    },
    {
      "classification_loss": 0.6615681052207947,
      "epoch": 10.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20100675523281097,
      "orthogonal_weight": 0.1,
      "step": 3174,
      "total_loss": 0.681668758392334,
      "weighted_orthogonal_loss": 0.020100675523281097
    },
    {
      "classification_loss": 0.6783624291419983,
      "epoch": 10.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20083625614643097,
      "orthogonal_weight": 0.1,
      "step": 3175,
      "total_loss": 0.6984460353851318,
      "weighted_orthogonal_loss": 0.020083626732230186
    },
    {
      "classification_loss": 0.6044204235076904,
      "epoch": 10.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20064738392829895,
      "orthogonal_weight": 0.1,
      "step": 3176,
      "total_loss": 0.6244851350784302,
      "weighted_orthogonal_loss": 0.020064739510416985
    },
    {
      "classification_loss": 0.6069426536560059,
      "epoch": 10.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20047633349895477,
      "orthogonal_weight": 0.1,
      "step": 3177,
      "total_loss": 0.6269902586936951,
      "weighted_orthogonal_loss": 0.020047632977366447
    },
    {
      "classification_loss": 0.5956539511680603,
      "epoch": 10.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20035751163959503,
      "orthogonal_weight": 0.1,
      "step": 3178,
      "total_loss": 0.6156896948814392,
      "weighted_orthogonal_loss": 0.020035751163959503
    },
    {
      "classification_loss": 0.5828166604042053,
      "epoch": 10.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20022684335708618,
      "orthogonal_weight": 0.1,
      "step": 3179,
      "total_loss": 0.6028393507003784,
      "weighted_orthogonal_loss": 0.020022684708237648
    },
    {
      "classification_loss": 0.5953060388565063,
      "epoch": 10.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20000028610229492,
      "orthogonal_weight": 0.1,
      "step": 3180,
      "total_loss": 0.6153060793876648,
      "weighted_orthogonal_loss": 0.020000029355287552
    },
    {
      "classification_loss": 0.5690193176269531,
      "epoch": 10.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1998233199119568,
      "orthogonal_weight": 0.1,
      "step": 3181,
      "total_loss": 0.5890016555786133,
      "weighted_orthogonal_loss": 0.01998233236372471
    },
    {
      "classification_loss": 0.6280540823936462,
      "epoch": 10.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19966624677181244,
      "orthogonal_weight": 0.1,
      "step": 3182,
      "total_loss": 0.6480206847190857,
      "weighted_orthogonal_loss": 0.019966624677181244
    },
    {
      "classification_loss": 0.567109227180481,
      "epoch": 10.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1994212418794632,
      "orthogonal_weight": 0.1,
      "step": 3183,
      "total_loss": 0.5870513319969177,
      "weighted_orthogonal_loss": 0.01994212530553341
    },
    {
      "classification_loss": 0.707578182220459,
      "epoch": 10.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19920247793197632,
      "orthogonal_weight": 0.1,
      "step": 3184,
      "total_loss": 0.7274984121322632,
      "weighted_orthogonal_loss": 0.01992024853825569
    },
    {
      "classification_loss": 0.6461969017982483,
      "epoch": 10.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19897067546844482,
      "orthogonal_weight": 0.1,
      "step": 3185,
      "total_loss": 0.6660939455032349,
      "weighted_orthogonal_loss": 0.019897067919373512
    },
    {
      "classification_loss": 0.6430558562278748,
      "epoch": 10.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19874483346939087,
      "orthogonal_weight": 0.1,
      "step": 3186,
      "total_loss": 0.6629303693771362,
      "weighted_orthogonal_loss": 0.019874483346939087
    },
    {
      "classification_loss": 0.6026715040206909,
      "epoch": 10.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19853822886943817,
      "orthogonal_weight": 0.1,
      "step": 3187,
      "total_loss": 0.6225253343582153,
      "weighted_orthogonal_loss": 0.019853822886943817
    },
    {
      "classification_loss": 0.5844972133636475,
      "epoch": 10.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983736753463745,
      "orthogonal_weight": 0.1,
      "step": 3188,
      "total_loss": 0.6043345928192139,
      "weighted_orthogonal_loss": 0.01983736827969551
    },
    {
      "classification_loss": 0.6269952654838562,
      "epoch": 10.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982380598783493,
      "orthogonal_weight": 0.1,
      "step": 3189,
      "total_loss": 0.6468190550804138,
      "weighted_orthogonal_loss": 0.01982380636036396
    },
    {
      "classification_loss": 0.692939043045044,
      "epoch": 10.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979862004518509,
      "orthogonal_weight": 0.1,
      "step": 3190,
      "total_loss": 0.7127376794815063,
      "weighted_orthogonal_loss": 0.01979861967265606
    },
    {
      "classification_loss": 0.6157068610191345,
      "epoch": 10.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19780407845973969,
      "orthogonal_weight": 0.1,
      "step": 3191,
      "total_loss": 0.6354872584342957,
      "weighted_orthogonal_loss": 0.019780408591032028
    },
    {
      "classification_loss": 0.586443305015564,
      "epoch": 10.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19771157205104828,
      "orthogonal_weight": 0.1,
      "step": 3192,
      "total_loss": 0.6062144637107849,
      "weighted_orthogonal_loss": 0.019771156832575798
    },
    {
      "classification_loss": 0.6094708442687988,
      "epoch": 10.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19765038788318634,
      "orthogonal_weight": 0.1,
      "step": 3193,
      "total_loss": 0.6292358636856079,
      "weighted_orthogonal_loss": 0.019765039905905724
    },
    {
      "classification_loss": 0.6655060052871704,
      "epoch": 10.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19757609069347382,
      "orthogonal_weight": 0.1,
      "step": 3194,
      "total_loss": 0.6852636337280273,
      "weighted_orthogonal_loss": 0.01975760981440544
    },
    {
      "classification_loss": 0.6139739751815796,
      "epoch": 10.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19753360748291016,
      "orthogonal_weight": 0.1,
      "step": 3195,
      "total_loss": 0.6337273120880127,
      "weighted_orthogonal_loss": 0.019753361120820045
    },
    {
      "classification_loss": 0.6706708669662476,
      "epoch": 10.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19743318855762482,
      "orthogonal_weight": 0.1,
      "step": 3196,
      "total_loss": 0.6904141902923584,
      "weighted_orthogonal_loss": 0.01974331960082054
    },
    {
      "classification_loss": 0.6121954321861267,
      "epoch": 10.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19736777245998383,
      "orthogonal_weight": 0.1,
      "step": 3197,
      "total_loss": 0.6319321990013123,
      "weighted_orthogonal_loss": 0.019736777991056442
    },
    {
      "classification_loss": 0.6256226897239685,
      "epoch": 10.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19727487862110138,
      "orthogonal_weight": 0.1,
      "step": 3198,
      "total_loss": 0.6453501582145691,
      "weighted_orthogonal_loss": 0.019727488979697227
    },
    {
      "classification_loss": 0.6606011986732483,
      "epoch": 10.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973244547843933,
      "orthogonal_weight": 0.1,
      "step": 3199,
      "total_loss": 0.6803336143493652,
      "weighted_orthogonal_loss": 0.01973244547843933
    },
    {
      "epoch": 10.491803278688524,
      "grad_norm": 3.0934677124023438,
      "learning_rate": 9.67e-05,
      "loss": 0.6483,
      "step": 3200
    },
    {
      "classification_loss": 0.5766051411628723,
      "epoch": 10.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19722194969654083,
      "orthogonal_weight": 0.1,
      "step": 3200,
      "total_loss": 0.5963273644447327,
      "weighted_orthogonal_loss": 0.019722195342183113
    },
    {
      "classification_loss": 0.6296571493148804,
      "epoch": 10.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19720572233200073,
      "orthogonal_weight": 0.1,
      "step": 3201,
      "total_loss": 0.649377703666687,
      "weighted_orthogonal_loss": 0.019720572978258133
    },
    {
      "classification_loss": 0.5521147847175598,
      "epoch": 10.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972058266401291,
      "orthogonal_weight": 0.1,
      "step": 3202,
      "total_loss": 0.5718353390693665,
      "weighted_orthogonal_loss": 0.01972058229148388
    },
    {
      "classification_loss": 0.6056040525436401,
      "epoch": 10.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972600817680359,
      "orthogonal_weight": 0.1,
      "step": 3203,
      "total_loss": 0.6253300905227661,
      "weighted_orthogonal_loss": 0.01972600817680359
    },
    {
      "classification_loss": 0.6539412140846252,
      "epoch": 10.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19737190008163452,
      "orthogonal_weight": 0.1,
      "step": 3204,
      "total_loss": 0.6736783981323242,
      "weighted_orthogonal_loss": 0.019737189635634422
    },
    {
      "classification_loss": 0.6802094578742981,
      "epoch": 10.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19718845188617706,
      "orthogonal_weight": 0.1,
      "step": 3205,
      "total_loss": 0.6999282836914062,
      "weighted_orthogonal_loss": 0.019718846306204796
    },
    {
      "classification_loss": 0.6125316619873047,
      "epoch": 10.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19697901606559753,
      "orthogonal_weight": 0.1,
      "step": 3206,
      "total_loss": 0.6322295665740967,
      "weighted_orthogonal_loss": 0.019697902724146843
    },
    {
      "classification_loss": 0.6579347848892212,
      "epoch": 10.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19682057201862335,
      "orthogonal_weight": 0.1,
      "step": 3207,
      "total_loss": 0.6776168346405029,
      "weighted_orthogonal_loss": 0.019682057201862335
    },
    {
      "classification_loss": 0.6357985734939575,
      "epoch": 10.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19666233658790588,
      "orthogonal_weight": 0.1,
      "step": 3208,
      "total_loss": 0.6554648280143738,
      "weighted_orthogonal_loss": 0.019666234031319618
    },
    {
      "classification_loss": 0.6495360732078552,
      "epoch": 10.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19667541980743408,
      "orthogonal_weight": 0.1,
      "step": 3209,
      "total_loss": 0.6692036390304565,
      "weighted_orthogonal_loss": 0.01966754160821438
    },
    {
      "classification_loss": 0.5946105718612671,
      "epoch": 10.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19669856131076813,
      "orthogonal_weight": 0.1,
      "step": 3210,
      "total_loss": 0.6142804026603699,
      "weighted_orthogonal_loss": 0.019669856876134872
    },
    {
      "classification_loss": 0.5677263140678406,
      "epoch": 10.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1966869831085205,
      "orthogonal_weight": 0.1,
      "step": 3211,
      "total_loss": 0.5873950123786926,
      "weighted_orthogonal_loss": 0.01966869831085205
    },
    {
      "classification_loss": 0.5934321284294128,
      "epoch": 10.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19673354923725128,
      "orthogonal_weight": 0.1,
      "step": 3212,
      "total_loss": 0.6131054759025574,
      "weighted_orthogonal_loss": 0.019673354923725128
    },
    {
      "classification_loss": 0.6029722094535828,
      "epoch": 10.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19679944217205048,
      "orthogonal_weight": 0.1,
      "step": 3213,
      "total_loss": 0.6226521730422974,
      "weighted_orthogonal_loss": 0.019679944962263107
    },
    {
      "classification_loss": 0.6019289493560791,
      "epoch": 10.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19698067009449005,
      "orthogonal_weight": 0.1,
      "step": 3214,
      "total_loss": 0.6216270327568054,
      "weighted_orthogonal_loss": 0.019698066636919975
    },
    {
      "classification_loss": 0.6289823651313782,
      "epoch": 10.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1971478909254074,
      "orthogonal_weight": 0.1,
      "step": 3215,
      "total_loss": 0.6486971378326416,
      "weighted_orthogonal_loss": 0.01971478946506977
    },
    {
      "classification_loss": 0.6078041195869446,
      "epoch": 10.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19734616577625275,
      "orthogonal_weight": 0.1,
      "step": 3216,
      "total_loss": 0.6275387406349182,
      "weighted_orthogonal_loss": 0.019734617322683334
    },
    {
      "classification_loss": 0.5994999408721924,
      "epoch": 10.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19763822853565216,
      "orthogonal_weight": 0.1,
      "step": 3217,
      "total_loss": 0.619263768196106,
      "weighted_orthogonal_loss": 0.019763823598623276
    },
    {
      "classification_loss": 0.6357787847518921,
      "epoch": 10.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19786424934864044,
      "orthogonal_weight": 0.1,
      "step": 3218,
      "total_loss": 0.6555652022361755,
      "weighted_orthogonal_loss": 0.019786424934864044
    },
    {
      "classification_loss": 0.6613152027130127,
      "epoch": 10.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1980726420879364,
      "orthogonal_weight": 0.1,
      "step": 3219,
      "total_loss": 0.6811224818229675,
      "weighted_orthogonal_loss": 0.01980726420879364
    },
    {
      "classification_loss": 0.6562060713768005,
      "epoch": 10.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19821257889270782,
      "orthogonal_weight": 0.1,
      "step": 3220,
      "total_loss": 0.6760273575782776,
      "weighted_orthogonal_loss": 0.019821258261799812
    },
    {
      "classification_loss": 0.7085306644439697,
      "epoch": 10.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983528435230255,
      "orthogonal_weight": 0.1,
      "step": 3221,
      "total_loss": 0.728365957736969,
      "weighted_orthogonal_loss": 0.01983528397977352
    },
    {
      "classification_loss": 0.6498488187789917,
      "epoch": 10.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984466165304184,
      "orthogonal_weight": 0.1,
      "step": 3222,
      "total_loss": 0.6696934700012207,
      "weighted_orthogonal_loss": 0.0198446623980999
    },
    {
      "classification_loss": 0.6556984186172485,
      "epoch": 10.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19848842918872833,
      "orthogonal_weight": 0.1,
      "step": 3223,
      "total_loss": 0.6755472421646118,
      "weighted_orthogonal_loss": 0.019848844036459923
    },
    {
      "classification_loss": 0.7002739310264587,
      "epoch": 10.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19856201112270355,
      "orthogonal_weight": 0.1,
      "step": 3224,
      "total_loss": 0.7201301455497742,
      "weighted_orthogonal_loss": 0.019856201484799385
    },
    {
      "classification_loss": 0.6410689353942871,
      "epoch": 10.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.198560893535614,
      "orthogonal_weight": 0.1,
      "step": 3225,
      "total_loss": 0.660925030708313,
      "weighted_orthogonal_loss": 0.01985608972609043
    },
    {
      "classification_loss": 0.6080114245414734,
      "epoch": 10.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1985233575105667,
      "orthogonal_weight": 0.1,
      "step": 3226,
      "total_loss": 0.6278637647628784,
      "weighted_orthogonal_loss": 0.01985233649611473
    },
    {
      "classification_loss": 0.7009126543998718,
      "epoch": 10.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984313279390335,
      "orthogonal_weight": 0.1,
      "step": 3227,
      "total_loss": 0.7207558155059814,
      "weighted_orthogonal_loss": 0.01984313316643238
    },
    {
      "classification_loss": 0.5543105006217957,
      "epoch": 10.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19836583733558655,
      "orthogonal_weight": 0.1,
      "step": 3228,
      "total_loss": 0.57414710521698,
      "weighted_orthogonal_loss": 0.019836584106087685
    },
    {
      "classification_loss": 0.6298384666442871,
      "epoch": 10.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982588917016983,
      "orthogonal_weight": 0.1,
      "step": 3229,
      "total_loss": 0.6496643424034119,
      "weighted_orthogonal_loss": 0.0198258887976408
    },
    {
      "classification_loss": 0.6155149936676025,
      "epoch": 10.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982097178697586,
      "orthogonal_weight": 0.1,
      "step": 3230,
      "total_loss": 0.6353359818458557,
      "weighted_orthogonal_loss": 0.01982097141444683
    },
    {
      "classification_loss": 0.6350451111793518,
      "epoch": 10.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19811442494392395,
      "orthogonal_weight": 0.1,
      "step": 3231,
      "total_loss": 0.6548565626144409,
      "weighted_orthogonal_loss": 0.019811442121863365
    },
    {
      "classification_loss": 0.6059394478797913,
      "epoch": 10.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19809003174304962,
      "orthogonal_weight": 0.1,
      "step": 3232,
      "total_loss": 0.6257484555244446,
      "weighted_orthogonal_loss": 0.019809003919363022
    },
    {
      "classification_loss": 0.6685729026794434,
      "epoch": 10.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19811080396175385,
      "orthogonal_weight": 0.1,
      "step": 3233,
      "total_loss": 0.6883839964866638,
      "weighted_orthogonal_loss": 0.019811080768704414
    },
    {
      "classification_loss": 0.581706702709198,
      "epoch": 10.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19815847277641296,
      "orthogonal_weight": 0.1,
      "step": 3234,
      "total_loss": 0.6015225648880005,
      "weighted_orthogonal_loss": 0.019815847277641296
    },
    {
      "classification_loss": 0.6474996209144592,
      "epoch": 10.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19823172688484192,
      "orthogonal_weight": 0.1,
      "step": 3235,
      "total_loss": 0.6673228144645691,
      "weighted_orthogonal_loss": 0.019823173061013222
    },
    {
      "classification_loss": 0.6594195365905762,
      "epoch": 10.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19823285937309265,
      "orthogonal_weight": 0.1,
      "step": 3236,
      "total_loss": 0.6792428493499756,
      "weighted_orthogonal_loss": 0.019823286682367325
    },
    {
      "classification_loss": 0.5791890621185303,
      "epoch": 10.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982329934835434,
      "orthogonal_weight": 0.1,
      "step": 3237,
      "total_loss": 0.5990123748779297,
      "weighted_orthogonal_loss": 0.01982329972088337
    },
    {
      "classification_loss": 0.610243022441864,
      "epoch": 10.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19827333092689514,
      "orthogonal_weight": 0.1,
      "step": 3238,
      "total_loss": 0.6300703287124634,
      "weighted_orthogonal_loss": 0.019827334210276604
    },
    {
      "classification_loss": 0.6464563012123108,
      "epoch": 10.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982795000076294,
      "orthogonal_weight": 0.1,
      "step": 3239,
      "total_loss": 0.6662842631340027,
      "weighted_orthogonal_loss": 0.019827950745821
    },
    {
      "classification_loss": 0.6484659314155579,
      "epoch": 10.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19832131266593933,
      "orthogonal_weight": 0.1,
      "step": 3240,
      "total_loss": 0.668298065662384,
      "weighted_orthogonal_loss": 0.019832132384181023
    },
    {
      "classification_loss": 0.6558490991592407,
      "epoch": 10.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19837623834609985,
      "orthogonal_weight": 0.1,
      "step": 3241,
      "total_loss": 0.6756867170333862,
      "weighted_orthogonal_loss": 0.019837623462080956
    },
    {
      "classification_loss": 0.6723147630691528,
      "epoch": 10.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19842775166034698,
      "orthogonal_weight": 0.1,
      "step": 3242,
      "total_loss": 0.6921575665473938,
      "weighted_orthogonal_loss": 0.01984277553856373
    },
    {
      "classification_loss": 0.686268150806427,
      "epoch": 10.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984456330537796,
      "orthogonal_weight": 0.1,
      "step": 3243,
      "total_loss": 0.7061127424240112,
      "weighted_orthogonal_loss": 0.01984456367790699
    },
    {
      "classification_loss": 0.6191068291664124,
      "epoch": 10.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984991580247879,
      "orthogonal_weight": 0.1,
      "step": 3244,
      "total_loss": 0.6389567255973816,
      "weighted_orthogonal_loss": 0.01984991692006588
    },
    {
      "classification_loss": 0.6504806280136108,
      "epoch": 10.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19854778051376343,
      "orthogonal_weight": 0.1,
      "step": 3245,
      "total_loss": 0.6703354120254517,
      "weighted_orthogonal_loss": 0.019854778423905373
    },
    {
      "classification_loss": 0.6123205423355103,
      "epoch": 10.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.198531374335289,
      "orthogonal_weight": 0.1,
      "step": 3246,
      "total_loss": 0.6321736574172974,
      "weighted_orthogonal_loss": 0.0198531374335289
    },
    {
      "classification_loss": 0.5577822327613831,
      "epoch": 10.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19848158955574036,
      "orthogonal_weight": 0.1,
      "step": 3247,
      "total_loss": 0.5776304006576538,
      "weighted_orthogonal_loss": 0.019848158583045006
    },
    {
      "classification_loss": 0.6140266060829163,
      "epoch": 10.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984189748764038,
      "orthogonal_weight": 0.1,
      "step": 3248,
      "total_loss": 0.6338685154914856,
      "weighted_orthogonal_loss": 0.01984189823269844
    },
    {
      "classification_loss": 0.5836926698684692,
      "epoch": 10.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983226090669632,
      "orthogonal_weight": 0.1,
      "step": 3249,
      "total_loss": 0.603524923324585,
      "weighted_orthogonal_loss": 0.01983226090669632
    },
    {
      "classification_loss": 0.6429319381713867,
      "epoch": 10.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19820210337638855,
      "orthogonal_weight": 0.1,
      "step": 3250,
      "total_loss": 0.6627521514892578,
      "weighted_orthogonal_loss": 0.019820211455225945
    },
    {
      "classification_loss": 0.5911808609962463,
      "epoch": 10.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19803397357463837,
      "orthogonal_weight": 0.1,
      "step": 3251,
      "total_loss": 0.6109842658042908,
      "weighted_orthogonal_loss": 0.019803397357463837
    },
    {
      "classification_loss": 0.5705957412719727,
      "epoch": 10.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979200392961502,
      "orthogonal_weight": 0.1,
      "step": 3252,
      "total_loss": 0.590387761592865,
      "weighted_orthogonal_loss": 0.01979200355708599
    },
    {
      "classification_loss": 0.582176148891449,
      "epoch": 10.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1977214366197586,
      "orthogonal_weight": 0.1,
      "step": 3253,
      "total_loss": 0.6019483208656311,
      "weighted_orthogonal_loss": 0.01977214403450489
    },
    {
      "classification_loss": 0.5676533579826355,
      "epoch": 10.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1975668966770172,
      "orthogonal_weight": 0.1,
      "step": 3254,
      "total_loss": 0.587410032749176,
      "weighted_orthogonal_loss": 0.01975668966770172
    },
    {
      "classification_loss": 0.5387680530548096,
      "epoch": 10.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973978877067566,
      "orthogonal_weight": 0.1,
      "step": 3255,
      "total_loss": 0.5585078597068787,
      "weighted_orthogonal_loss": 0.01973978988826275
    },
    {
      "classification_loss": 0.6519154906272888,
      "epoch": 10.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19724273681640625,
      "orthogonal_weight": 0.1,
      "step": 3256,
      "total_loss": 0.6716397404670715,
      "weighted_orthogonal_loss": 0.019724274054169655
    },
    {
      "classification_loss": 0.6731197834014893,
      "epoch": 10.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19712577760219574,
      "orthogonal_weight": 0.1,
      "step": 3257,
      "total_loss": 0.692832350730896,
      "weighted_orthogonal_loss": 0.019712578505277634
    },
    {
      "classification_loss": 0.6466309428215027,
      "epoch": 10.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19705556333065033,
      "orthogonal_weight": 0.1,
      "step": 3258,
      "total_loss": 0.6663364768028259,
      "weighted_orthogonal_loss": 0.019705556333065033
    },
    {
      "classification_loss": 0.6830372214317322,
      "epoch": 10.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19699318706989288,
      "orthogonal_weight": 0.1,
      "step": 3259,
      "total_loss": 0.7027365565299988,
      "weighted_orthogonal_loss": 0.01969931833446026
    },
    {
      "classification_loss": 0.5914362668991089,
      "epoch": 10.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19690565764904022,
      "orthogonal_weight": 0.1,
      "step": 3260,
      "total_loss": 0.6111268401145935,
      "weighted_orthogonal_loss": 0.019690565764904022
    },
    {
      "classification_loss": 0.6047062277793884,
      "epoch": 10.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19680075347423553,
      "orthogonal_weight": 0.1,
      "step": 3261,
      "total_loss": 0.6243863105773926,
      "weighted_orthogonal_loss": 0.019680075347423553
    },
    {
      "classification_loss": 0.6759189367294312,
      "epoch": 10.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19671867787837982,
      "orthogonal_weight": 0.1,
      "step": 3262,
      "total_loss": 0.6955907940864563,
      "weighted_orthogonal_loss": 0.019671868532896042
    },
    {
      "classification_loss": 0.6633822917938232,
      "epoch": 10.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1966671496629715,
      "orthogonal_weight": 0.1,
      "step": 3263,
      "total_loss": 0.6830490231513977,
      "weighted_orthogonal_loss": 0.01966671459376812
    },
    {
      "classification_loss": 0.6627127528190613,
      "epoch": 10.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19659778475761414,
      "orthogonal_weight": 0.1,
      "step": 3264,
      "total_loss": 0.682372510433197,
      "weighted_orthogonal_loss": 0.019659778103232384
    },
    {
      "classification_loss": 0.6209685206413269,
      "epoch": 10.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19656755030155182,
      "orthogonal_weight": 0.1,
      "step": 3265,
      "total_loss": 0.6406252980232239,
      "weighted_orthogonal_loss": 0.019656755030155182
    },
    {
      "classification_loss": 0.6247742176055908,
      "epoch": 10.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19653816521167755,
      "orthogonal_weight": 0.1,
      "step": 3266,
      "total_loss": 0.644428014755249,
      "weighted_orthogonal_loss": 0.019653817638754845
    },
    {
      "classification_loss": 0.7032064199447632,
      "epoch": 10.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1964997798204422,
      "orthogonal_weight": 0.1,
      "step": 3267,
      "total_loss": 0.7228564023971558,
      "weighted_orthogonal_loss": 0.01964997872710228
    },
    {
      "classification_loss": 0.6500499844551086,
      "epoch": 10.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19644679129123688,
      "orthogonal_weight": 0.1,
      "step": 3268,
      "total_loss": 0.6696946620941162,
      "weighted_orthogonal_loss": 0.019644679501652718
    },
    {
      "classification_loss": 0.6186570525169373,
      "epoch": 10.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1964595466852188,
      "orthogonal_weight": 0.1,
      "step": 3269,
      "total_loss": 0.6383029818534851,
      "weighted_orthogonal_loss": 0.01964595541357994
    },
    {
      "classification_loss": 0.6959887742996216,
      "epoch": 10.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19644972681999207,
      "orthogonal_weight": 0.1,
      "step": 3270,
      "total_loss": 0.715633749961853,
      "weighted_orthogonal_loss": 0.019644973799586296
    },
    {
      "classification_loss": 0.6469003558158875,
      "epoch": 10.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1963701993227005,
      "orthogonal_weight": 0.1,
      "step": 3271,
      "total_loss": 0.6665374040603638,
      "weighted_orthogonal_loss": 0.01963702030479908
    },
    {
      "classification_loss": 0.6042385101318359,
      "epoch": 10.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19631153345108032,
      "orthogonal_weight": 0.1,
      "step": 3272,
      "total_loss": 0.6238696575164795,
      "weighted_orthogonal_loss": 0.019631152972579002
    },
    {
      "classification_loss": 0.7306846380233765,
      "epoch": 10.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19626663625240326,
      "orthogonal_weight": 0.1,
      "step": 3273,
      "total_loss": 0.7503113150596619,
      "weighted_orthogonal_loss": 0.019626663997769356
    },
    {
      "classification_loss": 0.6787720322608948,
      "epoch": 10.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19624371826648712,
      "orthogonal_weight": 0.1,
      "step": 3274,
      "total_loss": 0.6983963847160339,
      "weighted_orthogonal_loss": 0.0196243729442358
    },
    {
      "classification_loss": 0.6536968350410461,
      "epoch": 10.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19621542096138,
      "orthogonal_weight": 0.1,
      "step": 3275,
      "total_loss": 0.6733183860778809,
      "weighted_orthogonal_loss": 0.01962154172360897
    },
    {
      "classification_loss": 0.5746452212333679,
      "epoch": 10.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19616694748401642,
      "orthogonal_weight": 0.1,
      "step": 3276,
      "total_loss": 0.5942619442939758,
      "weighted_orthogonal_loss": 0.01961669512093067
    },
    {
      "classification_loss": 0.6316951513290405,
      "epoch": 10.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19616396725177765,
      "orthogonal_weight": 0.1,
      "step": 3277,
      "total_loss": 0.6513115763664246,
      "weighted_orthogonal_loss": 0.019616397097706795
    },
    {
      "classification_loss": 0.6476165056228638,
      "epoch": 10.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1962122768163681,
      "orthogonal_weight": 0.1,
      "step": 3278,
      "total_loss": 0.6672377586364746,
      "weighted_orthogonal_loss": 0.0196212287992239
    },
    {
      "classification_loss": 0.5786530375480652,
      "epoch": 10.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19625689089298248,
      "orthogonal_weight": 0.1,
      "step": 3279,
      "total_loss": 0.5982787013053894,
      "weighted_orthogonal_loss": 0.019625689834356308
    },
    {
      "classification_loss": 0.6257156133651733,
      "epoch": 10.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1963457614183426,
      "orthogonal_weight": 0.1,
      "step": 3280,
      "total_loss": 0.6453502178192139,
      "weighted_orthogonal_loss": 0.01963457651436329
    },
    {
      "classification_loss": 0.6992221474647522,
      "epoch": 10.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1964530646800995,
      "orthogonal_weight": 0.1,
      "step": 3281,
      "total_loss": 0.7188674807548523,
      "weighted_orthogonal_loss": 0.01964530721306801
    },
    {
      "classification_loss": 0.6492093205451965,
      "epoch": 10.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19652043282985687,
      "orthogonal_weight": 0.1,
      "step": 3282,
      "total_loss": 0.6688613891601562,
      "weighted_orthogonal_loss": 0.019652044400572777
    },
    {
      "classification_loss": 0.6118029356002808,
      "epoch": 10.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19654184579849243,
      "orthogonal_weight": 0.1,
      "step": 3283,
      "total_loss": 0.6314570903778076,
      "weighted_orthogonal_loss": 0.019654184579849243
    },
    {
      "classification_loss": 0.6868159770965576,
      "epoch": 10.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19658072292804718,
      "orthogonal_weight": 0.1,
      "step": 3284,
      "total_loss": 0.7064740657806396,
      "weighted_orthogonal_loss": 0.019658071920275688
    },
    {
      "classification_loss": 0.6550677418708801,
      "epoch": 10.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19661717116832733,
      "orthogonal_weight": 0.1,
      "step": 3285,
      "total_loss": 0.6747294664382935,
      "weighted_orthogonal_loss": 0.019661717116832733
    },
    {
      "classification_loss": 0.6352603435516357,
      "epoch": 10.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1966143101453781,
      "orthogonal_weight": 0.1,
      "step": 3286,
      "total_loss": 0.6549217700958252,
      "weighted_orthogonal_loss": 0.0196614321321249
    },
    {
      "classification_loss": 0.5913910269737244,
      "epoch": 10.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19653014838695526,
      "orthogonal_weight": 0.1,
      "step": 3287,
      "total_loss": 0.6110440492630005,
      "weighted_orthogonal_loss": 0.019653014838695526
    },
    {
      "classification_loss": 0.6258500218391418,
      "epoch": 10.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19644637405872345,
      "orthogonal_weight": 0.1,
      "step": 3288,
      "total_loss": 0.6454946398735046,
      "weighted_orthogonal_loss": 0.019644638523459435
    },
    {
      "classification_loss": 0.7157259583473206,
      "epoch": 10.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19638940691947937,
      "orthogonal_weight": 0.1,
      "step": 3289,
      "total_loss": 0.7353649139404297,
      "weighted_orthogonal_loss": 0.019638940691947937
    },
    {
      "classification_loss": 0.5791862607002258,
      "epoch": 10.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1961916983127594,
      "orthogonal_weight": 0.1,
      "step": 3290,
      "total_loss": 0.5988054275512695,
      "weighted_orthogonal_loss": 0.019619170576334
    },
    {
      "classification_loss": 0.6734116077423096,
      "epoch": 10.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19601887464523315,
      "orthogonal_weight": 0.1,
      "step": 3291,
      "total_loss": 0.6930134892463684,
      "weighted_orthogonal_loss": 0.019601887091994286
    },
    {
      "classification_loss": 0.6006622314453125,
      "epoch": 10.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1958203911781311,
      "orthogonal_weight": 0.1,
      "step": 3292,
      "total_loss": 0.6202442646026611,
      "weighted_orthogonal_loss": 0.01958203874528408
    },
    {
      "classification_loss": 0.6169876456260681,
      "epoch": 10.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19568490982055664,
      "orthogonal_weight": 0.1,
      "step": 3293,
      "total_loss": 0.6365561485290527,
      "weighted_orthogonal_loss": 0.019568491727113724
    },
    {
      "classification_loss": 0.5900423526763916,
      "epoch": 10.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19558514654636383,
      "orthogonal_weight": 0.1,
      "step": 3294,
      "total_loss": 0.609600841999054,
      "weighted_orthogonal_loss": 0.019558515399694443
    },
    {
      "classification_loss": 0.6019104719161987,
      "epoch": 10.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1955116242170334,
      "orthogonal_weight": 0.1,
      "step": 3295,
      "total_loss": 0.6214616298675537,
      "weighted_orthogonal_loss": 0.019551163539290428
    },
    {
      "classification_loss": 0.6418150663375854,
      "epoch": 10.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19548553228378296,
      "orthogonal_weight": 0.1,
      "step": 3296,
      "total_loss": 0.6613636016845703,
      "weighted_orthogonal_loss": 0.019548553973436356
    },
    {
      "classification_loss": 0.6047481298446655,
      "epoch": 10.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19547079503536224,
      "orthogonal_weight": 0.1,
      "step": 3297,
      "total_loss": 0.6242952346801758,
      "weighted_orthogonal_loss": 0.019547080621123314
    },
    {
      "classification_loss": 0.6259167790412903,
      "epoch": 10.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19544772803783417,
      "orthogonal_weight": 0.1,
      "step": 3298,
      "total_loss": 0.6454615592956543,
      "weighted_orthogonal_loss": 0.019544772803783417
    },
    {
      "classification_loss": 0.6522433757781982,
      "epoch": 10.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19543690979480743,
      "orthogonal_weight": 0.1,
      "step": 3299,
      "total_loss": 0.6717870831489563,
      "weighted_orthogonal_loss": 0.019543690606951714
    },
    {
      "epoch": 10.819672131147541,
      "grad_norm": 7.077175140380859,
      "learning_rate": 9.336666666666667e-05,
      "loss": 0.6506,
      "step": 3300
    },
    {
      "classification_loss": 0.6736716032028198,
      "epoch": 10.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1954241842031479,
      "orthogonal_weight": 0.1,
      "step": 3300,
      "total_loss": 0.6932139992713928,
      "weighted_orthogonal_loss": 0.01954241842031479
    },
    {
      "classification_loss": 0.5825789570808411,
      "epoch": 10.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19540433585643768,
      "orthogonal_weight": 0.1,
      "step": 3301,
      "total_loss": 0.6021193861961365,
      "weighted_orthogonal_loss": 0.019540434703230858
    },
    {
      "classification_loss": 0.6378080248832703,
      "epoch": 10.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19537141919136047,
      "orthogonal_weight": 0.1,
      "step": 3302,
      "total_loss": 0.657345175743103,
      "weighted_orthogonal_loss": 0.019537141546607018
    },
    {
      "classification_loss": 0.5457038283348083,
      "epoch": 10.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19534386694431305,
      "orthogonal_weight": 0.1,
      "step": 3303,
      "total_loss": 0.5652382373809814,
      "weighted_orthogonal_loss": 0.019534386694431305
    },
    {
      "classification_loss": 0.57334965467453,
      "epoch": 10.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19537439942359924,
      "orthogonal_weight": 0.1,
      "step": 3304,
      "total_loss": 0.5928871035575867,
      "weighted_orthogonal_loss": 0.019537439569830894
    },
    {
      "classification_loss": 0.6391767859458923,
      "epoch": 10.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19538724422454834,
      "orthogonal_weight": 0.1,
      "step": 3305,
      "total_loss": 0.6587154865264893,
      "weighted_orthogonal_loss": 0.019538724794983864
    },
    {
      "classification_loss": 0.7137488722801208,
      "epoch": 10.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19538649916648865,
      "orthogonal_weight": 0.1,
      "step": 3306,
      "total_loss": 0.733287513256073,
      "weighted_orthogonal_loss": 0.019538650289177895
    },
    {
      "classification_loss": 0.728214681148529,
      "epoch": 10.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19537557661533356,
      "orthogonal_weight": 0.1,
      "step": 3307,
      "total_loss": 0.7477522492408752,
      "weighted_orthogonal_loss": 0.019537558779120445
    },
    {
      "classification_loss": 0.6708878874778748,
      "epoch": 10.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19528870284557343,
      "orthogonal_weight": 0.1,
      "step": 3308,
      "total_loss": 0.6904167532920837,
      "weighted_orthogonal_loss": 0.019528871402144432
    },
    {
      "classification_loss": 0.597282350063324,
      "epoch": 10.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1951931267976761,
      "orthogonal_weight": 0.1,
      "step": 3309,
      "total_loss": 0.6168016791343689,
      "weighted_orthogonal_loss": 0.01951931230723858
    },
    {
      "classification_loss": 0.6746135950088501,
      "epoch": 10.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19506914913654327,
      "orthogonal_weight": 0.1,
      "step": 3310,
      "total_loss": 0.6941205263137817,
      "weighted_orthogonal_loss": 0.019506914541125298
    },
    {
      "classification_loss": 0.6146380305290222,
      "epoch": 10.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1949961930513382,
      "orthogonal_weight": 0.1,
      "step": 3311,
      "total_loss": 0.6341376304626465,
      "weighted_orthogonal_loss": 0.01949962042272091
    },
    {
      "classification_loss": 0.695248544216156,
      "epoch": 10.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1949290931224823,
      "orthogonal_weight": 0.1,
      "step": 3312,
      "total_loss": 0.7147414684295654,
      "weighted_orthogonal_loss": 0.01949290931224823
    },
    {
      "classification_loss": 0.6258362531661987,
      "epoch": 10.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1948363482952118,
      "orthogonal_weight": 0.1,
      "step": 3313,
      "total_loss": 0.6453198790550232,
      "weighted_orthogonal_loss": 0.01948363520205021
    },
    {
      "classification_loss": 0.6405934691429138,
      "epoch": 10.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1947370171546936,
      "orthogonal_weight": 0.1,
      "step": 3314,
      "total_loss": 0.6600672006607056,
      "weighted_orthogonal_loss": 0.01947370171546936
    },
    {
      "classification_loss": 0.566551923751831,
      "epoch": 10.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19464655220508575,
      "orthogonal_weight": 0.1,
      "step": 3315,
      "total_loss": 0.5860165953636169,
      "weighted_orthogonal_loss": 0.019464654847979546
    },
    {
      "classification_loss": 0.6005792021751404,
      "epoch": 10.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19470874965190887,
      "orthogonal_weight": 0.1,
      "step": 3316,
      "total_loss": 0.6200500726699829,
      "weighted_orthogonal_loss": 0.019470876082777977
    },
    {
      "classification_loss": 0.6010231971740723,
      "epoch": 10.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19483530521392822,
      "orthogonal_weight": 0.1,
      "step": 3317,
      "total_loss": 0.6205067038536072,
      "weighted_orthogonal_loss": 0.019483530893921852
    },
    {
      "classification_loss": 0.6431112289428711,
      "epoch": 10.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19495557248592377,
      "orthogonal_weight": 0.1,
      "step": 3318,
      "total_loss": 0.6626067757606506,
      "weighted_orthogonal_loss": 0.019495557993650436
    },
    {
      "classification_loss": 0.6462124586105347,
      "epoch": 10.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19506718218326569,
      "orthogonal_weight": 0.1,
      "step": 3319,
      "total_loss": 0.6657191514968872,
      "weighted_orthogonal_loss": 0.01950671896338463
    },
    {
      "classification_loss": 0.6461573839187622,
      "epoch": 10.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1953340768814087,
      "orthogonal_weight": 0.1,
      "step": 3320,
      "total_loss": 0.6656907796859741,
      "weighted_orthogonal_loss": 0.01953340880572796
    },
    {
      "classification_loss": 0.6150531768798828,
      "epoch": 10.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19559775292873383,
      "orthogonal_weight": 0.1,
      "step": 3321,
      "total_loss": 0.6346129775047302,
      "weighted_orthogonal_loss": 0.019559776410460472
    },
    {
      "classification_loss": 0.6700038313865662,
      "epoch": 10.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19582068920135498,
      "orthogonal_weight": 0.1,
      "step": 3322,
      "total_loss": 0.6895859241485596,
      "weighted_orthogonal_loss": 0.019582068547606468
    },
    {
      "classification_loss": 0.6453760266304016,
      "epoch": 10.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19602526724338531,
      "orthogonal_weight": 0.1,
      "step": 3323,
      "total_loss": 0.664978563785553,
      "weighted_orthogonal_loss": 0.01960252784192562
    },
    {
      "classification_loss": 0.604527473449707,
      "epoch": 10.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19617992639541626,
      "orthogonal_weight": 0.1,
      "step": 3324,
      "total_loss": 0.6241454482078552,
      "weighted_orthogonal_loss": 0.019617993384599686
    },
    {
      "classification_loss": 0.594121515750885,
      "epoch": 10.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19631680846214294,
      "orthogonal_weight": 0.1,
      "step": 3325,
      "total_loss": 0.6137531995773315,
      "weighted_orthogonal_loss": 0.019631681963801384
    },
    {
      "classification_loss": 0.6414618492126465,
      "epoch": 10.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1964711844921112,
      "orthogonal_weight": 0.1,
      "step": 3326,
      "total_loss": 0.6611089706420898,
      "weighted_orthogonal_loss": 0.01964711956679821
    },
    {
      "classification_loss": 0.6038292646408081,
      "epoch": 10.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.196610227227211,
      "orthogonal_weight": 0.1,
      "step": 3327,
      "total_loss": 0.6234902739524841,
      "weighted_orthogonal_loss": 0.01966102235019207
    },
    {
      "classification_loss": 0.6623200178146362,
      "epoch": 10.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19687405228614807,
      "orthogonal_weight": 0.1,
      "step": 3328,
      "total_loss": 0.6820074319839478,
      "weighted_orthogonal_loss": 0.019687404856085777
    },
    {
      "classification_loss": 0.6285998821258545,
      "epoch": 10.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197103813290596,
      "orthogonal_weight": 0.1,
      "step": 3329,
      "total_loss": 0.6483102440834045,
      "weighted_orthogonal_loss": 0.01971038244664669
    },
    {
      "classification_loss": 0.6213744282722473,
      "epoch": 10.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973528414964676,
      "orthogonal_weight": 0.1,
      "step": 3330,
      "total_loss": 0.6411097049713135,
      "weighted_orthogonal_loss": 0.01973528414964676
    },
    {
      "classification_loss": 0.6056216359138489,
      "epoch": 10.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19754289090633392,
      "orthogonal_weight": 0.1,
      "step": 3331,
      "total_loss": 0.6253759264945984,
      "weighted_orthogonal_loss": 0.019754288718104362
    },
    {
      "classification_loss": 0.6455244421958923,
      "epoch": 10.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19774198532104492,
      "orthogonal_weight": 0.1,
      "step": 3332,
      "total_loss": 0.6652986407279968,
      "weighted_orthogonal_loss": 0.019774198532104492
    },
    {
      "classification_loss": 0.6898629069328308,
      "epoch": 10.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19789230823516846,
      "orthogonal_weight": 0.1,
      "step": 3333,
      "total_loss": 0.7096521258354187,
      "weighted_orthogonal_loss": 0.019789231941103935
    },
    {
      "classification_loss": 0.6144464612007141,
      "epoch": 10.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979934573173523,
      "orthogonal_weight": 0.1,
      "step": 3334,
      "total_loss": 0.6342458128929138,
      "weighted_orthogonal_loss": 0.01979934610426426
    },
    {
      "classification_loss": 0.6104452013969421,
      "epoch": 10.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19806577265262604,
      "orthogonal_weight": 0.1,
      "step": 3335,
      "total_loss": 0.6302517652511597,
      "weighted_orthogonal_loss": 0.019806576892733574
    },
    {
      "classification_loss": 0.6432119011878967,
      "epoch": 10.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1981460303068161,
      "orthogonal_weight": 0.1,
      "step": 3336,
      "total_loss": 0.6630265116691589,
      "weighted_orthogonal_loss": 0.01981460303068161
    },
    {
      "classification_loss": 0.5627653002738953,
      "epoch": 10.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19826112687587738,
      "orthogonal_weight": 0.1,
      "step": 3337,
      "total_loss": 0.5825914144515991,
      "weighted_orthogonal_loss": 0.019826112315058708
    },
    {
      "classification_loss": 0.6870617270469666,
      "epoch": 10.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19836477935314178,
      "orthogonal_weight": 0.1,
      "step": 3338,
      "total_loss": 0.7068982124328613,
      "weighted_orthogonal_loss": 0.01983647793531418
    },
    {
      "classification_loss": 0.6628492474555969,
      "epoch": 10.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984984576702118,
      "orthogonal_weight": 0.1,
      "step": 3339,
      "total_loss": 0.6826990842819214,
      "weighted_orthogonal_loss": 0.01984984613955021
    },
    {
      "classification_loss": 0.5856286287307739,
      "epoch": 10.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1985878199338913,
      "orthogonal_weight": 0.1,
      "step": 3340,
      "total_loss": 0.6054874062538147,
      "weighted_orthogonal_loss": 0.01985878311097622
    },
    {
      "classification_loss": 0.5981397032737732,
      "epoch": 10.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1986606866121292,
      "orthogonal_weight": 0.1,
      "step": 3341,
      "total_loss": 0.6180057525634766,
      "weighted_orthogonal_loss": 0.01986606977880001
    },
    {
      "classification_loss": 0.6132711172103882,
      "epoch": 10.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19867654144763947,
      "orthogonal_weight": 0.1,
      "step": 3342,
      "total_loss": 0.6331387758255005,
      "weighted_orthogonal_loss": 0.019867654889822006
    },
    {
      "classification_loss": 0.6339213848114014,
      "epoch": 10.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19868996739387512,
      "orthogonal_weight": 0.1,
      "step": 3343,
      "total_loss": 0.6537903547286987,
      "weighted_orthogonal_loss": 0.019868997856974602
    },
    {
      "classification_loss": 0.5791852474212646,
      "epoch": 10.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19854409992694855,
      "orthogonal_weight": 0.1,
      "step": 3344,
      "total_loss": 0.5990396738052368,
      "weighted_orthogonal_loss": 0.019854409620165825
    },
    {
      "classification_loss": 0.6495217084884644,
      "epoch": 10.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19841665029525757,
      "orthogonal_weight": 0.1,
      "step": 3345,
      "total_loss": 0.6693633794784546,
      "weighted_orthogonal_loss": 0.019841665402054787
    },
    {
      "classification_loss": 0.6348309516906738,
      "epoch": 10.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19826661050319672,
      "orthogonal_weight": 0.1,
      "step": 3346,
      "total_loss": 0.6546576023101807,
      "weighted_orthogonal_loss": 0.01982666179537773
    },
    {
      "classification_loss": 0.6063111424446106,
      "epoch": 10.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19813625514507294,
      "orthogonal_weight": 0.1,
      "step": 3347,
      "total_loss": 0.6261247396469116,
      "weighted_orthogonal_loss": 0.019813625141978264
    },
    {
      "classification_loss": 0.6595560312271118,
      "epoch": 10.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19799204170703888,
      "orthogonal_weight": 0.1,
      "step": 3348,
      "total_loss": 0.679355263710022,
      "weighted_orthogonal_loss": 0.019799204543232918
    },
    {
      "classification_loss": 0.67375248670578,
      "epoch": 10.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19783814251422882,
      "orthogonal_weight": 0.1,
      "step": 3349,
      "total_loss": 0.6935362815856934,
      "weighted_orthogonal_loss": 0.01978381536900997
    },
    {
      "classification_loss": 0.6906030178070068,
      "epoch": 10.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19768215715885162,
      "orthogonal_weight": 0.1,
      "step": 3350,
      "total_loss": 0.7103712558746338,
      "weighted_orthogonal_loss": 0.019768215715885162
    },
    {
      "classification_loss": 0.5712295770645142,
      "epoch": 10.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19760939478874207,
      "orthogonal_weight": 0.1,
      "step": 3351,
      "total_loss": 0.5909905433654785,
      "weighted_orthogonal_loss": 0.019760940223932266
    },
    {
      "classification_loss": 0.618568480014801,
      "epoch": 10.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19755186140537262,
      "orthogonal_weight": 0.1,
      "step": 3352,
      "total_loss": 0.6383236646652222,
      "weighted_orthogonal_loss": 0.019755186513066292
    },
    {
      "classification_loss": 0.6155542135238647,
      "epoch": 10.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19733230769634247,
      "orthogonal_weight": 0.1,
      "step": 3353,
      "total_loss": 0.6352874636650085,
      "weighted_orthogonal_loss": 0.019733231514692307
    },
    {
      "classification_loss": 0.5702957510948181,
      "epoch": 10.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19714367389678955,
      "orthogonal_weight": 0.1,
      "step": 3354,
      "total_loss": 0.5900101065635681,
      "weighted_orthogonal_loss": 0.019714368507266045
    },
    {
      "classification_loss": 0.6728466153144836,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.6925470232963562,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6994775533676147,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.7191779613494873,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6566882729530334,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.676388680934906,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6826518177986145,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.7023522257804871,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6884975433349609,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.7081979513168335,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6629024744033813,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.6826028823852539,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6551147699356079,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.6748151779174805,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.7040697932243347,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.7237702012062073,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.566,
      "eval_f1": 0.6841339155749636,
      "eval_loss": 0.696850597858429,
      "eval_precision": 0.625832223701731,
      "eval_recall": 0.7544141252006421,
      "eval_runtime": 6.1309,
      "eval_samples_per_second": 163.107,
      "eval_steps_per_second": 1.305,
      "step": 3355
    },
    {
      "classification_loss": 0.6754387617111206,
      "epoch": 11.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19700422883033752,
      "orthogonal_weight": 0.1,
      "step": 3355,
      "total_loss": 0.6951391696929932,
      "weighted_orthogonal_loss": 0.019700422883033752
    },
    {
      "classification_loss": 0.6248969435691833,
      "epoch": 11.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1968332976102829,
      "orthogonal_weight": 0.1,
      "step": 3356,
      "total_loss": 0.6445802450180054,
      "weighted_orthogonal_loss": 0.01968332938849926
    },
    {
      "classification_loss": 0.6418069005012512,
      "epoch": 11.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1967322826385498,
      "orthogonal_weight": 0.1,
      "step": 3357,
      "total_loss": 0.6614801287651062,
      "weighted_orthogonal_loss": 0.01967322826385498
    },
    {
      "classification_loss": 0.6883540749549866,
      "epoch": 11.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19667193293571472,
      "orthogonal_weight": 0.1,
      "step": 3358,
      "total_loss": 0.7080212831497192,
      "weighted_orthogonal_loss": 0.019667193293571472
    },
    {
      "classification_loss": 0.6030769348144531,
      "epoch": 11.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19633261859416962,
      "orthogonal_weight": 0.1,
      "step": 3359,
      "total_loss": 0.6227101683616638,
      "weighted_orthogonal_loss": 0.019633261486887932
    },
    {
      "classification_loss": 0.6163600087165833,
      "epoch": 11.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19603392481803894,
      "orthogonal_weight": 0.1,
      "step": 3360,
      "total_loss": 0.6359633803367615,
      "weighted_orthogonal_loss": 0.019603392109274864
    },
    {
      "classification_loss": 0.5892561674118042,
      "epoch": 11.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19577345252037048,
      "orthogonal_weight": 0.1,
      "step": 3361,
      "total_loss": 0.6088334918022156,
      "weighted_orthogonal_loss": 0.01957734487950802
    },
    {
      "classification_loss": 0.6390085816383362,
      "epoch": 11.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19558100402355194,
      "orthogonal_weight": 0.1,
      "step": 3362,
      "total_loss": 0.6585666537284851,
      "weighted_orthogonal_loss": 0.019558100029826164
    },
    {
      "classification_loss": 0.6100342273712158,
      "epoch": 11.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19546984136104584,
      "orthogonal_weight": 0.1,
      "step": 3363,
      "total_loss": 0.6295812129974365,
      "weighted_orthogonal_loss": 0.019546983763575554
    },
    {
      "classification_loss": 0.5798866152763367,
      "epoch": 11.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19534164667129517,
      "orthogonal_weight": 0.1,
      "step": 3364,
      "total_loss": 0.5994207859039307,
      "weighted_orthogonal_loss": 0.019534165039658546
    },
    {
      "classification_loss": 0.6095514893531799,
      "epoch": 11.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1952761560678482,
      "orthogonal_weight": 0.1,
      "step": 3365,
      "total_loss": 0.6290791034698486,
      "weighted_orthogonal_loss": 0.01952761597931385
    },
    {
      "classification_loss": 0.6456032991409302,
      "epoch": 11.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19527000188827515,
      "orthogonal_weight": 0.1,
      "step": 3366,
      "total_loss": 0.6651303172111511,
      "weighted_orthogonal_loss": 0.019527001306414604
    },
    {
      "classification_loss": 0.6224337220191956,
      "epoch": 11.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19527454674243927,
      "orthogonal_weight": 0.1,
      "step": 3367,
      "total_loss": 0.6419611573219299,
      "weighted_orthogonal_loss": 0.019527455791831017
    },
    {
      "classification_loss": 0.6206094026565552,
      "epoch": 11.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19529293477535248,
      "orthogonal_weight": 0.1,
      "step": 3368,
      "total_loss": 0.6401386857032776,
      "weighted_orthogonal_loss": 0.019529294222593307
    },
    {
      "classification_loss": 0.6596595644950867,
      "epoch": 11.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19528238475322723,
      "orthogonal_weight": 0.1,
      "step": 3369,
      "total_loss": 0.6791877746582031,
      "weighted_orthogonal_loss": 0.019528238102793694
    },
    {
      "classification_loss": 0.6177540421485901,
      "epoch": 11.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19526945054531097,
      "orthogonal_weight": 0.1,
      "step": 3370,
      "total_loss": 0.6372810006141663,
      "weighted_orthogonal_loss": 0.019526945427060127
    },
    {
      "classification_loss": 0.6537955403327942,
      "epoch": 11.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19530613720417023,
      "orthogonal_weight": 0.1,
      "step": 3371,
      "total_loss": 0.6733261346817017,
      "weighted_orthogonal_loss": 0.019530614838004112
    },
    {
      "classification_loss": 0.6126710176467896,
      "epoch": 11.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19538305699825287,
      "orthogonal_weight": 0.1,
      "step": 3372,
      "total_loss": 0.632209300994873,
      "weighted_orthogonal_loss": 0.019538305699825287
    },
    {
      "classification_loss": 0.6056843996047974,
      "epoch": 11.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1954808235168457,
      "orthogonal_weight": 0.1,
      "step": 3373,
      "total_loss": 0.625232458114624,
      "weighted_orthogonal_loss": 0.0195480827242136
    },
    {
      "classification_loss": 0.6194853186607361,
      "epoch": 11.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19560720026493073,
      "orthogonal_weight": 0.1,
      "step": 3374,
      "total_loss": 0.6390460133552551,
      "weighted_orthogonal_loss": 0.019560720771551132
    },
    {
      "classification_loss": 0.6567745804786682,
      "epoch": 11.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19577904045581818,
      "orthogonal_weight": 0.1,
      "step": 3375,
      "total_loss": 0.6763525009155273,
      "weighted_orthogonal_loss": 0.019577903673052788
    },
    {
      "classification_loss": 0.6396832466125488,
      "epoch": 11.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19594812393188477,
      "orthogonal_weight": 0.1,
      "step": 3376,
      "total_loss": 0.6592780351638794,
      "weighted_orthogonal_loss": 0.019594812765717506
    },
    {
      "classification_loss": 0.6076339483261108,
      "epoch": 11.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1961687207221985,
      "orthogonal_weight": 0.1,
      "step": 3377,
      "total_loss": 0.6272507905960083,
      "weighted_orthogonal_loss": 0.01961687207221985
    },
    {
      "classification_loss": 0.595254123210907,
      "epoch": 11.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19644320011138916,
      "orthogonal_weight": 0.1,
      "step": 3378,
      "total_loss": 0.6148984432220459,
      "weighted_orthogonal_loss": 0.019644320011138916
    },
    {
      "classification_loss": 0.659799337387085,
      "epoch": 11.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1966766119003296,
      "orthogonal_weight": 0.1,
      "step": 3379,
      "total_loss": 0.6794670224189758,
      "weighted_orthogonal_loss": 0.01966766081750393
    },
    {
      "classification_loss": 0.5855683088302612,
      "epoch": 11.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1969333291053772,
      "orthogonal_weight": 0.1,
      "step": 3380,
      "total_loss": 0.6052616238594055,
      "weighted_orthogonal_loss": 0.01969333365559578
    },
    {
      "classification_loss": 0.6380937695503235,
      "epoch": 11.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19712798297405243,
      "orthogonal_weight": 0.1,
      "step": 3381,
      "total_loss": 0.6578065752983093,
      "weighted_orthogonal_loss": 0.019712798297405243
    },
    {
      "classification_loss": 0.6241532564163208,
      "epoch": 11.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19723470509052277,
      "orthogonal_weight": 0.1,
      "step": 3382,
      "total_loss": 0.6438767313957214,
      "weighted_orthogonal_loss": 0.019723471254110336
    },
    {
      "classification_loss": 0.6080318093299866,
      "epoch": 11.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19719667732715607,
      "orthogonal_weight": 0.1,
      "step": 3383,
      "total_loss": 0.6277514696121216,
      "weighted_orthogonal_loss": 0.019719667732715607
    },
    {
      "classification_loss": 0.556495189666748,
      "epoch": 11.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19720621407032013,
      "orthogonal_weight": 0.1,
      "step": 3384,
      "total_loss": 0.5762158036231995,
      "weighted_orthogonal_loss": 0.019720621407032013
    },
    {
      "classification_loss": 0.6727653741836548,
      "epoch": 11.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973242312669754,
      "orthogonal_weight": 0.1,
      "step": 3385,
      "total_loss": 0.6924977898597717,
      "weighted_orthogonal_loss": 0.01973242312669754
    },
    {
      "classification_loss": 0.6058273911476135,
      "epoch": 11.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19744247198104858,
      "orthogonal_weight": 0.1,
      "step": 3386,
      "total_loss": 0.625571608543396,
      "weighted_orthogonal_loss": 0.01974424719810486
    },
    {
      "classification_loss": 0.5588247179985046,
      "epoch": 11.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1975640207529068,
      "orthogonal_weight": 0.1,
      "step": 3387,
      "total_loss": 0.5785810947418213,
      "weighted_orthogonal_loss": 0.01975640282034874
    },
    {
      "classification_loss": 0.6457964181900024,
      "epoch": 11.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1976850926876068,
      "orthogonal_weight": 0.1,
      "step": 3388,
      "total_loss": 0.6655649542808533,
      "weighted_orthogonal_loss": 0.01976851001381874
    },
    {
      "classification_loss": 0.6377184987068176,
      "epoch": 11.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19778402149677277,
      "orthogonal_weight": 0.1,
      "step": 3389,
      "total_loss": 0.6574969291687012,
      "weighted_orthogonal_loss": 0.019778402522206306
    },
    {
      "classification_loss": 0.6512441635131836,
      "epoch": 11.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197848379611969,
      "orthogonal_weight": 0.1,
      "step": 3390,
      "total_loss": 0.6710289716720581,
      "weighted_orthogonal_loss": 0.0197848379611969
    },
    {
      "classification_loss": 0.6494916677474976,
      "epoch": 11.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19789206981658936,
      "orthogonal_weight": 0.1,
      "step": 3391,
      "total_loss": 0.6692808866500854,
      "weighted_orthogonal_loss": 0.019789207726716995
    },
    {
      "classification_loss": 0.605165421962738,
      "epoch": 11.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19793976843357086,
      "orthogonal_weight": 0.1,
      "step": 3392,
      "total_loss": 0.624959409236908,
      "weighted_orthogonal_loss": 0.019793977960944176
    },
    {
      "classification_loss": 0.6421723365783691,
      "epoch": 11.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979934275150299,
      "orthogonal_weight": 0.1,
      "step": 3393,
      "total_loss": 0.6619716882705688,
      "weighted_orthogonal_loss": 0.01979934237897396
    },
    {
      "classification_loss": 0.6663711667060852,
      "epoch": 11.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19801272451877594,
      "orthogonal_weight": 0.1,
      "step": 3394,
      "total_loss": 0.6861724257469177,
      "weighted_orthogonal_loss": 0.019801272079348564
    },
    {
      "classification_loss": 0.637898862361908,
      "epoch": 11.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19800181686878204,
      "orthogonal_weight": 0.1,
      "step": 3395,
      "total_loss": 0.6576990485191345,
      "weighted_orthogonal_loss": 0.019800182431936264
    },
    {
      "classification_loss": 0.5513774156570435,
      "epoch": 11.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979760080575943,
      "orthogonal_weight": 0.1,
      "step": 3396,
      "total_loss": 0.5711750388145447,
      "weighted_orthogonal_loss": 0.01979760080575943
    },
    {
      "classification_loss": 0.597787082195282,
      "epoch": 11.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1978498101234436,
      "orthogonal_weight": 0.1,
      "step": 3397,
      "total_loss": 0.6175720691680908,
      "weighted_orthogonal_loss": 0.01978498138487339
    },
    {
      "classification_loss": 0.5685649514198303,
      "epoch": 11.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19770438969135284,
      "orthogonal_weight": 0.1,
      "step": 3398,
      "total_loss": 0.588335394859314,
      "weighted_orthogonal_loss": 0.019770439714193344
    },
    {
      "classification_loss": 0.567025899887085,
      "epoch": 11.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19764263927936554,
      "orthogonal_weight": 0.1,
      "step": 3399,
      "total_loss": 0.586790144443512,
      "weighted_orthogonal_loss": 0.019764265045523643
    },
    {
      "epoch": 11.147540983606557,
      "grad_norm": 3.2568697929382324,
      "learning_rate": 9.003333333333333e-05,
      "loss": 0.6456,
      "step": 3400
    },
    {
      "classification_loss": 0.6296533346176147,
      "epoch": 11.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197519451379776,
      "orthogonal_weight": 0.1,
      "step": 3400,
      "total_loss": 0.649405300617218,
      "weighted_orthogonal_loss": 0.01975194551050663
    },
    {
      "classification_loss": 0.5870374441146851,
      "epoch": 11.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19744156301021576,
      "orthogonal_weight": 0.1,
      "step": 3401,
      "total_loss": 0.6067816019058228,
      "weighted_orthogonal_loss": 0.019744155928492546
    },
    {
      "classification_loss": 0.6377599239349365,
      "epoch": 11.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19735005497932434,
      "orthogonal_weight": 0.1,
      "step": 3402,
      "total_loss": 0.6574949026107788,
      "weighted_orthogonal_loss": 0.019735006615519524
    },
    {
      "classification_loss": 0.5792717337608337,
      "epoch": 11.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19725915789604187,
      "orthogonal_weight": 0.1,
      "step": 3403,
      "total_loss": 0.5989976525306702,
      "weighted_orthogonal_loss": 0.019725916907191277
    },
    {
      "classification_loss": 0.5985157489776611,
      "epoch": 11.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973107010126114,
      "orthogonal_weight": 0.1,
      "step": 3404,
      "total_loss": 0.6182467937469482,
      "weighted_orthogonal_loss": 0.0197310708463192
    },
    {
      "classification_loss": 0.6020746827125549,
      "epoch": 11.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19733978807926178,
      "orthogonal_weight": 0.1,
      "step": 3405,
      "total_loss": 0.621808648109436,
      "weighted_orthogonal_loss": 0.019733978435397148
    },
    {
      "classification_loss": 0.6614677906036377,
      "epoch": 11.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974169760942459,
      "orthogonal_weight": 0.1,
      "step": 3406,
      "total_loss": 0.6812095046043396,
      "weighted_orthogonal_loss": 0.01974169723689556
    },
    {
      "classification_loss": 0.6515242457389832,
      "epoch": 11.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974034607410431,
      "orthogonal_weight": 0.1,
      "step": 3407,
      "total_loss": 0.6712645888328552,
      "weighted_orthogonal_loss": 0.01974034681916237
    },
    {
      "classification_loss": 0.5600160956382751,
      "epoch": 11.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974007487297058,
      "orthogonal_weight": 0.1,
      "step": 3408,
      "total_loss": 0.5797561407089233,
      "weighted_orthogonal_loss": 0.01974007487297058
    },
    {
      "classification_loss": 0.6002857089042664,
      "epoch": 11.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19732914865016937,
      "orthogonal_weight": 0.1,
      "step": 3409,
      "total_loss": 0.6200186014175415,
      "weighted_orthogonal_loss": 0.019732914865016937
    },
    {
      "classification_loss": 0.6596779227256775,
      "epoch": 11.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1972305178642273,
      "orthogonal_weight": 0.1,
      "step": 3410,
      "total_loss": 0.6794009804725647,
      "weighted_orthogonal_loss": 0.01972305215895176
    },
    {
      "classification_loss": 0.5591821074485779,
      "epoch": 11.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19718249142169952,
      "orthogonal_weight": 0.1,
      "step": 3411,
      "total_loss": 0.5789003372192383,
      "weighted_orthogonal_loss": 0.019718250259757042
    },
    {
      "classification_loss": 0.6115882992744446,
      "epoch": 11.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1971106231212616,
      "orthogonal_weight": 0.1,
      "step": 3412,
      "total_loss": 0.6312993764877319,
      "weighted_orthogonal_loss": 0.01971106231212616
    },
    {
      "classification_loss": 0.591049075126648,
      "epoch": 11.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19706085324287415,
      "orthogonal_weight": 0.1,
      "step": 3413,
      "total_loss": 0.6107551455497742,
      "weighted_orthogonal_loss": 0.019706085324287415
    },
    {
      "classification_loss": 0.6575918197631836,
      "epoch": 11.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19707229733467102,
      "orthogonal_weight": 0.1,
      "step": 3414,
      "total_loss": 0.6772990226745605,
      "weighted_orthogonal_loss": 0.01970723085105419
    },
    {
      "classification_loss": 0.6440057158470154,
      "epoch": 11.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19709831476211548,
      "orthogonal_weight": 0.1,
      "step": 3415,
      "total_loss": 0.6637155413627625,
      "weighted_orthogonal_loss": 0.019709831103682518
    },
    {
      "classification_loss": 0.6637409925460815,
      "epoch": 11.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19714510440826416,
      "orthogonal_weight": 0.1,
      "step": 3416,
      "total_loss": 0.6834555268287659,
      "weighted_orthogonal_loss": 0.019714510068297386
    },
    {
      "classification_loss": 0.5239930748939514,
      "epoch": 11.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197229266166687,
      "orthogonal_weight": 0.1,
      "step": 3417,
      "total_loss": 0.5437160134315491,
      "weighted_orthogonal_loss": 0.01972292736172676
    },
    {
      "classification_loss": 0.6258544921875,
      "epoch": 11.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1973344087600708,
      "orthogonal_weight": 0.1,
      "step": 3418,
      "total_loss": 0.6455879211425781,
      "weighted_orthogonal_loss": 0.01973344199359417
    },
    {
      "classification_loss": 0.5755916237831116,
      "epoch": 11.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1974761188030243,
      "orthogonal_weight": 0.1,
      "step": 3419,
      "total_loss": 0.5953392386436462,
      "weighted_orthogonal_loss": 0.01974761299788952
    },
    {
      "classification_loss": 0.6547790765762329,
      "epoch": 11.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1976143717765808,
      "orthogonal_weight": 0.1,
      "step": 3420,
      "total_loss": 0.6745405197143555,
      "weighted_orthogonal_loss": 0.01976143755018711
    },
    {
      "classification_loss": 0.644078254699707,
      "epoch": 11.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19777615368366241,
      "orthogonal_weight": 0.1,
      "step": 3421,
      "total_loss": 0.6638558506965637,
      "weighted_orthogonal_loss": 0.01977761648595333
    },
    {
      "classification_loss": 0.5711187124252319,
      "epoch": 11.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1979280412197113,
      "orthogonal_weight": 0.1,
      "step": 3422,
      "total_loss": 0.5909115076065063,
      "weighted_orthogonal_loss": 0.01979280449450016
    },
    {
      "classification_loss": 0.6395431160926819,
      "epoch": 11.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19809581339359283,
      "orthogonal_weight": 0.1,
      "step": 3423,
      "total_loss": 0.659352719783783,
      "weighted_orthogonal_loss": 0.019809581339359283
    },
    {
      "classification_loss": 0.6573584079742432,
      "epoch": 11.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19828568398952484,
      "orthogonal_weight": 0.1,
      "step": 3424,
      "total_loss": 0.6771869659423828,
      "weighted_orthogonal_loss": 0.019828569144010544
    },
    {
      "classification_loss": 0.627242386341095,
      "epoch": 11.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19842678308486938,
      "orthogonal_weight": 0.1,
      "step": 3425,
      "total_loss": 0.6470850706100464,
      "weighted_orthogonal_loss": 0.01984267868101597
    },
    {
      "classification_loss": 0.6002475619316101,
      "epoch": 11.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19851519167423248,
      "orthogonal_weight": 0.1,
      "step": 3426,
      "total_loss": 0.6200990676879883,
      "weighted_orthogonal_loss": 0.01985151879489422
    },
    {
      "classification_loss": 0.6531896591186523,
      "epoch": 11.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19856972992420197,
      "orthogonal_weight": 0.1,
      "step": 3427,
      "total_loss": 0.6730466485023499,
      "weighted_orthogonal_loss": 0.019856972619891167
    },
    {
      "classification_loss": 0.6162204146385193,
      "epoch": 11.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984362155199051,
      "orthogonal_weight": 0.1,
      "step": 3428,
      "total_loss": 0.6360640525817871,
      "weighted_orthogonal_loss": 0.01984362117946148
    },
    {
      "classification_loss": 0.6390261650085449,
      "epoch": 11.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983630210161209,
      "orthogonal_weight": 0.1,
      "step": 3429,
      "total_loss": 0.6588624715805054,
      "weighted_orthogonal_loss": 0.01983630284667015
    },
    {
      "classification_loss": 0.6052348613739014,
      "epoch": 11.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19829535484313965,
      "orthogonal_weight": 0.1,
      "step": 3430,
      "total_loss": 0.6250643730163574,
      "weighted_orthogonal_loss": 0.019829535856842995
    },
    {
      "classification_loss": 0.576034665107727,
      "epoch": 11.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19821412861347198,
      "orthogonal_weight": 0.1,
      "step": 3431,
      "total_loss": 0.5958560705184937,
      "weighted_orthogonal_loss": 0.0198214128613472
    },
    {
      "classification_loss": 0.5742348432540894,
      "epoch": 11.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19821028411388397,
      "orthogonal_weight": 0.1,
      "step": 3432,
      "total_loss": 0.5940558910369873,
      "weighted_orthogonal_loss": 0.019821029156446457
    },
    {
      "classification_loss": 0.6218910813331604,
      "epoch": 11.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19824010133743286,
      "orthogonal_weight": 0.1,
      "step": 3433,
      "total_loss": 0.6417151093482971,
      "weighted_orthogonal_loss": 0.019824011251330376
    },
    {
      "classification_loss": 0.544617235660553,
      "epoch": 11.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19828827679157257,
      "orthogonal_weight": 0.1,
      "step": 3434,
      "total_loss": 0.5644460916519165,
      "weighted_orthogonal_loss": 0.019828828051686287
    },
    {
      "classification_loss": 0.6080050468444824,
      "epoch": 11.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19833634793758392,
      "orthogonal_weight": 0.1,
      "step": 3435,
      "total_loss": 0.627838671207428,
      "weighted_orthogonal_loss": 0.019833635538816452
    },
    {
      "classification_loss": 0.6596100330352783,
      "epoch": 11.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19820895791053772,
      "orthogonal_weight": 0.1,
      "step": 3436,
      "total_loss": 0.6794309020042419,
      "weighted_orthogonal_loss": 0.01982089690864086
    },
    {
      "classification_loss": 0.5657957792282104,
      "epoch": 11.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1980879157781601,
      "orthogonal_weight": 0.1,
      "step": 3437,
      "total_loss": 0.5856045484542847,
      "weighted_orthogonal_loss": 0.01980879157781601
    },
    {
      "classification_loss": 0.690685510635376,
      "epoch": 11.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1978742480278015,
      "orthogonal_weight": 0.1,
      "step": 3438,
      "total_loss": 0.7104729413986206,
      "weighted_orthogonal_loss": 0.01978742517530918
    },
    {
      "classification_loss": 0.6548033952713013,
      "epoch": 11.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1977211833000183,
      "orthogonal_weight": 0.1,
      "step": 3439,
      "total_loss": 0.6745755076408386,
      "weighted_orthogonal_loss": 0.0197721179574728
    },
    {
      "classification_loss": 0.6315286755561829,
      "epoch": 11.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19747082889080048,
      "orthogonal_weight": 0.1,
      "step": 3440,
      "total_loss": 0.6512757539749146,
      "weighted_orthogonal_loss": 0.019747084006667137
    },
    {
      "classification_loss": 0.6290068626403809,
      "epoch": 11.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19733119010925293,
      "orthogonal_weight": 0.1,
      "step": 3441,
      "total_loss": 0.6487399935722351,
      "weighted_orthogonal_loss": 0.019733119755983353
    },
    {
      "classification_loss": 0.6022627949714661,
      "epoch": 11.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19720527529716492,
      "orthogonal_weight": 0.1,
      "step": 3442,
      "total_loss": 0.6219833493232727,
      "weighted_orthogonal_loss": 0.01972052827477455
    },
    {
      "classification_loss": 0.664307713508606,
      "epoch": 11.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1971353143453598,
      "orthogonal_weight": 0.1,
      "step": 3443,
      "total_loss": 0.6840212345123291,
      "weighted_orthogonal_loss": 0.01971353217959404
    },
    {
      "classification_loss": 0.6222238540649414,
      "epoch": 11.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19709046185016632,
      "orthogonal_weight": 0.1,
      "step": 3444,
      "total_loss": 0.6419329047203064,
      "weighted_orthogonal_loss": 0.019709046930074692
    },
    {
      "classification_loss": 0.6062164902687073,
      "epoch": 11.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19713348150253296,
      "orthogonal_weight": 0.1,
      "step": 3445,
      "total_loss": 0.6259298324584961,
      "weighted_orthogonal_loss": 0.019713347777724266
    },
    {
      "classification_loss": 0.5635494589805603,
      "epoch": 11.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19723182916641235,
      "orthogonal_weight": 0.1,
      "step": 3446,
      "total_loss": 0.5832726359367371,
      "weighted_orthogonal_loss": 0.019723182544112206
    },
    {
      "classification_loss": 0.5849801301956177,
      "epoch": 11.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19739465415477753,
      "orthogonal_weight": 0.1,
      "step": 3447,
      "total_loss": 0.6047195792198181,
      "weighted_orthogonal_loss": 0.019739465788006783
    },
    {
      "classification_loss": 0.6043797135353088,
      "epoch": 11.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1975332647562027,
      "orthogonal_weight": 0.1,
      "step": 3448,
      "total_loss": 0.6241330504417419,
      "weighted_orthogonal_loss": 0.01975332759320736
    },
    {
      "classification_loss": 0.6111614108085632,
      "epoch": 11.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1976338028907776,
      "orthogonal_weight": 0.1,
      "step": 3449,
      "total_loss": 0.6309248208999634,
      "weighted_orthogonal_loss": 0.01976338028907776
    },
    {
      "classification_loss": 0.5748581290245056,
      "epoch": 11.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19769562780857086,
      "orthogonal_weight": 0.1,
      "step": 3450,
      "total_loss": 0.5946276783943176,
      "weighted_orthogonal_loss": 0.019769562408328056
    },
    {
      "classification_loss": 0.6016968488693237,
      "epoch": 11.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1977357417345047,
      "orthogonal_weight": 0.1,
      "step": 3451,
      "total_loss": 0.6214704513549805,
      "weighted_orthogonal_loss": 0.0197735745459795
    },
    {
      "classification_loss": 0.6742215752601624,
      "epoch": 11.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19789281487464905,
      "orthogonal_weight": 0.1,
      "step": 3452,
      "total_loss": 0.694010853767395,
      "weighted_orthogonal_loss": 0.019789282232522964
    },
    {
      "classification_loss": 0.6334710121154785,
      "epoch": 11.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1980224996805191,
      "orthogonal_weight": 0.1,
      "step": 3453,
      "total_loss": 0.6532732844352722,
      "weighted_orthogonal_loss": 0.01980224996805191
    },
    {
      "classification_loss": 0.589356541633606,
      "epoch": 11.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1981550008058548,
      "orthogonal_weight": 0.1,
      "step": 3454,
      "total_loss": 0.6091720461845398,
      "weighted_orthogonal_loss": 0.01981550082564354
    },
    {
      "classification_loss": 0.6186953186988831,
      "epoch": 11.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19816751778125763,
      "orthogonal_weight": 0.1,
      "step": 3455,
      "total_loss": 0.6385120749473572,
      "weighted_orthogonal_loss": 0.019816752523183823
    },
    {
      "classification_loss": 0.6923904418945312,
      "epoch": 11.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982221156358719,
      "orthogonal_weight": 0.1,
      "step": 3456,
      "total_loss": 0.7122126817703247,
      "weighted_orthogonal_loss": 0.01982221193611622
    },
    {
      "classification_loss": 0.7148393392562866,
      "epoch": 11.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1982845813035965,
      "orthogonal_weight": 0.1,
      "step": 3457,
      "total_loss": 0.7346677780151367,
      "weighted_orthogonal_loss": 0.01982845924794674
    },
    {
      "classification_loss": 0.5246707201004028,
      "epoch": 11.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19835662841796875,
      "orthogonal_weight": 0.1,
      "step": 3458,
      "total_loss": 0.5445063710212708,
      "weighted_orthogonal_loss": 0.019835663959383965
    },
    {
      "classification_loss": 0.5638458132743835,
      "epoch": 11.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19861942529678345,
      "orthogonal_weight": 0.1,
      "step": 3459,
      "total_loss": 0.5837077498435974,
      "weighted_orthogonal_loss": 0.019861942157149315
    },
    {
      "classification_loss": 0.6707737445831299,
      "epoch": 11.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19885513186454773,
      "orthogonal_weight": 0.1,
      "step": 3460,
      "total_loss": 0.6906592845916748,
      "weighted_orthogonal_loss": 0.019885513931512833
    },
    {
      "classification_loss": 0.657095193862915,
      "epoch": 11.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1990971714258194,
      "orthogonal_weight": 0.1,
      "step": 3461,
      "total_loss": 0.6770049333572388,
      "weighted_orthogonal_loss": 0.01990971714258194
    },
    {
      "classification_loss": 0.5979017019271851,
      "epoch": 11.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19932027161121368,
      "orthogonal_weight": 0.1,
      "step": 3462,
      "total_loss": 0.6178337335586548,
      "weighted_orthogonal_loss": 0.019932027906179428
    },
    {
      "classification_loss": 0.6284440755844116,
      "epoch": 11.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19952765107154846,
      "orthogonal_weight": 0.1,
      "step": 3463,
      "total_loss": 0.6483968496322632,
      "weighted_orthogonal_loss": 0.019952764734625816
    },
    {
      "classification_loss": 0.6946005821228027,
      "epoch": 11.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19970937073230743,
      "orthogonal_weight": 0.1,
      "step": 3464,
      "total_loss": 0.7145715355873108,
      "weighted_orthogonal_loss": 0.019970936700701714
    },
    {
      "classification_loss": 0.5941193699836731,
      "epoch": 11.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19947941601276398,
      "orthogonal_weight": 0.1,
      "step": 3465,
      "total_loss": 0.6140673160552979,
      "weighted_orthogonal_loss": 0.019947942346334457
    },
    {
      "classification_loss": 0.619376003742218,
      "epoch": 11.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19928637146949768,
      "orthogonal_weight": 0.1,
      "step": 3466,
      "total_loss": 0.6393046379089355,
      "weighted_orthogonal_loss": 0.019928637892007828
    },
    {
      "classification_loss": 0.5768002867698669,
      "epoch": 11.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19915278255939484,
      "orthogonal_weight": 0.1,
      "step": 3467,
      "total_loss": 0.5967155694961548,
      "weighted_orthogonal_loss": 0.019915279000997543
    },
    {
      "classification_loss": 0.5844253301620483,
      "epoch": 11.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1990308314561844,
      "orthogonal_weight": 0.1,
      "step": 3468,
      "total_loss": 0.6043283939361572,
      "weighted_orthogonal_loss": 0.019903084263205528
    },
    {
      "classification_loss": 0.6347445845603943,
      "epoch": 11.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1989610195159912,
      "orthogonal_weight": 0.1,
      "step": 3469,
      "total_loss": 0.6546406745910645,
      "weighted_orthogonal_loss": 0.01989610306918621
    },
    {
      "classification_loss": 0.6752079129219055,
      "epoch": 11.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1988721340894699,
      "orthogonal_weight": 0.1,
      "step": 3470,
      "total_loss": 0.6950951218605042,
      "weighted_orthogonal_loss": 0.01988721452653408
    },
    {
      "classification_loss": 0.6776596307754517,
      "epoch": 11.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987634152173996,
      "orthogonal_weight": 0.1,
      "step": 3471,
      "total_loss": 0.6975359916687012,
      "weighted_orthogonal_loss": 0.01987634226679802
    },
    {
      "classification_loss": 0.6717751622200012,
      "epoch": 11.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1986660659313202,
      "orthogonal_weight": 0.1,
      "step": 3472,
      "total_loss": 0.6916417479515076,
      "weighted_orthogonal_loss": 0.01986660622060299
    },
    {
      "classification_loss": 0.6847217082977295,
      "epoch": 11.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.198569655418396,
      "orthogonal_weight": 0.1,
      "step": 3473,
      "total_loss": 0.704578697681427,
      "weighted_orthogonal_loss": 0.01985696516931057
    },
    {
      "classification_loss": 0.6246074438095093,
      "epoch": 11.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19853948056697845,
      "orthogonal_weight": 0.1,
      "step": 3474,
      "total_loss": 0.6444613933563232,
      "weighted_orthogonal_loss": 0.019853947684168816
    },
    {
      "classification_loss": 0.6341354846954346,
      "epoch": 11.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19849257171154022,
      "orthogonal_weight": 0.1,
      "step": 3475,
      "total_loss": 0.6539847254753113,
      "weighted_orthogonal_loss": 0.019849257543683052
    },
    {
      "classification_loss": 0.6410112977027893,
      "epoch": 11.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984071284532547,
      "orthogonal_weight": 0.1,
      "step": 3476,
      "total_loss": 0.6608520150184631,
      "weighted_orthogonal_loss": 0.01984071359038353
    },
    {
      "classification_loss": 0.5814054608345032,
      "epoch": 11.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983449012041092,
      "orthogonal_weight": 0.1,
      "step": 3477,
      "total_loss": 0.6012399792671204,
      "weighted_orthogonal_loss": 0.01983449049293995
    },
    {
      "classification_loss": 0.6398166418075562,
      "epoch": 11.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19832377135753632,
      "orthogonal_weight": 0.1,
      "step": 3478,
      "total_loss": 0.6596490144729614,
      "weighted_orthogonal_loss": 0.01983237825334072
    },
    {
      "classification_loss": 0.602337121963501,
      "epoch": 11.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19829602539539337,
      "orthogonal_weight": 0.1,
      "step": 3479,
      "total_loss": 0.6221667528152466,
      "weighted_orthogonal_loss": 0.019829602912068367
    },
    {
      "classification_loss": 0.5657230019569397,
      "epoch": 11.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19819988310337067,
      "orthogonal_weight": 0.1,
      "step": 3480,
      "total_loss": 0.5855429768562317,
      "weighted_orthogonal_loss": 0.019819987937808037
    },
    {
      "classification_loss": 0.65837562084198,
      "epoch": 11.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1981383115053177,
      "orthogonal_weight": 0.1,
      "step": 3481,
      "total_loss": 0.6781894564628601,
      "weighted_orthogonal_loss": 0.01981383189558983
    },
    {
      "classification_loss": 0.6648716926574707,
      "epoch": 11.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19808264076709747,
      "orthogonal_weight": 0.1,
      "step": 3482,
      "total_loss": 0.6846799850463867,
      "weighted_orthogonal_loss": 0.019808264449238777
    },
    {
      "classification_loss": 0.5984891057014465,
      "epoch": 11.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19803780317306519,
      "orthogonal_weight": 0.1,
      "step": 3483,
      "total_loss": 0.6182928681373596,
      "weighted_orthogonal_loss": 0.019803781062364578
    },
    {
      "classification_loss": 0.6141729950904846,
      "epoch": 11.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19802209734916687,
      "orthogonal_weight": 0.1,
      "step": 3484,
      "total_loss": 0.6339752078056335,
      "weighted_orthogonal_loss": 0.019802210852503777
    },
    {
      "classification_loss": 0.5913518071174622,
      "epoch": 11.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19829292595386505,
      "orthogonal_weight": 0.1,
      "step": 3485,
      "total_loss": 0.6111810803413391,
      "weighted_orthogonal_loss": 0.019829293712973595
    },
    {
      "classification_loss": 0.6303741335868835,
      "epoch": 11.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19857195019721985,
      "orthogonal_weight": 0.1,
      "step": 3486,
      "total_loss": 0.6502313017845154,
      "weighted_orthogonal_loss": 0.019857196137309074
    },
    {
      "classification_loss": 0.6944701075553894,
      "epoch": 11.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19886614382266998,
      "orthogonal_weight": 0.1,
      "step": 3487,
      "total_loss": 0.7143567204475403,
      "weighted_orthogonal_loss": 0.019886614754796028
    },
    {
      "classification_loss": 0.6135870218276978,
      "epoch": 11.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19909730553627014,
      "orthogonal_weight": 0.1,
      "step": 3488,
      "total_loss": 0.6334967613220215,
      "weighted_orthogonal_loss": 0.019909730181097984
    },
    {
      "classification_loss": 0.6245383024215698,
      "epoch": 11.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19927234947681427,
      "orthogonal_weight": 0.1,
      "step": 3489,
      "total_loss": 0.6444655656814575,
      "weighted_orthogonal_loss": 0.019927235320210457
    },
    {
      "classification_loss": 0.6085485816001892,
      "epoch": 11.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1994108408689499,
      "orthogonal_weight": 0.1,
      "step": 3490,
      "total_loss": 0.6284896731376648,
      "weighted_orthogonal_loss": 0.01994108408689499
    },
    {
      "classification_loss": 0.6326496601104736,
      "epoch": 11.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1995438188314438,
      "orthogonal_weight": 0.1,
      "step": 3491,
      "total_loss": 0.6526040434837341,
      "weighted_orthogonal_loss": 0.01995438151061535
    },
    {
      "classification_loss": 0.549893856048584,
      "epoch": 11.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19969207048416138,
      "orthogonal_weight": 0.1,
      "step": 3492,
      "total_loss": 0.5698630809783936,
      "weighted_orthogonal_loss": 0.019969208166003227
    },
    {
      "classification_loss": 0.6801932454109192,
      "epoch": 11.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19985856115818024,
      "orthogonal_weight": 0.1,
      "step": 3493,
      "total_loss": 0.7001791000366211,
      "weighted_orthogonal_loss": 0.019985856488347054
    },
    {
      "classification_loss": 0.5550642609596252,
      "epoch": 11.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2000373899936676,
      "orthogonal_weight": 0.1,
      "step": 3494,
      "total_loss": 0.5750679969787598,
      "weighted_orthogonal_loss": 0.02000373974442482
    },
    {
      "classification_loss": 0.6630894541740417,
      "epoch": 11.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2002248913049698,
      "orthogonal_weight": 0.1,
      "step": 3495,
      "total_loss": 0.6831119656562805,
      "weighted_orthogonal_loss": 0.02002248913049698
    },
    {
      "classification_loss": 0.6246228218078613,
      "epoch": 11.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2003827840089798,
      "orthogonal_weight": 0.1,
      "step": 3496,
      "total_loss": 0.6446611285209656,
      "weighted_orthogonal_loss": 0.02003827877342701
    },
    {
      "classification_loss": 0.6450607776641846,
      "epoch": 11.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20041993260383606,
      "orthogonal_weight": 0.1,
      "step": 3497,
      "total_loss": 0.6651027798652649,
      "weighted_orthogonal_loss": 0.020041992887854576
    },
    {
      "classification_loss": 0.6057057976722717,
      "epoch": 11.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20046718418598175,
      "orthogonal_weight": 0.1,
      "step": 3498,
      "total_loss": 0.6257525086402893,
      "weighted_orthogonal_loss": 0.020046718418598175
    },
    {
      "classification_loss": 0.6394599676132202,
      "epoch": 11.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2005114108324051,
      "orthogonal_weight": 0.1,
      "step": 3499,
      "total_loss": 0.6595110893249512,
      "weighted_orthogonal_loss": 0.0200511422008276
    },
    {
      "epoch": 11.475409836065573,
      "grad_norm": 24.843175888061523,
      "learning_rate": 8.67e-05,
      "loss": 0.6407,
      "step": 3500
    },
    {
      "classification_loss": 0.5348909497261047,
      "epoch": 11.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20052242279052734,
      "orthogonal_weight": 0.1,
      "step": 3500,
      "total_loss": 0.5549432039260864,
      "weighted_orthogonal_loss": 0.020052243024110794
    },
    {
      "classification_loss": 0.6499337553977966,
      "epoch": 11.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2005283534526825,
      "orthogonal_weight": 0.1,
      "step": 3501,
      "total_loss": 0.6699866056442261,
      "weighted_orthogonal_loss": 0.02005283534526825
    },
    {
      "classification_loss": 0.6034740805625916,
      "epoch": 11.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2005608230829239,
      "orthogonal_weight": 0.1,
      "step": 3502,
      "total_loss": 0.6235301494598389,
      "weighted_orthogonal_loss": 0.02005608193576336
    },
    {
      "classification_loss": 0.5877653360366821,
      "epoch": 11.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20057378709316254,
      "orthogonal_weight": 0.1,
      "step": 3503,
      "total_loss": 0.6078227162361145,
      "weighted_orthogonal_loss": 0.020057378336787224
    },
    {
      "classification_loss": 0.6182375550270081,
      "epoch": 11.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20053941011428833,
      "orthogonal_weight": 0.1,
      "step": 3504,
      "total_loss": 0.6382914781570435,
      "weighted_orthogonal_loss": 0.020053941756486893
    },
    {
      "classification_loss": 0.6413666605949402,
      "epoch": 11.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2005024403333664,
      "orthogonal_weight": 0.1,
      "step": 3505,
      "total_loss": 0.6614168882369995,
      "weighted_orthogonal_loss": 0.02005024440586567
    },
    {
      "classification_loss": 0.6538525223731995,
      "epoch": 11.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20041902363300323,
      "orthogonal_weight": 0.1,
      "step": 3506,
      "total_loss": 0.6738944053649902,
      "weighted_orthogonal_loss": 0.020041903480887413
    },
    {
      "classification_loss": 0.5822178721427917,
      "epoch": 11.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20024612545967102,
      "orthogonal_weight": 0.1,
      "step": 3507,
      "total_loss": 0.6022424697875977,
      "weighted_orthogonal_loss": 0.020024612545967102
    },
    {
      "classification_loss": 0.5936388969421387,
      "epoch": 11.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20004862546920776,
      "orthogonal_weight": 0.1,
      "step": 3508,
      "total_loss": 0.6136437654495239,
      "weighted_orthogonal_loss": 0.020004862919449806
    },
    {
      "classification_loss": 0.5823099613189697,
      "epoch": 11.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19986043870449066,
      "orthogonal_weight": 0.1,
      "step": 3509,
      "total_loss": 0.602295994758606,
      "weighted_orthogonal_loss": 0.019986044615507126
    },
    {
      "classification_loss": 0.6568015217781067,
      "epoch": 11.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1996176689863205,
      "orthogonal_weight": 0.1,
      "step": 3510,
      "total_loss": 0.6767632961273193,
      "weighted_orthogonal_loss": 0.01996176689863205
    },
    {
      "classification_loss": 0.5950485467910767,
      "epoch": 11.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1994381844997406,
      "orthogonal_weight": 0.1,
      "step": 3511,
      "total_loss": 0.6149923801422119,
      "weighted_orthogonal_loss": 0.01994381844997406
    },
    {
      "classification_loss": 0.6233565807342529,
      "epoch": 11.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19925734400749207,
      "orthogonal_weight": 0.1,
      "step": 3512,
      "total_loss": 0.6432822942733765,
      "weighted_orthogonal_loss": 0.019925734028220177
    },
    {
      "classification_loss": 0.6402203440666199,
      "epoch": 11.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.199071004986763,
      "orthogonal_weight": 0.1,
      "step": 3513,
      "total_loss": 0.6601274609565735,
      "weighted_orthogonal_loss": 0.01990710012614727
    },
    {
      "classification_loss": 0.7189162969589233,
      "epoch": 11.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1989148110151291,
      "orthogonal_weight": 0.1,
      "step": 3514,
      "total_loss": 0.7388077974319458,
      "weighted_orthogonal_loss": 0.01989148184657097
    },
    {
      "classification_loss": 0.6421436667442322,
      "epoch": 11.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987963318824768,
      "orthogonal_weight": 0.1,
      "step": 3515,
      "total_loss": 0.6620233058929443,
      "weighted_orthogonal_loss": 0.01987963356077671
    },
    {
      "classification_loss": 0.6035761833190918,
      "epoch": 11.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987353414297104,
      "orthogonal_weight": 0.1,
      "step": 3516,
      "total_loss": 0.6234497427940369,
      "weighted_orthogonal_loss": 0.01987353526055813
    },
    {
      "classification_loss": 0.6035647392272949,
      "epoch": 11.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19870342314243317,
      "orthogonal_weight": 0.1,
      "step": 3517,
      "total_loss": 0.6234350800514221,
      "weighted_orthogonal_loss": 0.019870342686772346
    },
    {
      "classification_loss": 0.5829825401306152,
      "epoch": 11.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19872136414051056,
      "orthogonal_weight": 0.1,
      "step": 3518,
      "total_loss": 0.6028546690940857,
      "weighted_orthogonal_loss": 0.019872136414051056
    },
    {
      "classification_loss": 0.6222354173660278,
      "epoch": 11.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.198747918009758,
      "orthogonal_weight": 0.1,
      "step": 3519,
      "total_loss": 0.6421102285385132,
      "weighted_orthogonal_loss": 0.01987479254603386
    },
    {
      "classification_loss": 0.5356424450874329,
      "epoch": 11.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987587958574295,
      "orthogonal_weight": 0.1,
      "step": 3520,
      "total_loss": 0.5555183291435242,
      "weighted_orthogonal_loss": 0.01987588033080101
    },
    {
      "classification_loss": 0.6289764046669006,
      "epoch": 11.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987992376089096,
      "orthogonal_weight": 0.1,
      "step": 3521,
      "total_loss": 0.6488563418388367,
      "weighted_orthogonal_loss": 0.01987992413341999
    },
    {
      "classification_loss": 0.6353176832199097,
      "epoch": 11.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19886377453804016,
      "orthogonal_weight": 0.1,
      "step": 3522,
      "total_loss": 0.6552040576934814,
      "weighted_orthogonal_loss": 0.019886378198862076
    },
    {
      "classification_loss": 0.6226377487182617,
      "epoch": 11.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19890077412128448,
      "orthogonal_weight": 0.1,
      "step": 3523,
      "total_loss": 0.6425278186798096,
      "weighted_orthogonal_loss": 0.01989007741212845
    },
    {
      "classification_loss": 0.6263144612312317,
      "epoch": 11.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19888825714588165,
      "orthogonal_weight": 0.1,
      "step": 3524,
      "total_loss": 0.6462032794952393,
      "weighted_orthogonal_loss": 0.019888825714588165
    },
    {
      "classification_loss": 0.5782173871994019,
      "epoch": 11.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1987995058298111,
      "orthogonal_weight": 0.1,
      "step": 3525,
      "total_loss": 0.5980973243713379,
      "weighted_orthogonal_loss": 0.01987995021045208
    },
    {
      "classification_loss": 0.6893696784973145,
      "epoch": 11.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19870604574680328,
      "orthogonal_weight": 0.1,
      "step": 3526,
      "total_loss": 0.7092402577400208,
      "weighted_orthogonal_loss": 0.019870605319738388
    },
    {
      "classification_loss": 0.6540466547012329,
      "epoch": 11.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19858993589878082,
      "orthogonal_weight": 0.1,
      "step": 3527,
      "total_loss": 0.6739056706428528,
      "weighted_orthogonal_loss": 0.019858993589878082
    },
    {
      "classification_loss": 0.6132566928863525,
      "epoch": 11.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1985853761434555,
      "orthogonal_weight": 0.1,
      "step": 3528,
      "total_loss": 0.6331152319908142,
      "weighted_orthogonal_loss": 0.01985853724181652
    },
    {
      "classification_loss": 0.5950912237167358,
      "epoch": 11.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19851604104042053,
      "orthogonal_weight": 0.1,
      "step": 3529,
      "total_loss": 0.6149428486824036,
      "weighted_orthogonal_loss": 0.019851604476571083
    },
    {
      "classification_loss": 0.6958813667297363,
      "epoch": 11.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19842684268951416,
      "orthogonal_weight": 0.1,
      "step": 3530,
      "total_loss": 0.7157240509986877,
      "weighted_orthogonal_loss": 0.019842684268951416
    },
    {
      "classification_loss": 0.6530783772468567,
      "epoch": 11.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19837971031665802,
      "orthogonal_weight": 0.1,
      "step": 3531,
      "total_loss": 0.6729163527488708,
      "weighted_orthogonal_loss": 0.01983797177672386
    },
    {
      "classification_loss": 0.5706225633621216,
      "epoch": 11.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983644813299179,
      "orthogonal_weight": 0.1,
      "step": 3532,
      "total_loss": 0.5904589891433716,
      "weighted_orthogonal_loss": 0.01983644813299179
    },
    {
      "classification_loss": 0.6307015419006348,
      "epoch": 11.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983998566865921,
      "orthogonal_weight": 0.1,
      "step": 3533,
      "total_loss": 0.6505415439605713,
      "weighted_orthogonal_loss": 0.01983998529613018
    },
    {
      "classification_loss": 0.6368873715400696,
      "epoch": 11.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1984509974718094,
      "orthogonal_weight": 0.1,
      "step": 3534,
      "total_loss": 0.6567324995994568,
      "weighted_orthogonal_loss": 0.01984510011970997
    },
    {
      "classification_loss": 0.6399344205856323,
      "epoch": 11.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1985277533531189,
      "orthogonal_weight": 0.1,
      "step": 3535,
      "total_loss": 0.6597871780395508,
      "weighted_orthogonal_loss": 0.01985277608036995
    },
    {
      "classification_loss": 0.7087293267250061,
      "epoch": 11.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1985766589641571,
      "orthogonal_weight": 0.1,
      "step": 3536,
      "total_loss": 0.7285869717597961,
      "weighted_orthogonal_loss": 0.01985766552388668
    },
    {
      "classification_loss": 0.657031774520874,
      "epoch": 11.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19851689040660858,
      "orthogonal_weight": 0.1,
      "step": 3537,
      "total_loss": 0.6768834590911865,
      "weighted_orthogonal_loss": 0.019851690158247948
    },
    {
      "classification_loss": 0.6268510818481445,
      "epoch": 11.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19843600690364838,
      "orthogonal_weight": 0.1,
      "step": 3538,
      "total_loss": 0.6466946601867676,
      "weighted_orthogonal_loss": 0.019843600690364838
    },
    {
      "classification_loss": 0.6528908610343933,
      "epoch": 11.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19836416840553284,
      "orthogonal_weight": 0.1,
      "step": 3539,
      "total_loss": 0.6727272868156433,
      "weighted_orthogonal_loss": 0.019836416468024254
    },
    {
      "classification_loss": 0.6405407190322876,
      "epoch": 11.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983015239238739,
      "orthogonal_weight": 0.1,
      "step": 3540,
      "total_loss": 0.6603708863258362,
      "weighted_orthogonal_loss": 0.01983015239238739
    },
    {
      "classification_loss": 0.7119734883308411,
      "epoch": 11.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19823355972766876,
      "orthogonal_weight": 0.1,
      "step": 3541,
      "total_loss": 0.7317968606948853,
      "weighted_orthogonal_loss": 0.019823355600237846
    },
    {
      "classification_loss": 0.5469262599945068,
      "epoch": 11.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19819214940071106,
      "orthogonal_weight": 0.1,
      "step": 3542,
      "total_loss": 0.5667454600334167,
      "weighted_orthogonal_loss": 0.019819214940071106
    },
    {
      "classification_loss": 0.6483120322227478,
      "epoch": 11.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1981673687696457,
      "orthogonal_weight": 0.1,
      "step": 3543,
      "total_loss": 0.6681287884712219,
      "weighted_orthogonal_loss": 0.01981673762202263
    },
    {
      "classification_loss": 0.7061789035797119,
      "epoch": 11.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19809642434120178,
      "orthogonal_weight": 0.1,
      "step": 3544,
      "total_loss": 0.7259885668754578,
      "weighted_orthogonal_loss": 0.019809642806649208
    },
    {
      "classification_loss": 0.5770228505134583,
      "epoch": 11.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19799426198005676,
      "orthogonal_weight": 0.1,
      "step": 3545,
      "total_loss": 0.5968222618103027,
      "weighted_orthogonal_loss": 0.019799426198005676
    },
    {
      "classification_loss": 0.7156651020050049,
      "epoch": 11.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197958305478096,
      "orthogonal_weight": 0.1,
      "step": 3546,
      "total_loss": 0.7354609370231628,
      "weighted_orthogonal_loss": 0.01979583129286766
    },
    {
      "classification_loss": 0.6623191237449646,
      "epoch": 11.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19794557988643646,
      "orthogonal_weight": 0.1,
      "step": 3547,
      "total_loss": 0.6821137070655823,
      "weighted_orthogonal_loss": 0.019794559106230736
    },
    {
      "classification_loss": 0.6422932744026184,
      "epoch": 11.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19792599976062775,
      "orthogonal_weight": 0.1,
      "step": 3548,
      "total_loss": 0.6620858907699585,
      "weighted_orthogonal_loss": 0.019792599603533745
    },
    {
      "classification_loss": 0.6882039308547974,
      "epoch": 11.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19774581491947174,
      "orthogonal_weight": 0.1,
      "step": 3549,
      "total_loss": 0.7079784870147705,
      "weighted_orthogonal_loss": 0.019774582237005234
    },
    {
      "classification_loss": 0.6363785862922668,
      "epoch": 11.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19761599600315094,
      "orthogonal_weight": 0.1,
      "step": 3550,
      "total_loss": 0.6561402082443237,
      "weighted_orthogonal_loss": 0.019761599600315094
    },
    {
      "classification_loss": 0.629967987537384,
      "epoch": 11.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1975182443857193,
      "orthogonal_weight": 0.1,
      "step": 3551,
      "total_loss": 0.6497198343276978,
      "weighted_orthogonal_loss": 0.01975182443857193
    },
    {
      "classification_loss": 0.6991011500358582,
      "epoch": 11.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19763995707035065,
      "orthogonal_weight": 0.1,
      "step": 3552,
      "total_loss": 0.718865156173706,
      "weighted_orthogonal_loss": 0.019763996824622154
    },
    {
      "classification_loss": 0.6487696170806885,
      "epoch": 11.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.197777658700943,
      "orthogonal_weight": 0.1,
      "step": 3553,
      "total_loss": 0.6685473918914795,
      "weighted_orthogonal_loss": 0.01977776549756527
    },
    {
      "classification_loss": 0.6146908402442932,
      "epoch": 11.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19797149300575256,
      "orthogonal_weight": 0.1,
      "step": 3554,
      "total_loss": 0.6344879865646362,
      "weighted_orthogonal_loss": 0.019797150045633316
    },
    {
      "classification_loss": 0.6793613433837891,
      "epoch": 11.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19806277751922607,
      "orthogonal_weight": 0.1,
      "step": 3555,
      "total_loss": 0.6991676092147827,
      "weighted_orthogonal_loss": 0.019806278869509697
    },
    {
      "classification_loss": 0.6416382193565369,
      "epoch": 11.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19821088016033173,
      "orthogonal_weight": 0.1,
      "step": 3556,
      "total_loss": 0.6614593267440796,
      "weighted_orthogonal_loss": 0.019821088761091232
    },
    {
      "classification_loss": 0.6844842433929443,
      "epoch": 11.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1983834058046341,
      "orthogonal_weight": 0.1,
      "step": 3557,
      "total_loss": 0.7043225765228271,
      "weighted_orthogonal_loss": 0.01983834058046341
    },
    {
      "classification_loss": 0.6169386506080627,
      "epoch": 11.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19853967428207397,
      "orthogonal_weight": 0.1,
      "step": 3558,
      "total_loss": 0.6367926001548767,
      "weighted_orthogonal_loss": 0.019853968173265457
    },
    {
      "classification_loss": 0.622760534286499,
      "epoch": 11.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1986788958311081,
      "orthogonal_weight": 0.1,
      "step": 3559,
      "total_loss": 0.6426284313201904,
      "weighted_orthogonal_loss": 0.01986788958311081
    },
    {
      "classification_loss": 0.5440108776092529,
      "epoch": 11.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19879110157489777,
      "orthogonal_weight": 0.1,
      "step": 3560,
      "total_loss": 0.5638899803161621,
      "weighted_orthogonal_loss": 0.019879110157489777
    },
    {
      "classification_loss": 0.6165128946304321,
      "epoch": 11.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19889555871486664,
      "orthogonal_weight": 0.1,
      "step": 3561,
      "total_loss": 0.636402428150177,
      "weighted_orthogonal_loss": 0.019889555871486664
    },
    {
      "classification_loss": 0.6571109294891357,
      "epoch": 11.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19903521239757538,
      "orthogonal_weight": 0.1,
      "step": 3562,
      "total_loss": 0.6770144701004028,
      "weighted_orthogonal_loss": 0.019903521984815598
    },
    {
      "classification_loss": 0.659576952457428,
      "epoch": 11.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19921644032001495,
      "orthogonal_weight": 0.1,
      "step": 3563,
      "total_loss": 0.6794986128807068,
      "weighted_orthogonal_loss": 0.019921643659472466
    },
    {
      "classification_loss": 0.6285961270332336,
      "epoch": 11.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.19947198033332825,
      "orthogonal_weight": 0.1,
      "step": 3564,
      "total_loss": 0.6485432982444763,
      "weighted_orthogonal_loss": 0.019947199150919914
    },
    {
      "classification_loss": 0.6466718912124634,
      "epoch": 11.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.1997768133878708,
      "orthogonal_weight": 0.1,
      "step": 3565,
      "total_loss": 0.666649580001831,
      "weighted_orthogonal_loss": 0.01997768133878708
    },
    {
      "classification_loss": 0.6053555607795715,
      "epoch": 11.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20005126297473907,
      "orthogonal_weight": 0.1,
      "step": 3566,
      "total_loss": 0.6253606677055359,
      "weighted_orthogonal_loss": 0.020005127415060997
    },
    {
      "classification_loss": 0.6047618389129639,
      "epoch": 11.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20027902722358704,
      "orthogonal_weight": 0.1,
      "step": 3567,
      "total_loss": 0.6247897148132324,
      "weighted_orthogonal_loss": 0.020027903839945793
    },
    {
      "classification_loss": 0.685771644115448,
      "epoch": 11.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20043623447418213,
      "orthogonal_weight": 0.1,
      "step": 3568,
      "total_loss": 0.7058152556419373,
      "weighted_orthogonal_loss": 0.020043624565005302
    },
    {
      "classification_loss": 0.6248801350593567,
      "epoch": 11.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20056556165218353,
      "orthogonal_weight": 0.1,
      "step": 3569,
      "total_loss": 0.6449366807937622,
      "weighted_orthogonal_loss": 0.020056556910276413
    },
    {
      "classification_loss": 0.6008397340774536,
      "epoch": 11.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2006935030221939,
      "orthogonal_weight": 0.1,
      "step": 3570,
      "total_loss": 0.6209090948104858,
      "weighted_orthogonal_loss": 0.02006935141980648
    },
    {
      "classification_loss": 0.6045106649398804,
      "epoch": 11.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20087146759033203,
      "orthogonal_weight": 0.1,
      "step": 3571,
      "total_loss": 0.6245977878570557,
      "weighted_orthogonal_loss": 0.020087147131562233
    },
    {
      "classification_loss": 0.5469591021537781,
      "epoch": 11.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20101605355739594,
      "orthogonal_weight": 0.1,
      "step": 3572,
      "total_loss": 0.5670607089996338,
      "weighted_orthogonal_loss": 0.020101604983210564
    },
    {
      "classification_loss": 0.5888016223907471,
      "epoch": 11.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20117756724357605,
      "orthogonal_weight": 0.1,
      "step": 3573,
      "total_loss": 0.6089193820953369,
      "weighted_orthogonal_loss": 0.020117757841944695
    },
    {
      "classification_loss": 0.58711838722229,
      "epoch": 11.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20130659639835358,
      "orthogonal_weight": 0.1,
      "step": 3574,
      "total_loss": 0.6072490215301514,
      "weighted_orthogonal_loss": 0.020130660384893417
    },
    {
      "classification_loss": 0.6501858234405518,
      "epoch": 11.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2014099508523941,
      "orthogonal_weight": 0.1,
      "step": 3575,
      "total_loss": 0.670326828956604,
      "weighted_orthogonal_loss": 0.0201409962028265
    },
    {
      "classification_loss": 0.621447741985321,
      "epoch": 11.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20146319270133972,
      "orthogonal_weight": 0.1,
      "step": 3576,
      "total_loss": 0.6415940523147583,
      "weighted_orthogonal_loss": 0.020146319642663002
    },
    {
      "classification_loss": 0.6185763478279114,
      "epoch": 11.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20151473581790924,
      "orthogonal_weight": 0.1,
      "step": 3577,
      "total_loss": 0.6387278437614441,
      "weighted_orthogonal_loss": 0.020151473581790924
    },
    {
      "classification_loss": 0.5506779551506042,
      "epoch": 11.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20160524547100067,
      "orthogonal_weight": 0.1,
      "step": 3578,
      "total_loss": 0.570838451385498,
      "weighted_orthogonal_loss": 0.020160524174571037
    },
    {
      "classification_loss": 0.6006315350532532,
      "epoch": 11.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20171576738357544,
      "orthogonal_weight": 0.1,
      "step": 3579,
      "total_loss": 0.6208031177520752,
      "weighted_orthogonal_loss": 0.020171577110886574
    },
    {
      "classification_loss": 0.6961484551429749,
      "epoch": 11.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20186316967010498,
      "orthogonal_weight": 0.1,
      "step": 3580,
      "total_loss": 0.7163347601890564,
      "weighted_orthogonal_loss": 0.020186318084597588
    },
    {
      "classification_loss": 0.6150558590888977,
      "epoch": 11.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2019249051809311,
      "orthogonal_weight": 0.1,
      "step": 3581,
      "total_loss": 0.6352483630180359,
      "weighted_orthogonal_loss": 0.02019249089062214
    },
    {
      "classification_loss": 0.6008940935134888,
      "epoch": 11.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20201225578784943,
      "orthogonal_weight": 0.1,
      "step": 3582,
      "total_loss": 0.6210952997207642,
      "weighted_orthogonal_loss": 0.020201226696372032
    },
    {
      "classification_loss": 0.6464874148368835,
      "epoch": 11.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20209261775016785,
      "orthogonal_weight": 0.1,
      "step": 3583,
      "total_loss": 0.6666966676712036,
      "weighted_orthogonal_loss": 0.020209262147545815
    },
    {
      "classification_loss": 0.6135347485542297,
      "epoch": 11.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20214413106441498,
      "orthogonal_weight": 0.1,
      "step": 3584,
      "total_loss": 0.6337491869926453,
      "weighted_orthogonal_loss": 0.020214414224028587
    },
    {
      "classification_loss": 0.6731067895889282,
      "epoch": 11.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021765261888504,
      "orthogonal_weight": 0.1,
      "step": 3585,
      "total_loss": 0.6933244466781616,
      "weighted_orthogonal_loss": 0.0202176533639431
    },
    {
      "classification_loss": 0.5800485610961914,
      "epoch": 11.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20223687589168549,
      "orthogonal_weight": 0.1,
      "step": 3586,
      "total_loss": 0.6002722382545471,
      "weighted_orthogonal_loss": 0.02022368833422661
    },
    {
      "classification_loss": 0.7133066654205322,
      "epoch": 11.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20237451791763306,
      "orthogonal_weight": 0.1,
      "step": 3587,
      "total_loss": 0.733544111251831,
      "weighted_orthogonal_loss": 0.020237451419234276
    },
    {
      "classification_loss": 0.6764195561408997,
      "epoch": 11.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20237509906291962,
      "orthogonal_weight": 0.1,
      "step": 3588,
      "total_loss": 0.6966570615768433,
      "weighted_orthogonal_loss": 0.02023751102387905
    },
    {
      "classification_loss": 0.631406307220459,
      "epoch": 11.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20235900580883026,
      "orthogonal_weight": 0.1,
      "step": 3589,
      "total_loss": 0.6516422033309937,
      "weighted_orthogonal_loss": 0.020235901698470116
    },
    {
      "classification_loss": 0.6707301139831543,
      "epoch": 11.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20216187834739685,
      "orthogonal_weight": 0.1,
      "step": 3590,
      "total_loss": 0.6909462809562683,
      "weighted_orthogonal_loss": 0.020216187462210655
    },
    {
      "classification_loss": 0.5903744697570801,
      "epoch": 11.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20201709866523743,
      "orthogonal_weight": 0.1,
      "step": 3591,
      "total_loss": 0.6105761528015137,
      "weighted_orthogonal_loss": 0.020201710984110832
    },
    {
      "classification_loss": 0.5511197447776794,
      "epoch": 11.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20198765397071838,
      "orthogonal_weight": 0.1,
      "step": 3592,
      "total_loss": 0.571318507194519,
      "weighted_orthogonal_loss": 0.020198766142129898
    },
    {
      "classification_loss": 0.6546164155006409,
      "epoch": 11.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20193451642990112,
      "orthogonal_weight": 0.1,
      "step": 3593,
      "total_loss": 0.6748098731040955,
      "weighted_orthogonal_loss": 0.020193452015519142
    },
    {
      "classification_loss": 0.5908384323120117,
      "epoch": 11.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2019132375717163,
      "orthogonal_weight": 0.1,
      "step": 3594,
      "total_loss": 0.6110297441482544,
      "weighted_orthogonal_loss": 0.02019132487475872
    },
    {
      "classification_loss": 0.6231002807617188,
      "epoch": 11.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20192579925060272,
      "orthogonal_weight": 0.1,
      "step": 3595,
      "total_loss": 0.6432928442955017,
      "weighted_orthogonal_loss": 0.020192580297589302
    },
    {
      "classification_loss": 0.5891109108924866,
      "epoch": 11.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20197796821594238,
      "orthogonal_weight": 0.1,
      "step": 3596,
      "total_loss": 0.6093087196350098,
      "weighted_orthogonal_loss": 0.020197797566652298
    },
    {
      "classification_loss": 0.605930745601654,
      "epoch": 11.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020384520292282,
      "orthogonal_weight": 0.1,
      "step": 3597,
      "total_loss": 0.6261345744132996,
      "weighted_orthogonal_loss": 0.02020384557545185
    },
    {
      "classification_loss": 0.6691569089889526,
      "epoch": 11.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202078178524971,
      "orthogonal_weight": 0.1,
      "step": 3598,
      "total_loss": 0.6893647313117981,
      "weighted_orthogonal_loss": 0.02020781859755516
    },
    {
      "classification_loss": 0.6435989737510681,
      "epoch": 11.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021142542362213,
      "orthogonal_weight": 0.1,
      "step": 3599,
      "total_loss": 0.6638103723526001,
      "weighted_orthogonal_loss": 0.02021142654120922
    },
    {
      "epoch": 11.80327868852459,
      "grad_norm": 8.175614356994629,
      "learning_rate": 8.336666666666667e-05,
      "loss": 0.6488,
      "step": 3600
    },
    {
      "classification_loss": 0.6192789077758789,
      "epoch": 11.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021045982837677,
      "orthogonal_weight": 0.1,
      "step": 3600,
      "total_loss": 0.6394893527030945,
      "weighted_orthogonal_loss": 0.02021045982837677
    },
    {
      "classification_loss": 0.5931121706962585,
      "epoch": 11.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20211224257946014,
      "orthogonal_weight": 0.1,
      "step": 3601,
      "total_loss": 0.6133233904838562,
      "weighted_orthogonal_loss": 0.020211225375533104
    },
    {
      "classification_loss": 0.6161953806877136,
      "epoch": 11.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020953893661499,
      "orthogonal_weight": 0.1,
      "step": 3602,
      "total_loss": 0.6364049315452576,
      "weighted_orthogonal_loss": 0.02020953968167305
    },
    {
      "classification_loss": 0.666886568069458,
      "epoch": 11.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20215165615081787,
      "orthogonal_weight": 0.1,
      "step": 3603,
      "total_loss": 0.6871017217636108,
      "weighted_orthogonal_loss": 0.020215166732668877
    },
    {
      "classification_loss": 0.6675664782524109,
      "epoch": 11.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20217813551425934,
      "orthogonal_weight": 0.1,
      "step": 3604,
      "total_loss": 0.6877843141555786,
      "weighted_orthogonal_loss": 0.020217813551425934
    },
    {
      "classification_loss": 0.6044008731842041,
      "epoch": 11.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202182337641716,
      "orthogonal_weight": 0.1,
      "step": 3605,
      "total_loss": 0.6246191263198853,
      "weighted_orthogonal_loss": 0.02021823450922966
    },
    {
      "classification_loss": 0.5376969575881958,
      "epoch": 11.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022138386964798,
      "orthogonal_weight": 0.1,
      "step": 3606,
      "total_loss": 0.55791836977005,
      "weighted_orthogonal_loss": 0.02022138424217701
    },
    {
      "classification_loss": 0.5924807786941528,
      "epoch": 11.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20224212110042572,
      "orthogonal_weight": 0.1,
      "step": 3607,
      "total_loss": 0.6127049922943115,
      "weighted_orthogonal_loss": 0.020224211737513542
    },
    {
      "classification_loss": 0.6583017110824585,
      "epoch": 11.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021430879831314,
      "orthogonal_weight": 0.1,
      "step": 3608,
      "total_loss": 0.6785160303115845,
      "weighted_orthogonal_loss": 0.02021430991590023
    },
    {
      "classification_loss": 0.6464916467666626,
      "epoch": 11.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020435929298401,
      "orthogonal_weight": 0.1,
      "step": 3609,
      "total_loss": 0.6666960120201111,
      "weighted_orthogonal_loss": 0.02020435966551304
    },
    {
      "classification_loss": 0.7018278241157532,
      "epoch": 11.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20197542011737823,
      "orthogonal_weight": 0.1,
      "step": 3610,
      "total_loss": 0.7220253944396973,
      "weighted_orthogonal_loss": 0.020197542384266853
    },
    {
      "classification_loss": 0.5689456462860107,
      "epoch": 11.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20186688005924225,
      "orthogonal_weight": 0.1,
      "step": 3611,
      "total_loss": 0.5891323089599609,
      "weighted_orthogonal_loss": 0.020186688750982285
    },
    {
      "classification_loss": 0.5379841923713684,
      "epoch": 11.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20179960131645203,
      "orthogonal_weight": 0.1,
      "step": 3612,
      "total_loss": 0.5581641793251038,
      "weighted_orthogonal_loss": 0.020179960876703262
    },
    {
      "classification_loss": 0.6840267181396484,
      "epoch": 11.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2018910050392151,
      "orthogonal_weight": 0.1,
      "step": 3613,
      "total_loss": 0.7042158246040344,
      "weighted_orthogonal_loss": 0.02018910087645054
    },
    {
      "classification_loss": 0.6673691272735596,
      "epoch": 11.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20197470486164093,
      "orthogonal_weight": 0.1,
      "step": 3614,
      "total_loss": 0.6875665783882141,
      "weighted_orthogonal_loss": 0.020197471603751183
    },
    {
      "classification_loss": 0.6777935028076172,
      "epoch": 11.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20206330716609955,
      "orthogonal_weight": 0.1,
      "step": 3615,
      "total_loss": 0.6979998350143433,
      "weighted_orthogonal_loss": 0.020206330344080925
    },
    {
      "classification_loss": 0.5465749502182007,
      "epoch": 11.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20206870138645172,
      "orthogonal_weight": 0.1,
      "step": 3616,
      "total_loss": 0.5667818188667297,
      "weighted_orthogonal_loss": 0.020206870511174202
    },
    {
      "classification_loss": 0.5524259805679321,
      "epoch": 11.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020544707775116,
      "orthogonal_weight": 0.1,
      "step": 3617,
      "total_loss": 0.5726314187049866,
      "weighted_orthogonal_loss": 0.02020544745028019
    },
    {
      "classification_loss": 0.5808762907981873,
      "epoch": 11.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20205241441726685,
      "orthogonal_weight": 0.1,
      "step": 3618,
      "total_loss": 0.6010815501213074,
      "weighted_orthogonal_loss": 0.020205242559313774
    },
    {
      "classification_loss": 0.6193593144416809,
      "epoch": 11.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20201857388019562,
      "orthogonal_weight": 0.1,
      "step": 3619,
      "total_loss": 0.6395611763000488,
      "weighted_orthogonal_loss": 0.02020185813307762
    },
    {
      "classification_loss": 0.7068017721176147,
      "epoch": 11.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020370215177536,
      "orthogonal_weight": 0.1,
      "step": 3620,
      "total_loss": 0.7270054817199707,
      "weighted_orthogonal_loss": 0.02020370215177536
    },
    {
      "classification_loss": 0.6210455298423767,
      "epoch": 11.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20199257135391235,
      "orthogonal_weight": 0.1,
      "step": 3621,
      "total_loss": 0.6412447690963745,
      "weighted_orthogonal_loss": 0.020199257880449295
    },
    {
      "classification_loss": 0.590722382068634,
      "epoch": 11.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20197398960590363,
      "orthogonal_weight": 0.1,
      "step": 3622,
      "total_loss": 0.6109197735786438,
      "weighted_orthogonal_loss": 0.020197398960590363
    },
    {
      "classification_loss": 0.595500111579895,
      "epoch": 11.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20204246044158936,
      "orthogonal_weight": 0.1,
      "step": 3623,
      "total_loss": 0.615704357624054,
      "weighted_orthogonal_loss": 0.020204246044158936
    },
    {
      "classification_loss": 0.6861968636512756,
      "epoch": 11.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20216058194637299,
      "orthogonal_weight": 0.1,
      "step": 3624,
      "total_loss": 0.7064129114151001,
      "weighted_orthogonal_loss": 0.02021605893969536
    },
    {
      "classification_loss": 0.6258659362792969,
      "epoch": 11.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20228838920593262,
      "orthogonal_weight": 0.1,
      "step": 3625,
      "total_loss": 0.646094799041748,
      "weighted_orthogonal_loss": 0.020228838548064232
    },
    {
      "classification_loss": 0.6705102920532227,
      "epoch": 11.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202459916472435,
      "orthogonal_weight": 0.1,
      "step": 3626,
      "total_loss": 0.6907562613487244,
      "weighted_orthogonal_loss": 0.0202459916472435
    },
    {
      "classification_loss": 0.7148578763008118,
      "epoch": 11.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20263175666332245,
      "orthogonal_weight": 0.1,
      "step": 3627,
      "total_loss": 0.7351210713386536,
      "weighted_orthogonal_loss": 0.020263176411390305
    },
    {
      "classification_loss": 0.741991400718689,
      "epoch": 11.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20283865928649902,
      "orthogonal_weight": 0.1,
      "step": 3628,
      "total_loss": 0.7622752785682678,
      "weighted_orthogonal_loss": 0.020283866673707962
    },
    {
      "classification_loss": 0.635947585105896,
      "epoch": 11.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305030047893524,
      "orthogonal_weight": 0.1,
      "step": 3629,
      "total_loss": 0.6562526226043701,
      "weighted_orthogonal_loss": 0.020305030047893524
    },
    {
      "classification_loss": 0.5971367359161377,
      "epoch": 11.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20322324335575104,
      "orthogonal_weight": 0.1,
      "step": 3630,
      "total_loss": 0.6174590587615967,
      "weighted_orthogonal_loss": 0.020322324708104134
    },
    {
      "classification_loss": 0.6248792409896851,
      "epoch": 11.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20332837104797363,
      "orthogonal_weight": 0.1,
      "step": 3631,
      "total_loss": 0.6452120542526245,
      "weighted_orthogonal_loss": 0.020332837477326393
    },
    {
      "classification_loss": 0.5843012928962708,
      "epoch": 11.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20337650179862976,
      "orthogonal_weight": 0.1,
      "step": 3632,
      "total_loss": 0.604638934135437,
      "weighted_orthogonal_loss": 0.020337650552392006
    },
    {
      "classification_loss": 0.704284131526947,
      "epoch": 11.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20331214368343353,
      "orthogonal_weight": 0.1,
      "step": 3633,
      "total_loss": 0.7246153354644775,
      "weighted_orthogonal_loss": 0.020331215113401413
    },
    {
      "classification_loss": 0.5937841534614563,
      "epoch": 11.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20323409140110016,
      "orthogonal_weight": 0.1,
      "step": 3634,
      "total_loss": 0.6141075491905212,
      "weighted_orthogonal_loss": 0.020323408767580986
    },
    {
      "classification_loss": 0.6356214284896851,
      "epoch": 11.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031240612268448,
      "orthogonal_weight": 0.1,
      "step": 3635,
      "total_loss": 0.6559338569641113,
      "weighted_orthogonal_loss": 0.02031240612268448
    },
    {
      "classification_loss": 0.5800917148590088,
      "epoch": 11.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029571533203125,
      "orthogonal_weight": 0.1,
      "step": 3636,
      "total_loss": 0.600387454032898,
      "weighted_orthogonal_loss": 0.02029571495950222
    },
    {
      "classification_loss": 0.5847275853157043,
      "epoch": 11.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027861475944519,
      "orthogonal_weight": 0.1,
      "step": 3637,
      "total_loss": 0.605006217956543,
      "weighted_orthogonal_loss": 0.02027861587703228
    },
    {
      "classification_loss": 0.6610692143440247,
      "epoch": 11.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20262718200683594,
      "orthogonal_weight": 0.1,
      "step": 3638,
      "total_loss": 0.6813319325447083,
      "weighted_orthogonal_loss": 0.020262718200683594
    },
    {
      "classification_loss": 0.6512939929962158,
      "epoch": 11.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20241646468639374,
      "orthogonal_weight": 0.1,
      "step": 3639,
      "total_loss": 0.6715356111526489,
      "weighted_orthogonal_loss": 0.020241646096110344
    },
    {
      "classification_loss": 0.6092414259910583,
      "epoch": 11.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20227448642253876,
      "orthogonal_weight": 0.1,
      "step": 3640,
      "total_loss": 0.6294688582420349,
      "weighted_orthogonal_loss": 0.020227449014782906
    },
    {
      "classification_loss": 0.6712035536766052,
      "epoch": 11.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20222587883472443,
      "orthogonal_weight": 0.1,
      "step": 3641,
      "total_loss": 0.691426157951355,
      "weighted_orthogonal_loss": 0.020222587510943413
    },
    {
      "classification_loss": 0.6078327298164368,
      "epoch": 11.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20219022035598755,
      "orthogonal_weight": 0.1,
      "step": 3642,
      "total_loss": 0.6280517578125,
      "weighted_orthogonal_loss": 0.020219022408127785
    },
    {
      "classification_loss": 0.5933604836463928,
      "epoch": 11.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20215699076652527,
      "orthogonal_weight": 0.1,
      "step": 3643,
      "total_loss": 0.6135761737823486,
      "weighted_orthogonal_loss": 0.020215699449181557
    },
    {
      "classification_loss": 0.6401485204696655,
      "epoch": 11.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20212431252002716,
      "orthogonal_weight": 0.1,
      "step": 3644,
      "total_loss": 0.6603609323501587,
      "weighted_orthogonal_loss": 0.020212432369589806
    },
    {
      "classification_loss": 0.6141277551651001,
      "epoch": 11.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20211689174175262,
      "orthogonal_weight": 0.1,
      "step": 3645,
      "total_loss": 0.634339451789856,
      "weighted_orthogonal_loss": 0.020211689174175262
    },
    {
      "classification_loss": 0.5656790733337402,
      "epoch": 11.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20211566984653473,
      "orthogonal_weight": 0.1,
      "step": 3646,
      "total_loss": 0.5858906507492065,
      "weighted_orthogonal_loss": 0.020211568102240562
    },
    {
      "classification_loss": 0.576734185218811,
      "epoch": 11.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021079808473587,
      "orthogonal_weight": 0.1,
      "step": 3647,
      "total_loss": 0.5969449877738953,
      "weighted_orthogonal_loss": 0.02021079882979393
    },
    {
      "classification_loss": 0.5650493502616882,
      "epoch": 11.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20208033919334412,
      "orthogonal_weight": 0.1,
      "step": 3648,
      "total_loss": 0.5852574110031128,
      "weighted_orthogonal_loss": 0.02020803466439247
    },
    {
      "classification_loss": 0.6112088561058044,
      "epoch": 11.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020713835954666,
      "orthogonal_weight": 0.1,
      "step": 3649,
      "total_loss": 0.6314160227775574,
      "weighted_orthogonal_loss": 0.02020713873207569
    },
    {
      "classification_loss": 0.6678983569145203,
      "epoch": 11.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20212021470069885,
      "orthogonal_weight": 0.1,
      "step": 3650,
      "total_loss": 0.6881103515625,
      "weighted_orthogonal_loss": 0.020212022587656975
    },
    {
      "classification_loss": 0.698672890663147,
      "epoch": 11.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021765261888504,
      "orthogonal_weight": 0.1,
      "step": 3651,
      "total_loss": 0.7188905477523804,
      "weighted_orthogonal_loss": 0.0202176533639431
    },
    {
      "classification_loss": 0.546786367893219,
      "epoch": 11.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20224983990192413,
      "orthogonal_weight": 0.1,
      "step": 3652,
      "total_loss": 0.5670113563537598,
      "weighted_orthogonal_loss": 0.020224984735250473
    },
    {
      "classification_loss": 0.6060171723365784,
      "epoch": 11.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022729516029358,
      "orthogonal_weight": 0.1,
      "step": 3653,
      "total_loss": 0.6262444853782654,
      "weighted_orthogonal_loss": 0.02022729627788067
    },
    {
      "classification_loss": 0.6538286209106445,
      "epoch": 11.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20232343673706055,
      "orthogonal_weight": 0.1,
      "step": 3654,
      "total_loss": 0.6740609407424927,
      "weighted_orthogonal_loss": 0.020232344046235085
    },
    {
      "classification_loss": 0.6188373565673828,
      "epoch": 11.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20239660143852234,
      "orthogonal_weight": 0.1,
      "step": 3655,
      "total_loss": 0.6390770077705383,
      "weighted_orthogonal_loss": 0.020239660516381264
    },
    {
      "classification_loss": 0.6037088632583618,
      "epoch": 11.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20249316096305847,
      "orthogonal_weight": 0.1,
      "step": 3656,
      "total_loss": 0.623958170413971,
      "weighted_orthogonal_loss": 0.020249316468834877
    },
    {
      "classification_loss": 0.6668620109558105,
      "epoch": 11.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20261549949645996,
      "orthogonal_weight": 0.1,
      "step": 3657,
      "total_loss": 0.6871235370635986,
      "weighted_orthogonal_loss": 0.020261550322175026
    },
    {
      "classification_loss": 0.6459926962852478,
      "epoch": 11.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027442455291748,
      "orthogonal_weight": 0.1,
      "step": 3658,
      "total_loss": 0.6662670969963074,
      "weighted_orthogonal_loss": 0.02027442492544651
    },
    {
      "classification_loss": 0.6297595500946045,
      "epoch": 11.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028471827507019,
      "orthogonal_weight": 0.1,
      "step": 3659,
      "total_loss": 0.6500442624092102,
      "weighted_orthogonal_loss": 0.02028471790254116
    },
    {
      "classification_loss": 0.7010380029678345,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7213287353515625,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.6989408731460571,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7192316055297852,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.6901598572731018,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7104505896568298,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.7108595967292786,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7311503291130066,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.6999974250793457,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7202881574630737,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.6961572766304016,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7164480090141296,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.680001974105835,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.700292706489563,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.7122033834457397,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.7324941158294678,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.508,
      "eval_f1": 0.5427509293680297,
      "eval_loss": 0.7186357378959656,
      "eval_precision": 0.6445916114790287,
      "eval_recall": 0.46869983948635635,
      "eval_runtime": 6.1576,
      "eval_samples_per_second": 162.402,
      "eval_steps_per_second": 1.299,
      "step": 3660
    },
    {
      "classification_loss": 0.59609055519104,
      "epoch": 12.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290735363960266,
      "orthogonal_weight": 0.1,
      "step": 3660,
      "total_loss": 0.6163812875747681,
      "weighted_orthogonal_loss": 0.020290736109018326
    },
    {
      "classification_loss": 0.5939298272132874,
      "epoch": 12.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20291884243488312,
      "orthogonal_weight": 0.1,
      "step": 3661,
      "total_loss": 0.6142216920852661,
      "weighted_orthogonal_loss": 0.0202918853610754
    },
    {
      "classification_loss": 0.655291736125946,
      "epoch": 12.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20288558304309845,
      "orthogonal_weight": 0.1,
      "step": 3662,
      "total_loss": 0.6755803227424622,
      "weighted_orthogonal_loss": 0.020288558676838875
    },
    {
      "classification_loss": 0.5771771669387817,
      "epoch": 12.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20278258621692657,
      "orthogonal_weight": 0.1,
      "step": 3663,
      "total_loss": 0.5974554419517517,
      "weighted_orthogonal_loss": 0.020278258249163628
    },
    {
      "classification_loss": 0.6606633067131042,
      "epoch": 12.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20265406370162964,
      "orthogonal_weight": 0.1,
      "step": 3664,
      "total_loss": 0.6809287071228027,
      "weighted_orthogonal_loss": 0.020265405997633934
    },
    {
      "classification_loss": 0.628753662109375,
      "epoch": 12.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025245577096939,
      "orthogonal_weight": 0.1,
      "step": 3665,
      "total_loss": 0.6490061283111572,
      "weighted_orthogonal_loss": 0.02025245688855648
    },
    {
      "classification_loss": 0.5898973345756531,
      "epoch": 12.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2024255394935608,
      "orthogonal_weight": 0.1,
      "step": 3666,
      "total_loss": 0.6101399064064026,
      "weighted_orthogonal_loss": 0.02024255506694317
    },
    {
      "classification_loss": 0.636817216873169,
      "epoch": 12.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20233382284641266,
      "orthogonal_weight": 0.1,
      "step": 3667,
      "total_loss": 0.657050609588623,
      "weighted_orthogonal_loss": 0.020233383402228355
    },
    {
      "classification_loss": 0.6069028973579407,
      "epoch": 12.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20232029259204865,
      "orthogonal_weight": 0.1,
      "step": 3668,
      "total_loss": 0.6271349191665649,
      "weighted_orthogonal_loss": 0.020232029259204865
    },
    {
      "classification_loss": 0.5556774139404297,
      "epoch": 12.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20222195982933044,
      "orthogonal_weight": 0.1,
      "step": 3669,
      "total_loss": 0.575899600982666,
      "weighted_orthogonal_loss": 0.020222196355462074
    },
    {
      "classification_loss": 0.6620588898658752,
      "epoch": 12.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021835297346115,
      "orthogonal_weight": 0.1,
      "step": 3670,
      "total_loss": 0.682277262210846,
      "weighted_orthogonal_loss": 0.02021835371851921
    },
    {
      "classification_loss": 0.5970172882080078,
      "epoch": 12.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202153742313385,
      "orthogonal_weight": 0.1,
      "step": 3671,
      "total_loss": 0.6172326803207397,
      "weighted_orthogonal_loss": 0.02021537534892559
    },
    {
      "classification_loss": 0.6429012417793274,
      "epoch": 12.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20227573812007904,
      "orthogonal_weight": 0.1,
      "step": 3672,
      "total_loss": 0.6631287932395935,
      "weighted_orthogonal_loss": 0.020227573812007904
    },
    {
      "classification_loss": 0.6051933765411377,
      "epoch": 12.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20238645374774933,
      "orthogonal_weight": 0.1,
      "step": 3673,
      "total_loss": 0.625432014465332,
      "weighted_orthogonal_loss": 0.020238645374774933
    },
    {
      "classification_loss": 0.6094114780426025,
      "epoch": 12.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20251359045505524,
      "orthogonal_weight": 0.1,
      "step": 3674,
      "total_loss": 0.629662811756134,
      "weighted_orthogonal_loss": 0.020251359790563583
    },
    {
      "classification_loss": 0.6740882396697998,
      "epoch": 12.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20266222953796387,
      "orthogonal_weight": 0.1,
      "step": 3675,
      "total_loss": 0.6943544745445251,
      "weighted_orthogonal_loss": 0.020266223698854446
    },
    {
      "classification_loss": 0.6021044254302979,
      "epoch": 12.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20278096199035645,
      "orthogonal_weight": 0.1,
      "step": 3676,
      "total_loss": 0.6223825216293335,
      "weighted_orthogonal_loss": 0.020278096199035645
    },
    {
      "classification_loss": 0.6324232816696167,
      "epoch": 12.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20288391411304474,
      "orthogonal_weight": 0.1,
      "step": 3677,
      "total_loss": 0.6527116894721985,
      "weighted_orthogonal_loss": 0.020288391038775444
    },
    {
      "classification_loss": 0.6444986462593079,
      "epoch": 12.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20285062491893768,
      "orthogonal_weight": 0.1,
      "step": 3678,
      "total_loss": 0.6647837162017822,
      "weighted_orthogonal_loss": 0.02028506249189377
    },
    {
      "classification_loss": 0.6559927463531494,
      "epoch": 12.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028491050004959,
      "orthogonal_weight": 0.1,
      "step": 3679,
      "total_loss": 0.6762776374816895,
      "weighted_orthogonal_loss": 0.02028491161763668
    },
    {
      "classification_loss": 0.5946214199066162,
      "epoch": 12.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20286348462104797,
      "orthogonal_weight": 0.1,
      "step": 3680,
      "total_loss": 0.6149077415466309,
      "weighted_orthogonal_loss": 0.020286349579691887
    },
    {
      "classification_loss": 0.5784226655960083,
      "epoch": 12.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20291493833065033,
      "orthogonal_weight": 0.1,
      "step": 3681,
      "total_loss": 0.5987141728401184,
      "weighted_orthogonal_loss": 0.020291494205594063
    },
    {
      "classification_loss": 0.6378359198570251,
      "epoch": 12.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20291316509246826,
      "orthogonal_weight": 0.1,
      "step": 3682,
      "total_loss": 0.6581272482872009,
      "weighted_orthogonal_loss": 0.020291317254304886
    },
    {
      "classification_loss": 0.6237573027610779,
      "epoch": 12.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029554843902588,
      "orthogonal_weight": 0.1,
      "step": 3683,
      "total_loss": 0.6440528631210327,
      "weighted_orthogonal_loss": 0.02029554918408394
    },
    {
      "classification_loss": 0.6214941143989563,
      "epoch": 12.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20297656953334808,
      "orthogonal_weight": 0.1,
      "step": 3684,
      "total_loss": 0.6417917609214783,
      "weighted_orthogonal_loss": 0.020297657698392868
    },
    {
      "classification_loss": 0.5673287510871887,
      "epoch": 12.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20291098952293396,
      "orthogonal_weight": 0.1,
      "step": 3685,
      "total_loss": 0.5876198410987854,
      "weighted_orthogonal_loss": 0.020291099324822426
    },
    {
      "classification_loss": 0.5792142748832703,
      "epoch": 12.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290809869766235,
      "orthogonal_weight": 0.1,
      "step": 3686,
      "total_loss": 0.5995050668716431,
      "weighted_orthogonal_loss": 0.020290810614824295
    },
    {
      "classification_loss": 0.6433432102203369,
      "epoch": 12.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20289292931556702,
      "orthogonal_weight": 0.1,
      "step": 3687,
      "total_loss": 0.6636325120925903,
      "weighted_orthogonal_loss": 0.020289292559027672
    },
    {
      "classification_loss": 0.6940675973892212,
      "epoch": 12.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028493732213974,
      "orthogonal_weight": 0.1,
      "step": 3688,
      "total_loss": 0.714352548122406,
      "weighted_orthogonal_loss": 0.02028493769466877
    },
    {
      "classification_loss": 0.5587230920791626,
      "epoch": 12.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20284207165241241,
      "orthogonal_weight": 0.1,
      "step": 3689,
      "total_loss": 0.5790073275566101,
      "weighted_orthogonal_loss": 0.02028420753777027
    },
    {
      "classification_loss": 0.6042565703392029,
      "epoch": 12.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20273445546627045,
      "orthogonal_weight": 0.1,
      "step": 3690,
      "total_loss": 0.624530017375946,
      "weighted_orthogonal_loss": 0.020273445174098015
    },
    {
      "classification_loss": 0.6251037120819092,
      "epoch": 12.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027389258146286,
      "orthogonal_weight": 0.1,
      "step": 3691,
      "total_loss": 0.6453775763511658,
      "weighted_orthogonal_loss": 0.02027389220893383
    },
    {
      "classification_loss": 0.6109638810157776,
      "epoch": 12.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20277675986289978,
      "orthogonal_weight": 0.1,
      "step": 3692,
      "total_loss": 0.6312415599822998,
      "weighted_orthogonal_loss": 0.020277677103877068
    },
    {
      "classification_loss": 0.5823956727981567,
      "epoch": 12.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20265908539295197,
      "orthogonal_weight": 0.1,
      "step": 3693,
      "total_loss": 0.6026616096496582,
      "weighted_orthogonal_loss": 0.020265908911824226
    },
    {
      "classification_loss": 0.5647407174110413,
      "epoch": 12.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20259518921375275,
      "orthogonal_weight": 0.1,
      "step": 3694,
      "total_loss": 0.585000216960907,
      "weighted_orthogonal_loss": 0.020259520038962364
    },
    {
      "classification_loss": 0.6084663271903992,
      "epoch": 12.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025703638792038,
      "orthogonal_weight": 0.1,
      "step": 3695,
      "total_loss": 0.6287233829498291,
      "weighted_orthogonal_loss": 0.02025703713297844
    },
    {
      "classification_loss": 0.6571363210678101,
      "epoch": 12.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2024107128381729,
      "orthogonal_weight": 0.1,
      "step": 3696,
      "total_loss": 0.6773774027824402,
      "weighted_orthogonal_loss": 0.02024107240140438
    },
    {
      "classification_loss": 0.6356388330459595,
      "epoch": 12.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20213821530342102,
      "orthogonal_weight": 0.1,
      "step": 3697,
      "total_loss": 0.6558526754379272,
      "weighted_orthogonal_loss": 0.020213821902871132
    },
    {
      "classification_loss": 0.622673511505127,
      "epoch": 12.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20192869007587433,
      "orthogonal_weight": 0.1,
      "step": 3698,
      "total_loss": 0.6428663730621338,
      "weighted_orthogonal_loss": 0.020192869007587433
    },
    {
      "classification_loss": 0.5409555435180664,
      "epoch": 12.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20165754854679108,
      "orthogonal_weight": 0.1,
      "step": 3699,
      "total_loss": 0.5611212849617004,
      "weighted_orthogonal_loss": 0.020165754482150078
    },
    {
      "epoch": 12.131147540983607,
      "grad_norm": 20.618268966674805,
      "learning_rate": 8.003333333333333e-05,
      "loss": 0.6414,
      "step": 3700
    },
    {
      "classification_loss": 0.6084494590759277,
      "epoch": 12.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20143502950668335,
      "orthogonal_weight": 0.1,
      "step": 3700,
      "total_loss": 0.6285929679870605,
      "weighted_orthogonal_loss": 0.020143503323197365
    },
    {
      "classification_loss": 0.6250066161155701,
      "epoch": 12.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2013610452413559,
      "orthogonal_weight": 0.1,
      "step": 3701,
      "total_loss": 0.6451427340507507,
      "weighted_orthogonal_loss": 0.02013610489666462
    },
    {
      "classification_loss": 0.6165909767150879,
      "epoch": 12.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20130154490470886,
      "orthogonal_weight": 0.1,
      "step": 3702,
      "total_loss": 0.636721134185791,
      "weighted_orthogonal_loss": 0.020130155608057976
    },
    {
      "classification_loss": 0.5988671183586121,
      "epoch": 12.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2013530433177948,
      "orthogonal_weight": 0.1,
      "step": 3703,
      "total_loss": 0.6190024018287659,
      "weighted_orthogonal_loss": 0.02013530395925045
    },
    {
      "classification_loss": 0.6197646856307983,
      "epoch": 12.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20141059160232544,
      "orthogonal_weight": 0.1,
      "step": 3704,
      "total_loss": 0.6399057507514954,
      "weighted_orthogonal_loss": 0.020141059532761574
    },
    {
      "classification_loss": 0.5684026479721069,
      "epoch": 12.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20145292580127716,
      "orthogonal_weight": 0.1,
      "step": 3705,
      "total_loss": 0.588547945022583,
      "weighted_orthogonal_loss": 0.020145293325185776
    },
    {
      "classification_loss": 0.6346617341041565,
      "epoch": 12.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2015238255262375,
      "orthogonal_weight": 0.1,
      "step": 3706,
      "total_loss": 0.6548141241073608,
      "weighted_orthogonal_loss": 0.02015238255262375
    },
    {
      "classification_loss": 0.6497957706451416,
      "epoch": 12.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20174308121204376,
      "orthogonal_weight": 0.1,
      "step": 3707,
      "total_loss": 0.6699700951576233,
      "weighted_orthogonal_loss": 0.020174307748675346
    },
    {
      "classification_loss": 0.6093767285346985,
      "epoch": 12.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2019805759191513,
      "orthogonal_weight": 0.1,
      "step": 3708,
      "total_loss": 0.6295747756958008,
      "weighted_orthogonal_loss": 0.02019805833697319
    },
    {
      "classification_loss": 0.6261605024337769,
      "epoch": 12.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021937072277069,
      "orthogonal_weight": 0.1,
      "step": 3709,
      "total_loss": 0.6463798880577087,
      "weighted_orthogonal_loss": 0.02021937072277069
    },
    {
      "classification_loss": 0.6834878921508789,
      "epoch": 12.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20237015187740326,
      "orthogonal_weight": 0.1,
      "step": 3710,
      "total_loss": 0.7037249207496643,
      "weighted_orthogonal_loss": 0.020237015560269356
    },
    {
      "classification_loss": 0.6574714183807373,
      "epoch": 12.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20255355536937714,
      "orthogonal_weight": 0.1,
      "step": 3711,
      "total_loss": 0.6777267456054688,
      "weighted_orthogonal_loss": 0.020255355164408684
    },
    {
      "classification_loss": 0.5847783088684082,
      "epoch": 12.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20273494720458984,
      "orthogonal_weight": 0.1,
      "step": 3712,
      "total_loss": 0.6050518155097961,
      "weighted_orthogonal_loss": 0.020273495465517044
    },
    {
      "classification_loss": 0.5920258164405823,
      "epoch": 12.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20289061963558197,
      "orthogonal_weight": 0.1,
      "step": 3713,
      "total_loss": 0.6123148798942566,
      "weighted_orthogonal_loss": 0.020289061591029167
    },
    {
      "classification_loss": 0.6174870133399963,
      "epoch": 12.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20309913158416748,
      "orthogonal_weight": 0.1,
      "step": 3714,
      "total_loss": 0.637796938419342,
      "weighted_orthogonal_loss": 0.020309913903474808
    },
    {
      "classification_loss": 0.5700266361236572,
      "epoch": 12.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032635658979416,
      "orthogonal_weight": 0.1,
      "step": 3715,
      "total_loss": 0.5903530120849609,
      "weighted_orthogonal_loss": 0.02032635733485222
    },
    {
      "classification_loss": 0.631033718585968,
      "epoch": 12.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20330871641635895,
      "orthogonal_weight": 0.1,
      "step": 3716,
      "total_loss": 0.6513645648956299,
      "weighted_orthogonal_loss": 0.020330872386693954
    },
    {
      "classification_loss": 0.5677372813224792,
      "epoch": 12.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20334677398204803,
      "orthogonal_weight": 0.1,
      "step": 3717,
      "total_loss": 0.5880719423294067,
      "weighted_orthogonal_loss": 0.020334677770733833
    },
    {
      "classification_loss": 0.6450908780097961,
      "epoch": 12.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20345453917980194,
      "orthogonal_weight": 0.1,
      "step": 3718,
      "total_loss": 0.665436327457428,
      "weighted_orthogonal_loss": 0.020345455035567284
    },
    {
      "classification_loss": 0.6562204957008362,
      "epoch": 12.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20359773933887482,
      "orthogonal_weight": 0.1,
      "step": 3719,
      "total_loss": 0.6765802502632141,
      "weighted_orthogonal_loss": 0.02035977505147457
    },
    {
      "classification_loss": 0.6602537631988525,
      "epoch": 12.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20369292795658112,
      "orthogonal_weight": 0.1,
      "step": 3720,
      "total_loss": 0.6806230545043945,
      "weighted_orthogonal_loss": 0.02036929316818714
    },
    {
      "classification_loss": 0.6677336096763611,
      "epoch": 12.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20380285382270813,
      "orthogonal_weight": 0.1,
      "step": 3721,
      "total_loss": 0.6881138682365417,
      "weighted_orthogonal_loss": 0.020380286499857903
    },
    {
      "classification_loss": 0.6234779357910156,
      "epoch": 12.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20371945202350616,
      "orthogonal_weight": 0.1,
      "step": 3722,
      "total_loss": 0.6438499093055725,
      "weighted_orthogonal_loss": 0.020371945574879646
    },
    {
      "classification_loss": 0.6019601821899414,
      "epoch": 12.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20361395180225372,
      "orthogonal_weight": 0.1,
      "step": 3723,
      "total_loss": 0.622321605682373,
      "weighted_orthogonal_loss": 0.020361395552754402
    },
    {
      "classification_loss": 0.6050880551338196,
      "epoch": 12.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20357857644557953,
      "orthogonal_weight": 0.1,
      "step": 3724,
      "total_loss": 0.6254459023475647,
      "weighted_orthogonal_loss": 0.020357858389616013
    },
    {
      "classification_loss": 0.5710528492927551,
      "epoch": 12.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20353737473487854,
      "orthogonal_weight": 0.1,
      "step": 3725,
      "total_loss": 0.5914065837860107,
      "weighted_orthogonal_loss": 0.020353738218545914
    },
    {
      "classification_loss": 0.6459406018257141,
      "epoch": 12.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036210298538208,
      "orthogonal_weight": 0.1,
      "step": 3726,
      "total_loss": 0.6663026809692383,
      "weighted_orthogonal_loss": 0.02036210335791111
    },
    {
      "classification_loss": 0.5773372650146484,
      "epoch": 12.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20372897386550903,
      "orthogonal_weight": 0.1,
      "step": 3727,
      "total_loss": 0.597710132598877,
      "weighted_orthogonal_loss": 0.020372897386550903
    },
    {
      "classification_loss": 0.6218625903129578,
      "epoch": 12.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20385728776454926,
      "orthogonal_weight": 0.1,
      "step": 3728,
      "total_loss": 0.6422483325004578,
      "weighted_orthogonal_loss": 0.020385729148983955
    },
    {
      "classification_loss": 0.5482704043388367,
      "epoch": 12.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20399579405784607,
      "orthogonal_weight": 0.1,
      "step": 3729,
      "total_loss": 0.5686699748039246,
      "weighted_orthogonal_loss": 0.020399579778313637
    },
    {
      "classification_loss": 0.598929226398468,
      "epoch": 12.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20416106283664703,
      "orthogonal_weight": 0.1,
      "step": 3730,
      "total_loss": 0.6193453073501587,
      "weighted_orthogonal_loss": 0.020416107028722763
    },
    {
      "classification_loss": 0.5923284888267517,
      "epoch": 12.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20435042679309845,
      "orthogonal_weight": 0.1,
      "step": 3731,
      "total_loss": 0.612763524055481,
      "weighted_orthogonal_loss": 0.020435042679309845
    },
    {
      "classification_loss": 0.5823366045951843,
      "epoch": 12.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20449665188789368,
      "orthogonal_weight": 0.1,
      "step": 3732,
      "total_loss": 0.6027862429618835,
      "weighted_orthogonal_loss": 0.020449666306376457
    },
    {
      "classification_loss": 0.48897606134414673,
      "epoch": 12.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20459549129009247,
      "orthogonal_weight": 0.1,
      "step": 3733,
      "total_loss": 0.5094355940818787,
      "weighted_orthogonal_loss": 0.020459549501538277
    },
    {
      "classification_loss": 0.5711866617202759,
      "epoch": 12.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2047112137079239,
      "orthogonal_weight": 0.1,
      "step": 3734,
      "total_loss": 0.5916577577590942,
      "weighted_orthogonal_loss": 0.02047112211585045
    },
    {
      "classification_loss": 0.625002384185791,
      "epoch": 12.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2048317939043045,
      "orthogonal_weight": 0.1,
      "step": 3735,
      "total_loss": 0.6454855799674988,
      "weighted_orthogonal_loss": 0.02048317901790142
    },
    {
      "classification_loss": 0.5958340764045715,
      "epoch": 12.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.204789400100708,
      "orthogonal_weight": 0.1,
      "step": 3736,
      "total_loss": 0.6163130402565002,
      "weighted_orthogonal_loss": 0.02047893963754177
    },
    {
      "classification_loss": 0.6255658864974976,
      "epoch": 12.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20478709042072296,
      "orthogonal_weight": 0.1,
      "step": 3737,
      "total_loss": 0.6460446119308472,
      "weighted_orthogonal_loss": 0.020478708669543266
    },
    {
      "classification_loss": 0.6708621978759766,
      "epoch": 12.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20485813915729523,
      "orthogonal_weight": 0.1,
      "step": 3738,
      "total_loss": 0.6913480162620544,
      "weighted_orthogonal_loss": 0.020485814660787582
    },
    {
      "classification_loss": 0.6793754696846008,
      "epoch": 12.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20490282773971558,
      "orthogonal_weight": 0.1,
      "step": 3739,
      "total_loss": 0.6998657584190369,
      "weighted_orthogonal_loss": 0.020490283146500587
    },
    {
      "classification_loss": 0.5809218287467957,
      "epoch": 12.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2049679309129715,
      "orthogonal_weight": 0.1,
      "step": 3740,
      "total_loss": 0.6014186143875122,
      "weighted_orthogonal_loss": 0.02049679309129715
    },
    {
      "classification_loss": 0.6616653800010681,
      "epoch": 12.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20503009855747223,
      "orthogonal_weight": 0.1,
      "step": 3741,
      "total_loss": 0.6821683645248413,
      "weighted_orthogonal_loss": 0.020503010600805283
    },
    {
      "classification_loss": 0.5984753966331482,
      "epoch": 12.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20508535206317902,
      "orthogonal_weight": 0.1,
      "step": 3742,
      "total_loss": 0.6189839243888855,
      "weighted_orthogonal_loss": 0.0205085352063179
    },
    {
      "classification_loss": 0.6528333425521851,
      "epoch": 12.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20509515702724457,
      "orthogonal_weight": 0.1,
      "step": 3743,
      "total_loss": 0.6733428835868835,
      "weighted_orthogonal_loss": 0.020509516820311546
    },
    {
      "classification_loss": 0.6866011619567871,
      "epoch": 12.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20505838096141815,
      "orthogonal_weight": 0.1,
      "step": 3744,
      "total_loss": 0.7071070075035095,
      "weighted_orthogonal_loss": 0.020505838096141815
    },
    {
      "classification_loss": 0.6643728017807007,
      "epoch": 12.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2049972414970398,
      "orthogonal_weight": 0.1,
      "step": 3745,
      "total_loss": 0.6848725080490112,
      "weighted_orthogonal_loss": 0.02049972489476204
    },
    {
      "classification_loss": 0.6382632851600647,
      "epoch": 12.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20494362711906433,
      "orthogonal_weight": 0.1,
      "step": 3746,
      "total_loss": 0.6587576270103455,
      "weighted_orthogonal_loss": 0.020494362339377403
    },
    {
      "classification_loss": 0.7680864334106445,
      "epoch": 12.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20492683351039886,
      "orthogonal_weight": 0.1,
      "step": 3747,
      "total_loss": 0.7885791063308716,
      "weighted_orthogonal_loss": 0.020492684096097946
    },
    {
      "classification_loss": 0.6271049380302429,
      "epoch": 12.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20490919053554535,
      "orthogonal_weight": 0.1,
      "step": 3748,
      "total_loss": 0.6475958824157715,
      "weighted_orthogonal_loss": 0.020490920171141624
    },
    {
      "classification_loss": 0.7177722454071045,
      "epoch": 12.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20486606657505035,
      "orthogonal_weight": 0.1,
      "step": 3749,
      "total_loss": 0.7382588386535645,
      "weighted_orthogonal_loss": 0.020486606284976006
    },
    {
      "classification_loss": 0.6183047890663147,
      "epoch": 12.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482714474201202,
      "orthogonal_weight": 0.1,
      "step": 3750,
      "total_loss": 0.6387875080108643,
      "weighted_orthogonal_loss": 0.020482715219259262
    },
    {
      "classification_loss": 0.6633800268173218,
      "epoch": 12.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482167601585388,
      "orthogonal_weight": 0.1,
      "step": 3751,
      "total_loss": 0.6838622093200684,
      "weighted_orthogonal_loss": 0.020482167601585388
    },
    {
      "classification_loss": 0.6294860243797302,
      "epoch": 12.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20500171184539795,
      "orthogonal_weight": 0.1,
      "step": 3752,
      "total_loss": 0.649986207485199,
      "weighted_orthogonal_loss": 0.020500171929597855
    },
    {
      "classification_loss": 0.6852908134460449,
      "epoch": 12.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2051485925912857,
      "orthogonal_weight": 0.1,
      "step": 3753,
      "total_loss": 0.7058056592941284,
      "weighted_orthogonal_loss": 0.02051485888659954
    },
    {
      "classification_loss": 0.5827822685241699,
      "epoch": 12.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20532923936843872,
      "orthogonal_weight": 0.1,
      "step": 3754,
      "total_loss": 0.6033151745796204,
      "weighted_orthogonal_loss": 0.020532924681901932
    },
    {
      "classification_loss": 0.710028350353241,
      "epoch": 12.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054598182439804,
      "orthogonal_weight": 0.1,
      "step": 3755,
      "total_loss": 0.7305743098258972,
      "weighted_orthogonal_loss": 0.02054598182439804
    },
    {
      "classification_loss": 0.5581571459770203,
      "epoch": 12.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20553842186927795,
      "orthogonal_weight": 0.1,
      "step": 3756,
      "total_loss": 0.5787109732627869,
      "weighted_orthogonal_loss": 0.020553842186927795
    },
    {
      "classification_loss": 0.5846422910690308,
      "epoch": 12.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569343864917755,
      "orthogonal_weight": 0.1,
      "step": 3757,
      "total_loss": 0.605211615562439,
      "weighted_orthogonal_loss": 0.020569344982504845
    },
    {
      "classification_loss": 0.6177204847335815,
      "epoch": 12.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20578579604625702,
      "orthogonal_weight": 0.1,
      "step": 3758,
      "total_loss": 0.6382990479469299,
      "weighted_orthogonal_loss": 0.020578579977154732
    },
    {
      "classification_loss": 0.6088820099830627,
      "epoch": 12.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2058401256799698,
      "orthogonal_weight": 0.1,
      "step": 3759,
      "total_loss": 0.6294659972190857,
      "weighted_orthogonal_loss": 0.02058401331305504
    },
    {
      "classification_loss": 0.7142455577850342,
      "epoch": 12.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20567163825035095,
      "orthogonal_weight": 0.1,
      "step": 3760,
      "total_loss": 0.7348127365112305,
      "weighted_orthogonal_loss": 0.020567163825035095
    },
    {
      "classification_loss": 0.710111677646637,
      "epoch": 12.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055394947528839,
      "orthogonal_weight": 0.1,
      "step": 3761,
      "total_loss": 0.7306656241416931,
      "weighted_orthogonal_loss": 0.02055395022034645
    },
    {
      "classification_loss": 0.5737346410751343,
      "epoch": 12.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20540012419223785,
      "orthogonal_weight": 0.1,
      "step": 3762,
      "total_loss": 0.594274640083313,
      "weighted_orthogonal_loss": 0.020540012046694756
    },
    {
      "classification_loss": 0.5852978825569153,
      "epoch": 12.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20531995594501495,
      "orthogonal_weight": 0.1,
      "step": 3763,
      "total_loss": 0.6058298945426941,
      "weighted_orthogonal_loss": 0.020531995221972466
    },
    {
      "classification_loss": 0.6483129262924194,
      "epoch": 12.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20523899793624878,
      "orthogonal_weight": 0.1,
      "step": 3764,
      "total_loss": 0.6688368320465088,
      "weighted_orthogonal_loss": 0.020523900166153908
    },
    {
      "classification_loss": 0.5606551170349121,
      "epoch": 12.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20519974827766418,
      "orthogonal_weight": 0.1,
      "step": 3765,
      "total_loss": 0.5811750888824463,
      "weighted_orthogonal_loss": 0.020519975572824478
    },
    {
      "classification_loss": 0.6117364764213562,
      "epoch": 12.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20516541600227356,
      "orthogonal_weight": 0.1,
      "step": 3766,
      "total_loss": 0.6322529911994934,
      "weighted_orthogonal_loss": 0.020516542717814445
    },
    {
      "classification_loss": 0.6365504264831543,
      "epoch": 12.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2051209658384323,
      "orthogonal_weight": 0.1,
      "step": 3767,
      "total_loss": 0.6570625305175781,
      "weighted_orthogonal_loss": 0.02051209658384323
    },
    {
      "classification_loss": 0.552690863609314,
      "epoch": 12.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20511747896671295,
      "orthogonal_weight": 0.1,
      "step": 3768,
      "total_loss": 0.5732026100158691,
      "weighted_orthogonal_loss": 0.020511748269200325
    },
    {
      "classification_loss": 0.6764131188392639,
      "epoch": 12.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20516330003738403,
      "orthogonal_weight": 0.1,
      "step": 3769,
      "total_loss": 0.6969294548034668,
      "weighted_orthogonal_loss": 0.020516330376267433
    },
    {
      "classification_loss": 0.6339809894561768,
      "epoch": 12.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20523865520954132,
      "orthogonal_weight": 0.1,
      "step": 3770,
      "total_loss": 0.6545048356056213,
      "weighted_orthogonal_loss": 0.02052386663854122
    },
    {
      "classification_loss": 0.6226287484169006,
      "epoch": 12.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20542140305042267,
      "orthogonal_weight": 0.1,
      "step": 3771,
      "total_loss": 0.6431708931922913,
      "weighted_orthogonal_loss": 0.020542141050100327
    },
    {
      "classification_loss": 0.6503053307533264,
      "epoch": 12.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20559194684028625,
      "orthogonal_weight": 0.1,
      "step": 3772,
      "total_loss": 0.6708645224571228,
      "weighted_orthogonal_loss": 0.020559195429086685
    },
    {
      "classification_loss": 0.6259857416152954,
      "epoch": 12.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569847524166107,
      "orthogonal_weight": 0.1,
      "step": 3773,
      "total_loss": 0.6465556025505066,
      "weighted_orthogonal_loss": 0.020569847896695137
    },
    {
      "classification_loss": 0.6051461696624756,
      "epoch": 12.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20582017302513123,
      "orthogonal_weight": 0.1,
      "step": 3774,
      "total_loss": 0.625728189945221,
      "weighted_orthogonal_loss": 0.020582018420100212
    },
    {
      "classification_loss": 0.695193886756897,
      "epoch": 12.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20591554045677185,
      "orthogonal_weight": 0.1,
      "step": 3775,
      "total_loss": 0.7157854437828064,
      "weighted_orthogonal_loss": 0.020591555163264275
    },
    {
      "classification_loss": 0.5630870461463928,
      "epoch": 12.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2060181200504303,
      "orthogonal_weight": 0.1,
      "step": 3776,
      "total_loss": 0.5836888551712036,
      "weighted_orthogonal_loss": 0.02060181275010109
    },
    {
      "classification_loss": 0.6291084885597229,
      "epoch": 12.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20618250966072083,
      "orthogonal_weight": 0.1,
      "step": 3777,
      "total_loss": 0.6497267484664917,
      "weighted_orthogonal_loss": 0.020618250593543053
    },
    {
      "classification_loss": 0.5829458832740784,
      "epoch": 12.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2063673585653305,
      "orthogonal_weight": 0.1,
      "step": 3778,
      "total_loss": 0.6035826206207275,
      "weighted_orthogonal_loss": 0.02063673548400402
    },
    {
      "classification_loss": 0.6407793164253235,
      "epoch": 12.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206569105386734,
      "orthogonal_weight": 0.1,
      "step": 3779,
      "total_loss": 0.6614362001419067,
      "weighted_orthogonal_loss": 0.02065691165626049
    },
    {
      "classification_loss": 0.6139624714851379,
      "epoch": 12.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20674236118793488,
      "orthogonal_weight": 0.1,
      "step": 3780,
      "total_loss": 0.6346367001533508,
      "weighted_orthogonal_loss": 0.020674236118793488
    },
    {
      "classification_loss": 0.6295819878578186,
      "epoch": 12.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20689833164215088,
      "orthogonal_weight": 0.1,
      "step": 3781,
      "total_loss": 0.6502718329429626,
      "weighted_orthogonal_loss": 0.020689833909273148
    },
    {
      "classification_loss": 0.5843213200569153,
      "epoch": 12.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704831182956696,
      "orthogonal_weight": 0.1,
      "step": 3782,
      "total_loss": 0.605026125907898,
      "weighted_orthogonal_loss": 0.020704831928014755
    },
    {
      "classification_loss": 0.6229526400566101,
      "epoch": 12.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20715700089931488,
      "orthogonal_weight": 0.1,
      "step": 3783,
      "total_loss": 0.6436683535575867,
      "weighted_orthogonal_loss": 0.020715700462460518
    },
    {
      "classification_loss": 0.5873398780822754,
      "epoch": 12.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2072097361087799,
      "orthogonal_weight": 0.1,
      "step": 3784,
      "total_loss": 0.6080608367919922,
      "weighted_orthogonal_loss": 0.02072097361087799
    },
    {
      "classification_loss": 0.6469902992248535,
      "epoch": 12.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20723380148410797,
      "orthogonal_weight": 0.1,
      "step": 3785,
      "total_loss": 0.6677137017250061,
      "weighted_orthogonal_loss": 0.020723380148410797
    },
    {
      "classification_loss": 0.5725803375244141,
      "epoch": 12.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20721812546253204,
      "orthogonal_weight": 0.1,
      "step": 3786,
      "total_loss": 0.5933021306991577,
      "weighted_orthogonal_loss": 0.020721813663840294
    },
    {
      "classification_loss": 0.5979093909263611,
      "epoch": 12.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704011619091034,
      "orthogonal_weight": 0.1,
      "step": 3787,
      "total_loss": 0.6186134219169617,
      "weighted_orthogonal_loss": 0.020704012364149094
    },
    {
      "classification_loss": 0.5881391167640686,
      "epoch": 12.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20684687793254852,
      "orthogonal_weight": 0.1,
      "step": 3788,
      "total_loss": 0.6088237762451172,
      "weighted_orthogonal_loss": 0.020684687420725822
    },
    {
      "classification_loss": 0.6121109127998352,
      "epoch": 12.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065986692905426,
      "orthogonal_weight": 0.1,
      "step": 3789,
      "total_loss": 0.6327707767486572,
      "weighted_orthogonal_loss": 0.02065986767411232
    },
    {
      "classification_loss": 0.5962658524513245,
      "epoch": 12.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206364706158638,
      "orthogonal_weight": 0.1,
      "step": 3790,
      "total_loss": 0.6169023513793945,
      "weighted_orthogonal_loss": 0.02063647098839283
    },
    {
      "classification_loss": 0.6706709265708923,
      "epoch": 12.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20619246363639832,
      "orthogonal_weight": 0.1,
      "step": 3791,
      "total_loss": 0.6912901997566223,
      "weighted_orthogonal_loss": 0.02061924710869789
    },
    {
      "classification_loss": 0.6590409278869629,
      "epoch": 12.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20602582395076752,
      "orthogonal_weight": 0.1,
      "step": 3792,
      "total_loss": 0.6796435117721558,
      "weighted_orthogonal_loss": 0.020602582022547722
    },
    {
      "classification_loss": 0.6601113080978394,
      "epoch": 12.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20587243139743805,
      "orthogonal_weight": 0.1,
      "step": 3793,
      "total_loss": 0.680698573589325,
      "weighted_orthogonal_loss": 0.020587243139743805
    },
    {
      "classification_loss": 0.659313976764679,
      "epoch": 12.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20573048293590546,
      "orthogonal_weight": 0.1,
      "step": 3794,
      "total_loss": 0.6798869967460632,
      "weighted_orthogonal_loss": 0.020573047921061516
    },
    {
      "classification_loss": 0.6542110443115234,
      "epoch": 12.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20546944439411163,
      "orthogonal_weight": 0.1,
      "step": 3795,
      "total_loss": 0.6747580170631409,
      "weighted_orthogonal_loss": 0.020546944811940193
    },
    {
      "classification_loss": 0.6756306886672974,
      "epoch": 12.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20519135892391205,
      "orthogonal_weight": 0.1,
      "step": 3796,
      "total_loss": 0.6961498260498047,
      "weighted_orthogonal_loss": 0.020519135519862175
    },
    {
      "classification_loss": 0.6164239645004272,
      "epoch": 12.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20498090982437134,
      "orthogonal_weight": 0.1,
      "step": 3797,
      "total_loss": 0.6369220614433289,
      "weighted_orthogonal_loss": 0.020498091354966164
    },
    {
      "classification_loss": 0.5272068381309509,
      "epoch": 12.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482338964939117,
      "orthogonal_weight": 0.1,
      "step": 3798,
      "total_loss": 0.5476891994476318,
      "weighted_orthogonal_loss": 0.020482338964939117
    },
    {
      "classification_loss": 0.6009061336517334,
      "epoch": 12.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20458456873893738,
      "orthogonal_weight": 0.1,
      "step": 3799,
      "total_loss": 0.6213645935058594,
      "weighted_orthogonal_loss": 0.020458457991480827
    },
    {
      "epoch": 12.459016393442623,
      "grad_norm": 18.981046676635742,
      "learning_rate": 7.670000000000001e-05,
      "loss": 0.6431,
      "step": 3800
    },
    {
      "classification_loss": 0.666409432888031,
      "epoch": 12.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20443308353424072,
      "orthogonal_weight": 0.1,
      "step": 3800,
      "total_loss": 0.686852753162384,
      "weighted_orthogonal_loss": 0.020443309098482132
    },
    {
      "classification_loss": 0.6843884587287903,
      "epoch": 12.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20433309674263,
      "orthogonal_weight": 0.1,
      "step": 3801,
      "total_loss": 0.704821765422821,
      "weighted_orthogonal_loss": 0.02043331041932106
    },
    {
      "classification_loss": 0.6244142055511475,
      "epoch": 12.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042163610458374,
      "orthogonal_weight": 0.1,
      "step": 3802,
      "total_loss": 0.6448358297348022,
      "weighted_orthogonal_loss": 0.02042163722217083
    },
    {
      "classification_loss": 0.5850411653518677,
      "epoch": 12.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20415611565113068,
      "orthogonal_weight": 0.1,
      "step": 3803,
      "total_loss": 0.6054567694664001,
      "weighted_orthogonal_loss": 0.020415611565113068
    },
    {
      "classification_loss": 0.6169503927230835,
      "epoch": 12.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20388884842395782,
      "orthogonal_weight": 0.1,
      "step": 3804,
      "total_loss": 0.6373392939567566,
      "weighted_orthogonal_loss": 0.020388884469866753
    },
    {
      "classification_loss": 0.5961942672729492,
      "epoch": 12.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20369786024093628,
      "orthogonal_weight": 0.1,
      "step": 3805,
      "total_loss": 0.6165640354156494,
      "weighted_orthogonal_loss": 0.020369786769151688
    },
    {
      "classification_loss": 0.6149117946624756,
      "epoch": 12.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036052942276001,
      "orthogonal_weight": 0.1,
      "step": 3806,
      "total_loss": 0.6352723240852356,
      "weighted_orthogonal_loss": 0.02036052942276001
    },
    {
      "classification_loss": 0.7015145421028137,
      "epoch": 12.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20353899896144867,
      "orthogonal_weight": 0.1,
      "step": 3807,
      "total_loss": 0.7218684554100037,
      "weighted_orthogonal_loss": 0.020353900268673897
    },
    {
      "classification_loss": 0.6701522469520569,
      "epoch": 12.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034887671470642,
      "orthogonal_weight": 0.1,
      "step": 3808,
      "total_loss": 0.6905010938644409,
      "weighted_orthogonal_loss": 0.02034887671470642
    },
    {
      "classification_loss": 0.6019116640090942,
      "epoch": 12.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20346315205097198,
      "orthogonal_weight": 0.1,
      "step": 3809,
      "total_loss": 0.6222580075263977,
      "weighted_orthogonal_loss": 0.02034631557762623
    },
    {
      "classification_loss": 0.6233519911766052,
      "epoch": 12.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20345936715602875,
      "orthogonal_weight": 0.1,
      "step": 3810,
      "total_loss": 0.6436979174613953,
      "weighted_orthogonal_loss": 0.020345937460660934
    },
    {
      "classification_loss": 0.6363617181777954,
      "epoch": 12.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20339113473892212,
      "orthogonal_weight": 0.1,
      "step": 3811,
      "total_loss": 0.656700849533081,
      "weighted_orthogonal_loss": 0.0203391145914793
    },
    {
      "classification_loss": 0.6345734596252441,
      "epoch": 12.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20337757468223572,
      "orthogonal_weight": 0.1,
      "step": 3812,
      "total_loss": 0.6549112200737,
      "weighted_orthogonal_loss": 0.02033775858581066
    },
    {
      "classification_loss": 0.6259527802467346,
      "epoch": 12.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20338204503059387,
      "orthogonal_weight": 0.1,
      "step": 3813,
      "total_loss": 0.6462909579277039,
      "weighted_orthogonal_loss": 0.020338205620646477
    },
    {
      "classification_loss": 0.5689196586608887,
      "epoch": 12.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20341049134731293,
      "orthogonal_weight": 0.1,
      "step": 3814,
      "total_loss": 0.5892606973648071,
      "weighted_orthogonal_loss": 0.020341049879789352
    },
    {
      "classification_loss": 0.6455407738685608,
      "epoch": 12.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034270465373993,
      "orthogonal_weight": 0.1,
      "step": 3815,
      "total_loss": 0.665883481502533,
      "weighted_orthogonal_loss": 0.02034270577132702
    },
    {
      "classification_loss": 0.6435316205024719,
      "epoch": 12.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20343947410583496,
      "orthogonal_weight": 0.1,
      "step": 3816,
      "total_loss": 0.6638755798339844,
      "weighted_orthogonal_loss": 0.020343948155641556
    },
    {
      "classification_loss": 0.6131305694580078,
      "epoch": 12.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20346537232398987,
      "orthogonal_weight": 0.1,
      "step": 3817,
      "total_loss": 0.6334770917892456,
      "weighted_orthogonal_loss": 0.020346537232398987
    },
    {
      "classification_loss": 0.6227474212646484,
      "epoch": 12.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20341545343399048,
      "orthogonal_weight": 0.1,
      "step": 3818,
      "total_loss": 0.6430889368057251,
      "weighted_orthogonal_loss": 0.020341545343399048
    },
    {
      "classification_loss": 0.5664803981781006,
      "epoch": 12.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20330815017223358,
      "orthogonal_weight": 0.1,
      "step": 3819,
      "total_loss": 0.5868111848831177,
      "weighted_orthogonal_loss": 0.02033081464469433
    },
    {
      "classification_loss": 0.6551743149757385,
      "epoch": 12.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20322537422180176,
      "orthogonal_weight": 0.1,
      "step": 3820,
      "total_loss": 0.6754968762397766,
      "weighted_orthogonal_loss": 0.020322537049651146
    },
    {
      "classification_loss": 0.6150071620941162,
      "epoch": 12.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031569629907608,
      "orthogonal_weight": 0.1,
      "step": 3821,
      "total_loss": 0.6353228688240051,
      "weighted_orthogonal_loss": 0.02031569741666317
    },
    {
      "classification_loss": 0.607181191444397,
      "epoch": 12.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20309922099113464,
      "orthogonal_weight": 0.1,
      "step": 3822,
      "total_loss": 0.6274911165237427,
      "weighted_orthogonal_loss": 0.020309923216700554
    },
    {
      "classification_loss": 0.6105467677116394,
      "epoch": 12.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20304562151432037,
      "orthogonal_weight": 0.1,
      "step": 3823,
      "total_loss": 0.6308513283729553,
      "weighted_orthogonal_loss": 0.020304562523961067
    },
    {
      "classification_loss": 0.6523447036743164,
      "epoch": 12.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030351459980011,
      "orthogonal_weight": 0.1,
      "step": 3824,
      "total_loss": 0.6726481914520264,
      "weighted_orthogonal_loss": 0.0203035157173872
    },
    {
      "classification_loss": 0.5915907621383667,
      "epoch": 12.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20302575826644897,
      "orthogonal_weight": 0.1,
      "step": 3825,
      "total_loss": 0.611893355846405,
      "weighted_orthogonal_loss": 0.020302576944231987
    },
    {
      "classification_loss": 0.6061673164367676,
      "epoch": 12.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20304031670093536,
      "orthogonal_weight": 0.1,
      "step": 3826,
      "total_loss": 0.6264713406562805,
      "weighted_orthogonal_loss": 0.020304031670093536
    },
    {
      "classification_loss": 0.549267053604126,
      "epoch": 12.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20304249227046967,
      "orthogonal_weight": 0.1,
      "step": 3827,
      "total_loss": 0.569571316242218,
      "weighted_orthogonal_loss": 0.020304249599575996
    },
    {
      "classification_loss": 0.6451972723007202,
      "epoch": 12.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20308907330036163,
      "orthogonal_weight": 0.1,
      "step": 3828,
      "total_loss": 0.6655061841011047,
      "weighted_orthogonal_loss": 0.020308908075094223
    },
    {
      "classification_loss": 0.6403594017028809,
      "epoch": 12.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20310789346694946,
      "orthogonal_weight": 0.1,
      "step": 3829,
      "total_loss": 0.6606701612472534,
      "weighted_orthogonal_loss": 0.020310789346694946
    },
    {
      "classification_loss": 0.6182470321655273,
      "epoch": 12.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311303436756134,
      "orthogonal_weight": 0.1,
      "step": 3830,
      "total_loss": 0.6385583281517029,
      "weighted_orthogonal_loss": 0.020311303436756134
    },
    {
      "classification_loss": 0.641444981098175,
      "epoch": 12.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305390655994415,
      "orthogonal_weight": 0.1,
      "step": 3831,
      "total_loss": 0.6617503762245178,
      "weighted_orthogonal_loss": 0.020305391401052475
    },
    {
      "classification_loss": 0.6915357112884521,
      "epoch": 12.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306864380836487,
      "orthogonal_weight": 0.1,
      "step": 3832,
      "total_loss": 0.7118425965309143,
      "weighted_orthogonal_loss": 0.020306864753365517
    },
    {
      "classification_loss": 0.6444091796875,
      "epoch": 12.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311184227466583,
      "orthogonal_weight": 0.1,
      "step": 3833,
      "total_loss": 0.664720356464386,
      "weighted_orthogonal_loss": 0.020311184227466583
    },
    {
      "classification_loss": 0.6997867226600647,
      "epoch": 12.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313657820224762,
      "orthogonal_weight": 0.1,
      "step": 3834,
      "total_loss": 0.7201004028320312,
      "weighted_orthogonal_loss": 0.020313657820224762
    },
    {
      "classification_loss": 0.6387869715690613,
      "epoch": 12.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20325131714344025,
      "orthogonal_weight": 0.1,
      "step": 3835,
      "total_loss": 0.6591120958328247,
      "weighted_orthogonal_loss": 0.020325131714344025
    },
    {
      "classification_loss": 0.5614438056945801,
      "epoch": 12.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20340728759765625,
      "orthogonal_weight": 0.1,
      "step": 3836,
      "total_loss": 0.5817845463752747,
      "weighted_orthogonal_loss": 0.020340729504823685
    },
    {
      "classification_loss": 0.6168650388717651,
      "epoch": 12.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20351895689964294,
      "orthogonal_weight": 0.1,
      "step": 3837,
      "total_loss": 0.6372169256210327,
      "weighted_orthogonal_loss": 0.020351896062493324
    },
    {
      "classification_loss": 0.635553777217865,
      "epoch": 12.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20358417928218842,
      "orthogonal_weight": 0.1,
      "step": 3838,
      "total_loss": 0.6559122204780579,
      "weighted_orthogonal_loss": 0.02035841904580593
    },
    {
      "classification_loss": 0.5222333073616028,
      "epoch": 12.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20366139709949493,
      "orthogonal_weight": 0.1,
      "step": 3839,
      "total_loss": 0.5425994396209717,
      "weighted_orthogonal_loss": 0.020366139709949493
    },
    {
      "classification_loss": 0.5974500775337219,
      "epoch": 12.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20375089347362518,
      "orthogonal_weight": 0.1,
      "step": 3840,
      "total_loss": 0.6178251504898071,
      "weighted_orthogonal_loss": 0.020375089719891548
    },
    {
      "classification_loss": 0.5924721956253052,
      "epoch": 12.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2038963884115219,
      "orthogonal_weight": 0.1,
      "step": 3841,
      "total_loss": 0.6128618121147156,
      "weighted_orthogonal_loss": 0.02038963884115219
    },
    {
      "classification_loss": 0.5771874189376831,
      "epoch": 12.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2040364295244217,
      "orthogonal_weight": 0.1,
      "step": 3842,
      "total_loss": 0.5975910425186157,
      "weighted_orthogonal_loss": 0.02040364407002926
    },
    {
      "classification_loss": 0.5780832767486572,
      "epoch": 12.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20420366525650024,
      "orthogonal_weight": 0.1,
      "step": 3843,
      "total_loss": 0.5985036492347717,
      "weighted_orthogonal_loss": 0.020420366898179054
    },
    {
      "classification_loss": 0.6671282649040222,
      "epoch": 12.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20424433052539825,
      "orthogonal_weight": 0.1,
      "step": 3844,
      "total_loss": 0.6875526905059814,
      "weighted_orthogonal_loss": 0.020424433052539825
    },
    {
      "classification_loss": 0.6437087059020996,
      "epoch": 12.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20427294075489044,
      "orthogonal_weight": 0.1,
      "step": 3845,
      "total_loss": 0.6641359925270081,
      "weighted_orthogonal_loss": 0.020427294075489044
    },
    {
      "classification_loss": 0.7079190611839294,
      "epoch": 12.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20428785681724548,
      "orthogonal_weight": 0.1,
      "step": 3846,
      "total_loss": 0.7283478379249573,
      "weighted_orthogonal_loss": 0.020428786054253578
    },
    {
      "classification_loss": 0.6279128193855286,
      "epoch": 12.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20429816842079163,
      "orthogonal_weight": 0.1,
      "step": 3847,
      "total_loss": 0.6483426094055176,
      "weighted_orthogonal_loss": 0.020429817959666252
    },
    {
      "classification_loss": 0.5941522121429443,
      "epoch": 12.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20430614054203033,
      "orthogonal_weight": 0.1,
      "step": 3848,
      "total_loss": 0.6145828366279602,
      "weighted_orthogonal_loss": 0.020430615171790123
    },
    {
      "classification_loss": 0.664912223815918,
      "epoch": 12.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20428887009620667,
      "orthogonal_weight": 0.1,
      "step": 3849,
      "total_loss": 0.6853411197662354,
      "weighted_orthogonal_loss": 0.020428886637091637
    },
    {
      "classification_loss": 0.6039208769798279,
      "epoch": 12.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20430901646614075,
      "orthogonal_weight": 0.1,
      "step": 3850,
      "total_loss": 0.6243517994880676,
      "weighted_orthogonal_loss": 0.020430902019143105
    },
    {
      "classification_loss": 0.6035632491111755,
      "epoch": 12.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20421631634235382,
      "orthogonal_weight": 0.1,
      "step": 3851,
      "total_loss": 0.6239848732948303,
      "weighted_orthogonal_loss": 0.020421631634235382
    },
    {
      "classification_loss": 0.619411826133728,
      "epoch": 12.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20414377748966217,
      "orthogonal_weight": 0.1,
      "step": 3852,
      "total_loss": 0.6398261785507202,
      "weighted_orthogonal_loss": 0.020414378494024277
    },
    {
      "classification_loss": 0.6166490316390991,
      "epoch": 12.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20407821238040924,
      "orthogonal_weight": 0.1,
      "step": 3853,
      "total_loss": 0.637056827545166,
      "weighted_orthogonal_loss": 0.020407821983098984
    },
    {
      "classification_loss": 0.6173757314682007,
      "epoch": 12.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20399390161037445,
      "orthogonal_weight": 0.1,
      "step": 3854,
      "total_loss": 0.6377751231193542,
      "weighted_orthogonal_loss": 0.020399389788508415
    },
    {
      "classification_loss": 0.5920538306236267,
      "epoch": 12.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20388971269130707,
      "orthogonal_weight": 0.1,
      "step": 3855,
      "total_loss": 0.6124427914619446,
      "weighted_orthogonal_loss": 0.020388972014188766
    },
    {
      "classification_loss": 0.5947369933128357,
      "epoch": 12.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037188857793808,
      "orthogonal_weight": 0.1,
      "step": 3856,
      "total_loss": 0.6151089072227478,
      "weighted_orthogonal_loss": 0.02037188969552517
    },
    {
      "classification_loss": 0.6074908971786499,
      "epoch": 12.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20359022915363312,
      "orthogonal_weight": 0.1,
      "step": 3857,
      "total_loss": 0.6278499364852905,
      "weighted_orthogonal_loss": 0.020359022542834282
    },
    {
      "classification_loss": 0.6573801040649414,
      "epoch": 12.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20347614586353302,
      "orthogonal_weight": 0.1,
      "step": 3858,
      "total_loss": 0.6777276992797852,
      "weighted_orthogonal_loss": 0.02034761570394039
    },
    {
      "classification_loss": 0.5877106785774231,
      "epoch": 12.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20336022973060608,
      "orthogonal_weight": 0.1,
      "step": 3859,
      "total_loss": 0.6080467104911804,
      "weighted_orthogonal_loss": 0.020336022600531578
    },
    {
      "classification_loss": 0.619421124458313,
      "epoch": 12.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20328302681446075,
      "orthogonal_weight": 0.1,
      "step": 3860,
      "total_loss": 0.6397494077682495,
      "weighted_orthogonal_loss": 0.020328303799033165
    },
    {
      "classification_loss": 0.5924704074859619,
      "epoch": 12.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20321692526340485,
      "orthogonal_weight": 0.1,
      "step": 3861,
      "total_loss": 0.6127920746803284,
      "weighted_orthogonal_loss": 0.020321693271398544
    },
    {
      "classification_loss": 0.6349996328353882,
      "epoch": 12.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032211273908615,
      "orthogonal_weight": 0.1,
      "step": 3862,
      "total_loss": 0.6553217172622681,
      "weighted_orthogonal_loss": 0.02032211236655712
    },
    {
      "classification_loss": 0.583920955657959,
      "epoch": 12.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20328128337860107,
      "orthogonal_weight": 0.1,
      "step": 3863,
      "total_loss": 0.6042490601539612,
      "weighted_orthogonal_loss": 0.020328128710389137
    },
    {
      "classification_loss": 0.6142183542251587,
      "epoch": 12.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20342381298542023,
      "orthogonal_weight": 0.1,
      "step": 3864,
      "total_loss": 0.634560763835907,
      "weighted_orthogonal_loss": 0.020342381671071053
    },
    {
      "classification_loss": 0.696337878704071,
      "epoch": 12.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20353129506111145,
      "orthogonal_weight": 0.1,
      "step": 3865,
      "total_loss": 0.7166910171508789,
      "weighted_orthogonal_loss": 0.020353129133582115
    },
    {
      "classification_loss": 0.6419983506202698,
      "epoch": 12.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20359431207180023,
      "orthogonal_weight": 0.1,
      "step": 3866,
      "total_loss": 0.6623578071594238,
      "weighted_orthogonal_loss": 0.020359432324767113
    },
    {
      "classification_loss": 0.6172131896018982,
      "epoch": 12.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20369413495063782,
      "orthogonal_weight": 0.1,
      "step": 3867,
      "total_loss": 0.6375826001167297,
      "weighted_orthogonal_loss": 0.02036941424012184
    },
    {
      "classification_loss": 0.6464583873748779,
      "epoch": 12.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2038104385137558,
      "orthogonal_weight": 0.1,
      "step": 3868,
      "total_loss": 0.6668394207954407,
      "weighted_orthogonal_loss": 0.02038104459643364
    },
    {
      "classification_loss": 0.531104564666748,
      "epoch": 12.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20390376448631287,
      "orthogonal_weight": 0.1,
      "step": 3869,
      "total_loss": 0.5514949560165405,
      "weighted_orthogonal_loss": 0.020390376448631287
    },
    {
      "classification_loss": 0.5913213491439819,
      "epoch": 12.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2039518803358078,
      "orthogonal_weight": 0.1,
      "step": 3870,
      "total_loss": 0.6117165088653564,
      "weighted_orthogonal_loss": 0.02039518766105175
    },
    {
      "classification_loss": 0.6364157795906067,
      "epoch": 12.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20401613414287567,
      "orthogonal_weight": 0.1,
      "step": 3871,
      "total_loss": 0.6568173766136169,
      "weighted_orthogonal_loss": 0.020401613786816597
    },
    {
      "classification_loss": 0.5821909308433533,
      "epoch": 12.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20407450199127197,
      "orthogonal_weight": 0.1,
      "step": 3872,
      "total_loss": 0.6025983691215515,
      "weighted_orthogonal_loss": 0.020407451316714287
    },
    {
      "classification_loss": 0.6770572662353516,
      "epoch": 12.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20419426262378693,
      "orthogonal_weight": 0.1,
      "step": 3873,
      "total_loss": 0.6974766850471497,
      "weighted_orthogonal_loss": 0.020419426262378693
    },
    {
      "classification_loss": 0.5897873044013977,
      "epoch": 12.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2044043391942978,
      "orthogonal_weight": 0.1,
      "step": 3874,
      "total_loss": 0.6102277636528015,
      "weighted_orthogonal_loss": 0.02044043503701687
    },
    {
      "classification_loss": 0.6119222044944763,
      "epoch": 12.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20463185012340546,
      "orthogonal_weight": 0.1,
      "step": 3875,
      "total_loss": 0.6323853731155396,
      "weighted_orthogonal_loss": 0.020463185384869576
    },
    {
      "classification_loss": 0.6951854228973389,
      "epoch": 12.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.204834446310997,
      "orthogonal_weight": 0.1,
      "step": 3876,
      "total_loss": 0.7156688570976257,
      "weighted_orthogonal_loss": 0.02048344537615776
    },
    {
      "classification_loss": 0.6605736017227173,
      "epoch": 12.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20499582588672638,
      "orthogonal_weight": 0.1,
      "step": 3877,
      "total_loss": 0.6810731887817383,
      "weighted_orthogonal_loss": 0.020499583333730698
    },
    {
      "classification_loss": 0.5332581400871277,
      "epoch": 12.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20514526963233948,
      "orthogonal_weight": 0.1,
      "step": 3878,
      "total_loss": 0.5537726879119873,
      "weighted_orthogonal_loss": 0.020514527335762978
    },
    {
      "classification_loss": 0.5763500928878784,
      "epoch": 12.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20530425012111664,
      "orthogonal_weight": 0.1,
      "step": 3879,
      "total_loss": 0.5968804955482483,
      "weighted_orthogonal_loss": 0.020530425012111664
    },
    {
      "classification_loss": 0.6815103888511658,
      "epoch": 12.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054537832736969,
      "orthogonal_weight": 0.1,
      "step": 3880,
      "total_loss": 0.7020557522773743,
      "weighted_orthogonal_loss": 0.02054537832736969
    },
    {
      "classification_loss": 0.6378584504127502,
      "epoch": 12.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055640071630478,
      "orthogonal_weight": 0.1,
      "step": 3881,
      "total_loss": 0.6584148406982422,
      "weighted_orthogonal_loss": 0.02055640146136284
    },
    {
      "classification_loss": 0.6045836210250854,
      "epoch": 12.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20567573606967926,
      "orthogonal_weight": 0.1,
      "step": 3882,
      "total_loss": 0.6251512169837952,
      "weighted_orthogonal_loss": 0.020567573606967926
    },
    {
      "classification_loss": 0.6256674528121948,
      "epoch": 12.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20580001175403595,
      "orthogonal_weight": 0.1,
      "step": 3883,
      "total_loss": 0.6462474465370178,
      "weighted_orthogonal_loss": 0.020580001175403595
    },
    {
      "classification_loss": 0.6882634162902832,
      "epoch": 12.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20589721202850342,
      "orthogonal_weight": 0.1,
      "step": 3884,
      "total_loss": 0.7088531255722046,
      "weighted_orthogonal_loss": 0.02058972232043743
    },
    {
      "classification_loss": 0.5835556387901306,
      "epoch": 12.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20592494308948517,
      "orthogonal_weight": 0.1,
      "step": 3885,
      "total_loss": 0.6041481494903564,
      "weighted_orthogonal_loss": 0.020592493936419487
    },
    {
      "classification_loss": 0.5557191967964172,
      "epoch": 12.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20600613951683044,
      "orthogonal_weight": 0.1,
      "step": 3886,
      "total_loss": 0.5763198137283325,
      "weighted_orthogonal_loss": 0.020600615069270134
    },
    {
      "classification_loss": 0.571892499923706,
      "epoch": 12.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2060745656490326,
      "orthogonal_weight": 0.1,
      "step": 3887,
      "total_loss": 0.5924999713897705,
      "weighted_orthogonal_loss": 0.02060745656490326
    },
    {
      "classification_loss": 0.5333091616630554,
      "epoch": 12.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20614123344421387,
      "orthogonal_weight": 0.1,
      "step": 3888,
      "total_loss": 0.5539233088493347,
      "weighted_orthogonal_loss": 0.020614122971892357
    },
    {
      "classification_loss": 0.6183010339736938,
      "epoch": 12.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20624561607837677,
      "orthogonal_weight": 0.1,
      "step": 3889,
      "total_loss": 0.6389256119728088,
      "weighted_orthogonal_loss": 0.020624561235308647
    },
    {
      "classification_loss": 0.5928951501846313,
      "epoch": 12.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20634107291698456,
      "orthogonal_weight": 0.1,
      "step": 3890,
      "total_loss": 0.6135292649269104,
      "weighted_orthogonal_loss": 0.020634107291698456
    },
    {
      "classification_loss": 0.6019229888916016,
      "epoch": 12.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206485778093338,
      "orthogonal_weight": 0.1,
      "step": 3891,
      "total_loss": 0.622571587562561,
      "weighted_orthogonal_loss": 0.02064857818186283
    },
    {
      "classification_loss": 0.6781260967254639,
      "epoch": 12.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065849006175995,
      "orthogonal_weight": 0.1,
      "step": 3892,
      "total_loss": 0.698784589767456,
      "weighted_orthogonal_loss": 0.02065849117934704
    },
    {
      "classification_loss": 0.6709427833557129,
      "epoch": 12.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20664283633232117,
      "orthogonal_weight": 0.1,
      "step": 3893,
      "total_loss": 0.6916070580482483,
      "weighted_orthogonal_loss": 0.020664284005761147
    },
    {
      "classification_loss": 0.6199911832809448,
      "epoch": 12.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065955549478531,
      "orthogonal_weight": 0.1,
      "step": 3894,
      "total_loss": 0.640650749206543,
      "weighted_orthogonal_loss": 0.0206595566123724
    },
    {
      "classification_loss": 0.542719304561615,
      "epoch": 12.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065407782793045,
      "orthogonal_weight": 0.1,
      "step": 3895,
      "total_loss": 0.5633733868598938,
      "weighted_orthogonal_loss": 0.02065407857298851
    },
    {
      "classification_loss": 0.6352882385253906,
      "epoch": 12.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20649990439414978,
      "orthogonal_weight": 0.1,
      "step": 3896,
      "total_loss": 0.6559382081031799,
      "weighted_orthogonal_loss": 0.020649990066885948
    },
    {
      "classification_loss": 0.5809481739997864,
      "epoch": 12.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2064380794763565,
      "orthogonal_weight": 0.1,
      "step": 3897,
      "total_loss": 0.6015920042991638,
      "weighted_orthogonal_loss": 0.02064380794763565
    },
    {
      "classification_loss": 0.6622282266616821,
      "epoch": 12.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20640921592712402,
      "orthogonal_weight": 0.1,
      "step": 3898,
      "total_loss": 0.6828691363334656,
      "weighted_orthogonal_loss": 0.020640922710299492
    },
    {
      "classification_loss": 0.6539566516876221,
      "epoch": 12.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2063860148191452,
      "orthogonal_weight": 0.1,
      "step": 3899,
      "total_loss": 0.6745952367782593,
      "weighted_orthogonal_loss": 0.02063860185444355
    },
    {
      "epoch": 12.78688524590164,
      "grad_norm": 4.067472457885742,
      "learning_rate": 7.336666666666667e-05,
      "loss": 0.6405,
      "step": 3900
    },
    {
      "classification_loss": 0.596406877040863,
      "epoch": 12.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2063431441783905,
      "orthogonal_weight": 0.1,
      "step": 3900,
      "total_loss": 0.6170411705970764,
      "weighted_orthogonal_loss": 0.02063431404531002
    },
    {
      "classification_loss": 0.6623178720474243,
      "epoch": 12.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062898725271225,
      "orthogonal_weight": 0.1,
      "step": 3901,
      "total_loss": 0.6829468607902527,
      "weighted_orthogonal_loss": 0.02062898688018322
    },
    {
      "classification_loss": 0.5710649490356445,
      "epoch": 12.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20617437362670898,
      "orthogonal_weight": 0.1,
      "step": 3902,
      "total_loss": 0.5916823744773865,
      "weighted_orthogonal_loss": 0.020617438480257988
    },
    {
      "classification_loss": 0.5949170589447021,
      "epoch": 12.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20607255399227142,
      "orthogonal_weight": 0.1,
      "step": 3903,
      "total_loss": 0.6155242919921875,
      "weighted_orthogonal_loss": 0.020607255399227142
    },
    {
      "classification_loss": 0.6427273750305176,
      "epoch": 12.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059967964887619,
      "orthogonal_weight": 0.1,
      "step": 3904,
      "total_loss": 0.6633270382881165,
      "weighted_orthogonal_loss": 0.02059968002140522
    },
    {
      "classification_loss": 0.6512285470962524,
      "epoch": 12.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20593075454235077,
      "orthogonal_weight": 0.1,
      "step": 3905,
      "total_loss": 0.6718215942382812,
      "weighted_orthogonal_loss": 0.020593075081706047
    },
    {
      "classification_loss": 0.5688289999961853,
      "epoch": 12.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20589953660964966,
      "orthogonal_weight": 0.1,
      "step": 3906,
      "total_loss": 0.5894189476966858,
      "weighted_orthogonal_loss": 0.020589953288435936
    },
    {
      "classification_loss": 0.5936951637268066,
      "epoch": 12.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20585113763809204,
      "orthogonal_weight": 0.1,
      "step": 3907,
      "total_loss": 0.6142802834510803,
      "weighted_orthogonal_loss": 0.020585114136338234
    },
    {
      "classification_loss": 0.6064910292625427,
      "epoch": 12.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20581303536891937,
      "orthogonal_weight": 0.1,
      "step": 3908,
      "total_loss": 0.6270723342895508,
      "weighted_orthogonal_loss": 0.020581303164362907
    },
    {
      "classification_loss": 0.5944085121154785,
      "epoch": 12.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20557424426078796,
      "orthogonal_weight": 0.1,
      "step": 3909,
      "total_loss": 0.6149659156799316,
      "weighted_orthogonal_loss": 0.020557424053549767
    },
    {
      "classification_loss": 0.6911041140556335,
      "epoch": 12.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20539052784442902,
      "orthogonal_weight": 0.1,
      "step": 3910,
      "total_loss": 0.7116431593894958,
      "weighted_orthogonal_loss": 0.0205390527844429
    },
    {
      "classification_loss": 0.6555670499801636,
      "epoch": 12.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20520512759685516,
      "orthogonal_weight": 0.1,
      "step": 3911,
      "total_loss": 0.6760875582695007,
      "weighted_orthogonal_loss": 0.020520513877272606
    },
    {
      "classification_loss": 0.5976174473762512,
      "epoch": 12.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20501714944839478,
      "orthogonal_weight": 0.1,
      "step": 3912,
      "total_loss": 0.6181191802024841,
      "weighted_orthogonal_loss": 0.020501716062426567
    },
    {
      "classification_loss": 0.641512393951416,
      "epoch": 12.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20485231280326843,
      "orthogonal_weight": 0.1,
      "step": 3913,
      "total_loss": 0.6619976162910461,
      "weighted_orthogonal_loss": 0.020485231652855873
    },
    {
      "classification_loss": 0.5596597790718079,
      "epoch": 12.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20473602414131165,
      "orthogonal_weight": 0.1,
      "step": 3914,
      "total_loss": 0.5801333785057068,
      "weighted_orthogonal_loss": 0.020473603159189224
    },
    {
      "classification_loss": 0.7086718082427979,
      "epoch": 12.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045787125825882,
      "orthogonal_weight": 0.1,
      "step": 3915,
      "total_loss": 0.7291296720504761,
      "weighted_orthogonal_loss": 0.02045787125825882
    },
    {
      "classification_loss": 0.6278504133224487,
      "epoch": 12.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20442791283130646,
      "orthogonal_weight": 0.1,
      "step": 3916,
      "total_loss": 0.6482931971549988,
      "weighted_orthogonal_loss": 0.020442791283130646
    },
    {
      "classification_loss": 0.6907338500022888,
      "epoch": 12.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20439666509628296,
      "orthogonal_weight": 0.1,
      "step": 3917,
      "total_loss": 0.7111735343933105,
      "weighted_orthogonal_loss": 0.020439667627215385
    },
    {
      "classification_loss": 0.66358482837677,
      "epoch": 12.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20435896515846252,
      "orthogonal_weight": 0.1,
      "step": 3918,
      "total_loss": 0.6840206980705261,
      "weighted_orthogonal_loss": 0.020435897633433342
    },
    {
      "classification_loss": 0.606227695941925,
      "epoch": 12.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20431163907051086,
      "orthogonal_weight": 0.1,
      "step": 3919,
      "total_loss": 0.6266588568687439,
      "weighted_orthogonal_loss": 0.020431164652109146
    },
    {
      "classification_loss": 0.6679161787033081,
      "epoch": 12.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20427170395851135,
      "orthogonal_weight": 0.1,
      "step": 3920,
      "total_loss": 0.688343346118927,
      "weighted_orthogonal_loss": 0.020427171140909195
    },
    {
      "classification_loss": 0.5865713357925415,
      "epoch": 12.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20431822538375854,
      "orthogonal_weight": 0.1,
      "step": 3921,
      "total_loss": 0.6070031523704529,
      "weighted_orthogonal_loss": 0.020431822165846825
    },
    {
      "classification_loss": 0.5797924995422363,
      "epoch": 12.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20438207685947418,
      "orthogonal_weight": 0.1,
      "step": 3922,
      "total_loss": 0.6002306938171387,
      "weighted_orthogonal_loss": 0.02043820731341839
    },
    {
      "classification_loss": 0.6433223485946655,
      "epoch": 12.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20439746975898743,
      "orthogonal_weight": 0.1,
      "step": 3923,
      "total_loss": 0.663762092590332,
      "weighted_orthogonal_loss": 0.020439747720956802
    },
    {
      "classification_loss": 0.6368598341941833,
      "epoch": 12.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.204382061958313,
      "orthogonal_weight": 0.1,
      "step": 3924,
      "total_loss": 0.6572980284690857,
      "weighted_orthogonal_loss": 0.02043820731341839
    },
    {
      "classification_loss": 0.6246681213378906,
      "epoch": 12.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20437152683734894,
      "orthogonal_weight": 0.1,
      "step": 3925,
      "total_loss": 0.6451053023338318,
      "weighted_orthogonal_loss": 0.020437153056263924
    },
    {
      "classification_loss": 0.5783061385154724,
      "epoch": 12.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043701708316803,
      "orthogonal_weight": 0.1,
      "step": 3926,
      "total_loss": 0.5987431406974792,
      "weighted_orthogonal_loss": 0.02043701708316803
    },
    {
      "classification_loss": 0.5810998678207397,
      "epoch": 12.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20434831082820892,
      "orthogonal_weight": 0.1,
      "step": 3927,
      "total_loss": 0.6015347242355347,
      "weighted_orthogonal_loss": 0.020434832200407982
    },
    {
      "classification_loss": 0.6154975295066833,
      "epoch": 12.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20432265102863312,
      "orthogonal_weight": 0.1,
      "step": 3928,
      "total_loss": 0.6359298229217529,
      "weighted_orthogonal_loss": 0.02043226547539234
    },
    {
      "classification_loss": 0.6157287955284119,
      "epoch": 12.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20427092909812927,
      "orthogonal_weight": 0.1,
      "step": 3929,
      "total_loss": 0.636155903339386,
      "weighted_orthogonal_loss": 0.020427092909812927
    },
    {
      "classification_loss": 0.5813918113708496,
      "epoch": 12.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2041853815317154,
      "orthogonal_weight": 0.1,
      "step": 3930,
      "total_loss": 0.6018103361129761,
      "weighted_orthogonal_loss": 0.02041853778064251
    },
    {
      "classification_loss": 0.6255858540534973,
      "epoch": 12.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2040850818157196,
      "orthogonal_weight": 0.1,
      "step": 3931,
      "total_loss": 0.6459943652153015,
      "weighted_orthogonal_loss": 0.02040850929915905
    },
    {
      "classification_loss": 0.560435950756073,
      "epoch": 12.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20399676263332367,
      "orthogonal_weight": 0.1,
      "step": 3932,
      "total_loss": 0.5808356404304504,
      "weighted_orthogonal_loss": 0.020399676635861397
    },
    {
      "classification_loss": 0.6679720878601074,
      "epoch": 12.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20392034947872162,
      "orthogonal_weight": 0.1,
      "step": 3933,
      "total_loss": 0.6883641481399536,
      "weighted_orthogonal_loss": 0.02039203606545925
    },
    {
      "classification_loss": 0.6453632712364197,
      "epoch": 12.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20385868847370148,
      "orthogonal_weight": 0.1,
      "step": 3934,
      "total_loss": 0.6657491326332092,
      "weighted_orthogonal_loss": 0.020385868847370148
    },
    {
      "classification_loss": 0.6639686822891235,
      "epoch": 12.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20380191504955292,
      "orthogonal_weight": 0.1,
      "step": 3935,
      "total_loss": 0.6843488812446594,
      "weighted_orthogonal_loss": 0.020380191504955292
    },
    {
      "classification_loss": 0.6305265426635742,
      "epoch": 12.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20372597873210907,
      "orthogonal_weight": 0.1,
      "step": 3936,
      "total_loss": 0.6508991122245789,
      "weighted_orthogonal_loss": 0.020372597500681877
    },
    {
      "classification_loss": 0.629812479019165,
      "epoch": 12.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036505490541458,
      "orthogonal_weight": 0.1,
      "step": 3937,
      "total_loss": 0.650177538394928,
      "weighted_orthogonal_loss": 0.02036505565047264
    },
    {
      "classification_loss": 0.6045907735824585,
      "epoch": 12.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20349591970443726,
      "orthogonal_weight": 0.1,
      "step": 3938,
      "total_loss": 0.6249403953552246,
      "weighted_orthogonal_loss": 0.020349591970443726
    },
    {
      "classification_loss": 0.568110466003418,
      "epoch": 12.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20334361493587494,
      "orthogonal_weight": 0.1,
      "step": 3939,
      "total_loss": 0.5884448289871216,
      "weighted_orthogonal_loss": 0.020334361121058464
    },
    {
      "classification_loss": 0.6509971022605896,
      "epoch": 12.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320411026477814,
      "orthogonal_weight": 0.1,
      "step": 3940,
      "total_loss": 0.6713175177574158,
      "weighted_orthogonal_loss": 0.020320411771535873
    },
    {
      "classification_loss": 0.6389966011047363,
      "epoch": 12.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305733382701874,
      "orthogonal_weight": 0.1,
      "step": 3941,
      "total_loss": 0.6593023538589478,
      "weighted_orthogonal_loss": 0.020305734127759933
    },
    {
      "classification_loss": 0.6519190073013306,
      "epoch": 12.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028588503599167,
      "orthogonal_weight": 0.1,
      "step": 3942,
      "total_loss": 0.6722049117088318,
      "weighted_orthogonal_loss": 0.02028588578104973
    },
    {
      "classification_loss": 0.6118219494819641,
      "epoch": 12.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027660310268402,
      "orthogonal_weight": 0.1,
      "step": 3943,
      "total_loss": 0.6320985555648804,
      "weighted_orthogonal_loss": 0.02027660422027111
    },
    {
      "classification_loss": 0.6065091490745544,
      "epoch": 12.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20271067321300507,
      "orthogonal_weight": 0.1,
      "step": 3944,
      "total_loss": 0.6267802119255066,
      "weighted_orthogonal_loss": 0.020271068438887596
    },
    {
      "classification_loss": 0.6080408096313477,
      "epoch": 12.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20269499719142914,
      "orthogonal_weight": 0.1,
      "step": 3945,
      "total_loss": 0.6283103227615356,
      "weighted_orthogonal_loss": 0.020269500091671944
    },
    {
      "classification_loss": 0.6203563809394836,
      "epoch": 12.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2026817947626114,
      "orthogonal_weight": 0.1,
      "step": 3946,
      "total_loss": 0.6406245827674866,
      "weighted_orthogonal_loss": 0.02026817947626114
    },
    {
      "classification_loss": 0.67228764295578,
      "epoch": 12.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027033269405365,
      "orthogonal_weight": 0.1,
      "step": 3947,
      "total_loss": 0.6925579905509949,
      "weighted_orthogonal_loss": 0.02027033269405365
    },
    {
      "classification_loss": 0.5950976014137268,
      "epoch": 12.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027406096458435,
      "orthogonal_weight": 0.1,
      "step": 3948,
      "total_loss": 0.6153716444969177,
      "weighted_orthogonal_loss": 0.02027406170964241
    },
    {
      "classification_loss": 0.7753733396530151,
      "epoch": 12.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20282994210720062,
      "orthogonal_weight": 0.1,
      "step": 3949,
      "total_loss": 0.7956563234329224,
      "weighted_orthogonal_loss": 0.020282994955778122
    },
    {
      "classification_loss": 0.622728168964386,
      "epoch": 12.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20286250114440918,
      "orthogonal_weight": 0.1,
      "step": 3950,
      "total_loss": 0.6430144309997559,
      "weighted_orthogonal_loss": 0.020286250859498978
    },
    {
      "classification_loss": 0.6291208267211914,
      "epoch": 12.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20284505188465118,
      "orthogonal_weight": 0.1,
      "step": 3951,
      "total_loss": 0.6494053602218628,
      "weighted_orthogonal_loss": 0.020284505560994148
    },
    {
      "classification_loss": 0.6389399170875549,
      "epoch": 12.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20287688076496124,
      "orthogonal_weight": 0.1,
      "step": 3952,
      "total_loss": 0.6592276096343994,
      "weighted_orthogonal_loss": 0.020287688821554184
    },
    {
      "classification_loss": 0.5873565673828125,
      "epoch": 12.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20294927060604095,
      "orthogonal_weight": 0.1,
      "step": 3953,
      "total_loss": 0.6076514720916748,
      "weighted_orthogonal_loss": 0.020294927060604095
    },
    {
      "classification_loss": 0.6533887982368469,
      "epoch": 12.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20299121737480164,
      "orthogonal_weight": 0.1,
      "step": 3954,
      "total_loss": 0.6736879348754883,
      "weighted_orthogonal_loss": 0.020299121737480164
    },
    {
      "classification_loss": 0.5862727165222168,
      "epoch": 12.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030039280653,
      "orthogonal_weight": 0.1,
      "step": 3955,
      "total_loss": 0.6065731048583984,
      "weighted_orthogonal_loss": 0.02030039392411709
    },
    {
      "classification_loss": 0.6086861491203308,
      "epoch": 12.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20303459465503693,
      "orthogonal_weight": 0.1,
      "step": 3956,
      "total_loss": 0.6289896368980408,
      "weighted_orthogonal_loss": 0.020303459838032722
    },
    {
      "classification_loss": 0.6428884267807007,
      "epoch": 12.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305100083351135,
      "orthogonal_weight": 0.1,
      "step": 3957,
      "total_loss": 0.6631935238838196,
      "weighted_orthogonal_loss": 0.020305100828409195
    },
    {
      "classification_loss": 0.6401076912879944,
      "epoch": 12.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305395126342773,
      "orthogonal_weight": 0.1,
      "step": 3958,
      "total_loss": 0.6604130864143372,
      "weighted_orthogonal_loss": 0.020305395126342773
    },
    {
      "classification_loss": 0.668560266494751,
      "epoch": 12.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20303615927696228,
      "orthogonal_weight": 0.1,
      "step": 3959,
      "total_loss": 0.6888638734817505,
      "weighted_orthogonal_loss": 0.020303616300225258
    },
    {
      "classification_loss": 0.5818291306495667,
      "epoch": 12.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20299185812473297,
      "orthogonal_weight": 0.1,
      "step": 3960,
      "total_loss": 0.6021283268928528,
      "weighted_orthogonal_loss": 0.020299186930060387
    },
    {
      "classification_loss": 0.5699833035469055,
      "epoch": 12.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20292633771896362,
      "orthogonal_weight": 0.1,
      "step": 3961,
      "total_loss": 0.5902759432792664,
      "weighted_orthogonal_loss": 0.020292634144425392
    },
    {
      "classification_loss": 0.5866835713386536,
      "epoch": 12.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029600888490677,
      "orthogonal_weight": 0.1,
      "step": 3962,
      "total_loss": 0.6069796085357666,
      "weighted_orthogonal_loss": 0.0202960092574358
    },
    {
      "classification_loss": 0.5857834815979004,
      "epoch": 12.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030014842748642,
      "orthogonal_weight": 0.1,
      "step": 3963,
      "total_loss": 0.6060836315155029,
      "weighted_orthogonal_loss": 0.02030014805495739
    },
    {
      "classification_loss": 0.5620390176773071,
      "epoch": 12.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203074112534523,
      "orthogonal_weight": 0.1,
      "step": 3964,
      "total_loss": 0.5823464393615723,
      "weighted_orthogonal_loss": 0.02030741237103939
    },
    {
      "classification_loss": 0.6968815922737122,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.717194676399231,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.7010995745658875,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.7214126586914062,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.6859560012817383,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.7062690854072571,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.7073414921760559,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.7276545763015747,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.6965973973274231,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.7169104814529419,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.693223774433136,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.7135368585586548,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.6758609414100647,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.6961740255355835,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.7122430801391602,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.732556164264679,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.514,
      "eval_f1": 0.558983666061706,
      "eval_loss": 0.7160772681236267,
      "eval_precision": 0.6430062630480167,
      "eval_recall": 0.4943820224719101,
      "eval_runtime": 6.1806,
      "eval_samples_per_second": 161.797,
      "eval_steps_per_second": 1.294,
      "step": 3965
    },
    {
      "classification_loss": 0.6761866211891174,
      "epoch": 13.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313091576099396,
      "orthogonal_weight": 0.1,
      "step": 3965,
      "total_loss": 0.6964997053146362,
      "weighted_orthogonal_loss": 0.020313091576099396
    },
    {
      "classification_loss": 0.6250228881835938,
      "epoch": 13.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20319359004497528,
      "orthogonal_weight": 0.1,
      "step": 3966,
      "total_loss": 0.645342230796814,
      "weighted_orthogonal_loss": 0.020319359377026558
    },
    {
      "classification_loss": 0.6026926040649414,
      "epoch": 13.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20321692526340485,
      "orthogonal_weight": 0.1,
      "step": 3967,
      "total_loss": 0.6230142712593079,
      "weighted_orthogonal_loss": 0.020321693271398544
    },
    {
      "classification_loss": 0.5827338695526123,
      "epoch": 13.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20324774086475372,
      "orthogonal_weight": 0.1,
      "step": 3968,
      "total_loss": 0.6030586361885071,
      "weighted_orthogonal_loss": 0.020324774086475372
    },
    {
      "classification_loss": 0.6865500211715698,
      "epoch": 13.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033068835735321,
      "orthogonal_weight": 0.1,
      "step": 3969,
      "total_loss": 0.7068806886672974,
      "weighted_orthogonal_loss": 0.02033068798482418
    },
    {
      "classification_loss": 0.6102930903434753,
      "epoch": 13.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20335112512111664,
      "orthogonal_weight": 0.1,
      "step": 3970,
      "total_loss": 0.630628228187561,
      "weighted_orthogonal_loss": 0.020335113629698753
    },
    {
      "classification_loss": 0.6217867136001587,
      "epoch": 13.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034074366092682,
      "orthogonal_weight": 0.1,
      "step": 3971,
      "total_loss": 0.6421274542808533,
      "weighted_orthogonal_loss": 0.02034074440598488
    },
    {
      "classification_loss": 0.6054633855819702,
      "epoch": 13.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20345301926136017,
      "orthogonal_weight": 0.1,
      "step": 3972,
      "total_loss": 0.6258087158203125,
      "weighted_orthogonal_loss": 0.020345302298665047
    },
    {
      "classification_loss": 0.6159859299659729,
      "epoch": 13.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20352141559123993,
      "orthogonal_weight": 0.1,
      "step": 3973,
      "total_loss": 0.6363380551338196,
      "weighted_orthogonal_loss": 0.020352141931653023
    },
    {
      "classification_loss": 0.625540018081665,
      "epoch": 13.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203608900308609,
      "orthogonal_weight": 0.1,
      "step": 3974,
      "total_loss": 0.6459009051322937,
      "weighted_orthogonal_loss": 0.02036089077591896
    },
    {
      "classification_loss": 0.5956734418869019,
      "epoch": 13.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037000209093094,
      "orthogonal_weight": 0.1,
      "step": 3975,
      "total_loss": 0.6160434484481812,
      "weighted_orthogonal_loss": 0.020370002835989
    },
    {
      "classification_loss": 0.5475828051567078,
      "epoch": 13.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037278413772583,
      "orthogonal_weight": 0.1,
      "step": 3976,
      "total_loss": 0.5679556131362915,
      "weighted_orthogonal_loss": 0.0203727837651968
    },
    {
      "classification_loss": 0.544152557849884,
      "epoch": 13.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20377042889595032,
      "orthogonal_weight": 0.1,
      "step": 3977,
      "total_loss": 0.5645295977592468,
      "weighted_orthogonal_loss": 0.02037704363465309
    },
    {
      "classification_loss": 0.6853955984115601,
      "epoch": 13.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2038242369890213,
      "orthogonal_weight": 0.1,
      "step": 3978,
      "total_loss": 0.7057780027389526,
      "weighted_orthogonal_loss": 0.02038242481648922
    },
    {
      "classification_loss": 0.6641449332237244,
      "epoch": 13.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20388105511665344,
      "orthogonal_weight": 0.1,
      "step": 3979,
      "total_loss": 0.6845330595970154,
      "weighted_orthogonal_loss": 0.020388105884194374
    },
    {
      "classification_loss": 0.6838987469673157,
      "epoch": 13.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2039055973291397,
      "orthogonal_weight": 0.1,
      "step": 3980,
      "total_loss": 0.7042893171310425,
      "weighted_orthogonal_loss": 0.02039056085050106
    },
    {
      "classification_loss": 0.5785335898399353,
      "epoch": 13.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203927680850029,
      "orthogonal_weight": 0.1,
      "step": 3981,
      "total_loss": 0.5989263653755188,
      "weighted_orthogonal_loss": 0.0203927680850029
    },
    {
      "classification_loss": 0.6018118262290955,
      "epoch": 13.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20396235585212708,
      "orthogonal_weight": 0.1,
      "step": 3982,
      "total_loss": 0.6222080588340759,
      "weighted_orthogonal_loss": 0.020396236330270767
    },
    {
      "classification_loss": 0.5988869071006775,
      "epoch": 13.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20400641858577728,
      "orthogonal_weight": 0.1,
      "step": 3983,
      "total_loss": 0.6192875504493713,
      "weighted_orthogonal_loss": 0.0204006414860487
    },
    {
      "classification_loss": 0.6430624127388,
      "epoch": 13.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2040596604347229,
      "orthogonal_weight": 0.1,
      "step": 3984,
      "total_loss": 0.6634683609008789,
      "weighted_orthogonal_loss": 0.02040596678853035
    },
    {
      "classification_loss": 0.593973696231842,
      "epoch": 13.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2041274905204773,
      "orthogonal_weight": 0.1,
      "step": 3985,
      "total_loss": 0.6143864393234253,
      "weighted_orthogonal_loss": 0.0204127486795187
    },
    {
      "classification_loss": 0.6070327162742615,
      "epoch": 13.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20420539379119873,
      "orthogonal_weight": 0.1,
      "step": 3986,
      "total_loss": 0.6274532675743103,
      "weighted_orthogonal_loss": 0.020420540124177933
    },
    {
      "classification_loss": 0.656975269317627,
      "epoch": 13.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20428816974163055,
      "orthogonal_weight": 0.1,
      "step": 3987,
      "total_loss": 0.6774041056632996,
      "weighted_orthogonal_loss": 0.020428817719221115
    },
    {
      "classification_loss": 0.588866651058197,
      "epoch": 13.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043515145778656,
      "orthogonal_weight": 0.1,
      "step": 3988,
      "total_loss": 0.6093018054962158,
      "weighted_orthogonal_loss": 0.02043515257537365
    },
    {
      "classification_loss": 0.6029210090637207,
      "epoch": 13.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20438483357429504,
      "orthogonal_weight": 0.1,
      "step": 3989,
      "total_loss": 0.6233595013618469,
      "weighted_orthogonal_loss": 0.020438482984900475
    },
    {
      "classification_loss": 0.5556643009185791,
      "epoch": 13.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20443226397037506,
      "orthogonal_weight": 0.1,
      "step": 3990,
      "total_loss": 0.5761075019836426,
      "weighted_orthogonal_loss": 0.020443227142095566
    },
    {
      "classification_loss": 0.5417293906211853,
      "epoch": 13.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20439444482326508,
      "orthogonal_weight": 0.1,
      "step": 3991,
      "total_loss": 0.5621688365936279,
      "weighted_orthogonal_loss": 0.020439444109797478
    },
    {
      "classification_loss": 0.6394184231758118,
      "epoch": 13.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20436592400074005,
      "orthogonal_weight": 0.1,
      "step": 3992,
      "total_loss": 0.6598550081253052,
      "weighted_orthogonal_loss": 0.020436592400074005
    },
    {
      "classification_loss": 0.6213717460632324,
      "epoch": 13.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043074071407318,
      "orthogonal_weight": 0.1,
      "step": 3993,
      "total_loss": 0.6418024897575378,
      "weighted_orthogonal_loss": 0.02043074183166027
    },
    {
      "classification_loss": 0.5895504951477051,
      "epoch": 13.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20423302054405212,
      "orthogonal_weight": 0.1,
      "step": 3994,
      "total_loss": 0.6099737882614136,
      "weighted_orthogonal_loss": 0.020423302426934242
    },
    {
      "classification_loss": 0.6152596473693848,
      "epoch": 13.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20425868034362793,
      "orthogonal_weight": 0.1,
      "step": 3995,
      "total_loss": 0.6356855034828186,
      "weighted_orthogonal_loss": 0.020425869151949883
    },
    {
      "classification_loss": 0.6155547499656677,
      "epoch": 13.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20421001315116882,
      "orthogonal_weight": 0.1,
      "step": 3996,
      "total_loss": 0.6359757781028748,
      "weighted_orthogonal_loss": 0.020421002060174942
    },
    {
      "classification_loss": 0.5934627652168274,
      "epoch": 13.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2041664570569992,
      "orthogonal_weight": 0.1,
      "step": 3997,
      "total_loss": 0.613879382610321,
      "weighted_orthogonal_loss": 0.02041664533317089
    },
    {
      "classification_loss": 0.5604584813117981,
      "epoch": 13.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.204131081700325,
      "orthogonal_weight": 0.1,
      "step": 3998,
      "total_loss": 0.58087158203125,
      "weighted_orthogonal_loss": 0.0204131081700325
    },
    {
      "classification_loss": 0.6668291091918945,
      "epoch": 13.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20405228435993195,
      "orthogonal_weight": 0.1,
      "step": 3999,
      "total_loss": 0.6872343420982361,
      "weighted_orthogonal_loss": 0.020405229181051254
    },
    {
      "epoch": 13.114754098360656,
      "grad_norm": 24.79193115234375,
      "learning_rate": 7.003333333333335e-05,
      "loss": 0.6391,
      "step": 4000
    },
    {
      "classification_loss": 0.547481119632721,
      "epoch": 13.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2039664089679718,
      "orthogonal_weight": 0.1,
      "step": 4000,
      "total_loss": 0.5678777694702148,
      "weighted_orthogonal_loss": 0.02039664052426815
    },
    {
      "classification_loss": 0.589474618434906,
      "epoch": 13.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20394288003444672,
      "orthogonal_weight": 0.1,
      "step": 4001,
      "total_loss": 0.6098688840866089,
      "weighted_orthogonal_loss": 0.02039428800344467
    },
    {
      "classification_loss": 0.6438143253326416,
      "epoch": 13.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20393629372119904,
      "orthogonal_weight": 0.1,
      "step": 4002,
      "total_loss": 0.664207935333252,
      "weighted_orthogonal_loss": 0.020393630489706993
    },
    {
      "classification_loss": 0.6242982745170593,
      "epoch": 13.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20391400158405304,
      "orthogonal_weight": 0.1,
      "step": 4003,
      "total_loss": 0.644689679145813,
      "weighted_orthogonal_loss": 0.020391400903463364
    },
    {
      "classification_loss": 0.6573174595832825,
      "epoch": 13.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20392242074012756,
      "orthogonal_weight": 0.1,
      "step": 4004,
      "total_loss": 0.677709698677063,
      "weighted_orthogonal_loss": 0.020392242819070816
    },
    {
      "classification_loss": 0.5438645482063293,
      "epoch": 13.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20399899780750275,
      "orthogonal_weight": 0.1,
      "step": 4005,
      "total_loss": 0.5642644762992859,
      "weighted_orthogonal_loss": 0.020399900153279305
    },
    {
      "classification_loss": 0.6936455965042114,
      "epoch": 13.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20405806601047516,
      "orthogonal_weight": 0.1,
      "step": 4006,
      "total_loss": 0.7140514254570007,
      "weighted_orthogonal_loss": 0.020405806601047516
    },
    {
      "classification_loss": 0.5984503030776978,
      "epoch": 13.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20409558713436127,
      "orthogonal_weight": 0.1,
      "step": 4007,
      "total_loss": 0.6188598871231079,
      "weighted_orthogonal_loss": 0.020409559831023216
    },
    {
      "classification_loss": 0.6308010816574097,
      "epoch": 13.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20411577820777893,
      "orthogonal_weight": 0.1,
      "step": 4008,
      "total_loss": 0.6512126326560974,
      "weighted_orthogonal_loss": 0.020411578938364983
    },
    {
      "classification_loss": 0.6282222867012024,
      "epoch": 13.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20413543283939362,
      "orthogonal_weight": 0.1,
      "step": 4009,
      "total_loss": 0.6486358046531677,
      "weighted_orthogonal_loss": 0.02041354402899742
    },
    {
      "classification_loss": 0.5718041658401489,
      "epoch": 13.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20417439937591553,
      "orthogonal_weight": 0.1,
      "step": 4010,
      "total_loss": 0.5922216176986694,
      "weighted_orthogonal_loss": 0.020417440682649612
    },
    {
      "classification_loss": 0.5667505264282227,
      "epoch": 13.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20422345399856567,
      "orthogonal_weight": 0.1,
      "step": 4011,
      "total_loss": 0.5871728658676147,
      "weighted_orthogonal_loss": 0.020422345027327538
    },
    {
      "classification_loss": 0.5528669357299805,
      "epoch": 13.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20425553619861603,
      "orthogonal_weight": 0.1,
      "step": 4012,
      "total_loss": 0.5732924938201904,
      "weighted_orthogonal_loss": 0.020425554364919662
    },
    {
      "classification_loss": 0.5641283988952637,
      "epoch": 13.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20442500710487366,
      "orthogonal_weight": 0.1,
      "step": 4013,
      "total_loss": 0.5845708847045898,
      "weighted_orthogonal_loss": 0.020442500710487366
    },
    {
      "classification_loss": 0.582527220249176,
      "epoch": 13.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045743614435196,
      "orthogonal_weight": 0.1,
      "step": 4014,
      "total_loss": 0.6029846668243408,
      "weighted_orthogonal_loss": 0.02045743726193905
    },
    {
      "classification_loss": 0.5931200385093689,
      "epoch": 13.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20471438765525818,
      "orthogonal_weight": 0.1,
      "step": 4015,
      "total_loss": 0.6135914921760559,
      "weighted_orthogonal_loss": 0.020471438765525818
    },
    {
      "classification_loss": 0.6057710647583008,
      "epoch": 13.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20487546920776367,
      "orthogonal_weight": 0.1,
      "step": 4016,
      "total_loss": 0.6262586116790771,
      "weighted_orthogonal_loss": 0.020487546920776367
    },
    {
      "classification_loss": 0.7517743706703186,
      "epoch": 13.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2049860656261444,
      "orthogonal_weight": 0.1,
      "step": 4017,
      "total_loss": 0.7722730040550232,
      "weighted_orthogonal_loss": 0.0204986073076725
    },
    {
      "classification_loss": 0.6085042357444763,
      "epoch": 13.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2051059752702713,
      "orthogonal_weight": 0.1,
      "step": 4018,
      "total_loss": 0.6290148496627808,
      "weighted_orthogonal_loss": 0.0205105971544981
    },
    {
      "classification_loss": 0.599370002746582,
      "epoch": 13.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205253005027771,
      "orthogonal_weight": 0.1,
      "step": 4019,
      "total_loss": 0.6198952794075012,
      "weighted_orthogonal_loss": 0.02052530087530613
    },
    {
      "classification_loss": 0.7200309634208679,
      "epoch": 13.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20541904866695404,
      "orthogonal_weight": 0.1,
      "step": 4020,
      "total_loss": 0.7405728697776794,
      "weighted_orthogonal_loss": 0.020541904494166374
    },
    {
      "classification_loss": 0.7230132818222046,
      "epoch": 13.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2053748518228531,
      "orthogonal_weight": 0.1,
      "step": 4021,
      "total_loss": 0.7435507774353027,
      "weighted_orthogonal_loss": 0.0205374862998724
    },
    {
      "classification_loss": 0.6417201161384583,
      "epoch": 13.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20520342886447906,
      "orthogonal_weight": 0.1,
      "step": 4022,
      "total_loss": 0.6622404456138611,
      "weighted_orthogonal_loss": 0.020520342513918877
    },
    {
      "classification_loss": 0.6835092902183533,
      "epoch": 13.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20502528548240662,
      "orthogonal_weight": 0.1,
      "step": 4023,
      "total_loss": 0.7040117979049683,
      "weighted_orthogonal_loss": 0.020502528175711632
    },
    {
      "classification_loss": 0.6371944546699524,
      "epoch": 13.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20488661527633667,
      "orthogonal_weight": 0.1,
      "step": 4024,
      "total_loss": 0.6576831340789795,
      "weighted_orthogonal_loss": 0.020488662645220757
    },
    {
      "classification_loss": 0.6829347610473633,
      "epoch": 13.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20479081571102142,
      "orthogonal_weight": 0.1,
      "step": 4025,
      "total_loss": 0.7034138441085815,
      "weighted_orthogonal_loss": 0.020479081198573112
    },
    {
      "classification_loss": 0.6695888042449951,
      "epoch": 13.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045847773551941,
      "orthogonal_weight": 0.1,
      "step": 4026,
      "total_loss": 0.6900472640991211,
      "weighted_orthogonal_loss": 0.02045847848057747
    },
    {
      "classification_loss": 0.6025359034538269,
      "epoch": 13.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20442257821559906,
      "orthogonal_weight": 0.1,
      "step": 4027,
      "total_loss": 0.622978150844574,
      "weighted_orthogonal_loss": 0.020442258566617966
    },
    {
      "classification_loss": 0.5852833390235901,
      "epoch": 13.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20422475039958954,
      "orthogonal_weight": 0.1,
      "step": 4028,
      "total_loss": 0.6057057976722717,
      "weighted_orthogonal_loss": 0.020422475412487984
    },
    {
      "classification_loss": 0.6272324919700623,
      "epoch": 13.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20408077538013458,
      "orthogonal_weight": 0.1,
      "step": 4029,
      "total_loss": 0.647640585899353,
      "weighted_orthogonal_loss": 0.02040807716548443
    },
    {
      "classification_loss": 0.5568161606788635,
      "epoch": 13.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20394346117973328,
      "orthogonal_weight": 0.1,
      "step": 4030,
      "total_loss": 0.5772104859352112,
      "weighted_orthogonal_loss": 0.020394345745444298
    },
    {
      "classification_loss": 0.645450234413147,
      "epoch": 13.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20389655232429504,
      "orthogonal_weight": 0.1,
      "step": 4031,
      "total_loss": 0.6658399105072021,
      "weighted_orthogonal_loss": 0.020389655604958534
    },
    {
      "classification_loss": 0.6513124704360962,
      "epoch": 13.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20383062958717346,
      "orthogonal_weight": 0.1,
      "step": 4032,
      "total_loss": 0.6716955304145813,
      "weighted_orthogonal_loss": 0.020383063703775406
    },
    {
      "classification_loss": 0.585931658744812,
      "epoch": 13.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20375482738018036,
      "orthogonal_weight": 0.1,
      "step": 4033,
      "total_loss": 0.6063071489334106,
      "weighted_orthogonal_loss": 0.020375482738018036
    },
    {
      "classification_loss": 0.6441746354103088,
      "epoch": 13.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036961317062378,
      "orthogonal_weight": 0.1,
      "step": 4034,
      "total_loss": 0.6645442247390747,
      "weighted_orthogonal_loss": 0.02036961354315281
    },
    {
      "classification_loss": 0.6432222127914429,
      "epoch": 13.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20364755392074585,
      "orthogonal_weight": 0.1,
      "step": 4035,
      "total_loss": 0.6635869741439819,
      "weighted_orthogonal_loss": 0.020364755764603615
    },
    {
      "classification_loss": 0.5711585283279419,
      "epoch": 13.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203579843044281,
      "orthogonal_weight": 0.1,
      "step": 4036,
      "total_loss": 0.5915164947509766,
      "weighted_orthogonal_loss": 0.02035798504948616
    },
    {
      "classification_loss": 0.5540891289710999,
      "epoch": 13.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20351667702198029,
      "orthogonal_weight": 0.1,
      "step": 4037,
      "total_loss": 0.5744407773017883,
      "weighted_orthogonal_loss": 0.020351668819785118
    },
    {
      "classification_loss": 0.5787075757980347,
      "epoch": 13.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20348890125751495,
      "orthogonal_weight": 0.1,
      "step": 4038,
      "total_loss": 0.5990564823150635,
      "weighted_orthogonal_loss": 0.020348889753222466
    },
    {
      "classification_loss": 0.5636112093925476,
      "epoch": 13.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034686654806137,
      "orthogonal_weight": 0.1,
      "step": 4039,
      "total_loss": 0.583958089351654,
      "weighted_orthogonal_loss": 0.0203468669205904
    },
    {
      "classification_loss": 0.5894037485122681,
      "epoch": 13.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20343628525733948,
      "orthogonal_weight": 0.1,
      "step": 4040,
      "total_loss": 0.6097473502159119,
      "weighted_orthogonal_loss": 0.020343629643321037
    },
    {
      "classification_loss": 0.6387791633605957,
      "epoch": 13.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20339471101760864,
      "orthogonal_weight": 0.1,
      "step": 4041,
      "total_loss": 0.65911865234375,
      "weighted_orthogonal_loss": 0.020339472219347954
    },
    {
      "classification_loss": 0.5864646434783936,
      "epoch": 13.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20334598422050476,
      "orthogonal_weight": 0.1,
      "step": 4042,
      "total_loss": 0.6067992448806763,
      "weighted_orthogonal_loss": 0.020334599539637566
    },
    {
      "classification_loss": 0.6605603694915771,
      "epoch": 13.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329393446445465,
      "orthogonal_weight": 0.1,
      "step": 4043,
      "total_loss": 0.6808897852897644,
      "weighted_orthogonal_loss": 0.020329393446445465
    },
    {
      "classification_loss": 0.6336538791656494,
      "epoch": 13.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032565027475357,
      "orthogonal_weight": 0.1,
      "step": 4044,
      "total_loss": 0.6539795398712158,
      "weighted_orthogonal_loss": 0.02032565139234066
    },
    {
      "classification_loss": 0.5815500020980835,
      "epoch": 13.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20318838953971863,
      "orthogonal_weight": 0.1,
      "step": 4045,
      "total_loss": 0.6018688678741455,
      "weighted_orthogonal_loss": 0.020318839699029922
    },
    {
      "classification_loss": 0.5316833853721619,
      "epoch": 13.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20315596461296082,
      "orthogonal_weight": 0.1,
      "step": 4046,
      "total_loss": 0.5519989728927612,
      "weighted_orthogonal_loss": 0.02031559683382511
    },
    {
      "classification_loss": 0.6616775989532471,
      "epoch": 13.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031729817390442,
      "orthogonal_weight": 0.1,
      "step": 4047,
      "total_loss": 0.6819949150085449,
      "weighted_orthogonal_loss": 0.02031729929149151
    },
    {
      "classification_loss": 0.6084509491920471,
      "epoch": 13.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320937037467957,
      "orthogonal_weight": 0.1,
      "step": 4048,
      "total_loss": 0.6287719011306763,
      "weighted_orthogonal_loss": 0.020320937037467957
    },
    {
      "classification_loss": 0.6334655284881592,
      "epoch": 13.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20323748886585236,
      "orthogonal_weight": 0.1,
      "step": 4049,
      "total_loss": 0.6537892818450928,
      "weighted_orthogonal_loss": 0.020323749631643295
    },
    {
      "classification_loss": 0.625359058380127,
      "epoch": 13.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20334281027317047,
      "orthogonal_weight": 0.1,
      "step": 4050,
      "total_loss": 0.6456933617591858,
      "weighted_orthogonal_loss": 0.020334281027317047
    },
    {
      "classification_loss": 0.5771461725234985,
      "epoch": 13.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20345443487167358,
      "orthogonal_weight": 0.1,
      "step": 4051,
      "total_loss": 0.5974916219711304,
      "weighted_orthogonal_loss": 0.020345443859696388
    },
    {
      "classification_loss": 0.6182956695556641,
      "epoch": 13.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20350079238414764,
      "orthogonal_weight": 0.1,
      "step": 4052,
      "total_loss": 0.6386457681655884,
      "weighted_orthogonal_loss": 0.020350079983472824
    },
    {
      "classification_loss": 0.6909823417663574,
      "epoch": 13.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20357243716716766,
      "orthogonal_weight": 0.1,
      "step": 4053,
      "total_loss": 0.7113395929336548,
      "weighted_orthogonal_loss": 0.020357243716716766
    },
    {
      "classification_loss": 0.6170692443847656,
      "epoch": 13.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036363035440445,
      "orthogonal_weight": 0.1,
      "step": 4054,
      "total_loss": 0.637432873249054,
      "weighted_orthogonal_loss": 0.02036363072693348
    },
    {
      "classification_loss": 0.6350744366645813,
      "epoch": 13.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20369994640350342,
      "orthogonal_weight": 0.1,
      "step": 4055,
      "total_loss": 0.6554444432258606,
      "weighted_orthogonal_loss": 0.0203699953854084
    },
    {
      "classification_loss": 0.6271771192550659,
      "epoch": 13.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20377217233181,
      "orthogonal_weight": 0.1,
      "step": 4056,
      "total_loss": 0.647554337978363,
      "weighted_orthogonal_loss": 0.02037721686065197
    },
    {
      "classification_loss": 0.585355818271637,
      "epoch": 13.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2038392573595047,
      "orthogonal_weight": 0.1,
      "step": 4057,
      "total_loss": 0.6057397723197937,
      "weighted_orthogonal_loss": 0.0203839261084795
    },
    {
      "classification_loss": 0.6392853260040283,
      "epoch": 13.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20388633012771606,
      "orthogonal_weight": 0.1,
      "step": 4058,
      "total_loss": 0.6596739292144775,
      "weighted_orthogonal_loss": 0.020388633012771606
    },
    {
      "classification_loss": 0.6620040535926819,
      "epoch": 13.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20398421585559845,
      "orthogonal_weight": 0.1,
      "step": 4059,
      "total_loss": 0.682402491569519,
      "weighted_orthogonal_loss": 0.020398421213030815
    },
    {
      "classification_loss": 0.6078004240989685,
      "epoch": 13.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2040656954050064,
      "orthogonal_weight": 0.1,
      "step": 4060,
      "total_loss": 0.6282069683074951,
      "weighted_orthogonal_loss": 0.0204065702855587
    },
    {
      "classification_loss": 0.6157265305519104,
      "epoch": 13.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20417554676532745,
      "orthogonal_weight": 0.1,
      "step": 4061,
      "total_loss": 0.6361441016197205,
      "weighted_orthogonal_loss": 0.020417554304003716
    },
    {
      "classification_loss": 0.5840868949890137,
      "epoch": 13.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20433156192302704,
      "orthogonal_weight": 0.1,
      "step": 4062,
      "total_loss": 0.6045200228691101,
      "weighted_orthogonal_loss": 0.020433155819773674
    },
    {
      "classification_loss": 0.6732400059700012,
      "epoch": 13.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20457234978675842,
      "orthogonal_weight": 0.1,
      "step": 4063,
      "total_loss": 0.6936972141265869,
      "weighted_orthogonal_loss": 0.020457236096262932
    },
    {
      "classification_loss": 0.6502084732055664,
      "epoch": 13.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20483823120594025,
      "orthogonal_weight": 0.1,
      "step": 4064,
      "total_loss": 0.6706923246383667,
      "weighted_orthogonal_loss": 0.020483823493123055
    },
    {
      "classification_loss": 0.6813350319862366,
      "epoch": 13.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20510131120681763,
      "orthogonal_weight": 0.1,
      "step": 4065,
      "total_loss": 0.7018451690673828,
      "weighted_orthogonal_loss": 0.020510131493210793
    },
    {
      "classification_loss": 0.6236699819564819,
      "epoch": 13.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2053506225347519,
      "orthogonal_weight": 0.1,
      "step": 4066,
      "total_loss": 0.6442050337791443,
      "weighted_orthogonal_loss": 0.02053506299853325
    },
    {
      "classification_loss": 0.6903913021087646,
      "epoch": 13.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20558299124240875,
      "orthogonal_weight": 0.1,
      "step": 4067,
      "total_loss": 0.7109495997428894,
      "weighted_orthogonal_loss": 0.020558299496769905
    },
    {
      "classification_loss": 0.6778232455253601,
      "epoch": 13.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20571689307689667,
      "orthogonal_weight": 0.1,
      "step": 4068,
      "total_loss": 0.6983949542045593,
      "weighted_orthogonal_loss": 0.020571690052747726
    },
    {
      "classification_loss": 0.6853146553039551,
      "epoch": 13.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20584988594055176,
      "orthogonal_weight": 0.1,
      "step": 4069,
      "total_loss": 0.7058996558189392,
      "weighted_orthogonal_loss": 0.020584989339113235
    },
    {
      "classification_loss": 0.6590197086334229,
      "epoch": 13.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059604823589325,
      "orthogonal_weight": 0.1,
      "step": 4070,
      "total_loss": 0.6796157360076904,
      "weighted_orthogonal_loss": 0.02059604786336422
    },
    {
      "classification_loss": 0.5429165959358215,
      "epoch": 13.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20607419312000275,
      "orthogonal_weight": 0.1,
      "step": 4071,
      "total_loss": 0.5635240077972412,
      "weighted_orthogonal_loss": 0.020607419312000275
    },
    {
      "classification_loss": 0.6440378427505493,
      "epoch": 13.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061932384967804,
      "orthogonal_weight": 0.1,
      "step": 4072,
      "total_loss": 0.6646571755409241,
      "weighted_orthogonal_loss": 0.02061932347714901
    },
    {
      "classification_loss": 0.5901108980178833,
      "epoch": 13.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20630861818790436,
      "orthogonal_weight": 0.1,
      "step": 4073,
      "total_loss": 0.6107417345046997,
      "weighted_orthogonal_loss": 0.020630862563848495
    },
    {
      "classification_loss": 0.6413062214851379,
      "epoch": 13.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20643049478530884,
      "orthogonal_weight": 0.1,
      "step": 4074,
      "total_loss": 0.6619492769241333,
      "weighted_orthogonal_loss": 0.020643049851059914
    },
    {
      "classification_loss": 0.5751996636390686,
      "epoch": 13.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20649798214435577,
      "orthogonal_weight": 0.1,
      "step": 4075,
      "total_loss": 0.5958494544029236,
      "weighted_orthogonal_loss": 0.020649798214435577
    },
    {
      "classification_loss": 0.5945660471916199,
      "epoch": 13.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065778225660324,
      "orthogonal_weight": 0.1,
      "step": 4076,
      "total_loss": 0.6152238249778748,
      "weighted_orthogonal_loss": 0.02065778337419033
    },
    {
      "classification_loss": 0.6043546199798584,
      "epoch": 13.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20656557381153107,
      "orthogonal_weight": 0.1,
      "step": 4077,
      "total_loss": 0.6250112056732178,
      "weighted_orthogonal_loss": 0.020656557753682137
    },
    {
      "classification_loss": 0.6937950253486633,
      "epoch": 13.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20665568113327026,
      "orthogonal_weight": 0.1,
      "step": 4078,
      "total_loss": 0.7144606113433838,
      "weighted_orthogonal_loss": 0.020665569230914116
    },
    {
      "classification_loss": 0.603264570236206,
      "epoch": 13.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20672734081745148,
      "orthogonal_weight": 0.1,
      "step": 4079,
      "total_loss": 0.6239373087882996,
      "weighted_orthogonal_loss": 0.020672734826803207
    },
    {
      "classification_loss": 0.6430878043174744,
      "epoch": 13.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20671851933002472,
      "orthogonal_weight": 0.1,
      "step": 4080,
      "total_loss": 0.6637596487998962,
      "weighted_orthogonal_loss": 0.020671851933002472
    },
    {
      "classification_loss": 0.6033278703689575,
      "epoch": 13.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20668594539165497,
      "orthogonal_weight": 0.1,
      "step": 4081,
      "total_loss": 0.6239964365959167,
      "weighted_orthogonal_loss": 0.020668594166636467
    },
    {
      "classification_loss": 0.616484522819519,
      "epoch": 13.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20666570961475372,
      "orthogonal_weight": 0.1,
      "step": 4082,
      "total_loss": 0.6371511220932007,
      "weighted_orthogonal_loss": 0.020666571334004402
    },
    {
      "classification_loss": 0.5831831693649292,
      "epoch": 13.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066473513841629,
      "orthogonal_weight": 0.1,
      "step": 4083,
      "total_loss": 0.6038479208946228,
      "weighted_orthogonal_loss": 0.02066473476588726
    },
    {
      "classification_loss": 0.6404078602790833,
      "epoch": 13.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20664222538471222,
      "orthogonal_weight": 0.1,
      "step": 4084,
      "total_loss": 0.6610720753669739,
      "weighted_orthogonal_loss": 0.020664222538471222
    },
    {
      "classification_loss": 0.6422271132469177,
      "epoch": 13.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20662818849086761,
      "orthogonal_weight": 0.1,
      "step": 4085,
      "total_loss": 0.6628899574279785,
      "weighted_orthogonal_loss": 0.02066281996667385
    },
    {
      "classification_loss": 0.5333354473114014,
      "epoch": 13.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206617534160614,
      "orthogonal_weight": 0.1,
      "step": 4086,
      "total_loss": 0.5539972186088562,
      "weighted_orthogonal_loss": 0.02066175453364849
    },
    {
      "classification_loss": 0.6301310658454895,
      "epoch": 13.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20663531124591827,
      "orthogonal_weight": 0.1,
      "step": 4087,
      "total_loss": 0.6507946252822876,
      "weighted_orthogonal_loss": 0.020663531497120857
    },
    {
      "classification_loss": 0.6358202695846558,
      "epoch": 13.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20665767788887024,
      "orthogonal_weight": 0.1,
      "step": 4088,
      "total_loss": 0.6564860343933105,
      "weighted_orthogonal_loss": 0.020665768533945084
    },
    {
      "classification_loss": 0.6263146996498108,
      "epoch": 13.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20665156841278076,
      "orthogonal_weight": 0.1,
      "step": 4089,
      "total_loss": 0.6469798684120178,
      "weighted_orthogonal_loss": 0.020665157586336136
    },
    {
      "classification_loss": 0.5641578435897827,
      "epoch": 13.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066475749015808,
      "orthogonal_weight": 0.1,
      "step": 4090,
      "total_loss": 0.5848225951194763,
      "weighted_orthogonal_loss": 0.02066475711762905
    },
    {
      "classification_loss": 0.5629416108131409,
      "epoch": 13.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20669019222259521,
      "orthogonal_weight": 0.1,
      "step": 4091,
      "total_loss": 0.5836106538772583,
      "weighted_orthogonal_loss": 0.02066901884973049
    },
    {
      "classification_loss": 0.6083651781082153,
      "epoch": 13.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20663434267044067,
      "orthogonal_weight": 0.1,
      "step": 4092,
      "total_loss": 0.6290286183357239,
      "weighted_orthogonal_loss": 0.020663434639573097
    },
    {
      "classification_loss": 0.6677167415618896,
      "epoch": 13.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20661264657974243,
      "orthogonal_weight": 0.1,
      "step": 4093,
      "total_loss": 0.6883779764175415,
      "weighted_orthogonal_loss": 0.020661264657974243
    },
    {
      "classification_loss": 0.599449872970581,
      "epoch": 13.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20652909576892853,
      "orthogonal_weight": 0.1,
      "step": 4094,
      "total_loss": 0.6201027631759644,
      "weighted_orthogonal_loss": 0.020652910694479942
    },
    {
      "classification_loss": 0.5809335708618164,
      "epoch": 13.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2064334899187088,
      "orthogonal_weight": 0.1,
      "step": 4095,
      "total_loss": 0.6015769243240356,
      "weighted_orthogonal_loss": 0.02064334973692894
    },
    {
      "classification_loss": 0.6660788059234619,
      "epoch": 13.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2063327580690384,
      "orthogonal_weight": 0.1,
      "step": 4096,
      "total_loss": 0.6867120862007141,
      "weighted_orthogonal_loss": 0.0206332765519619
    },
    {
      "classification_loss": 0.6332606077194214,
      "epoch": 13.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20620398223400116,
      "orthogonal_weight": 0.1,
      "step": 4097,
      "total_loss": 0.6538810133934021,
      "weighted_orthogonal_loss": 0.020620398223400116
    },
    {
      "classification_loss": 0.6284844875335693,
      "epoch": 13.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20606020092964172,
      "orthogonal_weight": 0.1,
      "step": 4098,
      "total_loss": 0.6490905284881592,
      "weighted_orthogonal_loss": 0.020606020465493202
    },
    {
      "classification_loss": 0.6633509993553162,
      "epoch": 13.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20598992705345154,
      "orthogonal_weight": 0.1,
      "step": 4099,
      "total_loss": 0.6839500069618225,
      "weighted_orthogonal_loss": 0.020598992705345154
    },
    {
      "epoch": 13.442622950819672,
      "grad_norm": 11.226195335388184,
      "learning_rate": 6.670000000000001e-05,
      "loss": 0.6414,
      "step": 4100
    },
    {
      "classification_loss": 0.5881906151771545,
      "epoch": 13.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20589925348758698,
      "orthogonal_weight": 0.1,
      "step": 4100,
      "total_loss": 0.608780562877655,
      "weighted_orthogonal_loss": 0.020589925348758698
    },
    {
      "classification_loss": 0.5922159552574158,
      "epoch": 13.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20580227673053741,
      "orthogonal_weight": 0.1,
      "step": 4101,
      "total_loss": 0.6127961874008179,
      "weighted_orthogonal_loss": 0.0205802284181118
    },
    {
      "classification_loss": 0.5624741315841675,
      "epoch": 13.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20572158694267273,
      "orthogonal_weight": 0.1,
      "step": 4102,
      "total_loss": 0.5830463171005249,
      "weighted_orthogonal_loss": 0.020572159439325333
    },
    {
      "classification_loss": 0.6451138854026794,
      "epoch": 13.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20567183196544647,
      "orthogonal_weight": 0.1,
      "step": 4103,
      "total_loss": 0.6656810641288757,
      "weighted_orthogonal_loss": 0.020567184314131737
    },
    {
      "classification_loss": 0.5604349970817566,
      "epoch": 13.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20567794144153595,
      "orthogonal_weight": 0.1,
      "step": 4104,
      "total_loss": 0.5810027718544006,
      "weighted_orthogonal_loss": 0.020567795261740685
    },
    {
      "classification_loss": 0.6029443740844727,
      "epoch": 13.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569992065429688,
      "orthogonal_weight": 0.1,
      "step": 4105,
      "total_loss": 0.6235143542289734,
      "weighted_orthogonal_loss": 0.020569993183016777
    },
    {
      "classification_loss": 0.6401203274726868,
      "epoch": 13.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20575840771198273,
      "orthogonal_weight": 0.1,
      "step": 4106,
      "total_loss": 0.6606961488723755,
      "weighted_orthogonal_loss": 0.020575841888785362
    },
    {
      "classification_loss": 0.5800597667694092,
      "epoch": 13.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20585094392299652,
      "orthogonal_weight": 0.1,
      "step": 4107,
      "total_loss": 0.6006448864936829,
      "weighted_orthogonal_loss": 0.02058509550988674
    },
    {
      "classification_loss": 0.6152467727661133,
      "epoch": 13.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059408724308014,
      "orthogonal_weight": 0.1,
      "step": 4108,
      "total_loss": 0.6358408331871033,
      "weighted_orthogonal_loss": 0.02059408836066723
    },
    {
      "classification_loss": 0.6425368785858154,
      "epoch": 13.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20600110292434692,
      "orthogonal_weight": 0.1,
      "step": 4109,
      "total_loss": 0.6631369590759277,
      "weighted_orthogonal_loss": 0.020600110292434692
    },
    {
      "classification_loss": 0.5138888359069824,
      "epoch": 13.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20603349804878235,
      "orthogonal_weight": 0.1,
      "step": 4110,
      "total_loss": 0.5344921946525574,
      "weighted_orthogonal_loss": 0.020603349432349205
    },
    {
      "classification_loss": 0.596874475479126,
      "epoch": 13.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20605947077274323,
      "orthogonal_weight": 0.1,
      "step": 4111,
      "total_loss": 0.6174803972244263,
      "weighted_orthogonal_loss": 0.020605947822332382
    },
    {
      "classification_loss": 0.6479966640472412,
      "epoch": 13.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206098273396492,
      "orthogonal_weight": 0.1,
      "step": 4112,
      "total_loss": 0.6686065196990967,
      "weighted_orthogonal_loss": 0.02060982771217823
    },
    {
      "classification_loss": 0.5821539759635925,
      "epoch": 13.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20609170198440552,
      "orthogonal_weight": 0.1,
      "step": 4113,
      "total_loss": 0.6027631759643555,
      "weighted_orthogonal_loss": 0.020609170198440552
    },
    {
      "classification_loss": 0.604682207107544,
      "epoch": 13.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20611579716205597,
      "orthogonal_weight": 0.1,
      "step": 4114,
      "total_loss": 0.6252937912940979,
      "weighted_orthogonal_loss": 0.020611580461263657
    },
    {
      "classification_loss": 0.638603925704956,
      "epoch": 13.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20611031353473663,
      "orthogonal_weight": 0.1,
      "step": 4115,
      "total_loss": 0.659214973449707,
      "weighted_orthogonal_loss": 0.020611030980944633
    },
    {
      "classification_loss": 0.6291707754135132,
      "epoch": 13.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20605768263339996,
      "orthogonal_weight": 0.1,
      "step": 4116,
      "total_loss": 0.6497765183448792,
      "weighted_orthogonal_loss": 0.020605769008398056
    },
    {
      "classification_loss": 0.6044110655784607,
      "epoch": 13.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2060289978981018,
      "orthogonal_weight": 0.1,
      "step": 4117,
      "total_loss": 0.6250139474868774,
      "weighted_orthogonal_loss": 0.02060290053486824
    },
    {
      "classification_loss": 0.5993170738220215,
      "epoch": 13.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2060154676437378,
      "orthogonal_weight": 0.1,
      "step": 4118,
      "total_loss": 0.6199186444282532,
      "weighted_orthogonal_loss": 0.02060154639184475
    },
    {
      "classification_loss": 0.645569920539856,
      "epoch": 13.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20604965090751648,
      "orthogonal_weight": 0.1,
      "step": 4119,
      "total_loss": 0.6661748886108398,
      "weighted_orthogonal_loss": 0.020604966208338737
    },
    {
      "classification_loss": 0.5928981304168701,
      "epoch": 13.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20606836676597595,
      "orthogonal_weight": 0.1,
      "step": 4120,
      "total_loss": 0.613504946231842,
      "weighted_orthogonal_loss": 0.020606836304068565
    },
    {
      "classification_loss": 0.5704196691513062,
      "epoch": 13.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20611704885959625,
      "orthogonal_weight": 0.1,
      "step": 4121,
      "total_loss": 0.5910313725471497,
      "weighted_orthogonal_loss": 0.020611705258488655
    },
    {
      "classification_loss": 0.6526835560798645,
      "epoch": 13.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20617885887622833,
      "orthogonal_weight": 0.1,
      "step": 4122,
      "total_loss": 0.6733014583587646,
      "weighted_orthogonal_loss": 0.020617885515093803
    },
    {
      "classification_loss": 0.6816024780273438,
      "epoch": 13.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062564343214035,
      "orthogonal_weight": 0.1,
      "step": 4123,
      "total_loss": 0.7022281289100647,
      "weighted_orthogonal_loss": 0.02062564343214035
    },
    {
      "classification_loss": 0.6702936291694641,
      "epoch": 13.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20631498098373413,
      "orthogonal_weight": 0.1,
      "step": 4124,
      "total_loss": 0.690925121307373,
      "weighted_orthogonal_loss": 0.020631497725844383
    },
    {
      "classification_loss": 0.5736626982688904,
      "epoch": 13.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20636604726314545,
      "orthogonal_weight": 0.1,
      "step": 4125,
      "total_loss": 0.59429931640625,
      "weighted_orthogonal_loss": 0.020636605098843575
    },
    {
      "classification_loss": 0.6362684369087219,
      "epoch": 13.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2064329981803894,
      "orthogonal_weight": 0.1,
      "step": 4126,
      "total_loss": 0.6569117307662964,
      "weighted_orthogonal_loss": 0.02064329944550991
    },
    {
      "classification_loss": 0.5262411236763,
      "epoch": 13.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20649750530719757,
      "orthogonal_weight": 0.1,
      "step": 4127,
      "total_loss": 0.5468908548355103,
      "weighted_orthogonal_loss": 0.020649751648306847
    },
    {
      "classification_loss": 0.5617560148239136,
      "epoch": 13.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20656917989253998,
      "orthogonal_weight": 0.1,
      "step": 4128,
      "total_loss": 0.5824129581451416,
      "weighted_orthogonal_loss": 0.020656919106841087
    },
    {
      "classification_loss": 0.631878674030304,
      "epoch": 13.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20663785934448242,
      "orthogonal_weight": 0.1,
      "step": 4129,
      "total_loss": 0.6525424718856812,
      "weighted_orthogonal_loss": 0.020663786679506302
    },
    {
      "classification_loss": 0.6529397964477539,
      "epoch": 13.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20665019750595093,
      "orthogonal_weight": 0.1,
      "step": 4130,
      "total_loss": 0.6736048460006714,
      "weighted_orthogonal_loss": 0.020665019750595093
    },
    {
      "classification_loss": 0.5894298553466797,
      "epoch": 13.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20664331316947937,
      "orthogonal_weight": 0.1,
      "step": 4131,
      "total_loss": 0.6100941896438599,
      "weighted_orthogonal_loss": 0.020664332434535027
    },
    {
      "classification_loss": 0.5948982238769531,
      "epoch": 13.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066086083650589,
      "orthogonal_weight": 0.1,
      "step": 4132,
      "total_loss": 0.6155591011047363,
      "weighted_orthogonal_loss": 0.02066086046397686
    },
    {
      "classification_loss": 0.6386579275131226,
      "epoch": 13.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20660407841205597,
      "orthogonal_weight": 0.1,
      "step": 4133,
      "total_loss": 0.6593183279037476,
      "weighted_orthogonal_loss": 0.020660407841205597
    },
    {
      "classification_loss": 0.6052480936050415,
      "epoch": 13.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20652489364147186,
      "orthogonal_weight": 0.1,
      "step": 4134,
      "total_loss": 0.6259005665779114,
      "weighted_orthogonal_loss": 0.020652489736676216
    },
    {
      "classification_loss": 0.5933069586753845,
      "epoch": 13.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20647788047790527,
      "orthogonal_weight": 0.1,
      "step": 4135,
      "total_loss": 0.6139547228813171,
      "weighted_orthogonal_loss": 0.020647788420319557
    },
    {
      "classification_loss": 0.6157731413841248,
      "epoch": 13.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20643197000026703,
      "orthogonal_weight": 0.1,
      "step": 4136,
      "total_loss": 0.6364163160324097,
      "weighted_orthogonal_loss": 0.020643197000026703
    },
    {
      "classification_loss": 0.5972166061401367,
      "epoch": 13.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20642387866973877,
      "orthogonal_weight": 0.1,
      "step": 4137,
      "total_loss": 0.6178590059280396,
      "weighted_orthogonal_loss": 0.020642388612031937
    },
    {
      "classification_loss": 0.6384539604187012,
      "epoch": 13.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20628005266189575,
      "orthogonal_weight": 0.1,
      "step": 4138,
      "total_loss": 0.6590819358825684,
      "weighted_orthogonal_loss": 0.020628005266189575
    },
    {
      "classification_loss": 0.6165125966072083,
      "epoch": 13.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061900943517685,
      "orthogonal_weight": 0.1,
      "step": 4139,
      "total_loss": 0.6371316313743591,
      "weighted_orthogonal_loss": 0.02061901055276394
    },
    {
      "classification_loss": 0.5677036046981812,
      "epoch": 13.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20611341297626495,
      "orthogonal_weight": 0.1,
      "step": 4140,
      "total_loss": 0.588314950466156,
      "weighted_orthogonal_loss": 0.020611342042684555
    },
    {
      "classification_loss": 0.5365458726882935,
      "epoch": 13.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20606522262096405,
      "orthogonal_weight": 0.1,
      "step": 4141,
      "total_loss": 0.5571523904800415,
      "weighted_orthogonal_loss": 0.020606523379683495
    },
    {
      "classification_loss": 0.5855668783187866,
      "epoch": 13.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2060132473707199,
      "orthogonal_weight": 0.1,
      "step": 4142,
      "total_loss": 0.6061682105064392,
      "weighted_orthogonal_loss": 0.02060132473707199
    },
    {
      "classification_loss": 0.5729082822799683,
      "epoch": 13.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20595121383666992,
      "orthogonal_weight": 0.1,
      "step": 4143,
      "total_loss": 0.5935034155845642,
      "weighted_orthogonal_loss": 0.020595122128725052
    },
    {
      "classification_loss": 0.6245256662368774,
      "epoch": 13.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059275209903717,
      "orthogonal_weight": 0.1,
      "step": 4144,
      "total_loss": 0.6451184153556824,
      "weighted_orthogonal_loss": 0.02059275284409523
    },
    {
      "classification_loss": 0.6179175972938538,
      "epoch": 13.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20592013001441956,
      "orthogonal_weight": 0.1,
      "step": 4145,
      "total_loss": 0.6385096311569214,
      "weighted_orthogonal_loss": 0.020592013373970985
    },
    {
      "classification_loss": 0.6182107925415039,
      "epoch": 13.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2058570235967636,
      "orthogonal_weight": 0.1,
      "step": 4146,
      "total_loss": 0.6387965083122253,
      "weighted_orthogonal_loss": 0.02058570273220539
    },
    {
      "classification_loss": 0.6276895403862,
      "epoch": 13.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2058141678571701,
      "orthogonal_weight": 0.1,
      "step": 4147,
      "total_loss": 0.6482709646224976,
      "weighted_orthogonal_loss": 0.02058141678571701
    },
    {
      "classification_loss": 0.6473322510719299,
      "epoch": 13.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20572562515735626,
      "orthogonal_weight": 0.1,
      "step": 4148,
      "total_loss": 0.667904794216156,
      "weighted_orthogonal_loss": 0.020572563633322716
    },
    {
      "classification_loss": 0.6234413385391235,
      "epoch": 13.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20565620064735413,
      "orthogonal_weight": 0.1,
      "step": 4149,
      "total_loss": 0.6440069675445557,
      "weighted_orthogonal_loss": 0.020565619692206383
    },
    {
      "classification_loss": 0.5713156461715698,
      "epoch": 13.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2056155651807785,
      "orthogonal_weight": 0.1,
      "step": 4150,
      "total_loss": 0.5918772220611572,
      "weighted_orthogonal_loss": 0.02056155726313591
    },
    {
      "classification_loss": 0.5971493124961853,
      "epoch": 13.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20554319024085999,
      "orthogonal_weight": 0.1,
      "step": 4151,
      "total_loss": 0.6177036166191101,
      "weighted_orthogonal_loss": 0.020554319024086
    },
    {
      "classification_loss": 0.6363638043403625,
      "epoch": 13.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055167853832245,
      "orthogonal_weight": 0.1,
      "step": 4152,
      "total_loss": 0.6569154858589172,
      "weighted_orthogonal_loss": 0.02055167965590954
    },
    {
      "classification_loss": 0.6154047846794128,
      "epoch": 13.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054653912782669,
      "orthogonal_weight": 0.1,
      "step": 4153,
      "total_loss": 0.6359513401985168,
      "weighted_orthogonal_loss": 0.02054653875529766
    },
    {
      "classification_loss": 0.5863955616950989,
      "epoch": 13.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054125815629959,
      "orthogonal_weight": 0.1,
      "step": 4154,
      "total_loss": 0.6069368124008179,
      "weighted_orthogonal_loss": 0.02054125815629959
    },
    {
      "classification_loss": 0.6123901605606079,
      "epoch": 13.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20537462830543518,
      "orthogonal_weight": 0.1,
      "step": 4155,
      "total_loss": 0.6329275965690613,
      "weighted_orthogonal_loss": 0.020537463948130608
    },
    {
      "classification_loss": 0.6310487985610962,
      "epoch": 13.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2053394764661789,
      "orthogonal_weight": 0.1,
      "step": 4156,
      "total_loss": 0.6515827178955078,
      "weighted_orthogonal_loss": 0.02053394727408886
    },
    {
      "classification_loss": 0.6802587509155273,
      "epoch": 13.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20533695816993713,
      "orthogonal_weight": 0.1,
      "step": 4157,
      "total_loss": 0.7007924318313599,
      "weighted_orthogonal_loss": 0.020533695816993713
    },
    {
      "classification_loss": 0.6122933030128479,
      "epoch": 13.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20529213547706604,
      "orthogonal_weight": 0.1,
      "step": 4158,
      "total_loss": 0.6328225135803223,
      "weighted_orthogonal_loss": 0.020529214292764664
    },
    {
      "classification_loss": 0.6516473293304443,
      "epoch": 13.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052420675754547,
      "orthogonal_weight": 0.1,
      "step": 4159,
      "total_loss": 0.6721715331077576,
      "weighted_orthogonal_loss": 0.02052420750260353
    },
    {
      "classification_loss": 0.6590788960456848,
      "epoch": 13.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2051490694284439,
      "orthogonal_weight": 0.1,
      "step": 4160,
      "total_loss": 0.6795938014984131,
      "weighted_orthogonal_loss": 0.02051490731537342
    },
    {
      "classification_loss": 0.5726723074913025,
      "epoch": 13.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20506791770458221,
      "orthogonal_weight": 0.1,
      "step": 4161,
      "total_loss": 0.5931791067123413,
      "weighted_orthogonal_loss": 0.02050679177045822
    },
    {
      "classification_loss": 0.5759870409965515,
      "epoch": 13.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20499834418296814,
      "orthogonal_weight": 0.1,
      "step": 4162,
      "total_loss": 0.5964868664741516,
      "weighted_orthogonal_loss": 0.020499834790825844
    },
    {
      "classification_loss": 0.5747949481010437,
      "epoch": 13.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20493526756763458,
      "orthogonal_weight": 0.1,
      "step": 4163,
      "total_loss": 0.5952884554862976,
      "weighted_orthogonal_loss": 0.020493527874350548
    },
    {
      "classification_loss": 0.6751468181610107,
      "epoch": 13.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20494423806667328,
      "orthogonal_weight": 0.1,
      "step": 4164,
      "total_loss": 0.6956412196159363,
      "weighted_orthogonal_loss": 0.020494423806667328
    },
    {
      "classification_loss": 0.6047298908233643,
      "epoch": 13.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20488964021205902,
      "orthogonal_weight": 0.1,
      "step": 4165,
      "total_loss": 0.6252188682556152,
      "weighted_orthogonal_loss": 0.020488964393734932
    },
    {
      "classification_loss": 0.6257818937301636,
      "epoch": 13.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482169091701508,
      "orthogonal_weight": 0.1,
      "step": 4166,
      "total_loss": 0.6462640762329102,
      "weighted_orthogonal_loss": 0.020482169464230537
    },
    {
      "classification_loss": 0.619227945804596,
      "epoch": 13.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20477813482284546,
      "orthogonal_weight": 0.1,
      "step": 4167,
      "total_loss": 0.6397057771682739,
      "weighted_orthogonal_loss": 0.020477814599871635
    },
    {
      "classification_loss": 0.6084756255149841,
      "epoch": 13.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20474818348884583,
      "orthogonal_weight": 0.1,
      "step": 4168,
      "total_loss": 0.6289504170417786,
      "weighted_orthogonal_loss": 0.020474819466471672
    },
    {
      "classification_loss": 0.6412352919578552,
      "epoch": 13.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2047395408153534,
      "orthogonal_weight": 0.1,
      "step": 4169,
      "total_loss": 0.6617092490196228,
      "weighted_orthogonal_loss": 0.02047395519912243
    },
    {
      "classification_loss": 0.6113758087158203,
      "epoch": 13.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20473814010620117,
      "orthogonal_weight": 0.1,
      "step": 4170,
      "total_loss": 0.6318496465682983,
      "weighted_orthogonal_loss": 0.020473813638091087
    },
    {
      "classification_loss": 0.49941349029541016,
      "epoch": 13.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20480310916900635,
      "orthogonal_weight": 0.1,
      "step": 4171,
      "total_loss": 0.5198938250541687,
      "weighted_orthogonal_loss": 0.020480310544371605
    },
    {
      "classification_loss": 0.5517557859420776,
      "epoch": 13.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20494863390922546,
      "orthogonal_weight": 0.1,
      "step": 4172,
      "total_loss": 0.5722506642341614,
      "weighted_orthogonal_loss": 0.020494863390922546
    },
    {
      "classification_loss": 0.668071448802948,
      "epoch": 13.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20509366691112518,
      "orthogonal_weight": 0.1,
      "step": 4173,
      "total_loss": 0.6885808110237122,
      "weighted_orthogonal_loss": 0.020509367808699608
    },
    {
      "classification_loss": 0.5699549317359924,
      "epoch": 13.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20520877838134766,
      "orthogonal_weight": 0.1,
      "step": 4174,
      "total_loss": 0.5904757976531982,
      "weighted_orthogonal_loss": 0.020520878955721855
    },
    {
      "classification_loss": 0.5961701273918152,
      "epoch": 13.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20530150830745697,
      "orthogonal_weight": 0.1,
      "step": 4175,
      "total_loss": 0.616700291633606,
      "weighted_orthogonal_loss": 0.020530151203274727
    },
    {
      "classification_loss": 0.6517266035079956,
      "epoch": 13.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20539982616901398,
      "orthogonal_weight": 0.1,
      "step": 4176,
      "total_loss": 0.6722666025161743,
      "weighted_orthogonal_loss": 0.020539982244372368
    },
    {
      "classification_loss": 0.5259795784950256,
      "epoch": 13.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20547181367874146,
      "orthogonal_weight": 0.1,
      "step": 4177,
      "total_loss": 0.5465267896652222,
      "weighted_orthogonal_loss": 0.020547181367874146
    },
    {
      "classification_loss": 0.6890313625335693,
      "epoch": 13.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20555444061756134,
      "orthogonal_weight": 0.1,
      "step": 4178,
      "total_loss": 0.7095867991447449,
      "weighted_orthogonal_loss": 0.020555444061756134
    },
    {
      "classification_loss": 0.6476441025733948,
      "epoch": 13.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20564532279968262,
      "orthogonal_weight": 0.1,
      "step": 4179,
      "total_loss": 0.668208658695221,
      "weighted_orthogonal_loss": 0.020564531907439232
    },
    {
      "classification_loss": 0.6065745949745178,
      "epoch": 13.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20570892095565796,
      "orthogonal_weight": 0.1,
      "step": 4180,
      "total_loss": 0.6271454691886902,
      "weighted_orthogonal_loss": 0.020570892840623856
    },
    {
      "classification_loss": 0.6874610185623169,
      "epoch": 13.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2057998776435852,
      "orthogonal_weight": 0.1,
      "step": 4181,
      "total_loss": 0.7080410122871399,
      "weighted_orthogonal_loss": 0.02057998813688755
    },
    {
      "classification_loss": 0.5612741708755493,
      "epoch": 13.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2058630883693695,
      "orthogonal_weight": 0.1,
      "step": 4182,
      "total_loss": 0.5818604826927185,
      "weighted_orthogonal_loss": 0.02058630995452404
    },
    {
      "classification_loss": 0.7470532655715942,
      "epoch": 13.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20589663088321686,
      "orthogonal_weight": 0.1,
      "step": 4183,
      "total_loss": 0.7676429152488708,
      "weighted_orthogonal_loss": 0.020589662715792656
    },
    {
      "classification_loss": 0.580892026424408,
      "epoch": 13.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20586930215358734,
      "orthogonal_weight": 0.1,
      "step": 4184,
      "total_loss": 0.6014789342880249,
      "weighted_orthogonal_loss": 0.020586930215358734
    },
    {
      "classification_loss": 0.6294839382171631,
      "epoch": 13.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20584946870803833,
      "orthogonal_weight": 0.1,
      "step": 4185,
      "total_loss": 0.6500688791275024,
      "weighted_orthogonal_loss": 0.020584946498274803
    },
    {
      "classification_loss": 0.6450069546699524,
      "epoch": 13.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20585259795188904,
      "orthogonal_weight": 0.1,
      "step": 4186,
      "total_loss": 0.6655921936035156,
      "weighted_orthogonal_loss": 0.020585259422659874
    },
    {
      "classification_loss": 0.654507577419281,
      "epoch": 13.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20583778619766235,
      "orthogonal_weight": 0.1,
      "step": 4187,
      "total_loss": 0.6750913858413696,
      "weighted_orthogonal_loss": 0.020583778619766235
    },
    {
      "classification_loss": 0.6576354503631592,
      "epoch": 13.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20582303404808044,
      "orthogonal_weight": 0.1,
      "step": 4188,
      "total_loss": 0.6782177686691284,
      "weighted_orthogonal_loss": 0.020582303404808044
    },
    {
      "classification_loss": 0.6085695624351501,
      "epoch": 13.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20578551292419434,
      "orthogonal_weight": 0.1,
      "step": 4189,
      "total_loss": 0.6291481256484985,
      "weighted_orthogonal_loss": 0.020578552037477493
    },
    {
      "classification_loss": 0.6647291779518127,
      "epoch": 13.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20575809478759766,
      "orthogonal_weight": 0.1,
      "step": 4190,
      "total_loss": 0.6853049993515015,
      "weighted_orthogonal_loss": 0.020575810223817825
    },
    {
      "classification_loss": 0.6250227093696594,
      "epoch": 13.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205718994140625,
      "orthogonal_weight": 0.1,
      "step": 4191,
      "total_loss": 0.645594596862793,
      "weighted_orthogonal_loss": 0.02057190053164959
    },
    {
      "classification_loss": 0.6332913041114807,
      "epoch": 13.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2056770771741867,
      "orthogonal_weight": 0.1,
      "step": 4192,
      "total_loss": 0.65385901927948,
      "weighted_orthogonal_loss": 0.02056770771741867
    },
    {
      "classification_loss": 0.6322547197341919,
      "epoch": 13.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20563508570194244,
      "orthogonal_weight": 0.1,
      "step": 4193,
      "total_loss": 0.6528182029724121,
      "weighted_orthogonal_loss": 0.020563509315252304
    },
    {
      "classification_loss": 0.5833441615104675,
      "epoch": 13.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054804265499115,
      "orthogonal_weight": 0.1,
      "step": 4194,
      "total_loss": 0.6038922071456909,
      "weighted_orthogonal_loss": 0.02054804377257824
    },
    {
      "classification_loss": 0.5661430358886719,
      "epoch": 13.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20521795749664307,
      "orthogonal_weight": 0.1,
      "step": 4195,
      "total_loss": 0.5866648554801941,
      "weighted_orthogonal_loss": 0.020521795377135277
    },
    {
      "classification_loss": 0.5715625882148743,
      "epoch": 13.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2049369364976883,
      "orthogonal_weight": 0.1,
      "step": 4196,
      "total_loss": 0.5920562744140625,
      "weighted_orthogonal_loss": 0.02049369364976883
    },
    {
      "classification_loss": 0.5908765196800232,
      "epoch": 13.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20470094680786133,
      "orthogonal_weight": 0.1,
      "step": 4197,
      "total_loss": 0.6113466024398804,
      "weighted_orthogonal_loss": 0.020470095798373222
    },
    {
      "classification_loss": 0.7274317741394043,
      "epoch": 13.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2044672667980194,
      "orthogonal_weight": 0.1,
      "step": 4198,
      "total_loss": 0.7478784918785095,
      "weighted_orthogonal_loss": 0.02044672705233097
    },
    {
      "classification_loss": 0.5336403846740723,
      "epoch": 13.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20428986847400665,
      "orthogonal_weight": 0.1,
      "step": 4199,
      "total_loss": 0.5540693998336792,
      "weighted_orthogonal_loss": 0.020428987219929695
    },
    {
      "epoch": 13.770491803278688,
      "grad_norm": 13.437827110290527,
      "learning_rate": 6.336666666666667e-05,
      "loss": 0.6328,
      "step": 4200
    },
    {
      "classification_loss": 0.5572406649589539,
      "epoch": 13.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2041531652212143,
      "orthogonal_weight": 0.1,
      "step": 4200,
      "total_loss": 0.5776559710502625,
      "weighted_orthogonal_loss": 0.02041531726717949
    },
    {
      "classification_loss": 0.5278298854827881,
      "epoch": 13.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20408622920513153,
      "orthogonal_weight": 0.1,
      "step": 4201,
      "total_loss": 0.5482385158538818,
      "weighted_orthogonal_loss": 0.020408622920513153
    },
    {
      "classification_loss": 0.6073870062828064,
      "epoch": 13.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20403175055980682,
      "orthogonal_weight": 0.1,
      "step": 4202,
      "total_loss": 0.6277901530265808,
      "weighted_orthogonal_loss": 0.020403174683451653
    },
    {
      "classification_loss": 0.6378240585327148,
      "epoch": 13.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20394320785999298,
      "orthogonal_weight": 0.1,
      "step": 4203,
      "total_loss": 0.6582183837890625,
      "weighted_orthogonal_loss": 0.020394321531057358
    },
    {
      "classification_loss": 0.5825121998786926,
      "epoch": 13.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20384319126605988,
      "orthogonal_weight": 0.1,
      "step": 4204,
      "total_loss": 0.602896511554718,
      "weighted_orthogonal_loss": 0.020384319126605988
    },
    {
      "classification_loss": 0.6637417674064636,
      "epoch": 13.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037876546382904,
      "orthogonal_weight": 0.1,
      "step": 4205,
      "total_loss": 0.6841205358505249,
      "weighted_orthogonal_loss": 0.02037876658141613
    },
    {
      "classification_loss": 0.7181118726730347,
      "epoch": 13.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20379801094532013,
      "orthogonal_weight": 0.1,
      "step": 4206,
      "total_loss": 0.7384916543960571,
      "weighted_orthogonal_loss": 0.020379802212119102
    },
    {
      "classification_loss": 0.6578795909881592,
      "epoch": 13.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2039123922586441,
      "orthogonal_weight": 0.1,
      "step": 4207,
      "total_loss": 0.6782708168029785,
      "weighted_orthogonal_loss": 0.02039123885333538
    },
    {
      "classification_loss": 0.5991621017456055,
      "epoch": 13.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20402266085147858,
      "orthogonal_weight": 0.1,
      "step": 4208,
      "total_loss": 0.6195643544197083,
      "weighted_orthogonal_loss": 0.020402265712618828
    },
    {
      "classification_loss": 0.5533060431480408,
      "epoch": 13.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20415757596492767,
      "orthogonal_weight": 0.1,
      "step": 4209,
      "total_loss": 0.5737218260765076,
      "weighted_orthogonal_loss": 0.020415758714079857
    },
    {
      "classification_loss": 0.6881225109100342,
      "epoch": 13.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042941153049469,
      "orthogonal_weight": 0.1,
      "step": 4210,
      "total_loss": 0.7085519433021545,
      "weighted_orthogonal_loss": 0.02042941190302372
    },
    {
      "classification_loss": 0.669718325138092,
      "epoch": 13.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20440271496772766,
      "orthogonal_weight": 0.1,
      "step": 4211,
      "total_loss": 0.6901586055755615,
      "weighted_orthogonal_loss": 0.020440271124243736
    },
    {
      "classification_loss": 0.5704522132873535,
      "epoch": 13.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20451828837394714,
      "orthogonal_weight": 0.1,
      "step": 4212,
      "total_loss": 0.5909040570259094,
      "weighted_orthogonal_loss": 0.020451828837394714
    },
    {
      "classification_loss": 0.663074254989624,
      "epoch": 13.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20462706685066223,
      "orthogonal_weight": 0.1,
      "step": 4213,
      "total_loss": 0.683536946773529,
      "weighted_orthogonal_loss": 0.020462706685066223
    },
    {
      "classification_loss": 0.7201507091522217,
      "epoch": 13.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20476041734218597,
      "orthogonal_weight": 0.1,
      "step": 4214,
      "total_loss": 0.7406267523765564,
      "weighted_orthogonal_loss": 0.020476041361689568
    },
    {
      "classification_loss": 0.5733499526977539,
      "epoch": 13.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2048092633485794,
      "orthogonal_weight": 0.1,
      "step": 4215,
      "total_loss": 0.5938308835029602,
      "weighted_orthogonal_loss": 0.020480927079916
    },
    {
      "classification_loss": 0.5619288682937622,
      "epoch": 13.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20484547317028046,
      "orthogonal_weight": 0.1,
      "step": 4216,
      "total_loss": 0.5824134349822998,
      "weighted_orthogonal_loss": 0.020484548062086105
    },
    {
      "classification_loss": 0.5913942456245422,
      "epoch": 13.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20486661791801453,
      "orthogonal_weight": 0.1,
      "step": 4217,
      "total_loss": 0.611880898475647,
      "weighted_orthogonal_loss": 0.020486662164330482
    },
    {
      "classification_loss": 0.636027991771698,
      "epoch": 13.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2049068957567215,
      "orthogonal_weight": 0.1,
      "step": 4218,
      "total_loss": 0.6565186977386475,
      "weighted_orthogonal_loss": 0.02049068920314312
    },
    {
      "classification_loss": 0.6140283346176147,
      "epoch": 13.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20489276945590973,
      "orthogonal_weight": 0.1,
      "step": 4219,
      "total_loss": 0.6345176100730896,
      "weighted_orthogonal_loss": 0.020489277318120003
    },
    {
      "classification_loss": 0.6021732091903687,
      "epoch": 13.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.204881951212883,
      "orthogonal_weight": 0.1,
      "step": 4220,
      "total_loss": 0.6226614117622375,
      "weighted_orthogonal_loss": 0.0204881951212883
    },
    {
      "classification_loss": 0.5902760624885559,
      "epoch": 13.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20490126311779022,
      "orthogonal_weight": 0.1,
      "step": 4221,
      "total_loss": 0.6107661724090576,
      "weighted_orthogonal_loss": 0.020490126684308052
    },
    {
      "classification_loss": 0.6315894722938538,
      "epoch": 13.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20497199892997742,
      "orthogonal_weight": 0.1,
      "step": 4222,
      "total_loss": 0.6520866751670837,
      "weighted_orthogonal_loss": 0.02049720101058483
    },
    {
      "classification_loss": 0.5829181671142578,
      "epoch": 13.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20505446195602417,
      "orthogonal_weight": 0.1,
      "step": 4223,
      "total_loss": 0.6034235954284668,
      "weighted_orthogonal_loss": 0.020505446940660477
    },
    {
      "classification_loss": 0.6050453186035156,
      "epoch": 13.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20512442290782928,
      "orthogonal_weight": 0.1,
      "step": 4224,
      "total_loss": 0.6255577802658081,
      "weighted_orthogonal_loss": 0.020512443035840988
    },
    {
      "classification_loss": 0.6495171189308167,
      "epoch": 13.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2051679939031601,
      "orthogonal_weight": 0.1,
      "step": 4225,
      "total_loss": 0.6700339317321777,
      "weighted_orthogonal_loss": 0.02051679976284504
    },
    {
      "classification_loss": 0.6274097561836243,
      "epoch": 13.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052369862794876,
      "orthogonal_weight": 0.1,
      "step": 4226,
      "total_loss": 0.6479334831237793,
      "weighted_orthogonal_loss": 0.02052369900047779
    },
    {
      "classification_loss": 0.5761861801147461,
      "epoch": 13.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052893340587616,
      "orthogonal_weight": 0.1,
      "step": 4227,
      "total_loss": 0.5967150926589966,
      "weighted_orthogonal_loss": 0.02052893303334713
    },
    {
      "classification_loss": 0.6117175817489624,
      "epoch": 13.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20537656545639038,
      "orthogonal_weight": 0.1,
      "step": 4228,
      "total_loss": 0.6322552561759949,
      "weighted_orthogonal_loss": 0.020537657663226128
    },
    {
      "classification_loss": 0.6248031854629517,
      "epoch": 13.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20543231070041656,
      "orthogonal_weight": 0.1,
      "step": 4229,
      "total_loss": 0.6453464031219482,
      "weighted_orthogonal_loss": 0.020543230697512627
    },
    {
      "classification_loss": 0.6623409390449524,
      "epoch": 13.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20550180971622467,
      "orthogonal_weight": 0.1,
      "step": 4230,
      "total_loss": 0.6828911304473877,
      "weighted_orthogonal_loss": 0.020550182089209557
    },
    {
      "classification_loss": 0.6052502989768982,
      "epoch": 13.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205597922205925,
      "orthogonal_weight": 0.1,
      "step": 4231,
      "total_loss": 0.6258100867271423,
      "weighted_orthogonal_loss": 0.02055979333817959
    },
    {
      "classification_loss": 0.6513109803199768,
      "epoch": 13.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20572127401828766,
      "orthogonal_weight": 0.1,
      "step": 4232,
      "total_loss": 0.6718831062316895,
      "weighted_orthogonal_loss": 0.020572127774357796
    },
    {
      "classification_loss": 0.6639962196350098,
      "epoch": 13.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20584478974342346,
      "orthogonal_weight": 0.1,
      "step": 4233,
      "total_loss": 0.6845806837081909,
      "weighted_orthogonal_loss": 0.020584478974342346
    },
    {
      "classification_loss": 0.5323986411094666,
      "epoch": 13.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20596642792224884,
      "orthogonal_weight": 0.1,
      "step": 4234,
      "total_loss": 0.5529952645301819,
      "weighted_orthogonal_loss": 0.020596643909811974
    },
    {
      "classification_loss": 0.6345369815826416,
      "epoch": 13.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20612043142318726,
      "orthogonal_weight": 0.1,
      "step": 4235,
      "total_loss": 0.6551490426063538,
      "weighted_orthogonal_loss": 0.020612044259905815
    },
    {
      "classification_loss": 0.5679509043693542,
      "epoch": 13.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062767595052719,
      "orthogonal_weight": 0.1,
      "step": 4236,
      "total_loss": 0.5885785818099976,
      "weighted_orthogonal_loss": 0.02062767557799816
    },
    {
      "classification_loss": 0.6167300939559937,
      "epoch": 13.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20639246702194214,
      "orthogonal_weight": 0.1,
      "step": 4237,
      "total_loss": 0.6373693346977234,
      "weighted_orthogonal_loss": 0.020639246329665184
    },
    {
      "classification_loss": 0.6679455041885376,
      "epoch": 13.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20645855367183685,
      "orthogonal_weight": 0.1,
      "step": 4238,
      "total_loss": 0.6885913610458374,
      "weighted_orthogonal_loss": 0.020645854994654655
    },
    {
      "classification_loss": 0.5709375739097595,
      "epoch": 13.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206477552652359,
      "orthogonal_weight": 0.1,
      "step": 4239,
      "total_loss": 0.5915853381156921,
      "weighted_orthogonal_loss": 0.02064775489270687
    },
    {
      "classification_loss": 0.6769832372665405,
      "epoch": 13.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20655615627765656,
      "orthogonal_weight": 0.1,
      "step": 4240,
      "total_loss": 0.6976388692855835,
      "weighted_orthogonal_loss": 0.020655615255236626
    },
    {
      "classification_loss": 0.6314358711242676,
      "epoch": 13.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20661483705043793,
      "orthogonal_weight": 0.1,
      "step": 4241,
      "total_loss": 0.6520973443984985,
      "weighted_orthogonal_loss": 0.020661484450101852
    },
    {
      "classification_loss": 0.6383203268051147,
      "epoch": 13.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066190391778946,
      "orthogonal_weight": 0.1,
      "step": 4242,
      "total_loss": 0.6589822173118591,
      "weighted_orthogonal_loss": 0.02066190354526043
    },
    {
      "classification_loss": 0.6156302690505981,
      "epoch": 13.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066301852464676,
      "orthogonal_weight": 0.1,
      "step": 4243,
      "total_loss": 0.6362932920455933,
      "weighted_orthogonal_loss": 0.02066301926970482
    },
    {
      "classification_loss": 0.6292291283607483,
      "epoch": 13.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066657990217209,
      "orthogonal_weight": 0.1,
      "step": 4244,
      "total_loss": 0.6498957276344299,
      "weighted_orthogonal_loss": 0.02066658064723015
    },
    {
      "classification_loss": 0.5216603875160217,
      "epoch": 13.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067127823829651,
      "orthogonal_weight": 0.1,
      "step": 4245,
      "total_loss": 0.5423316955566406,
      "weighted_orthogonal_loss": 0.02067127823829651
    },
    {
      "classification_loss": 0.5920228958129883,
      "epoch": 13.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20678433775901794,
      "orthogonal_weight": 0.1,
      "step": 4246,
      "total_loss": 0.6127013564109802,
      "weighted_orthogonal_loss": 0.020678434520959854
    },
    {
      "classification_loss": 0.6426464915275574,
      "epoch": 13.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20684348046779633,
      "orthogonal_weight": 0.1,
      "step": 4247,
      "total_loss": 0.6633308529853821,
      "weighted_orthogonal_loss": 0.020684348419308662
    },
    {
      "classification_loss": 0.6468214988708496,
      "epoch": 13.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20691175758838654,
      "orthogonal_weight": 0.1,
      "step": 4248,
      "total_loss": 0.6675126552581787,
      "weighted_orthogonal_loss": 0.020691176876425743
    },
    {
      "classification_loss": 0.605470597743988,
      "epoch": 13.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206936314702034,
      "orthogonal_weight": 0.1,
      "step": 4249,
      "total_loss": 0.6261642575263977,
      "weighted_orthogonal_loss": 0.02069363184273243
    },
    {
      "classification_loss": 0.6393426060676575,
      "epoch": 13.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20692826807498932,
      "orthogonal_weight": 0.1,
      "step": 4250,
      "total_loss": 0.6600354313850403,
      "weighted_orthogonal_loss": 0.02069282718002796
    },
    {
      "classification_loss": 0.5972558259963989,
      "epoch": 13.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20698173344135284,
      "orthogonal_weight": 0.1,
      "step": 4251,
      "total_loss": 0.6179540157318115,
      "weighted_orthogonal_loss": 0.020698172971606255
    },
    {
      "classification_loss": 0.6786723136901855,
      "epoch": 13.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20706526935100555,
      "orthogonal_weight": 0.1,
      "step": 4252,
      "total_loss": 0.6993788480758667,
      "weighted_orthogonal_loss": 0.020706526935100555
    },
    {
      "classification_loss": 0.6434656381607056,
      "epoch": 13.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20711669325828552,
      "orthogonal_weight": 0.1,
      "step": 4253,
      "total_loss": 0.6641772985458374,
      "weighted_orthogonal_loss": 0.020711669698357582
    },
    {
      "classification_loss": 0.6252033114433289,
      "epoch": 13.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2071353644132614,
      "orthogonal_weight": 0.1,
      "step": 4254,
      "total_loss": 0.6459168195724487,
      "weighted_orthogonal_loss": 0.02071353606879711
    },
    {
      "classification_loss": 0.6208789944648743,
      "epoch": 13.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069813311100006,
      "orthogonal_weight": 0.1,
      "step": 4255,
      "total_loss": 0.6415771245956421,
      "weighted_orthogonal_loss": 0.02069813385605812
    },
    {
      "classification_loss": 0.5833108425140381,
      "epoch": 13.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688791573047638,
      "orthogonal_weight": 0.1,
      "step": 4256,
      "total_loss": 0.6039996147155762,
      "weighted_orthogonal_loss": 0.020688792690634727
    },
    {
      "classification_loss": 0.6228214502334595,
      "epoch": 13.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068290114402771,
      "orthogonal_weight": 0.1,
      "step": 4257,
      "total_loss": 0.6435043811798096,
      "weighted_orthogonal_loss": 0.02068290114402771
    },
    {
      "classification_loss": 0.6123110055923462,
      "epoch": 13.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068023830652237,
      "orthogonal_weight": 0.1,
      "step": 4258,
      "total_loss": 0.6329912543296814,
      "weighted_orthogonal_loss": 0.02068023942410946
    },
    {
      "classification_loss": 0.7122365832328796,
      "epoch": 13.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067572921514511,
      "orthogonal_weight": 0.1,
      "step": 4259,
      "total_loss": 0.7329123020172119,
      "weighted_orthogonal_loss": 0.02067572996020317
    },
    {
      "classification_loss": 0.6228011250495911,
      "epoch": 13.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066754847764969,
      "orthogonal_weight": 0.1,
      "step": 4260,
      "total_loss": 0.6434686779975891,
      "weighted_orthogonal_loss": 0.02066754922270775
    },
    {
      "classification_loss": 0.6572840213775635,
      "epoch": 13.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2065468281507492,
      "orthogonal_weight": 0.1,
      "step": 4261,
      "total_loss": 0.67793869972229,
      "weighted_orthogonal_loss": 0.02065468393266201
    },
    {
      "classification_loss": 0.6605414152145386,
      "epoch": 13.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20639020204544067,
      "orthogonal_weight": 0.1,
      "step": 4262,
      "total_loss": 0.6811804175376892,
      "weighted_orthogonal_loss": 0.020639020949602127
    },
    {
      "classification_loss": 0.5683988928794861,
      "epoch": 13.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062477320432663,
      "orthogonal_weight": 0.1,
      "step": 4263,
      "total_loss": 0.5890236496925354,
      "weighted_orthogonal_loss": 0.02062477357685566
    },
    {
      "classification_loss": 0.5831080079078674,
      "epoch": 13.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20613399147987366,
      "orthogonal_weight": 0.1,
      "step": 4264,
      "total_loss": 0.6037213802337646,
      "weighted_orthogonal_loss": 0.020613400265574455
    },
    {
      "classification_loss": 0.6813532114028931,
      "epoch": 13.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20608031749725342,
      "orthogonal_weight": 0.1,
      "step": 4265,
      "total_loss": 0.7019612193107605,
      "weighted_orthogonal_loss": 0.02060803212225437
    },
    {
      "classification_loss": 0.6077439188957214,
      "epoch": 13.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2059873342514038,
      "orthogonal_weight": 0.1,
      "step": 4266,
      "total_loss": 0.6283426284790039,
      "weighted_orthogonal_loss": 0.02059873379766941
    },
    {
      "classification_loss": 0.5843331217765808,
      "epoch": 13.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20588989555835724,
      "orthogonal_weight": 0.1,
      "step": 4267,
      "total_loss": 0.6049221158027649,
      "weighted_orthogonal_loss": 0.020588990300893784
    },
    {
      "classification_loss": 0.5524393916130066,
      "epoch": 13.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20590578019618988,
      "orthogonal_weight": 0.1,
      "step": 4268,
      "total_loss": 0.5730299949645996,
      "weighted_orthogonal_loss": 0.020590579137206078
    },
    {
      "classification_loss": 0.5943663120269775,
      "epoch": 13.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20601539313793182,
      "orthogonal_weight": 0.1,
      "step": 4269,
      "total_loss": 0.6149678230285645,
      "weighted_orthogonal_loss": 0.020601538941264153
    },
    {
      "classification_loss": 0.6744819283485413,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.6950969696044922,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.6998980045318604,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.7205130457878113,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.6664712429046631,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.687086284160614,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.6844168901443481,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.7050319314002991,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.691360592842102,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.711975634098053,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.6686000823974609,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.6892151236534119,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.6526936888694763,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.6733087301254272,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.7044650316238403,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.7250800728797913,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.558,
      "eval_f1": 0.6681681681681682,
      "eval_loss": 0.7003334760665894,
      "eval_precision": 0.6276445698166432,
      "eval_recall": 0.7142857142857143,
      "eval_runtime": 6.1578,
      "eval_samples_per_second": 162.395,
      "eval_steps_per_second": 1.299,
      "step": 4270
    },
    {
      "classification_loss": 0.5893644094467163,
      "epoch": 14.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061501294374466,
      "orthogonal_weight": 0.1,
      "step": 4270,
      "total_loss": 0.6099794507026672,
      "weighted_orthogonal_loss": 0.02061501331627369
    },
    {
      "classification_loss": 0.615942656993866,
      "epoch": 14.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20628446340560913,
      "orthogonal_weight": 0.1,
      "step": 4271,
      "total_loss": 0.6365711092948914,
      "weighted_orthogonal_loss": 0.020628446713089943
    },
    {
      "classification_loss": 0.6594365239143372,
      "epoch": 14.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20648843050003052,
      "orthogonal_weight": 0.1,
      "step": 4272,
      "total_loss": 0.6800853610038757,
      "weighted_orthogonal_loss": 0.020648842677474022
    },
    {
      "classification_loss": 0.5710135102272034,
      "epoch": 14.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20669656991958618,
      "orthogonal_weight": 0.1,
      "step": 4273,
      "total_loss": 0.5916831493377686,
      "weighted_orthogonal_loss": 0.020669657737016678
    },
    {
      "classification_loss": 0.6143622994422913,
      "epoch": 14.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688962936401367,
      "orthogonal_weight": 0.1,
      "step": 4274,
      "total_loss": 0.6350512504577637,
      "weighted_orthogonal_loss": 0.020688964053988457
    },
    {
      "classification_loss": 0.5760618448257446,
      "epoch": 14.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2070818990468979,
      "orthogonal_weight": 0.1,
      "step": 4275,
      "total_loss": 0.5967700481414795,
      "weighted_orthogonal_loss": 0.02070819027721882
    },
    {
      "classification_loss": 0.6080761551856995,
      "epoch": 14.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20728923380374908,
      "orthogonal_weight": 0.1,
      "step": 4276,
      "total_loss": 0.6288051009178162,
      "weighted_orthogonal_loss": 0.02072892338037491
    },
    {
      "classification_loss": 0.6211885809898376,
      "epoch": 14.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20748066902160645,
      "orthogonal_weight": 0.1,
      "step": 4277,
      "total_loss": 0.6419366598129272,
      "weighted_orthogonal_loss": 0.020748067647218704
    },
    {
      "classification_loss": 0.573996901512146,
      "epoch": 14.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2076786309480667,
      "orthogonal_weight": 0.1,
      "step": 4278,
      "total_loss": 0.594764769077301,
      "weighted_orthogonal_loss": 0.02076786383986473
    },
    {
      "classification_loss": 0.6793634295463562,
      "epoch": 14.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20784790813922882,
      "orthogonal_weight": 0.1,
      "step": 4279,
      "total_loss": 0.7001482248306274,
      "weighted_orthogonal_loss": 0.020784791558980942
    },
    {
      "classification_loss": 0.5717634558677673,
      "epoch": 14.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20796793699264526,
      "orthogonal_weight": 0.1,
      "step": 4280,
      "total_loss": 0.5925602316856384,
      "weighted_orthogonal_loss": 0.020796794444322586
    },
    {
      "classification_loss": 0.5946834087371826,
      "epoch": 14.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20806267857551575,
      "orthogonal_weight": 0.1,
      "step": 4281,
      "total_loss": 0.615489661693573,
      "weighted_orthogonal_loss": 0.020806267857551575
    },
    {
      "classification_loss": 0.5598979592323303,
      "epoch": 14.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20817409455776215,
      "orthogonal_weight": 0.1,
      "step": 4282,
      "total_loss": 0.5807153582572937,
      "weighted_orthogonal_loss": 0.020817410200834274
    },
    {
      "classification_loss": 0.5506784319877625,
      "epoch": 14.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20829050242900848,
      "orthogonal_weight": 0.1,
      "step": 4283,
      "total_loss": 0.571507453918457,
      "weighted_orthogonal_loss": 0.02082904987037182
    },
    {
      "classification_loss": 0.7007852792739868,
      "epoch": 14.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084054946899414,
      "orthogonal_weight": 0.1,
      "step": 4284,
      "total_loss": 0.721625804901123,
      "weighted_orthogonal_loss": 0.02084054984152317
    },
    {
      "classification_loss": 0.5869267582893372,
      "epoch": 14.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20848825573921204,
      "orthogonal_weight": 0.1,
      "step": 4285,
      "total_loss": 0.6077755689620972,
      "weighted_orthogonal_loss": 0.020848825573921204
    },
    {
      "classification_loss": 0.5919227600097656,
      "epoch": 14.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20858930051326752,
      "orthogonal_weight": 0.1,
      "step": 4286,
      "total_loss": 0.6127817034721375,
      "weighted_orthogonal_loss": 0.02085893042385578
    },
    {
      "classification_loss": 0.6310223937034607,
      "epoch": 14.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087022066116333,
      "orthogonal_weight": 0.1,
      "step": 4287,
      "total_loss": 0.6518926024436951,
      "weighted_orthogonal_loss": 0.02087022177875042
    },
    {
      "classification_loss": 0.5396358966827393,
      "epoch": 14.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.208815336227417,
      "orthogonal_weight": 0.1,
      "step": 4288,
      "total_loss": 0.560517430305481,
      "weighted_orthogonal_loss": 0.0208815336227417
    },
    {
      "classification_loss": 0.6324776411056519,
      "epoch": 14.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20893096923828125,
      "orthogonal_weight": 0.1,
      "step": 4289,
      "total_loss": 0.65337073802948,
      "weighted_orthogonal_loss": 0.020893096923828125
    },
    {
      "classification_loss": 0.6000460982322693,
      "epoch": 14.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20924867689609528,
      "orthogonal_weight": 0.1,
      "step": 4290,
      "total_loss": 0.6209709644317627,
      "weighted_orthogonal_loss": 0.020924868062138557
    },
    {
      "classification_loss": 0.5607215762138367,
      "epoch": 14.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20951539278030396,
      "orthogonal_weight": 0.1,
      "step": 4291,
      "total_loss": 0.5816731452941895,
      "weighted_orthogonal_loss": 0.020951539278030396
    },
    {
      "classification_loss": 0.6041010022163391,
      "epoch": 14.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2097855657339096,
      "orthogonal_weight": 0.1,
      "step": 4292,
      "total_loss": 0.6250795722007751,
      "weighted_orthogonal_loss": 0.02097855694591999
    },
    {
      "classification_loss": 0.5546478033065796,
      "epoch": 14.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100100964307785,
      "orthogonal_weight": 0.1,
      "step": 4293,
      "total_loss": 0.5756487846374512,
      "weighted_orthogonal_loss": 0.02100100927054882
    },
    {
      "classification_loss": 0.7061516642570496,
      "epoch": 14.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21025152504444122,
      "orthogonal_weight": 0.1,
      "step": 4294,
      "total_loss": 0.7271768450737,
      "weighted_orthogonal_loss": 0.021025152876973152
    },
    {
      "classification_loss": 0.6708871126174927,
      "epoch": 14.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21044810116291046,
      "orthogonal_weight": 0.1,
      "step": 4295,
      "total_loss": 0.6919319033622742,
      "weighted_orthogonal_loss": 0.021044811233878136
    },
    {
      "classification_loss": 0.6150222420692444,
      "epoch": 14.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21058432757854462,
      "orthogonal_weight": 0.1,
      "step": 4296,
      "total_loss": 0.6360806822776794,
      "weighted_orthogonal_loss": 0.02105843275785446
    },
    {
      "classification_loss": 0.6138916611671448,
      "epoch": 14.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21074634790420532,
      "orthogonal_weight": 0.1,
      "step": 4297,
      "total_loss": 0.6349663138389587,
      "weighted_orthogonal_loss": 0.021074635908007622
    },
    {
      "classification_loss": 0.5741139650344849,
      "epoch": 14.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108556628227234,
      "orthogonal_weight": 0.1,
      "step": 4298,
      "total_loss": 0.5951995253562927,
      "weighted_orthogonal_loss": 0.02108556590974331
    },
    {
      "classification_loss": 0.6116890907287598,
      "epoch": 14.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21097096800804138,
      "orthogonal_weight": 0.1,
      "step": 4299,
      "total_loss": 0.632786214351654,
      "weighted_orthogonal_loss": 0.021097097545862198
    },
    {
      "epoch": 14.098360655737705,
      "grad_norm": 16.272445678710938,
      "learning_rate": 6.003333333333334e-05,
      "loss": 0.6356,
      "step": 4300
    },
    {
      "classification_loss": 0.7321974039077759,
      "epoch": 14.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109837293624878,
      "orthogonal_weight": 0.1,
      "step": 4300,
      "total_loss": 0.7533072233200073,
      "weighted_orthogonal_loss": 0.021109838038682938
    },
    {
      "classification_loss": 0.6736331582069397,
      "epoch": 14.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21117383241653442,
      "orthogonal_weight": 0.1,
      "step": 4301,
      "total_loss": 0.6947505474090576,
      "weighted_orthogonal_loss": 0.021117383614182472
    },
    {
      "classification_loss": 0.6049872040748596,
      "epoch": 14.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111867219209671,
      "orthogonal_weight": 0.1,
      "step": 4302,
      "total_loss": 0.6261059045791626,
      "weighted_orthogonal_loss": 0.02111867256462574
    },
    {
      "classification_loss": 0.6671785116195679,
      "epoch": 14.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112184315919876,
      "orthogonal_weight": 0.1,
      "step": 4303,
      "total_loss": 0.688300371170044,
      "weighted_orthogonal_loss": 0.02112184278666973
    },
    {
      "classification_loss": 0.6349980235099792,
      "epoch": 14.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21128089725971222,
      "orthogonal_weight": 0.1,
      "step": 4304,
      "total_loss": 0.6561261415481567,
      "weighted_orthogonal_loss": 0.021128090098500252
    },
    {
      "classification_loss": 0.5558840036392212,
      "epoch": 14.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21134696900844574,
      "orthogonal_weight": 0.1,
      "step": 4305,
      "total_loss": 0.577018678188324,
      "weighted_orthogonal_loss": 0.021134696900844574
    },
    {
      "classification_loss": 0.6135738492012024,
      "epoch": 14.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21138007938861847,
      "orthogonal_weight": 0.1,
      "step": 4306,
      "total_loss": 0.6347118616104126,
      "weighted_orthogonal_loss": 0.021138008683919907
    },
    {
      "classification_loss": 0.6182996034622192,
      "epoch": 14.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113838940858841,
      "orthogonal_weight": 0.1,
      "step": 4307,
      "total_loss": 0.6394379734992981,
      "weighted_orthogonal_loss": 0.0211383905261755
    },
    {
      "classification_loss": 0.5782467722892761,
      "epoch": 14.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21138907968997955,
      "orthogonal_weight": 0.1,
      "step": 4308,
      "total_loss": 0.599385678768158,
      "weighted_orthogonal_loss": 0.021138908341526985
    },
    {
      "classification_loss": 0.6252729892730713,
      "epoch": 14.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113541215658188,
      "orthogonal_weight": 0.1,
      "step": 4309,
      "total_loss": 0.6464083790779114,
      "weighted_orthogonal_loss": 0.02113541215658188
    },
    {
      "classification_loss": 0.6568697094917297,
      "epoch": 14.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21132463216781616,
      "orthogonal_weight": 0.1,
      "step": 4310,
      "total_loss": 0.6780021786689758,
      "weighted_orthogonal_loss": 0.021132463589310646
    },
    {
      "classification_loss": 0.5586476922035217,
      "epoch": 14.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21127398312091827,
      "orthogonal_weight": 0.1,
      "step": 4311,
      "total_loss": 0.5797750949859619,
      "weighted_orthogonal_loss": 0.021127399057149887
    },
    {
      "classification_loss": 0.5790613889694214,
      "epoch": 14.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112235277891159,
      "orthogonal_weight": 0.1,
      "step": 4312,
      "total_loss": 0.6001837253570557,
      "weighted_orthogonal_loss": 0.02112235315144062
    },
    {
      "classification_loss": 0.6346606016159058,
      "epoch": 14.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21114642918109894,
      "orthogonal_weight": 0.1,
      "step": 4313,
      "total_loss": 0.655775249004364,
      "weighted_orthogonal_loss": 0.021114643663167953
    },
    {
      "classification_loss": 0.5742526054382324,
      "epoch": 14.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105659008026123,
      "orthogonal_weight": 0.1,
      "step": 4314,
      "total_loss": 0.5953582525253296,
      "weighted_orthogonal_loss": 0.021105660125613213
    },
    {
      "classification_loss": 0.6000678539276123,
      "epoch": 14.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21089448034763336,
      "orthogonal_weight": 0.1,
      "step": 4315,
      "total_loss": 0.6211572885513306,
      "weighted_orthogonal_loss": 0.021089447662234306
    },
    {
      "classification_loss": 0.5976835489273071,
      "epoch": 14.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2107260823249817,
      "orthogonal_weight": 0.1,
      "step": 4316,
      "total_loss": 0.6187561750411987,
      "weighted_orthogonal_loss": 0.02107260935008526
    },
    {
      "classification_loss": 0.5673159956932068,
      "epoch": 14.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21059156954288483,
      "orthogonal_weight": 0.1,
      "step": 4317,
      "total_loss": 0.5883751511573792,
      "weighted_orthogonal_loss": 0.021059157326817513
    },
    {
      "classification_loss": 0.6566923260688782,
      "epoch": 14.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104388028383255,
      "orthogonal_weight": 0.1,
      "step": 4318,
      "total_loss": 0.677736222743988,
      "weighted_orthogonal_loss": 0.02104387991130352
    },
    {
      "classification_loss": 0.6539112329483032,
      "epoch": 14.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103172391653061,
      "orthogonal_weight": 0.1,
      "step": 4319,
      "total_loss": 0.6749429702758789,
      "weighted_orthogonal_loss": 0.02103172428905964
    },
    {
      "classification_loss": 0.6610804200172424,
      "epoch": 14.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101982682943344,
      "orthogonal_weight": 0.1,
      "step": 4320,
      "total_loss": 0.682100236415863,
      "weighted_orthogonal_loss": 0.0210198275744915
    },
    {
      "classification_loss": 0.6695778965950012,
      "epoch": 14.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21009382605552673,
      "orthogonal_weight": 0.1,
      "step": 4321,
      "total_loss": 0.6905872821807861,
      "weighted_orthogonal_loss": 0.021009383723139763
    },
    {
      "classification_loss": 0.6136146783828735,
      "epoch": 14.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099616378545761,
      "orthogonal_weight": 0.1,
      "step": 4322,
      "total_loss": 0.6346108317375183,
      "weighted_orthogonal_loss": 0.02099616453051567
    },
    {
      "classification_loss": 0.6060771346092224,
      "epoch": 14.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20985856652259827,
      "orthogonal_weight": 0.1,
      "step": 4323,
      "total_loss": 0.627062976360321,
      "weighted_orthogonal_loss": 0.020985856652259827
    },
    {
      "classification_loss": 0.5747273564338684,
      "epoch": 14.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20980313420295715,
      "orthogonal_weight": 0.1,
      "step": 4324,
      "total_loss": 0.5957076549530029,
      "weighted_orthogonal_loss": 0.020980313420295715
    },
    {
      "classification_loss": 0.5759207606315613,
      "epoch": 14.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2097620666027069,
      "orthogonal_weight": 0.1,
      "step": 4325,
      "total_loss": 0.5968969464302063,
      "weighted_orthogonal_loss": 0.02097620628774166
    },
    {
      "classification_loss": 0.686306357383728,
      "epoch": 14.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20974543690681458,
      "orthogonal_weight": 0.1,
      "step": 4326,
      "total_loss": 0.7072808742523193,
      "weighted_orthogonal_loss": 0.020974544808268547
    },
    {
      "classification_loss": 0.5934939384460449,
      "epoch": 14.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20972846448421478,
      "orthogonal_weight": 0.1,
      "step": 4327,
      "total_loss": 0.6144667863845825,
      "weighted_orthogonal_loss": 0.02097284607589245
    },
    {
      "classification_loss": 0.6112632751464844,
      "epoch": 14.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209734246134758,
      "orthogonal_weight": 0.1,
      "step": 4328,
      "total_loss": 0.6322367191314697,
      "weighted_orthogonal_loss": 0.02097342535853386
    },
    {
      "classification_loss": 0.6252149343490601,
      "epoch": 14.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20973888039588928,
      "orthogonal_weight": 0.1,
      "step": 4329,
      "total_loss": 0.6461887955665588,
      "weighted_orthogonal_loss": 0.020973889157176018
    },
    {
      "classification_loss": 0.6397260427474976,
      "epoch": 14.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20975084602832794,
      "orthogonal_weight": 0.1,
      "step": 4330,
      "total_loss": 0.6607011556625366,
      "weighted_orthogonal_loss": 0.020975084975361824
    },
    {
      "classification_loss": 0.5903295874595642,
      "epoch": 14.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20977449417114258,
      "orthogonal_weight": 0.1,
      "step": 4331,
      "total_loss": 0.6113070249557495,
      "weighted_orthogonal_loss": 0.020977450534701347
    },
    {
      "classification_loss": 0.5127413868904114,
      "epoch": 14.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2097371369600296,
      "orthogonal_weight": 0.1,
      "step": 4332,
      "total_loss": 0.5337151288986206,
      "weighted_orthogonal_loss": 0.02097371406853199
    },
    {
      "classification_loss": 0.6315818428993225,
      "epoch": 14.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20970745384693146,
      "orthogonal_weight": 0.1,
      "step": 4333,
      "total_loss": 0.652552604675293,
      "weighted_orthogonal_loss": 0.020970745012164116
    },
    {
      "classification_loss": 0.5144380331039429,
      "epoch": 14.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096662074327469,
      "orthogonal_weight": 0.1,
      "step": 4334,
      "total_loss": 0.5354046821594238,
      "weighted_orthogonal_loss": 0.02096662111580372
    },
    {
      "classification_loss": 0.5233181118965149,
      "epoch": 14.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20962782204151154,
      "orthogonal_weight": 0.1,
      "step": 4335,
      "total_loss": 0.5442808866500854,
      "weighted_orthogonal_loss": 0.020962782204151154
    },
    {
      "classification_loss": 0.6140021681785583,
      "epoch": 14.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20959119498729706,
      "orthogonal_weight": 0.1,
      "step": 4336,
      "total_loss": 0.6349613070487976,
      "weighted_orthogonal_loss": 0.020959120243787766
    },
    {
      "classification_loss": 0.6073886156082153,
      "epoch": 14.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20956318080425262,
      "orthogonal_weight": 0.1,
      "step": 4337,
      "total_loss": 0.6283449530601501,
      "weighted_orthogonal_loss": 0.020956318825483322
    },
    {
      "classification_loss": 0.609158992767334,
      "epoch": 14.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20950199663639069,
      "orthogonal_weight": 0.1,
      "step": 4338,
      "total_loss": 0.6301091909408569,
      "weighted_orthogonal_loss": 0.0209502000361681
    },
    {
      "classification_loss": 0.5711261630058289,
      "epoch": 14.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20937053859233856,
      "orthogonal_weight": 0.1,
      "step": 4339,
      "total_loss": 0.5920631885528564,
      "weighted_orthogonal_loss": 0.020937053486704826
    },
    {
      "classification_loss": 0.609488308429718,
      "epoch": 14.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20923694968223572,
      "orthogonal_weight": 0.1,
      "step": 4340,
      "total_loss": 0.6304119825363159,
      "weighted_orthogonal_loss": 0.020923694595694542
    },
    {
      "classification_loss": 0.5922542810440063,
      "epoch": 14.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20905275642871857,
      "orthogonal_weight": 0.1,
      "step": 4341,
      "total_loss": 0.6131595373153687,
      "weighted_orthogonal_loss": 0.020905276760458946
    },
    {
      "classification_loss": 0.569575309753418,
      "epoch": 14.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20890481770038605,
      "orthogonal_weight": 0.1,
      "step": 4342,
      "total_loss": 0.590465784072876,
      "weighted_orthogonal_loss": 0.020890481770038605
    },
    {
      "classification_loss": 0.5904523134231567,
      "epoch": 14.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2088048905134201,
      "orthogonal_weight": 0.1,
      "step": 4343,
      "total_loss": 0.6113327741622925,
      "weighted_orthogonal_loss": 0.02088048867881298
    },
    {
      "classification_loss": 0.6633343696594238,
      "epoch": 14.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20878131687641144,
      "orthogonal_weight": 0.1,
      "step": 4344,
      "total_loss": 0.6842125058174133,
      "weighted_orthogonal_loss": 0.020878132432699203
    },
    {
      "classification_loss": 0.6295453906059265,
      "epoch": 14.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20872469246387482,
      "orthogonal_weight": 0.1,
      "step": 4345,
      "total_loss": 0.6504178643226624,
      "weighted_orthogonal_loss": 0.02087246999144554
    },
    {
      "classification_loss": 0.6503980159759521,
      "epoch": 14.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20860864222049713,
      "orthogonal_weight": 0.1,
      "step": 4346,
      "total_loss": 0.6712588667869568,
      "weighted_orthogonal_loss": 0.020860863849520683
    },
    {
      "classification_loss": 0.6279857754707336,
      "epoch": 14.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20850062370300293,
      "orthogonal_weight": 0.1,
      "step": 4347,
      "total_loss": 0.6488358378410339,
      "weighted_orthogonal_loss": 0.020850062370300293
    },
    {
      "classification_loss": 0.6201646327972412,
      "epoch": 14.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20838288962841034,
      "orthogonal_weight": 0.1,
      "step": 4348,
      "total_loss": 0.641002893447876,
      "weighted_orthogonal_loss": 0.020838288590312004
    },
    {
      "classification_loss": 0.6080716252326965,
      "epoch": 14.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20830701291561127,
      "orthogonal_weight": 0.1,
      "step": 4349,
      "total_loss": 0.6289023160934448,
      "weighted_orthogonal_loss": 0.020830702036619186
    },
    {
      "classification_loss": 0.6191524863243103,
      "epoch": 14.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2082352340221405,
      "orthogonal_weight": 0.1,
      "step": 4350,
      "total_loss": 0.6399760246276855,
      "weighted_orthogonal_loss": 0.02082352340221405
    },
    {
      "classification_loss": 0.6094573736190796,
      "epoch": 14.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2081167846918106,
      "orthogonal_weight": 0.1,
      "step": 4351,
      "total_loss": 0.6302690505981445,
      "weighted_orthogonal_loss": 0.02081167884171009
    },
    {
      "classification_loss": 0.6156749129295349,
      "epoch": 14.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079963982105255,
      "orthogonal_weight": 0.1,
      "step": 4352,
      "total_loss": 0.6364745497703552,
      "weighted_orthogonal_loss": 0.02079964056611061
    },
    {
      "classification_loss": 0.5432945489883423,
      "epoch": 14.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079317420721054,
      "orthogonal_weight": 0.1,
      "step": 4353,
      "total_loss": 0.5640877485275269,
      "weighted_orthogonal_loss": 0.02079317532479763
    },
    {
      "classification_loss": 0.6161881685256958,
      "epoch": 14.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207887664437294,
      "orthogonal_weight": 0.1,
      "step": 4354,
      "total_loss": 0.636976957321167,
      "weighted_orthogonal_loss": 0.0207887664437294
    },
    {
      "classification_loss": 0.5978598594665527,
      "epoch": 14.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20788030326366425,
      "orthogonal_weight": 0.1,
      "step": 4355,
      "total_loss": 0.6186478734016418,
      "weighted_orthogonal_loss": 0.020788030698895454
    },
    {
      "classification_loss": 0.5936208963394165,
      "epoch": 14.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079077661037445,
      "orthogonal_weight": 0.1,
      "step": 4356,
      "total_loss": 0.6144116520881653,
      "weighted_orthogonal_loss": 0.02079077623784542
    },
    {
      "classification_loss": 0.5553193688392639,
      "epoch": 14.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20786035060882568,
      "orthogonal_weight": 0.1,
      "step": 4357,
      "total_loss": 0.5761054158210754,
      "weighted_orthogonal_loss": 0.020786035805940628
    },
    {
      "classification_loss": 0.6014549732208252,
      "epoch": 14.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20780707895755768,
      "orthogonal_weight": 0.1,
      "step": 4358,
      "total_loss": 0.6222356557846069,
      "weighted_orthogonal_loss": 0.020780708640813828
    },
    {
      "classification_loss": 0.6589808464050293,
      "epoch": 14.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2076767235994339,
      "orthogonal_weight": 0.1,
      "step": 4359,
      "total_loss": 0.67974853515625,
      "weighted_orthogonal_loss": 0.02076767198741436
    },
    {
      "classification_loss": 0.5596922039985657,
      "epoch": 14.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20750217139720917,
      "orthogonal_weight": 0.1,
      "step": 4360,
      "total_loss": 0.5804424285888672,
      "weighted_orthogonal_loss": 0.020750217139720917
    },
    {
      "classification_loss": 0.5915365815162659,
      "epoch": 14.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20738764107227325,
      "orthogonal_weight": 0.1,
      "step": 4361,
      "total_loss": 0.6122753620147705,
      "weighted_orthogonal_loss": 0.020738763734698296
    },
    {
      "classification_loss": 0.5823776125907898,
      "epoch": 14.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20716750621795654,
      "orthogonal_weight": 0.1,
      "step": 4362,
      "total_loss": 0.6030943393707275,
      "weighted_orthogonal_loss": 0.020716750994324684
    },
    {
      "classification_loss": 0.5817863941192627,
      "epoch": 14.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20699742436408997,
      "orthogonal_weight": 0.1,
      "step": 4363,
      "total_loss": 0.6024861335754395,
      "weighted_orthogonal_loss": 0.020699743181467056
    },
    {
      "classification_loss": 0.669765055179596,
      "epoch": 14.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20681238174438477,
      "orthogonal_weight": 0.1,
      "step": 4364,
      "total_loss": 0.6904463171958923,
      "weighted_orthogonal_loss": 0.020681237801909447
    },
    {
      "classification_loss": 0.6019006967544556,
      "epoch": 14.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20663030445575714,
      "orthogonal_weight": 0.1,
      "step": 4365,
      "total_loss": 0.6225637197494507,
      "weighted_orthogonal_loss": 0.020663030445575714
    },
    {
      "classification_loss": 0.6540049910545349,
      "epoch": 14.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20646615326404572,
      "orthogonal_weight": 0.1,
      "step": 4366,
      "total_loss": 0.6746516227722168,
      "weighted_orthogonal_loss": 0.02064661495387554
    },
    {
      "classification_loss": 0.578284740447998,
      "epoch": 14.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20630767941474915,
      "orthogonal_weight": 0.1,
      "step": 4367,
      "total_loss": 0.5989155173301697,
      "weighted_orthogonal_loss": 0.020630767568945885
    },
    {
      "classification_loss": 0.6020622253417969,
      "epoch": 14.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20611409842967987,
      "orthogonal_weight": 0.1,
      "step": 4368,
      "total_loss": 0.6226736307144165,
      "weighted_orthogonal_loss": 0.020611410960555077
    },
    {
      "classification_loss": 0.559840738773346,
      "epoch": 14.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20590749382972717,
      "orthogonal_weight": 0.1,
      "step": 4369,
      "total_loss": 0.5804314613342285,
      "weighted_orthogonal_loss": 0.020590750500559807
    },
    {
      "classification_loss": 0.7041093707084656,
      "epoch": 14.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20571540296077728,
      "orthogonal_weight": 0.1,
      "step": 4370,
      "total_loss": 0.7246809005737305,
      "weighted_orthogonal_loss": 0.020571541041135788
    },
    {
      "classification_loss": 0.6013789176940918,
      "epoch": 14.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20554326474666595,
      "orthogonal_weight": 0.1,
      "step": 4371,
      "total_loss": 0.6219332218170166,
      "weighted_orthogonal_loss": 0.020554326474666595
    },
    {
      "classification_loss": 0.5865194797515869,
      "epoch": 14.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2053595632314682,
      "orthogonal_weight": 0.1,
      "step": 4372,
      "total_loss": 0.6070554256439209,
      "weighted_orthogonal_loss": 0.02053595706820488
    },
    {
      "classification_loss": 0.686204195022583,
      "epoch": 14.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052324414253235,
      "orthogonal_weight": 0.1,
      "step": 4373,
      "total_loss": 0.7067274451255798,
      "weighted_orthogonal_loss": 0.02052324451506138
    },
    {
      "classification_loss": 0.6320376396179199,
      "epoch": 14.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2050982564687729,
      "orthogonal_weight": 0.1,
      "step": 4374,
      "total_loss": 0.6525474786758423,
      "weighted_orthogonal_loss": 0.02050982601940632
    },
    {
      "classification_loss": 0.6294841766357422,
      "epoch": 14.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20500420033931732,
      "orthogonal_weight": 0.1,
      "step": 4375,
      "total_loss": 0.64998459815979,
      "weighted_orthogonal_loss": 0.020500419661402702
    },
    {
      "classification_loss": 0.7049991488456726,
      "epoch": 14.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20493817329406738,
      "orthogonal_weight": 0.1,
      "step": 4376,
      "total_loss": 0.7254929542541504,
      "weighted_orthogonal_loss": 0.020493818446993828
    },
    {
      "classification_loss": 0.5958129167556763,
      "epoch": 14.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20488987863063812,
      "orthogonal_weight": 0.1,
      "step": 4377,
      "total_loss": 0.6163018941879272,
      "weighted_orthogonal_loss": 0.020488988608121872
    },
    {
      "classification_loss": 0.6701872944831848,
      "epoch": 14.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20485396683216095,
      "orthogonal_weight": 0.1,
      "step": 4378,
      "total_loss": 0.6906726956367493,
      "weighted_orthogonal_loss": 0.020485397428274155
    },
    {
      "classification_loss": 0.5562899112701416,
      "epoch": 14.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482484996318817,
      "orthogonal_weight": 0.1,
      "step": 4379,
      "total_loss": 0.5767723917961121,
      "weighted_orthogonal_loss": 0.020482486113905907
    },
    {
      "classification_loss": 0.6253101229667664,
      "epoch": 14.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20480413734912872,
      "orthogonal_weight": 0.1,
      "step": 4380,
      "total_loss": 0.6457905173301697,
      "weighted_orthogonal_loss": 0.020480414852499962
    },
    {
      "classification_loss": 0.5561206340789795,
      "epoch": 14.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20480550825595856,
      "orthogonal_weight": 0.1,
      "step": 4381,
      "total_loss": 0.5766012072563171,
      "weighted_orthogonal_loss": 0.020480550825595856
    },
    {
      "classification_loss": 0.6435644030570984,
      "epoch": 14.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20482809841632843,
      "orthogonal_weight": 0.1,
      "step": 4382,
      "total_loss": 0.6640472412109375,
      "weighted_orthogonal_loss": 0.020482810214161873
    },
    {
      "classification_loss": 0.6387983560562134,
      "epoch": 14.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20483385026454926,
      "orthogonal_weight": 0.1,
      "step": 4383,
      "total_loss": 0.6592817306518555,
      "weighted_orthogonal_loss": 0.020483385771512985
    },
    {
      "classification_loss": 0.6543758511543274,
      "epoch": 14.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20480649173259735,
      "orthogonal_weight": 0.1,
      "step": 4384,
      "total_loss": 0.6748564839363098,
      "weighted_orthogonal_loss": 0.020480649545788765
    },
    {
      "classification_loss": 0.5994712114334106,
      "epoch": 14.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2047818899154663,
      "orthogonal_weight": 0.1,
      "step": 4385,
      "total_loss": 0.6199494004249573,
      "weighted_orthogonal_loss": 0.02047818899154663
    },
    {
      "classification_loss": 0.6333546042442322,
      "epoch": 14.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20472857356071472,
      "orthogonal_weight": 0.1,
      "step": 4386,
      "total_loss": 0.6538274884223938,
      "weighted_orthogonal_loss": 0.020472858101129532
    },
    {
      "classification_loss": 0.6454573273658752,
      "epoch": 14.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20466159284114838,
      "orthogonal_weight": 0.1,
      "step": 4387,
      "total_loss": 0.6659234762191772,
      "weighted_orthogonal_loss": 0.020466160029172897
    },
    {
      "classification_loss": 0.5556902885437012,
      "epoch": 14.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20461292564868927,
      "orthogonal_weight": 0.1,
      "step": 4388,
      "total_loss": 0.5761516094207764,
      "weighted_orthogonal_loss": 0.020461292937397957
    },
    {
      "classification_loss": 0.621384859085083,
      "epoch": 14.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20454782247543335,
      "orthogonal_weight": 0.1,
      "step": 4389,
      "total_loss": 0.6418396234512329,
      "weighted_orthogonal_loss": 0.020454782992601395
    },
    {
      "classification_loss": 0.590187132358551,
      "epoch": 14.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045094519853592,
      "orthogonal_weight": 0.1,
      "step": 4390,
      "total_loss": 0.6106380820274353,
      "weighted_orthogonal_loss": 0.02045094594359398
    },
    {
      "classification_loss": 0.6277757883071899,
      "epoch": 14.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20444925129413605,
      "orthogonal_weight": 0.1,
      "step": 4391,
      "total_loss": 0.6482207179069519,
      "weighted_orthogonal_loss": 0.020444925874471664
    },
    {
      "classification_loss": 0.6194832921028137,
      "epoch": 14.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20439116656780243,
      "orthogonal_weight": 0.1,
      "step": 4392,
      "total_loss": 0.6399223804473877,
      "weighted_orthogonal_loss": 0.020439116284251213
    },
    {
      "classification_loss": 0.668013870716095,
      "epoch": 14.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20434750616550446,
      "orthogonal_weight": 0.1,
      "step": 4393,
      "total_loss": 0.6884486079216003,
      "weighted_orthogonal_loss": 0.020434750244021416
    },
    {
      "classification_loss": 0.5688674449920654,
      "epoch": 14.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20431675016880035,
      "orthogonal_weight": 0.1,
      "step": 4394,
      "total_loss": 0.5892991423606873,
      "weighted_orthogonal_loss": 0.020431675016880035
    },
    {
      "classification_loss": 0.598612904548645,
      "epoch": 14.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043042629957199,
      "orthogonal_weight": 0.1,
      "step": 4395,
      "total_loss": 0.6190433502197266,
      "weighted_orthogonal_loss": 0.02043042704463005
    },
    {
      "classification_loss": 0.6765292882919312,
      "epoch": 14.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20427656173706055,
      "orthogonal_weight": 0.1,
      "step": 4396,
      "total_loss": 0.6969569325447083,
      "weighted_orthogonal_loss": 0.020427657291293144
    },
    {
      "classification_loss": 0.6574883460998535,
      "epoch": 14.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042587399482727,
      "orthogonal_weight": 0.1,
      "step": 4397,
      "total_loss": 0.6779142022132874,
      "weighted_orthogonal_loss": 0.02042587473988533
    },
    {
      "classification_loss": 0.6696650385856628,
      "epoch": 14.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042749673128128,
      "orthogonal_weight": 0.1,
      "step": 4398,
      "total_loss": 0.6900925636291504,
      "weighted_orthogonal_loss": 0.02042749710381031
    },
    {
      "classification_loss": 0.6281089782714844,
      "epoch": 14.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20430080592632294,
      "orthogonal_weight": 0.1,
      "step": 4399,
      "total_loss": 0.6485390663146973,
      "weighted_orthogonal_loss": 0.020430080592632294
    },
    {
      "epoch": 14.426229508196721,
      "grad_norm": 7.66865348815918,
      "learning_rate": 5.6699999999999996e-05,
      "loss": 0.6349,
      "step": 4400
    },
    {
      "classification_loss": 0.5766698718070984,
      "epoch": 14.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043420523405075,
      "orthogonal_weight": 0.1,
      "step": 4400,
      "total_loss": 0.5971040725708008,
      "weighted_orthogonal_loss": 0.02043420635163784
    },
    {
      "classification_loss": 0.5793570280075073,
      "epoch": 14.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20438925921916962,
      "orthogonal_weight": 0.1,
      "step": 4401,
      "total_loss": 0.599795937538147,
      "weighted_orthogonal_loss": 0.02043892629444599
    },
    {
      "classification_loss": 0.5804986357688904,
      "epoch": 14.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20443779230117798,
      "orthogonal_weight": 0.1,
      "step": 4402,
      "total_loss": 0.6009424328804016,
      "weighted_orthogonal_loss": 0.020443780347704887
    },
    {
      "classification_loss": 0.5998159646987915,
      "epoch": 14.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2044782191514969,
      "orthogonal_weight": 0.1,
      "step": 4403,
      "total_loss": 0.6202638149261475,
      "weighted_orthogonal_loss": 0.02044782228767872
    },
    {
      "classification_loss": 0.5785397291183472,
      "epoch": 14.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045084685087204,
      "orthogonal_weight": 0.1,
      "step": 4404,
      "total_loss": 0.5989905595779419,
      "weighted_orthogonal_loss": 0.02045084722340107
    },
    {
      "classification_loss": 0.624367892742157,
      "epoch": 14.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20453934371471405,
      "orthogonal_weight": 0.1,
      "step": 4405,
      "total_loss": 0.64482182264328,
      "weighted_orthogonal_loss": 0.020453935489058495
    },
    {
      "classification_loss": 0.54461270570755,
      "epoch": 14.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20457985997200012,
      "orthogonal_weight": 0.1,
      "step": 4406,
      "total_loss": 0.5650706887245178,
      "weighted_orthogonal_loss": 0.020457986742258072
    },
    {
      "classification_loss": 0.6416100859642029,
      "epoch": 14.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20463000237941742,
      "orthogonal_weight": 0.1,
      "step": 4407,
      "total_loss": 0.6620730757713318,
      "weighted_orthogonal_loss": 0.0204630009829998
    },
    {
      "classification_loss": 0.6590054631233215,
      "epoch": 14.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2046339064836502,
      "orthogonal_weight": 0.1,
      "step": 4408,
      "total_loss": 0.6794688701629639,
      "weighted_orthogonal_loss": 0.02046339027583599
    },
    {
      "classification_loss": 0.7218465805053711,
      "epoch": 14.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20461392402648926,
      "orthogonal_weight": 0.1,
      "step": 4409,
      "total_loss": 0.7423079609870911,
      "weighted_orthogonal_loss": 0.020461393520236015
    },
    {
      "classification_loss": 0.5814407467842102,
      "epoch": 14.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2046123892068863,
      "orthogonal_weight": 0.1,
      "step": 4410,
      "total_loss": 0.6019020080566406,
      "weighted_orthogonal_loss": 0.02046123892068863
    },
    {
      "classification_loss": 0.6378714442253113,
      "epoch": 14.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2046135514974594,
      "orthogonal_weight": 0.1,
      "step": 4411,
      "total_loss": 0.6583328247070312,
      "weighted_orthogonal_loss": 0.02046135626733303
    },
    {
      "classification_loss": 0.6259307861328125,
      "epoch": 14.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20461592078208923,
      "orthogonal_weight": 0.1,
      "step": 4412,
      "total_loss": 0.6463924050331116,
      "weighted_orthogonal_loss": 0.020461592823266983
    },
    {
      "classification_loss": 0.6400936841964722,
      "epoch": 14.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20461316406726837,
      "orthogonal_weight": 0.1,
      "step": 4413,
      "total_loss": 0.6605550050735474,
      "weighted_orthogonal_loss": 0.020461317151784897
    },
    {
      "classification_loss": 0.6069233417510986,
      "epoch": 14.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20460398495197296,
      "orthogonal_weight": 0.1,
      "step": 4414,
      "total_loss": 0.6273837685585022,
      "weighted_orthogonal_loss": 0.020460398867726326
    },
    {
      "classification_loss": 0.6473521590232849,
      "epoch": 14.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20456072688102722,
      "orthogonal_weight": 0.1,
      "step": 4415,
      "total_loss": 0.6678082346916199,
      "weighted_orthogonal_loss": 0.02045607380568981
    },
    {
      "classification_loss": 0.6934903264045715,
      "epoch": 14.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20450752973556519,
      "orthogonal_weight": 0.1,
      "step": 4416,
      "total_loss": 0.7139410972595215,
      "weighted_orthogonal_loss": 0.020450754091143608
    },
    {
      "classification_loss": 0.5725148320198059,
      "epoch": 14.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20447498559951782,
      "orthogonal_weight": 0.1,
      "step": 4417,
      "total_loss": 0.5929623246192932,
      "weighted_orthogonal_loss": 0.020447498187422752
    },
    {
      "classification_loss": 0.6184179782867432,
      "epoch": 14.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20442137122154236,
      "orthogonal_weight": 0.1,
      "step": 4418,
      "total_loss": 0.6388601064682007,
      "weighted_orthogonal_loss": 0.020442137494683266
    },
    {
      "classification_loss": 0.6360524892807007,
      "epoch": 14.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20435459911823273,
      "orthogonal_weight": 0.1,
      "step": 4419,
      "total_loss": 0.6564879417419434,
      "weighted_orthogonal_loss": 0.020435459911823273
    },
    {
      "classification_loss": 0.6552703380584717,
      "epoch": 14.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20430801808834076,
      "orthogonal_weight": 0.1,
      "step": 4420,
      "total_loss": 0.6757011413574219,
      "weighted_orthogonal_loss": 0.020430801436305046
    },
    {
      "classification_loss": 0.689437985420227,
      "epoch": 14.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20427899062633514,
      "orthogonal_weight": 0.1,
      "step": 4421,
      "total_loss": 0.7098658680915833,
      "weighted_orthogonal_loss": 0.020427899435162544
    },
    {
      "classification_loss": 0.5034748315811157,
      "epoch": 14.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20415373146533966,
      "orthogonal_weight": 0.1,
      "step": 4422,
      "total_loss": 0.5238901972770691,
      "weighted_orthogonal_loss": 0.020415373146533966
    },
    {
      "classification_loss": 0.6287925839424133,
      "epoch": 14.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20406469702720642,
      "orthogonal_weight": 0.1,
      "step": 4423,
      "total_loss": 0.6491990685462952,
      "weighted_orthogonal_loss": 0.020406469702720642
    },
    {
      "classification_loss": 0.6241966485977173,
      "epoch": 14.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20403040945529938,
      "orthogonal_weight": 0.1,
      "step": 4424,
      "total_loss": 0.6445996761322021,
      "weighted_orthogonal_loss": 0.020403040573000908
    },
    {
      "classification_loss": 0.6432749629020691,
      "epoch": 14.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20400117337703705,
      "orthogonal_weight": 0.1,
      "step": 4425,
      "total_loss": 0.66367506980896,
      "weighted_orthogonal_loss": 0.020400118082761765
    },
    {
      "classification_loss": 0.6508864164352417,
      "epoch": 14.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2039787769317627,
      "orthogonal_weight": 0.1,
      "step": 4426,
      "total_loss": 0.6712843179702759,
      "weighted_orthogonal_loss": 0.02039787732064724
    },
    {
      "classification_loss": 0.6790475249290466,
      "epoch": 14.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20394200086593628,
      "orthogonal_weight": 0.1,
      "step": 4427,
      "total_loss": 0.6994417309761047,
      "weighted_orthogonal_loss": 0.020394200459122658
    },
    {
      "classification_loss": 0.5558292269706726,
      "epoch": 14.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20390789210796356,
      "orthogonal_weight": 0.1,
      "step": 4428,
      "total_loss": 0.5762200355529785,
      "weighted_orthogonal_loss": 0.020390789955854416
    },
    {
      "classification_loss": 0.6988803148269653,
      "epoch": 14.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037707269191742,
      "orthogonal_weight": 0.1,
      "step": 4429,
      "total_loss": 0.7192574143409729,
      "weighted_orthogonal_loss": 0.02037707343697548
    },
    {
      "classification_loss": 0.6546622514724731,
      "epoch": 14.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2036616951227188,
      "orthogonal_weight": 0.1,
      "step": 4430,
      "total_loss": 0.6750284433364868,
      "weighted_orthogonal_loss": 0.02036616951227188
    },
    {
      "classification_loss": 0.6551070213317871,
      "epoch": 14.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20355337858200073,
      "orthogonal_weight": 0.1,
      "step": 4431,
      "total_loss": 0.6754623651504517,
      "weighted_orthogonal_loss": 0.020355338230729103
    },
    {
      "classification_loss": 0.6674289107322693,
      "epoch": 14.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20345188677310944,
      "orthogonal_weight": 0.1,
      "step": 4432,
      "total_loss": 0.687774121761322,
      "weighted_orthogonal_loss": 0.020345188677310944
    },
    {
      "classification_loss": 0.6759970188140869,
      "epoch": 14.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20335353910923004,
      "orthogonal_weight": 0.1,
      "step": 4433,
      "total_loss": 0.6963323950767517,
      "weighted_orthogonal_loss": 0.020335353910923004
    },
    {
      "classification_loss": 0.5344955325126648,
      "epoch": 14.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032782882452011,
      "orthogonal_weight": 0.1,
      "step": 4434,
      "total_loss": 0.5548233389854431,
      "weighted_orthogonal_loss": 0.02032782882452011
    },
    {
      "classification_loss": 0.6160032749176025,
      "epoch": 14.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032066136598587,
      "orthogonal_weight": 0.1,
      "step": 4435,
      "total_loss": 0.6363239288330078,
      "weighted_orthogonal_loss": 0.02032066136598587
    },
    {
      "classification_loss": 0.5784153938293457,
      "epoch": 14.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031380534172058,
      "orthogonal_weight": 0.1,
      "step": 4436,
      "total_loss": 0.5987291932106018,
      "weighted_orthogonal_loss": 0.02031380496919155
    },
    {
      "classification_loss": 0.5995587706565857,
      "epoch": 14.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306789875030518,
      "orthogonal_weight": 0.1,
      "step": 4437,
      "total_loss": 0.6198655366897583,
      "weighted_orthogonal_loss": 0.020306790247559547
    },
    {
      "classification_loss": 0.5939779877662659,
      "epoch": 14.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030169814825058,
      "orthogonal_weight": 0.1,
      "step": 4438,
      "total_loss": 0.6142796874046326,
      "weighted_orthogonal_loss": 0.02030169777572155
    },
    {
      "classification_loss": 0.6039919257164001,
      "epoch": 14.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030441164970398,
      "orthogonal_weight": 0.1,
      "step": 4439,
      "total_loss": 0.6242963075637817,
      "weighted_orthogonal_loss": 0.02030441164970398
    },
    {
      "classification_loss": 0.6907931566238403,
      "epoch": 14.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20308592915534973,
      "orthogonal_weight": 0.1,
      "step": 4440,
      "total_loss": 0.711101770401001,
      "weighted_orthogonal_loss": 0.020308593288064003
    },
    {
      "classification_loss": 0.5974463820457458,
      "epoch": 14.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031363546848297,
      "orthogonal_weight": 0.1,
      "step": 4441,
      "total_loss": 0.6177600026130676,
      "weighted_orthogonal_loss": 0.02031363546848297
    },
    {
      "classification_loss": 0.6158462166786194,
      "epoch": 14.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031852751970291,
      "orthogonal_weight": 0.1,
      "step": 4442,
      "total_loss": 0.6361647248268127,
      "weighted_orthogonal_loss": 0.02031852863729
    },
    {
      "classification_loss": 0.6004310250282288,
      "epoch": 14.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20323944091796875,
      "orthogonal_weight": 0.1,
      "step": 4443,
      "total_loss": 0.6207549571990967,
      "weighted_orthogonal_loss": 0.020323945209383965
    },
    {
      "classification_loss": 0.640346884727478,
      "epoch": 14.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20321960747241974,
      "orthogonal_weight": 0.1,
      "step": 4444,
      "total_loss": 0.6606688499450684,
      "weighted_orthogonal_loss": 0.020321961492300034
    },
    {
      "classification_loss": 0.6709553599357605,
      "epoch": 14.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320720970630646,
      "orthogonal_weight": 0.1,
      "step": 4445,
      "total_loss": 0.6912760734558105,
      "weighted_orthogonal_loss": 0.020320720970630646
    },
    {
      "classification_loss": 0.5649563670158386,
      "epoch": 14.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20319421589374542,
      "orthogonal_weight": 0.1,
      "step": 4446,
      "total_loss": 0.5852757692337036,
      "weighted_orthogonal_loss": 0.020319422706961632
    },
    {
      "classification_loss": 0.6232315897941589,
      "epoch": 14.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031908482313156,
      "orthogonal_weight": 0.1,
      "step": 4447,
      "total_loss": 0.6435506939888,
      "weighted_orthogonal_loss": 0.02031908556818962
    },
    {
      "classification_loss": 0.7133133411407471,
      "epoch": 14.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20318053662776947,
      "orthogonal_weight": 0.1,
      "step": 4448,
      "total_loss": 0.7336313724517822,
      "weighted_orthogonal_loss": 0.020318053662776947
    },
    {
      "classification_loss": 0.6293874979019165,
      "epoch": 14.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031797468662262,
      "orthogonal_weight": 0.1,
      "step": 4449,
      "total_loss": 0.6497054696083069,
      "weighted_orthogonal_loss": 0.02031797543168068
    },
    {
      "classification_loss": 0.684672474861145,
      "epoch": 14.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20318622887134552,
      "orthogonal_weight": 0.1,
      "step": 4450,
      "total_loss": 0.7049911022186279,
      "weighted_orthogonal_loss": 0.02031862363219261
    },
    {
      "classification_loss": 0.6658926010131836,
      "epoch": 14.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20315976440906525,
      "orthogonal_weight": 0.1,
      "step": 4451,
      "total_loss": 0.6862086057662964,
      "weighted_orthogonal_loss": 0.020315976813435555
    },
    {
      "classification_loss": 0.5981805324554443,
      "epoch": 14.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311681926250458,
      "orthogonal_weight": 0.1,
      "step": 4452,
      "total_loss": 0.6184921860694885,
      "weighted_orthogonal_loss": 0.020311681553721428
    },
    {
      "classification_loss": 0.6510080695152283,
      "epoch": 14.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20307327806949615,
      "orthogonal_weight": 0.1,
      "step": 4453,
      "total_loss": 0.6713153719902039,
      "weighted_orthogonal_loss": 0.020307328552007675
    },
    {
      "classification_loss": 0.5486926436424255,
      "epoch": 14.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20300181210041046,
      "orthogonal_weight": 0.1,
      "step": 4454,
      "total_loss": 0.5689928531646729,
      "weighted_orthogonal_loss": 0.020300181582570076
    },
    {
      "classification_loss": 0.6502998471260071,
      "epoch": 14.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029654085636139,
      "orthogonal_weight": 0.1,
      "step": 4455,
      "total_loss": 0.6705963611602783,
      "weighted_orthogonal_loss": 0.02029654197394848
    },
    {
      "classification_loss": 0.6533692479133606,
      "epoch": 14.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20288747549057007,
      "orthogonal_weight": 0.1,
      "step": 4456,
      "total_loss": 0.673658013343811,
      "weighted_orthogonal_loss": 0.020288748666644096
    },
    {
      "classification_loss": 0.6482520699501038,
      "epoch": 14.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20285403728485107,
      "orthogonal_weight": 0.1,
      "step": 4457,
      "total_loss": 0.6685374975204468,
      "weighted_orthogonal_loss": 0.020285403355956078
    },
    {
      "classification_loss": 0.6299088001251221,
      "epoch": 14.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20280833542346954,
      "orthogonal_weight": 0.1,
      "step": 4458,
      "total_loss": 0.6501896381378174,
      "weighted_orthogonal_loss": 0.020280834287405014
    },
    {
      "classification_loss": 0.5462557077407837,
      "epoch": 14.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027609795331955,
      "orthogonal_weight": 0.1,
      "step": 4459,
      "total_loss": 0.566531777381897,
      "weighted_orthogonal_loss": 0.02027609758079052
    },
    {
      "classification_loss": 0.5855653285980225,
      "epoch": 14.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20271022617816925,
      "orthogonal_weight": 0.1,
      "step": 4460,
      "total_loss": 0.6058363318443298,
      "weighted_orthogonal_loss": 0.020271023735404015
    },
    {
      "classification_loss": 0.6630726456642151,
      "epoch": 14.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20267529785633087,
      "orthogonal_weight": 0.1,
      "step": 4461,
      "total_loss": 0.6833401918411255,
      "weighted_orthogonal_loss": 0.020267529413104057
    },
    {
      "classification_loss": 0.5451992750167847,
      "epoch": 14.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20261812210083008,
      "orthogonal_weight": 0.1,
      "step": 4462,
      "total_loss": 0.5654610991477966,
      "weighted_orthogonal_loss": 0.020261812955141068
    },
    {
      "classification_loss": 0.5928410887718201,
      "epoch": 14.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20258842408657074,
      "orthogonal_weight": 0.1,
      "step": 4463,
      "total_loss": 0.6130999326705933,
      "weighted_orthogonal_loss": 0.020258842036128044
    },
    {
      "classification_loss": 0.5800082087516785,
      "epoch": 14.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20255814492702484,
      "orthogonal_weight": 0.1,
      "step": 4464,
      "total_loss": 0.6002640128135681,
      "weighted_orthogonal_loss": 0.020255815237760544
    },
    {
      "classification_loss": 0.5789527297019958,
      "epoch": 14.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025289088487625,
      "orthogonal_weight": 0.1,
      "step": 4465,
      "total_loss": 0.5992056131362915,
      "weighted_orthogonal_loss": 0.02025289088487625
    },
    {
      "classification_loss": 0.6788733601570129,
      "epoch": 14.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20254479348659515,
      "orthogonal_weight": 0.1,
      "step": 4466,
      "total_loss": 0.6991278529167175,
      "weighted_orthogonal_loss": 0.020254479721188545
    },
    {
      "classification_loss": 0.6171695590019226,
      "epoch": 14.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20262236893177032,
      "orthogonal_weight": 0.1,
      "step": 4467,
      "total_loss": 0.637431800365448,
      "weighted_orthogonal_loss": 0.020262237638235092
    },
    {
      "classification_loss": 0.5749055743217468,
      "epoch": 14.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20266474783420563,
      "orthogonal_weight": 0.1,
      "step": 4468,
      "total_loss": 0.5951720476150513,
      "weighted_orthogonal_loss": 0.020266475155949593
    },
    {
      "classification_loss": 0.5317125916481018,
      "epoch": 14.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20273065567016602,
      "orthogonal_weight": 0.1,
      "step": 4469,
      "total_loss": 0.5519856810569763,
      "weighted_orthogonal_loss": 0.02027306519448757
    },
    {
      "classification_loss": 0.6222394704818726,
      "epoch": 14.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20280225574970245,
      "orthogonal_weight": 0.1,
      "step": 4470,
      "total_loss": 0.6425197124481201,
      "weighted_orthogonal_loss": 0.020280225202441216
    },
    {
      "classification_loss": 0.6216817498207092,
      "epoch": 14.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20289593935012817,
      "orthogonal_weight": 0.1,
      "step": 4471,
      "total_loss": 0.6419713497161865,
      "weighted_orthogonal_loss": 0.020289594307541847
    },
    {
      "classification_loss": 0.6425349712371826,
      "epoch": 14.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20300373435020447,
      "orthogonal_weight": 0.1,
      "step": 4472,
      "total_loss": 0.6628353595733643,
      "weighted_orthogonal_loss": 0.020300373435020447
    },
    {
      "classification_loss": 0.7138873934745789,
      "epoch": 14.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20305770635604858,
      "orthogonal_weight": 0.1,
      "step": 4473,
      "total_loss": 0.7341931462287903,
      "weighted_orthogonal_loss": 0.020305771380662918
    },
    {
      "classification_loss": 0.6141581535339355,
      "epoch": 14.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306017994880676,
      "orthogonal_weight": 0.1,
      "step": 4474,
      "total_loss": 0.6344641447067261,
      "weighted_orthogonal_loss": 0.020306019112467766
    },
    {
      "classification_loss": 0.5668255090713501,
      "epoch": 14.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030140608549118,
      "orthogonal_weight": 0.1,
      "step": 4475,
      "total_loss": 0.5871269106864929,
      "weighted_orthogonal_loss": 0.02030140720307827
    },
    {
      "classification_loss": 0.6066910028457642,
      "epoch": 14.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20293383300304413,
      "orthogonal_weight": 0.1,
      "step": 4476,
      "total_loss": 0.6269843578338623,
      "weighted_orthogonal_loss": 0.020293382927775383
    },
    {
      "classification_loss": 0.5816367268562317,
      "epoch": 14.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20296142995357513,
      "orthogonal_weight": 0.1,
      "step": 4477,
      "total_loss": 0.6019328832626343,
      "weighted_orthogonal_loss": 0.020296143367886543
    },
    {
      "classification_loss": 0.5662527084350586,
      "epoch": 14.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20301850140094757,
      "orthogonal_weight": 0.1,
      "step": 4478,
      "total_loss": 0.5865545868873596,
      "weighted_orthogonal_loss": 0.020301850512623787
    },
    {
      "classification_loss": 0.5325332283973694,
      "epoch": 14.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030559778213501,
      "orthogonal_weight": 0.1,
      "step": 4479,
      "total_loss": 0.5528388023376465,
      "weighted_orthogonal_loss": 0.02030559815466404
    },
    {
      "classification_loss": 0.582848846912384,
      "epoch": 14.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20309245586395264,
      "orthogonal_weight": 0.1,
      "step": 4480,
      "total_loss": 0.6031581163406372,
      "weighted_orthogonal_loss": 0.020309245213866234
    },
    {
      "classification_loss": 0.6571897864341736,
      "epoch": 14.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031220942735672,
      "orthogonal_weight": 0.1,
      "step": 4481,
      "total_loss": 0.6775019764900208,
      "weighted_orthogonal_loss": 0.02031221054494381
    },
    {
      "classification_loss": 0.6445944905281067,
      "epoch": 14.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20314164459705353,
      "orthogonal_weight": 0.1,
      "step": 4482,
      "total_loss": 0.6649086475372314,
      "weighted_orthogonal_loss": 0.020314164459705353
    },
    {
      "classification_loss": 0.6501563191413879,
      "epoch": 14.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20316727459430695,
      "orthogonal_weight": 0.1,
      "step": 4483,
      "total_loss": 0.670473039150238,
      "weighted_orthogonal_loss": 0.020316727459430695
    },
    {
      "classification_loss": 0.5734102725982666,
      "epoch": 14.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20317602157592773,
      "orthogonal_weight": 0.1,
      "step": 4484,
      "total_loss": 0.5937278866767883,
      "weighted_orthogonal_loss": 0.020317602902650833
    },
    {
      "classification_loss": 0.6819648742675781,
      "epoch": 14.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20317862927913666,
      "orthogonal_weight": 0.1,
      "step": 4485,
      "total_loss": 0.702282726764679,
      "weighted_orthogonal_loss": 0.020317863672971725
    },
    {
      "classification_loss": 0.5957381725311279,
      "epoch": 14.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320914685726166,
      "orthogonal_weight": 0.1,
      "step": 4486,
      "total_loss": 0.6160590648651123,
      "weighted_orthogonal_loss": 0.020320914685726166
    },
    {
      "classification_loss": 0.567875862121582,
      "epoch": 14.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031479924917221,
      "orthogonal_weight": 0.1,
      "step": 4487,
      "total_loss": 0.5881906747817993,
      "weighted_orthogonal_loss": 0.02031479962170124
    },
    {
      "classification_loss": 0.6500428915023804,
      "epoch": 14.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311498641967773,
      "orthogonal_weight": 0.1,
      "step": 4488,
      "total_loss": 0.6703543663024902,
      "weighted_orthogonal_loss": 0.020311499014496803
    },
    {
      "classification_loss": 0.538773775100708,
      "epoch": 14.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20308056473731995,
      "orthogonal_weight": 0.1,
      "step": 4489,
      "total_loss": 0.5590818524360657,
      "weighted_orthogonal_loss": 0.020308056846261024
    },
    {
      "classification_loss": 0.5760650038719177,
      "epoch": 14.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20301635563373566,
      "orthogonal_weight": 0.1,
      "step": 4490,
      "total_loss": 0.5963666439056396,
      "weighted_orthogonal_loss": 0.020301636308431625
    },
    {
      "classification_loss": 0.5593469738960266,
      "epoch": 14.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20298618078231812,
      "orthogonal_weight": 0.1,
      "step": 4491,
      "total_loss": 0.579645574092865,
      "weighted_orthogonal_loss": 0.02029861882328987
    },
    {
      "classification_loss": 0.5901080369949341,
      "epoch": 14.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029542177915573,
      "orthogonal_weight": 0.1,
      "step": 4492,
      "total_loss": 0.6104034781455994,
      "weighted_orthogonal_loss": 0.02029542252421379
    },
    {
      "classification_loss": 0.6267902851104736,
      "epoch": 14.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20295201241970062,
      "orthogonal_weight": 0.1,
      "step": 4493,
      "total_loss": 0.6470854878425598,
      "weighted_orthogonal_loss": 0.020295200869441032
    },
    {
      "classification_loss": 0.6950931549072266,
      "epoch": 14.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20304612815380096,
      "orthogonal_weight": 0.1,
      "step": 4494,
      "total_loss": 0.7153977751731873,
      "weighted_orthogonal_loss": 0.020304612815380096
    },
    {
      "classification_loss": 0.5895752906799316,
      "epoch": 14.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20307020843029022,
      "orthogonal_weight": 0.1,
      "step": 4495,
      "total_loss": 0.6098822951316833,
      "weighted_orthogonal_loss": 0.020307021215558052
    },
    {
      "classification_loss": 0.637824535369873,
      "epoch": 14.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031092792749405,
      "orthogonal_weight": 0.1,
      "step": 4496,
      "total_loss": 0.6581354737281799,
      "weighted_orthogonal_loss": 0.02031092904508114
    },
    {
      "classification_loss": 0.6602362990379333,
      "epoch": 14.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20313876867294312,
      "orthogonal_weight": 0.1,
      "step": 4497,
      "total_loss": 0.6805501580238342,
      "weighted_orthogonal_loss": 0.02031387761235237
    },
    {
      "classification_loss": 0.60341876745224,
      "epoch": 14.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20302839577198029,
      "orthogonal_weight": 0.1,
      "step": 4498,
      "total_loss": 0.6237215995788574,
      "weighted_orthogonal_loss": 0.02030283957719803
    },
    {
      "classification_loss": 0.6628453731536865,
      "epoch": 14.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028336077928543,
      "orthogonal_weight": 0.1,
      "step": 4499,
      "total_loss": 0.6831287145614624,
      "weighted_orthogonal_loss": 0.02028336189687252
    },
    {
      "epoch": 14.754098360655737,
      "grad_norm": 14.267552375793457,
      "learning_rate": 5.3366666666666665e-05,
      "loss": 0.6389,
      "step": 4500
    },
    {
      "classification_loss": 0.5780515074729919,
      "epoch": 14.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20264498889446259,
      "orthogonal_weight": 0.1,
      "step": 4500,
      "total_loss": 0.5983160138130188,
      "weighted_orthogonal_loss": 0.02026449888944626
    },
    {
      "classification_loss": 0.6186909675598145,
      "epoch": 14.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025286704301834,
      "orthogonal_weight": 0.1,
      "step": 4501,
      "total_loss": 0.6389438509941101,
      "weighted_orthogonal_loss": 0.02025286667048931
    },
    {
      "classification_loss": 0.6364519000053406,
      "epoch": 14.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20245137810707092,
      "orthogonal_weight": 0.1,
      "step": 4502,
      "total_loss": 0.6566970348358154,
      "weighted_orthogonal_loss": 0.020245138555765152
    },
    {
      "classification_loss": 0.655159592628479,
      "epoch": 14.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20239511132240295,
      "orthogonal_weight": 0.1,
      "step": 4503,
      "total_loss": 0.675399124622345,
      "weighted_orthogonal_loss": 0.020239511504769325
    },
    {
      "classification_loss": 0.6347508430480957,
      "epoch": 14.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20233285427093506,
      "orthogonal_weight": 0.1,
      "step": 4504,
      "total_loss": 0.6549841165542603,
      "weighted_orthogonal_loss": 0.020233286544680595
    },
    {
      "classification_loss": 0.6556198000907898,
      "epoch": 14.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022712379693985,
      "orthogonal_weight": 0.1,
      "step": 4505,
      "total_loss": 0.6758469343185425,
      "weighted_orthogonal_loss": 0.02022712491452694
    },
    {
      "classification_loss": 0.5926071405410767,
      "epoch": 14.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022053748369217,
      "orthogonal_weight": 0.1,
      "step": 4506,
      "total_loss": 0.6128276586532593,
      "weighted_orthogonal_loss": 0.02022053860127926
    },
    {
      "classification_loss": 0.6124446988105774,
      "epoch": 14.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021477073431015,
      "orthogonal_weight": 0.1,
      "step": 4507,
      "total_loss": 0.6326594948768616,
      "weighted_orthogonal_loss": 0.02021477185189724
    },
    {
      "classification_loss": 0.676240086555481,
      "epoch": 14.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20209403336048126,
      "orthogonal_weight": 0.1,
      "step": 4508,
      "total_loss": 0.6964495182037354,
      "weighted_orthogonal_loss": 0.020209403708577156
    },
    {
      "classification_loss": 0.6465486288070679,
      "epoch": 14.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20204393565654755,
      "orthogonal_weight": 0.1,
      "step": 4509,
      "total_loss": 0.6667529940605164,
      "weighted_orthogonal_loss": 0.020204393193125725
    },
    {
      "classification_loss": 0.6708902716636658,
      "epoch": 14.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20203422009944916,
      "orthogonal_weight": 0.1,
      "step": 4510,
      "total_loss": 0.6910936832427979,
      "weighted_orthogonal_loss": 0.020203422755002975
    },
    {
      "classification_loss": 0.633641242980957,
      "epoch": 14.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20205463469028473,
      "orthogonal_weight": 0.1,
      "step": 4511,
      "total_loss": 0.6538466811180115,
      "weighted_orthogonal_loss": 0.020205464214086533
    },
    {
      "classification_loss": 0.6430624723434448,
      "epoch": 14.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020602524280548,
      "orthogonal_weight": 0.1,
      "step": 4512,
      "total_loss": 0.663268506526947,
      "weighted_orthogonal_loss": 0.02020602487027645
    },
    {
      "classification_loss": 0.5966771245002747,
      "epoch": 14.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20208120346069336,
      "orthogonal_weight": 0.1,
      "step": 4513,
      "total_loss": 0.616885244846344,
      "weighted_orthogonal_loss": 0.020208120346069336
    },
    {
      "classification_loss": 0.6119859218597412,
      "epoch": 14.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20210842788219452,
      "orthogonal_weight": 0.1,
      "step": 4514,
      "total_loss": 0.6321967840194702,
      "weighted_orthogonal_loss": 0.02021084353327751
    },
    {
      "classification_loss": 0.6137178540229797,
      "epoch": 14.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20218594372272491,
      "orthogonal_weight": 0.1,
      "step": 4515,
      "total_loss": 0.6339364647865295,
      "weighted_orthogonal_loss": 0.02021859399974346
    },
    {
      "classification_loss": 0.5937524437904358,
      "epoch": 14.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022443562746048,
      "orthogonal_weight": 0.1,
      "step": 4516,
      "total_loss": 0.6139768958091736,
      "weighted_orthogonal_loss": 0.02022443525493145
    },
    {
      "classification_loss": 0.6297425031661987,
      "epoch": 14.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20222383737564087,
      "orthogonal_weight": 0.1,
      "step": 4517,
      "total_loss": 0.6499648690223694,
      "weighted_orthogonal_loss": 0.020222384482622147
    },
    {
      "classification_loss": 0.5827279686927795,
      "epoch": 14.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20221003890037537,
      "orthogonal_weight": 0.1,
      "step": 4518,
      "total_loss": 0.6029489636421204,
      "weighted_orthogonal_loss": 0.020221004262566566
    },
    {
      "classification_loss": 0.5879449248313904,
      "epoch": 14.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20218999683856964,
      "orthogonal_weight": 0.1,
      "step": 4519,
      "total_loss": 0.6081639528274536,
      "weighted_orthogonal_loss": 0.020219000056385994
    },
    {
      "classification_loss": 0.6897825002670288,
      "epoch": 14.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20221880078315735,
      "orthogonal_weight": 0.1,
      "step": 4520,
      "total_loss": 0.7100043892860413,
      "weighted_orthogonal_loss": 0.020221879705786705
    },
    {
      "classification_loss": 0.6078536510467529,
      "epoch": 14.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20226602256298065,
      "orthogonal_weight": 0.1,
      "step": 4521,
      "total_loss": 0.6280802488327026,
      "weighted_orthogonal_loss": 0.020226603373885155
    },
    {
      "classification_loss": 0.6076774597167969,
      "epoch": 14.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022882103919983,
      "orthogonal_weight": 0.1,
      "step": 4522,
      "total_loss": 0.6279062628746033,
      "weighted_orthogonal_loss": 0.02022882178425789
    },
    {
      "classification_loss": 0.5403793454170227,
      "epoch": 14.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023410052061081,
      "orthogonal_weight": 0.1,
      "step": 4523,
      "total_loss": 0.5606134533882141,
      "weighted_orthogonal_loss": 0.02023410052061081
    },
    {
      "classification_loss": 0.6904721260070801,
      "epoch": 14.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20241142809391022,
      "orthogonal_weight": 0.1,
      "step": 4524,
      "total_loss": 0.710713267326355,
      "weighted_orthogonal_loss": 0.02024114318192005
    },
    {
      "classification_loss": 0.6768262982368469,
      "epoch": 14.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20240187644958496,
      "orthogonal_weight": 0.1,
      "step": 4525,
      "total_loss": 0.6970664858818054,
      "weighted_orthogonal_loss": 0.020240187644958496
    },
    {
      "classification_loss": 0.6562904119491577,
      "epoch": 14.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20241151750087738,
      "orthogonal_weight": 0.1,
      "step": 4526,
      "total_loss": 0.6765315532684326,
      "weighted_orthogonal_loss": 0.020241152495145798
    },
    {
      "classification_loss": 0.5473936200141907,
      "epoch": 14.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023901343345642,
      "orthogonal_weight": 0.1,
      "step": 4527,
      "total_loss": 0.5676326155662537,
      "weighted_orthogonal_loss": 0.02023901417851448
    },
    {
      "classification_loss": 0.6014103889465332,
      "epoch": 14.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20240628719329834,
      "orthogonal_weight": 0.1,
      "step": 4528,
      "total_loss": 0.6216509938240051,
      "weighted_orthogonal_loss": 0.020240629091858864
    },
    {
      "classification_loss": 0.6753965020179749,
      "epoch": 14.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202328160405159,
      "orthogonal_weight": 0.1,
      "step": 4529,
      "total_loss": 0.6956292986869812,
      "weighted_orthogonal_loss": 0.02023281715810299
    },
    {
      "classification_loss": 0.6384907364845276,
      "epoch": 14.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20225316286087036,
      "orthogonal_weight": 0.1,
      "step": 4530,
      "total_loss": 0.658716082572937,
      "weighted_orthogonal_loss": 0.020225316286087036
    },
    {
      "classification_loss": 0.6547917127609253,
      "epoch": 14.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20224525034427643,
      "orthogonal_weight": 0.1,
      "step": 4531,
      "total_loss": 0.6750162243843079,
      "weighted_orthogonal_loss": 0.020224524661898613
    },
    {
      "classification_loss": 0.6000513434410095,
      "epoch": 14.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023034691810608,
      "orthogonal_weight": 0.1,
      "step": 4532,
      "total_loss": 0.6202816963195801,
      "weighted_orthogonal_loss": 0.02023034729063511
    },
    {
      "classification_loss": 0.5820949077606201,
      "epoch": 14.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023710161447525,
      "orthogonal_weight": 0.1,
      "step": 4533,
      "total_loss": 0.6023319959640503,
      "weighted_orthogonal_loss": 0.02023710124194622
    },
    {
      "classification_loss": 0.6258647441864014,
      "epoch": 14.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20247425138950348,
      "orthogonal_weight": 0.1,
      "step": 4534,
      "total_loss": 0.6461121439933777,
      "weighted_orthogonal_loss": 0.020247425884008408
    },
    {
      "classification_loss": 0.6146891117095947,
      "epoch": 14.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20259739458560944,
      "orthogonal_weight": 0.1,
      "step": 4535,
      "total_loss": 0.6349488496780396,
      "weighted_orthogonal_loss": 0.020259739831089973
    },
    {
      "classification_loss": 0.5948410034179688,
      "epoch": 14.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027297168970108,
      "orthogonal_weight": 0.1,
      "step": 4536,
      "total_loss": 0.6151139736175537,
      "weighted_orthogonal_loss": 0.02027297206223011
    },
    {
      "classification_loss": 0.554638147354126,
      "epoch": 14.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20287707448005676,
      "orthogonal_weight": 0.1,
      "step": 4537,
      "total_loss": 0.5749258399009705,
      "weighted_orthogonal_loss": 0.020287707448005676
    },
    {
      "classification_loss": 0.5967307686805725,
      "epoch": 14.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20299769937992096,
      "orthogonal_weight": 0.1,
      "step": 4538,
      "total_loss": 0.6170305609703064,
      "weighted_orthogonal_loss": 0.020299769937992096
    },
    {
      "classification_loss": 0.6609770059585571,
      "epoch": 14.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20304934680461884,
      "orthogonal_weight": 0.1,
      "step": 4539,
      "total_loss": 0.6812819242477417,
      "weighted_orthogonal_loss": 0.020304935052990913
    },
    {
      "classification_loss": 0.623092770576477,
      "epoch": 14.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311705768108368,
      "orthogonal_weight": 0.1,
      "step": 4540,
      "total_loss": 0.643404483795166,
      "weighted_orthogonal_loss": 0.020311705768108368
    },
    {
      "classification_loss": 0.6217734217643738,
      "epoch": 14.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032114714384079,
      "orthogonal_weight": 0.1,
      "step": 4541,
      "total_loss": 0.6420945525169373,
      "weighted_orthogonal_loss": 0.02032114751636982
    },
    {
      "classification_loss": 0.5849288702011108,
      "epoch": 14.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20338650047779083,
      "orthogonal_weight": 0.1,
      "step": 4542,
      "total_loss": 0.6052675247192383,
      "weighted_orthogonal_loss": 0.020338650792837143
    },
    {
      "classification_loss": 0.571036696434021,
      "epoch": 14.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2035370022058487,
      "orthogonal_weight": 0.1,
      "step": 4543,
      "total_loss": 0.5913903713226318,
      "weighted_orthogonal_loss": 0.02035370096564293
    },
    {
      "classification_loss": 0.6618292927742004,
      "epoch": 14.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20372144877910614,
      "orthogonal_weight": 0.1,
      "step": 4544,
      "total_loss": 0.6822014451026917,
      "weighted_orthogonal_loss": 0.020372144877910614
    },
    {
      "classification_loss": 0.5874319076538086,
      "epoch": 14.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20386970043182373,
      "orthogonal_weight": 0.1,
      "step": 4545,
      "total_loss": 0.6078189015388489,
      "weighted_orthogonal_loss": 0.020386969670653343
    },
    {
      "classification_loss": 0.6879287958145142,
      "epoch": 14.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2040039598941803,
      "orthogonal_weight": 0.1,
      "step": 4546,
      "total_loss": 0.7083292007446289,
      "weighted_orthogonal_loss": 0.020400395616889
    },
    {
      "classification_loss": 0.6587880253791809,
      "epoch": 14.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20409724116325378,
      "orthogonal_weight": 0.1,
      "step": 4547,
      "total_loss": 0.6791977286338806,
      "weighted_orthogonal_loss": 0.02040972374379635
    },
    {
      "classification_loss": 0.5929787755012512,
      "epoch": 14.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20416076481342316,
      "orthogonal_weight": 0.1,
      "step": 4548,
      "total_loss": 0.6133948564529419,
      "weighted_orthogonal_loss": 0.020416077226400375
    },
    {
      "classification_loss": 0.6070232391357422,
      "epoch": 14.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20422157645225525,
      "orthogonal_weight": 0.1,
      "step": 4549,
      "total_loss": 0.6274453997612,
      "weighted_orthogonal_loss": 0.020422158762812614
    },
    {
      "classification_loss": 0.6241762042045593,
      "epoch": 14.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20426936447620392,
      "orthogonal_weight": 0.1,
      "step": 4550,
      "total_loss": 0.6446031332015991,
      "weighted_orthogonal_loss": 0.020426936447620392
    },
    {
      "classification_loss": 0.6768456697463989,
      "epoch": 14.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042953372001648,
      "orthogonal_weight": 0.1,
      "step": 4551,
      "total_loss": 0.6972752213478088,
      "weighted_orthogonal_loss": 0.02042953483760357
    },
    {
      "classification_loss": 0.5767468214035034,
      "epoch": 14.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2043180614709854,
      "orthogonal_weight": 0.1,
      "step": 4552,
      "total_loss": 0.5971786379814148,
      "weighted_orthogonal_loss": 0.02043180726468563
    },
    {
      "classification_loss": 0.5846258401870728,
      "epoch": 14.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20437833666801453,
      "orthogonal_weight": 0.1,
      "step": 4553,
      "total_loss": 0.6050636768341064,
      "weighted_orthogonal_loss": 0.020437834784388542
    },
    {
      "classification_loss": 0.6867586374282837,
      "epoch": 14.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20451323688030243,
      "orthogonal_weight": 0.1,
      "step": 4554,
      "total_loss": 0.7072099447250366,
      "weighted_orthogonal_loss": 0.020451324060559273
    },
    {
      "classification_loss": 0.554841160774231,
      "epoch": 14.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20460852980613708,
      "orthogonal_weight": 0.1,
      "step": 4555,
      "total_loss": 0.575302004814148,
      "weighted_orthogonal_loss": 0.02046085335314274
    },
    {
      "classification_loss": 0.6023864150047302,
      "epoch": 14.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20470263063907623,
      "orthogonal_weight": 0.1,
      "step": 4556,
      "total_loss": 0.6228566765785217,
      "weighted_orthogonal_loss": 0.020470263436436653
    },
    {
      "classification_loss": 0.5852603316307068,
      "epoch": 14.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2047445923089981,
      "orthogonal_weight": 0.1,
      "step": 4557,
      "total_loss": 0.6057347655296326,
      "weighted_orthogonal_loss": 0.02047445997595787
    },
    {
      "classification_loss": 0.6121829152107239,
      "epoch": 14.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2047659009695053,
      "orthogonal_weight": 0.1,
      "step": 4558,
      "total_loss": 0.6326594948768616,
      "weighted_orthogonal_loss": 0.02047659084200859
    },
    {
      "classification_loss": 0.5916188359260559,
      "epoch": 14.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2046806514263153,
      "orthogonal_weight": 0.1,
      "step": 4559,
      "total_loss": 0.6120868921279907,
      "weighted_orthogonal_loss": 0.02046806551516056
    },
    {
      "classification_loss": 0.637935221195221,
      "epoch": 14.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2046029418706894,
      "orthogonal_weight": 0.1,
      "step": 4560,
      "total_loss": 0.658395528793335,
      "weighted_orthogonal_loss": 0.02046029455959797
    },
    {
      "classification_loss": 0.5903654098510742,
      "epoch": 14.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2045312374830246,
      "orthogonal_weight": 0.1,
      "step": 4561,
      "total_loss": 0.6108185052871704,
      "weighted_orthogonal_loss": 0.02045312337577343
    },
    {
      "classification_loss": 0.6364131569862366,
      "epoch": 14.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20437254011631012,
      "orthogonal_weight": 0.1,
      "step": 4562,
      "total_loss": 0.6568503975868225,
      "weighted_orthogonal_loss": 0.020437253639101982
    },
    {
      "classification_loss": 0.5896924734115601,
      "epoch": 14.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20421305298805237,
      "orthogonal_weight": 0.1,
      "step": 4563,
      "total_loss": 0.610113799571991,
      "weighted_orthogonal_loss": 0.020421305671334267
    },
    {
      "classification_loss": 0.6480991840362549,
      "epoch": 14.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20403745770454407,
      "orthogonal_weight": 0.1,
      "step": 4564,
      "total_loss": 0.668502926826477,
      "weighted_orthogonal_loss": 0.020403746515512466
    },
    {
      "classification_loss": 0.6469085216522217,
      "epoch": 14.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20386004447937012,
      "orthogonal_weight": 0.1,
      "step": 4565,
      "total_loss": 0.6672945022583008,
      "weighted_orthogonal_loss": 0.02038600482046604
    },
    {
      "classification_loss": 0.6467280387878418,
      "epoch": 14.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20375680923461914,
      "orthogonal_weight": 0.1,
      "step": 4566,
      "total_loss": 0.6671037077903748,
      "weighted_orthogonal_loss": 0.020375682041049004
    },
    {
      "classification_loss": 0.6013751029968262,
      "epoch": 14.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20366936922073364,
      "orthogonal_weight": 0.1,
      "step": 4567,
      "total_loss": 0.6217420101165771,
      "weighted_orthogonal_loss": 0.020366936922073364
    },
    {
      "classification_loss": 0.6750290989875793,
      "epoch": 14.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203583762049675,
      "orthogonal_weight": 0.1,
      "step": 4568,
      "total_loss": 0.6953874826431274,
      "weighted_orthogonal_loss": 0.0203583762049675
    },
    {
      "classification_loss": 0.6224583387374878,
      "epoch": 14.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20348761975765228,
      "orthogonal_weight": 0.1,
      "step": 4569,
      "total_loss": 0.642807126045227,
      "weighted_orthogonal_loss": 0.020348763093352318
    },
    {
      "classification_loss": 0.5910288691520691,
      "epoch": 14.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20340724289417267,
      "orthogonal_weight": 0.1,
      "step": 4570,
      "total_loss": 0.6113696098327637,
      "weighted_orthogonal_loss": 0.020340723916888237
    },
    {
      "classification_loss": 0.6714766025543213,
      "epoch": 14.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20335102081298828,
      "orthogonal_weight": 0.1,
      "step": 4571,
      "total_loss": 0.6918116807937622,
      "weighted_orthogonal_loss": 0.020335102453827858
    },
    {
      "classification_loss": 0.6354425549507141,
      "epoch": 14.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033194750547409,
      "orthogonal_weight": 0.1,
      "step": 4572,
      "total_loss": 0.6557744741439819,
      "weighted_orthogonal_loss": 0.02033194713294506
    },
    {
      "classification_loss": 0.6311507225036621,
      "epoch": 14.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20330075919628143,
      "orthogonal_weight": 0.1,
      "step": 4573,
      "total_loss": 0.6514807939529419,
      "weighted_orthogonal_loss": 0.020330077037215233
    },
    {
      "classification_loss": 0.5713295936584473,
      "epoch": 14.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329315960407257,
      "orthogonal_weight": 0.1,
      "step": 4574,
      "total_loss": 0.591658890247345,
      "weighted_orthogonal_loss": 0.020329317077994347
    },
    {
      "classification_loss": 0.681728720664978,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.7020581960678101,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6976180076599121,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.7179474830627441,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6737912893295288,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.6941207647323608,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6960058212280273,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.7163352966308594,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6948482990264893,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.7151777744293213,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6783604621887207,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.6986899375915527,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.6662658452987671,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.6865953207015991,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.7059822678565979,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.7263117432594299,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.54,
      "eval_f1": 0.6290322580645161,
      "eval_loss": 0.7066947817802429,
      "eval_precision": 0.6320907617504052,
      "eval_recall": 0.6260032102728732,
      "eval_runtime": 6.1532,
      "eval_samples_per_second": 162.518,
      "eval_steps_per_second": 1.3,
      "step": 4575
    },
    {
      "classification_loss": 0.6628294587135315,
      "epoch": 15.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329459011554718,
      "orthogonal_weight": 0.1,
      "step": 4575,
      "total_loss": 0.6831589341163635,
      "weighted_orthogonal_loss": 0.020329458639025688
    },
    {
      "classification_loss": 0.5523650646209717,
      "epoch": 15.00327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329800248146057,
      "orthogonal_weight": 0.1,
      "step": 4576,
      "total_loss": 0.5726948380470276,
      "weighted_orthogonal_loss": 0.020329801365733147
    },
    {
      "classification_loss": 0.6236716508865356,
      "epoch": 15.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20331858098506927,
      "orthogonal_weight": 0.1,
      "step": 4577,
      "total_loss": 0.6440035104751587,
      "weighted_orthogonal_loss": 0.020331857725977898
    },
    {
      "classification_loss": 0.6986061930656433,
      "epoch": 15.00983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033502608537674,
      "orthogonal_weight": 0.1,
      "step": 4578,
      "total_loss": 0.7189412117004395,
      "weighted_orthogonal_loss": 0.02033502608537674
    },
    {
      "classification_loss": 0.5757442116737366,
      "epoch": 15.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20336472988128662,
      "orthogonal_weight": 0.1,
      "step": 4579,
      "total_loss": 0.5960806608200073,
      "weighted_orthogonal_loss": 0.020336473360657692
    },
    {
      "classification_loss": 0.5722684860229492,
      "epoch": 15.01639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20336857438087463,
      "orthogonal_weight": 0.1,
      "step": 4580,
      "total_loss": 0.5926053524017334,
      "weighted_orthogonal_loss": 0.020336857065558434
    },
    {
      "classification_loss": 0.6129381060600281,
      "epoch": 15.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20335659384727478,
      "orthogonal_weight": 0.1,
      "step": 4581,
      "total_loss": 0.6332737803459167,
      "weighted_orthogonal_loss": 0.020335659384727478
    },
    {
      "classification_loss": 0.5672736763954163,
      "epoch": 15.02295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033586949110031,
      "orthogonal_weight": 0.1,
      "step": 4582,
      "total_loss": 0.5876095294952393,
      "weighted_orthogonal_loss": 0.02033586986362934
    },
    {
      "classification_loss": 0.5918005108833313,
      "epoch": 15.026229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033264935016632,
      "orthogonal_weight": 0.1,
      "step": 4583,
      "total_loss": 0.6121331453323364,
      "weighted_orthogonal_loss": 0.02033264935016632
    },
    {
      "classification_loss": 0.6553739309310913,
      "epoch": 15.029508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033129334449768,
      "orthogonal_weight": 0.1,
      "step": 4584,
      "total_loss": 0.6757051944732666,
      "weighted_orthogonal_loss": 0.02033129334449768
    },
    {
      "classification_loss": 0.618338942527771,
      "epoch": 15.032786885245901,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329535007476807,
      "orthogonal_weight": 0.1,
      "step": 4585,
      "total_loss": 0.6386684775352478,
      "weighted_orthogonal_loss": 0.020329535007476807
    },
    {
      "classification_loss": 0.6103707551956177,
      "epoch": 15.036065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20327091217041016,
      "orthogonal_weight": 0.1,
      "step": 4586,
      "total_loss": 0.6306978464126587,
      "weighted_orthogonal_loss": 0.020327091217041016
    },
    {
      "classification_loss": 0.6216312646865845,
      "epoch": 15.039344262295081,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20327213406562805,
      "orthogonal_weight": 0.1,
      "step": 4587,
      "total_loss": 0.641958475112915,
      "weighted_orthogonal_loss": 0.020327214151620865
    },
    {
      "classification_loss": 0.5906224846839905,
      "epoch": 15.042622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20326249301433563,
      "orthogonal_weight": 0.1,
      "step": 4588,
      "total_loss": 0.6109487414360046,
      "weighted_orthogonal_loss": 0.020326249301433563
    },
    {
      "classification_loss": 0.6097358465194702,
      "epoch": 15.045901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20327086746692657,
      "orthogonal_weight": 0.1,
      "step": 4589,
      "total_loss": 0.6300629377365112,
      "weighted_orthogonal_loss": 0.020327087491750717
    },
    {
      "classification_loss": 0.6317344307899475,
      "epoch": 15.049180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20327454805374146,
      "orthogonal_weight": 0.1,
      "step": 4590,
      "total_loss": 0.6520618796348572,
      "weighted_orthogonal_loss": 0.020327454432845116
    },
    {
      "classification_loss": 0.7450631856918335,
      "epoch": 15.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329196751117706,
      "orthogonal_weight": 0.1,
      "step": 4591,
      "total_loss": 0.7653923630714417,
      "weighted_orthogonal_loss": 0.020329197868704796
    },
    {
      "classification_loss": 0.6370741128921509,
      "epoch": 15.055737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20328544080257416,
      "orthogonal_weight": 0.1,
      "step": 4592,
      "total_loss": 0.6574026346206665,
      "weighted_orthogonal_loss": 0.020328544080257416
    },
    {
      "classification_loss": 0.6204581260681152,
      "epoch": 15.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20325985550880432,
      "orthogonal_weight": 0.1,
      "step": 4593,
      "total_loss": 0.6407840847969055,
      "weighted_orthogonal_loss": 0.02032598666846752
    },
    {
      "classification_loss": 0.6305952072143555,
      "epoch": 15.062295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20326104760169983,
      "orthogonal_weight": 0.1,
      "step": 4594,
      "total_loss": 0.6509212851524353,
      "weighted_orthogonal_loss": 0.020326105877757072
    },
    {
      "classification_loss": 0.6253136396408081,
      "epoch": 15.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20325979590415955,
      "orthogonal_weight": 0.1,
      "step": 4595,
      "total_loss": 0.6456395983695984,
      "weighted_orthogonal_loss": 0.020325979217886925
    },
    {
      "classification_loss": 0.6767383813858032,
      "epoch": 15.068852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032759040594101,
      "orthogonal_weight": 0.1,
      "step": 4596,
      "total_loss": 0.6970659494400024,
      "weighted_orthogonal_loss": 0.02032759040594101
    },
    {
      "classification_loss": 0.6258871555328369,
      "epoch": 15.072131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329920947551727,
      "orthogonal_weight": 0.1,
      "step": 4597,
      "total_loss": 0.6462170481681824,
      "weighted_orthogonal_loss": 0.020329920575022697
    },
    {
      "classification_loss": 0.6044973731040955,
      "epoch": 15.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032899409532547,
      "orthogonal_weight": 0.1,
      "step": 4598,
      "total_loss": 0.6248263716697693,
      "weighted_orthogonal_loss": 0.02032899484038353
    },
    {
      "classification_loss": 0.6074065566062927,
      "epoch": 15.078688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20328350365161896,
      "orthogonal_weight": 0.1,
      "step": 4599,
      "total_loss": 0.627734899520874,
      "weighted_orthogonal_loss": 0.020328350365161896
    },
    {
      "epoch": 15.081967213114755,
      "grad_norm": 6.496823310852051,
      "learning_rate": 5.0033333333333334e-05,
      "loss": 0.6417,
      "step": 4600
    },
    {
      "classification_loss": 0.6685582399368286,
      "epoch": 15.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329776406288147,
      "orthogonal_weight": 0.1,
      "step": 4600,
      "total_loss": 0.6888880133628845,
      "weighted_orthogonal_loss": 0.020329777151346207
    },
    {
      "classification_loss": 0.651391863822937,
      "epoch": 15.085245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329539477825165,
      "orthogonal_weight": 0.1,
      "step": 4601,
      "total_loss": 0.6717213988304138,
      "weighted_orthogonal_loss": 0.020329540595412254
    },
    {
      "classification_loss": 0.5765361785888672,
      "epoch": 15.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20328456163406372,
      "orthogonal_weight": 0.1,
      "step": 4602,
      "total_loss": 0.596864640712738,
      "weighted_orthogonal_loss": 0.020328456535935402
    },
    {
      "classification_loss": 0.577515184879303,
      "epoch": 15.091803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20326730608940125,
      "orthogonal_weight": 0.1,
      "step": 4603,
      "total_loss": 0.5978419184684753,
      "weighted_orthogonal_loss": 0.020326731726527214
    },
    {
      "classification_loss": 0.6263288259506226,
      "epoch": 15.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20326454937458038,
      "orthogonal_weight": 0.1,
      "step": 4604,
      "total_loss": 0.646655261516571,
      "weighted_orthogonal_loss": 0.020326456055045128
    },
    {
      "classification_loss": 0.5999723672866821,
      "epoch": 15.098360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20324404537677765,
      "orthogonal_weight": 0.1,
      "step": 4605,
      "total_loss": 0.6202967762947083,
      "weighted_orthogonal_loss": 0.020324405282735825
    },
    {
      "classification_loss": 0.5847955346107483,
      "epoch": 15.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320628583431244,
      "orthogonal_weight": 0.1,
      "step": 4606,
      "total_loss": 0.6051161885261536,
      "weighted_orthogonal_loss": 0.020320629701018333
    },
    {
      "classification_loss": 0.6280797719955444,
      "epoch": 15.104918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20318372547626495,
      "orthogonal_weight": 0.1,
      "step": 4607,
      "total_loss": 0.6483981609344482,
      "weighted_orthogonal_loss": 0.020318372175097466
    },
    {
      "classification_loss": 0.6151465773582458,
      "epoch": 15.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203147754073143,
      "orthogonal_weight": 0.1,
      "step": 4608,
      "total_loss": 0.6354613304138184,
      "weighted_orthogonal_loss": 0.0203147754073143
    },
    {
      "classification_loss": 0.6168789863586426,
      "epoch": 15.111475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20309937000274658,
      "orthogonal_weight": 0.1,
      "step": 4609,
      "total_loss": 0.6371889114379883,
      "weighted_orthogonal_loss": 0.020309938117861748
    },
    {
      "classification_loss": 0.6588423252105713,
      "epoch": 15.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306101441383362,
      "orthogonal_weight": 0.1,
      "step": 4610,
      "total_loss": 0.6791484355926514,
      "weighted_orthogonal_loss": 0.020306101068854332
    },
    {
      "classification_loss": 0.671425461769104,
      "epoch": 15.118032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20303021371364594,
      "orthogonal_weight": 0.1,
      "step": 4611,
      "total_loss": 0.6917284727096558,
      "weighted_orthogonal_loss": 0.020303022116422653
    },
    {
      "classification_loss": 0.6428136229515076,
      "epoch": 15.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20299752056598663,
      "orthogonal_weight": 0.1,
      "step": 4612,
      "total_loss": 0.6631133556365967,
      "weighted_orthogonal_loss": 0.020299753174185753
    },
    {
      "classification_loss": 0.6362029910087585,
      "epoch": 15.124590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20294874906539917,
      "orthogonal_weight": 0.1,
      "step": 4613,
      "total_loss": 0.6564978361129761,
      "weighted_orthogonal_loss": 0.020294874906539917
    },
    {
      "classification_loss": 0.6312594413757324,
      "epoch": 15.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20287741720676422,
      "orthogonal_weight": 0.1,
      "step": 4614,
      "total_loss": 0.6515471935272217,
      "weighted_orthogonal_loss": 0.02028774283826351
    },
    {
      "classification_loss": 0.6082217693328857,
      "epoch": 15.131147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20279932022094727,
      "orthogonal_weight": 0.1,
      "step": 4615,
      "total_loss": 0.6285017132759094,
      "weighted_orthogonal_loss": 0.020279932767152786
    },
    {
      "classification_loss": 0.5815604329109192,
      "epoch": 15.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027413696050644,
      "orthogonal_weight": 0.1,
      "step": 4616,
      "total_loss": 0.6018345952033997,
      "weighted_orthogonal_loss": 0.02027413807809353
    },
    {
      "classification_loss": 0.6847863793373108,
      "epoch": 15.137704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2027221918106079,
      "orthogonal_weight": 0.1,
      "step": 4617,
      "total_loss": 0.7050585746765137,
      "weighted_orthogonal_loss": 0.02027221955358982
    },
    {
      "classification_loss": 0.5526756644248962,
      "epoch": 15.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2026827037334442,
      "orthogonal_weight": 0.1,
      "step": 4618,
      "total_loss": 0.572943925857544,
      "weighted_orthogonal_loss": 0.02026827074587345
    },
    {
      "classification_loss": 0.6186343431472778,
      "epoch": 15.144262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20265407860279083,
      "orthogonal_weight": 0.1,
      "step": 4619,
      "total_loss": 0.6388997435569763,
      "weighted_orthogonal_loss": 0.020265407860279083
    },
    {
      "classification_loss": 0.6228504180908203,
      "epoch": 15.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20262464880943298,
      "orthogonal_weight": 0.1,
      "step": 4620,
      "total_loss": 0.6431128978729248,
      "weighted_orthogonal_loss": 0.0202624648809433
    },
    {
      "classification_loss": 0.599790096282959,
      "epoch": 15.150819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20256109535694122,
      "orthogonal_weight": 0.1,
      "step": 4621,
      "total_loss": 0.6200461983680725,
      "weighted_orthogonal_loss": 0.020256109535694122
    },
    {
      "classification_loss": 0.663820207118988,
      "epoch": 15.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20252130925655365,
      "orthogonal_weight": 0.1,
      "step": 4622,
      "total_loss": 0.6840723156929016,
      "weighted_orthogonal_loss": 0.020252130925655365
    },
    {
      "classification_loss": 0.636667788028717,
      "epoch": 15.157377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023407220840454,
      "orthogonal_weight": 0.1,
      "step": 4623,
      "total_loss": 0.6569018363952637,
      "weighted_orthogonal_loss": 0.02023407258093357
    },
    {
      "classification_loss": 0.5685034394264221,
      "epoch": 15.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20217077434062958,
      "orthogonal_weight": 0.1,
      "step": 4624,
      "total_loss": 0.5887205004692078,
      "weighted_orthogonal_loss": 0.020217077806591988
    },
    {
      "classification_loss": 0.7050551772117615,
      "epoch": 15.163934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20202738046646118,
      "orthogonal_weight": 0.1,
      "step": 4625,
      "total_loss": 0.725257933139801,
      "weighted_orthogonal_loss": 0.020202739164233208
    },
    {
      "classification_loss": 0.6081130504608154,
      "epoch": 15.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20190145075321198,
      "orthogonal_weight": 0.1,
      "step": 4626,
      "total_loss": 0.6283031702041626,
      "weighted_orthogonal_loss": 0.020190145820379257
    },
    {
      "classification_loss": 0.6398654580116272,
      "epoch": 15.170491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20181305706501007,
      "orthogonal_weight": 0.1,
      "step": 4627,
      "total_loss": 0.6600467562675476,
      "weighted_orthogonal_loss": 0.020181305706501007
    },
    {
      "classification_loss": 0.5472655296325684,
      "epoch": 15.173770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2017509639263153,
      "orthogonal_weight": 0.1,
      "step": 4628,
      "total_loss": 0.5674406290054321,
      "weighted_orthogonal_loss": 0.02017509751021862
    },
    {
      "classification_loss": 0.5198599100112915,
      "epoch": 15.177049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.201711967587471,
      "orthogonal_weight": 0.1,
      "step": 4629,
      "total_loss": 0.5400311350822449,
      "weighted_orthogonal_loss": 0.02017119713127613
    },
    {
      "classification_loss": 0.5585311055183411,
      "epoch": 15.180327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20170260965824127,
      "orthogonal_weight": 0.1,
      "step": 4630,
      "total_loss": 0.578701376914978,
      "weighted_orthogonal_loss": 0.020170262083411217
    },
    {
      "classification_loss": 0.5769650340080261,
      "epoch": 15.183606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20170657336711884,
      "orthogonal_weight": 0.1,
      "step": 4631,
      "total_loss": 0.5971356630325317,
      "weighted_orthogonal_loss": 0.020170656964182854
    },
    {
      "classification_loss": 0.4995216429233551,
      "epoch": 15.186885245901639,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2016981691122055,
      "orthogonal_weight": 0.1,
      "step": 4632,
      "total_loss": 0.5196914672851562,
      "weighted_orthogonal_loss": 0.02016981691122055
    },
    {
      "classification_loss": 0.617399275302887,
      "epoch": 15.190163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20169910788536072,
      "orthogonal_weight": 0.1,
      "step": 4633,
      "total_loss": 0.6375691890716553,
      "weighted_orthogonal_loss": 0.02016991190612316
    },
    {
      "classification_loss": 0.6787473559379578,
      "epoch": 15.193442622950819,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20169857144355774,
      "orthogonal_weight": 0.1,
      "step": 4634,
      "total_loss": 0.6989172101020813,
      "weighted_orthogonal_loss": 0.020169857889413834
    },
    {
      "classification_loss": 0.5387837290763855,
      "epoch": 15.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2017475962638855,
      "orthogonal_weight": 0.1,
      "step": 4635,
      "total_loss": 0.5589584708213806,
      "weighted_orthogonal_loss": 0.02017476037144661
    },
    {
      "classification_loss": 0.5481470823287964,
      "epoch": 15.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20183192193508148,
      "orthogonal_weight": 0.1,
      "step": 4636,
      "total_loss": 0.5683302879333496,
      "weighted_orthogonal_loss": 0.020183192566037178
    },
    {
      "classification_loss": 0.5780046582221985,
      "epoch": 15.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20191088318824768,
      "orthogonal_weight": 0.1,
      "step": 4637,
      "total_loss": 0.5981957316398621,
      "weighted_orthogonal_loss": 0.020191088318824768
    },
    {
      "classification_loss": 0.6401774883270264,
      "epoch": 15.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20199744403362274,
      "orthogonal_weight": 0.1,
      "step": 4638,
      "total_loss": 0.6603772044181824,
      "weighted_orthogonal_loss": 0.020199744030833244
    },
    {
      "classification_loss": 0.541073739528656,
      "epoch": 15.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20209094882011414,
      "orthogonal_weight": 0.1,
      "step": 4639,
      "total_loss": 0.5612828135490417,
      "weighted_orthogonal_loss": 0.020209094509482384
    },
    {
      "classification_loss": 0.6250625848770142,
      "epoch": 15.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2021884173154831,
      "orthogonal_weight": 0.1,
      "step": 4640,
      "total_loss": 0.6452814340591431,
      "weighted_orthogonal_loss": 0.02021884173154831
    },
    {
      "classification_loss": 0.574636697769165,
      "epoch": 15.216393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20226748287677765,
      "orthogonal_weight": 0.1,
      "step": 4641,
      "total_loss": 0.5948634743690491,
      "weighted_orthogonal_loss": 0.020226748660206795
    },
    {
      "classification_loss": 0.6231802105903625,
      "epoch": 15.219672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20235948264598846,
      "orthogonal_weight": 0.1,
      "step": 4642,
      "total_loss": 0.643416166305542,
      "weighted_orthogonal_loss": 0.020235948264598846
    },
    {
      "classification_loss": 0.6086865663528442,
      "epoch": 15.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.202472984790802,
      "orthogonal_weight": 0.1,
      "step": 4643,
      "total_loss": 0.628933846950531,
      "weighted_orthogonal_loss": 0.02024729922413826
    },
    {
      "classification_loss": 0.735231876373291,
      "epoch": 15.226229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2025914192199707,
      "orthogonal_weight": 0.1,
      "step": 4644,
      "total_loss": 0.7554910182952881,
      "weighted_orthogonal_loss": 0.02025914192199707
    },
    {
      "classification_loss": 0.5387385487556458,
      "epoch": 15.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20267857611179352,
      "orthogonal_weight": 0.1,
      "step": 4645,
      "total_loss": 0.55900639295578,
      "weighted_orthogonal_loss": 0.020267857238650322
    },
    {
      "classification_loss": 0.6118512749671936,
      "epoch": 15.232786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20274686813354492,
      "orthogonal_weight": 0.1,
      "step": 4646,
      "total_loss": 0.632125973701477,
      "weighted_orthogonal_loss": 0.020274687558412552
    },
    {
      "classification_loss": 0.6061514019966125,
      "epoch": 15.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20281530916690826,
      "orthogonal_weight": 0.1,
      "step": 4647,
      "total_loss": 0.6264329552650452,
      "weighted_orthogonal_loss": 0.020281530916690826
    },
    {
      "classification_loss": 0.5993613004684448,
      "epoch": 15.239344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20285837352275848,
      "orthogonal_weight": 0.1,
      "step": 4648,
      "total_loss": 0.6196471452713013,
      "weighted_orthogonal_loss": 0.02028583735227585
    },
    {
      "classification_loss": 0.6379204988479614,
      "epoch": 15.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20290865004062653,
      "orthogonal_weight": 0.1,
      "step": 4649,
      "total_loss": 0.658211350440979,
      "weighted_orthogonal_loss": 0.020290864631533623
    },
    {
      "classification_loss": 0.5891872048377991,
      "epoch": 15.245901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029387503862381,
      "orthogonal_weight": 0.1,
      "step": 4650,
      "total_loss": 0.6094810962677002,
      "weighted_orthogonal_loss": 0.02029387466609478
    },
    {
      "classification_loss": 0.6341547966003418,
      "epoch": 15.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20295317471027374,
      "orthogonal_weight": 0.1,
      "step": 4651,
      "total_loss": 0.6544501185417175,
      "weighted_orthogonal_loss": 0.020295318216085434
    },
    {
      "classification_loss": 0.6633678674697876,
      "epoch": 15.252459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029164582490921,
      "orthogonal_weight": 0.1,
      "step": 4652,
      "total_loss": 0.6836594939231873,
      "weighted_orthogonal_loss": 0.0202916469424963
    },
    {
      "classification_loss": 0.5947168469429016,
      "epoch": 15.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028800994157791,
      "orthogonal_weight": 0.1,
      "step": 4653,
      "total_loss": 0.61500483751297,
      "weighted_orthogonal_loss": 0.020288011059165
    },
    {
      "classification_loss": 0.5868436098098755,
      "epoch": 15.259016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20284028351306915,
      "orthogonal_weight": 0.1,
      "step": 4654,
      "total_loss": 0.6071276664733887,
      "weighted_orthogonal_loss": 0.020284028723835945
    },
    {
      "classification_loss": 0.5420889854431152,
      "epoch": 15.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028178721666336,
      "orthogonal_weight": 0.1,
      "step": 4655,
      "total_loss": 0.562370777130127,
      "weighted_orthogonal_loss": 0.02028178796172142
    },
    {
      "classification_loss": 0.6477406620979309,
      "epoch": 15.265573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20281334221363068,
      "orthogonal_weight": 0.1,
      "step": 4656,
      "total_loss": 0.6680219769477844,
      "weighted_orthogonal_loss": 0.020281335338950157
    },
    {
      "classification_loss": 0.6183339357376099,
      "epoch": 15.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20268335938453674,
      "orthogonal_weight": 0.1,
      "step": 4657,
      "total_loss": 0.6386022567749023,
      "weighted_orthogonal_loss": 0.020268335938453674
    },
    {
      "classification_loss": 0.6091427206993103,
      "epoch": 15.272131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20257867872714996,
      "orthogonal_weight": 0.1,
      "step": 4658,
      "total_loss": 0.6294006109237671,
      "weighted_orthogonal_loss": 0.020257867872714996
    },
    {
      "classification_loss": 0.5678408741950989,
      "epoch": 15.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20247839391231537,
      "orthogonal_weight": 0.1,
      "step": 4659,
      "total_loss": 0.5880886912345886,
      "weighted_orthogonal_loss": 0.020247839391231537
    },
    {
      "classification_loss": 0.6630898118019104,
      "epoch": 15.278688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20240630209445953,
      "orthogonal_weight": 0.1,
      "step": 4660,
      "total_loss": 0.6833304166793823,
      "weighted_orthogonal_loss": 0.020240630954504013
    },
    {
      "classification_loss": 0.5981878638267517,
      "epoch": 15.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023659199476242,
      "orthogonal_weight": 0.1,
      "step": 4661,
      "total_loss": 0.6184244751930237,
      "weighted_orthogonal_loss": 0.02023659273982048
    },
    {
      "classification_loss": 0.6854277849197388,
      "epoch": 15.285245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023475617170334,
      "orthogonal_weight": 0.1,
      "step": 4662,
      "total_loss": 0.7056625485420227,
      "weighted_orthogonal_loss": 0.02023475617170334
    },
    {
      "classification_loss": 0.6496167778968811,
      "epoch": 15.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20220819115638733,
      "orthogonal_weight": 0.1,
      "step": 4663,
      "total_loss": 0.6698375940322876,
      "weighted_orthogonal_loss": 0.020220819860696793
    },
    {
      "classification_loss": 0.5633982419967651,
      "epoch": 15.291803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20208242535591125,
      "orthogonal_weight": 0.1,
      "step": 4664,
      "total_loss": 0.583606481552124,
      "weighted_orthogonal_loss": 0.020208243280649185
    },
    {
      "classification_loss": 0.6342743039131165,
      "epoch": 15.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2018692046403885,
      "orthogonal_weight": 0.1,
      "step": 4665,
      "total_loss": 0.6544612050056458,
      "weighted_orthogonal_loss": 0.02018692158162594
    },
    {
      "classification_loss": 0.5691114068031311,
      "epoch": 15.298360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2016850709915161,
      "orthogonal_weight": 0.1,
      "step": 4666,
      "total_loss": 0.5892798900604248,
      "weighted_orthogonal_loss": 0.02016850747168064
    },
    {
      "classification_loss": 0.593811571598053,
      "epoch": 15.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20150145888328552,
      "orthogonal_weight": 0.1,
      "step": 4667,
      "total_loss": 0.6139616966247559,
      "weighted_orthogonal_loss": 0.020150145515799522
    },
    {
      "classification_loss": 0.6896977424621582,
      "epoch": 15.304918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20133791863918304,
      "orthogonal_weight": 0.1,
      "step": 4668,
      "total_loss": 0.7098315358161926,
      "weighted_orthogonal_loss": 0.020133791491389275
    },
    {
      "classification_loss": 0.6436819434165955,
      "epoch": 15.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2011750340461731,
      "orthogonal_weight": 0.1,
      "step": 4669,
      "total_loss": 0.6637994647026062,
      "weighted_orthogonal_loss": 0.0201175045222044
    },
    {
      "classification_loss": 0.657855749130249,
      "epoch": 15.311475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20103642344474792,
      "orthogonal_weight": 0.1,
      "step": 4670,
      "total_loss": 0.6779593825340271,
      "weighted_orthogonal_loss": 0.020103642717003822
    },
    {
      "classification_loss": 0.49981749057769775,
      "epoch": 15.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20090915262699127,
      "orthogonal_weight": 0.1,
      "step": 4671,
      "total_loss": 0.5199084281921387,
      "weighted_orthogonal_loss": 0.020090915262699127
    },
    {
      "classification_loss": 0.6918861269950867,
      "epoch": 15.318032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20081612467765808,
      "orthogonal_weight": 0.1,
      "step": 4672,
      "total_loss": 0.7119677662849426,
      "weighted_orthogonal_loss": 0.020081613212823868
    },
    {
      "classification_loss": 0.5380501747131348,
      "epoch": 15.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20073355734348297,
      "orthogonal_weight": 0.1,
      "step": 4673,
      "total_loss": 0.5581235289573669,
      "weighted_orthogonal_loss": 0.020073356106877327
    },
    {
      "classification_loss": 0.684005618095398,
      "epoch": 15.324590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20082736015319824,
      "orthogonal_weight": 0.1,
      "step": 4674,
      "total_loss": 0.7040883302688599,
      "weighted_orthogonal_loss": 0.020082736387848854
    },
    {
      "classification_loss": 0.596020519733429,
      "epoch": 15.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20092518627643585,
      "orthogonal_weight": 0.1,
      "step": 4675,
      "total_loss": 0.6161130666732788,
      "weighted_orthogonal_loss": 0.020092519000172615
    },
    {
      "classification_loss": 0.565126359462738,
      "epoch": 15.331147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20102843642234802,
      "orthogonal_weight": 0.1,
      "step": 4676,
      "total_loss": 0.585229218006134,
      "weighted_orthogonal_loss": 0.020102843642234802
    },
    {
      "classification_loss": 0.6330623030662537,
      "epoch": 15.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20114371180534363,
      "orthogonal_weight": 0.1,
      "step": 4677,
      "total_loss": 0.6531766653060913,
      "weighted_orthogonal_loss": 0.020114371553063393
    },
    {
      "classification_loss": 0.6599088907241821,
      "epoch": 15.337704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20128530263900757,
      "orthogonal_weight": 0.1,
      "step": 4678,
      "total_loss": 0.6800374388694763,
      "weighted_orthogonal_loss": 0.020128531381487846
    },
    {
      "classification_loss": 0.6546540856361389,
      "epoch": 15.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20142237842082977,
      "orthogonal_weight": 0.1,
      "step": 4679,
      "total_loss": 0.6747963428497314,
      "weighted_orthogonal_loss": 0.020142238587141037
    },
    {
      "classification_loss": 0.5684629678726196,
      "epoch": 15.344262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20155666768550873,
      "orthogonal_weight": 0.1,
      "step": 4680,
      "total_loss": 0.5886186361312866,
      "weighted_orthogonal_loss": 0.020155666396021843
    },
    {
      "classification_loss": 0.613442599773407,
      "epoch": 15.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20168562233448029,
      "orthogonal_weight": 0.1,
      "step": 4681,
      "total_loss": 0.6336111426353455,
      "weighted_orthogonal_loss": 0.020168563351035118
    },
    {
      "classification_loss": 0.7283455729484558,
      "epoch": 15.350819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20182165503501892,
      "orthogonal_weight": 0.1,
      "step": 4682,
      "total_loss": 0.7485277652740479,
      "weighted_orthogonal_loss": 0.020182166248559952
    },
    {
      "classification_loss": 0.6693521738052368,
      "epoch": 15.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20191408693790436,
      "orthogonal_weight": 0.1,
      "step": 4683,
      "total_loss": 0.689543604850769,
      "weighted_orthogonal_loss": 0.020191408693790436
    },
    {
      "classification_loss": 0.6572818756103516,
      "epoch": 15.357377049180329,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2020333856344223,
      "orthogonal_weight": 0.1,
      "step": 4684,
      "total_loss": 0.6774852275848389,
      "weighted_orthogonal_loss": 0.02020333893597126
    },
    {
      "classification_loss": 0.6659321188926697,
      "epoch": 15.360655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20214328169822693,
      "orthogonal_weight": 0.1,
      "step": 4685,
      "total_loss": 0.6861464381217957,
      "weighted_orthogonal_loss": 0.020214328542351723
    },
    {
      "classification_loss": 0.606568455696106,
      "epoch": 15.363934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2022751271724701,
      "orthogonal_weight": 0.1,
      "step": 4686,
      "total_loss": 0.6267959475517273,
      "weighted_orthogonal_loss": 0.02022751234471798
    },
    {
      "classification_loss": 0.6270858645439148,
      "epoch": 15.3672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2023671418428421,
      "orthogonal_weight": 0.1,
      "step": 4687,
      "total_loss": 0.6473225951194763,
      "weighted_orthogonal_loss": 0.02023671381175518
    },
    {
      "classification_loss": 0.6528308987617493,
      "epoch": 15.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20246730744838715,
      "orthogonal_weight": 0.1,
      "step": 4688,
      "total_loss": 0.6730776429176331,
      "weighted_orthogonal_loss": 0.020246731117367744
    },
    {
      "classification_loss": 0.6451116800308228,
      "epoch": 15.37377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20255692303180695,
      "orthogonal_weight": 0.1,
      "step": 4689,
      "total_loss": 0.6653673648834229,
      "weighted_orthogonal_loss": 0.020255692303180695
    },
    {
      "classification_loss": 0.7267354726791382,
      "epoch": 15.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20264704525470734,
      "orthogonal_weight": 0.1,
      "step": 4690,
      "total_loss": 0.7470001578330994,
      "weighted_orthogonal_loss": 0.020264705643057823
    },
    {
      "classification_loss": 0.6456493139266968,
      "epoch": 15.38032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20274077355861664,
      "orthogonal_weight": 0.1,
      "step": 4691,
      "total_loss": 0.6659234166145325,
      "weighted_orthogonal_loss": 0.020274078473448753
    },
    {
      "classification_loss": 0.6612439155578613,
      "epoch": 15.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2028283029794693,
      "orthogonal_weight": 0.1,
      "step": 4692,
      "total_loss": 0.6815267205238342,
      "weighted_orthogonal_loss": 0.02028283104300499
    },
    {
      "classification_loss": 0.6168637871742249,
      "epoch": 15.38688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20289106667041779,
      "orthogonal_weight": 0.1,
      "step": 4693,
      "total_loss": 0.637152910232544,
      "weighted_orthogonal_loss": 0.02028910629451275
    },
    {
      "classification_loss": 0.6355090737342834,
      "epoch": 15.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2029334008693695,
      "orthogonal_weight": 0.1,
      "step": 4694,
      "total_loss": 0.6558024287223816,
      "weighted_orthogonal_loss": 0.02029334008693695
    },
    {
      "classification_loss": 0.6419410705566406,
      "epoch": 15.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20300111174583435,
      "orthogonal_weight": 0.1,
      "step": 4695,
      "total_loss": 0.6622411608695984,
      "weighted_orthogonal_loss": 0.020300110802054405
    },
    {
      "classification_loss": 0.6031572222709656,
      "epoch": 15.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2030550092458725,
      "orthogonal_weight": 0.1,
      "step": 4696,
      "total_loss": 0.6234627366065979,
      "weighted_orthogonal_loss": 0.02030550129711628
    },
    {
      "classification_loss": 0.7046334743499756,
      "epoch": 15.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20306530594825745,
      "orthogonal_weight": 0.1,
      "step": 4697,
      "total_loss": 0.7249400019645691,
      "weighted_orthogonal_loss": 0.020306531339883804
    },
    {
      "classification_loss": 0.5949099659919739,
      "epoch": 15.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20308466255664825,
      "orthogonal_weight": 0.1,
      "step": 4698,
      "total_loss": 0.615218460559845,
      "weighted_orthogonal_loss": 0.020308466628193855
    },
    {
      "classification_loss": 0.6113404035568237,
      "epoch": 15.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20311763882637024,
      "orthogonal_weight": 0.1,
      "step": 4699,
      "total_loss": 0.6316521763801575,
      "weighted_orthogonal_loss": 0.020311763510107994
    },
    {
      "epoch": 15.40983606557377,
      "grad_norm": 19.984939575195312,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 0.6391,
      "step": 4700
    },
    {
      "classification_loss": 0.6410505771636963,
      "epoch": 15.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2031552642583847,
      "orthogonal_weight": 0.1,
      "step": 4700,
      "total_loss": 0.6613661050796509,
      "weighted_orthogonal_loss": 0.02031552605330944
    },
    {
      "classification_loss": 0.6140931248664856,
      "epoch": 15.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20320014655590057,
      "orthogonal_weight": 0.1,
      "step": 4701,
      "total_loss": 0.6344131231307983,
      "weighted_orthogonal_loss": 0.020320015028119087
    },
    {
      "classification_loss": 0.5691627264022827,
      "epoch": 15.416393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032390981912613,
      "orthogonal_weight": 0.1,
      "step": 4702,
      "total_loss": 0.5894866585731506,
      "weighted_orthogonal_loss": 0.02032390981912613
    },
    {
      "classification_loss": 0.6503623127937317,
      "epoch": 15.419672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032615691423416,
      "orthogonal_weight": 0.1,
      "step": 4703,
      "total_loss": 0.6706884503364563,
      "weighted_orthogonal_loss": 0.02032615803182125
    },
    {
      "classification_loss": 0.5883714556694031,
      "epoch": 15.422950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033190280199051,
      "orthogonal_weight": 0.1,
      "step": 4704,
      "total_loss": 0.6087033748626709,
      "weighted_orthogonal_loss": 0.02033190242946148
    },
    {
      "classification_loss": 0.5464611053466797,
      "epoch": 15.426229508196721,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033728063106537,
      "orthogonal_weight": 0.1,
      "step": 4705,
      "total_loss": 0.5667983889579773,
      "weighted_orthogonal_loss": 0.020337281748652458
    },
    {
      "classification_loss": 0.5720607042312622,
      "epoch": 15.429508196721311,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20339852571487427,
      "orthogonal_weight": 0.1,
      "step": 4706,
      "total_loss": 0.5924005508422852,
      "weighted_orthogonal_loss": 0.020339852198958397
    },
    {
      "classification_loss": 0.6765906810760498,
      "epoch": 15.432786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20341193675994873,
      "orthogonal_weight": 0.1,
      "step": 4707,
      "total_loss": 0.6969318985939026,
      "weighted_orthogonal_loss": 0.020341193303465843
    },
    {
      "classification_loss": 0.5936906933784485,
      "epoch": 15.436065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034088373184204,
      "orthogonal_weight": 0.1,
      "step": 4708,
      "total_loss": 0.6140315532684326,
      "weighted_orthogonal_loss": 0.02034088410437107
    },
    {
      "classification_loss": 0.5970738530158997,
      "epoch": 15.439344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203426793217659,
      "orthogonal_weight": 0.1,
      "step": 4709,
      "total_loss": 0.6174165606498718,
      "weighted_orthogonal_loss": 0.02034267969429493
    },
    {
      "classification_loss": 0.572896420955658,
      "epoch": 15.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20349065959453583,
      "orthogonal_weight": 0.1,
      "step": 4710,
      "total_loss": 0.5932455062866211,
      "weighted_orthogonal_loss": 0.020349066704511642
    },
    {
      "classification_loss": 0.5907500982284546,
      "epoch": 15.445901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2035551220178604,
      "orthogonal_weight": 0.1,
      "step": 4711,
      "total_loss": 0.6111056208610535,
      "weighted_orthogonal_loss": 0.02035551331937313
    },
    {
      "classification_loss": 0.5813530087471008,
      "epoch": 15.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20359084010124207,
      "orthogonal_weight": 0.1,
      "step": 4712,
      "total_loss": 0.6017121076583862,
      "weighted_orthogonal_loss": 0.020359084010124207
    },
    {
      "classification_loss": 0.5857252478599548,
      "epoch": 15.452459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20365336537361145,
      "orthogonal_weight": 0.1,
      "step": 4713,
      "total_loss": 0.6060906052589417,
      "weighted_orthogonal_loss": 0.020365336909890175
    },
    {
      "classification_loss": 0.6234972476959229,
      "epoch": 15.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20370669662952423,
      "orthogonal_weight": 0.1,
      "step": 4714,
      "total_loss": 0.6438679099082947,
      "weighted_orthogonal_loss": 0.020370669662952423
    },
    {
      "classification_loss": 0.6621344685554504,
      "epoch": 15.459016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20373980700969696,
      "orthogonal_weight": 0.1,
      "step": 4715,
      "total_loss": 0.6825084686279297,
      "weighted_orthogonal_loss": 0.020373981446027756
    },
    {
      "classification_loss": 0.5734274387359619,
      "epoch": 15.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20378199219703674,
      "orthogonal_weight": 0.1,
      "step": 4716,
      "total_loss": 0.5938056111335754,
      "weighted_orthogonal_loss": 0.020378200337290764
    },
    {
      "classification_loss": 0.6045415997505188,
      "epoch": 15.465573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20383453369140625,
      "orthogonal_weight": 0.1,
      "step": 4717,
      "total_loss": 0.6249250769615173,
      "weighted_orthogonal_loss": 0.020383452996611595
    },
    {
      "classification_loss": 0.601153552532196,
      "epoch": 15.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2037344127893448,
      "orthogonal_weight": 0.1,
      "step": 4718,
      "total_loss": 0.6215270161628723,
      "weighted_orthogonal_loss": 0.02037344127893448
    },
    {
      "classification_loss": 0.6630151271820068,
      "epoch": 15.472131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20363588631153107,
      "orthogonal_weight": 0.1,
      "step": 4719,
      "total_loss": 0.6833786964416504,
      "weighted_orthogonal_loss": 0.020363589748740196
    },
    {
      "classification_loss": 0.6179310083389282,
      "epoch": 15.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20352549850940704,
      "orthogonal_weight": 0.1,
      "step": 4720,
      "total_loss": 0.6382835507392883,
      "weighted_orthogonal_loss": 0.020352549850940704
    },
    {
      "classification_loss": 0.6226621866226196,
      "epoch": 15.478688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034299075603485,
      "orthogonal_weight": 0.1,
      "step": 4721,
      "total_loss": 0.6430051922798157,
      "weighted_orthogonal_loss": 0.02034299075603485
    },
    {
      "classification_loss": 0.6862261891365051,
      "epoch": 15.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20333760976791382,
      "orthogonal_weight": 0.1,
      "step": 4722,
      "total_loss": 0.706559956073761,
      "weighted_orthogonal_loss": 0.02033376134932041
    },
    {
      "classification_loss": 0.6577069163322449,
      "epoch": 15.485245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329242944717407,
      "orthogonal_weight": 0.1,
      "step": 4723,
      "total_loss": 0.6780361533164978,
      "weighted_orthogonal_loss": 0.020329242572188377
    },
    {
      "classification_loss": 0.5262006521224976,
      "epoch": 15.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032564878463745,
      "orthogonal_weight": 0.1,
      "step": 4724,
      "total_loss": 0.546526312828064,
      "weighted_orthogonal_loss": 0.02032564952969551
    },
    {
      "classification_loss": 0.5712006688117981,
      "epoch": 15.491803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.203226700425148,
      "orthogonal_weight": 0.1,
      "step": 4725,
      "total_loss": 0.5915233492851257,
      "weighted_orthogonal_loss": 0.02032267116010189
    },
    {
      "classification_loss": 0.527863085269928,
      "epoch": 15.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20322513580322266,
      "orthogonal_weight": 0.1,
      "step": 4726,
      "total_loss": 0.5481855869293213,
      "weighted_orthogonal_loss": 0.020322514697909355
    },
    {
      "classification_loss": 0.6869407892227173,
      "epoch": 15.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032431662082672,
      "orthogonal_weight": 0.1,
      "step": 4727,
      "total_loss": 0.7072650790214539,
      "weighted_orthogonal_loss": 0.02032431773841381
    },
    {
      "classification_loss": 0.6309688091278076,
      "epoch": 15.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2032553255558014,
      "orthogonal_weight": 0.1,
      "step": 4728,
      "total_loss": 0.6512943506240845,
      "weighted_orthogonal_loss": 0.02032553218305111
    },
    {
      "classification_loss": 0.556119978427887,
      "epoch": 15.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20329764485359192,
      "orthogonal_weight": 0.1,
      "step": 4729,
      "total_loss": 0.5764497518539429,
      "weighted_orthogonal_loss": 0.020329764112830162
    },
    {
      "classification_loss": 0.6617765426635742,
      "epoch": 15.508196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2033872902393341,
      "orthogonal_weight": 0.1,
      "step": 4730,
      "total_loss": 0.6821152567863464,
      "weighted_orthogonal_loss": 0.02033872902393341
    },
    {
      "classification_loss": 0.6465812921524048,
      "epoch": 15.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2034774273633957,
      "orthogonal_weight": 0.1,
      "step": 4731,
      "total_loss": 0.6669290065765381,
      "weighted_orthogonal_loss": 0.02034774236381054
    },
    {
      "classification_loss": 0.7269420027732849,
      "epoch": 15.514754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2035812884569168,
      "orthogonal_weight": 0.1,
      "step": 4732,
      "total_loss": 0.7473001480102539,
      "weighted_orthogonal_loss": 0.02035812847316265
    },
    {
      "classification_loss": 0.6673457026481628,
      "epoch": 15.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20368950068950653,
      "orthogonal_weight": 0.1,
      "step": 4733,
      "total_loss": 0.6877146363258362,
      "weighted_orthogonal_loss": 0.020368950441479683
    },
    {
      "classification_loss": 0.593234121799469,
      "epoch": 15.521311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20378239452838898,
      "orthogonal_weight": 0.1,
      "step": 4734,
      "total_loss": 0.6136123538017273,
      "weighted_orthogonal_loss": 0.020378239452838898
    },
    {
      "classification_loss": 0.6124717593193054,
      "epoch": 15.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20392252504825592,
      "orthogonal_weight": 0.1,
      "step": 4735,
      "total_loss": 0.6328639984130859,
      "weighted_orthogonal_loss": 0.020392252132296562
    },
    {
      "classification_loss": 0.6055597066879272,
      "epoch": 15.527868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20411139726638794,
      "orthogonal_weight": 0.1,
      "step": 4736,
      "total_loss": 0.6259708404541016,
      "weighted_orthogonal_loss": 0.020411139354109764
    },
    {
      "classification_loss": 0.6087183952331543,
      "epoch": 15.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2042616456747055,
      "orthogonal_weight": 0.1,
      "step": 4737,
      "total_loss": 0.629144549369812,
      "weighted_orthogonal_loss": 0.02042616531252861
    },
    {
      "classification_loss": 0.5754982233047485,
      "epoch": 15.534426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2044127732515335,
      "orthogonal_weight": 0.1,
      "step": 4738,
      "total_loss": 0.5959395170211792,
      "weighted_orthogonal_loss": 0.02044127695262432
    },
    {
      "classification_loss": 0.6031385064125061,
      "epoch": 15.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20455403625965118,
      "orthogonal_weight": 0.1,
      "step": 4739,
      "total_loss": 0.6235939264297485,
      "weighted_orthogonal_loss": 0.02045540325343609
    },
    {
      "classification_loss": 0.5987440347671509,
      "epoch": 15.540983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20468786358833313,
      "orthogonal_weight": 0.1,
      "step": 4740,
      "total_loss": 0.619212806224823,
      "weighted_orthogonal_loss": 0.020468786358833313
    },
    {
      "classification_loss": 0.5633459687232971,
      "epoch": 15.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20481346547603607,
      "orthogonal_weight": 0.1,
      "step": 4741,
      "total_loss": 0.5838273167610168,
      "weighted_orthogonal_loss": 0.020481346175074577
    },
    {
      "classification_loss": 0.5591936111450195,
      "epoch": 15.547540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20492634177207947,
      "orthogonal_weight": 0.1,
      "step": 4742,
      "total_loss": 0.5796862244606018,
      "weighted_orthogonal_loss": 0.020492633804678917
    },
    {
      "classification_loss": 0.5878321528434753,
      "epoch": 15.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20504112541675568,
      "orthogonal_weight": 0.1,
      "step": 4743,
      "total_loss": 0.6083362698554993,
      "weighted_orthogonal_loss": 0.020504113286733627
    },
    {
      "classification_loss": 0.6521825790405273,
      "epoch": 15.554098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20514366030693054,
      "orthogonal_weight": 0.1,
      "step": 4744,
      "total_loss": 0.6726969480514526,
      "weighted_orthogonal_loss": 0.020514367148280144
    },
    {
      "classification_loss": 0.5499147772789001,
      "epoch": 15.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20524360239505768,
      "orthogonal_weight": 0.1,
      "step": 4745,
      "total_loss": 0.5704391598701477,
      "weighted_orthogonal_loss": 0.020524360239505768
    },
    {
      "classification_loss": 0.6445589065551758,
      "epoch": 15.560655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205328106880188,
      "orthogonal_weight": 0.1,
      "step": 4746,
      "total_loss": 0.6650916934013367,
      "weighted_orthogonal_loss": 0.02053281106054783
    },
    {
      "classification_loss": 0.6375184655189514,
      "epoch": 15.563934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20542103052139282,
      "orthogonal_weight": 0.1,
      "step": 4747,
      "total_loss": 0.6580605506896973,
      "weighted_orthogonal_loss": 0.020542103797197342
    },
    {
      "classification_loss": 0.6300756931304932,
      "epoch": 15.567213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20546218752861023,
      "orthogonal_weight": 0.1,
      "step": 4748,
      "total_loss": 0.6506218910217285,
      "weighted_orthogonal_loss": 0.020546218380331993
    },
    {
      "classification_loss": 0.6245477795600891,
      "epoch": 15.570491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055225968360901,
      "orthogonal_weight": 0.1,
      "step": 4749,
      "total_loss": 0.6451000571250916,
      "weighted_orthogonal_loss": 0.0205522608011961
    },
    {
      "classification_loss": 0.5761752724647522,
      "epoch": 15.573770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055305391550064,
      "orthogonal_weight": 0.1,
      "step": 4750,
      "total_loss": 0.5967283248901367,
      "weighted_orthogonal_loss": 0.02055305428802967
    },
    {
      "classification_loss": 0.7123479843139648,
      "epoch": 15.577049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20551782846450806,
      "orthogonal_weight": 0.1,
      "step": 4751,
      "total_loss": 0.7328997850418091,
      "weighted_orthogonal_loss": 0.020551783964037895
    },
    {
      "classification_loss": 0.5852165818214417,
      "epoch": 15.580327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20551219582557678,
      "orthogonal_weight": 0.1,
      "step": 4752,
      "total_loss": 0.6057677865028381,
      "weighted_orthogonal_loss": 0.020551219582557678
    },
    {
      "classification_loss": 0.5941603779792786,
      "epoch": 15.583606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055298537015915,
      "orthogonal_weight": 0.1,
      "step": 4753,
      "total_loss": 0.6147133708000183,
      "weighted_orthogonal_loss": 0.02055298537015915
    },
    {
      "classification_loss": 0.5938237905502319,
      "epoch": 15.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2055676430463791,
      "orthogonal_weight": 0.1,
      "step": 4754,
      "total_loss": 0.6143805384635925,
      "weighted_orthogonal_loss": 0.02055676467716694
    },
    {
      "classification_loss": 0.6594951152801514,
      "epoch": 15.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20562376081943512,
      "orthogonal_weight": 0.1,
      "step": 4755,
      "total_loss": 0.6800574660301208,
      "weighted_orthogonal_loss": 0.02056237682700157
    },
    {
      "classification_loss": 0.542034387588501,
      "epoch": 15.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569811761379242,
      "orthogonal_weight": 0.1,
      "step": 4756,
      "total_loss": 0.5626041889190674,
      "weighted_orthogonal_loss": 0.0205698125064373
    },
    {
      "classification_loss": 0.5615671277046204,
      "epoch": 15.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20577357709407806,
      "orthogonal_weight": 0.1,
      "step": 4757,
      "total_loss": 0.5821444988250732,
      "weighted_orthogonal_loss": 0.020577358081936836
    },
    {
      "classification_loss": 0.610275149345398,
      "epoch": 15.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205823615193367,
      "orthogonal_weight": 0.1,
      "step": 4758,
      "total_loss": 0.630857527256012,
      "weighted_orthogonal_loss": 0.02058236114680767
    },
    {
      "classification_loss": 0.5973538160324097,
      "epoch": 15.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20582066476345062,
      "orthogonal_weight": 0.1,
      "step": 4759,
      "total_loss": 0.6179358959197998,
      "weighted_orthogonal_loss": 0.020582066848874092
    },
    {
      "classification_loss": 0.6253830194473267,
      "epoch": 15.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2057698518037796,
      "orthogonal_weight": 0.1,
      "step": 4760,
      "total_loss": 0.6459600329399109,
      "weighted_orthogonal_loss": 0.02057698555290699
    },
    {
      "classification_loss": 0.5998661518096924,
      "epoch": 15.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20573574304580688,
      "orthogonal_weight": 0.1,
      "step": 4761,
      "total_loss": 0.6204397082328796,
      "weighted_orthogonal_loss": 0.020573575049638748
    },
    {
      "classification_loss": 0.6487712264060974,
      "epoch": 15.61311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20572659373283386,
      "orthogonal_weight": 0.1,
      "step": 4762,
      "total_loss": 0.669343888759613,
      "weighted_orthogonal_loss": 0.020572660490870476
    },
    {
      "classification_loss": 0.6460140347480774,
      "epoch": 15.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20571967959403992,
      "orthogonal_weight": 0.1,
      "step": 4763,
      "total_loss": 0.6665859818458557,
      "weighted_orthogonal_loss": 0.020571967586874962
    },
    {
      "classification_loss": 0.5827794671058655,
      "epoch": 15.61967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569990575313568,
      "orthogonal_weight": 0.1,
      "step": 4764,
      "total_loss": 0.6033494472503662,
      "weighted_orthogonal_loss": 0.020569991320371628
    },
    {
      "classification_loss": 0.5670647025108337,
      "epoch": 15.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20569927990436554,
      "orthogonal_weight": 0.1,
      "step": 4765,
      "total_loss": 0.5876346230506897,
      "weighted_orthogonal_loss": 0.020569927990436554
    },
    {
      "classification_loss": 0.6074469089508057,
      "epoch": 15.62622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2057104855775833,
      "orthogonal_weight": 0.1,
      "step": 4766,
      "total_loss": 0.6280179619789124,
      "weighted_orthogonal_loss": 0.02057104930281639
    },
    {
      "classification_loss": 0.5882232189178467,
      "epoch": 15.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20567838847637177,
      "orthogonal_weight": 0.1,
      "step": 4767,
      "total_loss": 0.6087910532951355,
      "weighted_orthogonal_loss": 0.020567839965224266
    },
    {
      "classification_loss": 0.6059304475784302,
      "epoch": 15.6327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20562414824962616,
      "orthogonal_weight": 0.1,
      "step": 4768,
      "total_loss": 0.6264928579330444,
      "weighted_orthogonal_loss": 0.020562415942549706
    },
    {
      "classification_loss": 0.6116783022880554,
      "epoch": 15.636065573770491,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20555751025676727,
      "orthogonal_weight": 0.1,
      "step": 4769,
      "total_loss": 0.6322340369224548,
      "weighted_orthogonal_loss": 0.020555751398205757
    },
    {
      "classification_loss": 0.6161084771156311,
      "epoch": 15.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20552022755146027,
      "orthogonal_weight": 0.1,
      "step": 4770,
      "total_loss": 0.6366605162620544,
      "weighted_orthogonal_loss": 0.020552022382616997
    },
    {
      "classification_loss": 0.7054666876792908,
      "epoch": 15.642622950819671,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20547164976596832,
      "orthogonal_weight": 0.1,
      "step": 4771,
      "total_loss": 0.7260138392448425,
      "weighted_orthogonal_loss": 0.020547164604067802
    },
    {
      "classification_loss": 0.6906742453575134,
      "epoch": 15.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2054167091846466,
      "orthogonal_weight": 0.1,
      "step": 4772,
      "total_loss": 0.7112159132957458,
      "weighted_orthogonal_loss": 0.02054167166352272
    },
    {
      "classification_loss": 0.6320399045944214,
      "epoch": 15.649180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2053470015525818,
      "orthogonal_weight": 0.1,
      "step": 4773,
      "total_loss": 0.6525745987892151,
      "weighted_orthogonal_loss": 0.02053469978272915
    },
    {
      "classification_loss": 0.5945989489555359,
      "epoch": 15.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052663266658783,
      "orthogonal_weight": 0.1,
      "step": 4774,
      "total_loss": 0.6151255965232849,
      "weighted_orthogonal_loss": 0.02052663266658783
    },
    {
      "classification_loss": 0.6466554403305054,
      "epoch": 15.655737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20517835021018982,
      "orthogonal_weight": 0.1,
      "step": 4775,
      "total_loss": 0.6671732664108276,
      "weighted_orthogonal_loss": 0.020517835393548012
    },
    {
      "classification_loss": 0.642078697681427,
      "epoch": 15.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20508350431919098,
      "orthogonal_weight": 0.1,
      "step": 4776,
      "total_loss": 0.66258704662323,
      "weighted_orthogonal_loss": 0.020508350804448128
    },
    {
      "classification_loss": 0.5556818246841431,
      "epoch": 15.662295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20499499142169952,
      "orthogonal_weight": 0.1,
      "step": 4777,
      "total_loss": 0.5761813521385193,
      "weighted_orthogonal_loss": 0.020499499514698982
    },
    {
      "classification_loss": 0.644054114818573,
      "epoch": 15.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20501680672168732,
      "orthogonal_weight": 0.1,
      "step": 4778,
      "total_loss": 0.6645557880401611,
      "weighted_orthogonal_loss": 0.02050168067216873
    },
    {
      "classification_loss": 0.5748377442359924,
      "epoch": 15.668852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20505361258983612,
      "orthogonal_weight": 0.1,
      "step": 4779,
      "total_loss": 0.5953431129455566,
      "weighted_orthogonal_loss": 0.020505361258983612
    },
    {
      "classification_loss": 0.6025064587593079,
      "epoch": 15.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20515908300876617,
      "orthogonal_weight": 0.1,
      "step": 4780,
      "total_loss": 0.6230223774909973,
      "weighted_orthogonal_loss": 0.020515909418463707
    },
    {
      "classification_loss": 0.55361407995224,
      "epoch": 15.675409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2052401751279831,
      "orthogonal_weight": 0.1,
      "step": 4781,
      "total_loss": 0.5741381049156189,
      "weighted_orthogonal_loss": 0.02052401751279831
    },
    {
      "classification_loss": 0.5895295739173889,
      "epoch": 15.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20531244575977325,
      "orthogonal_weight": 0.1,
      "step": 4782,
      "total_loss": 0.6100608110427856,
      "weighted_orthogonal_loss": 0.020531244575977325
    },
    {
      "classification_loss": 0.6579264402389526,
      "epoch": 15.681967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20536109805107117,
      "orthogonal_weight": 0.1,
      "step": 4783,
      "total_loss": 0.678462564945221,
      "weighted_orthogonal_loss": 0.020536109805107117
    },
    {
      "classification_loss": 0.5847840309143066,
      "epoch": 15.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.205426886677742,
      "orthogonal_weight": 0.1,
      "step": 4784,
      "total_loss": 0.6053267121315002,
      "weighted_orthogonal_loss": 0.0205426886677742
    },
    {
      "classification_loss": 0.6032772660255432,
      "epoch": 15.688524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20550848543643951,
      "orthogonal_weight": 0.1,
      "step": 4785,
      "total_loss": 0.623828113079071,
      "weighted_orthogonal_loss": 0.02055084891617298
    },
    {
      "classification_loss": 0.6163533329963684,
      "epoch": 15.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20556236803531647,
      "orthogonal_weight": 0.1,
      "step": 4786,
      "total_loss": 0.636909544467926,
      "weighted_orthogonal_loss": 0.020556237548589706
    },
    {
      "classification_loss": 0.6103451251983643,
      "epoch": 15.695081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20561841130256653,
      "orthogonal_weight": 0.1,
      "step": 4787,
      "total_loss": 0.6309069395065308,
      "weighted_orthogonal_loss": 0.020561842247843742
    },
    {
      "classification_loss": 0.6004741787910461,
      "epoch": 15.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20568066835403442,
      "orthogonal_weight": 0.1,
      "step": 4788,
      "total_loss": 0.6210422515869141,
      "weighted_orthogonal_loss": 0.020568067207932472
    },
    {
      "classification_loss": 0.6462699770927429,
      "epoch": 15.701639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20578904449939728,
      "orthogonal_weight": 0.1,
      "step": 4789,
      "total_loss": 0.66684889793396,
      "weighted_orthogonal_loss": 0.020578904077410698
    },
    {
      "classification_loss": 0.5889654755592346,
      "epoch": 15.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20590639114379883,
      "orthogonal_weight": 0.1,
      "step": 4790,
      "total_loss": 0.6095561385154724,
      "weighted_orthogonal_loss": 0.020590638741850853
    },
    {
      "classification_loss": 0.5897223353385925,
      "epoch": 15.708196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20600619912147522,
      "orthogonal_weight": 0.1,
      "step": 4791,
      "total_loss": 0.6103229522705078,
      "weighted_orthogonal_loss": 0.02060062065720558
    },
    {
      "classification_loss": 0.6022064685821533,
      "epoch": 15.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20609577000141144,
      "orthogonal_weight": 0.1,
      "step": 4792,
      "total_loss": 0.6228160262107849,
      "weighted_orthogonal_loss": 0.020609578117728233
    },
    {
      "classification_loss": 0.5929111242294312,
      "epoch": 15.714754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20618696510791779,
      "orthogonal_weight": 0.1,
      "step": 4793,
      "total_loss": 0.6135298013687134,
      "weighted_orthogonal_loss": 0.020618697628378868
    },
    {
      "classification_loss": 0.5713356733322144,
      "epoch": 15.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20629456639289856,
      "orthogonal_weight": 0.1,
      "step": 4794,
      "total_loss": 0.5919651389122009,
      "weighted_orthogonal_loss": 0.020629456266760826
    },
    {
      "classification_loss": 0.5802148580551147,
      "epoch": 15.721311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20638392865657806,
      "orthogonal_weight": 0.1,
      "step": 4795,
      "total_loss": 0.6008532643318176,
      "weighted_orthogonal_loss": 0.020638393238186836
    },
    {
      "classification_loss": 0.5795436501502991,
      "epoch": 15.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20646236836910248,
      "orthogonal_weight": 0.1,
      "step": 4796,
      "total_loss": 0.6001898646354675,
      "weighted_orthogonal_loss": 0.020646236836910248
    },
    {
      "classification_loss": 0.61872398853302,
      "epoch": 15.727868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20655278861522675,
      "orthogonal_weight": 0.1,
      "step": 4797,
      "total_loss": 0.6393792629241943,
      "weighted_orthogonal_loss": 0.020655279979109764
    },
    {
      "classification_loss": 0.5435323119163513,
      "epoch": 15.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20663948357105255,
      "orthogonal_weight": 0.1,
      "step": 4798,
      "total_loss": 0.5641962885856628,
      "weighted_orthogonal_loss": 0.020663948729634285
    },
    {
      "classification_loss": 0.6235119104385376,
      "epoch": 15.734426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067604511976242,
      "orthogonal_weight": 0.1,
      "step": 4799,
      "total_loss": 0.6441879272460938,
      "weighted_orthogonal_loss": 0.02067604474723339
    },
    {
      "epoch": 15.737704918032787,
      "grad_norm": 20.811603546142578,
      "learning_rate": 4.3366666666666666e-05,
      "loss": 0.6296,
      "step": 4800
    },
    {
      "classification_loss": 0.5906400084495544,
      "epoch": 15.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20687228441238403,
      "orthogonal_weight": 0.1,
      "step": 4800,
      "total_loss": 0.6113272309303284,
      "weighted_orthogonal_loss": 0.020687228068709373
    },
    {
      "classification_loss": 0.5824813842773438,
      "epoch": 15.740983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20703254640102386,
      "orthogonal_weight": 0.1,
      "step": 4801,
      "total_loss": 0.6031846404075623,
      "weighted_orthogonal_loss": 0.020703254267573357
    },
    {
      "classification_loss": 0.5994035005569458,
      "epoch": 15.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207180917263031,
      "orthogonal_weight": 0.1,
      "step": 4802,
      "total_loss": 0.6201215982437134,
      "weighted_orthogonal_loss": 0.02071809209883213
    },
    {
      "classification_loss": 0.6671721935272217,
      "epoch": 15.747540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2073221206665039,
      "orthogonal_weight": 0.1,
      "step": 4803,
      "total_loss": 0.687904417514801,
      "weighted_orthogonal_loss": 0.02073221281170845
    },
    {
      "classification_loss": 0.523277759552002,
      "epoch": 15.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2073875218629837,
      "orthogonal_weight": 0.1,
      "step": 4804,
      "total_loss": 0.5440165400505066,
      "weighted_orthogonal_loss": 0.0207387525588274
    },
    {
      "classification_loss": 0.6052411794662476,
      "epoch": 15.754098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2074458748102188,
      "orthogonal_weight": 0.1,
      "step": 4805,
      "total_loss": 0.6259857416152954,
      "weighted_orthogonal_loss": 0.02074458822607994
    },
    {
      "classification_loss": 0.5249406695365906,
      "epoch": 15.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20752356946468353,
      "orthogonal_weight": 0.1,
      "step": 4806,
      "total_loss": 0.545693039894104,
      "weighted_orthogonal_loss": 0.020752357318997383
    },
    {
      "classification_loss": 0.6046459078788757,
      "epoch": 15.760655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20760084688663483,
      "orthogonal_weight": 0.1,
      "step": 4807,
      "total_loss": 0.6254059672355652,
      "weighted_orthogonal_loss": 0.020760085433721542
    },
    {
      "classification_loss": 0.6731601357460022,
      "epoch": 15.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20767171680927277,
      "orthogonal_weight": 0.1,
      "step": 4808,
      "total_loss": 0.6939272880554199,
      "weighted_orthogonal_loss": 0.020767172798514366
    },
    {
      "classification_loss": 0.6349120736122131,
      "epoch": 15.767213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20777112245559692,
      "orthogonal_weight": 0.1,
      "step": 4809,
      "total_loss": 0.6556891798973083,
      "weighted_orthogonal_loss": 0.020777111873030663
    },
    {
      "classification_loss": 0.6244019269943237,
      "epoch": 15.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20782645046710968,
      "orthogonal_weight": 0.1,
      "step": 4810,
      "total_loss": 0.6451845765113831,
      "weighted_orthogonal_loss": 0.020782645791769028
    },
    {
      "classification_loss": 0.6719644069671631,
      "epoch": 15.773770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20789147913455963,
      "orthogonal_weight": 0.1,
      "step": 4811,
      "total_loss": 0.6927535533905029,
      "weighted_orthogonal_loss": 0.020789148285984993
    },
    {
      "classification_loss": 0.5465016961097717,
      "epoch": 15.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20794256031513214,
      "orthogonal_weight": 0.1,
      "step": 4812,
      "total_loss": 0.5672959685325623,
      "weighted_orthogonal_loss": 0.020794255658984184
    },
    {
      "classification_loss": 0.6000812649726868,
      "epoch": 15.780327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20798009634017944,
      "orthogonal_weight": 0.1,
      "step": 4813,
      "total_loss": 0.6208792924880981,
      "weighted_orthogonal_loss": 0.020798010751605034
    },
    {
      "classification_loss": 0.5673270225524902,
      "epoch": 15.783606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20802338421344757,
      "orthogonal_weight": 0.1,
      "step": 4814,
      "total_loss": 0.5881293416023254,
      "weighted_orthogonal_loss": 0.020802339538931847
    },
    {
      "classification_loss": 0.6680957674980164,
      "epoch": 15.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20806549489498138,
      "orthogonal_weight": 0.1,
      "step": 4815,
      "total_loss": 0.6889023184776306,
      "weighted_orthogonal_loss": 0.02080654911696911
    },
    {
      "classification_loss": 0.6241386532783508,
      "epoch": 15.790163934426229,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2080928385257721,
      "orthogonal_weight": 0.1,
      "step": 4816,
      "total_loss": 0.6449479460716248,
      "weighted_orthogonal_loss": 0.02080928348004818
    },
    {
      "classification_loss": 0.6146749258041382,
      "epoch": 15.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20811480283737183,
      "orthogonal_weight": 0.1,
      "step": 4817,
      "total_loss": 0.6354864239692688,
      "weighted_orthogonal_loss": 0.020811481401324272
    },
    {
      "classification_loss": 0.6048856377601624,
      "epoch": 15.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20811344683170319,
      "orthogonal_weight": 0.1,
      "step": 4818,
      "total_loss": 0.6256969571113586,
      "weighted_orthogonal_loss": 0.02081134542822838
    },
    {
      "classification_loss": 0.6616538166999817,
      "epoch": 15.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20813356339931488,
      "orthogonal_weight": 0.1,
      "step": 4819,
      "total_loss": 0.6824671626091003,
      "weighted_orthogonal_loss": 0.020813357084989548
    },
    {
      "classification_loss": 0.6832188367843628,
      "epoch": 15.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20808923244476318,
      "orthogonal_weight": 0.1,
      "step": 4820,
      "total_loss": 0.7040277719497681,
      "weighted_orthogonal_loss": 0.020808923989534378
    },
    {
      "classification_loss": 0.5596755146980286,
      "epoch": 15.806557377049181,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2080741822719574,
      "orthogonal_weight": 0.1,
      "step": 4821,
      "total_loss": 0.5804829597473145,
      "weighted_orthogonal_loss": 0.0208074189722538
    },
    {
      "classification_loss": 0.6499117016792297,
      "epoch": 15.809836065573771,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20806075632572174,
      "orthogonal_weight": 0.1,
      "step": 4822,
      "total_loss": 0.6707177758216858,
      "weighted_orthogonal_loss": 0.020806076005101204
    },
    {
      "classification_loss": 0.6345216035842896,
      "epoch": 15.813114754098361,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20806437730789185,
      "orthogonal_weight": 0.1,
      "step": 4823,
      "total_loss": 0.6553280353546143,
      "weighted_orthogonal_loss": 0.020806437358260155
    },
    {
      "classification_loss": 0.5761461853981018,
      "epoch": 15.816393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20807401835918427,
      "orthogonal_weight": 0.1,
      "step": 4824,
      "total_loss": 0.5969535708427429,
      "weighted_orthogonal_loss": 0.020807402208447456
    },
    {
      "classification_loss": 0.5486636757850647,
      "epoch": 15.819672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20810340344905853,
      "orthogonal_weight": 0.1,
      "step": 4825,
      "total_loss": 0.5694740414619446,
      "weighted_orthogonal_loss": 0.020810341462492943
    },
    {
      "classification_loss": 0.6874301433563232,
      "epoch": 15.822950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20812268555164337,
      "orthogonal_weight": 0.1,
      "step": 4826,
      "total_loss": 0.7082424163818359,
      "weighted_orthogonal_loss": 0.020812269300222397
    },
    {
      "classification_loss": 0.7195605039596558,
      "epoch": 15.826229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20815296471118927,
      "orthogonal_weight": 0.1,
      "step": 4827,
      "total_loss": 0.740375816822052,
      "weighted_orthogonal_loss": 0.020815296098589897
    },
    {
      "classification_loss": 0.6336842179298401,
      "epoch": 15.829508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20816615223884583,
      "orthogonal_weight": 0.1,
      "step": 4828,
      "total_loss": 0.6545008420944214,
      "weighted_orthogonal_loss": 0.020816614851355553
    },
    {
      "classification_loss": 0.7132787704467773,
      "epoch": 15.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20812147855758667,
      "orthogonal_weight": 0.1,
      "step": 4829,
      "total_loss": 0.7340909242630005,
      "weighted_orthogonal_loss": 0.020812148228287697
    },
    {
      "classification_loss": 0.5930513143539429,
      "epoch": 15.836065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2080715000629425,
      "orthogonal_weight": 0.1,
      "step": 4830,
      "total_loss": 0.6138584613800049,
      "weighted_orthogonal_loss": 0.02080715075135231
    },
    {
      "classification_loss": 0.6267666220664978,
      "epoch": 15.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20805537700653076,
      "orthogonal_weight": 0.1,
      "step": 4831,
      "total_loss": 0.6475721597671509,
      "weighted_orthogonal_loss": 0.020805537700653076
    },
    {
      "classification_loss": 0.544898271560669,
      "epoch": 15.842622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20803160965442657,
      "orthogonal_weight": 0.1,
      "step": 4832,
      "total_loss": 0.565701425075531,
      "weighted_orthogonal_loss": 0.020803160965442657
    },
    {
      "classification_loss": 0.6289799809455872,
      "epoch": 15.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20802393555641174,
      "orthogonal_weight": 0.1,
      "step": 4833,
      "total_loss": 0.6497823596000671,
      "weighted_orthogonal_loss": 0.020802393555641174
    },
    {
      "classification_loss": 0.5907372236251831,
      "epoch": 15.849180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20799998939037323,
      "orthogonal_weight": 0.1,
      "step": 4834,
      "total_loss": 0.6115372180938721,
      "weighted_orthogonal_loss": 0.020800000056624413
    },
    {
      "classification_loss": 0.6548910140991211,
      "epoch": 15.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079830765724182,
      "orthogonal_weight": 0.1,
      "step": 4835,
      "total_loss": 0.6756893396377563,
      "weighted_orthogonal_loss": 0.02079830877482891
    },
    {
      "classification_loss": 0.5056306719779968,
      "epoch": 15.855737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079578936100006,
      "orthogonal_weight": 0.1,
      "step": 4836,
      "total_loss": 0.5264264345169067,
      "weighted_orthogonal_loss": 0.02079579047858715
    },
    {
      "classification_loss": 0.605803906917572,
      "epoch": 15.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207917720079422,
      "orthogonal_weight": 0.1,
      "step": 4837,
      "total_loss": 0.626595675945282,
      "weighted_orthogonal_loss": 0.02079177275300026
    },
    {
      "classification_loss": 0.5614129304885864,
      "epoch": 15.862295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20787158608436584,
      "orthogonal_weight": 0.1,
      "step": 4838,
      "total_loss": 0.5822001099586487,
      "weighted_orthogonal_loss": 0.020787158980965614
    },
    {
      "classification_loss": 0.6273019909858704,
      "epoch": 15.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20784665644168854,
      "orthogonal_weight": 0.1,
      "step": 4839,
      "total_loss": 0.648086667060852,
      "weighted_orthogonal_loss": 0.020784666761755943
    },
    {
      "classification_loss": 0.6433212757110596,
      "epoch": 15.868852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2077566236257553,
      "orthogonal_weight": 0.1,
      "step": 4840,
      "total_loss": 0.6640969514846802,
      "weighted_orthogonal_loss": 0.02077566273510456
    },
    {
      "classification_loss": 0.6282591819763184,
      "epoch": 15.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20763970911502838,
      "orthogonal_weight": 0.1,
      "step": 4841,
      "total_loss": 0.649023175239563,
      "weighted_orthogonal_loss": 0.020763970911502838
    },
    {
      "classification_loss": 0.6341126561164856,
      "epoch": 15.875409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20751100778579712,
      "orthogonal_weight": 0.1,
      "step": 4842,
      "total_loss": 0.6548637747764587,
      "weighted_orthogonal_loss": 0.0207511018961668
    },
    {
      "classification_loss": 0.6466689109802246,
      "epoch": 15.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20739296078681946,
      "orthogonal_weight": 0.1,
      "step": 4843,
      "total_loss": 0.6674082279205322,
      "weighted_orthogonal_loss": 0.020739296451210976
    },
    {
      "classification_loss": 0.5548484921455383,
      "epoch": 15.881967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2072935253381729,
      "orthogonal_weight": 0.1,
      "step": 4844,
      "total_loss": 0.5755778551101685,
      "weighted_orthogonal_loss": 0.02072935365140438
    },
    {
      "classification_loss": 0.6527272462844849,
      "epoch": 15.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20721203088760376,
      "orthogonal_weight": 0.1,
      "step": 4845,
      "total_loss": 0.6734484434127808,
      "weighted_orthogonal_loss": 0.020721202716231346
    },
    {
      "classification_loss": 0.7048597931861877,
      "epoch": 15.888524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20712877810001373,
      "orthogonal_weight": 0.1,
      "step": 4846,
      "total_loss": 0.7255726456642151,
      "weighted_orthogonal_loss": 0.020712878555059433
    },
    {
      "classification_loss": 0.6236209869384766,
      "epoch": 15.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20702600479125977,
      "orthogonal_weight": 0.1,
      "step": 4847,
      "total_loss": 0.6443235874176025,
      "weighted_orthogonal_loss": 0.020702600479125977
    },
    {
      "classification_loss": 0.6231698989868164,
      "epoch": 15.895081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20694124698638916,
      "orthogonal_weight": 0.1,
      "step": 4848,
      "total_loss": 0.6438640356063843,
      "weighted_orthogonal_loss": 0.020694125443696976
    },
    {
      "classification_loss": 0.6756933927536011,
      "epoch": 15.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068895399570465,
      "orthogonal_weight": 0.1,
      "step": 4849,
      "total_loss": 0.6963823437690735,
      "weighted_orthogonal_loss": 0.02068895474076271
    },
    {
      "classification_loss": 0.6402668356895447,
      "epoch": 15.901639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20683683454990387,
      "orthogonal_weight": 0.1,
      "step": 4850,
      "total_loss": 0.6609505414962769,
      "weighted_orthogonal_loss": 0.020683683454990387
    },
    {
      "classification_loss": 0.6593683362007141,
      "epoch": 15.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20680169761180878,
      "orthogonal_weight": 0.1,
      "step": 4851,
      "total_loss": 0.6800485253334045,
      "weighted_orthogonal_loss": 0.020680170506238937
    },
    {
      "classification_loss": 0.6718922257423401,
      "epoch": 15.908196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20677748322486877,
      "orthogonal_weight": 0.1,
      "step": 4852,
      "total_loss": 0.6925699710845947,
      "weighted_orthogonal_loss": 0.020677749067544937
    },
    {
      "classification_loss": 0.5985032916069031,
      "epoch": 15.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20676366984844208,
      "orthogonal_weight": 0.1,
      "step": 4853,
      "total_loss": 0.6191796660423279,
      "weighted_orthogonal_loss": 0.020676366984844208
    },
    {
      "classification_loss": 0.5864852666854858,
      "epoch": 15.914754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20678164064884186,
      "orthogonal_weight": 0.1,
      "step": 4854,
      "total_loss": 0.6071634292602539,
      "weighted_orthogonal_loss": 0.020678164437413216
    },
    {
      "classification_loss": 0.61739182472229,
      "epoch": 15.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20681746304035187,
      "orthogonal_weight": 0.1,
      "step": 4855,
      "total_loss": 0.6380735635757446,
      "weighted_orthogonal_loss": 0.020681746304035187
    },
    {
      "classification_loss": 0.627200186252594,
      "epoch": 15.921311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20687060058116913,
      "orthogonal_weight": 0.1,
      "step": 4856,
      "total_loss": 0.6478872299194336,
      "weighted_orthogonal_loss": 0.020687060430645943
    },
    {
      "classification_loss": 0.6347405910491943,
      "epoch": 15.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20690444111824036,
      "orthogonal_weight": 0.1,
      "step": 4857,
      "total_loss": 0.6554310321807861,
      "weighted_orthogonal_loss": 0.020690444856882095
    },
    {
      "classification_loss": 0.5762079954147339,
      "epoch": 15.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20696909725666046,
      "orthogonal_weight": 0.1,
      "step": 4858,
      "total_loss": 0.5969049334526062,
      "weighted_orthogonal_loss": 0.020696910098195076
    },
    {
      "classification_loss": 0.5488309860229492,
      "epoch": 15.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704394578933716,
      "orthogonal_weight": 0.1,
      "step": 4859,
      "total_loss": 0.5695353746414185,
      "weighted_orthogonal_loss": 0.020704394206404686
    },
    {
      "classification_loss": 0.6234181523323059,
      "epoch": 15.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20707786083221436,
      "orthogonal_weight": 0.1,
      "step": 4860,
      "total_loss": 0.6441259384155273,
      "weighted_orthogonal_loss": 0.020707786083221436
    },
    {
      "classification_loss": 0.6165904402732849,
      "epoch": 15.937704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20708703994750977,
      "orthogonal_weight": 0.1,
      "step": 4861,
      "total_loss": 0.637299120426178,
      "weighted_orthogonal_loss": 0.020708704367280006
    },
    {
      "classification_loss": 0.6286361217498779,
      "epoch": 15.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2070920765399933,
      "orthogonal_weight": 0.1,
      "step": 4862,
      "total_loss": 0.649345338344574,
      "weighted_orthogonal_loss": 0.0207092072814703
    },
    {
      "classification_loss": 0.5235094428062439,
      "epoch": 15.944262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20705127716064453,
      "orthogonal_weight": 0.1,
      "step": 4863,
      "total_loss": 0.5442145466804504,
      "weighted_orthogonal_loss": 0.020705128088593483
    },
    {
      "classification_loss": 0.6019008755683899,
      "epoch": 15.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704276859760284,
      "orthogonal_weight": 0.1,
      "step": 4864,
      "total_loss": 0.6226051449775696,
      "weighted_orthogonal_loss": 0.020704276859760284
    },
    {
      "classification_loss": 0.6391159296035767,
      "epoch": 15.950819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069997489452362,
      "orthogonal_weight": 0.1,
      "step": 4865,
      "total_loss": 0.6598159074783325,
      "weighted_orthogonal_loss": 0.02069997601211071
    },
    {
      "classification_loss": 0.5972601175308228,
      "epoch": 15.954098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20696347951889038,
      "orthogonal_weight": 0.1,
      "step": 4866,
      "total_loss": 0.6179564595222473,
      "weighted_orthogonal_loss": 0.020696347579360008
    },
    {
      "classification_loss": 0.5874453783035278,
      "epoch": 15.957377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069421410560608,
      "orthogonal_weight": 0.1,
      "step": 4867,
      "total_loss": 0.6081395745277405,
      "weighted_orthogonal_loss": 0.02069421485066414
    },
    {
      "classification_loss": 0.6483021974563599,
      "epoch": 15.960655737704919,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20694994926452637,
      "orthogonal_weight": 0.1,
      "step": 4868,
      "total_loss": 0.6689971685409546,
      "weighted_orthogonal_loss": 0.020694995298981667
    },
    {
      "classification_loss": 0.6210930347442627,
      "epoch": 15.963934426229509,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20694810152053833,
      "orthogonal_weight": 0.1,
      "step": 4869,
      "total_loss": 0.6417878270149231,
      "weighted_orthogonal_loss": 0.020694810897111893
    },
    {
      "classification_loss": 0.568767249584198,
      "epoch": 15.967213114754099,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20693808794021606,
      "orthogonal_weight": 0.1,
      "step": 4870,
      "total_loss": 0.589461088180542,
      "weighted_orthogonal_loss": 0.020693808794021606
    },
    {
      "classification_loss": 0.587710440158844,
      "epoch": 15.970491803278689,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20696406066417694,
      "orthogonal_weight": 0.1,
      "step": 4871,
      "total_loss": 0.6084068417549133,
      "weighted_orthogonal_loss": 0.020696407184004784
    },
    {
      "classification_loss": 0.6467154622077942,
      "epoch": 15.973770491803279,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069743424654007,
      "orthogonal_weight": 0.1,
      "step": 4872,
      "total_loss": 0.6674128770828247,
      "weighted_orthogonal_loss": 0.02069743536412716
    },
    {
      "classification_loss": 0.5868759155273438,
      "epoch": 15.97704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069828063249588,
      "orthogonal_weight": 0.1,
      "step": 4873,
      "total_loss": 0.6075742244720459,
      "weighted_orthogonal_loss": 0.02069828100502491
    },
    {
      "classification_loss": 0.6099636554718018,
      "epoch": 15.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20698648691177368,
      "orthogonal_weight": 0.1,
      "step": 4874,
      "total_loss": 0.6306623220443726,
      "weighted_orthogonal_loss": 0.020698649808764458
    },
    {
      "classification_loss": 0.5670701265335083,
      "epoch": 15.98360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20699293911457062,
      "orthogonal_weight": 0.1,
      "step": 4875,
      "total_loss": 0.5877694487571716,
      "weighted_orthogonal_loss": 0.02069929428398609
    },
    {
      "classification_loss": 0.5360196828842163,
      "epoch": 15.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20697566866874695,
      "orthogonal_weight": 0.1,
      "step": 4876,
      "total_loss": 0.5567172765731812,
      "weighted_orthogonal_loss": 0.020697567611932755
    },
    {
      "classification_loss": 0.6318943500518799,
      "epoch": 15.99016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069544643163681,
      "orthogonal_weight": 0.1,
      "step": 4877,
      "total_loss": 0.6525897979736328,
      "weighted_orthogonal_loss": 0.02069544605910778
    },
    {
      "classification_loss": 0.6457476615905762,
      "epoch": 15.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069309502840042,
      "orthogonal_weight": 0.1,
      "step": 4878,
      "total_loss": 0.6664407849311829,
      "weighted_orthogonal_loss": 0.02069309540092945
    },
    {
      "classification_loss": 0.5325995683670044,
      "epoch": 15.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688892900943756,
      "orthogonal_weight": 0.1,
      "step": 4879,
      "total_loss": 0.553288459777832,
      "weighted_orthogonal_loss": 0.020688893273472786
    },
    {
      "classification_loss": 0.7086828947067261,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7293686866760254,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.7022964954376221,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7229822874069214,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.7001144289970398,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7208002209663391,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.7221261262893677,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.742811918258667,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.7091463804244995,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7298321723937988,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.708308219909668,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7289940118789673,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.6947607398033142,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7154465317726135,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.722197413444519,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.7428832054138184,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.486,
      "eval_f1": 0.48906560636182905,
      "eval_loss": 0.7288101315498352,
      "eval_precision": 0.6422976501305483,
      "eval_recall": 0.39486356340288925,
      "eval_runtime": 6.1661,
      "eval_samples_per_second": 162.176,
      "eval_steps_per_second": 1.297,
      "step": 4880
    },
    {
      "classification_loss": 0.6017940640449524,
      "epoch": 16.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068578004837036,
      "orthogonal_weight": 0.1,
      "step": 4880,
      "total_loss": 0.6224798560142517,
      "weighted_orthogonal_loss": 0.02068578079342842
    },
    {
      "classification_loss": 0.5768191814422607,
      "epoch": 16.003278688524592,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20682398974895477,
      "orthogonal_weight": 0.1,
      "step": 4881,
      "total_loss": 0.5975015759468079,
      "weighted_orthogonal_loss": 0.020682400092482567
    },
    {
      "classification_loss": 0.5008688569068909,
      "epoch": 16.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068081647157669,
      "orthogonal_weight": 0.1,
      "step": 4882,
      "total_loss": 0.5215497016906738,
      "weighted_orthogonal_loss": 0.02068081684410572
    },
    {
      "classification_loss": 0.5171810984611511,
      "epoch": 16.009836065573772,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20682014524936676,
      "orthogonal_weight": 0.1,
      "step": 4883,
      "total_loss": 0.5378631353378296,
      "weighted_orthogonal_loss": 0.020682014524936676
    },
    {
      "classification_loss": 0.6535409092903137,
      "epoch": 16.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20681393146514893,
      "orthogonal_weight": 0.1,
      "step": 4884,
      "total_loss": 0.6742222905158997,
      "weighted_orthogonal_loss": 0.020681394264101982
    },
    {
      "classification_loss": 0.6774813532829285,
      "epoch": 16.016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20670434832572937,
      "orthogonal_weight": 0.1,
      "step": 4885,
      "total_loss": 0.6981517672538757,
      "weighted_orthogonal_loss": 0.020670434460043907
    },
    {
      "classification_loss": 0.550421953201294,
      "epoch": 16.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20658890902996063,
      "orthogonal_weight": 0.1,
      "step": 4886,
      "total_loss": 0.5710808634757996,
      "weighted_orthogonal_loss": 0.020658891648054123
    },
    {
      "classification_loss": 0.5955320596694946,
      "epoch": 16.022950819672133,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20651711523532867,
      "orthogonal_weight": 0.1,
      "step": 4887,
      "total_loss": 0.6161837577819824,
      "weighted_orthogonal_loss": 0.020651711151003838
    },
    {
      "classification_loss": 0.6863107085227966,
      "epoch": 16.02622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2064724862575531,
      "orthogonal_weight": 0.1,
      "step": 4888,
      "total_loss": 0.7069579362869263,
      "weighted_orthogonal_loss": 0.02064724825322628
    },
    {
      "classification_loss": 0.5999546647071838,
      "epoch": 16.029508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20644786953926086,
      "orthogonal_weight": 0.1,
      "step": 4889,
      "total_loss": 0.6205994486808777,
      "weighted_orthogonal_loss": 0.020644787698984146
    },
    {
      "classification_loss": 0.5992540121078491,
      "epoch": 16.0327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2064187079668045,
      "orthogonal_weight": 0.1,
      "step": 4890,
      "total_loss": 0.619895875453949,
      "weighted_orthogonal_loss": 0.02064187079668045
    },
    {
      "classification_loss": 0.5710647106170654,
      "epoch": 16.036065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20639774203300476,
      "orthogonal_weight": 0.1,
      "step": 4891,
      "total_loss": 0.5917044878005981,
      "weighted_orthogonal_loss": 0.020639775320887566
    },
    {
      "classification_loss": 0.6946070790290833,
      "epoch": 16.03934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20642803609371185,
      "orthogonal_weight": 0.1,
      "step": 4892,
      "total_loss": 0.7152498960494995,
      "weighted_orthogonal_loss": 0.020642803981900215
    },
    {
      "classification_loss": 0.5847803354263306,
      "epoch": 16.042622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20643587410449982,
      "orthogonal_weight": 0.1,
      "step": 4893,
      "total_loss": 0.6054239273071289,
      "weighted_orthogonal_loss": 0.02064358815550804
    },
    {
      "classification_loss": 0.6213952302932739,
      "epoch": 16.04590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20638206601142883,
      "orthogonal_weight": 0.1,
      "step": 4894,
      "total_loss": 0.6420334577560425,
      "weighted_orthogonal_loss": 0.020638206973671913
    },
    {
      "classification_loss": 0.5418623089790344,
      "epoch": 16.049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20635248720645905,
      "orthogonal_weight": 0.1,
      "step": 4895,
      "total_loss": 0.5624975562095642,
      "weighted_orthogonal_loss": 0.020635249093174934
    },
    {
      "classification_loss": 0.6618872284889221,
      "epoch": 16.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20633341372013092,
      "orthogonal_weight": 0.1,
      "step": 4896,
      "total_loss": 0.6825205683708191,
      "weighted_orthogonal_loss": 0.020633341744542122
    },
    {
      "classification_loss": 0.6494864821434021,
      "epoch": 16.055737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20631293952465057,
      "orthogonal_weight": 0.1,
      "step": 4897,
      "total_loss": 0.6701177954673767,
      "weighted_orthogonal_loss": 0.020631294697523117
    },
    {
      "classification_loss": 0.5556432604789734,
      "epoch": 16.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20626895129680634,
      "orthogonal_weight": 0.1,
      "step": 4898,
      "total_loss": 0.5762701630592346,
      "weighted_orthogonal_loss": 0.020626895129680634
    },
    {
      "classification_loss": 0.705696165561676,
      "epoch": 16.062295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062610685825348,
      "orthogonal_weight": 0.1,
      "step": 4899,
      "total_loss": 0.7263222932815552,
      "weighted_orthogonal_loss": 0.02062610723078251
    },
    {
      "epoch": 16.065573770491802,
      "grad_norm": 20.325525283813477,
      "learning_rate": 4.0033333333333335e-05,
      "loss": 0.633,
      "step": 4900
    },
    {
      "classification_loss": 0.6803285479545593,
      "epoch": 16.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20623913407325745,
      "orthogonal_weight": 0.1,
      "step": 4900,
      "total_loss": 0.7009524703025818,
      "weighted_orthogonal_loss": 0.020623913034796715
    },
    {
      "classification_loss": 0.62994784116745,
      "epoch": 16.068852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20621399581432343,
      "orthogonal_weight": 0.1,
      "step": 4901,
      "total_loss": 0.6505692601203918,
      "weighted_orthogonal_loss": 0.020621400326490402
    },
    {
      "classification_loss": 0.716471254825592,
      "epoch": 16.072131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061738520860672,
      "orthogonal_weight": 0.1,
      "step": 4902,
      "total_loss": 0.7370886206626892,
      "weighted_orthogonal_loss": 0.02061738632619381
    },
    {
      "classification_loss": 0.5476832985877991,
      "epoch": 16.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20612294971942902,
      "orthogonal_weight": 0.1,
      "step": 4903,
      "total_loss": 0.5682955980300903,
      "weighted_orthogonal_loss": 0.02061229571700096
    },
    {
      "classification_loss": 0.5688506960868835,
      "epoch": 16.078688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20610599219799042,
      "orthogonal_weight": 0.1,
      "step": 4904,
      "total_loss": 0.5894612669944763,
      "weighted_orthogonal_loss": 0.020610598847270012
    },
    {
      "classification_loss": 0.6573520302772522,
      "epoch": 16.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061394453048706,
      "orthogonal_weight": 0.1,
      "step": 4905,
      "total_loss": 0.6779659986495972,
      "weighted_orthogonal_loss": 0.02061394415795803
    },
    {
      "classification_loss": 0.6277270317077637,
      "epoch": 16.085245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20616987347602844,
      "orthogonal_weight": 0.1,
      "step": 4906,
      "total_loss": 0.6483440399169922,
      "weighted_orthogonal_loss": 0.020616987720131874
    },
    {
      "classification_loss": 0.6746155619621277,
      "epoch": 16.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062273770570755,
      "orthogonal_weight": 0.1,
      "step": 4907,
      "total_loss": 0.6952382922172546,
      "weighted_orthogonal_loss": 0.02062273770570755
    },
    {
      "classification_loss": 0.6012928485870361,
      "epoch": 16.091803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062358260154724,
      "orthogonal_weight": 0.1,
      "step": 4908,
      "total_loss": 0.6219164133071899,
      "weighted_orthogonal_loss": 0.0206235833466053
    },
    {
      "classification_loss": 0.627232551574707,
      "epoch": 16.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2062029242515564,
      "orthogonal_weight": 0.1,
      "step": 4909,
      "total_loss": 0.6478528380393982,
      "weighted_orthogonal_loss": 0.02062029205262661
    },
    {
      "classification_loss": 0.5862275958061218,
      "epoch": 16.098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20618057250976562,
      "orthogonal_weight": 0.1,
      "step": 4910,
      "total_loss": 0.6068456768989563,
      "weighted_orthogonal_loss": 0.020618056878447533
    },
    {
      "classification_loss": 0.605401873588562,
      "epoch": 16.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2061898112297058,
      "orthogonal_weight": 0.1,
      "step": 4911,
      "total_loss": 0.6260208487510681,
      "weighted_orthogonal_loss": 0.02061898075044155
    },
    {
      "classification_loss": 0.5642623901367188,
      "epoch": 16.104918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20620889961719513,
      "orthogonal_weight": 0.1,
      "step": 4912,
      "total_loss": 0.5848832726478577,
      "weighted_orthogonal_loss": 0.020620889961719513
    },
    {
      "classification_loss": 0.6028140187263489,
      "epoch": 16.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20625291764736176,
      "orthogonal_weight": 0.1,
      "step": 4913,
      "total_loss": 0.6234393119812012,
      "weighted_orthogonal_loss": 0.020625291392207146
    },
    {
      "classification_loss": 0.5619932413101196,
      "epoch": 16.111475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20627717673778534,
      "orthogonal_weight": 0.1,
      "step": 4914,
      "total_loss": 0.5826209783554077,
      "weighted_orthogonal_loss": 0.020627718418836594
    },
    {
      "classification_loss": 0.5941897630691528,
      "epoch": 16.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20629142224788666,
      "orthogonal_weight": 0.1,
      "step": 4915,
      "total_loss": 0.6148189306259155,
      "weighted_orthogonal_loss": 0.020629143342375755
    },
    {
      "classification_loss": 0.6192734241485596,
      "epoch": 16.118032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2063123732805252,
      "orthogonal_weight": 0.1,
      "step": 4916,
      "total_loss": 0.6399046778678894,
      "weighted_orthogonal_loss": 0.02063123695552349
    },
    {
      "classification_loss": 0.5968295931816101,
      "epoch": 16.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20636039972305298,
      "orthogonal_weight": 0.1,
      "step": 4917,
      "total_loss": 0.617465615272522,
      "weighted_orthogonal_loss": 0.020636040717363358
    },
    {
      "classification_loss": 0.6935237646102905,
      "epoch": 16.124590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20646658539772034,
      "orthogonal_weight": 0.1,
      "step": 4918,
      "total_loss": 0.7141703963279724,
      "weighted_orthogonal_loss": 0.020646659657359123
    },
    {
      "classification_loss": 0.6483644247055054,
      "epoch": 16.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.206558957695961,
      "orthogonal_weight": 0.1,
      "step": 4919,
      "total_loss": 0.6690202951431274,
      "weighted_orthogonal_loss": 0.02065589651465416
    },
    {
      "classification_loss": 0.6234279870986938,
      "epoch": 16.131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2066214382648468,
      "orthogonal_weight": 0.1,
      "step": 4920,
      "total_loss": 0.6440901160240173,
      "weighted_orthogonal_loss": 0.02066214382648468
    },
    {
      "classification_loss": 0.7018725872039795,
      "epoch": 16.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20667524635791779,
      "orthogonal_weight": 0.1,
      "step": 4921,
      "total_loss": 0.7225401401519775,
      "weighted_orthogonal_loss": 0.02066752500832081
    },
    {
      "classification_loss": 0.6885560750961304,
      "epoch": 16.137704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20672841370105743,
      "orthogonal_weight": 0.1,
      "step": 4922,
      "total_loss": 0.7092289328575134,
      "weighted_orthogonal_loss": 0.020672840997576714
    },
    {
      "classification_loss": 0.6117769479751587,
      "epoch": 16.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067783623933792,
      "orthogonal_weight": 0.1,
      "step": 4923,
      "total_loss": 0.6324548125267029,
      "weighted_orthogonal_loss": 0.02067783661186695
    },
    {
      "classification_loss": 0.5769213438034058,
      "epoch": 16.14426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20683354139328003,
      "orthogonal_weight": 0.1,
      "step": 4924,
      "total_loss": 0.5976046919822693,
      "weighted_orthogonal_loss": 0.020683353766798973
    },
    {
      "classification_loss": 0.6096182465553284,
      "epoch": 16.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068876028060913,
      "orthogonal_weight": 0.1,
      "step": 4925,
      "total_loss": 0.6303070187568665,
      "weighted_orthogonal_loss": 0.02068876102566719
    },
    {
      "classification_loss": 0.6693016290664673,
      "epoch": 16.15081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20691990852355957,
      "orthogonal_weight": 0.1,
      "step": 4926,
      "total_loss": 0.6899936199188232,
      "weighted_orthogonal_loss": 0.020691990852355957
    },
    {
      "classification_loss": 0.6553529500961304,
      "epoch": 16.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20692235231399536,
      "orthogonal_weight": 0.1,
      "step": 4927,
      "total_loss": 0.6760451793670654,
      "weighted_orthogonal_loss": 0.020692234858870506
    },
    {
      "classification_loss": 0.5239223837852478,
      "epoch": 16.15737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20692278444766998,
      "orthogonal_weight": 0.1,
      "step": 4928,
      "total_loss": 0.5446146726608276,
      "weighted_orthogonal_loss": 0.020692279562354088
    },
    {
      "classification_loss": 0.6999570727348328,
      "epoch": 16.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20692144334316254,
      "orthogonal_weight": 0.1,
      "step": 4929,
      "total_loss": 0.720649242401123,
      "weighted_orthogonal_loss": 0.020692145451903343
    },
    {
      "classification_loss": 0.5416374206542969,
      "epoch": 16.16393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20687338709831238,
      "orthogonal_weight": 0.1,
      "step": 4930,
      "total_loss": 0.5623247623443604,
      "weighted_orthogonal_loss": 0.020687339827418327
    },
    {
      "classification_loss": 0.5532315969467163,
      "epoch": 16.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20684412121772766,
      "orthogonal_weight": 0.1,
      "step": 4931,
      "total_loss": 0.5739160180091858,
      "weighted_orthogonal_loss": 0.020684411749243736
    },
    {
      "classification_loss": 0.573232889175415,
      "epoch": 16.17049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068755328655243,
      "orthogonal_weight": 0.1,
      "step": 4932,
      "total_loss": 0.5939204692840576,
      "weighted_orthogonal_loss": 0.02068755403161049
    },
    {
      "classification_loss": 0.6915525794029236,
      "epoch": 16.17377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688724517822266,
      "orthogonal_weight": 0.1,
      "step": 4933,
      "total_loss": 0.7122412919998169,
      "weighted_orthogonal_loss": 0.020688725635409355
    },
    {
      "classification_loss": 0.6072946190834045,
      "epoch": 16.17704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688560605049133,
      "orthogonal_weight": 0.1,
      "step": 4934,
      "total_loss": 0.6279831528663635,
      "weighted_orthogonal_loss": 0.020688561722636223
    },
    {
      "classification_loss": 0.6659535765647888,
      "epoch": 16.18032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20688091218471527,
      "orthogonal_weight": 0.1,
      "step": 4935,
      "total_loss": 0.6866416931152344,
      "weighted_orthogonal_loss": 0.020688092336058617
    },
    {
      "classification_loss": 0.6050920486450195,
      "epoch": 16.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20689377188682556,
      "orthogonal_weight": 0.1,
      "step": 4936,
      "total_loss": 0.6257814168930054,
      "weighted_orthogonal_loss": 0.020689377561211586
    },
    {
      "classification_loss": 0.55547034740448,
      "epoch": 16.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068987637758255,
      "orthogonal_weight": 0.1,
      "step": 4937,
      "total_loss": 0.5761602520942688,
      "weighted_orthogonal_loss": 0.02068987675011158
    },
    {
      "classification_loss": 0.6247528791427612,
      "epoch": 16.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20689065754413605,
      "orthogonal_weight": 0.1,
      "step": 4938,
      "total_loss": 0.6454419493675232,
      "weighted_orthogonal_loss": 0.020689066499471664
    },
    {
      "classification_loss": 0.6023082137107849,
      "epoch": 16.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20691078901290894,
      "orthogonal_weight": 0.1,
      "step": 4939,
      "total_loss": 0.6229993104934692,
      "weighted_orthogonal_loss": 0.020691080018877983
    },
    {
      "classification_loss": 0.6481994986534119,
      "epoch": 16.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20693661272525787,
      "orthogonal_weight": 0.1,
      "step": 4940,
      "total_loss": 0.6688931584358215,
      "weighted_orthogonal_loss": 0.020693661645054817
    },
    {
      "classification_loss": 0.6329153180122375,
      "epoch": 16.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2069777101278305,
      "orthogonal_weight": 0.1,
      "step": 4941,
      "total_loss": 0.6536130905151367,
      "weighted_orthogonal_loss": 0.02069777064025402
    },
    {
      "classification_loss": 0.5487526655197144,
      "epoch": 16.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20702575147151947,
      "orthogonal_weight": 0.1,
      "step": 4942,
      "total_loss": 0.5694552659988403,
      "weighted_orthogonal_loss": 0.020702576264739037
    },
    {
      "classification_loss": 0.6464026570320129,
      "epoch": 16.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20705218613147736,
      "orthogonal_weight": 0.1,
      "step": 4943,
      "total_loss": 0.667107880115509,
      "weighted_orthogonal_loss": 0.020705219358205795
    },
    {
      "classification_loss": 0.6059338450431824,
      "epoch": 16.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20706847310066223,
      "orthogonal_weight": 0.1,
      "step": 4944,
      "total_loss": 0.6266406774520874,
      "weighted_orthogonal_loss": 0.020706847310066223
    },
    {
      "classification_loss": 0.6135536432266235,
      "epoch": 16.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2071036994457245,
      "orthogonal_weight": 0.1,
      "step": 4945,
      "total_loss": 0.6342639923095703,
      "weighted_orthogonal_loss": 0.02071036957204342
    },
    {
      "classification_loss": 0.5928063988685608,
      "epoch": 16.21639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20715682208538055,
      "orthogonal_weight": 0.1,
      "step": 4946,
      "total_loss": 0.6135220527648926,
      "weighted_orthogonal_loss": 0.020715681836009026
    },
    {
      "classification_loss": 0.6639893054962158,
      "epoch": 16.21967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2072231024503708,
      "orthogonal_weight": 0.1,
      "step": 4947,
      "total_loss": 0.6847116351127625,
      "weighted_orthogonal_loss": 0.02072231099009514
    },
    {
      "classification_loss": 0.5732082724571228,
      "epoch": 16.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2072962373495102,
      "orthogonal_weight": 0.1,
      "step": 4948,
      "total_loss": 0.593937873840332,
      "weighted_orthogonal_loss": 0.02072962373495102
    },
    {
      "classification_loss": 0.6210005283355713,
      "epoch": 16.22622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2073790729045868,
      "orthogonal_weight": 0.1,
      "step": 4949,
      "total_loss": 0.6417384147644043,
      "weighted_orthogonal_loss": 0.02073790691792965
    },
    {
      "classification_loss": 0.5385098457336426,
      "epoch": 16.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20746080577373505,
      "orthogonal_weight": 0.1,
      "step": 4950,
      "total_loss": 0.5592558979988098,
      "weighted_orthogonal_loss": 0.020746080204844475
    },
    {
      "classification_loss": 0.5495302677154541,
      "epoch": 16.2327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2074863463640213,
      "orthogonal_weight": 0.1,
      "step": 4951,
      "total_loss": 0.5702788829803467,
      "weighted_orthogonal_loss": 0.02074863575398922
    },
    {
      "classification_loss": 0.6313859820365906,
      "epoch": 16.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20750437676906586,
      "orthogonal_weight": 0.1,
      "step": 4952,
      "total_loss": 0.6521364450454712,
      "weighted_orthogonal_loss": 0.020750438794493675
    },
    {
      "classification_loss": 0.6661205291748047,
      "epoch": 16.23934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20760859549045563,
      "orthogonal_weight": 0.1,
      "step": 4953,
      "total_loss": 0.6868813633918762,
      "weighted_orthogonal_loss": 0.020760860294103622
    },
    {
      "classification_loss": 0.5850937962532043,
      "epoch": 16.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20770715177059174,
      "orthogonal_weight": 0.1,
      "step": 4954,
      "total_loss": 0.6058645248413086,
      "weighted_orthogonal_loss": 0.020770715549588203
    },
    {
      "classification_loss": 0.6266643404960632,
      "epoch": 16.24590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20781825482845306,
      "orthogonal_weight": 0.1,
      "step": 4955,
      "total_loss": 0.6474461555480957,
      "weighted_orthogonal_loss": 0.020781826227903366
    },
    {
      "classification_loss": 0.653340220451355,
      "epoch": 16.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20791557431221008,
      "orthogonal_weight": 0.1,
      "step": 4956,
      "total_loss": 0.6741317510604858,
      "weighted_orthogonal_loss": 0.020791558548808098
    },
    {
      "classification_loss": 0.6612972021102905,
      "epoch": 16.25245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20800532400608063,
      "orthogonal_weight": 0.1,
      "step": 4957,
      "total_loss": 0.6820977330207825,
      "weighted_orthogonal_loss": 0.020800532773137093
    },
    {
      "classification_loss": 0.6095242500305176,
      "epoch": 16.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20809516310691833,
      "orthogonal_weight": 0.1,
      "step": 4958,
      "total_loss": 0.6303337812423706,
      "weighted_orthogonal_loss": 0.020809516310691833
    },
    {
      "classification_loss": 0.6333102583885193,
      "epoch": 16.25901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20817631483078003,
      "orthogonal_weight": 0.1,
      "step": 4959,
      "total_loss": 0.6541278958320618,
      "weighted_orthogonal_loss": 0.020817631855607033
    },
    {
      "classification_loss": 0.6161705851554871,
      "epoch": 16.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20822396874427795,
      "orthogonal_weight": 0.1,
      "step": 4960,
      "total_loss": 0.6369929909706116,
      "weighted_orthogonal_loss": 0.020822396501898766
    },
    {
      "classification_loss": 0.6238552927970886,
      "epoch": 16.2655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2082340568304062,
      "orthogonal_weight": 0.1,
      "step": 4961,
      "total_loss": 0.6446787118911743,
      "weighted_orthogonal_loss": 0.02082340605556965
    },
    {
      "classification_loss": 0.6326968669891357,
      "epoch": 16.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20824940502643585,
      "orthogonal_weight": 0.1,
      "step": 4962,
      "total_loss": 0.6535218358039856,
      "weighted_orthogonal_loss": 0.020824940875172615
    },
    {
      "classification_loss": 0.609157145023346,
      "epoch": 16.272131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20829589664936066,
      "orthogonal_weight": 0.1,
      "step": 4963,
      "total_loss": 0.6299867630004883,
      "weighted_orthogonal_loss": 0.020829590037465096
    },
    {
      "classification_loss": 0.6671311855316162,
      "epoch": 16.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20834441483020782,
      "orthogonal_weight": 0.1,
      "step": 4964,
      "total_loss": 0.6879656314849854,
      "weighted_orthogonal_loss": 0.020834442228078842
    },
    {
      "classification_loss": 0.6480410099029541,
      "epoch": 16.278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.208401158452034,
      "orthogonal_weight": 0.1,
      "step": 4965,
      "total_loss": 0.6688811182975769,
      "weighted_orthogonal_loss": 0.0208401158452034
    },
    {
      "classification_loss": 0.5727090239524841,
      "epoch": 16.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20844809710979462,
      "orthogonal_weight": 0.1,
      "step": 4966,
      "total_loss": 0.5935538411140442,
      "weighted_orthogonal_loss": 0.02084480971097946
    },
    {
      "classification_loss": 0.5779460072517395,
      "epoch": 16.285245901639342,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20862682163715363,
      "orthogonal_weight": 0.1,
      "step": 4967,
      "total_loss": 0.5988087058067322,
      "weighted_orthogonal_loss": 0.020862681791186333
    },
    {
      "classification_loss": 0.6863586902618408,
      "epoch": 16.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20888014137744904,
      "orthogonal_weight": 0.1,
      "step": 4968,
      "total_loss": 0.707246720790863,
      "weighted_orthogonal_loss": 0.020888013765215874
    },
    {
      "classification_loss": 0.6211444139480591,
      "epoch": 16.291803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091304063796997,
      "orthogonal_weight": 0.1,
      "step": 4969,
      "total_loss": 0.642057478427887,
      "weighted_orthogonal_loss": 0.02091304026544094
    },
    {
      "classification_loss": 0.6977391839027405,
      "epoch": 16.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20931017398834229,
      "orthogonal_weight": 0.1,
      "step": 4970,
      "total_loss": 0.7186701893806458,
      "weighted_orthogonal_loss": 0.020931018516421318
    },
    {
      "classification_loss": 0.6295732259750366,
      "epoch": 16.298360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20947130024433136,
      "orthogonal_weight": 0.1,
      "step": 4971,
      "total_loss": 0.650520384311676,
      "weighted_orthogonal_loss": 0.020947130396962166
    },
    {
      "classification_loss": 0.6301392912864685,
      "epoch": 16.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20960448682308197,
      "orthogonal_weight": 0.1,
      "step": 4972,
      "total_loss": 0.6510997414588928,
      "weighted_orthogonal_loss": 0.020960448309779167
    },
    {
      "classification_loss": 0.543904185295105,
      "epoch": 16.304918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096930295228958,
      "orthogonal_weight": 0.1,
      "step": 4973,
      "total_loss": 0.5648735165596008,
      "weighted_orthogonal_loss": 0.02096930332481861
    },
    {
      "classification_loss": 0.5972177386283875,
      "epoch": 16.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20981250703334808,
      "orthogonal_weight": 0.1,
      "step": 4974,
      "total_loss": 0.6181989908218384,
      "weighted_orthogonal_loss": 0.02098125033080578
    },
    {
      "classification_loss": 0.593870222568512,
      "epoch": 16.311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20995283126831055,
      "orthogonal_weight": 0.1,
      "step": 4975,
      "total_loss": 0.6148654818534851,
      "weighted_orthogonal_loss": 0.020995283499360085
    },
    {
      "classification_loss": 0.5976109504699707,
      "epoch": 16.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21001161634922028,
      "orthogonal_weight": 0.1,
      "step": 4976,
      "total_loss": 0.6186121106147766,
      "weighted_orthogonal_loss": 0.021001162007451057
    },
    {
      "classification_loss": 0.5308858156204224,
      "epoch": 16.318032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20998434722423553,
      "orthogonal_weight": 0.1,
      "step": 4977,
      "total_loss": 0.5518842339515686,
      "weighted_orthogonal_loss": 0.020998435094952583
    },
    {
      "classification_loss": 0.642326295375824,
      "epoch": 16.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20997129380702972,
      "orthogonal_weight": 0.1,
      "step": 4978,
      "total_loss": 0.6633234024047852,
      "weighted_orthogonal_loss": 0.020997129380702972
    },
    {
      "classification_loss": 0.6856814622879028,
      "epoch": 16.324590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099708616733551,
      "orthogonal_weight": 0.1,
      "step": 4979,
      "total_loss": 0.706678569316864,
      "weighted_orthogonal_loss": 0.02099708653986454
    },
    {
      "classification_loss": 0.5983803272247314,
      "epoch": 16.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20997081696987152,
      "orthogonal_weight": 0.1,
      "step": 4980,
      "total_loss": 0.6193774342536926,
      "weighted_orthogonal_loss": 0.02099708281457424
    },
    {
      "classification_loss": 0.5893567204475403,
      "epoch": 16.331147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20995397865772247,
      "orthogonal_weight": 0.1,
      "step": 4981,
      "total_loss": 0.610352098941803,
      "weighted_orthogonal_loss": 0.020995398983359337
    },
    {
      "classification_loss": 0.5641103386878967,
      "epoch": 16.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20989401638507843,
      "orthogonal_weight": 0.1,
      "step": 4982,
      "total_loss": 0.5850997567176819,
      "weighted_orthogonal_loss": 0.020989401265978813
    },
    {
      "classification_loss": 0.599723219871521,
      "epoch": 16.337704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20985856652259827,
      "orthogonal_weight": 0.1,
      "step": 4983,
      "total_loss": 0.6207090616226196,
      "weighted_orthogonal_loss": 0.020985856652259827
    },
    {
      "classification_loss": 0.6307494044303894,
      "epoch": 16.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20981690287590027,
      "orthogonal_weight": 0.1,
      "step": 4984,
      "total_loss": 0.6517310738563538,
      "weighted_orthogonal_loss": 0.020981689915060997
    },
    {
      "classification_loss": 0.6987158060073853,
      "epoch": 16.34426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20976769924163818,
      "orthogonal_weight": 0.1,
      "step": 4985,
      "total_loss": 0.719692587852478,
      "weighted_orthogonal_loss": 0.020976770669221878
    },
    {
      "classification_loss": 0.5551290512084961,
      "epoch": 16.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20971062779426575,
      "orthogonal_weight": 0.1,
      "step": 4986,
      "total_loss": 0.5761001110076904,
      "weighted_orthogonal_loss": 0.020971063524484634
    },
    {
      "classification_loss": 0.568966269493103,
      "epoch": 16.35081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20957304537296295,
      "orthogonal_weight": 0.1,
      "step": 4987,
      "total_loss": 0.5899235606193542,
      "weighted_orthogonal_loss": 0.020957304164767265
    },
    {
      "classification_loss": 0.6180557608604431,
      "epoch": 16.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2094428837299347,
      "orthogonal_weight": 0.1,
      "step": 4988,
      "total_loss": 0.6390000581741333,
      "weighted_orthogonal_loss": 0.02094428800046444
    },
    {
      "classification_loss": 0.5850921869277954,
      "epoch": 16.35737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20934675633907318,
      "orthogonal_weight": 0.1,
      "step": 4989,
      "total_loss": 0.6060268878936768,
      "weighted_orthogonal_loss": 0.020934676751494408
    },
    {
      "classification_loss": 0.5728582739830017,
      "epoch": 16.360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092677801847458,
      "orthogonal_weight": 0.1,
      "step": 4990,
      "total_loss": 0.5937850475311279,
      "weighted_orthogonal_loss": 0.02092677913606167
    },
    {
      "classification_loss": 0.6594613194465637,
      "epoch": 16.36393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20924019813537598,
      "orthogonal_weight": 0.1,
      "step": 4991,
      "total_loss": 0.6803853511810303,
      "weighted_orthogonal_loss": 0.020924020558595657
    },
    {
      "classification_loss": 0.7042810916900635,
      "epoch": 16.367213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092684954404831,
      "orthogonal_weight": 0.1,
      "step": 4992,
      "total_loss": 0.7252079248428345,
      "weighted_orthogonal_loss": 0.02092684991657734
    },
    {
      "classification_loss": 0.5764466524124146,
      "epoch": 16.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20926186442375183,
      "orthogonal_weight": 0.1,
      "step": 4993,
      "total_loss": 0.597372829914093,
      "weighted_orthogonal_loss": 0.020926186814904213
    },
    {
      "classification_loss": 0.6468634605407715,
      "epoch": 16.373770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092685103416443,
      "orthogonal_weight": 0.1,
      "step": 4994,
      "total_loss": 0.6677902936935425,
      "weighted_orthogonal_loss": 0.02092685177922249
    },
    {
      "classification_loss": 0.6370346546173096,
      "epoch": 16.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20926058292388916,
      "orthogonal_weight": 0.1,
      "step": 4995,
      "total_loss": 0.6579607129096985,
      "weighted_orthogonal_loss": 0.020926058292388916
    },
    {
      "classification_loss": 0.6240867376327515,
      "epoch": 16.380327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091856598854065,
      "orthogonal_weight": 0.1,
      "step": 4996,
      "total_loss": 0.6450052857398987,
      "weighted_orthogonal_loss": 0.02091856673359871
    },
    {
      "classification_loss": 0.6576476097106934,
      "epoch": 16.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209128737449646,
      "orthogonal_weight": 0.1,
      "step": 4997,
      "total_loss": 0.6785604953765869,
      "weighted_orthogonal_loss": 0.02091287449002266
    },
    {
      "classification_loss": 0.586753249168396,
      "epoch": 16.386885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20907361805438995,
      "orthogonal_weight": 0.1,
      "step": 4998,
      "total_loss": 0.6076605916023254,
      "weighted_orthogonal_loss": 0.020907362923026085
    },
    {
      "classification_loss": 0.5781774520874023,
      "epoch": 16.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20902065932750702,
      "orthogonal_weight": 0.1,
      "step": 4999,
      "total_loss": 0.5990794897079468,
      "weighted_orthogonal_loss": 0.020902065560221672
    },
    {
      "epoch": 16.39344262295082,
      "grad_norm": 2.0020508766174316,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 0.6382,
      "step": 5000
    },
    {
      "classification_loss": 0.5508506894111633,
      "epoch": 16.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091701328754425,
      "orthogonal_weight": 0.1,
      "step": 5000,
      "total_loss": 0.5717676877975464,
      "weighted_orthogonal_loss": 0.02091701328754425
    },
    {
      "classification_loss": 0.6256839632987976,
      "epoch": 16.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20930731296539307,
      "orthogonal_weight": 0.1,
      "step": 5001,
      "total_loss": 0.646614670753479,
      "weighted_orthogonal_loss": 0.020930731669068336
    },
    {
      "classification_loss": 0.5383952260017395,
      "epoch": 16.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20938880741596222,
      "orthogonal_weight": 0.1,
      "step": 5002,
      "total_loss": 0.5593340992927551,
      "weighted_orthogonal_loss": 0.020938880741596222
    },
    {
      "classification_loss": 0.648320734500885,
      "epoch": 16.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20945604145526886,
      "orthogonal_weight": 0.1,
      "step": 5003,
      "total_loss": 0.6692663431167603,
      "weighted_orthogonal_loss": 0.020945604890584946
    },
    {
      "classification_loss": 0.6359373927116394,
      "epoch": 16.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20949596166610718,
      "orthogonal_weight": 0.1,
      "step": 5004,
      "total_loss": 0.6568869948387146,
      "weighted_orthogonal_loss": 0.020949596539139748
    },
    {
      "classification_loss": 0.6464738845825195,
      "epoch": 16.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20950277149677277,
      "orthogonal_weight": 0.1,
      "step": 5005,
      "total_loss": 0.6674241423606873,
      "weighted_orthogonal_loss": 0.020950278267264366
    },
    {
      "classification_loss": 0.6931778788566589,
      "epoch": 16.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2094990760087967,
      "orthogonal_weight": 0.1,
      "step": 5006,
      "total_loss": 0.714127779006958,
      "weighted_orthogonal_loss": 0.02094990760087967
    },
    {
      "classification_loss": 0.673997700214386,
      "epoch": 16.41639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20948933064937592,
      "orthogonal_weight": 0.1,
      "step": 5007,
      "total_loss": 0.6949466466903687,
      "weighted_orthogonal_loss": 0.02094893343746662
    },
    {
      "classification_loss": 0.5604140758514404,
      "epoch": 16.41967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20947857201099396,
      "orthogonal_weight": 0.1,
      "step": 5008,
      "total_loss": 0.5813619494438171,
      "weighted_orthogonal_loss": 0.020947856828570366
    },
    {
      "classification_loss": 0.5975140333175659,
      "epoch": 16.42295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20947957038879395,
      "orthogonal_weight": 0.1,
      "step": 5009,
      "total_loss": 0.6184619665145874,
      "weighted_orthogonal_loss": 0.020947957411408424
    },
    {
      "classification_loss": 0.6420714855194092,
      "epoch": 16.42622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20946736633777618,
      "orthogonal_weight": 0.1,
      "step": 5010,
      "total_loss": 0.6630182266235352,
      "weighted_orthogonal_loss": 0.020946737378835678
    },
    {
      "classification_loss": 0.6381005644798279,
      "epoch": 16.42950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20946098864078522,
      "orthogonal_weight": 0.1,
      "step": 5011,
      "total_loss": 0.6590466499328613,
      "weighted_orthogonal_loss": 0.020946098491549492
    },
    {
      "classification_loss": 0.6545616388320923,
      "epoch": 16.432786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20945985615253448,
      "orthogonal_weight": 0.1,
      "step": 5012,
      "total_loss": 0.6755076050758362,
      "weighted_orthogonal_loss": 0.020945986732840538
    },
    {
      "classification_loss": 0.5944355726242065,
      "epoch": 16.43606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2094341516494751,
      "orthogonal_weight": 0.1,
      "step": 5013,
      "total_loss": 0.6153789758682251,
      "weighted_orthogonal_loss": 0.0209434162825346
    },
    {
      "classification_loss": 0.607035756111145,
      "epoch": 16.439344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20940864086151123,
      "orthogonal_weight": 0.1,
      "step": 5014,
      "total_loss": 0.6279765963554382,
      "weighted_orthogonal_loss": 0.020940864458680153
    },
    {
      "classification_loss": 0.6982908248901367,
      "epoch": 16.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20938608050346375,
      "orthogonal_weight": 0.1,
      "step": 5015,
      "total_loss": 0.7192294597625732,
      "weighted_orthogonal_loss": 0.020938608795404434
    },
    {
      "classification_loss": 0.6664681434631348,
      "epoch": 16.445901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093498855829239,
      "orthogonal_weight": 0.1,
      "step": 5016,
      "total_loss": 0.68740314245224,
      "weighted_orthogonal_loss": 0.02093498967587948
    },
    {
      "classification_loss": 0.6395109295845032,
      "epoch": 16.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093411237001419,
      "orthogonal_weight": 0.1,
      "step": 5017,
      "total_loss": 0.6604450345039368,
      "weighted_orthogonal_loss": 0.02093411237001419
    },
    {
      "classification_loss": 0.5519574880599976,
      "epoch": 16.452459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20934243500232697,
      "orthogonal_weight": 0.1,
      "step": 5018,
      "total_loss": 0.5728917121887207,
      "weighted_orthogonal_loss": 0.020934244617819786
    },
    {
      "classification_loss": 0.6462332606315613,
      "epoch": 16.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20938417315483093,
      "orthogonal_weight": 0.1,
      "step": 5019,
      "total_loss": 0.6671716570854187,
      "weighted_orthogonal_loss": 0.020938416942954063
    },
    {
      "classification_loss": 0.5688523650169373,
      "epoch": 16.459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20938490331172943,
      "orthogonal_weight": 0.1,
      "step": 5020,
      "total_loss": 0.5897908806800842,
      "weighted_orthogonal_loss": 0.020938491448760033
    },
    {
      "classification_loss": 0.6303209662437439,
      "epoch": 16.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20940068364143372,
      "orthogonal_weight": 0.1,
      "step": 5021,
      "total_loss": 0.651261031627655,
      "weighted_orthogonal_loss": 0.02094006910920143
    },
    {
      "classification_loss": 0.5886463522911072,
      "epoch": 16.465573770491805,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20940373837947845,
      "orthogonal_weight": 0.1,
      "step": 5022,
      "total_loss": 0.6095867156982422,
      "weighted_orthogonal_loss": 0.020940374583005905
    },
    {
      "classification_loss": 0.5676963329315186,
      "epoch": 16.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093847244977951,
      "orthogonal_weight": 0.1,
      "step": 5023,
      "total_loss": 0.5886347889900208,
      "weighted_orthogonal_loss": 0.02093847282230854
    },
    {
      "classification_loss": 0.5880709290504456,
      "epoch": 16.472131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093607783317566,
      "orthogonal_weight": 0.1,
      "step": 5024,
      "total_loss": 0.6090070009231567,
      "weighted_orthogonal_loss": 0.02093607746064663
    },
    {
      "classification_loss": 0.5679880380630493,
      "epoch": 16.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20927749574184418,
      "orthogonal_weight": 0.1,
      "step": 5025,
      "total_loss": 0.5889157652854919,
      "weighted_orthogonal_loss": 0.020927749574184418
    },
    {
      "classification_loss": 0.6242473721504211,
      "epoch": 16.478688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091999053955078,
      "orthogonal_weight": 0.1,
      "step": 5026,
      "total_loss": 0.645167350769043,
      "weighted_orthogonal_loss": 0.02091999165713787
    },
    {
      "classification_loss": 0.7112599015235901,
      "epoch": 16.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20914196968078613,
      "orthogonal_weight": 0.1,
      "step": 5027,
      "total_loss": 0.7321740984916687,
      "weighted_orthogonal_loss": 0.020914196968078613
    },
    {
      "classification_loss": 0.565182626247406,
      "epoch": 16.485245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20904000103473663,
      "orthogonal_weight": 0.1,
      "step": 5028,
      "total_loss": 0.586086630821228,
      "weighted_orthogonal_loss": 0.020904000848531723
    },
    {
      "classification_loss": 0.5779290199279785,
      "epoch": 16.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20895913243293762,
      "orthogonal_weight": 0.1,
      "step": 5029,
      "total_loss": 0.5988249182701111,
      "weighted_orthogonal_loss": 0.020895913243293762
    },
    {
      "classification_loss": 0.5944980382919312,
      "epoch": 16.491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20884962379932404,
      "orthogonal_weight": 0.1,
      "step": 5030,
      "total_loss": 0.6153830289840698,
      "weighted_orthogonal_loss": 0.020884962752461433
    },
    {
      "classification_loss": 0.64908367395401,
      "epoch": 16.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087302803993225,
      "orthogonal_weight": 0.1,
      "step": 5031,
      "total_loss": 0.6699566841125488,
      "weighted_orthogonal_loss": 0.02087302878499031
    },
    {
      "classification_loss": 0.6793968677520752,
      "epoch": 16.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20860888063907623,
      "orthogonal_weight": 0.1,
      "step": 5032,
      "total_loss": 0.7002577781677246,
      "weighted_orthogonal_loss": 0.020860888063907623
    },
    {
      "classification_loss": 0.5651301145553589,
      "epoch": 16.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20847180485725403,
      "orthogonal_weight": 0.1,
      "step": 5033,
      "total_loss": 0.58597731590271,
      "weighted_orthogonal_loss": 0.020847180858254433
    },
    {
      "classification_loss": 0.5865851640701294,
      "epoch": 16.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20835289359092712,
      "orthogonal_weight": 0.1,
      "step": 5034,
      "total_loss": 0.6074204444885254,
      "weighted_orthogonal_loss": 0.020835289731621742
    },
    {
      "classification_loss": 0.6401393413543701,
      "epoch": 16.508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2082589864730835,
      "orthogonal_weight": 0.1,
      "step": 5035,
      "total_loss": 0.6609652638435364,
      "weighted_orthogonal_loss": 0.02082589827477932
    },
    {
      "classification_loss": 0.6429294347763062,
      "epoch": 16.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20814457535743713,
      "orthogonal_weight": 0.1,
      "step": 5036,
      "total_loss": 0.6637439131736755,
      "weighted_orthogonal_loss": 0.020814457908272743
    },
    {
      "classification_loss": 0.6524440050125122,
      "epoch": 16.514754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20805087685585022,
      "orthogonal_weight": 0.1,
      "step": 5037,
      "total_loss": 0.6732490658760071,
      "weighted_orthogonal_loss": 0.02080508880317211
    },
    {
      "classification_loss": 0.6654105186462402,
      "epoch": 16.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20797868072986603,
      "orthogonal_weight": 0.1,
      "step": 5038,
      "total_loss": 0.6862083673477173,
      "weighted_orthogonal_loss": 0.020797869190573692
    },
    {
      "classification_loss": 0.6321436762809753,
      "epoch": 16.521311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20790798962116241,
      "orthogonal_weight": 0.1,
      "step": 5039,
      "total_loss": 0.6529344916343689,
      "weighted_orthogonal_loss": 0.02079079858958721
    },
    {
      "classification_loss": 0.6316365003585815,
      "epoch": 16.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20785319805145264,
      "orthogonal_weight": 0.1,
      "step": 5040,
      "total_loss": 0.6524218320846558,
      "weighted_orthogonal_loss": 0.020785320550203323
    },
    {
      "classification_loss": 0.5644903779029846,
      "epoch": 16.527868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2078183889389038,
      "orthogonal_weight": 0.1,
      "step": 5041,
      "total_loss": 0.5852721929550171,
      "weighted_orthogonal_loss": 0.02078183926641941
    },
    {
      "classification_loss": 0.6506332159042358,
      "epoch": 16.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2078116536140442,
      "orthogonal_weight": 0.1,
      "step": 5042,
      "total_loss": 0.6714143753051758,
      "weighted_orthogonal_loss": 0.02078116498887539
    },
    {
      "classification_loss": 0.5633110404014587,
      "epoch": 16.534426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207798033952713,
      "orthogonal_weight": 0.1,
      "step": 5043,
      "total_loss": 0.5840908288955688,
      "weighted_orthogonal_loss": 0.0207798033952713
    },
    {
      "classification_loss": 0.6831351518630981,
      "epoch": 16.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207783043384552,
      "orthogonal_weight": 0.1,
      "step": 5044,
      "total_loss": 0.7039134502410889,
      "weighted_orthogonal_loss": 0.02077830396592617
    },
    {
      "classification_loss": 0.6674848794937134,
      "epoch": 16.540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20773227512836456,
      "orthogonal_weight": 0.1,
      "step": 5045,
      "total_loss": 0.6882581114768982,
      "weighted_orthogonal_loss": 0.020773228257894516
    },
    {
      "classification_loss": 0.6480637192726135,
      "epoch": 16.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20767541229724884,
      "orthogonal_weight": 0.1,
      "step": 5046,
      "total_loss": 0.6688312888145447,
      "weighted_orthogonal_loss": 0.020767541602253914
    },
    {
      "classification_loss": 0.592084527015686,
      "epoch": 16.547540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2076161652803421,
      "orthogonal_weight": 0.1,
      "step": 5047,
      "total_loss": 0.6128461360931396,
      "weighted_orthogonal_loss": 0.02076161652803421
    },
    {
      "classification_loss": 0.6564025282859802,
      "epoch": 16.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20751896500587463,
      "orthogonal_weight": 0.1,
      "step": 5048,
      "total_loss": 0.6771544218063354,
      "weighted_orthogonal_loss": 0.020751897245645523
    },
    {
      "classification_loss": 0.6033346652984619,
      "epoch": 16.554098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20737680792808533,
      "orthogonal_weight": 0.1,
      "step": 5049,
      "total_loss": 0.6240723729133606,
      "weighted_orthogonal_loss": 0.020737681537866592
    },
    {
      "classification_loss": 0.5744146704673767,
      "epoch": 16.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2072720229625702,
      "orthogonal_weight": 0.1,
      "step": 5050,
      "total_loss": 0.5951418876647949,
      "weighted_orthogonal_loss": 0.02072720229625702
    },
    {
      "classification_loss": 0.576322615146637,
      "epoch": 16.560655737704916,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20716701447963715,
      "orthogonal_weight": 0.1,
      "step": 5051,
      "total_loss": 0.5970393419265747,
      "weighted_orthogonal_loss": 0.020716702565550804
    },
    {
      "classification_loss": 0.5585293769836426,
      "epoch": 16.56393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20705461502075195,
      "orthogonal_weight": 0.1,
      "step": 5052,
      "total_loss": 0.5792348384857178,
      "weighted_orthogonal_loss": 0.020705461502075195
    },
    {
      "classification_loss": 0.5994076728820801,
      "epoch": 16.567213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20694559812545776,
      "orthogonal_weight": 0.1,
      "step": 5053,
      "total_loss": 0.6201022267341614,
      "weighted_orthogonal_loss": 0.020694559440016747
    },
    {
      "classification_loss": 0.5291697978973389,
      "epoch": 16.57049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20685242116451263,
      "orthogonal_weight": 0.1,
      "step": 5054,
      "total_loss": 0.5498550534248352,
      "weighted_orthogonal_loss": 0.020685242488980293
    },
    {
      "classification_loss": 0.544641375541687,
      "epoch": 16.57377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20678873360157013,
      "orthogonal_weight": 0.1,
      "step": 5055,
      "total_loss": 0.5653202533721924,
      "weighted_orthogonal_loss": 0.020678874105215073
    },
    {
      "classification_loss": 0.6216056942939758,
      "epoch": 16.57704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20675155520439148,
      "orthogonal_weight": 0.1,
      "step": 5056,
      "total_loss": 0.6422808766365051,
      "weighted_orthogonal_loss": 0.020675156265497208
    },
    {
      "classification_loss": 0.5736383199691772,
      "epoch": 16.58032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20673343539237976,
      "orthogonal_weight": 0.1,
      "step": 5057,
      "total_loss": 0.5943116545677185,
      "weighted_orthogonal_loss": 0.020673343911767006
    },
    {
      "classification_loss": 0.6552794575691223,
      "epoch": 16.58360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20673274993896484,
      "orthogonal_weight": 0.1,
      "step": 5058,
      "total_loss": 0.6759527325630188,
      "weighted_orthogonal_loss": 0.020673274993896484
    },
    {
      "classification_loss": 0.6083236932754517,
      "epoch": 16.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20671899616718292,
      "orthogonal_weight": 0.1,
      "step": 5059,
      "total_loss": 0.6289955973625183,
      "weighted_orthogonal_loss": 0.020671900361776352
    },
    {
      "classification_loss": 0.5807356834411621,
      "epoch": 16.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20669986307621002,
      "orthogonal_weight": 0.1,
      "step": 5060,
      "total_loss": 0.601405680179596,
      "weighted_orthogonal_loss": 0.020669987425208092
    },
    {
      "classification_loss": 0.585405170917511,
      "epoch": 16.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20668910443782806,
      "orthogonal_weight": 0.1,
      "step": 5061,
      "total_loss": 0.6060740947723389,
      "weighted_orthogonal_loss": 0.020668910816311836
    },
    {
      "classification_loss": 0.6604265570640564,
      "epoch": 16.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20668955147266388,
      "orthogonal_weight": 0.1,
      "step": 5062,
      "total_loss": 0.681095540523529,
      "weighted_orthogonal_loss": 0.020668955519795418
    },
    {
      "classification_loss": 0.5663260817527771,
      "epoch": 16.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20672936737537384,
      "orthogonal_weight": 0.1,
      "step": 5063,
      "total_loss": 0.5869989991188049,
      "weighted_orthogonal_loss": 0.020672937855124474
    },
    {
      "classification_loss": 0.6059889793395996,
      "epoch": 16.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2067485749721527,
      "orthogonal_weight": 0.1,
      "step": 5064,
      "total_loss": 0.626663863658905,
      "weighted_orthogonal_loss": 0.02067485824227333
    },
    {
      "classification_loss": 0.6109861731529236,
      "epoch": 16.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20677916705608368,
      "orthogonal_weight": 0.1,
      "step": 5065,
      "total_loss": 0.6316640973091125,
      "weighted_orthogonal_loss": 0.020677916705608368
    },
    {
      "classification_loss": 0.5798109173774719,
      "epoch": 16.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20680172741413116,
      "orthogonal_weight": 0.1,
      "step": 5066,
      "total_loss": 0.6004911065101624,
      "weighted_orthogonal_loss": 0.020680172368884087
    },
    {
      "classification_loss": 0.6140763759613037,
      "epoch": 16.613114754098362,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2068282514810562,
      "orthogonal_weight": 0.1,
      "step": 5067,
      "total_loss": 0.6347591876983643,
      "weighted_orthogonal_loss": 0.02068282477557659
    },
    {
      "classification_loss": 0.6385989785194397,
      "epoch": 16.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20686650276184082,
      "orthogonal_weight": 0.1,
      "step": 5068,
      "total_loss": 0.6592856049537659,
      "weighted_orthogonal_loss": 0.020686650648713112
    },
    {
      "classification_loss": 0.6705081462860107,
      "epoch": 16.619672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20682282745838165,
      "orthogonal_weight": 0.1,
      "step": 5069,
      "total_loss": 0.6911904215812683,
      "weighted_orthogonal_loss": 0.020682282745838165
    },
    {
      "classification_loss": 0.6210532188415527,
      "epoch": 16.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20682553946971893,
      "orthogonal_weight": 0.1,
      "step": 5070,
      "total_loss": 0.6417357921600342,
      "weighted_orthogonal_loss": 0.020682554692029953
    },
    {
      "classification_loss": 0.6366114616394043,
      "epoch": 16.626229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20685751736164093,
      "orthogonal_weight": 0.1,
      "step": 5071,
      "total_loss": 0.6572971940040588,
      "weighted_orthogonal_loss": 0.020685752853751183
    },
    {
      "classification_loss": 0.5883292555809021,
      "epoch": 16.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20691417157649994,
      "orthogonal_weight": 0.1,
      "step": 5072,
      "total_loss": 0.6090206503868103,
      "weighted_orthogonal_loss": 0.020691417157649994
    },
    {
      "classification_loss": 0.6376307010650635,
      "epoch": 16.632786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20697514712810516,
      "orthogonal_weight": 0.1,
      "step": 5073,
      "total_loss": 0.6583282351493835,
      "weighted_orthogonal_loss": 0.020697515457868576
    },
    {
      "classification_loss": 0.6109879612922668,
      "epoch": 16.63606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2070026397705078,
      "orthogonal_weight": 0.1,
      "step": 5074,
      "total_loss": 0.6316882371902466,
      "weighted_orthogonal_loss": 0.02070026472210884
    },
    {
      "classification_loss": 0.628984808921814,
      "epoch": 16.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704007148742676,
      "orthogonal_weight": 0.1,
      "step": 5075,
      "total_loss": 0.6496888399124146,
      "weighted_orthogonal_loss": 0.020704006776213646
    },
    {
      "classification_loss": 0.6050707101821899,
      "epoch": 16.64262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20707033574581146,
      "orthogonal_weight": 0.1,
      "step": 5076,
      "total_loss": 0.6257777214050293,
      "weighted_orthogonal_loss": 0.020707033574581146
    },
    {
      "classification_loss": 0.597680926322937,
      "epoch": 16.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20711973309516907,
      "orthogonal_weight": 0.1,
      "step": 5077,
      "total_loss": 0.6183928847312927,
      "weighted_orthogonal_loss": 0.020711973309516907
    },
    {
      "classification_loss": 0.611724317073822,
      "epoch": 16.64918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20713746547698975,
      "orthogonal_weight": 0.1,
      "step": 5078,
      "total_loss": 0.632438063621521,
      "weighted_orthogonal_loss": 0.020713746547698975
    },
    {
      "classification_loss": 0.6547852754592896,
      "epoch": 16.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2070770561695099,
      "orthogonal_weight": 0.1,
      "step": 5079,
      "total_loss": 0.6754930019378662,
      "weighted_orthogonal_loss": 0.02070770598948002
    },
    {
      "classification_loss": 0.6350650191307068,
      "epoch": 16.65573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20703621208667755,
      "orthogonal_weight": 0.1,
      "step": 5080,
      "total_loss": 0.655768632888794,
      "weighted_orthogonal_loss": 0.020703621208667755
    },
    {
      "classification_loss": 0.5377770662307739,
      "epoch": 16.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20699836313724518,
      "orthogonal_weight": 0.1,
      "step": 5081,
      "total_loss": 0.5584769248962402,
      "weighted_orthogonal_loss": 0.020699836313724518
    },
    {
      "classification_loss": 0.5769702196121216,
      "epoch": 16.662295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20704394578933716,
      "orthogonal_weight": 0.1,
      "step": 5082,
      "total_loss": 0.5976746082305908,
      "weighted_orthogonal_loss": 0.020704394206404686
    },
    {
      "classification_loss": 0.664970874786377,
      "epoch": 16.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20707210898399353,
      "orthogonal_weight": 0.1,
      "step": 5083,
      "total_loss": 0.6856780648231506,
      "weighted_orthogonal_loss": 0.020707210525870323
    },
    {
      "classification_loss": 0.6160796284675598,
      "epoch": 16.668852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2071213275194168,
      "orthogonal_weight": 0.1,
      "step": 5084,
      "total_loss": 0.6367917656898499,
      "weighted_orthogonal_loss": 0.02071213349699974
    },
    {
      "classification_loss": 0.549315333366394,
      "epoch": 16.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20717263221740723,
      "orthogonal_weight": 0.1,
      "step": 5085,
      "total_loss": 0.5700325965881348,
      "weighted_orthogonal_loss": 0.020717263221740723
    },
    {
      "classification_loss": 0.6160566806793213,
      "epoch": 16.675409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20724469423294067,
      "orthogonal_weight": 0.1,
      "step": 5086,
      "total_loss": 0.6367811560630798,
      "weighted_orthogonal_loss": 0.020724469795823097
    },
    {
      "classification_loss": 0.6622215509414673,
      "epoch": 16.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2073623687028885,
      "orthogonal_weight": 0.1,
      "step": 5087,
      "total_loss": 0.6829577684402466,
      "weighted_orthogonal_loss": 0.02073623798787594
    },
    {
      "classification_loss": 0.5943720936775208,
      "epoch": 16.681967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20748062431812286,
      "orthogonal_weight": 0.1,
      "step": 5088,
      "total_loss": 0.6151201725006104,
      "weighted_orthogonal_loss": 0.020748062059283257
    },
    {
      "classification_loss": 0.6039309501647949,
      "epoch": 16.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20760293304920197,
      "orthogonal_weight": 0.1,
      "step": 5089,
      "total_loss": 0.6246912479400635,
      "weighted_orthogonal_loss": 0.020760294049978256
    },
    {
      "classification_loss": 0.5858084559440613,
      "epoch": 16.688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2077331244945526,
      "orthogonal_weight": 0.1,
      "step": 5090,
      "total_loss": 0.6065817475318909,
      "weighted_orthogonal_loss": 0.02077331207692623
    },
    {
      "classification_loss": 0.689030647277832,
      "epoch": 16.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20786119997501373,
      "orthogonal_weight": 0.1,
      "step": 5091,
      "total_loss": 0.7098167538642883,
      "weighted_orthogonal_loss": 0.020786119624972343
    },
    {
      "classification_loss": 0.6524938941001892,
      "epoch": 16.695081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20798079669475555,
      "orthogonal_weight": 0.1,
      "step": 5092,
      "total_loss": 0.6732919812202454,
      "weighted_orthogonal_loss": 0.020798079669475555
    },
    {
      "classification_loss": 0.6442475914955139,
      "epoch": 16.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20804646611213684,
      "orthogonal_weight": 0.1,
      "step": 5093,
      "total_loss": 0.6650522351264954,
      "weighted_orthogonal_loss": 0.020804647356271744
    },
    {
      "classification_loss": 0.6309026479721069,
      "epoch": 16.701639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20813429355621338,
      "orthogonal_weight": 0.1,
      "step": 5094,
      "total_loss": 0.6517160534858704,
      "weighted_orthogonal_loss": 0.020813429728150368
    },
    {
      "classification_loss": 0.5638802647590637,
      "epoch": 16.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2082265168428421,
      "orthogonal_weight": 0.1,
      "step": 5095,
      "total_loss": 0.5847029089927673,
      "weighted_orthogonal_loss": 0.02082265168428421
    },
    {
      "classification_loss": 0.5400971174240112,
      "epoch": 16.708196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20832480490207672,
      "orthogonal_weight": 0.1,
      "step": 5096,
      "total_loss": 0.5609295964241028,
      "weighted_orthogonal_loss": 0.020832480862736702
    },
    {
      "classification_loss": 0.538170576095581,
      "epoch": 16.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20845216512680054,
      "orthogonal_weight": 0.1,
      "step": 5097,
      "total_loss": 0.5590158104896545,
      "weighted_orthogonal_loss": 0.020845217630267143
    },
    {
      "classification_loss": 0.7105413675308228,
      "epoch": 16.714754098360658,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20853972434997559,
      "orthogonal_weight": 0.1,
      "step": 5098,
      "total_loss": 0.7313953638076782,
      "weighted_orthogonal_loss": 0.02085397206246853
    },
    {
      "classification_loss": 0.6202402114868164,
      "epoch": 16.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086283564567566,
      "orthogonal_weight": 0.1,
      "step": 5099,
      "total_loss": 0.6411030292510986,
      "weighted_orthogonal_loss": 0.02086283639073372
    },
    {
      "epoch": 16.721311475409838,
      "grad_norm": 11.618266105651855,
      "learning_rate": 3.336666666666667e-05,
      "loss": 0.6353,
      "step": 5100
    },
    {
      "classification_loss": 0.5993766784667969,
      "epoch": 16.721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20870567858219147,
      "orthogonal_weight": 0.1,
      "step": 5100,
      "total_loss": 0.6202472448348999,
      "weighted_orthogonal_loss": 0.020870568230748177
    },
    {
      "classification_loss": 0.5079820156097412,
      "epoch": 16.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20880010724067688,
      "orthogonal_weight": 0.1,
      "step": 5101,
      "total_loss": 0.5288619995117188,
      "weighted_orthogonal_loss": 0.020880011841654778
    },
    {
      "classification_loss": 0.6050728559494019,
      "epoch": 16.727868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20891104638576508,
      "orthogonal_weight": 0.1,
      "step": 5102,
      "total_loss": 0.6259639859199524,
      "weighted_orthogonal_loss": 0.020891105756163597
    },
    {
      "classification_loss": 0.6547068357467651,
      "epoch": 16.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.208995059132576,
      "orthogonal_weight": 0.1,
      "step": 5103,
      "total_loss": 0.675606369972229,
      "weighted_orthogonal_loss": 0.02089950628578663
    },
    {
      "classification_loss": 0.5662418007850647,
      "epoch": 16.7344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20909954607486725,
      "orthogonal_weight": 0.1,
      "step": 5104,
      "total_loss": 0.5871517658233643,
      "weighted_orthogonal_loss": 0.020909955725073814
    },
    {
      "classification_loss": 0.5610747933387756,
      "epoch": 16.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20919480919837952,
      "orthogonal_weight": 0.1,
      "step": 5105,
      "total_loss": 0.5819942951202393,
      "weighted_orthogonal_loss": 0.02091948129236698
    },
    {
      "classification_loss": 0.5312808752059937,
      "epoch": 16.74098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20931169390678406,
      "orthogonal_weight": 0.1,
      "step": 5106,
      "total_loss": 0.5522120594978333,
      "weighted_orthogonal_loss": 0.020931169390678406
    },
    {
      "classification_loss": 0.6404781937599182,
      "epoch": 16.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20940950512886047,
      "orthogonal_weight": 0.1,
      "step": 5107,
      "total_loss": 0.661419153213501,
      "weighted_orthogonal_loss": 0.020940950140357018
    },
    {
      "classification_loss": 0.6226540803909302,
      "epoch": 16.74754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20947371423244476,
      "orthogonal_weight": 0.1,
      "step": 5108,
      "total_loss": 0.6436014771461487,
      "weighted_orthogonal_loss": 0.020947372540831566
    },
    {
      "classification_loss": 0.6227028965950012,
      "epoch": 16.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2095051258802414,
      "orthogonal_weight": 0.1,
      "step": 5109,
      "total_loss": 0.643653392791748,
      "weighted_orthogonal_loss": 0.02095051296055317
    },
    {
      "classification_loss": 0.593396008014679,
      "epoch": 16.75409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20955459773540497,
      "orthogonal_weight": 0.1,
      "step": 5110,
      "total_loss": 0.6143514513969421,
      "weighted_orthogonal_loss": 0.020955460146069527
    },
    {
      "classification_loss": 0.6039241552352905,
      "epoch": 16.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20956610143184662,
      "orthogonal_weight": 0.1,
      "step": 5111,
      "total_loss": 0.6248807907104492,
      "weighted_orthogonal_loss": 0.02095661126077175
    },
    {
      "classification_loss": 0.5949894189834595,
      "epoch": 16.76065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2095697820186615,
      "orthogonal_weight": 0.1,
      "step": 5112,
      "total_loss": 0.6159464120864868,
      "weighted_orthogonal_loss": 0.02095697820186615
    },
    {
      "classification_loss": 0.5816430449485779,
      "epoch": 16.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20959211885929108,
      "orthogonal_weight": 0.1,
      "step": 5113,
      "total_loss": 0.6026022434234619,
      "weighted_orthogonal_loss": 0.020959211513400078
    },
    {
      "classification_loss": 0.5866002440452576,
      "epoch": 16.7672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20957764983177185,
      "orthogonal_weight": 0.1,
      "step": 5114,
      "total_loss": 0.607558012008667,
      "weighted_orthogonal_loss": 0.020957766100764275
    },
    {
      "classification_loss": 0.6832252740859985,
      "epoch": 16.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20955748856067657,
      "orthogonal_weight": 0.1,
      "step": 5115,
      "total_loss": 0.7041810154914856,
      "weighted_orthogonal_loss": 0.020955748856067657
    },
    {
      "classification_loss": 0.6002948880195618,
      "epoch": 16.77377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20952767133712769,
      "orthogonal_weight": 0.1,
      "step": 5116,
      "total_loss": 0.6212476491928101,
      "weighted_orthogonal_loss": 0.02095276676118374
    },
    {
      "classification_loss": 0.6345152258872986,
      "epoch": 16.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20953333377838135,
      "orthogonal_weight": 0.1,
      "step": 5117,
      "total_loss": 0.6554685831069946,
      "weighted_orthogonal_loss": 0.020953333005309105
    },
    {
      "classification_loss": 0.7170763611793518,
      "epoch": 16.78032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096118927001953,
      "orthogonal_weight": 0.1,
      "step": 5118,
      "total_loss": 0.7380375266075134,
      "weighted_orthogonal_loss": 0.02096118964254856
    },
    {
      "classification_loss": 0.6365403532981873,
      "epoch": 16.78360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20966368913650513,
      "orthogonal_weight": 0.1,
      "step": 5119,
      "total_loss": 0.6575067043304443,
      "weighted_orthogonal_loss": 0.020966369658708572
    },
    {
      "classification_loss": 0.6483041048049927,
      "epoch": 16.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20969048142433167,
      "orthogonal_weight": 0.1,
      "step": 5120,
      "total_loss": 0.6692731380462646,
      "weighted_orthogonal_loss": 0.020969048142433167
    },
    {
      "classification_loss": 0.5993762612342834,
      "epoch": 16.79016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20970702171325684,
      "orthogonal_weight": 0.1,
      "step": 5121,
      "total_loss": 0.6203469634056091,
      "weighted_orthogonal_loss": 0.020970702171325684
    },
    {
      "classification_loss": 0.7167741060256958,
      "epoch": 16.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096996158361435,
      "orthogonal_weight": 0.1,
      "step": 5122,
      "total_loss": 0.7377440929412842,
      "weighted_orthogonal_loss": 0.02096996270120144
    },
    {
      "classification_loss": 0.6330444812774658,
      "epoch": 16.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20970439910888672,
      "orthogonal_weight": 0.1,
      "step": 5123,
      "total_loss": 0.6540149450302124,
      "weighted_orthogonal_loss": 0.020970439538359642
    },
    {
      "classification_loss": 0.7048415541648865,
      "epoch": 16.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20969587564468384,
      "orthogonal_weight": 0.1,
      "step": 5124,
      "total_loss": 0.7258111238479614,
      "weighted_orthogonal_loss": 0.020969588309526443
    },
    {
      "classification_loss": 0.6520181894302368,
      "epoch": 16.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20968618988990784,
      "orthogonal_weight": 0.1,
      "step": 5125,
      "total_loss": 0.6729868054389954,
      "weighted_orthogonal_loss": 0.020968619734048843
    },
    {
      "classification_loss": 0.6978933215141296,
      "epoch": 16.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20965902507305145,
      "orthogonal_weight": 0.1,
      "step": 5126,
      "total_loss": 0.7188591957092285,
      "weighted_orthogonal_loss": 0.020965902134776115
    },
    {
      "classification_loss": 0.5931385159492493,
      "epoch": 16.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20961743593215942,
      "orthogonal_weight": 0.1,
      "step": 5127,
      "total_loss": 0.6141002774238586,
      "weighted_orthogonal_loss": 0.020961744710803032
    },
    {
      "classification_loss": 0.6040863990783691,
      "epoch": 16.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20958302915096283,
      "orthogonal_weight": 0.1,
      "step": 5128,
      "total_loss": 0.6250447034835815,
      "weighted_orthogonal_loss": 0.020958302542567253
    },
    {
      "classification_loss": 0.5591262578964233,
      "epoch": 16.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20954068005084991,
      "orthogonal_weight": 0.1,
      "step": 5129,
      "total_loss": 0.5800803303718567,
      "weighted_orthogonal_loss": 0.02095406875014305
    },
    {
      "classification_loss": 0.6462163925170898,
      "epoch": 16.81967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2094368040561676,
      "orthogonal_weight": 0.1,
      "step": 5130,
      "total_loss": 0.6671600937843323,
      "weighted_orthogonal_loss": 0.02094368077814579
    },
    {
      "classification_loss": 0.6472558379173279,
      "epoch": 16.82295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20933538675308228,
      "orthogonal_weight": 0.1,
      "step": 5131,
      "total_loss": 0.6681894063949585,
      "weighted_orthogonal_loss": 0.020933538675308228
    },
    {
      "classification_loss": 0.5859053134918213,
      "epoch": 16.82622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091868817806244,
      "orthogonal_weight": 0.1,
      "step": 5132,
      "total_loss": 0.6068239808082581,
      "weighted_orthogonal_loss": 0.02091868780553341
    },
    {
      "classification_loss": 0.6313208937644958,
      "epoch": 16.82950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20903262495994568,
      "orthogonal_weight": 0.1,
      "step": 5133,
      "total_loss": 0.6522241830825806,
      "weighted_orthogonal_loss": 0.020903263241052628
    },
    {
      "classification_loss": 0.5817198157310486,
      "epoch": 16.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20887155830860138,
      "orthogonal_weight": 0.1,
      "step": 5134,
      "total_loss": 0.6026069521903992,
      "weighted_orthogonal_loss": 0.020887156948447227
    },
    {
      "classification_loss": 0.6042428612709045,
      "epoch": 16.83606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20871713757514954,
      "orthogonal_weight": 0.1,
      "step": 5135,
      "total_loss": 0.6251145601272583,
      "weighted_orthogonal_loss": 0.020871713757514954
    },
    {
      "classification_loss": 0.6829856634140015,
      "epoch": 16.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085692584514618,
      "orthogonal_weight": 0.1,
      "step": 5136,
      "total_loss": 0.7038425803184509,
      "weighted_orthogonal_loss": 0.02085692621767521
    },
    {
      "classification_loss": 0.6460375189781189,
      "epoch": 16.84262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842942595481873,
      "orthogonal_weight": 0.1,
      "step": 5137,
      "total_loss": 0.6668804883956909,
      "weighted_orthogonal_loss": 0.020842943340539932
    },
    {
      "classification_loss": 0.5753609538078308,
      "epoch": 16.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20831561088562012,
      "orthogonal_weight": 0.1,
      "step": 5138,
      "total_loss": 0.5961925387382507,
      "weighted_orthogonal_loss": 0.020831560716032982
    },
    {
      "classification_loss": 0.680604100227356,
      "epoch": 16.84918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20820799469947815,
      "orthogonal_weight": 0.1,
      "step": 5139,
      "total_loss": 0.7014248967170715,
      "weighted_orthogonal_loss": 0.020820800215005875
    },
    {
      "classification_loss": 0.5618764758110046,
      "epoch": 16.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2081255465745926,
      "orthogonal_weight": 0.1,
      "step": 5140,
      "total_loss": 0.5826890468597412,
      "weighted_orthogonal_loss": 0.02081255428493023
    },
    {
      "classification_loss": 0.6591193675994873,
      "epoch": 16.855737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20804010331630707,
      "orthogonal_weight": 0.1,
      "step": 5141,
      "total_loss": 0.6799233555793762,
      "weighted_orthogonal_loss": 0.020804010331630707
    },
    {
      "classification_loss": 0.5846565365791321,
      "epoch": 16.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20797188580036163,
      "orthogonal_weight": 0.1,
      "step": 5142,
      "total_loss": 0.6054537296295166,
      "weighted_orthogonal_loss": 0.020797189325094223
    },
    {
      "classification_loss": 0.5585991144180298,
      "epoch": 16.862295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20796558260917664,
      "orthogonal_weight": 0.1,
      "step": 5143,
      "total_loss": 0.5793956518173218,
      "weighted_orthogonal_loss": 0.020796557888388634
    },
    {
      "classification_loss": 0.5786438584327698,
      "epoch": 16.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20792537927627563,
      "orthogonal_weight": 0.1,
      "step": 5144,
      "total_loss": 0.5994364023208618,
      "weighted_orthogonal_loss": 0.020792538300156593
    },
    {
      "classification_loss": 0.6040967702865601,
      "epoch": 16.868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20788010954856873,
      "orthogonal_weight": 0.1,
      "step": 5145,
      "total_loss": 0.6248847842216492,
      "weighted_orthogonal_loss": 0.020788012072443962
    },
    {
      "classification_loss": 0.6036792397499084,
      "epoch": 16.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20785528421401978,
      "orthogonal_weight": 0.1,
      "step": 5146,
      "total_loss": 0.624464750289917,
      "weighted_orthogonal_loss": 0.020785529166460037
    },
    {
      "classification_loss": 0.6465128064155579,
      "epoch": 16.875409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20781895518302917,
      "orthogonal_weight": 0.1,
      "step": 5147,
      "total_loss": 0.6672946810722351,
      "weighted_orthogonal_loss": 0.020781895145773888
    },
    {
      "classification_loss": 0.5566989779472351,
      "epoch": 16.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20779013633728027,
      "orthogonal_weight": 0.1,
      "step": 5148,
      "total_loss": 0.5774779915809631,
      "weighted_orthogonal_loss": 0.020779013633728027
    },
    {
      "classification_loss": 0.6057711839675903,
      "epoch": 16.881967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2077689915895462,
      "orthogonal_weight": 0.1,
      "step": 5149,
      "total_loss": 0.6265481114387512,
      "weighted_orthogonal_loss": 0.02077689953148365
    },
    {
      "classification_loss": 0.5449550151824951,
      "epoch": 16.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20776133239269257,
      "orthogonal_weight": 0.1,
      "step": 5150,
      "total_loss": 0.5657311677932739,
      "weighted_orthogonal_loss": 0.020776133984327316
    },
    {
      "classification_loss": 0.6393197178840637,
      "epoch": 16.888524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20776985585689545,
      "orthogonal_weight": 0.1,
      "step": 5151,
      "total_loss": 0.6600967049598694,
      "weighted_orthogonal_loss": 0.020776985213160515
    },
    {
      "classification_loss": 0.5691369771957397,
      "epoch": 16.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2077890932559967,
      "orthogonal_weight": 0.1,
      "step": 5152,
      "total_loss": 0.5899158716201782,
      "weighted_orthogonal_loss": 0.02077890932559967
    },
    {
      "classification_loss": 0.5887901186943054,
      "epoch": 16.895081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20782151818275452,
      "orthogonal_weight": 0.1,
      "step": 5153,
      "total_loss": 0.6095722913742065,
      "weighted_orthogonal_loss": 0.02078215219080448
    },
    {
      "classification_loss": 0.5642470717430115,
      "epoch": 16.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20783430337905884,
      "orthogonal_weight": 0.1,
      "step": 5154,
      "total_loss": 0.5850304961204529,
      "weighted_orthogonal_loss": 0.020783429965376854
    },
    {
      "classification_loss": 0.6443339586257935,
      "epoch": 16.901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20785173773765564,
      "orthogonal_weight": 0.1,
      "step": 5155,
      "total_loss": 0.6651191115379333,
      "weighted_orthogonal_loss": 0.020785173401236534
    },
    {
      "classification_loss": 0.5898183584213257,
      "epoch": 16.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20787902176380157,
      "orthogonal_weight": 0.1,
      "step": 5156,
      "total_loss": 0.6106062531471252,
      "weighted_orthogonal_loss": 0.020787902176380157
    },
    {
      "classification_loss": 0.5182791948318481,
      "epoch": 16.908196721311477,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2078918069601059,
      "orthogonal_weight": 0.1,
      "step": 5157,
      "total_loss": 0.5390684008598328,
      "weighted_orthogonal_loss": 0.02078918181359768
    },
    {
      "classification_loss": 0.6158789992332458,
      "epoch": 16.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20787417888641357,
      "orthogonal_weight": 0.1,
      "step": 5158,
      "total_loss": 0.6366664171218872,
      "weighted_orthogonal_loss": 0.020787417888641357
    },
    {
      "classification_loss": 0.611671507358551,
      "epoch": 16.914754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20787174999713898,
      "orthogonal_weight": 0.1,
      "step": 5159,
      "total_loss": 0.6324586868286133,
      "weighted_orthogonal_loss": 0.020787175744771957
    },
    {
      "classification_loss": 0.5311596989631653,
      "epoch": 16.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.207868292927742,
      "orthogonal_weight": 0.1,
      "step": 5160,
      "total_loss": 0.5519465208053589,
      "weighted_orthogonal_loss": 0.0207868292927742
    },
    {
      "classification_loss": 0.6440777778625488,
      "epoch": 16.921311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20787377655506134,
      "orthogonal_weight": 0.1,
      "step": 5161,
      "total_loss": 0.6648651361465454,
      "weighted_orthogonal_loss": 0.020787378773093224
    },
    {
      "classification_loss": 0.5801907777786255,
      "epoch": 16.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20788834989070892,
      "orthogonal_weight": 0.1,
      "step": 5162,
      "total_loss": 0.6009796261787415,
      "weighted_orthogonal_loss": 0.020788835361599922
    },
    {
      "classification_loss": 0.6864900588989258,
      "epoch": 16.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079133540391922,
      "orthogonal_weight": 0.1,
      "step": 5163,
      "total_loss": 0.7072814106941223,
      "weighted_orthogonal_loss": 0.02079133503139019
    },
    {
      "classification_loss": 0.658108651638031,
      "epoch": 16.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20792455971240997,
      "orthogonal_weight": 0.1,
      "step": 5164,
      "total_loss": 0.6789011359214783,
      "weighted_orthogonal_loss": 0.020792456343770027
    },
    {
      "classification_loss": 0.618829071521759,
      "epoch": 16.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20792432129383087,
      "orthogonal_weight": 0.1,
      "step": 5165,
      "total_loss": 0.6396214962005615,
      "weighted_orthogonal_loss": 0.020792432129383087
    },
    {
      "classification_loss": 0.6359203457832336,
      "epoch": 16.937704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20795007050037384,
      "orthogonal_weight": 0.1,
      "step": 5166,
      "total_loss": 0.6567153334617615,
      "weighted_orthogonal_loss": 0.020795008167624474
    },
    {
      "classification_loss": 0.5471760630607605,
      "epoch": 16.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20796923339366913,
      "orthogonal_weight": 0.1,
      "step": 5167,
      "total_loss": 0.5679729580879211,
      "weighted_orthogonal_loss": 0.020796922966837883
    },
    {
      "classification_loss": 0.6607544422149658,
      "epoch": 16.944262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2079959660768509,
      "orthogonal_weight": 0.1,
      "step": 5168,
      "total_loss": 0.6815540194511414,
      "weighted_orthogonal_loss": 0.02079959772527218
    },
    {
      "classification_loss": 0.6471209526062012,
      "epoch": 16.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2080143392086029,
      "orthogonal_weight": 0.1,
      "step": 5169,
      "total_loss": 0.6679223775863647,
      "weighted_orthogonal_loss": 0.02080143429338932
    },
    {
      "classification_loss": 0.5907338261604309,
      "epoch": 16.950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2080303281545639,
      "orthogonal_weight": 0.1,
      "step": 5170,
      "total_loss": 0.6115368604660034,
      "weighted_orthogonal_loss": 0.02080303244292736
    },
    {
      "classification_loss": 0.5735197067260742,
      "epoch": 16.95409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20804046094417572,
      "orthogonal_weight": 0.1,
      "step": 5171,
      "total_loss": 0.5943237543106079,
      "weighted_orthogonal_loss": 0.020804045721888542
    },
    {
      "classification_loss": 0.7533671855926514,
      "epoch": 16.957377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20809762179851532,
      "orthogonal_weight": 0.1,
      "step": 5172,
      "total_loss": 0.7741769552230835,
      "weighted_orthogonal_loss": 0.020809762179851532
    },
    {
      "classification_loss": 0.6545354723930359,
      "epoch": 16.96065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2081398367881775,
      "orthogonal_weight": 0.1,
      "step": 5173,
      "total_loss": 0.6753494739532471,
      "weighted_orthogonal_loss": 0.02081398479640484
    },
    {
      "classification_loss": 0.6329357624053955,
      "epoch": 16.963934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2081781029701233,
      "orthogonal_weight": 0.1,
      "step": 5174,
      "total_loss": 0.6537535786628723,
      "weighted_orthogonal_loss": 0.02081781066954136
    },
    {
      "classification_loss": 0.6307634711265564,
      "epoch": 16.9672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20820604264736176,
      "orthogonal_weight": 0.1,
      "step": 5175,
      "total_loss": 0.6515840888023376,
      "weighted_orthogonal_loss": 0.020820604637265205
    },
    {
      "classification_loss": 0.5881576538085938,
      "epoch": 16.970491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20823974907398224,
      "orthogonal_weight": 0.1,
      "step": 5176,
      "total_loss": 0.6089816093444824,
      "weighted_orthogonal_loss": 0.020823976024985313
    },
    {
      "classification_loss": 0.5256726741790771,
      "epoch": 16.97377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20829395949840546,
      "orthogonal_weight": 0.1,
      "step": 5177,
      "total_loss": 0.5465020537376404,
      "weighted_orthogonal_loss": 0.020829396322369576
    },
    {
      "classification_loss": 0.5715144872665405,
      "epoch": 16.977049180327867,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20838463306427002,
      "orthogonal_weight": 0.1,
      "step": 5178,
      "total_loss": 0.5923529267311096,
      "weighted_orthogonal_loss": 0.020838463678956032
    },
    {
      "classification_loss": 0.5846229195594788,
      "epoch": 16.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084691822528839,
      "orthogonal_weight": 0.1,
      "step": 5179,
      "total_loss": 0.605469822883606,
      "weighted_orthogonal_loss": 0.02084691822528839
    },
    {
      "classification_loss": 0.6176389455795288,
      "epoch": 16.983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085161954164505,
      "orthogonal_weight": 0.1,
      "step": 5180,
      "total_loss": 0.6384905576705933,
      "weighted_orthogonal_loss": 0.02085161954164505
    },
    {
      "classification_loss": 0.6627376079559326,
      "epoch": 16.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20857782661914825,
      "orthogonal_weight": 0.1,
      "step": 5181,
      "total_loss": 0.6835954189300537,
      "weighted_orthogonal_loss": 0.020857783034443855
    },
    {
      "classification_loss": 0.5914762020111084,
      "epoch": 16.990163934426228,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086365967988968,
      "orthogonal_weight": 0.1,
      "step": 5182,
      "total_loss": 0.6123398542404175,
      "weighted_orthogonal_loss": 0.02086365967988968
    },
    {
      "classification_loss": 0.5951086282730103,
      "epoch": 16.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867294073104858,
      "orthogonal_weight": 0.1,
      "step": 5183,
      "total_loss": 0.6159759163856506,
      "weighted_orthogonal_loss": 0.02086729370057583
    },
    {
      "classification_loss": 0.6137885451316833,
      "epoch": 16.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20868714153766632,
      "orthogonal_weight": 0.1,
      "step": 5184,
      "total_loss": 0.6346572637557983,
      "weighted_orthogonal_loss": 0.020868714898824692
    },
    {
      "classification_loss": 0.7240321040153503,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.7449018359184265,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7044864892959595,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.7253562211990356,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7147933840751648,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.735663115978241,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7370570302009583,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.7579267621040344,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7180295586585999,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.738899290561676,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.723365068435669,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.7442348003387451,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7098649740219116,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.7307347059249878,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.7308902144432068,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.751759946346283,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.474,
      "eval_f1": 0.4232456140350877,
      "eval_loss": 0.7409307956695557,
      "eval_precision": 0.6678200692041523,
      "eval_recall": 0.3097913322632424,
      "eval_runtime": 6.1751,
      "eval_samples_per_second": 161.94,
      "eval_steps_per_second": 1.296,
      "step": 5185
    },
    {
      "classification_loss": 0.6045868992805481,
      "epoch": 17.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20869721472263336,
      "orthogonal_weight": 0.1,
      "step": 5185,
      "total_loss": 0.6254566311836243,
      "weighted_orthogonal_loss": 0.020869722589850426
    },
    {
      "classification_loss": 0.5410327911376953,
      "epoch": 17.003278688524592,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20872487127780914,
      "orthogonal_weight": 0.1,
      "step": 5186,
      "total_loss": 0.5619052648544312,
      "weighted_orthogonal_loss": 0.020872486755251884
    },
    {
      "classification_loss": 0.6098892688751221,
      "epoch": 17.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087935358285904,
      "orthogonal_weight": 0.1,
      "step": 5187,
      "total_loss": 0.6307685971260071,
      "weighted_orthogonal_loss": 0.0208793543279171
    },
    {
      "classification_loss": 0.5715572834014893,
      "epoch": 17.009836065573772,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2088707983493805,
      "orthogonal_weight": 0.1,
      "step": 5188,
      "total_loss": 0.5924443602561951,
      "weighted_orthogonal_loss": 0.02088708057999611
    },
    {
      "classification_loss": 0.6214680075645447,
      "epoch": 17.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20895633101463318,
      "orthogonal_weight": 0.1,
      "step": 5189,
      "total_loss": 0.6423636674880981,
      "weighted_orthogonal_loss": 0.020895633846521378
    },
    {
      "classification_loss": 0.6138273477554321,
      "epoch": 17.016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20904190838336945,
      "orthogonal_weight": 0.1,
      "step": 5190,
      "total_loss": 0.6347315311431885,
      "weighted_orthogonal_loss": 0.020904190838336945
    },
    {
      "classification_loss": 0.6393383145332336,
      "epoch": 17.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20909877121448517,
      "orthogonal_weight": 0.1,
      "step": 5191,
      "total_loss": 0.6602482199668884,
      "weighted_orthogonal_loss": 0.020909877493977547
    },
    {
      "classification_loss": 0.5725703835487366,
      "epoch": 17.022950819672133,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20914454758167267,
      "orthogonal_weight": 0.1,
      "step": 5192,
      "total_loss": 0.5934848189353943,
      "weighted_orthogonal_loss": 0.020914455875754356
    },
    {
      "classification_loss": 0.5812237858772278,
      "epoch": 17.02622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20924806594848633,
      "orthogonal_weight": 0.1,
      "step": 5193,
      "total_loss": 0.6021485924720764,
      "weighted_orthogonal_loss": 0.020924806594848633
    },
    {
      "classification_loss": 0.5727120637893677,
      "epoch": 17.029508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093394547700882,
      "orthogonal_weight": 0.1,
      "step": 5194,
      "total_loss": 0.5936459898948669,
      "weighted_orthogonal_loss": 0.02093394659459591
    },
    {
      "classification_loss": 0.6275976300239563,
      "epoch": 17.0327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209406778216362,
      "orthogonal_weight": 0.1,
      "step": 5195,
      "total_loss": 0.6485382914543152,
      "weighted_orthogonal_loss": 0.02094067819416523
    },
    {
      "classification_loss": 0.6093268394470215,
      "epoch": 17.036065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20945952832698822,
      "orthogonal_weight": 0.1,
      "step": 5196,
      "total_loss": 0.6302728056907654,
      "weighted_orthogonal_loss": 0.020945953205227852
    },
    {
      "classification_loss": 0.5297271013259888,
      "epoch": 17.03934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209494948387146,
      "orthogonal_weight": 0.1,
      "step": 5197,
      "total_loss": 0.5506765842437744,
      "weighted_orthogonal_loss": 0.02094949595630169
    },
    {
      "classification_loss": 0.6808351874351501,
      "epoch": 17.042622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209588423371315,
      "orthogonal_weight": 0.1,
      "step": 5198,
      "total_loss": 0.7017940282821655,
      "weighted_orthogonal_loss": 0.02095884270966053
    },
    {
      "classification_loss": 0.5854487419128418,
      "epoch": 17.04590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20966392755508423,
      "orthogonal_weight": 0.1,
      "step": 5199,
      "total_loss": 0.6064151525497437,
      "weighted_orthogonal_loss": 0.020966393873095512
    },
    {
      "epoch": 17.049180327868854,
      "grad_norm": 18.63687515258789,
      "learning_rate": 3.0033333333333336e-05,
      "loss": 0.6312,
      "step": 5200
    },
    {
      "classification_loss": 0.5166268348693848,
      "epoch": 17.049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20972859859466553,
      "orthogonal_weight": 0.1,
      "step": 5200,
      "total_loss": 0.5375996828079224,
      "weighted_orthogonal_loss": 0.020972860977053642
    },
    {
      "classification_loss": 0.636967122554779,
      "epoch": 17.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2097829133272171,
      "orthogonal_weight": 0.1,
      "step": 5201,
      "total_loss": 0.6579453945159912,
      "weighted_orthogonal_loss": 0.0209782924503088
    },
    {
      "classification_loss": 0.6040589809417725,
      "epoch": 17.055737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20981836318969727,
      "orthogonal_weight": 0.1,
      "step": 5202,
      "total_loss": 0.6250408291816711,
      "weighted_orthogonal_loss": 0.020981837064027786
    },
    {
      "classification_loss": 0.6121731400489807,
      "epoch": 17.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20986317098140717,
      "orthogonal_weight": 0.1,
      "step": 5203,
      "total_loss": 0.6331594586372375,
      "weighted_orthogonal_loss": 0.020986316725611687
    },
    {
      "classification_loss": 0.5604734420776367,
      "epoch": 17.062295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20992523431777954,
      "orthogonal_weight": 0.1,
      "step": 5204,
      "total_loss": 0.5814659595489502,
      "weighted_orthogonal_loss": 0.020992523059248924
    },
    {
      "classification_loss": 0.7061488628387451,
      "epoch": 17.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100517749786377,
      "orthogonal_weight": 0.1,
      "step": 5205,
      "total_loss": 0.727154016494751,
      "weighted_orthogonal_loss": 0.0210051778703928
    },
    {
      "classification_loss": 0.6425321102142334,
      "epoch": 17.068852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101624757051468,
      "orthogonal_weight": 0.1,
      "step": 5206,
      "total_loss": 0.6635483503341675,
      "weighted_orthogonal_loss": 0.02101624757051468
    },
    {
      "classification_loss": 0.6274775266647339,
      "epoch": 17.072131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21026815474033356,
      "orthogonal_weight": 0.1,
      "step": 5207,
      "total_loss": 0.6485043168067932,
      "weighted_orthogonal_loss": 0.021026816219091415
    },
    {
      "classification_loss": 0.5840221047401428,
      "epoch": 17.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21035701036453247,
      "orthogonal_weight": 0.1,
      "step": 5208,
      "total_loss": 0.6050578355789185,
      "weighted_orthogonal_loss": 0.021035701036453247
    },
    {
      "classification_loss": 0.6346802711486816,
      "epoch": 17.078688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21042309701442719,
      "orthogonal_weight": 0.1,
      "step": 5209,
      "total_loss": 0.6557225584983826,
      "weighted_orthogonal_loss": 0.02104230970144272
    },
    {
      "classification_loss": 0.6718130111694336,
      "epoch": 17.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21047882735729218,
      "orthogonal_weight": 0.1,
      "step": 5210,
      "total_loss": 0.6928609013557434,
      "weighted_orthogonal_loss": 0.021047882735729218
    },
    {
      "classification_loss": 0.5686061978340149,
      "epoch": 17.085245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105093151330948,
      "orthogonal_weight": 0.1,
      "step": 5211,
      "total_loss": 0.5896571278572083,
      "weighted_orthogonal_loss": 0.02105093188583851
    },
    {
      "classification_loss": 0.5749422311782837,
      "epoch": 17.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21053318679332733,
      "orthogonal_weight": 0.1,
      "step": 5212,
      "total_loss": 0.5959955453872681,
      "weighted_orthogonal_loss": 0.021053319796919823
    },
    {
      "classification_loss": 0.6436275243759155,
      "epoch": 17.091803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21055467426776886,
      "orthogonal_weight": 0.1,
      "step": 5213,
      "total_loss": 0.6646829843521118,
      "weighted_orthogonal_loss": 0.021055467426776886
    },
    {
      "classification_loss": 0.5818844437599182,
      "epoch": 17.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21056820452213287,
      "orthogonal_weight": 0.1,
      "step": 5214,
      "total_loss": 0.6029412746429443,
      "weighted_orthogonal_loss": 0.021056821569800377
    },
    {
      "classification_loss": 0.6150912046432495,
      "epoch": 17.098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105884552001953,
      "orthogonal_weight": 0.1,
      "step": 5215,
      "total_loss": 0.636150062084198,
      "weighted_orthogonal_loss": 0.02105884626507759
    },
    {
      "classification_loss": 0.5431102514266968,
      "epoch": 17.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21061809360980988,
      "orthogonal_weight": 0.1,
      "step": 5216,
      "total_loss": 0.564172089099884,
      "weighted_orthogonal_loss": 0.021061809733510017
    },
    {
      "classification_loss": 0.5785496234893799,
      "epoch": 17.104918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21065862476825714,
      "orthogonal_weight": 0.1,
      "step": 5217,
      "total_loss": 0.5996155142784119,
      "weighted_orthogonal_loss": 0.021065862849354744
    },
    {
      "classification_loss": 0.6717599034309387,
      "epoch": 17.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21067984402179718,
      "orthogonal_weight": 0.1,
      "step": 5218,
      "total_loss": 0.6928278803825378,
      "weighted_orthogonal_loss": 0.021067984402179718
    },
    {
      "classification_loss": 0.5888983607292175,
      "epoch": 17.111475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21068701148033142,
      "orthogonal_weight": 0.1,
      "step": 5219,
      "total_loss": 0.609967052936554,
      "weighted_orthogonal_loss": 0.021068701520562172
    },
    {
      "classification_loss": 0.5522478818893433,
      "epoch": 17.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21068240702152252,
      "orthogonal_weight": 0.1,
      "step": 5220,
      "total_loss": 0.5733160972595215,
      "weighted_orthogonal_loss": 0.021068241447210312
    },
    {
      "classification_loss": 0.6367982029914856,
      "epoch": 17.118032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21072439849376678,
      "orthogonal_weight": 0.1,
      "step": 5221,
      "total_loss": 0.6578706502914429,
      "weighted_orthogonal_loss": 0.02107243984937668
    },
    {
      "classification_loss": 0.6004242897033691,
      "epoch": 17.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21075305342674255,
      "orthogonal_weight": 0.1,
      "step": 5222,
      "total_loss": 0.6214995980262756,
      "weighted_orthogonal_loss": 0.021075306460261345
    },
    {
      "classification_loss": 0.5307871699333191,
      "epoch": 17.124590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082693338394165,
      "orthogonal_weight": 0.1,
      "step": 5223,
      "total_loss": 0.5518698692321777,
      "weighted_orthogonal_loss": 0.021082693710923195
    },
    {
      "classification_loss": 0.6052944660186768,
      "epoch": 17.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21096277236938477,
      "orthogonal_weight": 0.1,
      "step": 5224,
      "total_loss": 0.6263907551765442,
      "weighted_orthogonal_loss": 0.021096277981996536
    },
    {
      "classification_loss": 0.6254328489303589,
      "epoch": 17.131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21106326580047607,
      "orthogonal_weight": 0.1,
      "step": 5225,
      "total_loss": 0.6465391516685486,
      "weighted_orthogonal_loss": 0.021106326952576637
    },
    {
      "classification_loss": 0.6292654275894165,
      "epoch": 17.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21113139390945435,
      "orthogonal_weight": 0.1,
      "step": 5226,
      "total_loss": 0.6503785848617554,
      "weighted_orthogonal_loss": 0.021113140508532524
    },
    {
      "classification_loss": 0.575802743434906,
      "epoch": 17.137704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21118752658367157,
      "orthogonal_weight": 0.1,
      "step": 5227,
      "total_loss": 0.5969215035438538,
      "weighted_orthogonal_loss": 0.021118752658367157
    },
    {
      "classification_loss": 0.6436758637428284,
      "epoch": 17.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21124735474586487,
      "orthogonal_weight": 0.1,
      "step": 5228,
      "total_loss": 0.6648005843162537,
      "weighted_orthogonal_loss": 0.021124735474586487
    },
    {
      "classification_loss": 0.6395196318626404,
      "epoch": 17.14426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21128816902637482,
      "orthogonal_weight": 0.1,
      "step": 5229,
      "total_loss": 0.6606484651565552,
      "weighted_orthogonal_loss": 0.021128816530108452
    },
    {
      "classification_loss": 0.5789273977279663,
      "epoch": 17.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113262265920639,
      "orthogonal_weight": 0.1,
      "step": 5230,
      "total_loss": 0.6000600457191467,
      "weighted_orthogonal_loss": 0.02113262377679348
    },
    {
      "classification_loss": 0.7010990381240845,
      "epoch": 17.15081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113211303949356,
      "orthogonal_weight": 0.1,
      "step": 5231,
      "total_loss": 0.7222311496734619,
      "weighted_orthogonal_loss": 0.02113211341202259
    },
    {
      "classification_loss": 0.5798215270042419,
      "epoch": 17.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113184779882431,
      "orthogonal_weight": 0.1,
      "step": 5232,
      "total_loss": 0.6009534001350403,
      "weighted_orthogonal_loss": 0.0211318489164114
    },
    {
      "classification_loss": 0.720207154750824,
      "epoch": 17.15737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21130700409412384,
      "orthogonal_weight": 0.1,
      "step": 5233,
      "total_loss": 0.7413378357887268,
      "weighted_orthogonal_loss": 0.021130701526999474
    },
    {
      "classification_loss": 0.6146507859230042,
      "epoch": 17.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113012969493866,
      "orthogonal_weight": 0.1,
      "step": 5234,
      "total_loss": 0.635780930519104,
      "weighted_orthogonal_loss": 0.02113012969493866
    },
    {
      "classification_loss": 0.6036164164543152,
      "epoch": 17.16393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113085389137268,
      "orthogonal_weight": 0.1,
      "step": 5235,
      "total_loss": 0.6247472763061523,
      "weighted_orthogonal_loss": 0.02113085426390171
    },
    {
      "classification_loss": 0.6792434453964233,
      "epoch": 17.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21132677793502808,
      "orthogonal_weight": 0.1,
      "step": 5236,
      "total_loss": 0.7003761529922485,
      "weighted_orthogonal_loss": 0.021132677793502808
    },
    {
      "classification_loss": 0.5548227429389954,
      "epoch": 17.17049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113366276025772,
      "orthogonal_weight": 0.1,
      "step": 5237,
      "total_loss": 0.575956404209137,
      "weighted_orthogonal_loss": 0.02113366313278675
    },
    {
      "classification_loss": 0.6016991138458252,
      "epoch": 17.17377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21132980287075043,
      "orthogonal_weight": 0.1,
      "step": 5238,
      "total_loss": 0.6228321194648743,
      "weighted_orthogonal_loss": 0.021132981404662132
    },
    {
      "classification_loss": 0.6357075572013855,
      "epoch": 17.17704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2113267034292221,
      "orthogonal_weight": 0.1,
      "step": 5239,
      "total_loss": 0.6568402051925659,
      "weighted_orthogonal_loss": 0.02113267034292221
    },
    {
      "classification_loss": 0.6088325381278992,
      "epoch": 17.18032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21130795776844025,
      "orthogonal_weight": 0.1,
      "step": 5240,
      "total_loss": 0.6299633383750916,
      "weighted_orthogonal_loss": 0.021130796521902084
    },
    {
      "classification_loss": 0.5459993481636047,
      "epoch": 17.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21128177642822266,
      "orthogonal_weight": 0.1,
      "step": 5241,
      "total_loss": 0.567127525806427,
      "weighted_orthogonal_loss": 0.021128177642822266
    },
    {
      "classification_loss": 0.5939151048660278,
      "epoch": 17.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112257033586502,
      "orthogonal_weight": 0.1,
      "step": 5242,
      "total_loss": 0.6150376796722412,
      "weighted_orthogonal_loss": 0.02112257108092308
    },
    {
      "classification_loss": 0.6148395538330078,
      "epoch": 17.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112104445695877,
      "orthogonal_weight": 0.1,
      "step": 5243,
      "total_loss": 0.635960578918457,
      "weighted_orthogonal_loss": 0.02112104557454586
    },
    {
      "classification_loss": 0.6080625057220459,
      "epoch": 17.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112097293138504,
      "orthogonal_weight": 0.1,
      "step": 5244,
      "total_loss": 0.6291834712028503,
      "weighted_orthogonal_loss": 0.02112097293138504
    },
    {
      "classification_loss": 0.6017498970031738,
      "epoch": 17.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112109363079071,
      "orthogonal_weight": 0.1,
      "step": 5245,
      "total_loss": 0.6228709816932678,
      "weighted_orthogonal_loss": 0.02112109400331974
    },
    {
      "classification_loss": 0.5680346488952637,
      "epoch": 17.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21118709444999695,
      "orthogonal_weight": 0.1,
      "step": 5246,
      "total_loss": 0.5891533493995667,
      "weighted_orthogonal_loss": 0.021118709817528725
    },
    {
      "classification_loss": 0.6011546850204468,
      "epoch": 17.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21116550266742706,
      "orthogonal_weight": 0.1,
      "step": 5247,
      "total_loss": 0.6222712397575378,
      "weighted_orthogonal_loss": 0.021116551011800766
    },
    {
      "classification_loss": 0.659822404384613,
      "epoch": 17.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111286222934723,
      "orthogonal_weight": 0.1,
      "step": 5248,
      "total_loss": 0.680935263633728,
      "weighted_orthogonal_loss": 0.02111286297440529
    },
    {
      "classification_loss": 0.5412780046463013,
      "epoch": 17.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109600365161896,
      "orthogonal_weight": 0.1,
      "step": 5249,
      "total_loss": 0.5623875856399536,
      "weighted_orthogonal_loss": 0.021109601482748985
    },
    {
      "classification_loss": 0.6876461505889893,
      "epoch": 17.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105600893497467,
      "orthogonal_weight": 0.1,
      "step": 5250,
      "total_loss": 0.7087517380714417,
      "weighted_orthogonal_loss": 0.021105600520968437
    },
    {
      "classification_loss": 0.572920560836792,
      "epoch": 17.21639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110266387462616,
      "orthogonal_weight": 0.1,
      "step": 5251,
      "total_loss": 0.5940232276916504,
      "weighted_orthogonal_loss": 0.02110266499221325
    },
    {
      "classification_loss": 0.7601230144500732,
      "epoch": 17.21967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21100212633609772,
      "orthogonal_weight": 0.1,
      "step": 5252,
      "total_loss": 0.7812232375144958,
      "weighted_orthogonal_loss": 0.02110021375119686
    },
    {
      "classification_loss": 0.6380702257156372,
      "epoch": 17.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099434792995453,
      "orthogonal_weight": 0.1,
      "step": 5253,
      "total_loss": 0.6591696739196777,
      "weighted_orthogonal_loss": 0.021099435165524483
    },
    {
      "classification_loss": 0.6064714789390564,
      "epoch": 17.22622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109803855419159,
      "orthogonal_weight": 0.1,
      "step": 5254,
      "total_loss": 0.6275694966316223,
      "weighted_orthogonal_loss": 0.02109803818166256
    },
    {
      "classification_loss": 0.5830204486846924,
      "epoch": 17.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109380066394806,
      "orthogonal_weight": 0.1,
      "step": 5255,
      "total_loss": 0.6041142344474792,
      "weighted_orthogonal_loss": 0.02109380066394806
    },
    {
      "classification_loss": 0.6501071453094482,
      "epoch": 17.2327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21091021597385406,
      "orthogonal_weight": 0.1,
      "step": 5256,
      "total_loss": 0.6711981892585754,
      "weighted_orthogonal_loss": 0.021091021597385406
    },
    {
      "classification_loss": 0.59633868932724,
      "epoch": 17.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108793407678604,
      "orthogonal_weight": 0.1,
      "step": 5257,
      "total_loss": 0.6174266338348389,
      "weighted_orthogonal_loss": 0.02108793519437313
    },
    {
      "classification_loss": 0.536003053188324,
      "epoch": 17.23934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21084363758563995,
      "orthogonal_weight": 0.1,
      "step": 5258,
      "total_loss": 0.5570874214172363,
      "weighted_orthogonal_loss": 0.021084364503622055
    },
    {
      "classification_loss": 0.5165699124336243,
      "epoch": 17.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082259714603424,
      "orthogonal_weight": 0.1,
      "step": 5259,
      "total_loss": 0.5376521944999695,
      "weighted_orthogonal_loss": 0.021082259714603424
    },
    {
      "classification_loss": 0.6537761092185974,
      "epoch": 17.24590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108001559972763,
      "orthogonal_weight": 0.1,
      "step": 5260,
      "total_loss": 0.6748561263084412,
      "weighted_orthogonal_loss": 0.0210800152271986
    },
    {
      "classification_loss": 0.5700681805610657,
      "epoch": 17.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2107936292886734,
      "orthogonal_weight": 0.1,
      "step": 5261,
      "total_loss": 0.5911475419998169,
      "weighted_orthogonal_loss": 0.02107936330139637
    },
    {
      "classification_loss": 0.602502703666687,
      "epoch": 17.25245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2107786238193512,
      "orthogonal_weight": 0.1,
      "step": 5262,
      "total_loss": 0.6235805749893188,
      "weighted_orthogonal_loss": 0.02107786200940609
    },
    {
      "classification_loss": 0.6390748023986816,
      "epoch": 17.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106897383928299,
      "orthogonal_weight": 0.1,
      "step": 5263,
      "total_loss": 0.6601437926292419,
      "weighted_orthogonal_loss": 0.02106897346675396
    },
    {
      "classification_loss": 0.640954852104187,
      "epoch": 17.25901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106139212846756,
      "orthogonal_weight": 0.1,
      "step": 5264,
      "total_loss": 0.6620162725448608,
      "weighted_orthogonal_loss": 0.02106139250099659
    },
    {
      "classification_loss": 0.5874063372612,
      "epoch": 17.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21056373417377472,
      "orthogonal_weight": 0.1,
      "step": 5265,
      "total_loss": 0.6084626913070679,
      "weighted_orthogonal_loss": 0.02105637453496456
    },
    {
      "classification_loss": 0.6071871519088745,
      "epoch": 17.2655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105405181646347,
      "orthogonal_weight": 0.1,
      "step": 5266,
      "total_loss": 0.6282411813735962,
      "weighted_orthogonal_loss": 0.02105405181646347
    },
    {
      "classification_loss": 0.6704283952713013,
      "epoch": 17.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21052810549736023,
      "orthogonal_weight": 0.1,
      "step": 5267,
      "total_loss": 0.6914812326431274,
      "weighted_orthogonal_loss": 0.021052811294794083
    },
    {
      "classification_loss": 0.6732646226882935,
      "epoch": 17.272131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21052540838718414,
      "orthogonal_weight": 0.1,
      "step": 5268,
      "total_loss": 0.6943171620368958,
      "weighted_orthogonal_loss": 0.021052541211247444
    },
    {
      "classification_loss": 0.6602120995521545,
      "epoch": 17.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21051040291786194,
      "orthogonal_weight": 0.1,
      "step": 5269,
      "total_loss": 0.6812631487846375,
      "weighted_orthogonal_loss": 0.021051039919257164
    },
    {
      "classification_loss": 0.6298531293869019,
      "epoch": 17.278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21048970520496368,
      "orthogonal_weight": 0.1,
      "step": 5270,
      "total_loss": 0.6509020924568176,
      "weighted_orthogonal_loss": 0.02104897052049637
    },
    {
      "classification_loss": 0.6260998845100403,
      "epoch": 17.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21046693623065948,
      "orthogonal_weight": 0.1,
      "step": 5271,
      "total_loss": 0.6471465826034546,
      "weighted_orthogonal_loss": 0.021046694368124008
    },
    {
      "classification_loss": 0.5597817301750183,
      "epoch": 17.285245901639342,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21043513715267181,
      "orthogonal_weight": 0.1,
      "step": 5272,
      "total_loss": 0.5808252692222595,
      "weighted_orthogonal_loss": 0.02104351483285427
    },
    {
      "classification_loss": 0.6207708716392517,
      "epoch": 17.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21042975783348083,
      "orthogonal_weight": 0.1,
      "step": 5273,
      "total_loss": 0.6418138742446899,
      "weighted_orthogonal_loss": 0.021042976528406143
    },
    {
      "classification_loss": 0.5569608211517334,
      "epoch": 17.291803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104106992483139,
      "orthogonal_weight": 0.1,
      "step": 5274,
      "total_loss": 0.5780019164085388,
      "weighted_orthogonal_loss": 0.02104107104241848
    },
    {
      "classification_loss": 0.5899162292480469,
      "epoch": 17.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104157954454422,
      "orthogonal_weight": 0.1,
      "step": 5275,
      "total_loss": 0.6109578013420105,
      "weighted_orthogonal_loss": 0.02104157954454422
    },
    {
      "classification_loss": 0.5940483212471008,
      "epoch": 17.298360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210413858294487,
      "orthogonal_weight": 0.1,
      "step": 5276,
      "total_loss": 0.6150897145271301,
      "weighted_orthogonal_loss": 0.0210413858294487
    },
    {
      "classification_loss": 0.5581049919128418,
      "epoch": 17.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21044951677322388,
      "orthogonal_weight": 0.1,
      "step": 5277,
      "total_loss": 0.5791499614715576,
      "weighted_orthogonal_loss": 0.021044952794909477
    },
    {
      "classification_loss": 0.6060478687286377,
      "epoch": 17.304918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21047744154930115,
      "orthogonal_weight": 0.1,
      "step": 5278,
      "total_loss": 0.627095639705658,
      "weighted_orthogonal_loss": 0.021047744899988174
    },
    {
      "classification_loss": 0.6166161298751831,
      "epoch": 17.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21049420535564423,
      "orthogonal_weight": 0.1,
      "step": 5279,
      "total_loss": 0.6376655697822571,
      "weighted_orthogonal_loss": 0.021049421280622482
    },
    {
      "classification_loss": 0.6168466210365295,
      "epoch": 17.311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21050234138965607,
      "orthogonal_weight": 0.1,
      "step": 5280,
      "total_loss": 0.6378968358039856,
      "weighted_orthogonal_loss": 0.021050235256552696
    },
    {
      "classification_loss": 0.5517979860305786,
      "epoch": 17.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21051134169101715,
      "orthogonal_weight": 0.1,
      "step": 5281,
      "total_loss": 0.5728490948677063,
      "weighted_orthogonal_loss": 0.021051134914159775
    },
    {
      "classification_loss": 0.5555430054664612,
      "epoch": 17.318032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21050068736076355,
      "orthogonal_weight": 0.1,
      "step": 5282,
      "total_loss": 0.5765931010246277,
      "weighted_orthogonal_loss": 0.021050069481134415
    },
    {
      "classification_loss": 0.6586064100265503,
      "epoch": 17.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21044929325580597,
      "orthogonal_weight": 0.1,
      "step": 5283,
      "total_loss": 0.6796513199806213,
      "weighted_orthogonal_loss": 0.021044930443167686
    },
    {
      "classification_loss": 0.6322399377822876,
      "epoch": 17.324590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21038909256458282,
      "orthogonal_weight": 0.1,
      "step": 5284,
      "total_loss": 0.6532788276672363,
      "weighted_orthogonal_loss": 0.021038910374045372
    },
    {
      "classification_loss": 0.5939881801605225,
      "epoch": 17.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210361048579216,
      "orthogonal_weight": 0.1,
      "step": 5285,
      "total_loss": 0.6150242686271667,
      "weighted_orthogonal_loss": 0.02103610523045063
    },
    {
      "classification_loss": 0.6358276009559631,
      "epoch": 17.331147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21034763753414154,
      "orthogonal_weight": 0.1,
      "step": 5286,
      "total_loss": 0.6568623781204224,
      "weighted_orthogonal_loss": 0.021034764125943184
    },
    {
      "classification_loss": 0.675646960735321,
      "epoch": 17.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103300243616104,
      "orthogonal_weight": 0.1,
      "step": 5287,
      "total_loss": 0.696679949760437,
      "weighted_orthogonal_loss": 0.02103300206363201
    },
    {
      "classification_loss": 0.5627841353416443,
      "epoch": 17.337704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21028998494148254,
      "orthogonal_weight": 0.1,
      "step": 5288,
      "total_loss": 0.5838131308555603,
      "weighted_orthogonal_loss": 0.021028999239206314
    },
    {
      "classification_loss": 0.6055290699005127,
      "epoch": 17.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2102491408586502,
      "orthogonal_weight": 0.1,
      "step": 5289,
      "total_loss": 0.626554012298584,
      "weighted_orthogonal_loss": 0.02102491445839405
    },
    {
      "classification_loss": 0.6484096646308899,
      "epoch": 17.34426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21021711826324463,
      "orthogonal_weight": 0.1,
      "step": 5290,
      "total_loss": 0.6694313883781433,
      "weighted_orthogonal_loss": 0.021021712571382523
    },
    {
      "classification_loss": 0.6204822063446045,
      "epoch": 17.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21019503474235535,
      "orthogonal_weight": 0.1,
      "step": 5291,
      "total_loss": 0.6415017247200012,
      "weighted_orthogonal_loss": 0.021019503474235535
    },
    {
      "classification_loss": 0.6143576502799988,
      "epoch": 17.35081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21018889546394348,
      "orthogonal_weight": 0.1,
      "step": 5292,
      "total_loss": 0.635376513004303,
      "weighted_orthogonal_loss": 0.021018890663981438
    },
    {
      "classification_loss": 0.690142035484314,
      "epoch": 17.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101735919713974,
      "orthogonal_weight": 0.1,
      "step": 5293,
      "total_loss": 0.7111594080924988,
      "weighted_orthogonal_loss": 0.02101735956966877
    },
    {
      "classification_loss": 0.5751425623893738,
      "epoch": 17.35737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21015559136867523,
      "orthogonal_weight": 0.1,
      "step": 5294,
      "total_loss": 0.5961581468582153,
      "weighted_orthogonal_loss": 0.021015560254454613
    },
    {
      "classification_loss": 0.5975521802902222,
      "epoch": 17.360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21014930307865143,
      "orthogonal_weight": 0.1,
      "step": 5295,
      "total_loss": 0.6185671091079712,
      "weighted_orthogonal_loss": 0.021014930680394173
    },
    {
      "classification_loss": 0.627511203289032,
      "epoch": 17.36393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21015670895576477,
      "orthogonal_weight": 0.1,
      "step": 5296,
      "total_loss": 0.6485268473625183,
      "weighted_orthogonal_loss": 0.021015672013163567
    },
    {
      "classification_loss": 0.660285472869873,
      "epoch": 17.367213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101723700761795,
      "orthogonal_weight": 0.1,
      "step": 5297,
      "total_loss": 0.6813027262687683,
      "weighted_orthogonal_loss": 0.02101723663508892
    },
    {
      "classification_loss": 0.5619266033172607,
      "epoch": 17.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21019478142261505,
      "orthogonal_weight": 0.1,
      "step": 5298,
      "total_loss": 0.5829460620880127,
      "weighted_orthogonal_loss": 0.021019479259848595
    },
    {
      "classification_loss": 0.6854510307312012,
      "epoch": 17.373770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21020977199077606,
      "orthogonal_weight": 0.1,
      "step": 5299,
      "total_loss": 0.7064719796180725,
      "weighted_orthogonal_loss": 0.021020976826548576
    },
    {
      "epoch": 17.37704918032787,
      "grad_norm": 8.667724609375,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 0.633,
      "step": 5300
    },
    {
      "classification_loss": 0.5984213948249817,
      "epoch": 17.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21022914350032806,
      "orthogonal_weight": 0.1,
      "step": 5300,
      "total_loss": 0.6194443106651306,
      "weighted_orthogonal_loss": 0.021022913977503777
    },
    {
      "classification_loss": 0.53749018907547,
      "epoch": 17.380327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210256889462471,
      "orthogonal_weight": 0.1,
      "step": 5301,
      "total_loss": 0.5585159063339233,
      "weighted_orthogonal_loss": 0.02102568931877613
    },
    {
      "classification_loss": 0.5886920690536499,
      "epoch": 17.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21027453243732452,
      "orthogonal_weight": 0.1,
      "step": 5302,
      "total_loss": 0.6097195148468018,
      "weighted_orthogonal_loss": 0.021027453243732452
    },
    {
      "classification_loss": 0.5941780209541321,
      "epoch": 17.386885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2102922797203064,
      "orthogonal_weight": 0.1,
      "step": 5303,
      "total_loss": 0.6152072548866272,
      "weighted_orthogonal_loss": 0.02102922834455967
    },
    {
      "classification_loss": 0.6099388003349304,
      "epoch": 17.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103218287229538,
      "orthogonal_weight": 0.1,
      "step": 5304,
      "total_loss": 0.6309709548950195,
      "weighted_orthogonal_loss": 0.02103218249976635
    },
    {
      "classification_loss": 0.6427068710327148,
      "epoch": 17.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21034011244773865,
      "orthogonal_weight": 0.1,
      "step": 5305,
      "total_loss": 0.663740873336792,
      "weighted_orthogonal_loss": 0.021034011617302895
    },
    {
      "classification_loss": 0.5887614488601685,
      "epoch": 17.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21034862101078033,
      "orthogonal_weight": 0.1,
      "step": 5306,
      "total_loss": 0.6097962856292725,
      "weighted_orthogonal_loss": 0.021034862846136093
    },
    {
      "classification_loss": 0.6416457295417786,
      "epoch": 17.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21035075187683105,
      "orthogonal_weight": 0.1,
      "step": 5307,
      "total_loss": 0.6626808047294617,
      "weighted_orthogonal_loss": 0.021035075187683105
    },
    {
      "classification_loss": 0.5707740783691406,
      "epoch": 17.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21034613251686096,
      "orthogonal_weight": 0.1,
      "step": 5308,
      "total_loss": 0.5918086767196655,
      "weighted_orthogonal_loss": 0.021034613251686096
    },
    {
      "classification_loss": 0.5816894173622131,
      "epoch": 17.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21035629510879517,
      "orthogonal_weight": 0.1,
      "step": 5309,
      "total_loss": 0.6027250289916992,
      "weighted_orthogonal_loss": 0.021035630255937576
    },
    {
      "classification_loss": 0.5350924730300903,
      "epoch": 17.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21038341522216797,
      "orthogonal_weight": 0.1,
      "step": 5310,
      "total_loss": 0.5561308264732361,
      "weighted_orthogonal_loss": 0.021038342267274857
    },
    {
      "classification_loss": 0.5796454548835754,
      "epoch": 17.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21041500568389893,
      "orthogonal_weight": 0.1,
      "step": 5311,
      "total_loss": 0.6006869673728943,
      "weighted_orthogonal_loss": 0.021041501313447952
    },
    {
      "classification_loss": 0.6068023443222046,
      "epoch": 17.41639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21045748889446259,
      "orthogonal_weight": 0.1,
      "step": 5312,
      "total_loss": 0.6278480887413025,
      "weighted_orthogonal_loss": 0.021045750007033348
    },
    {
      "classification_loss": 0.6274386048316956,
      "epoch": 17.41967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21048711240291595,
      "orthogonal_weight": 0.1,
      "step": 5313,
      "total_loss": 0.6484873294830322,
      "weighted_orthogonal_loss": 0.021048711612820625
    },
    {
      "classification_loss": 0.57765793800354,
      "epoch": 17.42295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21051761507987976,
      "orthogonal_weight": 0.1,
      "step": 5314,
      "total_loss": 0.5987097024917603,
      "weighted_orthogonal_loss": 0.021051762625575066
    },
    {
      "classification_loss": 0.6086606383323669,
      "epoch": 17.42622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21055656671524048,
      "orthogonal_weight": 0.1,
      "step": 5315,
      "total_loss": 0.6297162771224976,
      "weighted_orthogonal_loss": 0.021055657416582108
    },
    {
      "classification_loss": 0.5617108345031738,
      "epoch": 17.42950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105826884508133,
      "orthogonal_weight": 0.1,
      "step": 5316,
      "total_loss": 0.5827690958976746,
      "weighted_orthogonal_loss": 0.02105826884508133
    },
    {
      "classification_loss": 0.6515005826950073,
      "epoch": 17.432786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21061082184314728,
      "orthogonal_weight": 0.1,
      "step": 5317,
      "total_loss": 0.6725616455078125,
      "weighted_orthogonal_loss": 0.021061083301901817
    },
    {
      "classification_loss": 0.5850984454154968,
      "epoch": 17.43606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21064022183418274,
      "orthogonal_weight": 0.1,
      "step": 5318,
      "total_loss": 0.6061624884605408,
      "weighted_orthogonal_loss": 0.021064022555947304
    },
    {
      "classification_loss": 0.5522817969322205,
      "epoch": 17.439344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21067291498184204,
      "orthogonal_weight": 0.1,
      "step": 5319,
      "total_loss": 0.573349118232727,
      "weighted_orthogonal_loss": 0.021067291498184204
    },
    {
      "classification_loss": 0.6084697246551514,
      "epoch": 17.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21072165668010712,
      "orthogonal_weight": 0.1,
      "step": 5320,
      "total_loss": 0.6295418739318848,
      "weighted_orthogonal_loss": 0.02107216604053974
    },
    {
      "classification_loss": 0.6582582592964172,
      "epoch": 17.445901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2107570916414261,
      "orthogonal_weight": 0.1,
      "step": 5321,
      "total_loss": 0.6793339848518372,
      "weighted_orthogonal_loss": 0.02107570879161358
    },
    {
      "classification_loss": 0.621111273765564,
      "epoch": 17.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210787832736969,
      "orthogonal_weight": 0.1,
      "step": 5322,
      "total_loss": 0.6421900391578674,
      "weighted_orthogonal_loss": 0.02107878401875496
    },
    {
      "classification_loss": 0.5886436104774475,
      "epoch": 17.452459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082016825675964,
      "orthogonal_weight": 0.1,
      "step": 5323,
      "total_loss": 0.6097256541252136,
      "weighted_orthogonal_loss": 0.021082017570734024
    },
    {
      "classification_loss": 0.5576252937316895,
      "epoch": 17.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108984738588333,
      "orthogonal_weight": 0.1,
      "step": 5324,
      "total_loss": 0.5787151455879211,
      "weighted_orthogonal_loss": 0.02108984813094139
    },
    {
      "classification_loss": 0.6442393660545349,
      "epoch": 17.459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094532310962677,
      "orthogonal_weight": 0.1,
      "step": 5325,
      "total_loss": 0.6653339266777039,
      "weighted_orthogonal_loss": 0.021094532683491707
    },
    {
      "classification_loss": 0.5969054698944092,
      "epoch": 17.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099962294101715,
      "orthogonal_weight": 0.1,
      "step": 5326,
      "total_loss": 0.6180054545402527,
      "weighted_orthogonal_loss": 0.021099962294101715
    },
    {
      "classification_loss": 0.5985169410705566,
      "epoch": 17.465573770491805,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105949580669403,
      "orthogonal_weight": 0.1,
      "step": 5327,
      "total_loss": 0.6196228861808777,
      "weighted_orthogonal_loss": 0.021105950698256493
    },
    {
      "classification_loss": 0.5727631449699402,
      "epoch": 17.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109962463378906,
      "orthogonal_weight": 0.1,
      "step": 5328,
      "total_loss": 0.5938730835914612,
      "weighted_orthogonal_loss": 0.021109962835907936
    },
    {
      "classification_loss": 0.6842387318611145,
      "epoch": 17.472131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21114417910575867,
      "orthogonal_weight": 0.1,
      "step": 5329,
      "total_loss": 0.7053531408309937,
      "weighted_orthogonal_loss": 0.021114418283104897
    },
    {
      "classification_loss": 0.6777070760726929,
      "epoch": 17.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115052700042725,
      "orthogonal_weight": 0.1,
      "step": 5330,
      "total_loss": 0.6988221406936646,
      "weighted_orthogonal_loss": 0.021115053445100784
    },
    {
      "classification_loss": 0.6598074436187744,
      "epoch": 17.478688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115772426128387,
      "orthogonal_weight": 0.1,
      "step": 5331,
      "total_loss": 0.6809232234954834,
      "weighted_orthogonal_loss": 0.021115772426128387
    },
    {
      "classification_loss": 0.6841883063316345,
      "epoch": 17.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21117910742759705,
      "orthogonal_weight": 0.1,
      "step": 5332,
      "total_loss": 0.7053062319755554,
      "weighted_orthogonal_loss": 0.021117910742759705
    },
    {
      "classification_loss": 0.7554134130477905,
      "epoch": 17.485245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21117618680000305,
      "orthogonal_weight": 0.1,
      "step": 5333,
      "total_loss": 0.7765310406684875,
      "weighted_orthogonal_loss": 0.021117618307471275
    },
    {
      "classification_loss": 0.5780527591705322,
      "epoch": 17.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211162731051445,
      "orthogonal_weight": 0.1,
      "step": 5334,
      "total_loss": 0.5991690158843994,
      "weighted_orthogonal_loss": 0.02111627347767353
    },
    {
      "classification_loss": 0.6026705503463745,
      "epoch": 17.491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21114332973957062,
      "orthogonal_weight": 0.1,
      "step": 5335,
      "total_loss": 0.6237848997116089,
      "weighted_orthogonal_loss": 0.021114332601428032
    },
    {
      "classification_loss": 0.5795946717262268,
      "epoch": 17.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21112412214279175,
      "orthogonal_weight": 0.1,
      "step": 5336,
      "total_loss": 0.6007070541381836,
      "weighted_orthogonal_loss": 0.021112412214279175
    },
    {
      "classification_loss": 0.622184157371521,
      "epoch": 17.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21110598742961884,
      "orthogonal_weight": 0.1,
      "step": 5337,
      "total_loss": 0.6432947516441345,
      "weighted_orthogonal_loss": 0.021110599860548973
    },
    {
      "classification_loss": 0.6448901891708374,
      "epoch": 17.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21110780537128448,
      "orthogonal_weight": 0.1,
      "step": 5338,
      "total_loss": 0.6660009622573853,
      "weighted_orthogonal_loss": 0.02111078053712845
    },
    {
      "classification_loss": 0.5693756341934204,
      "epoch": 17.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111026793718338,
      "orthogonal_weight": 0.1,
      "step": 5339,
      "total_loss": 0.5904859304428101,
      "weighted_orthogonal_loss": 0.02111026830971241
    },
    {
      "classification_loss": 0.598359227180481,
      "epoch": 17.508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21110840141773224,
      "orthogonal_weight": 0.1,
      "step": 5340,
      "total_loss": 0.6194700598716736,
      "weighted_orthogonal_loss": 0.021110840141773224
    },
    {
      "classification_loss": 0.6601107120513916,
      "epoch": 17.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21112152934074402,
      "orthogonal_weight": 0.1,
      "step": 5341,
      "total_loss": 0.6812228560447693,
      "weighted_orthogonal_loss": 0.02111215330660343
    },
    {
      "classification_loss": 0.6305198073387146,
      "epoch": 17.514754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21111412346363068,
      "orthogonal_weight": 0.1,
      "step": 5342,
      "total_loss": 0.651631236076355,
      "weighted_orthogonal_loss": 0.021111411973834038
    },
    {
      "classification_loss": 0.6073877215385437,
      "epoch": 17.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21110765635967255,
      "orthogonal_weight": 0.1,
      "step": 5343,
      "total_loss": 0.6284984946250916,
      "weighted_orthogonal_loss": 0.021110765635967255
    },
    {
      "classification_loss": 0.6304101347923279,
      "epoch": 17.521311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109192073345184,
      "orthogonal_weight": 0.1,
      "step": 5344,
      "total_loss": 0.6515192985534668,
      "weighted_orthogonal_loss": 0.021109191700816154
    },
    {
      "classification_loss": 0.5797370076179504,
      "epoch": 17.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107235550880432,
      "orthogonal_weight": 0.1,
      "step": 5345,
      "total_loss": 0.6008442640304565,
      "weighted_orthogonal_loss": 0.021107235923409462
    },
    {
      "classification_loss": 0.5524267554283142,
      "epoch": 17.527868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21104387938976288,
      "orthogonal_weight": 0.1,
      "step": 5346,
      "total_loss": 0.5735311508178711,
      "weighted_orthogonal_loss": 0.021104387938976288
    },
    {
      "classification_loss": 0.6397126317024231,
      "epoch": 17.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21101319789886475,
      "orthogonal_weight": 0.1,
      "step": 5347,
      "total_loss": 0.6608139276504517,
      "weighted_orthogonal_loss": 0.021101320162415504
    },
    {
      "classification_loss": 0.605746865272522,
      "epoch": 17.534426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109822779893875,
      "orthogonal_weight": 0.1,
      "step": 5348,
      "total_loss": 0.626845121383667,
      "weighted_orthogonal_loss": 0.02109822817146778
    },
    {
      "classification_loss": 0.6337658762931824,
      "epoch": 17.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094602346420288,
      "orthogonal_weight": 0.1,
      "step": 5349,
      "total_loss": 0.6548604965209961,
      "weighted_orthogonal_loss": 0.021094603464007378
    },
    {
      "classification_loss": 0.675104558467865,
      "epoch": 17.540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109030932188034,
      "orthogonal_weight": 0.1,
      "step": 5350,
      "total_loss": 0.6961948871612549,
      "weighted_orthogonal_loss": 0.0210903100669384
    },
    {
      "classification_loss": 0.5983292460441589,
      "epoch": 17.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21089030802249908,
      "orthogonal_weight": 0.1,
      "step": 5351,
      "total_loss": 0.6194182634353638,
      "weighted_orthogonal_loss": 0.02108903042972088
    },
    {
      "classification_loss": 0.6118634939193726,
      "epoch": 17.547540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210863396525383,
      "orthogonal_weight": 0.1,
      "step": 5352,
      "total_loss": 0.6329498291015625,
      "weighted_orthogonal_loss": 0.02108634077012539
    },
    {
      "classification_loss": 0.5965170860290527,
      "epoch": 17.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21084798872470856,
      "orthogonal_weight": 0.1,
      "step": 5353,
      "total_loss": 0.6176018714904785,
      "weighted_orthogonal_loss": 0.021084798499941826
    },
    {
      "classification_loss": 0.7188751101493835,
      "epoch": 17.554098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21084290742874146,
      "orthogonal_weight": 0.1,
      "step": 5354,
      "total_loss": 0.7399594187736511,
      "weighted_orthogonal_loss": 0.021084291860461235
    },
    {
      "classification_loss": 0.637665331363678,
      "epoch": 17.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21076244115829468,
      "orthogonal_weight": 0.1,
      "step": 5355,
      "total_loss": 0.6587415933609009,
      "weighted_orthogonal_loss": 0.021076245233416557
    },
    {
      "classification_loss": 0.5393003225326538,
      "epoch": 17.560655737704916,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106873244047165,
      "orthogonal_weight": 0.1,
      "step": 5356,
      "total_loss": 0.560369074344635,
      "weighted_orthogonal_loss": 0.02106873318552971
    },
    {
      "classification_loss": 0.528238832950592,
      "epoch": 17.56393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106131762266159,
      "orthogonal_weight": 0.1,
      "step": 5357,
      "total_loss": 0.5493001341819763,
      "weighted_orthogonal_loss": 0.02106131799519062
    },
    {
      "classification_loss": 0.5875399112701416,
      "epoch": 17.567213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21054399013519287,
      "orthogonal_weight": 0.1,
      "step": 5358,
      "total_loss": 0.6085942983627319,
      "weighted_orthogonal_loss": 0.021054400131106377
    },
    {
      "classification_loss": 0.5883606672286987,
      "epoch": 17.57049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21046635508537292,
      "orthogonal_weight": 0.1,
      "step": 5359,
      "total_loss": 0.6094073057174683,
      "weighted_orthogonal_loss": 0.021046636626124382
    },
    {
      "classification_loss": 0.5754157900810242,
      "epoch": 17.57377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037989854812622,
      "orthogonal_weight": 0.1,
      "step": 5360,
      "total_loss": 0.5964537858963013,
      "weighted_orthogonal_loss": 0.021037990227341652
    },
    {
      "classification_loss": 0.5058596730232239,
      "epoch": 17.57704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21028873324394226,
      "orthogonal_weight": 0.1,
      "step": 5361,
      "total_loss": 0.5268885493278503,
      "weighted_orthogonal_loss": 0.021028874441981316
    },
    {
      "classification_loss": 0.6213141083717346,
      "epoch": 17.58032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21021106839179993,
      "orthogonal_weight": 0.1,
      "step": 5362,
      "total_loss": 0.6423352360725403,
      "weighted_orthogonal_loss": 0.021021107211709023
    },
    {
      "classification_loss": 0.5519089698791504,
      "epoch": 17.58360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21015191078186035,
      "orthogonal_weight": 0.1,
      "step": 5363,
      "total_loss": 0.5729241371154785,
      "weighted_orthogonal_loss": 0.021015191450715065
    },
    {
      "classification_loss": 0.6321941614151001,
      "epoch": 17.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101060450077057,
      "orthogonal_weight": 0.1,
      "step": 5364,
      "total_loss": 0.6532047390937805,
      "weighted_orthogonal_loss": 0.02101060561835766
    },
    {
      "classification_loss": 0.6225845813751221,
      "epoch": 17.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21005411446094513,
      "orthogonal_weight": 0.1,
      "step": 5365,
      "total_loss": 0.643589973449707,
      "weighted_orthogonal_loss": 0.021005412563681602
    },
    {
      "classification_loss": 0.6122977137565613,
      "epoch": 17.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21002031862735748,
      "orthogonal_weight": 0.1,
      "step": 5366,
      "total_loss": 0.6332997679710388,
      "weighted_orthogonal_loss": 0.02100203186273575
    },
    {
      "classification_loss": 0.5739974975585938,
      "epoch": 17.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21001100540161133,
      "orthogonal_weight": 0.1,
      "step": 5367,
      "total_loss": 0.5949985980987549,
      "weighted_orthogonal_loss": 0.021001100540161133
    },
    {
      "classification_loss": 0.5285667181015015,
      "epoch": 17.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210004061460495,
      "orthogonal_weight": 0.1,
      "step": 5368,
      "total_loss": 0.5495671033859253,
      "weighted_orthogonal_loss": 0.02100040577352047
    },
    {
      "classification_loss": 0.6203577518463135,
      "epoch": 17.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100134938955307,
      "orthogonal_weight": 0.1,
      "step": 5369,
      "total_loss": 0.6413590908050537,
      "weighted_orthogonal_loss": 0.02100135013461113
    },
    {
      "classification_loss": 0.5530818700790405,
      "epoch": 17.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099934071302414,
      "orthogonal_weight": 0.1,
      "step": 5370,
      "total_loss": 0.5740811824798584,
      "weighted_orthogonal_loss": 0.02099934034049511
    },
    {
      "classification_loss": 0.6098302006721497,
      "epoch": 17.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100067138671875,
      "orthogonal_weight": 0.1,
      "step": 5371,
      "total_loss": 0.6308308839797974,
      "weighted_orthogonal_loss": 0.02100067213177681
    },
    {
      "classification_loss": 0.6516447067260742,
      "epoch": 17.613114754098362,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209990993142128,
      "orthogonal_weight": 0.1,
      "step": 5372,
      "total_loss": 0.672643780708313,
      "weighted_orthogonal_loss": 0.02099910005927086
    },
    {
      "classification_loss": 0.6382648944854736,
      "epoch": 17.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21000277996063232,
      "orthogonal_weight": 0.1,
      "step": 5373,
      "total_loss": 0.6592651605606079,
      "weighted_orthogonal_loss": 0.021000279113650322
    },
    {
      "classification_loss": 0.5959926247596741,
      "epoch": 17.619672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100919485092163,
      "orthogonal_weight": 0.1,
      "step": 5374,
      "total_loss": 0.6170018315315247,
      "weighted_orthogonal_loss": 0.02100919559597969
    },
    {
      "classification_loss": 0.6436645984649658,
      "epoch": 17.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101694792509079,
      "orthogonal_weight": 0.1,
      "step": 5375,
      "total_loss": 0.6646815538406372,
      "weighted_orthogonal_loss": 0.02101694792509079
    },
    {
      "classification_loss": 0.6294234991073608,
      "epoch": 17.626229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21024486422538757,
      "orthogonal_weight": 0.1,
      "step": 5376,
      "total_loss": 0.6504479646682739,
      "weighted_orthogonal_loss": 0.021024486050009727
    },
    {
      "classification_loss": 0.4643520712852478,
      "epoch": 17.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103171944618225,
      "orthogonal_weight": 0.1,
      "step": 5377,
      "total_loss": 0.4853837788105011,
      "weighted_orthogonal_loss": 0.02103172056376934
    },
    {
      "classification_loss": 0.6653316020965576,
      "epoch": 17.632786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104029506444931,
      "orthogonal_weight": 0.1,
      "step": 5378,
      "total_loss": 0.686371922492981,
      "weighted_orthogonal_loss": 0.0210402961820364
    },
    {
      "classification_loss": 0.5740728378295898,
      "epoch": 17.63606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21049191057682037,
      "orthogonal_weight": 0.1,
      "step": 5379,
      "total_loss": 0.5951220393180847,
      "weighted_orthogonal_loss": 0.021049192175269127
    },
    {
      "classification_loss": 0.4972524344921112,
      "epoch": 17.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21058227121829987,
      "orthogonal_weight": 0.1,
      "step": 5380,
      "total_loss": 0.5183106660842896,
      "weighted_orthogonal_loss": 0.021058227866888046
    },
    {
      "classification_loss": 0.49019089341163635,
      "epoch": 17.64262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21065698564052582,
      "orthogonal_weight": 0.1,
      "step": 5381,
      "total_loss": 0.5112565755844116,
      "weighted_orthogonal_loss": 0.02106569893658161
    },
    {
      "classification_loss": 0.5794388651847839,
      "epoch": 17.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21071912348270416,
      "orthogonal_weight": 0.1,
      "step": 5382,
      "total_loss": 0.6005107760429382,
      "weighted_orthogonal_loss": 0.021071912720799446
    },
    {
      "classification_loss": 0.653680145740509,
      "epoch": 17.64918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21078838407993317,
      "orthogonal_weight": 0.1,
      "step": 5383,
      "total_loss": 0.6747589707374573,
      "weighted_orthogonal_loss": 0.021078838035464287
    },
    {
      "classification_loss": 0.6387957334518433,
      "epoch": 17.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108311802148819,
      "orthogonal_weight": 0.1,
      "step": 5384,
      "total_loss": 0.6598788499832153,
      "weighted_orthogonal_loss": 0.02108311839401722
    },
    {
      "classification_loss": 0.590660572052002,
      "epoch": 17.65573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21085664629936218,
      "orthogonal_weight": 0.1,
      "step": 5385,
      "total_loss": 0.6117462515830994,
      "weighted_orthogonal_loss": 0.021085664629936218
    },
    {
      "classification_loss": 0.6374448537826538,
      "epoch": 17.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108868956565857,
      "orthogonal_weight": 0.1,
      "step": 5386,
      "total_loss": 0.6585335731506348,
      "weighted_orthogonal_loss": 0.02108868956565857
    },
    {
      "classification_loss": 0.6239959597587585,
      "epoch": 17.662295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108219712972641,
      "orthogonal_weight": 0.1,
      "step": 5387,
      "total_loss": 0.645078182220459,
      "weighted_orthogonal_loss": 0.0210821982473135
    },
    {
      "classification_loss": 0.601396918296814,
      "epoch": 17.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21077203750610352,
      "orthogonal_weight": 0.1,
      "step": 5388,
      "total_loss": 0.6224741339683533,
      "weighted_orthogonal_loss": 0.02107720449566841
    },
    {
      "classification_loss": 0.5558158159255981,
      "epoch": 17.668852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21073219180107117,
      "orthogonal_weight": 0.1,
      "step": 5389,
      "total_loss": 0.5768890380859375,
      "weighted_orthogonal_loss": 0.021073220297694206
    },
    {
      "classification_loss": 0.6434321403503418,
      "epoch": 17.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21069766581058502,
      "orthogonal_weight": 0.1,
      "step": 5390,
      "total_loss": 0.6645019054412842,
      "weighted_orthogonal_loss": 0.021069766953587532
    },
    {
      "classification_loss": 0.6434789896011353,
      "epoch": 17.675409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21067683398723602,
      "orthogonal_weight": 0.1,
      "step": 5391,
      "total_loss": 0.6645466685295105,
      "weighted_orthogonal_loss": 0.021067684516310692
    },
    {
      "classification_loss": 0.7442925572395325,
      "epoch": 17.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21066255867481232,
      "orthogonal_weight": 0.1,
      "step": 5392,
      "total_loss": 0.7653588056564331,
      "weighted_orthogonal_loss": 0.02106625586748123
    },
    {
      "classification_loss": 0.569127082824707,
      "epoch": 17.681967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106129676103592,
      "orthogonal_weight": 0.1,
      "step": 5393,
      "total_loss": 0.5901883840560913,
      "weighted_orthogonal_loss": 0.02106129750609398
    },
    {
      "classification_loss": 0.5561193227767944,
      "epoch": 17.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105773240327835,
      "orthogonal_weight": 0.1,
      "step": 5394,
      "total_loss": 0.5771770477294922,
      "weighted_orthogonal_loss": 0.02105773240327835
    },
    {
      "classification_loss": 0.6411541104316711,
      "epoch": 17.688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21055300533771515,
      "orthogonal_weight": 0.1,
      "step": 5395,
      "total_loss": 0.6622093915939331,
      "weighted_orthogonal_loss": 0.021055301651358604
    },
    {
      "classification_loss": 0.6178351044654846,
      "epoch": 17.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21052798628807068,
      "orthogonal_weight": 0.1,
      "step": 5396,
      "total_loss": 0.638887882232666,
      "weighted_orthogonal_loss": 0.021052798256278038
    },
    {
      "classification_loss": 0.6168888211250305,
      "epoch": 17.695081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21051008999347687,
      "orthogonal_weight": 0.1,
      "step": 5397,
      "total_loss": 0.6379398107528687,
      "weighted_orthogonal_loss": 0.021051010116934776
    },
    {
      "classification_loss": 0.6222436428070068,
      "epoch": 17.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21048837900161743,
      "orthogonal_weight": 0.1,
      "step": 5398,
      "total_loss": 0.6432924866676331,
      "weighted_orthogonal_loss": 0.021048838272690773
    },
    {
      "classification_loss": 0.6486738920211792,
      "epoch": 17.701639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104579210281372,
      "orthogonal_weight": 0.1,
      "step": 5399,
      "total_loss": 0.6697196960449219,
      "weighted_orthogonal_loss": 0.02104579284787178
    },
    {
      "epoch": 17.704918032786885,
      "grad_norm": 10.839394569396973,
      "learning_rate": 2.3366666666666668e-05,
      "loss": 0.6271,
      "step": 5400
    },
    {
      "classification_loss": 0.5541702508926392,
      "epoch": 17.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21042796969413757,
      "orthogonal_weight": 0.1,
      "step": 5400,
      "total_loss": 0.5752130746841431,
      "weighted_orthogonal_loss": 0.021042797714471817
    },
    {
      "classification_loss": 0.621375322341919,
      "epoch": 17.708196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21041154861450195,
      "orthogonal_weight": 0.1,
      "step": 5401,
      "total_loss": 0.6424164772033691,
      "weighted_orthogonal_loss": 0.021041154861450195
    },
    {
      "classification_loss": 0.5983502268791199,
      "epoch": 17.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103976011276245,
      "orthogonal_weight": 0.1,
      "step": 5402,
      "total_loss": 0.6193900108337402,
      "weighted_orthogonal_loss": 0.02103975974023342
    },
    {
      "classification_loss": 0.5495327711105347,
      "epoch": 17.714754098360658,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21039459109306335,
      "orthogonal_weight": 0.1,
      "step": 5403,
      "total_loss": 0.5705722570419312,
      "weighted_orthogonal_loss": 0.021039459854364395
    },
    {
      "classification_loss": 0.6500464081764221,
      "epoch": 17.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103796899318695,
      "orthogonal_weight": 0.1,
      "step": 5404,
      "total_loss": 0.6710844039916992,
      "weighted_orthogonal_loss": 0.02103796973824501
    },
    {
      "classification_loss": 0.5551597476005554,
      "epoch": 17.721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037228405475616,
      "orthogonal_weight": 0.1,
      "step": 5405,
      "total_loss": 0.5761969685554504,
      "weighted_orthogonal_loss": 0.021037228405475616
    },
    {
      "classification_loss": 0.5196424126625061,
      "epoch": 17.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103748321533203,
      "orthogonal_weight": 0.1,
      "step": 5406,
      "total_loss": 0.5406798720359802,
      "weighted_orthogonal_loss": 0.02103748358786106
    },
    {
      "classification_loss": 0.587578535079956,
      "epoch": 17.727868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103705257177353,
      "orthogonal_weight": 0.1,
      "step": 5407,
      "total_loss": 0.6086155772209167,
      "weighted_orthogonal_loss": 0.02103705331683159
    },
    {
      "classification_loss": 0.6313334703445435,
      "epoch": 17.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21036705374717712,
      "orthogonal_weight": 0.1,
      "step": 5408,
      "total_loss": 0.6523701548576355,
      "weighted_orthogonal_loss": 0.021036705002188683
    },
    {
      "classification_loss": 0.6412715911865234,
      "epoch": 17.7344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21036043763160706,
      "orthogonal_weight": 0.1,
      "step": 5409,
      "total_loss": 0.662307620048523,
      "weighted_orthogonal_loss": 0.021036043763160706
    },
    {
      "classification_loss": 0.6400212049484253,
      "epoch": 17.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210366889834404,
      "orthogonal_weight": 0.1,
      "step": 5410,
      "total_loss": 0.6610578894615173,
      "weighted_orthogonal_loss": 0.02103669010102749
    },
    {
      "classification_loss": 0.6459038257598877,
      "epoch": 17.74098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103770524263382,
      "orthogonal_weight": 0.1,
      "step": 5411,
      "total_loss": 0.6669415235519409,
      "weighted_orthogonal_loss": 0.02103770524263382
    },
    {
      "classification_loss": 0.686329185962677,
      "epoch": 17.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2103750854730606,
      "orthogonal_weight": 0.1,
      "step": 5412,
      "total_loss": 0.7073667049407959,
      "weighted_orthogonal_loss": 0.02103750966489315
    },
    {
      "classification_loss": 0.6981455683708191,
      "epoch": 17.74754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037030220031738,
      "orthogonal_weight": 0.1,
      "step": 5413,
      "total_loss": 0.7191826105117798,
      "weighted_orthogonal_loss": 0.021037030965089798
    },
    {
      "classification_loss": 0.6398077011108398,
      "epoch": 17.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21036991477012634,
      "orthogonal_weight": 0.1,
      "step": 5414,
      "total_loss": 0.6608446836471558,
      "weighted_orthogonal_loss": 0.021036991849541664
    },
    {
      "classification_loss": 0.4910683333873749,
      "epoch": 17.75409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037371456623077,
      "orthogonal_weight": 0.1,
      "step": 5415,
      "total_loss": 0.5121057033538818,
      "weighted_orthogonal_loss": 0.021037371829152107
    },
    {
      "classification_loss": 0.5812931656837463,
      "epoch": 17.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037836372852325,
      "orthogonal_weight": 0.1,
      "step": 5416,
      "total_loss": 0.6023309826850891,
      "weighted_orthogonal_loss": 0.021037837490439415
    },
    {
      "classification_loss": 0.6494450569152832,
      "epoch": 17.76065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21037882566452026,
      "orthogonal_weight": 0.1,
      "step": 5417,
      "total_loss": 0.6704829335212708,
      "weighted_orthogonal_loss": 0.021037882193922997
    },
    {
      "classification_loss": 0.6186608672142029,
      "epoch": 17.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21038566529750824,
      "orthogonal_weight": 0.1,
      "step": 5418,
      "total_loss": 0.6396994590759277,
      "weighted_orthogonal_loss": 0.021038567647337914
    },
    {
      "classification_loss": 0.5933927297592163,
      "epoch": 17.7672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210391566157341,
      "orthogonal_weight": 0.1,
      "step": 5419,
      "total_loss": 0.6144318580627441,
      "weighted_orthogonal_loss": 0.02103915624320507
    },
    {
      "classification_loss": 0.6659021973609924,
      "epoch": 17.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21040035784244537,
      "orthogonal_weight": 0.1,
      "step": 5420,
      "total_loss": 0.6869422197341919,
      "weighted_orthogonal_loss": 0.021040035411715508
    },
    {
      "classification_loss": 0.56601881980896,
      "epoch": 17.77377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104034125804901,
      "orthogonal_weight": 0.1,
      "step": 5421,
      "total_loss": 0.5870591402053833,
      "weighted_orthogonal_loss": 0.02104034088551998
    },
    {
      "classification_loss": 0.6442990899085999,
      "epoch": 17.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21044643223285675,
      "orthogonal_weight": 0.1,
      "step": 5422,
      "total_loss": 0.6653437614440918,
      "weighted_orthogonal_loss": 0.021044643595814705
    },
    {
      "classification_loss": 0.6112830638885498,
      "epoch": 17.78032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21046669781208038,
      "orthogonal_weight": 0.1,
      "step": 5423,
      "total_loss": 0.6323297619819641,
      "weighted_orthogonal_loss": 0.021046670153737068
    },
    {
      "classification_loss": 0.6259248852729797,
      "epoch": 17.78360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2104870080947876,
      "orthogonal_weight": 0.1,
      "step": 5424,
      "total_loss": 0.6469736099243164,
      "weighted_orthogonal_loss": 0.02104870043694973
    },
    {
      "classification_loss": 0.6028180718421936,
      "epoch": 17.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210504949092865,
      "orthogonal_weight": 0.1,
      "step": 5425,
      "total_loss": 0.6238685846328735,
      "weighted_orthogonal_loss": 0.02105049602687359
    },
    {
      "classification_loss": 0.5807129144668579,
      "epoch": 17.79016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21052634716033936,
      "orthogonal_weight": 0.1,
      "step": 5426,
      "total_loss": 0.6017655730247498,
      "weighted_orthogonal_loss": 0.021052634343504906
    },
    {
      "classification_loss": 0.61263108253479,
      "epoch": 17.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21054106950759888,
      "orthogonal_weight": 0.1,
      "step": 5427,
      "total_loss": 0.6336851716041565,
      "weighted_orthogonal_loss": 0.021054107695817947
    },
    {
      "classification_loss": 0.6311449408531189,
      "epoch": 17.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2105284035205841,
      "orthogonal_weight": 0.1,
      "step": 5428,
      "total_loss": 0.6521977782249451,
      "weighted_orthogonal_loss": 0.02105284109711647
    },
    {
      "classification_loss": 0.6401838660240173,
      "epoch": 17.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210553839802742,
      "orthogonal_weight": 0.1,
      "step": 5429,
      "total_loss": 0.6612392663955688,
      "weighted_orthogonal_loss": 0.02105538360774517
    },
    {
      "classification_loss": 0.6310572624206543,
      "epoch": 17.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21057875454425812,
      "orthogonal_weight": 0.1,
      "step": 5430,
      "total_loss": 0.6521151661872864,
      "weighted_orthogonal_loss": 0.02105787582695484
    },
    {
      "classification_loss": 0.6462739706039429,
      "epoch": 17.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21060523390769958,
      "orthogonal_weight": 0.1,
      "step": 5431,
      "total_loss": 0.6673344969749451,
      "weighted_orthogonal_loss": 0.021060524508357048
    },
    {
      "classification_loss": 0.5551989674568176,
      "epoch": 17.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21063721179962158,
      "orthogonal_weight": 0.1,
      "step": 5432,
      "total_loss": 0.5762627124786377,
      "weighted_orthogonal_loss": 0.02106372080743313
    },
    {
      "classification_loss": 0.5092452764511108,
      "epoch": 17.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21067748963832855,
      "orthogonal_weight": 0.1,
      "step": 5433,
      "total_loss": 0.5303130149841309,
      "weighted_orthogonal_loss": 0.021067749708890915
    },
    {
      "classification_loss": 0.6241979002952576,
      "epoch": 17.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21070349216461182,
      "orthogonal_weight": 0.1,
      "step": 5434,
      "total_loss": 0.6452682614326477,
      "weighted_orthogonal_loss": 0.02107034996151924
    },
    {
      "classification_loss": 0.7270421981811523,
      "epoch": 17.81967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2107337862253189,
      "orthogonal_weight": 0.1,
      "step": 5435,
      "total_loss": 0.748115599155426,
      "weighted_orthogonal_loss": 0.02107337862253189
    },
    {
      "classification_loss": 0.6397867202758789,
      "epoch": 17.82295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21076267957687378,
      "orthogonal_weight": 0.1,
      "step": 5436,
      "total_loss": 0.6608629822731018,
      "weighted_orthogonal_loss": 0.021076267585158348
    },
    {
      "classification_loss": 0.6457502245903015,
      "epoch": 17.82622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082372963428497,
      "orthogonal_weight": 0.1,
      "step": 5437,
      "total_loss": 0.6668326258659363,
      "weighted_orthogonal_loss": 0.021082373335957527
    },
    {
      "classification_loss": 0.6182589530944824,
      "epoch": 17.82950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21087431907653809,
      "orthogonal_weight": 0.1,
      "step": 5438,
      "total_loss": 0.6393463611602783,
      "weighted_orthogonal_loss": 0.02108743228018284
    },
    {
      "classification_loss": 0.6797743439674377,
      "epoch": 17.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109237015247345,
      "orthogonal_weight": 0.1,
      "step": 5439,
      "total_loss": 0.70086669921875,
      "weighted_orthogonal_loss": 0.02109237015247345
    },
    {
      "classification_loss": 0.6232761740684509,
      "epoch": 17.83606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109416127204895,
      "orthogonal_weight": 0.1,
      "step": 5440,
      "total_loss": 0.6443703174591064,
      "weighted_orthogonal_loss": 0.02109416201710701
    },
    {
      "classification_loss": 0.5932436585426331,
      "epoch": 17.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109484225511551,
      "orthogonal_weight": 0.1,
      "step": 5441,
      "total_loss": 0.6143385171890259,
      "weighted_orthogonal_loss": 0.02109484188258648
    },
    {
      "classification_loss": 0.5785291194915771,
      "epoch": 17.84262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21097171306610107,
      "orthogonal_weight": 0.1,
      "step": 5442,
      "total_loss": 0.5996263027191162,
      "weighted_orthogonal_loss": 0.021097172051668167
    },
    {
      "classification_loss": 0.5760223865509033,
      "epoch": 17.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099182963371277,
      "orthogonal_weight": 0.1,
      "step": 5443,
      "total_loss": 0.5971215963363647,
      "weighted_orthogonal_loss": 0.021099183708429337
    },
    {
      "classification_loss": 0.6464829444885254,
      "epoch": 17.84918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21100914478302002,
      "orthogonal_weight": 0.1,
      "step": 5444,
      "total_loss": 0.6675838828086853,
      "weighted_orthogonal_loss": 0.021100914105772972
    },
    {
      "classification_loss": 0.5874255299568176,
      "epoch": 17.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110244482755661,
      "orthogonal_weight": 0.1,
      "step": 5445,
      "total_loss": 0.6085279583930969,
      "weighted_orthogonal_loss": 0.02110244520008564
    },
    {
      "classification_loss": 0.5209687948226929,
      "epoch": 17.855737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21103300154209137,
      "orthogonal_weight": 0.1,
      "step": 5446,
      "total_loss": 0.5420721173286438,
      "weighted_orthogonal_loss": 0.021103300154209137
    },
    {
      "classification_loss": 0.5812572836875916,
      "epoch": 17.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110416740179062,
      "orthogonal_weight": 0.1,
      "step": 5447,
      "total_loss": 0.6023614406585693,
      "weighted_orthogonal_loss": 0.02110416814684868
    },
    {
      "classification_loss": 0.5965103507041931,
      "epoch": 17.862295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107277274131775,
      "orthogonal_weight": 0.1,
      "step": 5448,
      "total_loss": 0.6176176071166992,
      "weighted_orthogonal_loss": 0.021107276901602745
    },
    {
      "classification_loss": 0.5466484427452087,
      "epoch": 17.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21111375093460083,
      "orthogonal_weight": 0.1,
      "step": 5449,
      "total_loss": 0.5677598118782043,
      "weighted_orthogonal_loss": 0.021111374720931053
    },
    {
      "classification_loss": 0.5875409841537476,
      "epoch": 17.868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115365624427795,
      "orthogonal_weight": 0.1,
      "step": 5450,
      "total_loss": 0.6086563467979431,
      "weighted_orthogonal_loss": 0.021115366369485855
    },
    {
      "classification_loss": 0.6601619720458984,
      "epoch": 17.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211195170879364,
      "orthogonal_weight": 0.1,
      "step": 5451,
      "total_loss": 0.6812815070152283,
      "weighted_orthogonal_loss": 0.02111951820552349
    },
    {
      "classification_loss": 0.6480852365493774,
      "epoch": 17.875409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112399935722351,
      "orthogonal_weight": 0.1,
      "step": 5452,
      "total_loss": 0.6692092418670654,
      "weighted_orthogonal_loss": 0.02112399972975254
    },
    {
      "classification_loss": 0.6125982403755188,
      "epoch": 17.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21127159893512726,
      "orthogonal_weight": 0.1,
      "step": 5453,
      "total_loss": 0.6337254047393799,
      "weighted_orthogonal_loss": 0.021127160638570786
    },
    {
      "classification_loss": 0.5512630939483643,
      "epoch": 17.881967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21128955483436584,
      "orthogonal_weight": 0.1,
      "step": 5454,
      "total_loss": 0.5723920464515686,
      "weighted_orthogonal_loss": 0.021128956228494644
    },
    {
      "classification_loss": 0.6779864430427551,
      "epoch": 17.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21129897236824036,
      "orthogonal_weight": 0.1,
      "step": 5455,
      "total_loss": 0.6991163492202759,
      "weighted_orthogonal_loss": 0.021129896864295006
    },
    {
      "classification_loss": 0.6160175204277039,
      "epoch": 17.888524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21129989624023438,
      "orthogonal_weight": 0.1,
      "step": 5456,
      "total_loss": 0.6371474862098694,
      "weighted_orthogonal_loss": 0.021129989996552467
    },
    {
      "classification_loss": 0.7248049378395081,
      "epoch": 17.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112930417060852,
      "orthogonal_weight": 0.1,
      "step": 5457,
      "total_loss": 0.745934247970581,
      "weighted_orthogonal_loss": 0.02112930454313755
    },
    {
      "classification_loss": 0.6227072477340698,
      "epoch": 17.895081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21129103004932404,
      "orthogonal_weight": 0.1,
      "step": 5458,
      "total_loss": 0.6438363790512085,
      "weighted_orthogonal_loss": 0.021129103377461433
    },
    {
      "classification_loss": 0.6178213357925415,
      "epoch": 17.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21126894652843475,
      "orthogonal_weight": 0.1,
      "step": 5459,
      "total_loss": 0.6389482021331787,
      "weighted_orthogonal_loss": 0.021126894280314445
    },
    {
      "classification_loss": 0.6486846804618835,
      "epoch": 17.901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21124668419361115,
      "orthogonal_weight": 0.1,
      "step": 5460,
      "total_loss": 0.6698093414306641,
      "weighted_orthogonal_loss": 0.021124668419361115
    },
    {
      "classification_loss": 0.5962053537368774,
      "epoch": 17.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21121250092983246,
      "orthogonal_weight": 0.1,
      "step": 5461,
      "total_loss": 0.6173266172409058,
      "weighted_orthogonal_loss": 0.021121250465512276
    },
    {
      "classification_loss": 0.5946999192237854,
      "epoch": 17.908196721311477,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21119163930416107,
      "orthogonal_weight": 0.1,
      "step": 5462,
      "total_loss": 0.6158190965652466,
      "weighted_orthogonal_loss": 0.021119164302945137
    },
    {
      "classification_loss": 0.6317656636238098,
      "epoch": 17.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111893743276596,
      "orthogonal_weight": 0.1,
      "step": 5463,
      "total_loss": 0.6528846025466919,
      "weighted_orthogonal_loss": 0.02111893706023693
    },
    {
      "classification_loss": 0.6614985466003418,
      "epoch": 17.914754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21117016673088074,
      "orthogonal_weight": 0.1,
      "step": 5464,
      "total_loss": 0.6826155781745911,
      "weighted_orthogonal_loss": 0.021117016673088074
    },
    {
      "classification_loss": 0.6911617517471313,
      "epoch": 17.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111450582742691,
      "orthogonal_weight": 0.1,
      "step": 5465,
      "total_loss": 0.7122762799263,
      "weighted_orthogonal_loss": 0.02111450582742691
    },
    {
      "classification_loss": 0.604815661907196,
      "epoch": 17.921311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111305594444275,
      "orthogonal_weight": 0.1,
      "step": 5466,
      "total_loss": 0.6259286999702454,
      "weighted_orthogonal_loss": 0.02111305668950081
    },
    {
      "classification_loss": 0.6523866057395935,
      "epoch": 17.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21112510561943054,
      "orthogonal_weight": 0.1,
      "step": 5467,
      "total_loss": 0.6734991073608398,
      "weighted_orthogonal_loss": 0.021112510934472084
    },
    {
      "classification_loss": 0.616033136844635,
      "epoch": 17.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110954374074936,
      "orthogonal_weight": 0.1,
      "step": 5468,
      "total_loss": 0.6371426582336426,
      "weighted_orthogonal_loss": 0.02110954374074936
    },
    {
      "classification_loss": 0.6170393824577332,
      "epoch": 17.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21106354892253876,
      "orthogonal_weight": 0.1,
      "step": 5469,
      "total_loss": 0.6381457448005676,
      "weighted_orthogonal_loss": 0.021106354892253876
    },
    {
      "classification_loss": 0.5567579865455627,
      "epoch": 17.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110382318496704,
      "orthogonal_weight": 0.1,
      "step": 5470,
      "total_loss": 0.5778617858886719,
      "weighted_orthogonal_loss": 0.02110382355749607
    },
    {
      "classification_loss": 0.6086793541908264,
      "epoch": 17.937704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110171765089035,
      "orthogonal_weight": 0.1,
      "step": 5471,
      "total_loss": 0.6297810673713684,
      "weighted_orthogonal_loss": 0.02110171876847744
    },
    {
      "classification_loss": 0.6192992925643921,
      "epoch": 17.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099300682544708,
      "orthogonal_weight": 0.1,
      "step": 5472,
      "total_loss": 0.6403986215591431,
      "weighted_orthogonal_loss": 0.021099301055073738
    },
    {
      "classification_loss": 0.6477391719818115,
      "epoch": 17.944262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21096165478229523,
      "orthogonal_weight": 0.1,
      "step": 5473,
      "total_loss": 0.6688353419303894,
      "weighted_orthogonal_loss": 0.021096166223287582
    },
    {
      "classification_loss": 0.6353000402450562,
      "epoch": 17.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109377086162567,
      "orthogonal_weight": 0.1,
      "step": 5474,
      "total_loss": 0.656393826007843,
      "weighted_orthogonal_loss": 0.02109377086162567
    },
    {
      "classification_loss": 0.6078466773033142,
      "epoch": 17.950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21091288328170776,
      "orthogonal_weight": 0.1,
      "step": 5475,
      "total_loss": 0.6289379596710205,
      "weighted_orthogonal_loss": 0.021091287955641747
    },
    {
      "classification_loss": 0.562790036201477,
      "epoch": 17.95409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21089494228363037,
      "orthogonal_weight": 0.1,
      "step": 5476,
      "total_loss": 0.5838795304298401,
      "weighted_orthogonal_loss": 0.021089494228363037
    },
    {
      "classification_loss": 0.5798214673995972,
      "epoch": 17.957377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21085701882839203,
      "orthogonal_weight": 0.1,
      "step": 5477,
      "total_loss": 0.6009071469306946,
      "weighted_orthogonal_loss": 0.021085701882839203
    },
    {
      "classification_loss": 0.6514154672622681,
      "epoch": 17.96065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21081803739070892,
      "orthogonal_weight": 0.1,
      "step": 5478,
      "total_loss": 0.6724972724914551,
      "weighted_orthogonal_loss": 0.021081803366541862
    },
    {
      "classification_loss": 0.6576468348503113,
      "epoch": 17.963934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21081648766994476,
      "orthogonal_weight": 0.1,
      "step": 5479,
      "total_loss": 0.678728461265564,
      "weighted_orthogonal_loss": 0.021081648766994476
    },
    {
      "classification_loss": 0.6355907320976257,
      "epoch": 17.9672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21080337464809418,
      "orthogonal_weight": 0.1,
      "step": 5480,
      "total_loss": 0.6566710472106934,
      "weighted_orthogonal_loss": 0.021080337464809418
    },
    {
      "classification_loss": 0.5573196411132812,
      "epoch": 17.970491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082435548305511,
      "orthogonal_weight": 0.1,
      "step": 5481,
      "total_loss": 0.5784021019935608,
      "weighted_orthogonal_loss": 0.0210824366658926
    },
    {
      "classification_loss": 0.5867404937744141,
      "epoch": 17.97377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21084922552108765,
      "orthogonal_weight": 0.1,
      "step": 5482,
      "total_loss": 0.6078253984451294,
      "weighted_orthogonal_loss": 0.021084923297166824
    },
    {
      "classification_loss": 0.5362964868545532,
      "epoch": 17.977049180327867,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21086633205413818,
      "orthogonal_weight": 0.1,
      "step": 5483,
      "total_loss": 0.557383120059967,
      "weighted_orthogonal_loss": 0.02108663320541382
    },
    {
      "classification_loss": 0.6066330075263977,
      "epoch": 17.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21088731288909912,
      "orthogonal_weight": 0.1,
      "step": 5484,
      "total_loss": 0.6277217268943787,
      "weighted_orthogonal_loss": 0.021088732406497
    },
    {
      "classification_loss": 0.6126208305358887,
      "epoch": 17.983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21091507375240326,
      "orthogonal_weight": 0.1,
      "step": 5485,
      "total_loss": 0.6337123513221741,
      "weighted_orthogonal_loss": 0.021091507747769356
    },
    {
      "classification_loss": 0.6525118947029114,
      "epoch": 17.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21093089878559113,
      "orthogonal_weight": 0.1,
      "step": 5486,
      "total_loss": 0.6736049652099609,
      "weighted_orthogonal_loss": 0.021093090996146202
    },
    {
      "classification_loss": 0.5958446264266968,
      "epoch": 17.990163934426228,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21095025539398193,
      "orthogonal_weight": 0.1,
      "step": 5487,
      "total_loss": 0.6169396638870239,
      "weighted_orthogonal_loss": 0.021095026284456253
    },
    {
      "classification_loss": 0.6202292442321777,
      "epoch": 17.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21096153557300568,
      "orthogonal_weight": 0.1,
      "step": 5488,
      "total_loss": 0.6413254141807556,
      "weighted_orthogonal_loss": 0.021096153184771538
    },
    {
      "classification_loss": 0.4830084443092346,
      "epoch": 17.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109658122062683,
      "orthogonal_weight": 0.1,
      "step": 5489,
      "total_loss": 0.5041050314903259,
      "weighted_orthogonal_loss": 0.02109658159315586
    },
    {
      "classification_loss": 0.7131787538528442,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7342782020568848,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.7016081213951111,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7227075695991516,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.7034724354743958,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7245718836784363,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.726764440536499,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7478638887405396,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.7097641229629517,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7308635711669922,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.710422933101654,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7315223813056946,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.7015801072120667,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7226795554161072,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.7250230312347412,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.7461224794387817,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.489,
      "eval_f1": 0.47697031729785055,
      "eval_loss": 0.7322511076927185,
      "eval_precision": 0.6581920903954802,
      "eval_recall": 0.3739967897271268,
      "eval_runtime": 6.1415,
      "eval_samples_per_second": 162.826,
      "eval_steps_per_second": 1.303,
      "step": 5490
    },
    {
      "classification_loss": 0.5810283422470093,
      "epoch": 18.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099431812763214,
      "orthogonal_weight": 0.1,
      "step": 5490,
      "total_loss": 0.6021277904510498,
      "weighted_orthogonal_loss": 0.021099431440234184
    },
    {
      "classification_loss": 0.5845311880111694,
      "epoch": 18.003278688524592,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21101732552051544,
      "orthogonal_weight": 0.1,
      "step": 5491,
      "total_loss": 0.6056329011917114,
      "weighted_orthogonal_loss": 0.021101733669638634
    },
    {
      "classification_loss": 0.6467795968055725,
      "epoch": 18.00655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21104268729686737,
      "orthogonal_weight": 0.1,
      "step": 5492,
      "total_loss": 0.6678838729858398,
      "weighted_orthogonal_loss": 0.021104268729686737
    },
    {
      "classification_loss": 0.6281165480613708,
      "epoch": 18.009836065573772,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105864644050598,
      "orthogonal_weight": 0.1,
      "step": 5493,
      "total_loss": 0.6492224335670471,
      "weighted_orthogonal_loss": 0.021105865016579628
    },
    {
      "classification_loss": 0.5624076128005981,
      "epoch": 18.01311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107295155525208,
      "orthogonal_weight": 0.1,
      "step": 5494,
      "total_loss": 0.583514928817749,
      "weighted_orthogonal_loss": 0.021107295528054237
    },
    {
      "classification_loss": 0.6428660750389099,
      "epoch": 18.016393442622952,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109266579151154,
      "orthogonal_weight": 0.1,
      "step": 5495,
      "total_loss": 0.6639753580093384,
      "weighted_orthogonal_loss": 0.021109266206622124
    },
    {
      "classification_loss": 0.5745415091514587,
      "epoch": 18.01967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110932618379593,
      "orthogonal_weight": 0.1,
      "step": 5496,
      "total_loss": 0.595650851726532,
      "weighted_orthogonal_loss": 0.0211093258112669
    },
    {
      "classification_loss": 0.5891650915145874,
      "epoch": 18.022950819672133,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109770238399506,
      "orthogonal_weight": 0.1,
      "step": 5497,
      "total_loss": 0.6102748513221741,
      "weighted_orthogonal_loss": 0.021109770983457565
    },
    {
      "classification_loss": 0.6791678071022034,
      "epoch": 18.02622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108506619930267,
      "orthogonal_weight": 0.1,
      "step": 5498,
      "total_loss": 0.7002763152122498,
      "weighted_orthogonal_loss": 0.021108506247401237
    },
    {
      "classification_loss": 0.5281957983970642,
      "epoch": 18.029508196721313,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110816240310669,
      "orthogonal_weight": 0.1,
      "step": 5499,
      "total_loss": 0.5493039488792419,
      "weighted_orthogonal_loss": 0.02110816352069378
    },
    {
      "epoch": 18.0327868852459,
      "grad_norm": 9.03116226196289,
      "learning_rate": 2.0033333333333334e-05,
      "loss": 0.6323,
      "step": 5500
    },
    {
      "classification_loss": 0.627738893032074,
      "epoch": 18.0327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107622981071472,
      "orthogonal_weight": 0.1,
      "step": 5500,
      "total_loss": 0.6488465070724487,
      "weighted_orthogonal_loss": 0.021107623353600502
    },
    {
      "classification_loss": 0.5770788192749023,
      "epoch": 18.036065573770493,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108488738536835,
      "orthogonal_weight": 0.1,
      "step": 5501,
      "total_loss": 0.5981873273849487,
      "weighted_orthogonal_loss": 0.021108489483594894
    },
    {
      "classification_loss": 0.5614668726921082,
      "epoch": 18.03934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111133486032486,
      "orthogonal_weight": 0.1,
      "step": 5502,
      "total_loss": 0.582578182220459,
      "weighted_orthogonal_loss": 0.02111133560538292
    },
    {
      "classification_loss": 0.6210890412330627,
      "epoch": 18.042622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211106076836586,
      "orthogonal_weight": 0.1,
      "step": 5503,
      "total_loss": 0.6421996355056763,
      "weighted_orthogonal_loss": 0.02111060731112957
    },
    {
      "classification_loss": 0.6527096033096313,
      "epoch": 18.04590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109986305236816,
      "orthogonal_weight": 0.1,
      "step": 5504,
      "total_loss": 0.6738196015357971,
      "weighted_orthogonal_loss": 0.021109987050294876
    },
    {
      "classification_loss": 0.6068559885025024,
      "epoch": 18.049180327868854,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110939472913742,
      "orthogonal_weight": 0.1,
      "step": 5505,
      "total_loss": 0.6279653906822205,
      "weighted_orthogonal_loss": 0.02110939472913742
    },
    {
      "classification_loss": 0.5539416670799255,
      "epoch": 18.052459016393442,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109691262245178,
      "orthogonal_weight": 0.1,
      "step": 5506,
      "total_loss": 0.5750513672828674,
      "weighted_orthogonal_loss": 0.02110969088971615
    },
    {
      "classification_loss": 0.5938857197761536,
      "epoch": 18.055737704918034,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109963953495026,
      "orthogonal_weight": 0.1,
      "step": 5507,
      "total_loss": 0.6149956583976746,
      "weighted_orthogonal_loss": 0.021109964698553085
    },
    {
      "classification_loss": 0.6296212077140808,
      "epoch": 18.059016393442622,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109887957572937,
      "orthogonal_weight": 0.1,
      "step": 5508,
      "total_loss": 0.650731086730957,
      "weighted_orthogonal_loss": 0.021109888330101967
    },
    {
      "classification_loss": 0.6643228530883789,
      "epoch": 18.062295081967214,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109506487846375,
      "orthogonal_weight": 0.1,
      "step": 5509,
      "total_loss": 0.6854323744773865,
      "weighted_orthogonal_loss": 0.021109506487846375
    },
    {
      "classification_loss": 0.6169781684875488,
      "epoch": 18.065573770491802,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110956460237503,
      "orthogonal_weight": 0.1,
      "step": 5510,
      "total_loss": 0.6380877494812012,
      "weighted_orthogonal_loss": 0.021109564229846
    },
    {
      "classification_loss": 0.5883306264877319,
      "epoch": 18.068852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108593046665192,
      "orthogonal_weight": 0.1,
      "step": 5511,
      "total_loss": 0.6094391942024231,
      "weighted_orthogonal_loss": 0.02110859379172325
    },
    {
      "classification_loss": 0.5957038402557373,
      "epoch": 18.072131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110951989889145,
      "orthogonal_weight": 0.1,
      "step": 5512,
      "total_loss": 0.6168133616447449,
      "weighted_orthogonal_loss": 0.02110951952636242
    },
    {
      "classification_loss": 0.5804187655448914,
      "epoch": 18.075409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21109506487846375,
      "orthogonal_weight": 0.1,
      "step": 5513,
      "total_loss": 0.6015282869338989,
      "weighted_orthogonal_loss": 0.021109506487846375
    },
    {
      "classification_loss": 0.6055997014045715,
      "epoch": 18.078688524590163,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211089625954628,
      "orthogonal_weight": 0.1,
      "step": 5514,
      "total_loss": 0.6267086863517761,
      "weighted_orthogonal_loss": 0.0211089625954628
    },
    {
      "classification_loss": 0.612634539604187,
      "epoch": 18.081967213114755,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108241379261017,
      "orthogonal_weight": 0.1,
      "step": 5515,
      "total_loss": 0.6337428092956543,
      "weighted_orthogonal_loss": 0.021108241751790047
    },
    {
      "classification_loss": 0.6353951096534729,
      "epoch": 18.085245901639343,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110651284456253,
      "orthogonal_weight": 0.1,
      "step": 5516,
      "total_loss": 0.6565016508102417,
      "weighted_orthogonal_loss": 0.02110651321709156
    },
    {
      "classification_loss": 0.593278706073761,
      "epoch": 18.088524590163935,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105416119098663,
      "orthogonal_weight": 0.1,
      "step": 5517,
      "total_loss": 0.614384114742279,
      "weighted_orthogonal_loss": 0.021105416119098663
    },
    {
      "classification_loss": 0.5951212048530579,
      "epoch": 18.091803278688523,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21104110777378082,
      "orthogonal_weight": 0.1,
      "step": 5518,
      "total_loss": 0.6162253022193909,
      "weighted_orthogonal_loss": 0.021104110404849052
    },
    {
      "classification_loss": 0.6142765283584595,
      "epoch": 18.095081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21103404462337494,
      "orthogonal_weight": 0.1,
      "step": 5519,
      "total_loss": 0.6353799104690552,
      "weighted_orthogonal_loss": 0.021103404462337494
    },
    {
      "classification_loss": 0.5855938792228699,
      "epoch": 18.098360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21102619171142578,
      "orthogonal_weight": 0.1,
      "step": 5520,
      "total_loss": 0.6066964864730835,
      "weighted_orthogonal_loss": 0.021102620288729668
    },
    {
      "classification_loss": 0.633552610874176,
      "epoch": 18.101639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21101529896259308,
      "orthogonal_weight": 0.1,
      "step": 5521,
      "total_loss": 0.6546541452407837,
      "weighted_orthogonal_loss": 0.021101530641317368
    },
    {
      "classification_loss": 0.6297272443771362,
      "epoch": 18.104918032786884,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21100826561450958,
      "orthogonal_weight": 0.1,
      "step": 5522,
      "total_loss": 0.6508280634880066,
      "weighted_orthogonal_loss": 0.021100826561450958
    },
    {
      "classification_loss": 0.6389968991279602,
      "epoch": 18.108196721311476,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109978199005127,
      "orthogonal_weight": 0.1,
      "step": 5523,
      "total_loss": 0.6600967049598694,
      "weighted_orthogonal_loss": 0.02109978161752224
    },
    {
      "classification_loss": 0.5996295213699341,
      "epoch": 18.111475409836064,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109963446855545,
      "orthogonal_weight": 0.1,
      "step": 5524,
      "total_loss": 0.6207291483879089,
      "weighted_orthogonal_loss": 0.02109963446855545
    },
    {
      "classification_loss": 0.649306058883667,
      "epoch": 18.114754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21099495887756348,
      "orthogonal_weight": 0.1,
      "step": 5525,
      "total_loss": 0.6704055666923523,
      "weighted_orthogonal_loss": 0.021099496632814407
    },
    {
      "classification_loss": 0.5912129878997803,
      "epoch": 18.118032786885244,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21098731458187103,
      "orthogonal_weight": 0.1,
      "step": 5526,
      "total_loss": 0.6123117208480835,
      "weighted_orthogonal_loss": 0.021098731085658073
    },
    {
      "classification_loss": 0.560101330280304,
      "epoch": 18.121311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21098032593727112,
      "orthogonal_weight": 0.1,
      "step": 5527,
      "total_loss": 0.5811993479728699,
      "weighted_orthogonal_loss": 0.021098032593727112
    },
    {
      "classification_loss": 0.6746377348899841,
      "epoch": 18.124590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21098238229751587,
      "orthogonal_weight": 0.1,
      "step": 5528,
      "total_loss": 0.6957359910011292,
      "weighted_orthogonal_loss": 0.021098239347338676
    },
    {
      "classification_loss": 0.6102811694145203,
      "epoch": 18.127868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094277501106262,
      "orthogonal_weight": 0.1,
      "step": 5529,
      "total_loss": 0.6313754320144653,
      "weighted_orthogonal_loss": 0.021094277501106262
    },
    {
      "classification_loss": 0.5434715151786804,
      "epoch": 18.131147540983605,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21091368794441223,
      "orthogonal_weight": 0.1,
      "step": 5530,
      "total_loss": 0.5645628571510315,
      "weighted_orthogonal_loss": 0.021091369912028313
    },
    {
      "classification_loss": 0.6757029294967651,
      "epoch": 18.134426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108810395002365,
      "orthogonal_weight": 0.1,
      "step": 5531,
      "total_loss": 0.6967910528182983,
      "weighted_orthogonal_loss": 0.02108810469508171
    },
    {
      "classification_loss": 0.6161622405052185,
      "epoch": 18.137704918032785,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108500450849533,
      "orthogonal_weight": 0.1,
      "step": 5532,
      "total_loss": 0.6372472643852234,
      "weighted_orthogonal_loss": 0.02108500525355339
    },
    {
      "classification_loss": 0.6218228340148926,
      "epoch": 18.140983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21084649860858917,
      "orthogonal_weight": 0.1,
      "step": 5533,
      "total_loss": 0.6429075002670288,
      "weighted_orthogonal_loss": 0.021084649488329887
    },
    {
      "classification_loss": 0.601604700088501,
      "epoch": 18.14426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21085526049137115,
      "orthogonal_weight": 0.1,
      "step": 5534,
      "total_loss": 0.6226902008056641,
      "weighted_orthogonal_loss": 0.021085526794195175
    },
    {
      "classification_loss": 0.6114409565925598,
      "epoch": 18.147540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21087779104709625,
      "orthogonal_weight": 0.1,
      "step": 5535,
      "total_loss": 0.6325287222862244,
      "weighted_orthogonal_loss": 0.021087778732180595
    },
    {
      "classification_loss": 0.5851995348930359,
      "epoch": 18.15081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21088796854019165,
      "orthogonal_weight": 0.1,
      "step": 5536,
      "total_loss": 0.6062883138656616,
      "weighted_orthogonal_loss": 0.021088797599077225
    },
    {
      "classification_loss": 0.5869584679603577,
      "epoch": 18.154098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108880579471588,
      "orthogonal_weight": 0.1,
      "step": 5537,
      "total_loss": 0.6080472469329834,
      "weighted_orthogonal_loss": 0.02108880691230297
    },
    {
      "classification_loss": 0.5937634706497192,
      "epoch": 18.15737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108975350856781,
      "orthogonal_weight": 0.1,
      "step": 5538,
      "total_loss": 0.6148532032966614,
      "weighted_orthogonal_loss": 0.02108975313603878
    },
    {
      "classification_loss": 0.6381981372833252,
      "epoch": 18.160655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109030932188034,
      "orthogonal_weight": 0.1,
      "step": 5539,
      "total_loss": 0.6592884659767151,
      "weighted_orthogonal_loss": 0.0210903100669384
    },
    {
      "classification_loss": 0.5686750411987305,
      "epoch": 18.16393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21090258657932281,
      "orthogonal_weight": 0.1,
      "step": 5540,
      "total_loss": 0.5897653102874756,
      "weighted_orthogonal_loss": 0.02109025977551937
    },
    {
      "classification_loss": 0.6752724051475525,
      "epoch": 18.167213114754098,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21091392636299133,
      "orthogonal_weight": 0.1,
      "step": 5541,
      "total_loss": 0.6963638067245483,
      "weighted_orthogonal_loss": 0.021091392263770103
    },
    {
      "classification_loss": 0.5673556923866272,
      "epoch": 18.17049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21093298494815826,
      "orthogonal_weight": 0.1,
      "step": 5542,
      "total_loss": 0.5884490013122559,
      "weighted_orthogonal_loss": 0.021093299612402916
    },
    {
      "classification_loss": 0.6467140316963196,
      "epoch": 18.17377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094460785388947,
      "orthogonal_weight": 0.1,
      "step": 5543,
      "total_loss": 0.667808473110199,
      "weighted_orthogonal_loss": 0.021094461902976036
    },
    {
      "classification_loss": 0.6450685262680054,
      "epoch": 18.17704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094107627868652,
      "orthogonal_weight": 0.1,
      "step": 5544,
      "total_loss": 0.6661626100540161,
      "weighted_orthogonal_loss": 0.021094108000397682
    },
    {
      "classification_loss": 0.7227994203567505,
      "epoch": 18.18032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21093976497650146,
      "orthogonal_weight": 0.1,
      "step": 5545,
      "total_loss": 0.7438933849334717,
      "weighted_orthogonal_loss": 0.021093977615237236
    },
    {
      "classification_loss": 0.6209275126457214,
      "epoch": 18.18360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21093089878559113,
      "orthogonal_weight": 0.1,
      "step": 5546,
      "total_loss": 0.642020583152771,
      "weighted_orthogonal_loss": 0.021093090996146202
    },
    {
      "classification_loss": 0.6323110461235046,
      "epoch": 18.18688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109387069940567,
      "orthogonal_weight": 0.1,
      "step": 5547,
      "total_loss": 0.6534048914909363,
      "weighted_orthogonal_loss": 0.02109387144446373
    },
    {
      "classification_loss": 0.5713949203491211,
      "epoch": 18.19016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094147861003876,
      "orthogonal_weight": 0.1,
      "step": 5548,
      "total_loss": 0.5924890637397766,
      "weighted_orthogonal_loss": 0.021094148978590965
    },
    {
      "classification_loss": 0.5933094024658203,
      "epoch": 18.19344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094004809856415,
      "orthogonal_weight": 0.1,
      "step": 5549,
      "total_loss": 0.6144034266471863,
      "weighted_orthogonal_loss": 0.021094005554914474
    },
    {
      "classification_loss": 0.5630362629890442,
      "epoch": 18.19672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21094121038913727,
      "orthogonal_weight": 0.1,
      "step": 5550,
      "total_loss": 0.5841304063796997,
      "weighted_orthogonal_loss": 0.021094121038913727
    },
    {
      "classification_loss": 0.607939600944519,
      "epoch": 18.2,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109774500131607,
      "orthogonal_weight": 0.1,
      "step": 5551,
      "total_loss": 0.6290373206138611,
      "weighted_orthogonal_loss": 0.02109774574637413
    },
    {
      "classification_loss": 0.610078752040863,
      "epoch": 18.20327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109992802143097,
      "orthogonal_weight": 0.1,
      "step": 5552,
      "total_loss": 0.6311786770820618,
      "weighted_orthogonal_loss": 0.02109992876648903
    },
    {
      "classification_loss": 0.629112720489502,
      "epoch": 18.20655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110104113817215,
      "orthogonal_weight": 0.1,
      "step": 5553,
      "total_loss": 0.6502137780189514,
      "weighted_orthogonal_loss": 0.02110104076564312
    },
    {
      "classification_loss": 0.6451266407966614,
      "epoch": 18.20983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21101532876491547,
      "orthogonal_weight": 0.1,
      "step": 5554,
      "total_loss": 0.666228175163269,
      "weighted_orthogonal_loss": 0.021101532503962517
    },
    {
      "classification_loss": 0.5382184386253357,
      "epoch": 18.21311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110060602426529,
      "orthogonal_weight": 0.1,
      "step": 5555,
      "total_loss": 0.559319019317627,
      "weighted_orthogonal_loss": 0.02110060676932335
    },
    {
      "classification_loss": 0.6302832365036011,
      "epoch": 18.21639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110249251127243,
      "orthogonal_weight": 0.1,
      "step": 5556,
      "total_loss": 0.6513857245445251,
      "weighted_orthogonal_loss": 0.02110249362885952
    },
    {
      "classification_loss": 0.6064902544021606,
      "epoch": 18.21967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21104687452316284,
      "orthogonal_weight": 0.1,
      "step": 5557,
      "total_loss": 0.6275949478149414,
      "weighted_orthogonal_loss": 0.021104687824845314
    },
    {
      "classification_loss": 0.673528790473938,
      "epoch": 18.222950819672132,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110632210969925,
      "orthogonal_weight": 0.1,
      "step": 5558,
      "total_loss": 0.6946350932121277,
      "weighted_orthogonal_loss": 0.02110632322728634
    },
    {
      "classification_loss": 0.6329578161239624,
      "epoch": 18.22622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21105942130088806,
      "orthogonal_weight": 0.1,
      "step": 5559,
      "total_loss": 0.6540637612342834,
      "weighted_orthogonal_loss": 0.021105943247675896
    },
    {
      "classification_loss": 0.5745667815208435,
      "epoch": 18.229508196721312,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108271181583405,
      "orthogonal_weight": 0.1,
      "step": 5560,
      "total_loss": 0.5956750512123108,
      "weighted_orthogonal_loss": 0.021108271554112434
    },
    {
      "classification_loss": 0.7148482203483582,
      "epoch": 18.2327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211105078458786,
      "orthogonal_weight": 0.1,
      "step": 5561,
      "total_loss": 0.7359587550163269,
      "weighted_orthogonal_loss": 0.02111050859093666
    },
    {
      "classification_loss": 0.5473232269287109,
      "epoch": 18.236065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21112623810768127,
      "orthogonal_weight": 0.1,
      "step": 5562,
      "total_loss": 0.5684358477592468,
      "weighted_orthogonal_loss": 0.021112624555826187
    },
    {
      "classification_loss": 0.5566058158874512,
      "epoch": 18.23934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115070581436157,
      "orthogonal_weight": 0.1,
      "step": 5563,
      "total_loss": 0.5777208805084229,
      "weighted_orthogonal_loss": 0.021115070208907127
    },
    {
      "classification_loss": 0.6554174423217773,
      "epoch": 18.242622950819673,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111557424068451,
      "orthogonal_weight": 0.1,
      "step": 5564,
      "total_loss": 0.676533043384552,
      "weighted_orthogonal_loss": 0.02111557498574257
    },
    {
      "classification_loss": 0.5922852754592896,
      "epoch": 18.24590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115167438983917,
      "orthogonal_weight": 0.1,
      "step": 5565,
      "total_loss": 0.6134004592895508,
      "weighted_orthogonal_loss": 0.021115167066454887
    },
    {
      "classification_loss": 0.6495516896247864,
      "epoch": 18.249180327868853,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115411818027496,
      "orthogonal_weight": 0.1,
      "step": 5566,
      "total_loss": 0.6706671118736267,
      "weighted_orthogonal_loss": 0.021115412935614586
    },
    {
      "classification_loss": 0.5979490876197815,
      "epoch": 18.25245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21116553246974945,
      "orthogonal_weight": 0.1,
      "step": 5567,
      "total_loss": 0.6190656423568726,
      "weighted_orthogonal_loss": 0.021116552874445915
    },
    {
      "classification_loss": 0.61554354429245,
      "epoch": 18.255737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21118322014808655,
      "orthogonal_weight": 0.1,
      "step": 5568,
      "total_loss": 0.6366618871688843,
      "weighted_orthogonal_loss": 0.021118322387337685
    },
    {
      "classification_loss": 0.5363969802856445,
      "epoch": 18.25901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21120460331439972,
      "orthogonal_weight": 0.1,
      "step": 5569,
      "total_loss": 0.5575174689292908,
      "weighted_orthogonal_loss": 0.021120460703969002
    },
    {
      "classification_loss": 0.581845760345459,
      "epoch": 18.262295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112254649400711,
      "orthogonal_weight": 0.1,
      "step": 5570,
      "total_loss": 0.6029683351516724,
      "weighted_orthogonal_loss": 0.02112254686653614
    },
    {
      "classification_loss": 0.6791175007820129,
      "epoch": 18.2655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112456113100052,
      "orthogonal_weight": 0.1,
      "step": 5571,
      "total_loss": 0.7002420425415039,
      "weighted_orthogonal_loss": 0.02112456224858761
    },
    {
      "classification_loss": 0.6784679889678955,
      "epoch": 18.268852459016394,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2112220823764801,
      "orthogonal_weight": 0.1,
      "step": 5572,
      "total_loss": 0.6995902061462402,
      "weighted_orthogonal_loss": 0.02112220786511898
    },
    {
      "classification_loss": 0.5427847504615784,
      "epoch": 18.272131147540982,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21120835840702057,
      "orthogonal_weight": 0.1,
      "step": 5573,
      "total_loss": 0.5639055967330933,
      "weighted_orthogonal_loss": 0.021120836958289146
    },
    {
      "classification_loss": 0.5902315974235535,
      "epoch": 18.275409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111959606409073,
      "orthogonal_weight": 0.1,
      "step": 5574,
      "total_loss": 0.6113511919975281,
      "weighted_orthogonal_loss": 0.02111959643661976
    },
    {
      "classification_loss": 0.6259908080101013,
      "epoch": 18.278688524590162,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21119222044944763,
      "orthogonal_weight": 0.1,
      "step": 5575,
      "total_loss": 0.6471100449562073,
      "weighted_orthogonal_loss": 0.021119222044944763
    },
    {
      "classification_loss": 0.6074650287628174,
      "epoch": 18.281967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111850082874298,
      "orthogonal_weight": 0.1,
      "step": 5576,
      "total_loss": 0.628583550453186,
      "weighted_orthogonal_loss": 0.02111850120127201
    },
    {
      "classification_loss": 0.6450287103652954,
      "epoch": 18.285245901639342,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111848145723343,
      "orthogonal_weight": 0.1,
      "step": 5577,
      "total_loss": 0.6661471724510193,
      "weighted_orthogonal_loss": 0.02111848257482052
    },
    {
      "classification_loss": 0.6375022530555725,
      "epoch": 18.288524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21119128167629242,
      "orthogonal_weight": 0.1,
      "step": 5578,
      "total_loss": 0.6586213707923889,
      "weighted_orthogonal_loss": 0.0211191289126873
    },
    {
      "classification_loss": 0.5189608931541443,
      "epoch": 18.291803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21121817827224731,
      "orthogonal_weight": 0.1,
      "step": 5579,
      "total_loss": 0.5400826930999756,
      "weighted_orthogonal_loss": 0.02112181857228279
    },
    {
      "classification_loss": 0.5738716721534729,
      "epoch": 18.295081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21125003695487976,
      "orthogonal_weight": 0.1,
      "step": 5580,
      "total_loss": 0.5949966907501221,
      "weighted_orthogonal_loss": 0.021125003695487976
    },
    {
      "classification_loss": 0.48821863532066345,
      "epoch": 18.298360655737707,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21121273934841156,
      "orthogonal_weight": 0.1,
      "step": 5581,
      "total_loss": 0.5093399286270142,
      "weighted_orthogonal_loss": 0.021121274679899216
    },
    {
      "classification_loss": 0.6432601809501648,
      "epoch": 18.301639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21117831766605377,
      "orthogonal_weight": 0.1,
      "step": 5582,
      "total_loss": 0.6643779873847961,
      "weighted_orthogonal_loss": 0.021117832511663437
    },
    {
      "classification_loss": 0.5056383013725281,
      "epoch": 18.304918032786887,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21115106344223022,
      "orthogonal_weight": 0.1,
      "step": 5583,
      "total_loss": 0.5267534255981445,
      "weighted_orthogonal_loss": 0.021115107461810112
    },
    {
      "classification_loss": 0.5935394763946533,
      "epoch": 18.308196721311475,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21113628149032593,
      "orthogonal_weight": 0.1,
      "step": 5584,
      "total_loss": 0.6146531105041504,
      "weighted_orthogonal_loss": 0.021113628521561623
    },
    {
      "classification_loss": 0.5494080185890198,
      "epoch": 18.311475409836067,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21112105250358582,
      "orthogonal_weight": 0.1,
      "step": 5585,
      "total_loss": 0.5705201029777527,
      "weighted_orthogonal_loss": 0.02111210487782955
    },
    {
      "classification_loss": 0.5604767203330994,
      "epoch": 18.314754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21110369265079498,
      "orthogonal_weight": 0.1,
      "step": 5586,
      "total_loss": 0.5815870761871338,
      "weighted_orthogonal_loss": 0.02111036889255047
    },
    {
      "classification_loss": 0.6006674766540527,
      "epoch": 18.318032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2110891044139862,
      "orthogonal_weight": 0.1,
      "step": 5587,
      "total_loss": 0.6217764019966125,
      "weighted_orthogonal_loss": 0.02110891044139862
    },
    {
      "classification_loss": 0.6177339553833008,
      "epoch": 18.321311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107642352581024,
      "orthogonal_weight": 0.1,
      "step": 5588,
      "total_loss": 0.6388415694236755,
      "weighted_orthogonal_loss": 0.021107641980051994
    },
    {
      "classification_loss": 0.6119734644889832,
      "epoch": 18.324590163934428,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.211068257689476,
      "orthogonal_weight": 0.1,
      "step": 5589,
      "total_loss": 0.6330803036689758,
      "weighted_orthogonal_loss": 0.02110682614147663
    },
    {
      "classification_loss": 0.7263109683990479,
      "epoch": 18.327868852459016,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21107687056064606,
      "orthogonal_weight": 0.1,
      "step": 5590,
      "total_loss": 0.7474186420440674,
      "weighted_orthogonal_loss": 0.021107686683535576
    },
    {
      "classification_loss": 0.5958821773529053,
      "epoch": 18.331147540983608,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2111361175775528,
      "orthogonal_weight": 0.1,
      "step": 5591,
      "total_loss": 0.6169958114624023,
      "weighted_orthogonal_loss": 0.02111361175775528
    },
    {
      "classification_loss": 0.626257061958313,
      "epoch": 18.334426229508196,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21120281517505646,
      "orthogonal_weight": 0.1,
      "step": 5592,
      "total_loss": 0.6473773717880249,
      "weighted_orthogonal_loss": 0.021120281890034676
    },
    {
      "classification_loss": 0.5627865195274353,
      "epoch": 18.337704918032788,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21125489473342896,
      "orthogonal_weight": 0.1,
      "step": 5593,
      "total_loss": 0.5839120149612427,
      "weighted_orthogonal_loss": 0.021125489845871925
    },
    {
      "classification_loss": 0.5974477529525757,
      "epoch": 18.340983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21127261221408844,
      "orthogonal_weight": 0.1,
      "step": 5594,
      "total_loss": 0.6185750365257263,
      "weighted_orthogonal_loss": 0.021127261221408844
    },
    {
      "classification_loss": 0.6083399057388306,
      "epoch": 18.34426229508197,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21128055453300476,
      "orthogonal_weight": 0.1,
      "step": 5595,
      "total_loss": 0.6294679641723633,
      "weighted_orthogonal_loss": 0.021128056570887566
    },
    {
      "classification_loss": 0.6775171160697937,
      "epoch": 18.347540983606557,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21126912534236908,
      "orthogonal_weight": 0.1,
      "step": 5596,
      "total_loss": 0.6986440420150757,
      "weighted_orthogonal_loss": 0.021126912906765938
    },
    {
      "classification_loss": 0.6149626970291138,
      "epoch": 18.35081967213115,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21125513315200806,
      "orthogonal_weight": 0.1,
      "step": 5597,
      "total_loss": 0.6360881924629211,
      "weighted_orthogonal_loss": 0.021125514060258865
    },
    {
      "classification_loss": 0.6376105546951294,
      "epoch": 18.354098360655737,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21123738586902618,
      "orthogonal_weight": 0.1,
      "step": 5598,
      "total_loss": 0.6587343215942383,
      "weighted_orthogonal_loss": 0.021123738959431648
    },
    {
      "classification_loss": 0.6476401686668396,
      "epoch": 18.35737704918033,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21119767427444458,
      "orthogonal_weight": 0.1,
      "step": 5599,
      "total_loss": 0.6687599420547485,
      "weighted_orthogonal_loss": 0.021119767799973488
    },
    {
      "epoch": 18.360655737704917,
      "grad_norm": 4.078786373138428,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 0.6305,
      "step": 5600
    },
    {
      "classification_loss": 0.5985381603240967,
      "epoch": 18.360655737704917,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21113736927509308,
      "orthogonal_weight": 0.1,
      "step": 5600,
      "total_loss": 0.6196519136428833,
      "weighted_orthogonal_loss": 0.021113736554980278
    },
    {
      "classification_loss": 0.6035073399543762,
      "epoch": 18.36393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21108120679855347,
      "orthogonal_weight": 0.1,
      "step": 5601,
      "total_loss": 0.6246154308319092,
      "weighted_orthogonal_loss": 0.021108120679855347
    },
    {
      "classification_loss": 0.6101140379905701,
      "epoch": 18.367213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21102534234523773,
      "orthogonal_weight": 0.1,
      "step": 5602,
      "total_loss": 0.6312165856361389,
      "weighted_orthogonal_loss": 0.021102534607052803
    },
    {
      "classification_loss": 0.5813207626342773,
      "epoch": 18.37049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2109789401292801,
      "orthogonal_weight": 0.1,
      "step": 5603,
      "total_loss": 0.6024186611175537,
      "weighted_orthogonal_loss": 0.02109789475798607
    },
    {
      "classification_loss": 0.5988249778747559,
      "epoch": 18.373770491803278,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21093285083770752,
      "orthogonal_weight": 0.1,
      "step": 5604,
      "total_loss": 0.6199182868003845,
      "weighted_orthogonal_loss": 0.021093284711241722
    },
    {
      "classification_loss": 0.5876189470291138,
      "epoch": 18.37704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21088996529579163,
      "orthogonal_weight": 0.1,
      "step": 5605,
      "total_loss": 0.6087079644203186,
      "weighted_orthogonal_loss": 0.021088996902108192
    },
    {
      "classification_loss": 0.5119184851646423,
      "epoch": 18.380327868852458,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2108486443758011,
      "orthogonal_weight": 0.1,
      "step": 5606,
      "total_loss": 0.5330033302307129,
      "weighted_orthogonal_loss": 0.021084865555167198
    },
    {
      "classification_loss": 0.6154627799987793,
      "epoch": 18.38360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21082249283790588,
      "orthogonal_weight": 0.1,
      "step": 5607,
      "total_loss": 0.6365450024604797,
      "weighted_orthogonal_loss": 0.021082250401377678
    },
    {
      "classification_loss": 0.6342762112617493,
      "epoch": 18.386885245901638,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21080420911312103,
      "orthogonal_weight": 0.1,
      "step": 5608,
      "total_loss": 0.6553566455841064,
      "weighted_orthogonal_loss": 0.021080421283841133
    },
    {
      "classification_loss": 0.5232537984848022,
      "epoch": 18.39016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21078409254550934,
      "orthogonal_weight": 0.1,
      "step": 5609,
      "total_loss": 0.5443322062492371,
      "weighted_orthogonal_loss": 0.021078409627079964
    },
    {
      "classification_loss": 0.63498854637146,
      "epoch": 18.39344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21076011657714844,
      "orthogonal_weight": 0.1,
      "step": 5610,
      "total_loss": 0.6560645699501038,
      "weighted_orthogonal_loss": 0.021076012402772903
    },
    {
      "classification_loss": 0.6241185069084167,
      "epoch": 18.39672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21072585880756378,
      "orthogonal_weight": 0.1,
      "step": 5611,
      "total_loss": 0.6451910734176636,
      "weighted_orthogonal_loss": 0.021072586998343468
    },
    {
      "classification_loss": 0.6363571286201477,
      "epoch": 18.4,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21069221198558807,
      "orthogonal_weight": 0.1,
      "step": 5612,
      "total_loss": 0.6574263572692871,
      "weighted_orthogonal_loss": 0.021069221198558807
    },
    {
      "classification_loss": 0.6447362303733826,
      "epoch": 18.40327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106483280658722,
      "orthogonal_weight": 0.1,
      "step": 5613,
      "total_loss": 0.6658010482788086,
      "weighted_orthogonal_loss": 0.02106483280658722
    },
    {
      "classification_loss": 0.5734249949455261,
      "epoch": 18.40655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2106042504310608,
      "orthogonal_weight": 0.1,
      "step": 5614,
      "total_loss": 0.5944854021072388,
      "weighted_orthogonal_loss": 0.02106042578816414
    },
    {
      "classification_loss": 0.5645385980606079,
      "epoch": 18.40983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21055983006954193,
      "orthogonal_weight": 0.1,
      "step": 5615,
      "total_loss": 0.5855945944786072,
      "weighted_orthogonal_loss": 0.021055983379483223
    },
    {
      "classification_loss": 0.6515647172927856,
      "epoch": 18.41311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21051402390003204,
      "orthogonal_weight": 0.1,
      "step": 5616,
      "total_loss": 0.6726161241531372,
      "weighted_orthogonal_loss": 0.021051403135061264
    },
    {
      "classification_loss": 0.6107845902442932,
      "epoch": 18.41639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21044044196605682,
      "orthogonal_weight": 0.1,
      "step": 5617,
      "total_loss": 0.6318286061286926,
      "weighted_orthogonal_loss": 0.021044043824076653
    },
    {
      "classification_loss": 0.6091954708099365,
      "epoch": 18.41967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21038325130939484,
      "orthogonal_weight": 0.1,
      "step": 5618,
      "total_loss": 0.6302338242530823,
      "weighted_orthogonal_loss": 0.021038325503468513
    },
    {
      "classification_loss": 0.5782207250595093,
      "epoch": 18.42295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21032820641994476,
      "orthogonal_weight": 0.1,
      "step": 5619,
      "total_loss": 0.5992535352706909,
      "weighted_orthogonal_loss": 0.021032821387052536
    },
    {
      "classification_loss": 0.5820640325546265,
      "epoch": 18.42622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21028423309326172,
      "orthogonal_weight": 0.1,
      "step": 5620,
      "total_loss": 0.6030924320220947,
      "weighted_orthogonal_loss": 0.0210284236818552
    },
    {
      "classification_loss": 0.7023900747299194,
      "epoch": 18.42950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21020957827568054,
      "orthogonal_weight": 0.1,
      "step": 5621,
      "total_loss": 0.7234110236167908,
      "weighted_orthogonal_loss": 0.021020958200097084
    },
    {
      "classification_loss": 0.6142688393592834,
      "epoch": 18.432786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21014146506786346,
      "orthogonal_weight": 0.1,
      "step": 5622,
      "total_loss": 0.6352829933166504,
      "weighted_orthogonal_loss": 0.021014146506786346
    },
    {
      "classification_loss": 0.6056121587753296,
      "epoch": 18.43606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21008142828941345,
      "orthogonal_weight": 0.1,
      "step": 5623,
      "total_loss": 0.6266202926635742,
      "weighted_orthogonal_loss": 0.021008143201470375
    },
    {
      "classification_loss": 0.6110079884529114,
      "epoch": 18.439344262295084,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210040882229805,
      "orthogonal_weight": 0.1,
      "step": 5624,
      "total_loss": 0.6320120692253113,
      "weighted_orthogonal_loss": 0.0210040882229805
    },
    {
      "classification_loss": 0.5721759796142578,
      "epoch": 18.442622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21001183986663818,
      "orthogonal_weight": 0.1,
      "step": 5625,
      "total_loss": 0.5931771397590637,
      "weighted_orthogonal_loss": 0.021001184359192848
    },
    {
      "classification_loss": 0.6512614488601685,
      "epoch": 18.445901639344264,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20998786389827728,
      "orthogonal_weight": 0.1,
      "step": 5626,
      "total_loss": 0.6722602248191833,
      "weighted_orthogonal_loss": 0.020998787134885788
    },
    {
      "classification_loss": 0.6246633529663086,
      "epoch": 18.449180327868852,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20997779071331024,
      "orthogonal_weight": 0.1,
      "step": 5627,
      "total_loss": 0.6456611156463623,
      "weighted_orthogonal_loss": 0.020997779443860054
    },
    {
      "classification_loss": 0.6988711357116699,
      "epoch": 18.452459016393444,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099655419588089,
      "orthogonal_weight": 0.1,
      "step": 5628,
      "total_loss": 0.7198677062988281,
      "weighted_orthogonal_loss": 0.02099655382335186
    },
    {
      "classification_loss": 0.6296859383583069,
      "epoch": 18.455737704918032,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20993967354297638,
      "orthogonal_weight": 0.1,
      "step": 5629,
      "total_loss": 0.650679886341095,
      "weighted_orthogonal_loss": 0.020993968471884727
    },
    {
      "classification_loss": 0.6369109153747559,
      "epoch": 18.459016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20991875231266022,
      "orthogonal_weight": 0.1,
      "step": 5630,
      "total_loss": 0.6579027771949768,
      "weighted_orthogonal_loss": 0.020991874858736992
    },
    {
      "classification_loss": 0.5578699111938477,
      "epoch": 18.462295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20990441739559174,
      "orthogonal_weight": 0.1,
      "step": 5631,
      "total_loss": 0.578860342502594,
      "weighted_orthogonal_loss": 0.020990442484617233
    },
    {
      "classification_loss": 0.5459223985671997,
      "epoch": 18.465573770491805,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20988582074642181,
      "orthogonal_weight": 0.1,
      "step": 5632,
      "total_loss": 0.566910982131958,
      "weighted_orthogonal_loss": 0.02098858170211315
    },
    {
      "classification_loss": 0.593005895614624,
      "epoch": 18.468852459016393,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2098819464445114,
      "orthogonal_weight": 0.1,
      "step": 5633,
      "total_loss": 0.6139940619468689,
      "weighted_orthogonal_loss": 0.02098819427192211
    },
    {
      "classification_loss": 0.6201330423355103,
      "epoch": 18.472131147540985,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20988543331623077,
      "orthogonal_weight": 0.1,
      "step": 5634,
      "total_loss": 0.6411215662956238,
      "weighted_orthogonal_loss": 0.020988544449210167
    },
    {
      "classification_loss": 0.5989071130752563,
      "epoch": 18.475409836065573,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20988918840885162,
      "orthogonal_weight": 0.1,
      "step": 5635,
      "total_loss": 0.6198960542678833,
      "weighted_orthogonal_loss": 0.020988918840885162
    },
    {
      "classification_loss": 0.6140685081481934,
      "epoch": 18.478688524590165,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2098829448223114,
      "orthogonal_weight": 0.1,
      "step": 5636,
      "total_loss": 0.6350567936897278,
      "weighted_orthogonal_loss": 0.02098829485476017
    },
    {
      "classification_loss": 0.5829188823699951,
      "epoch": 18.481967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20987066626548767,
      "orthogonal_weight": 0.1,
      "step": 5637,
      "total_loss": 0.603905975818634,
      "weighted_orthogonal_loss": 0.020987067371606827
    },
    {
      "classification_loss": 0.6134486794471741,
      "epoch": 18.485245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2098662555217743,
      "orthogonal_weight": 0.1,
      "step": 5638,
      "total_loss": 0.6344352960586548,
      "weighted_orthogonal_loss": 0.02098662592470646
    },
    {
      "classification_loss": 0.5754207372665405,
      "epoch": 18.488524590163934,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20986589789390564,
      "orthogonal_weight": 0.1,
      "step": 5639,
      "total_loss": 0.5964073538780212,
      "weighted_orthogonal_loss": 0.020986590534448624
    },
    {
      "classification_loss": 0.5801679491996765,
      "epoch": 18.491803278688526,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20988468825817108,
      "orthogonal_weight": 0.1,
      "step": 5640,
      "total_loss": 0.6011564135551453,
      "weighted_orthogonal_loss": 0.020988469943404198
    },
    {
      "classification_loss": 0.5847904086112976,
      "epoch": 18.495081967213114,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2098967432975769,
      "orthogonal_weight": 0.1,
      "step": 5641,
      "total_loss": 0.6057800650596619,
      "weighted_orthogonal_loss": 0.02098967507481575
    },
    {
      "classification_loss": 0.5569632053375244,
      "epoch": 18.498360655737706,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20990024507045746,
      "orthogonal_weight": 0.1,
      "step": 5642,
      "total_loss": 0.5779532194137573,
      "weighted_orthogonal_loss": 0.020990025252103806
    },
    {
      "classification_loss": 0.5360362529754639,
      "epoch": 18.501639344262294,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20990602672100067,
      "orthogonal_weight": 0.1,
      "step": 5643,
      "total_loss": 0.5570268630981445,
      "weighted_orthogonal_loss": 0.020990602672100067
    },
    {
      "classification_loss": 0.6428914070129395,
      "epoch": 18.504918032786886,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20991064608097076,
      "orthogonal_weight": 0.1,
      "step": 5644,
      "total_loss": 0.6638824939727783,
      "weighted_orthogonal_loss": 0.020991064608097076
    },
    {
      "classification_loss": 0.6110186576843262,
      "epoch": 18.508196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20991811156272888,
      "orthogonal_weight": 0.1,
      "step": 5645,
      "total_loss": 0.6320104598999023,
      "weighted_orthogonal_loss": 0.020991811528801918
    },
    {
      "classification_loss": 0.5729688405990601,
      "epoch": 18.511475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099214494228363,
      "orthogonal_weight": 0.1,
      "step": 5646,
      "total_loss": 0.5939610004425049,
      "weighted_orthogonal_loss": 0.02099214494228363
    },
    {
      "classification_loss": 0.6742134094238281,
      "epoch": 18.514754098360655,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20992900431156158,
      "orthogonal_weight": 0.1,
      "step": 5647,
      "total_loss": 0.6952062845230103,
      "weighted_orthogonal_loss": 0.020992901176214218
    },
    {
      "classification_loss": 0.7030998468399048,
      "epoch": 18.518032786885247,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099423110485077,
      "orthogonal_weight": 0.1,
      "step": 5648,
      "total_loss": 0.7240940928459167,
      "weighted_orthogonal_loss": 0.02099423110485077
    },
    {
      "classification_loss": 0.6593818068504333,
      "epoch": 18.521311475409835,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2099592685699463,
      "orthogonal_weight": 0.1,
      "step": 5649,
      "total_loss": 0.680377721786499,
      "weighted_orthogonal_loss": 0.02099592797458172
    },
    {
      "classification_loss": 0.6745871901512146,
      "epoch": 18.524590163934427,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20997734367847443,
      "orthogonal_weight": 0.1,
      "step": 5650,
      "total_loss": 0.6955849528312683,
      "weighted_orthogonal_loss": 0.020997734740376472
    },
    {
      "classification_loss": 0.6087035536766052,
      "epoch": 18.527868852459015,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20998652279376984,
      "orthogonal_weight": 0.1,
      "step": 5651,
      "total_loss": 0.6297022104263306,
      "weighted_orthogonal_loss": 0.020998653024435043
    },
    {
      "classification_loss": 0.6219021081924438,
      "epoch": 18.531147540983607,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21001125872135162,
      "orthogonal_weight": 0.1,
      "step": 5652,
      "total_loss": 0.642903208732605,
      "weighted_orthogonal_loss": 0.021001126617193222
    },
    {
      "classification_loss": 0.6539826989173889,
      "epoch": 18.534426229508195,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21002793312072754,
      "orthogonal_weight": 0.1,
      "step": 5653,
      "total_loss": 0.6749854683876038,
      "weighted_orthogonal_loss": 0.021002793684601784
    },
    {
      "classification_loss": 0.5466797351837158,
      "epoch": 18.537704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21003110706806183,
      "orthogonal_weight": 0.1,
      "step": 5654,
      "total_loss": 0.5676828622817993,
      "weighted_orthogonal_loss": 0.021003110334277153
    },
    {
      "classification_loss": 0.5982413291931152,
      "epoch": 18.540983606557376,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21002916991710663,
      "orthogonal_weight": 0.1,
      "step": 5655,
      "total_loss": 0.6192442178726196,
      "weighted_orthogonal_loss": 0.021002916619181633
    },
    {
      "classification_loss": 0.6188202500343323,
      "epoch": 18.544262295081968,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21004362404346466,
      "orthogonal_weight": 0.1,
      "step": 5656,
      "total_loss": 0.639824628829956,
      "weighted_orthogonal_loss": 0.021004362031817436
    },
    {
      "classification_loss": 0.6780910491943359,
      "epoch": 18.547540983606556,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21005454659461975,
      "orthogonal_weight": 0.1,
      "step": 5657,
      "total_loss": 0.6990965008735657,
      "weighted_orthogonal_loss": 0.021005455404520035
    },
    {
      "classification_loss": 0.607979953289032,
      "epoch": 18.550819672131148,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21006770431995392,
      "orthogonal_weight": 0.1,
      "step": 5658,
      "total_loss": 0.6289867162704468,
      "weighted_orthogonal_loss": 0.021006770431995392
    },
    {
      "classification_loss": 0.5618642568588257,
      "epoch": 18.554098360655736,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21007736027240753,
      "orthogonal_weight": 0.1,
      "step": 5659,
      "total_loss": 0.5828719735145569,
      "weighted_orthogonal_loss": 0.021007737144827843
    },
    {
      "classification_loss": 0.5604460835456848,
      "epoch": 18.557377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100902646780014,
      "orthogonal_weight": 0.1,
      "step": 5660,
      "total_loss": 0.5814551115036011,
      "weighted_orthogonal_loss": 0.02100902609527111
    },
    {
      "classification_loss": 0.5932947993278503,
      "epoch": 18.560655737704916,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.210104301571846,
      "orthogonal_weight": 0.1,
      "step": 5661,
      "total_loss": 0.6143052577972412,
      "weighted_orthogonal_loss": 0.02101043052971363
    },
    {
      "classification_loss": 0.6064823269844055,
      "epoch": 18.56393442622951,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21012142300605774,
      "orthogonal_weight": 0.1,
      "step": 5662,
      "total_loss": 0.6274944543838501,
      "weighted_orthogonal_loss": 0.021012142300605774
    },
    {
      "classification_loss": 0.7014628052711487,
      "epoch": 18.567213114754097,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21013182401657104,
      "orthogonal_weight": 0.1,
      "step": 5663,
      "total_loss": 0.7224760055541992,
      "weighted_orthogonal_loss": 0.021013183519244194
    },
    {
      "classification_loss": 0.6403776407241821,
      "epoch": 18.57049180327869,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21013633906841278,
      "orthogonal_weight": 0.1,
      "step": 5664,
      "total_loss": 0.6613912582397461,
      "weighted_orthogonal_loss": 0.021013634279370308
    },
    {
      "classification_loss": 0.5702931880950928,
      "epoch": 18.57377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21014349162578583,
      "orthogonal_weight": 0.1,
      "step": 5665,
      "total_loss": 0.591307520866394,
      "weighted_orthogonal_loss": 0.021014349535107613
    },
    {
      "classification_loss": 0.6056223511695862,
      "epoch": 18.57704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21014168858528137,
      "orthogonal_weight": 0.1,
      "step": 5666,
      "total_loss": 0.6266365051269531,
      "weighted_orthogonal_loss": 0.021014168858528137
    },
    {
      "classification_loss": 0.6830345988273621,
      "epoch": 18.58032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21013985574245453,
      "orthogonal_weight": 0.1,
      "step": 5667,
      "total_loss": 0.7040485739707947,
      "weighted_orthogonal_loss": 0.021013986319303513
    },
    {
      "classification_loss": 0.62005615234375,
      "epoch": 18.58360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21013061702251434,
      "orthogonal_weight": 0.1,
      "step": 5668,
      "total_loss": 0.641069233417511,
      "weighted_orthogonal_loss": 0.021013062447309494
    },
    {
      "classification_loss": 0.7140626311302185,
      "epoch": 18.58688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2101152539253235,
      "orthogonal_weight": 0.1,
      "step": 5669,
      "total_loss": 0.7350741624832153,
      "weighted_orthogonal_loss": 0.02101152576506138
    },
    {
      "classification_loss": 0.6211110353469849,
      "epoch": 18.59016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100975513458252,
      "orthogonal_weight": 0.1,
      "step": 5670,
      "total_loss": 0.6421207785606384,
      "weighted_orthogonal_loss": 0.02100975625216961
    },
    {
      "classification_loss": 0.5949558019638062,
      "epoch": 18.59344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21008358895778656,
      "orthogonal_weight": 0.1,
      "step": 5671,
      "total_loss": 0.6159641742706299,
      "weighted_orthogonal_loss": 0.021008359268307686
    },
    {
      "classification_loss": 0.7338508367538452,
      "epoch": 18.59672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21007366478443146,
      "orthogonal_weight": 0.1,
      "step": 5672,
      "total_loss": 0.7548581957817078,
      "weighted_orthogonal_loss": 0.021007366478443146
    },
    {
      "classification_loss": 0.6991455554962158,
      "epoch": 18.6,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.21006731688976288,
      "orthogonal_weight": 0.1,
      "step": 5673,
      "total_loss": 0.7201522588729858,
      "weighted_orthogonal_loss": 0.021006731316447258
    },
    {
      "classification_loss": 0.5589559674263,
      "epoch": 18.60327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2100321501493454,
      "orthogonal_weight": 0.1,
      "step": 5674,
      "total_loss": 0.5799591541290283,
      "weighted_orthogonal_loss": 0.02100321464240551
    },
    {
      "classification_loss": 0.5947462320327759,
      "epoch": 18.60655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20998349785804749,
      "orthogonal_weight": 0.1,
      "step": 5675,
      "total_loss": 0.6157445907592773,
      "weighted_orthogonal_loss": 0.02099834941327572
    },
    {
      "classification_loss": 0.6597771048545837,
      "epoch": 18.60983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20993874967098236,
      "orthogonal_weight": 0.1,
      "step": 5676,
      "total_loss": 0.680770993232727,
      "weighted_orthogonal_loss": 0.020993875339627266
    },
    {
      "classification_loss": 0.7291103601455688,
      "epoch": 18.613114754098362,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20988306403160095,
      "orthogonal_weight": 0.1,
      "step": 5677,
      "total_loss": 0.7500986456871033,
      "weighted_orthogonal_loss": 0.020988306030631065
    },
    {
      "classification_loss": 0.5655995011329651,
      "epoch": 18.61639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20983080565929413,
      "orthogonal_weight": 0.1,
      "step": 5678,
      "total_loss": 0.586582601070404,
      "weighted_orthogonal_loss": 0.020983081310987473
    },
    {
      "classification_loss": 0.6124371290206909,
      "epoch": 18.619672131147542,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2097892314195633,
      "orthogonal_weight": 0.1,
      "step": 5679,
      "total_loss": 0.6334160566329956,
      "weighted_orthogonal_loss": 0.02097892388701439
    },
    {
      "classification_loss": 0.5829157829284668,
      "epoch": 18.62295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20975938439369202,
      "orthogonal_weight": 0.1,
      "step": 5680,
      "total_loss": 0.6038917303085327,
      "weighted_orthogonal_loss": 0.020975938066840172
    },
    {
      "classification_loss": 0.5510499477386475,
      "epoch": 18.626229508196722,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20970496535301208,
      "orthogonal_weight": 0.1,
      "step": 5681,
      "total_loss": 0.5720204710960388,
      "weighted_orthogonal_loss": 0.020970497280359268
    },
    {
      "classification_loss": 0.5989094376564026,
      "epoch": 18.62950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20967677235603333,
      "orthogonal_weight": 0.1,
      "step": 5682,
      "total_loss": 0.6198770999908447,
      "weighted_orthogonal_loss": 0.020967677235603333
    },
    {
      "classification_loss": 0.6543790102005005,
      "epoch": 18.632786885245903,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096511274576187,
      "orthogonal_weight": 0.1,
      "step": 5683,
      "total_loss": 0.6753441095352173,
      "weighted_orthogonal_loss": 0.02096511237323284
    },
    {
      "classification_loss": 0.6093118786811829,
      "epoch": 18.63606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20964039862155914,
      "orthogonal_weight": 0.1,
      "step": 5684,
      "total_loss": 0.6302759051322937,
      "weighted_orthogonal_loss": 0.020964039489626884
    },
    {
      "classification_loss": 0.6305786967277527,
      "epoch": 18.639344262295083,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20963400602340698,
      "orthogonal_weight": 0.1,
      "step": 5685,
      "total_loss": 0.651542067527771,
      "weighted_orthogonal_loss": 0.020963400602340698
    },
    {
      "classification_loss": 0.580644428730011,
      "epoch": 18.64262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20963777601718903,
      "orthogonal_weight": 0.1,
      "step": 5686,
      "total_loss": 0.6016082167625427,
      "weighted_orthogonal_loss": 0.020963778719305992
    },
    {
      "classification_loss": 0.5523547530174255,
      "epoch": 18.645901639344263,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20963893830776215,
      "orthogonal_weight": 0.1,
      "step": 5687,
      "total_loss": 0.5733186602592468,
      "weighted_orthogonal_loss": 0.020963894203305244
    },
    {
      "classification_loss": 0.5770658254623413,
      "epoch": 18.64918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2096453458070755,
      "orthogonal_weight": 0.1,
      "step": 5688,
      "total_loss": 0.5980303883552551,
      "weighted_orthogonal_loss": 0.02096453495323658
    },
    {
      "classification_loss": 0.5264899730682373,
      "epoch": 18.652459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20965266227722168,
      "orthogonal_weight": 0.1,
      "step": 5689,
      "total_loss": 0.5474552512168884,
      "weighted_orthogonal_loss": 0.020965266972780228
    },
    {
      "classification_loss": 0.582668662071228,
      "epoch": 18.65573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20965781807899475,
      "orthogonal_weight": 0.1,
      "step": 5690,
      "total_loss": 0.6036344170570374,
      "weighted_orthogonal_loss": 0.020965782925486565
    },
    {
      "classification_loss": 0.7146496772766113,
      "epoch": 18.659016393442624,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20965790748596191,
      "orthogonal_weight": 0.1,
      "step": 5691,
      "total_loss": 0.7356154918670654,
      "weighted_orthogonal_loss": 0.02096579037606716
    },
    {
      "classification_loss": 0.5711209774017334,
      "epoch": 18.662295081967212,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20963746309280396,
      "orthogonal_weight": 0.1,
      "step": 5692,
      "total_loss": 0.5920847058296204,
      "weighted_orthogonal_loss": 0.020963747054338455
    },
    {
      "classification_loss": 0.5812788009643555,
      "epoch": 18.665573770491804,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20960530638694763,
      "orthogonal_weight": 0.1,
      "step": 5693,
      "total_loss": 0.6022393107414246,
      "weighted_orthogonal_loss": 0.020960530266165733
    },
    {
      "classification_loss": 0.6049572825431824,
      "epoch": 18.668852459016392,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20960573852062225,
      "orthogonal_weight": 0.1,
      "step": 5694,
      "total_loss": 0.6259178519248962,
      "weighted_orthogonal_loss": 0.020960574969649315
    },
    {
      "classification_loss": 0.5896404385566711,
      "epoch": 18.672131147540984,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20959965884685516,
      "orthogonal_weight": 0.1,
      "step": 5695,
      "total_loss": 0.6106004118919373,
      "weighted_orthogonal_loss": 0.020959965884685516
    },
    {
      "classification_loss": 0.7206981778144836,
      "epoch": 18.675409836065572,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20957869291305542,
      "orthogonal_weight": 0.1,
      "step": 5696,
      "total_loss": 0.7416560649871826,
      "weighted_orthogonal_loss": 0.02095787040889263
    },
    {
      "classification_loss": 0.6164306998252869,
      "epoch": 18.678688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2095542699098587,
      "orthogonal_weight": 0.1,
      "step": 5697,
      "total_loss": 0.63738614320755,
      "weighted_orthogonal_loss": 0.02095542661845684
    },
    {
      "classification_loss": 0.5639773011207581,
      "epoch": 18.681967213114753,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20953692495822906,
      "orthogonal_weight": 0.1,
      "step": 5698,
      "total_loss": 0.5849310159683228,
      "weighted_orthogonal_loss": 0.020953692495822906
    },
    {
      "classification_loss": 0.601040244102478,
      "epoch": 18.685245901639345,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20952479541301727,
      "orthogonal_weight": 0.1,
      "step": 5699,
      "total_loss": 0.6219927072525024,
      "weighted_orthogonal_loss": 0.020952479913830757
    },
    {
      "epoch": 18.688524590163933,
      "grad_norm": 10.88345718383789,
      "learning_rate": 1.3366666666666667e-05,
      "loss": 0.6329,
      "step": 5700
    },
    {
      "classification_loss": 0.5998681783676147,
      "epoch": 18.688524590163933,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2095172256231308,
      "orthogonal_weight": 0.1,
      "step": 5700,
      "total_loss": 0.6208199262619019,
      "weighted_orthogonal_loss": 0.02095172367990017
    },
    {
      "classification_loss": 0.7071910500526428,
      "epoch": 18.691803278688525,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2095169872045517,
      "orthogonal_weight": 0.1,
      "step": 5701,
      "total_loss": 0.7281427383422852,
      "weighted_orthogonal_loss": 0.02095169946551323
    },
    {
      "classification_loss": 0.6164147257804871,
      "epoch": 18.695081967213113,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20948287844657898,
      "orthogonal_weight": 0.1,
      "step": 5702,
      "total_loss": 0.6373630166053772,
      "weighted_orthogonal_loss": 0.020948288962244987
    },
    {
      "classification_loss": 0.5957249402999878,
      "epoch": 18.698360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20945031940937042,
      "orthogonal_weight": 0.1,
      "step": 5703,
      "total_loss": 0.6166699528694153,
      "weighted_orthogonal_loss": 0.020945033058524132
    },
    {
      "classification_loss": 0.6231206059455872,
      "epoch": 18.701639344262293,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20941117405891418,
      "orthogonal_weight": 0.1,
      "step": 5704,
      "total_loss": 0.6440617442131042,
      "weighted_orthogonal_loss": 0.02094111777842045
    },
    {
      "classification_loss": 0.6580747365951538,
      "epoch": 18.704918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209374338388443,
      "orthogonal_weight": 0.1,
      "step": 5705,
      "total_loss": 0.6790121793746948,
      "weighted_orthogonal_loss": 0.02093743346631527
    },
    {
      "classification_loss": 0.5317500233650208,
      "epoch": 18.708196721311474,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2093459516763687,
      "orthogonal_weight": 0.1,
      "step": 5706,
      "total_loss": 0.5526846051216125,
      "weighted_orthogonal_loss": 0.02093459479510784
    },
    {
      "classification_loss": 0.5720308423042297,
      "epoch": 18.711475409836066,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20931264758110046,
      "orthogonal_weight": 0.1,
      "step": 5707,
      "total_loss": 0.5929620862007141,
      "weighted_orthogonal_loss": 0.020931264385581017
    },
    {
      "classification_loss": 0.6366180777549744,
      "epoch": 18.714754098360658,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20928362011909485,
      "orthogonal_weight": 0.1,
      "step": 5708,
      "total_loss": 0.6575464606285095,
      "weighted_orthogonal_loss": 0.020928362384438515
    },
    {
      "classification_loss": 0.6486144661903381,
      "epoch": 18.718032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20925478637218475,
      "orthogonal_weight": 0.1,
      "step": 5709,
      "total_loss": 0.6695399284362793,
      "weighted_orthogonal_loss": 0.020925479009747505
    },
    {
      "classification_loss": 0.6720724105834961,
      "epoch": 18.721311475409838,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2092229127883911,
      "orthogonal_weight": 0.1,
      "step": 5710,
      "total_loss": 0.6929947137832642,
      "weighted_orthogonal_loss": 0.02092229202389717
    },
    {
      "classification_loss": 0.5607696771621704,
      "epoch": 18.724590163934426,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20918244123458862,
      "orthogonal_weight": 0.1,
      "step": 5711,
      "total_loss": 0.5816879272460938,
      "weighted_orthogonal_loss": 0.020918244495987892
    },
    {
      "classification_loss": 0.563762903213501,
      "epoch": 18.727868852459018,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20914684236049652,
      "orthogonal_weight": 0.1,
      "step": 5712,
      "total_loss": 0.5846775770187378,
      "weighted_orthogonal_loss": 0.020914684981107712
    },
    {
      "classification_loss": 0.5918470621109009,
      "epoch": 18.731147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2091248333454132,
      "orthogonal_weight": 0.1,
      "step": 5713,
      "total_loss": 0.612759530544281,
      "weighted_orthogonal_loss": 0.02091248333454132
    },
    {
      "classification_loss": 0.5735213756561279,
      "epoch": 18.7344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20911206305027008,
      "orthogonal_weight": 0.1,
      "step": 5714,
      "total_loss": 0.5944325923919678,
      "weighted_orthogonal_loss": 0.020911207422614098
    },
    {
      "classification_loss": 0.6197468042373657,
      "epoch": 18.737704918032787,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20910204946994781,
      "orthogonal_weight": 0.1,
      "step": 5715,
      "total_loss": 0.6406570076942444,
      "weighted_orthogonal_loss": 0.02091020531952381
    },
    {
      "classification_loss": 0.6283955574035645,
      "epoch": 18.74098360655738,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20909050107002258,
      "orthogonal_weight": 0.1,
      "step": 5716,
      "total_loss": 0.6493046283721924,
      "weighted_orthogonal_loss": 0.020909050479531288
    },
    {
      "classification_loss": 0.5904003381729126,
      "epoch": 18.744262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20906709134578705,
      "orthogonal_weight": 0.1,
      "step": 5717,
      "total_loss": 0.6113070249557495,
      "weighted_orthogonal_loss": 0.020906709134578705
    },
    {
      "classification_loss": 0.5620509386062622,
      "epoch": 18.74754098360656,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20905405282974243,
      "orthogonal_weight": 0.1,
      "step": 5718,
      "total_loss": 0.5829563140869141,
      "weighted_orthogonal_loss": 0.020905405282974243
    },
    {
      "classification_loss": 0.5986084938049316,
      "epoch": 18.750819672131147,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2090371996164322,
      "orthogonal_weight": 0.1,
      "step": 5719,
      "total_loss": 0.6195122003555298,
      "weighted_orthogonal_loss": 0.02090371958911419
    },
    {
      "classification_loss": 0.6230206489562988,
      "epoch": 18.75409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20902171730995178,
      "orthogonal_weight": 0.1,
      "step": 5720,
      "total_loss": 0.6439228057861328,
      "weighted_orthogonal_loss": 0.020902171730995178
    },
    {
      "classification_loss": 0.531568706035614,
      "epoch": 18.757377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.209007129073143,
      "orthogonal_weight": 0.1,
      "step": 5721,
      "total_loss": 0.5524694323539734,
      "weighted_orthogonal_loss": 0.02090071327984333
    },
    {
      "classification_loss": 0.6600950956344604,
      "epoch": 18.76065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20899362862110138,
      "orthogonal_weight": 0.1,
      "step": 5722,
      "total_loss": 0.68099445104599,
      "weighted_orthogonal_loss": 0.020899362862110138
    },
    {
      "classification_loss": 0.6079339385032654,
      "epoch": 18.763934426229508,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20894849300384521,
      "orthogonal_weight": 0.1,
      "step": 5723,
      "total_loss": 0.628828763961792,
      "weighted_orthogonal_loss": 0.02089484967291355
    },
    {
      "classification_loss": 0.5784456133842468,
      "epoch": 18.7672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20891550183296204,
      "orthogonal_weight": 0.1,
      "step": 5724,
      "total_loss": 0.5993371605873108,
      "weighted_orthogonal_loss": 0.020891550928354263
    },
    {
      "classification_loss": 0.5920088291168213,
      "epoch": 18.770491803278688,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2088707685470581,
      "orthogonal_weight": 0.1,
      "step": 5725,
      "total_loss": 0.6128959059715271,
      "weighted_orthogonal_loss": 0.02088707685470581
    },
    {
      "classification_loss": 0.5835508108139038,
      "epoch": 18.77377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.208832249045372,
      "orthogonal_weight": 0.1,
      "step": 5726,
      "total_loss": 0.6044340133666992,
      "weighted_orthogonal_loss": 0.0208832249045372
    },
    {
      "classification_loss": 0.6290628910064697,
      "epoch": 18.777049180327868,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20880378782749176,
      "orthogonal_weight": 0.1,
      "step": 5727,
      "total_loss": 0.6499432921409607,
      "weighted_orthogonal_loss": 0.020880378782749176
    },
    {
      "classification_loss": 0.5625126361846924,
      "epoch": 18.78032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2087746411561966,
      "orthogonal_weight": 0.1,
      "step": 5728,
      "total_loss": 0.5833901166915894,
      "weighted_orthogonal_loss": 0.02087746374309063
    },
    {
      "classification_loss": 0.5518805384635925,
      "epoch": 18.78360655737705,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20874901115894318,
      "orthogonal_weight": 0.1,
      "step": 5729,
      "total_loss": 0.5727554559707642,
      "weighted_orthogonal_loss": 0.020874900743365288
    },
    {
      "classification_loss": 0.5883073806762695,
      "epoch": 18.78688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20871293544769287,
      "orthogonal_weight": 0.1,
      "step": 5730,
      "total_loss": 0.6091786623001099,
      "weighted_orthogonal_loss": 0.020871294662356377
    },
    {
      "classification_loss": 0.6401464939117432,
      "epoch": 18.79016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20868010818958282,
      "orthogonal_weight": 0.1,
      "step": 5731,
      "total_loss": 0.6610144972801208,
      "weighted_orthogonal_loss": 0.020868010818958282
    },
    {
      "classification_loss": 0.6090677976608276,
      "epoch": 18.79344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20864899456501007,
      "orthogonal_weight": 0.1,
      "step": 5732,
      "total_loss": 0.629932701587677,
      "weighted_orthogonal_loss": 0.020864900201559067
    },
    {
      "classification_loss": 0.6042503118515015,
      "epoch": 18.79672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20861585438251495,
      "orthogonal_weight": 0.1,
      "step": 5733,
      "total_loss": 0.6251118779182434,
      "weighted_orthogonal_loss": 0.020861586555838585
    },
    {
      "classification_loss": 0.5359727740287781,
      "epoch": 18.8,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20858700573444366,
      "orthogonal_weight": 0.1,
      "step": 5734,
      "total_loss": 0.5568314790725708,
      "weighted_orthogonal_loss": 0.020858701318502426
    },
    {
      "classification_loss": 0.65077805519104,
      "epoch": 18.80327868852459,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20856797695159912,
      "orthogonal_weight": 0.1,
      "step": 5735,
      "total_loss": 0.6716348528862,
      "weighted_orthogonal_loss": 0.020856797695159912
    },
    {
      "classification_loss": 0.5704644918441772,
      "epoch": 18.80655737704918,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20854546129703522,
      "orthogonal_weight": 0.1,
      "step": 5736,
      "total_loss": 0.5913190245628357,
      "weighted_orthogonal_loss": 0.020854545757174492
    },
    {
      "classification_loss": 0.6222528219223022,
      "epoch": 18.80983606557377,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20852740108966827,
      "orthogonal_weight": 0.1,
      "step": 5737,
      "total_loss": 0.6431055665016174,
      "weighted_orthogonal_loss": 0.020852740854024887
    },
    {
      "classification_loss": 0.5618917942047119,
      "epoch": 18.81311475409836,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085198163986206,
      "orthogonal_weight": 0.1,
      "step": 5738,
      "total_loss": 0.582743763923645,
      "weighted_orthogonal_loss": 0.02085198275744915
    },
    {
      "classification_loss": 0.6694728136062622,
      "epoch": 18.81639344262295,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085171639919281,
      "orthogonal_weight": 0.1,
      "step": 5739,
      "total_loss": 0.6903245449066162,
      "weighted_orthogonal_loss": 0.02085171639919281
    },
    {
      "classification_loss": 0.5495797991752625,
      "epoch": 18.81967213114754,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085154801607132,
      "orthogonal_weight": 0.1,
      "step": 5740,
      "total_loss": 0.5704313516616821,
      "weighted_orthogonal_loss": 0.02085154876112938
    },
    {
      "classification_loss": 0.5469924807548523,
      "epoch": 18.82295081967213,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20851290225982666,
      "orthogonal_weight": 0.1,
      "step": 5741,
      "total_loss": 0.5678437948226929,
      "weighted_orthogonal_loss": 0.020851289853453636
    },
    {
      "classification_loss": 0.6351468563079834,
      "epoch": 18.82622950819672,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085217386484146,
      "orthogonal_weight": 0.1,
      "step": 5742,
      "total_loss": 0.6559990048408508,
      "weighted_orthogonal_loss": 0.02085217460989952
    },
    {
      "classification_loss": 0.54096919298172,
      "epoch": 18.82950819672131,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20852993428707123,
      "orthogonal_weight": 0.1,
      "step": 5743,
      "total_loss": 0.5618221759796143,
      "weighted_orthogonal_loss": 0.020852994173765182
    },
    {
      "classification_loss": 0.5656737089157104,
      "epoch": 18.832786885245902,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20854251086711884,
      "orthogonal_weight": 0.1,
      "step": 5744,
      "total_loss": 0.586527943611145,
      "weighted_orthogonal_loss": 0.020854251459240913
    },
    {
      "classification_loss": 0.6013257503509521,
      "epoch": 18.83606557377049,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20856399834156036,
      "orthogonal_weight": 0.1,
      "step": 5745,
      "total_loss": 0.6221821308135986,
      "weighted_orthogonal_loss": 0.020856400951743126
    },
    {
      "classification_loss": 0.48287659883499146,
      "epoch": 18.839344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20858187973499298,
      "orthogonal_weight": 0.1,
      "step": 5746,
      "total_loss": 0.5037347674369812,
      "weighted_orthogonal_loss": 0.020858189091086388
    },
    {
      "classification_loss": 0.5905901789665222,
      "epoch": 18.84262295081967,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20860500633716583,
      "orthogonal_weight": 0.1,
      "step": 5747,
      "total_loss": 0.6114506721496582,
      "weighted_orthogonal_loss": 0.020860500633716583
    },
    {
      "classification_loss": 0.6290283799171448,
      "epoch": 18.845901639344262,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20862829685211182,
      "orthogonal_weight": 0.1,
      "step": 5748,
      "total_loss": 0.649891197681427,
      "weighted_orthogonal_loss": 0.02086283080279827
    },
    {
      "classification_loss": 0.6417298913002014,
      "epoch": 18.84918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086486518383026,
      "orthogonal_weight": 0.1,
      "step": 5749,
      "total_loss": 0.662594735622406,
      "weighted_orthogonal_loss": 0.02086486481130123
    },
    {
      "classification_loss": 0.583430290222168,
      "epoch": 18.852459016393443,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867426693439484,
      "orthogonal_weight": 0.1,
      "step": 5750,
      "total_loss": 0.6042976975440979,
      "weighted_orthogonal_loss": 0.020867427811026573
    },
    {
      "classification_loss": 0.648880124092102,
      "epoch": 18.855737704918035,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20870016515254974,
      "orthogonal_weight": 0.1,
      "step": 5751,
      "total_loss": 0.6697501540184021,
      "weighted_orthogonal_loss": 0.020870016887784004
    },
    {
      "classification_loss": 0.6100035905838013,
      "epoch": 18.859016393442623,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20871612429618835,
      "orthogonal_weight": 0.1,
      "step": 5752,
      "total_loss": 0.6308752298355103,
      "weighted_orthogonal_loss": 0.020871613174676895
    },
    {
      "classification_loss": 0.6096939444541931,
      "epoch": 18.862295081967215,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20870141685009003,
      "orthogonal_weight": 0.1,
      "step": 5753,
      "total_loss": 0.6305640935897827,
      "weighted_orthogonal_loss": 0.020870141685009003
    },
    {
      "classification_loss": 0.6801490783691406,
      "epoch": 18.865573770491803,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20868857204914093,
      "orthogonal_weight": 0.1,
      "step": 5754,
      "total_loss": 0.7010179162025452,
      "weighted_orthogonal_loss": 0.020868858322501183
    },
    {
      "classification_loss": 0.5384737253189087,
      "epoch": 18.868852459016395,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867957174777985,
      "orthogonal_weight": 0.1,
      "step": 5755,
      "total_loss": 0.5593416690826416,
      "weighted_orthogonal_loss": 0.020867956802248955
    },
    {
      "classification_loss": 0.6137102842330933,
      "epoch": 18.872131147540983,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20867210626602173,
      "orthogonal_weight": 0.1,
      "step": 5756,
      "total_loss": 0.6345775127410889,
      "weighted_orthogonal_loss": 0.020867211744189262
    },
    {
      "classification_loss": 0.5562444925308228,
      "epoch": 18.875409836065575,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20866410434246063,
      "orthogonal_weight": 0.1,
      "step": 5757,
      "total_loss": 0.5771108865737915,
      "weighted_orthogonal_loss": 0.020866410806775093
    },
    {
      "classification_loss": 0.5750245451927185,
      "epoch": 18.878688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2086450606584549,
      "orthogonal_weight": 0.1,
      "step": 5758,
      "total_loss": 0.5958890318870544,
      "weighted_orthogonal_loss": 0.02086450718343258
    },
    {
      "classification_loss": 0.5532569289207458,
      "epoch": 18.881967213114756,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20861312747001648,
      "orthogonal_weight": 0.1,
      "step": 5759,
      "total_loss": 0.5741182565689087,
      "weighted_orthogonal_loss": 0.020861312747001648
    },
    {
      "classification_loss": 0.6283751726150513,
      "epoch": 18.885245901639344,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20858033001422882,
      "orthogonal_weight": 0.1,
      "step": 5760,
      "total_loss": 0.6492332220077515,
      "weighted_orthogonal_loss": 0.020858032628893852
    },
    {
      "classification_loss": 0.6320455074310303,
      "epoch": 18.888524590163936,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085629105567932,
      "orthogonal_weight": 0.1,
      "step": 5761,
      "total_loss": 0.6529017686843872,
      "weighted_orthogonal_loss": 0.02085629105567932
    },
    {
      "classification_loss": 0.6069247126579285,
      "epoch": 18.891803278688524,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20854826271533966,
      "orthogonal_weight": 0.1,
      "step": 5762,
      "total_loss": 0.6277795433998108,
      "weighted_orthogonal_loss": 0.020854827016592026
    },
    {
      "classification_loss": 0.5556691884994507,
      "epoch": 18.895081967213116,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20853975415229797,
      "orthogonal_weight": 0.1,
      "step": 5763,
      "total_loss": 0.5765231847763062,
      "weighted_orthogonal_loss": 0.020853975787758827
    },
    {
      "classification_loss": 0.5512169003486633,
      "epoch": 18.898360655737704,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085295021533966,
      "orthogonal_weight": 0.1,
      "step": 5764,
      "total_loss": 0.5720698237419128,
      "weighted_orthogonal_loss": 0.02085295133292675
    },
    {
      "classification_loss": 0.5327535271644592,
      "epoch": 18.901639344262296,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2085215300321579,
      "orthogonal_weight": 0.1,
      "step": 5765,
      "total_loss": 0.5536056756973267,
      "weighted_orthogonal_loss": 0.02085215412080288
    },
    {
      "classification_loss": 0.6054513454437256,
      "epoch": 18.904918032786885,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20851947367191315,
      "orthogonal_weight": 0.1,
      "step": 5766,
      "total_loss": 0.6263033151626587,
      "weighted_orthogonal_loss": 0.020851947367191315
    },
    {
      "classification_loss": 0.6412458419799805,
      "epoch": 18.908196721311477,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20850761234760284,
      "orthogonal_weight": 0.1,
      "step": 5767,
      "total_loss": 0.6620966196060181,
      "weighted_orthogonal_loss": 0.020850760862231255
    },
    {
      "classification_loss": 0.5655643343925476,
      "epoch": 18.911475409836065,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20848479866981506,
      "orthogonal_weight": 0.1,
      "step": 5768,
      "total_loss": 0.586412787437439,
      "weighted_orthogonal_loss": 0.020848480984568596
    },
    {
      "classification_loss": 0.6709608435630798,
      "epoch": 18.914754098360657,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20846237242221832,
      "orthogonal_weight": 0.1,
      "step": 5769,
      "total_loss": 0.6918070912361145,
      "weighted_orthogonal_loss": 0.020846238359808922
    },
    {
      "classification_loss": 0.5454132556915283,
      "epoch": 18.918032786885245,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20844684541225433,
      "orthogonal_weight": 0.1,
      "step": 5770,
      "total_loss": 0.5662579536437988,
      "weighted_orthogonal_loss": 0.020844684913754463
    },
    {
      "classification_loss": 0.5884203314781189,
      "epoch": 18.921311475409837,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084307223558426,
      "orthogonal_weight": 0.1,
      "step": 5771,
      "total_loss": 0.6092634201049805,
      "weighted_orthogonal_loss": 0.02084307186305523
    },
    {
      "classification_loss": 0.6222392320632935,
      "epoch": 18.924590163934425,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20841625332832336,
      "orthogonal_weight": 0.1,
      "step": 5772,
      "total_loss": 0.6430808305740356,
      "weighted_orthogonal_loss": 0.020841626450419426
    },
    {
      "classification_loss": 0.6661485433578491,
      "epoch": 18.927868852459017,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084094136953354,
      "orthogonal_weight": 0.1,
      "step": 5773,
      "total_loss": 0.6869894862174988,
      "weighted_orthogonal_loss": 0.02084094099700451
    },
    {
      "classification_loss": 0.571570098400116,
      "epoch": 18.931147540983606,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840588212013245,
      "orthogonal_weight": 0.1,
      "step": 5774,
      "total_loss": 0.592410683631897,
      "weighted_orthogonal_loss": 0.020840588957071304
    },
    {
      "classification_loss": 0.6168445944786072,
      "epoch": 18.934426229508198,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084108144044876,
      "orthogonal_weight": 0.1,
      "step": 5775,
      "total_loss": 0.6376856565475464,
      "weighted_orthogonal_loss": 0.02084108255803585
    },
    {
      "classification_loss": 0.5981782078742981,
      "epoch": 18.937704918032786,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840874314308167,
      "orthogonal_weight": 0.1,
      "step": 5776,
      "total_loss": 0.619019091129303,
      "weighted_orthogonal_loss": 0.020840873941779137
    },
    {
      "classification_loss": 0.5985507965087891,
      "epoch": 18.940983606557378,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840588212013245,
      "orthogonal_weight": 0.1,
      "step": 5777,
      "total_loss": 0.6193913817405701,
      "weighted_orthogonal_loss": 0.020840588957071304
    },
    {
      "classification_loss": 0.562620222568512,
      "epoch": 18.944262295081966,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840543508529663,
      "orthogonal_weight": 0.1,
      "step": 5778,
      "total_loss": 0.5834607481956482,
      "weighted_orthogonal_loss": 0.020840544253587723
    },
    {
      "classification_loss": 0.6501470804214478,
      "epoch": 18.947540983606558,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084030956029892,
      "orthogonal_weight": 0.1,
      "step": 5779,
      "total_loss": 0.6709873676300049,
      "weighted_orthogonal_loss": 0.02084030956029892
    },
    {
      "classification_loss": 0.5856135487556458,
      "epoch": 18.950819672131146,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2084014117717743,
      "orthogonal_weight": 0.1,
      "step": 5780,
      "total_loss": 0.6064537167549133,
      "weighted_orthogonal_loss": 0.02084014192223549
    },
    {
      "classification_loss": 0.63527911901474,
      "epoch": 18.95409836065574,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20839959383010864,
      "orthogonal_weight": 0.1,
      "step": 5781,
      "total_loss": 0.6561191082000732,
      "weighted_orthogonal_loss": 0.020839959383010864
    },
    {
      "classification_loss": 0.714602530002594,
      "epoch": 18.957377049180327,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20839987695217133,
      "orthogonal_weight": 0.1,
      "step": 5782,
      "total_loss": 0.7354425191879272,
      "weighted_orthogonal_loss": 0.020839987322688103
    },
    {
      "classification_loss": 0.5574007034301758,
      "epoch": 18.96065573770492,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20839469134807587,
      "orthogonal_weight": 0.1,
      "step": 5783,
      "total_loss": 0.578240156173706,
      "weighted_orthogonal_loss": 0.020839469507336617
    },
    {
      "classification_loss": 0.5709248185157776,
      "epoch": 18.963934426229507,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20839354395866394,
      "orthogonal_weight": 0.1,
      "step": 5784,
      "total_loss": 0.5917641520500183,
      "weighted_orthogonal_loss": 0.020839354023337364
    },
    {
      "classification_loss": 0.7119463086128235,
      "epoch": 18.9672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20839279890060425,
      "orthogonal_weight": 0.1,
      "step": 5785,
      "total_loss": 0.7327855825424194,
      "weighted_orthogonal_loss": 0.020839279517531395
    },
    {
      "classification_loss": 0.6297515630722046,
      "epoch": 18.970491803278687,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20838817954063416,
      "orthogonal_weight": 0.1,
      "step": 5786,
      "total_loss": 0.6505903601646423,
      "weighted_orthogonal_loss": 0.020838817581534386
    },
    {
      "classification_loss": 0.6117461323738098,
      "epoch": 18.97377049180328,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2083907425403595,
      "orthogonal_weight": 0.1,
      "step": 5787,
      "total_loss": 0.6325852274894714,
      "weighted_orthogonal_loss": 0.02083907462656498
    },
    {
      "classification_loss": 0.6367029547691345,
      "epoch": 18.977049180327867,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.208394855260849,
      "orthogonal_weight": 0.1,
      "step": 5788,
      "total_loss": 0.6575424671173096,
      "weighted_orthogonal_loss": 0.02083948627114296
    },
    {
      "classification_loss": 0.5486899614334106,
      "epoch": 18.98032786885246,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.2083997279405594,
      "orthogonal_weight": 0.1,
      "step": 5789,
      "total_loss": 0.5695299506187439,
      "weighted_orthogonal_loss": 0.02083997242152691
    },
    {
      "classification_loss": 0.6400679349899292,
      "epoch": 18.983606557377048,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840440690517426,
      "orthogonal_weight": 0.1,
      "step": 5790,
      "total_loss": 0.6609084010124207,
      "weighted_orthogonal_loss": 0.020840441808104515
    },
    {
      "classification_loss": 0.6338101029396057,
      "epoch": 18.98688524590164,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840345323085785,
      "orthogonal_weight": 0.1,
      "step": 5791,
      "total_loss": 0.6546504497528076,
      "weighted_orthogonal_loss": 0.020840344950556755
    },
    {
      "classification_loss": 0.5597909688949585,
      "epoch": 18.990163934426228,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20840555429458618,
      "orthogonal_weight": 0.1,
      "step": 5792,
      "total_loss": 0.5806314945220947,
      "weighted_orthogonal_loss": 0.020840555429458618
    },
    {
      "classification_loss": 0.7186787724494934,
      "epoch": 18.99344262295082,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20841041207313538,
      "orthogonal_weight": 0.1,
      "step": 5793,
      "total_loss": 0.7395198345184326,
      "weighted_orthogonal_loss": 0.020841041579842567
    },
    {
      "classification_loss": 0.623634934425354,
      "epoch": 18.99672131147541,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20841486752033234,
      "orthogonal_weight": 0.1,
      "step": 5794,
      "total_loss": 0.6444764137268066,
      "weighted_orthogonal_loss": 0.020841486752033234
    },
    {
      "classification_loss": 0.7147295475006104,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7355716228485107,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7020092606544495,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7228513360023499,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7040001749992371,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7248422503471375,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7274972796440125,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7483393549919128,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7107033729553223,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7315454483032227,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7114116549491882,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7322537302970886,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.703766942024231,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7246090173721313,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "classification_loss": 0.7258719205856323,
      "epoch": 19.0,
      "mode": "CLoRA",
      "num_lora_layers": 36,
      "orthogonal_loss": 0.20842094719409943,
      "orthogonal_weight": 0.1,
      "step": 5795,
      "total_loss": 0.7467139959335327,
      "weighted_orthogonal_loss": 0.020842095836997032
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.476,
      "eval_f1": 0.4575569358178054,
      "eval_loss": 0.7330198884010315,
      "eval_precision": 0.6443148688046647,
      "eval_recall": 0.3547351524879615,
      "eval_runtime": 6.1372,
      "eval_samples_per_second": 162.942,
      "eval_steps_per_second": 1.304,
      "step": 5795
    }
  ],
  "logging_steps": 100,
  "max_steps": 6100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.487426481321984e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
