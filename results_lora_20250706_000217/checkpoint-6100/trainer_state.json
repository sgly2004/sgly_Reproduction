{
  "best_global_step": 305,
  "best_metric": 0.31990521327014215,
  "best_model_checkpoint": "./results_lora_20250706_000217/checkpoint-305",
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 6100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "classification_loss": 6.029106140136719,
      "epoch": 0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 0,
      "total_loss": 6.029106140136719
    },
    {
      "classification_loss": 5.26099967956543,
      "epoch": 0.003278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1,
      "total_loss": 5.26099967956543
    },
    {
      "classification_loss": 6.786002159118652,
      "epoch": 0.006557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2,
      "total_loss": 6.786002159118652
    },
    {
      "classification_loss": 6.763433456420898,
      "epoch": 0.009836065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3,
      "total_loss": 6.763433456420898
    },
    {
      "classification_loss": 7.246137619018555,
      "epoch": 0.013114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4,
      "total_loss": 7.246137619018555
    },
    {
      "classification_loss": 5.6747283935546875,
      "epoch": 0.01639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5,
      "total_loss": 5.6747283935546875
    },
    {
      "classification_loss": 7.14031457901001,
      "epoch": 0.019672131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6,
      "total_loss": 7.14031457901001
    },
    {
      "classification_loss": 7.131854057312012,
      "epoch": 0.022950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 7,
      "total_loss": 7.131854057312012
    },
    {
      "classification_loss": 6.111852645874023,
      "epoch": 0.02622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 8,
      "total_loss": 6.111852645874023
    },
    {
      "classification_loss": 6.751564025878906,
      "epoch": 0.029508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 9,
      "total_loss": 6.751564025878906
    },
    {
      "classification_loss": 4.768473148345947,
      "epoch": 0.03278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 10,
      "total_loss": 4.768473148345947
    },
    {
      "classification_loss": 6.933128833770752,
      "epoch": 0.036065573770491806,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 11,
      "total_loss": 6.933128833770752
    },
    {
      "classification_loss": 6.745428085327148,
      "epoch": 0.03934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 12,
      "total_loss": 6.745428085327148
    },
    {
      "classification_loss": 7.054797172546387,
      "epoch": 0.04262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 13,
      "total_loss": 7.054797172546387
    },
    {
      "classification_loss": 6.76793909072876,
      "epoch": 0.04590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 14,
      "total_loss": 6.76793909072876
    },
    {
      "classification_loss": 5.073094844818115,
      "epoch": 0.04918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 15,
      "total_loss": 5.073094844818115
    },
    {
      "classification_loss": 6.4377055168151855,
      "epoch": 0.05245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 16,
      "total_loss": 6.4377055168151855
    },
    {
      "classification_loss": 5.5165863037109375,
      "epoch": 0.05573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 17,
      "total_loss": 5.5165863037109375
    },
    {
      "classification_loss": 7.268939018249512,
      "epoch": 0.05901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 18,
      "total_loss": 7.268939018249512
    },
    {
      "classification_loss": 6.805829048156738,
      "epoch": 0.06229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 19,
      "total_loss": 6.805829048156738
    },
    {
      "classification_loss": 6.703608512878418,
      "epoch": 0.06557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 20,
      "total_loss": 6.703608512878418
    },
    {
      "classification_loss": 5.311041831970215,
      "epoch": 0.06885245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 21,
      "total_loss": 5.311041831970215
    },
    {
      "classification_loss": 5.257755279541016,
      "epoch": 0.07213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 22,
      "total_loss": 5.257755279541016
    },
    {
      "classification_loss": 6.257777214050293,
      "epoch": 0.07540983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 23,
      "total_loss": 6.257777214050293
    },
    {
      "classification_loss": 5.339997291564941,
      "epoch": 0.07868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 24,
      "total_loss": 5.339997291564941
    },
    {
      "classification_loss": 5.6603007316589355,
      "epoch": 0.08196721311475409,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 25,
      "total_loss": 5.6603007316589355
    },
    {
      "classification_loss": 5.220198631286621,
      "epoch": 0.08524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 26,
      "total_loss": 5.220198631286621
    },
    {
      "classification_loss": 5.460502624511719,
      "epoch": 0.08852459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 27,
      "total_loss": 5.460502624511719
    },
    {
      "classification_loss": 4.58080530166626,
      "epoch": 0.09180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 28,
      "total_loss": 4.58080530166626
    },
    {
      "classification_loss": 6.558686256408691,
      "epoch": 0.09508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 29,
      "total_loss": 6.558686256408691
    },
    {
      "classification_loss": 4.91140079498291,
      "epoch": 0.09836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 30,
      "total_loss": 4.91140079498291
    },
    {
      "classification_loss": 5.6349334716796875,
      "epoch": 0.10163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 31,
      "total_loss": 5.6349334716796875
    },
    {
      "classification_loss": 5.403424263000488,
      "epoch": 0.10491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 32,
      "total_loss": 5.403424263000488
    },
    {
      "classification_loss": 3.603884220123291,
      "epoch": 0.10819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 33,
      "total_loss": 3.603884220123291
    },
    {
      "classification_loss": 4.430056095123291,
      "epoch": 0.11147540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 34,
      "total_loss": 4.430056095123291
    },
    {
      "classification_loss": 5.044696807861328,
      "epoch": 0.11475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 35,
      "total_loss": 5.044696807861328
    },
    {
      "classification_loss": 4.773556709289551,
      "epoch": 0.1180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 36,
      "total_loss": 4.773556709289551
    },
    {
      "classification_loss": 5.51384973526001,
      "epoch": 0.12131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 37,
      "total_loss": 5.51384973526001
    },
    {
      "classification_loss": 4.824620723724365,
      "epoch": 0.12459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 38,
      "total_loss": 4.824620723724365
    },
    {
      "classification_loss": 4.803764343261719,
      "epoch": 0.12786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 39,
      "total_loss": 4.803764343261719
    },
    {
      "classification_loss": 3.645808696746826,
      "epoch": 0.13114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 40,
      "total_loss": 3.645808696746826
    },
    {
      "classification_loss": 4.754886627197266,
      "epoch": 0.13442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 41,
      "total_loss": 4.754886627197266
    },
    {
      "classification_loss": 3.2896270751953125,
      "epoch": 0.1377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 42,
      "total_loss": 3.2896270751953125
    },
    {
      "classification_loss": 3.987785816192627,
      "epoch": 0.14098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 43,
      "total_loss": 3.987785816192627
    },
    {
      "classification_loss": 3.4023499488830566,
      "epoch": 0.14426229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 44,
      "total_loss": 3.4023499488830566
    },
    {
      "classification_loss": 2.4281792640686035,
      "epoch": 0.14754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 45,
      "total_loss": 2.4281792640686035
    },
    {
      "classification_loss": 2.922004222869873,
      "epoch": 0.15081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 46,
      "total_loss": 2.922004222869873
    },
    {
      "classification_loss": 2.2227625846862793,
      "epoch": 0.1540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 47,
      "total_loss": 2.2227625846862793
    },
    {
      "classification_loss": 2.1517064571380615,
      "epoch": 0.15737704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 48,
      "total_loss": 2.1517064571380615
    },
    {
      "classification_loss": 1.749600887298584,
      "epoch": 0.16065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 49,
      "total_loss": 1.749600887298584
    },
    {
      "classification_loss": 1.7081162929534912,
      "epoch": 0.16393442622950818,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 50,
      "total_loss": 1.7081162929534912
    },
    {
      "classification_loss": 1.1040520668029785,
      "epoch": 0.16721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 51,
      "total_loss": 1.1040520668029785
    },
    {
      "classification_loss": 1.0640112161636353,
      "epoch": 0.17049180327868851,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 52,
      "total_loss": 1.0640112161636353
    },
    {
      "classification_loss": 1.0751070976257324,
      "epoch": 0.1737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 53,
      "total_loss": 1.0751070976257324
    },
    {
      "classification_loss": 1.1094213724136353,
      "epoch": 0.17704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 54,
      "total_loss": 1.1094213724136353
    },
    {
      "classification_loss": 1.2306082248687744,
      "epoch": 0.18032786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 55,
      "total_loss": 1.2306082248687744
    },
    {
      "classification_loss": 1.1208399534225464,
      "epoch": 0.18360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 56,
      "total_loss": 1.1208399534225464
    },
    {
      "classification_loss": 1.0001277923583984,
      "epoch": 0.18688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 57,
      "total_loss": 1.0001277923583984
    },
    {
      "classification_loss": 0.9024312496185303,
      "epoch": 0.1901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 58,
      "total_loss": 0.9024312496185303
    },
    {
      "classification_loss": 0.8169190883636475,
      "epoch": 0.19344262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 59,
      "total_loss": 0.8169190883636475
    },
    {
      "classification_loss": 0.809917151927948,
      "epoch": 0.19672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 60,
      "total_loss": 0.809917151927948
    },
    {
      "classification_loss": 1.0662477016448975,
      "epoch": 0.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 61,
      "total_loss": 1.0662477016448975
    },
    {
      "classification_loss": 0.9991847276687622,
      "epoch": 0.20327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 62,
      "total_loss": 0.9991847276687622
    },
    {
      "classification_loss": 1.049583077430725,
      "epoch": 0.20655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 63,
      "total_loss": 1.049583077430725
    },
    {
      "classification_loss": 1.0871797800064087,
      "epoch": 0.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 64,
      "total_loss": 1.0871797800064087
    },
    {
      "classification_loss": 0.9566490650177002,
      "epoch": 0.21311475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 65,
      "total_loss": 0.9566490650177002
    },
    {
      "classification_loss": 1.1002774238586426,
      "epoch": 0.21639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 66,
      "total_loss": 1.1002774238586426
    },
    {
      "classification_loss": 0.9420120120048523,
      "epoch": 0.21967213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 67,
      "total_loss": 0.9420120120048523
    },
    {
      "classification_loss": 0.9195044636726379,
      "epoch": 0.22295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 68,
      "total_loss": 0.9195044636726379
    },
    {
      "classification_loss": 0.941886842250824,
      "epoch": 0.2262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 69,
      "total_loss": 0.941886842250824
    },
    {
      "classification_loss": 0.9129692316055298,
      "epoch": 0.22950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 70,
      "total_loss": 0.9129692316055298
    },
    {
      "classification_loss": 0.966028094291687,
      "epoch": 0.23278688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 71,
      "total_loss": 0.966028094291687
    },
    {
      "classification_loss": 0.7267212867736816,
      "epoch": 0.2360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 72,
      "total_loss": 0.7267212867736816
    },
    {
      "classification_loss": 0.8605775237083435,
      "epoch": 0.23934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 73,
      "total_loss": 0.8605775237083435
    },
    {
      "classification_loss": 0.8440930247306824,
      "epoch": 0.24262295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 74,
      "total_loss": 0.8440930247306824
    },
    {
      "classification_loss": 0.9578810334205627,
      "epoch": 0.2459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 75,
      "total_loss": 0.9578810334205627
    },
    {
      "classification_loss": 0.739755392074585,
      "epoch": 0.24918032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 76,
      "total_loss": 0.739755392074585
    },
    {
      "classification_loss": 0.6734002828598022,
      "epoch": 0.25245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 77,
      "total_loss": 0.6734002828598022
    },
    {
      "classification_loss": 0.8013323545455933,
      "epoch": 0.25573770491803277,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 78,
      "total_loss": 0.8013323545455933
    },
    {
      "classification_loss": 0.8135108351707458,
      "epoch": 0.25901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 79,
      "total_loss": 0.8135108351707458
    },
    {
      "classification_loss": 0.7676095962524414,
      "epoch": 0.26229508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 80,
      "total_loss": 0.7676095962524414
    },
    {
      "classification_loss": 0.8518051505088806,
      "epoch": 0.26557377049180325,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 81,
      "total_loss": 0.8518051505088806
    },
    {
      "classification_loss": 0.7586124539375305,
      "epoch": 0.26885245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 82,
      "total_loss": 0.7586124539375305
    },
    {
      "classification_loss": 0.8029384613037109,
      "epoch": 0.2721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 83,
      "total_loss": 0.8029384613037109
    },
    {
      "classification_loss": 0.7209784388542175,
      "epoch": 0.2754098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 84,
      "total_loss": 0.7209784388542175
    },
    {
      "classification_loss": 0.8773118257522583,
      "epoch": 0.2786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 85,
      "total_loss": 0.8773118257522583
    },
    {
      "classification_loss": 0.901491641998291,
      "epoch": 0.2819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 86,
      "total_loss": 0.901491641998291
    },
    {
      "classification_loss": 0.8136327266693115,
      "epoch": 0.28524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 87,
      "total_loss": 0.8136327266693115
    },
    {
      "classification_loss": 0.8451808094978333,
      "epoch": 0.28852459016393445,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 88,
      "total_loss": 0.8451808094978333
    },
    {
      "classification_loss": 0.8602125644683838,
      "epoch": 0.29180327868852457,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 89,
      "total_loss": 0.8602125644683838
    },
    {
      "classification_loss": 0.7479987740516663,
      "epoch": 0.29508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 90,
      "total_loss": 0.7479987740516663
    },
    {
      "classification_loss": 0.6634376645088196,
      "epoch": 0.2983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 91,
      "total_loss": 0.6634376645088196
    },
    {
      "classification_loss": 0.8941195011138916,
      "epoch": 0.3016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 92,
      "total_loss": 0.8941195011138916
    },
    {
      "classification_loss": 0.817435622215271,
      "epoch": 0.30491803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 93,
      "total_loss": 0.817435622215271
    },
    {
      "classification_loss": 0.8090084195137024,
      "epoch": 0.3081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 94,
      "total_loss": 0.8090084195137024
    },
    {
      "classification_loss": 0.6875966191291809,
      "epoch": 0.3114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 95,
      "total_loss": 0.6875966191291809
    },
    {
      "classification_loss": 0.7169122099876404,
      "epoch": 0.31475409836065577,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 96,
      "total_loss": 0.7169122099876404
    },
    {
      "classification_loss": 0.7003886699676514,
      "epoch": 0.3180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 97,
      "total_loss": 0.7003886699676514
    },
    {
      "classification_loss": 0.7689865827560425,
      "epoch": 0.32131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 98,
      "total_loss": 0.7689865827560425
    },
    {
      "classification_loss": 0.6941261291503906,
      "epoch": 0.32459016393442625,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 99,
      "total_loss": 0.6941261291503906
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 5.701595306396484,
      "learning_rate": 0.00019800000000000002,
      "loss": 3.0912,
      "step": 100
    },
    {
      "classification_loss": 0.742901086807251,
      "epoch": 0.32786885245901637,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 100,
      "total_loss": 0.742901086807251
    },
    {
      "classification_loss": 0.6920511722564697,
      "epoch": 0.33114754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 101,
      "total_loss": 0.6920511722564697
    },
    {
      "classification_loss": 0.7078407406806946,
      "epoch": 0.3344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 102,
      "total_loss": 0.7078407406806946
    },
    {
      "classification_loss": 0.752394437789917,
      "epoch": 0.3377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 103,
      "total_loss": 0.752394437789917
    },
    {
      "classification_loss": 0.7132714986801147,
      "epoch": 0.34098360655737703,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 104,
      "total_loss": 0.7132714986801147
    },
    {
      "classification_loss": 0.7066264152526855,
      "epoch": 0.3442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 105,
      "total_loss": 0.7066264152526855
    },
    {
      "classification_loss": 0.7448021769523621,
      "epoch": 0.3475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 106,
      "total_loss": 0.7448021769523621
    },
    {
      "classification_loss": 0.692280113697052,
      "epoch": 0.35081967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 107,
      "total_loss": 0.692280113697052
    },
    {
      "classification_loss": 0.6864626407623291,
      "epoch": 0.3540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 108,
      "total_loss": 0.6864626407623291
    },
    {
      "classification_loss": 0.7038480043411255,
      "epoch": 0.35737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 109,
      "total_loss": 0.7038480043411255
    },
    {
      "classification_loss": 0.7720316648483276,
      "epoch": 0.36065573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 110,
      "total_loss": 0.7720316648483276
    },
    {
      "classification_loss": 0.7428768873214722,
      "epoch": 0.3639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 111,
      "total_loss": 0.7428768873214722
    },
    {
      "classification_loss": 0.7480695247650146,
      "epoch": 0.36721311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 112,
      "total_loss": 0.7480695247650146
    },
    {
      "classification_loss": 0.7385047674179077,
      "epoch": 0.3704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 113,
      "total_loss": 0.7385047674179077
    },
    {
      "classification_loss": 0.7424154877662659,
      "epoch": 0.3737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 114,
      "total_loss": 0.7424154877662659
    },
    {
      "classification_loss": 0.7708160877227783,
      "epoch": 0.3770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 115,
      "total_loss": 0.7708160877227783
    },
    {
      "classification_loss": 0.7045778632164001,
      "epoch": 0.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 116,
      "total_loss": 0.7045778632164001
    },
    {
      "classification_loss": 0.6869282126426697,
      "epoch": 0.3836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 117,
      "total_loss": 0.6869282126426697
    },
    {
      "classification_loss": 0.686357855796814,
      "epoch": 0.38688524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 118,
      "total_loss": 0.686357855796814
    },
    {
      "classification_loss": 0.7250933051109314,
      "epoch": 0.3901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 119,
      "total_loss": 0.7250933051109314
    },
    {
      "classification_loss": 0.7211783528327942,
      "epoch": 0.39344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 120,
      "total_loss": 0.7211783528327942
    },
    {
      "classification_loss": 0.7074207663536072,
      "epoch": 0.39672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 121,
      "total_loss": 0.7074207663536072
    },
    {
      "classification_loss": 0.7038979530334473,
      "epoch": 0.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 122,
      "total_loss": 0.7038979530334473
    },
    {
      "classification_loss": 0.713259756565094,
      "epoch": 0.40327868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 123,
      "total_loss": 0.713259756565094
    },
    {
      "classification_loss": 0.7022611498832703,
      "epoch": 0.4065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 124,
      "total_loss": 0.7022611498832703
    },
    {
      "classification_loss": 0.7241578698158264,
      "epoch": 0.4098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 125,
      "total_loss": 0.7241578698158264
    },
    {
      "classification_loss": 0.6973316669464111,
      "epoch": 0.4131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 126,
      "total_loss": 0.6973316669464111
    },
    {
      "classification_loss": 0.7200682759284973,
      "epoch": 0.4163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 127,
      "total_loss": 0.7200682759284973
    },
    {
      "classification_loss": 0.7193293571472168,
      "epoch": 0.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 128,
      "total_loss": 0.7193293571472168
    },
    {
      "classification_loss": 0.7121246457099915,
      "epoch": 0.42295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 129,
      "total_loss": 0.7121246457099915
    },
    {
      "classification_loss": 0.7147690653800964,
      "epoch": 0.4262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 130,
      "total_loss": 0.7147690653800964
    },
    {
      "classification_loss": 0.7148407697677612,
      "epoch": 0.42950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 131,
      "total_loss": 0.7148407697677612
    },
    {
      "classification_loss": 0.6894114017486572,
      "epoch": 0.43278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 132,
      "total_loss": 0.6894114017486572
    },
    {
      "classification_loss": 0.7117214202880859,
      "epoch": 0.4360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 133,
      "total_loss": 0.7117214202880859
    },
    {
      "classification_loss": 0.7498599290847778,
      "epoch": 0.43934426229508194,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 134,
      "total_loss": 0.7498599290847778
    },
    {
      "classification_loss": 0.7207503318786621,
      "epoch": 0.4426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 135,
      "total_loss": 0.7207503318786621
    },
    {
      "classification_loss": 0.7144953608512878,
      "epoch": 0.4459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 136,
      "total_loss": 0.7144953608512878
    },
    {
      "classification_loss": 0.7184303402900696,
      "epoch": 0.4491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 137,
      "total_loss": 0.7184303402900696
    },
    {
      "classification_loss": 0.7242590188980103,
      "epoch": 0.4524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 138,
      "total_loss": 0.7242590188980103
    },
    {
      "classification_loss": 0.7010200619697571,
      "epoch": 0.4557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 139,
      "total_loss": 0.7010200619697571
    },
    {
      "classification_loss": 0.6684954166412354,
      "epoch": 0.45901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 140,
      "total_loss": 0.6684954166412354
    },
    {
      "classification_loss": 0.6995996236801147,
      "epoch": 0.46229508196721314,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 141,
      "total_loss": 0.6995996236801147
    },
    {
      "classification_loss": 0.7771286964416504,
      "epoch": 0.46557377049180326,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 142,
      "total_loss": 0.7771286964416504
    },
    {
      "classification_loss": 0.7298861145973206,
      "epoch": 0.46885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 143,
      "total_loss": 0.7298861145973206
    },
    {
      "classification_loss": 0.7282312512397766,
      "epoch": 0.4721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 144,
      "total_loss": 0.7282312512397766
    },
    {
      "classification_loss": 0.6427392959594727,
      "epoch": 0.47540983606557374,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 145,
      "total_loss": 0.6427392959594727
    },
    {
      "classification_loss": 0.7246519923210144,
      "epoch": 0.4786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 146,
      "total_loss": 0.7246519923210144
    },
    {
      "classification_loss": 0.730600893497467,
      "epoch": 0.4819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 147,
      "total_loss": 0.730600893497467
    },
    {
      "classification_loss": 0.7111387252807617,
      "epoch": 0.4852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 148,
      "total_loss": 0.7111387252807617
    },
    {
      "classification_loss": 0.7102357745170593,
      "epoch": 0.4885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 149,
      "total_loss": 0.7102357745170593
    },
    {
      "classification_loss": 0.7123368978500366,
      "epoch": 0.4918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 150,
      "total_loss": 0.7123368978500366
    },
    {
      "classification_loss": 0.7341248393058777,
      "epoch": 0.49508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 151,
      "total_loss": 0.7341248393058777
    },
    {
      "classification_loss": 0.7222155928611755,
      "epoch": 0.49836065573770494,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 152,
      "total_loss": 0.7222155928611755
    },
    {
      "classification_loss": 0.7102056741714478,
      "epoch": 0.5016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 153,
      "total_loss": 0.7102056741714478
    },
    {
      "classification_loss": 0.7005139589309692,
      "epoch": 0.5049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 154,
      "total_loss": 0.7005139589309692
    },
    {
      "classification_loss": 0.6699138283729553,
      "epoch": 0.5081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 155,
      "total_loss": 0.6699138283729553
    },
    {
      "classification_loss": 0.7051196098327637,
      "epoch": 0.5114754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 156,
      "total_loss": 0.7051196098327637
    },
    {
      "classification_loss": 0.7138460278511047,
      "epoch": 0.5147540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 157,
      "total_loss": 0.7138460278511047
    },
    {
      "classification_loss": 0.7164344191551208,
      "epoch": 0.5180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 158,
      "total_loss": 0.7164344191551208
    },
    {
      "classification_loss": 0.7110159397125244,
      "epoch": 0.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 159,
      "total_loss": 0.7110159397125244
    },
    {
      "classification_loss": 0.6978866457939148,
      "epoch": 0.5245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 160,
      "total_loss": 0.6978866457939148
    },
    {
      "classification_loss": 0.7022634744644165,
      "epoch": 0.5278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 161,
      "total_loss": 0.7022634744644165
    },
    {
      "classification_loss": 0.7068108916282654,
      "epoch": 0.5311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 162,
      "total_loss": 0.7068108916282654
    },
    {
      "classification_loss": 0.701731264591217,
      "epoch": 0.5344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 163,
      "total_loss": 0.701731264591217
    },
    {
      "classification_loss": 0.7147204279899597,
      "epoch": 0.5377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 164,
      "total_loss": 0.7147204279899597
    },
    {
      "classification_loss": 0.6866638660430908,
      "epoch": 0.5409836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 165,
      "total_loss": 0.6866638660430908
    },
    {
      "classification_loss": 0.7390316724777222,
      "epoch": 0.5442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 166,
      "total_loss": 0.7390316724777222
    },
    {
      "classification_loss": 0.7071415185928345,
      "epoch": 0.5475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 167,
      "total_loss": 0.7071415185928345
    },
    {
      "classification_loss": 0.689320981502533,
      "epoch": 0.5508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 168,
      "total_loss": 0.689320981502533
    },
    {
      "classification_loss": 0.7058994174003601,
      "epoch": 0.5540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 169,
      "total_loss": 0.7058994174003601
    },
    {
      "classification_loss": 0.7203948497772217,
      "epoch": 0.5573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 170,
      "total_loss": 0.7203948497772217
    },
    {
      "classification_loss": 0.7007912397384644,
      "epoch": 0.5606557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 171,
      "total_loss": 0.7007912397384644
    },
    {
      "classification_loss": 0.6909976005554199,
      "epoch": 0.5639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 172,
      "total_loss": 0.6909976005554199
    },
    {
      "classification_loss": 0.7286224961280823,
      "epoch": 0.5672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 173,
      "total_loss": 0.7286224961280823
    },
    {
      "classification_loss": 0.7029265761375427,
      "epoch": 0.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 174,
      "total_loss": 0.7029265761375427
    },
    {
      "classification_loss": 0.7289374470710754,
      "epoch": 0.5737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 175,
      "total_loss": 0.7289374470710754
    },
    {
      "classification_loss": 0.7278526425361633,
      "epoch": 0.5770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 176,
      "total_loss": 0.7278526425361633
    },
    {
      "classification_loss": 0.7072170376777649,
      "epoch": 0.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 177,
      "total_loss": 0.7072170376777649
    },
    {
      "classification_loss": 0.6945974826812744,
      "epoch": 0.5836065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 178,
      "total_loss": 0.6945974826812744
    },
    {
      "classification_loss": 0.6839261054992676,
      "epoch": 0.5868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 179,
      "total_loss": 0.6839261054992676
    },
    {
      "classification_loss": 0.6654853224754333,
      "epoch": 0.5901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 180,
      "total_loss": 0.6654853224754333
    },
    {
      "classification_loss": 0.6980960369110107,
      "epoch": 0.5934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 181,
      "total_loss": 0.6980960369110107
    },
    {
      "classification_loss": 0.7297942638397217,
      "epoch": 0.5967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 182,
      "total_loss": 0.7297942638397217
    },
    {
      "classification_loss": 0.6894410252571106,
      "epoch": 0.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 183,
      "total_loss": 0.6894410252571106
    },
    {
      "classification_loss": 0.7140787243843079,
      "epoch": 0.6032786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 184,
      "total_loss": 0.7140787243843079
    },
    {
      "classification_loss": 0.6974874138832092,
      "epoch": 0.6065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 185,
      "total_loss": 0.6974874138832092
    },
    {
      "classification_loss": 0.7107126712799072,
      "epoch": 0.6098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 186,
      "total_loss": 0.7107126712799072
    },
    {
      "classification_loss": 0.7369199991226196,
      "epoch": 0.6131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 187,
      "total_loss": 0.7369199991226196
    },
    {
      "classification_loss": 0.705725908279419,
      "epoch": 0.6163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 188,
      "total_loss": 0.705725908279419
    },
    {
      "classification_loss": 0.7055432200431824,
      "epoch": 0.6196721311475409,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 189,
      "total_loss": 0.7055432200431824
    },
    {
      "classification_loss": 0.6962285041809082,
      "epoch": 0.6229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 190,
      "total_loss": 0.6962285041809082
    },
    {
      "classification_loss": 0.7342478036880493,
      "epoch": 0.6262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 191,
      "total_loss": 0.7342478036880493
    },
    {
      "classification_loss": 0.7222051620483398,
      "epoch": 0.6295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 192,
      "total_loss": 0.7222051620483398
    },
    {
      "classification_loss": 0.6642899513244629,
      "epoch": 0.6327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 193,
      "total_loss": 0.6642899513244629
    },
    {
      "classification_loss": 0.7100484371185303,
      "epoch": 0.6360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 194,
      "total_loss": 0.7100484371185303
    },
    {
      "classification_loss": 0.713492214679718,
      "epoch": 0.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 195,
      "total_loss": 0.713492214679718
    },
    {
      "classification_loss": 0.6334360837936401,
      "epoch": 0.6426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 196,
      "total_loss": 0.6334360837936401
    },
    {
      "classification_loss": 0.6974565386772156,
      "epoch": 0.6459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 197,
      "total_loss": 0.6974565386772156
    },
    {
      "classification_loss": 0.702074408531189,
      "epoch": 0.6491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 198,
      "total_loss": 0.702074408531189
    },
    {
      "classification_loss": 0.7526955008506775,
      "epoch": 0.6524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 199,
      "total_loss": 0.7526955008506775
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 4.703481674194336,
      "learning_rate": 0.0001967,
      "loss": 0.7118,
      "step": 200
    },
    {
      "classification_loss": 0.7006101608276367,
      "epoch": 0.6557377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 200,
      "total_loss": 0.7006101608276367
    },
    {
      "classification_loss": 0.7057560086250305,
      "epoch": 0.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 201,
      "total_loss": 0.7057560086250305
    },
    {
      "classification_loss": 0.6795766353607178,
      "epoch": 0.6622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 202,
      "total_loss": 0.6795766353607178
    },
    {
      "classification_loss": 0.6476075649261475,
      "epoch": 0.6655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 203,
      "total_loss": 0.6476075649261475
    },
    {
      "classification_loss": 0.7112053632736206,
      "epoch": 0.6688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 204,
      "total_loss": 0.7112053632736206
    },
    {
      "classification_loss": 0.704059362411499,
      "epoch": 0.6721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 205,
      "total_loss": 0.704059362411499
    },
    {
      "classification_loss": 0.7086321115493774,
      "epoch": 0.6754098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 206,
      "total_loss": 0.7086321115493774
    },
    {
      "classification_loss": 0.6958596110343933,
      "epoch": 0.6786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 207,
      "total_loss": 0.6958596110343933
    },
    {
      "classification_loss": 0.6778581142425537,
      "epoch": 0.6819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 208,
      "total_loss": 0.6778581142425537
    },
    {
      "classification_loss": 0.6778616309165955,
      "epoch": 0.6852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 209,
      "total_loss": 0.6778616309165955
    },
    {
      "classification_loss": 0.7022836804389954,
      "epoch": 0.6885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 210,
      "total_loss": 0.7022836804389954
    },
    {
      "classification_loss": 0.7133873105049133,
      "epoch": 0.6918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 211,
      "total_loss": 0.7133873105049133
    },
    {
      "classification_loss": 0.6909018158912659,
      "epoch": 0.6950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 212,
      "total_loss": 0.6909018158912659
    },
    {
      "classification_loss": 0.6824254393577576,
      "epoch": 0.6983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 213,
      "total_loss": 0.6824254393577576
    },
    {
      "classification_loss": 0.7163437604904175,
      "epoch": 0.7016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 214,
      "total_loss": 0.7163437604904175
    },
    {
      "classification_loss": 0.6583008766174316,
      "epoch": 0.7049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 215,
      "total_loss": 0.6583008766174316
    },
    {
      "classification_loss": 0.6642976403236389,
      "epoch": 0.7081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 216,
      "total_loss": 0.6642976403236389
    },
    {
      "classification_loss": 0.6475402116775513,
      "epoch": 0.7114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 217,
      "total_loss": 0.6475402116775513
    },
    {
      "classification_loss": 0.6955196261405945,
      "epoch": 0.7147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 218,
      "total_loss": 0.6955196261405945
    },
    {
      "classification_loss": 0.7278201580047607,
      "epoch": 0.7180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 219,
      "total_loss": 0.7278201580047607
    },
    {
      "classification_loss": 0.7335761189460754,
      "epoch": 0.7213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 220,
      "total_loss": 0.7335761189460754
    },
    {
      "classification_loss": 0.6683060526847839,
      "epoch": 0.7245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 221,
      "total_loss": 0.6683060526847839
    },
    {
      "classification_loss": 0.7194944024085999,
      "epoch": 0.7278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 222,
      "total_loss": 0.7194944024085999
    },
    {
      "classification_loss": 0.718978762626648,
      "epoch": 0.7311475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 223,
      "total_loss": 0.718978762626648
    },
    {
      "classification_loss": 0.7054257988929749,
      "epoch": 0.7344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 224,
      "total_loss": 0.7054257988929749
    },
    {
      "classification_loss": 0.718989372253418,
      "epoch": 0.7377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 225,
      "total_loss": 0.718989372253418
    },
    {
      "classification_loss": 0.7282262444496155,
      "epoch": 0.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 226,
      "total_loss": 0.7282262444496155
    },
    {
      "classification_loss": 0.6980904340744019,
      "epoch": 0.7442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 227,
      "total_loss": 0.6980904340744019
    },
    {
      "classification_loss": 0.6713348031044006,
      "epoch": 0.7475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 228,
      "total_loss": 0.6713348031044006
    },
    {
      "classification_loss": 0.7151282429695129,
      "epoch": 0.7508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 229,
      "total_loss": 0.7151282429695129
    },
    {
      "classification_loss": 0.6882845163345337,
      "epoch": 0.7540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 230,
      "total_loss": 0.6882845163345337
    },
    {
      "classification_loss": 0.7072422504425049,
      "epoch": 0.7573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 231,
      "total_loss": 0.7072422504425049
    },
    {
      "classification_loss": 0.6815532445907593,
      "epoch": 0.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 232,
      "total_loss": 0.6815532445907593
    },
    {
      "classification_loss": 0.6569985151290894,
      "epoch": 0.7639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 233,
      "total_loss": 0.6569985151290894
    },
    {
      "classification_loss": 0.6934366822242737,
      "epoch": 0.7672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 234,
      "total_loss": 0.6934366822242737
    },
    {
      "classification_loss": 0.6896246671676636,
      "epoch": 0.7704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 235,
      "total_loss": 0.6896246671676636
    },
    {
      "classification_loss": 0.726188063621521,
      "epoch": 0.7737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 236,
      "total_loss": 0.726188063621521
    },
    {
      "classification_loss": 0.6986669301986694,
      "epoch": 0.7770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 237,
      "total_loss": 0.6986669301986694
    },
    {
      "classification_loss": 0.7299679517745972,
      "epoch": 0.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 238,
      "total_loss": 0.7299679517745972
    },
    {
      "classification_loss": 0.681686520576477,
      "epoch": 0.7836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 239,
      "total_loss": 0.681686520576477
    },
    {
      "classification_loss": 0.6903578042984009,
      "epoch": 0.7868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 240,
      "total_loss": 0.6903578042984009
    },
    {
      "classification_loss": 0.7175540328025818,
      "epoch": 0.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 241,
      "total_loss": 0.7175540328025818
    },
    {
      "classification_loss": 0.6984310746192932,
      "epoch": 0.7934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 242,
      "total_loss": 0.6984310746192932
    },
    {
      "classification_loss": 0.6987614631652832,
      "epoch": 0.7967213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 243,
      "total_loss": 0.6987614631652832
    },
    {
      "classification_loss": 0.6763342618942261,
      "epoch": 0.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 244,
      "total_loss": 0.6763342618942261
    },
    {
      "classification_loss": 0.7228949069976807,
      "epoch": 0.8032786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 245,
      "total_loss": 0.7228949069976807
    },
    {
      "classification_loss": 0.6791761517524719,
      "epoch": 0.8065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 246,
      "total_loss": 0.6791761517524719
    },
    {
      "classification_loss": 0.6982665061950684,
      "epoch": 0.8098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 247,
      "total_loss": 0.6982665061950684
    },
    {
      "classification_loss": 0.7332811951637268,
      "epoch": 0.8131147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 248,
      "total_loss": 0.7332811951637268
    },
    {
      "classification_loss": 0.6729944348335266,
      "epoch": 0.8163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 249,
      "total_loss": 0.6729944348335266
    },
    {
      "classification_loss": 0.6996914148330688,
      "epoch": 0.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 250,
      "total_loss": 0.6996914148330688
    },
    {
      "classification_loss": 0.7072135806083679,
      "epoch": 0.8229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 251,
      "total_loss": 0.7072135806083679
    },
    {
      "classification_loss": 0.6905090808868408,
      "epoch": 0.8262295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 252,
      "total_loss": 0.6905090808868408
    },
    {
      "classification_loss": 0.671786904335022,
      "epoch": 0.8295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 253,
      "total_loss": 0.671786904335022
    },
    {
      "classification_loss": 0.6960476636886597,
      "epoch": 0.8327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 254,
      "total_loss": 0.6960476636886597
    },
    {
      "classification_loss": 0.6613081693649292,
      "epoch": 0.8360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 255,
      "total_loss": 0.6613081693649292
    },
    {
      "classification_loss": 0.6890307664871216,
      "epoch": 0.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 256,
      "total_loss": 0.6890307664871216
    },
    {
      "classification_loss": 0.6780089139938354,
      "epoch": 0.8426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 257,
      "total_loss": 0.6780089139938354
    },
    {
      "classification_loss": 0.6876348257064819,
      "epoch": 0.8459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 258,
      "total_loss": 0.6876348257064819
    },
    {
      "classification_loss": 0.7140586972236633,
      "epoch": 0.8491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 259,
      "total_loss": 0.7140586972236633
    },
    {
      "classification_loss": 0.69904625415802,
      "epoch": 0.8524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 260,
      "total_loss": 0.69904625415802
    },
    {
      "classification_loss": 0.6914536952972412,
      "epoch": 0.8557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 261,
      "total_loss": 0.6914536952972412
    },
    {
      "classification_loss": 0.6884915828704834,
      "epoch": 0.8590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 262,
      "total_loss": 0.6884915828704834
    },
    {
      "classification_loss": 0.686316967010498,
      "epoch": 0.8622950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 263,
      "total_loss": 0.686316967010498
    },
    {
      "classification_loss": 0.6936506628990173,
      "epoch": 0.8655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 264,
      "total_loss": 0.6936506628990173
    },
    {
      "classification_loss": 0.7467581629753113,
      "epoch": 0.8688524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 265,
      "total_loss": 0.7467581629753113
    },
    {
      "classification_loss": 0.706075131893158,
      "epoch": 0.8721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 266,
      "total_loss": 0.706075131893158
    },
    {
      "classification_loss": 0.680850625038147,
      "epoch": 0.8754098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 267,
      "total_loss": 0.680850625038147
    },
    {
      "classification_loss": 0.6794779896736145,
      "epoch": 0.8786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 268,
      "total_loss": 0.6794779896736145
    },
    {
      "classification_loss": 0.6976137757301331,
      "epoch": 0.8819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 269,
      "total_loss": 0.6976137757301331
    },
    {
      "classification_loss": 0.6684204339981079,
      "epoch": 0.8852459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 270,
      "total_loss": 0.6684204339981079
    },
    {
      "classification_loss": 0.7025395035743713,
      "epoch": 0.8885245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 271,
      "total_loss": 0.7025395035743713
    },
    {
      "classification_loss": 0.6849387884140015,
      "epoch": 0.8918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 272,
      "total_loss": 0.6849387884140015
    },
    {
      "classification_loss": 0.6784437894821167,
      "epoch": 0.8950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 273,
      "total_loss": 0.6784437894821167
    },
    {
      "classification_loss": 0.6674915552139282,
      "epoch": 0.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 274,
      "total_loss": 0.6674915552139282
    },
    {
      "classification_loss": 0.6754313707351685,
      "epoch": 0.9016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 275,
      "total_loss": 0.6754313707351685
    },
    {
      "classification_loss": 0.6888018846511841,
      "epoch": 0.9049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 276,
      "total_loss": 0.6888018846511841
    },
    {
      "classification_loss": 0.7052072882652283,
      "epoch": 0.9081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 277,
      "total_loss": 0.7052072882652283
    },
    {
      "classification_loss": 0.6901190876960754,
      "epoch": 0.9114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 278,
      "total_loss": 0.6901190876960754
    },
    {
      "classification_loss": 0.7169199585914612,
      "epoch": 0.9147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 279,
      "total_loss": 0.7169199585914612
    },
    {
      "classification_loss": 0.6962001919746399,
      "epoch": 0.9180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 280,
      "total_loss": 0.6962001919746399
    },
    {
      "classification_loss": 0.6727451086044312,
      "epoch": 0.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 281,
      "total_loss": 0.6727451086044312
    },
    {
      "classification_loss": 0.6463252305984497,
      "epoch": 0.9245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 282,
      "total_loss": 0.6463252305984497
    },
    {
      "classification_loss": 0.6885053515434265,
      "epoch": 0.9278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 283,
      "total_loss": 0.6885053515434265
    },
    {
      "classification_loss": 0.695947527885437,
      "epoch": 0.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 284,
      "total_loss": 0.695947527885437
    },
    {
      "classification_loss": 0.6800493001937866,
      "epoch": 0.9344262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 285,
      "total_loss": 0.6800493001937866
    },
    {
      "classification_loss": 0.7095627784729004,
      "epoch": 0.9377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 286,
      "total_loss": 0.7095627784729004
    },
    {
      "classification_loss": 0.6669729948043823,
      "epoch": 0.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 287,
      "total_loss": 0.6669729948043823
    },
    {
      "classification_loss": 0.6740326285362244,
      "epoch": 0.9442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 288,
      "total_loss": 0.6740326285362244
    },
    {
      "classification_loss": 0.685367226600647,
      "epoch": 0.9475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 289,
      "total_loss": 0.685367226600647
    },
    {
      "classification_loss": 0.6946611404418945,
      "epoch": 0.9508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 290,
      "total_loss": 0.6946611404418945
    },
    {
      "classification_loss": 0.6969387531280518,
      "epoch": 0.9540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 291,
      "total_loss": 0.6969387531280518
    },
    {
      "classification_loss": 0.6880154609680176,
      "epoch": 0.9573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 292,
      "total_loss": 0.6880154609680176
    },
    {
      "classification_loss": 0.6588075757026672,
      "epoch": 0.9606557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 293,
      "total_loss": 0.6588075757026672
    },
    {
      "classification_loss": 0.7109318375587463,
      "epoch": 0.9639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 294,
      "total_loss": 0.7109318375587463
    },
    {
      "classification_loss": 0.7191862463951111,
      "epoch": 0.9672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 295,
      "total_loss": 0.7191862463951111
    },
    {
      "classification_loss": 0.691542387008667,
      "epoch": 0.9704918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 296,
      "total_loss": 0.691542387008667
    },
    {
      "classification_loss": 0.6856371760368347,
      "epoch": 0.9737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 297,
      "total_loss": 0.6856371760368347
    },
    {
      "classification_loss": 0.6834441423416138,
      "epoch": 0.9770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 298,
      "total_loss": 0.6834441423416138
    },
    {
      "classification_loss": 0.6589464545249939,
      "epoch": 0.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 299,
      "total_loss": 0.6589464545249939
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 0.7335357069969177,
      "learning_rate": 0.0001933666666666667,
      "loss": 0.6927,
      "step": 300
    },
    {
      "classification_loss": 0.7044894695281982,
      "epoch": 0.9836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 300,
      "total_loss": 0.7044894695281982
    },
    {
      "classification_loss": 0.6442395448684692,
      "epoch": 0.9868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 301,
      "total_loss": 0.6442395448684692
    },
    {
      "classification_loss": 0.6622635722160339,
      "epoch": 0.9901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 302,
      "total_loss": 0.6622635722160339
    },
    {
      "classification_loss": 0.6949057579040527,
      "epoch": 0.9934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 303,
      "total_loss": 0.6949057579040527
    },
    {
      "classification_loss": 0.6714540719985962,
      "epoch": 0.9967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 304,
      "total_loss": 0.6714540719985962
    },
    {
      "classification_loss": 0.7162638306617737,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7162638306617737
    },
    {
      "classification_loss": 0.718992292881012,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.718992292881012
    },
    {
      "classification_loss": 0.7255061268806458,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7255061268806458
    },
    {
      "classification_loss": 0.7313178181648254,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7313178181648254
    },
    {
      "classification_loss": 0.7115769982337952,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7115769982337952
    },
    {
      "classification_loss": 0.7226206064224243,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7226206064224243
    },
    {
      "classification_loss": 0.7160924673080444,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.7160924673080444
    },
    {
      "classification_loss": 0.6986309885978699,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.6986309885978699
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.426,
      "eval_f1": 0.31990521327014215,
      "eval_loss": 0.718080997467041,
      "eval_precision": 0.6308411214953271,
      "eval_recall": 0.21428571428571427,
      "eval_runtime": 6.0571,
      "eval_samples_per_second": 165.094,
      "eval_steps_per_second": 1.321,
      "step": 305
    },
    {
      "classification_loss": 0.6848212480545044,
      "epoch": 1.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 305,
      "total_loss": 0.6848212480545044
    },
    {
      "classification_loss": 0.6966485381126404,
      "epoch": 1.0032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 306,
      "total_loss": 0.6966485381126404
    },
    {
      "classification_loss": 0.6982526779174805,
      "epoch": 1.0065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 307,
      "total_loss": 0.6982526779174805
    },
    {
      "classification_loss": 0.6771653890609741,
      "epoch": 1.0098360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 308,
      "total_loss": 0.6771653890609741
    },
    {
      "classification_loss": 0.7104071974754333,
      "epoch": 1.0131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 309,
      "total_loss": 0.7104071974754333
    },
    {
      "classification_loss": 0.6861061453819275,
      "epoch": 1.0163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 310,
      "total_loss": 0.6861061453819275
    },
    {
      "classification_loss": 0.6968622207641602,
      "epoch": 1.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 311,
      "total_loss": 0.6968622207641602
    },
    {
      "classification_loss": 0.6723414063453674,
      "epoch": 1.022950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 312,
      "total_loss": 0.6723414063453674
    },
    {
      "classification_loss": 0.6801667809486389,
      "epoch": 1.0262295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 313,
      "total_loss": 0.6801667809486389
    },
    {
      "classification_loss": 0.6736375093460083,
      "epoch": 1.0295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 314,
      "total_loss": 0.6736375093460083
    },
    {
      "classification_loss": 0.6726878881454468,
      "epoch": 1.0327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 315,
      "total_loss": 0.6726878881454468
    },
    {
      "classification_loss": 0.6938344240188599,
      "epoch": 1.0360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 316,
      "total_loss": 0.6938344240188599
    },
    {
      "classification_loss": 0.6581801772117615,
      "epoch": 1.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 317,
      "total_loss": 0.6581801772117615
    },
    {
      "classification_loss": 0.6751754879951477,
      "epoch": 1.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 318,
      "total_loss": 0.6751754879951477
    },
    {
      "classification_loss": 0.7201510071754456,
      "epoch": 1.0459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 319,
      "total_loss": 0.7201510071754456
    },
    {
      "classification_loss": 0.6931667923927307,
      "epoch": 1.0491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 320,
      "total_loss": 0.6931667923927307
    },
    {
      "classification_loss": 0.6565389633178711,
      "epoch": 1.0524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 321,
      "total_loss": 0.6565389633178711
    },
    {
      "classification_loss": 0.6852599382400513,
      "epoch": 1.0557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 322,
      "total_loss": 0.6852599382400513
    },
    {
      "classification_loss": 0.6914754509925842,
      "epoch": 1.0590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 323,
      "total_loss": 0.6914754509925842
    },
    {
      "classification_loss": 0.6961082220077515,
      "epoch": 1.0622950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 324,
      "total_loss": 0.6961082220077515
    },
    {
      "classification_loss": 0.68470698595047,
      "epoch": 1.0655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 325,
      "total_loss": 0.68470698595047
    },
    {
      "classification_loss": 0.6738974452018738,
      "epoch": 1.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 326,
      "total_loss": 0.6738974452018738
    },
    {
      "classification_loss": 0.6581007242202759,
      "epoch": 1.0721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 327,
      "total_loss": 0.6581007242202759
    },
    {
      "classification_loss": 0.6673474311828613,
      "epoch": 1.0754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 328,
      "total_loss": 0.6673474311828613
    },
    {
      "classification_loss": 0.6496099233627319,
      "epoch": 1.0786885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 329,
      "total_loss": 0.6496099233627319
    },
    {
      "classification_loss": 0.6547068953514099,
      "epoch": 1.0819672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 330,
      "total_loss": 0.6547068953514099
    },
    {
      "classification_loss": 0.7050886750221252,
      "epoch": 1.0852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 331,
      "total_loss": 0.7050886750221252
    },
    {
      "classification_loss": 0.6974179148674011,
      "epoch": 1.0885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 332,
      "total_loss": 0.6974179148674011
    },
    {
      "classification_loss": 0.6830812692642212,
      "epoch": 1.0918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 333,
      "total_loss": 0.6830812692642212
    },
    {
      "classification_loss": 0.7118186950683594,
      "epoch": 1.0950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 334,
      "total_loss": 0.7118186950683594
    },
    {
      "classification_loss": 0.7309463620185852,
      "epoch": 1.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 335,
      "total_loss": 0.7309463620185852
    },
    {
      "classification_loss": 0.7098247408866882,
      "epoch": 1.1016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 336,
      "total_loss": 0.7098247408866882
    },
    {
      "classification_loss": 0.6780053973197937,
      "epoch": 1.1049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 337,
      "total_loss": 0.6780053973197937
    },
    {
      "classification_loss": 0.6910977363586426,
      "epoch": 1.1081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 338,
      "total_loss": 0.6910977363586426
    },
    {
      "classification_loss": 0.6865598559379578,
      "epoch": 1.1114754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 339,
      "total_loss": 0.6865598559379578
    },
    {
      "classification_loss": 0.6198625564575195,
      "epoch": 1.1147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 340,
      "total_loss": 0.6198625564575195
    },
    {
      "classification_loss": 0.7204165458679199,
      "epoch": 1.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 341,
      "total_loss": 0.7204165458679199
    },
    {
      "classification_loss": 0.6816821694374084,
      "epoch": 1.1213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 342,
      "total_loss": 0.6816821694374084
    },
    {
      "classification_loss": 0.6702285408973694,
      "epoch": 1.1245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 343,
      "total_loss": 0.6702285408973694
    },
    {
      "classification_loss": 0.6479620933532715,
      "epoch": 1.1278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 344,
      "total_loss": 0.6479620933532715
    },
    {
      "classification_loss": 0.6663740277290344,
      "epoch": 1.1311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 345,
      "total_loss": 0.6663740277290344
    },
    {
      "classification_loss": 0.6634979844093323,
      "epoch": 1.1344262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 346,
      "total_loss": 0.6634979844093323
    },
    {
      "classification_loss": 0.6820067763328552,
      "epoch": 1.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 347,
      "total_loss": 0.6820067763328552
    },
    {
      "classification_loss": 0.685373842716217,
      "epoch": 1.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 348,
      "total_loss": 0.685373842716217
    },
    {
      "classification_loss": 0.6951534748077393,
      "epoch": 1.1442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 349,
      "total_loss": 0.6951534748077393
    },
    {
      "classification_loss": 0.6503526568412781,
      "epoch": 1.1475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 350,
      "total_loss": 0.6503526568412781
    },
    {
      "classification_loss": 0.6928096413612366,
      "epoch": 1.1508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 351,
      "total_loss": 0.6928096413612366
    },
    {
      "classification_loss": 0.6768551468849182,
      "epoch": 1.1540983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 352,
      "total_loss": 0.6768551468849182
    },
    {
      "classification_loss": 0.6428161859512329,
      "epoch": 1.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 353,
      "total_loss": 0.6428161859512329
    },
    {
      "classification_loss": 0.6681473851203918,
      "epoch": 1.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 354,
      "total_loss": 0.6681473851203918
    },
    {
      "classification_loss": 0.6482967734336853,
      "epoch": 1.1639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 355,
      "total_loss": 0.6482967734336853
    },
    {
      "classification_loss": 0.6705722808837891,
      "epoch": 1.1672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 356,
      "total_loss": 0.6705722808837891
    },
    {
      "classification_loss": 0.6407349705696106,
      "epoch": 1.1704918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 357,
      "total_loss": 0.6407349705696106
    },
    {
      "classification_loss": 0.7089855670928955,
      "epoch": 1.1737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 358,
      "total_loss": 0.7089855670928955
    },
    {
      "classification_loss": 0.6488339304924011,
      "epoch": 1.1770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 359,
      "total_loss": 0.6488339304924011
    },
    {
      "classification_loss": 0.6799866557121277,
      "epoch": 1.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 360,
      "total_loss": 0.6799866557121277
    },
    {
      "classification_loss": 0.7046429514884949,
      "epoch": 1.1836065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 361,
      "total_loss": 0.7046429514884949
    },
    {
      "classification_loss": 0.6905555129051208,
      "epoch": 1.1868852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 362,
      "total_loss": 0.6905555129051208
    },
    {
      "classification_loss": 0.6759887337684631,
      "epoch": 1.1901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 363,
      "total_loss": 0.6759887337684631
    },
    {
      "classification_loss": 0.632932722568512,
      "epoch": 1.1934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 364,
      "total_loss": 0.632932722568512
    },
    {
      "classification_loss": 0.7288864850997925,
      "epoch": 1.1967213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 365,
      "total_loss": 0.7288864850997925
    },
    {
      "classification_loss": 0.7018261551856995,
      "epoch": 1.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 366,
      "total_loss": 0.7018261551856995
    },
    {
      "classification_loss": 0.6441947817802429,
      "epoch": 1.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 367,
      "total_loss": 0.6441947817802429
    },
    {
      "classification_loss": 0.7334960103034973,
      "epoch": 1.2065573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 368,
      "total_loss": 0.7334960103034973
    },
    {
      "classification_loss": 0.6877341866493225,
      "epoch": 1.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 369,
      "total_loss": 0.6877341866493225
    },
    {
      "classification_loss": 0.6665780544281006,
      "epoch": 1.2131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 370,
      "total_loss": 0.6665780544281006
    },
    {
      "classification_loss": 0.6543006300926208,
      "epoch": 1.2163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 371,
      "total_loss": 0.6543006300926208
    },
    {
      "classification_loss": 0.7008847594261169,
      "epoch": 1.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 372,
      "total_loss": 0.7008847594261169
    },
    {
      "classification_loss": 0.7062990069389343,
      "epoch": 1.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 373,
      "total_loss": 0.7062990069389343
    },
    {
      "classification_loss": 0.6467128396034241,
      "epoch": 1.2262295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 374,
      "total_loss": 0.6467128396034241
    },
    {
      "classification_loss": 0.6916633248329163,
      "epoch": 1.2295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 375,
      "total_loss": 0.6916633248329163
    },
    {
      "classification_loss": 0.6728904843330383,
      "epoch": 1.2327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 376,
      "total_loss": 0.6728904843330383
    },
    {
      "classification_loss": 0.6907960176467896,
      "epoch": 1.2360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 377,
      "total_loss": 0.6907960176467896
    },
    {
      "classification_loss": 0.6886368989944458,
      "epoch": 1.2393442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 378,
      "total_loss": 0.6886368989944458
    },
    {
      "classification_loss": 0.6569947004318237,
      "epoch": 1.2426229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 379,
      "total_loss": 0.6569947004318237
    },
    {
      "classification_loss": 0.6647143363952637,
      "epoch": 1.2459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 380,
      "total_loss": 0.6647143363952637
    },
    {
      "classification_loss": 0.6997794508934021,
      "epoch": 1.2491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 381,
      "total_loss": 0.6997794508934021
    },
    {
      "classification_loss": 0.6335008144378662,
      "epoch": 1.2524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 382,
      "total_loss": 0.6335008144378662
    },
    {
      "classification_loss": 0.6584832072257996,
      "epoch": 1.2557377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 383,
      "total_loss": 0.6584832072257996
    },
    {
      "classification_loss": 0.7369388341903687,
      "epoch": 1.2590163934426228,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 384,
      "total_loss": 0.7369388341903687
    },
    {
      "classification_loss": 0.6482481956481934,
      "epoch": 1.2622950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 385,
      "total_loss": 0.6482481956481934
    },
    {
      "classification_loss": 0.7202877402305603,
      "epoch": 1.2655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 386,
      "total_loss": 0.7202877402305603
    },
    {
      "classification_loss": 0.6177520751953125,
      "epoch": 1.2688524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 387,
      "total_loss": 0.6177520751953125
    },
    {
      "classification_loss": 0.6579982042312622,
      "epoch": 1.2721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 388,
      "total_loss": 0.6579982042312622
    },
    {
      "classification_loss": 0.6664286255836487,
      "epoch": 1.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 389,
      "total_loss": 0.6664286255836487
    },
    {
      "classification_loss": 0.7351288795471191,
      "epoch": 1.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 390,
      "total_loss": 0.7351288795471191
    },
    {
      "classification_loss": 0.674067497253418,
      "epoch": 1.2819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 391,
      "total_loss": 0.674067497253418
    },
    {
      "classification_loss": 0.6532196998596191,
      "epoch": 1.2852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 392,
      "total_loss": 0.6532196998596191
    },
    {
      "classification_loss": 0.6973771452903748,
      "epoch": 1.2885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 393,
      "total_loss": 0.6973771452903748
    },
    {
      "classification_loss": 0.6737073063850403,
      "epoch": 1.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 394,
      "total_loss": 0.6737073063850403
    },
    {
      "classification_loss": 0.6934196352958679,
      "epoch": 1.2950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 395,
      "total_loss": 0.6934196352958679
    },
    {
      "classification_loss": 0.7097926139831543,
      "epoch": 1.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 396,
      "total_loss": 0.7097926139831543
    },
    {
      "classification_loss": 0.6944233179092407,
      "epoch": 1.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 397,
      "total_loss": 0.6944233179092407
    },
    {
      "classification_loss": 0.7158463597297668,
      "epoch": 1.3049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 398,
      "total_loss": 0.7158463597297668
    },
    {
      "classification_loss": 0.7102077603340149,
      "epoch": 1.3081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 399,
      "total_loss": 0.7102077603340149
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 4.7904839515686035,
      "learning_rate": 0.00019003333333333336,
      "loss": 0.6808,
      "step": 400
    },
    {
      "classification_loss": 0.6769688725471497,
      "epoch": 1.3114754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 400,
      "total_loss": 0.6769688725471497
    },
    {
      "classification_loss": 0.7169974446296692,
      "epoch": 1.3147540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 401,
      "total_loss": 0.7169974446296692
    },
    {
      "classification_loss": 0.6981260180473328,
      "epoch": 1.318032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 402,
      "total_loss": 0.6981260180473328
    },
    {
      "classification_loss": 0.6863323450088501,
      "epoch": 1.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 403,
      "total_loss": 0.6863323450088501
    },
    {
      "classification_loss": 0.6627207398414612,
      "epoch": 1.3245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 404,
      "total_loss": 0.6627207398414612
    },
    {
      "classification_loss": 0.7193465232849121,
      "epoch": 1.3278688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 405,
      "total_loss": 0.7193465232849121
    },
    {
      "classification_loss": 0.6781594157218933,
      "epoch": 1.3311475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 406,
      "total_loss": 0.6781594157218933
    },
    {
      "classification_loss": 0.6865848898887634,
      "epoch": 1.3344262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 407,
      "total_loss": 0.6865848898887634
    },
    {
      "classification_loss": 0.656986653804779,
      "epoch": 1.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 408,
      "total_loss": 0.656986653804779
    },
    {
      "classification_loss": 0.6695076823234558,
      "epoch": 1.340983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 409,
      "total_loss": 0.6695076823234558
    },
    {
      "classification_loss": 0.6722299456596375,
      "epoch": 1.3442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 410,
      "total_loss": 0.6722299456596375
    },
    {
      "classification_loss": 0.6868859529495239,
      "epoch": 1.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 411,
      "total_loss": 0.6868859529495239
    },
    {
      "classification_loss": 0.6813832521438599,
      "epoch": 1.3508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 412,
      "total_loss": 0.6813832521438599
    },
    {
      "classification_loss": 0.6951927542686462,
      "epoch": 1.3540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 413,
      "total_loss": 0.6951927542686462
    },
    {
      "classification_loss": 0.6991255879402161,
      "epoch": 1.3573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 414,
      "total_loss": 0.6991255879402161
    },
    {
      "classification_loss": 0.6326900124549866,
      "epoch": 1.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 415,
      "total_loss": 0.6326900124549866
    },
    {
      "classification_loss": 0.6811577081680298,
      "epoch": 1.3639344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 416,
      "total_loss": 0.6811577081680298
    },
    {
      "classification_loss": 0.63130784034729,
      "epoch": 1.3672131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 417,
      "total_loss": 0.63130784034729
    },
    {
      "classification_loss": 0.6839938163757324,
      "epoch": 1.3704918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 418,
      "total_loss": 0.6839938163757324
    },
    {
      "classification_loss": 0.6608614325523376,
      "epoch": 1.3737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 419,
      "total_loss": 0.6608614325523376
    },
    {
      "classification_loss": 0.6734241247177124,
      "epoch": 1.3770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 420,
      "total_loss": 0.6734241247177124
    },
    {
      "classification_loss": 0.6762297749519348,
      "epoch": 1.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 421,
      "total_loss": 0.6762297749519348
    },
    {
      "classification_loss": 0.633268415927887,
      "epoch": 1.3836065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 422,
      "total_loss": 0.633268415927887
    },
    {
      "classification_loss": 0.6914992928504944,
      "epoch": 1.3868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 423,
      "total_loss": 0.6914992928504944
    },
    {
      "classification_loss": 0.6836352348327637,
      "epoch": 1.3901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 424,
      "total_loss": 0.6836352348327637
    },
    {
      "classification_loss": 0.6781685948371887,
      "epoch": 1.3934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 425,
      "total_loss": 0.6781685948371887
    },
    {
      "classification_loss": 0.6553655862808228,
      "epoch": 1.3967213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 426,
      "total_loss": 0.6553655862808228
    },
    {
      "classification_loss": 0.6339852809906006,
      "epoch": 1.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 427,
      "total_loss": 0.6339852809906006
    },
    {
      "classification_loss": 0.6871461868286133,
      "epoch": 1.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 428,
      "total_loss": 0.6871461868286133
    },
    {
      "classification_loss": 0.6575843691825867,
      "epoch": 1.4065573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 429,
      "total_loss": 0.6575843691825867
    },
    {
      "classification_loss": 0.6591646075248718,
      "epoch": 1.4098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 430,
      "total_loss": 0.6591646075248718
    },
    {
      "classification_loss": 0.6860789656639099,
      "epoch": 1.4131147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 431,
      "total_loss": 0.6860789656639099
    },
    {
      "classification_loss": 0.6611535549163818,
      "epoch": 1.4163934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 432,
      "total_loss": 0.6611535549163818
    },
    {
      "classification_loss": 0.685343325138092,
      "epoch": 1.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 433,
      "total_loss": 0.685343325138092
    },
    {
      "classification_loss": 0.657705545425415,
      "epoch": 1.4229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 434,
      "total_loss": 0.657705545425415
    },
    {
      "classification_loss": 0.7025576233863831,
      "epoch": 1.4262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 435,
      "total_loss": 0.7025576233863831
    },
    {
      "classification_loss": 0.6381174921989441,
      "epoch": 1.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 436,
      "total_loss": 0.6381174921989441
    },
    {
      "classification_loss": 0.6740797758102417,
      "epoch": 1.4327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 437,
      "total_loss": 0.6740797758102417
    },
    {
      "classification_loss": 0.7165680527687073,
      "epoch": 1.4360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 438,
      "total_loss": 0.7165680527687073
    },
    {
      "classification_loss": 0.6642221212387085,
      "epoch": 1.4393442622950818,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 439,
      "total_loss": 0.6642221212387085
    },
    {
      "classification_loss": 0.6284206509590149,
      "epoch": 1.4426229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 440,
      "total_loss": 0.6284206509590149
    },
    {
      "classification_loss": 0.7223174571990967,
      "epoch": 1.4459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 441,
      "total_loss": 0.7223174571990967
    },
    {
      "classification_loss": 0.6528487205505371,
      "epoch": 1.4491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 442,
      "total_loss": 0.6528487205505371
    },
    {
      "classification_loss": 0.6593498587608337,
      "epoch": 1.4524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 443,
      "total_loss": 0.6593498587608337
    },
    {
      "classification_loss": 0.7194620966911316,
      "epoch": 1.455737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 444,
      "total_loss": 0.7194620966911316
    },
    {
      "classification_loss": 0.6397531032562256,
      "epoch": 1.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 445,
      "total_loss": 0.6397531032562256
    },
    {
      "classification_loss": 0.6968640685081482,
      "epoch": 1.4622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 446,
      "total_loss": 0.6968640685081482
    },
    {
      "classification_loss": 0.6712772250175476,
      "epoch": 1.4655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 447,
      "total_loss": 0.6712772250175476
    },
    {
      "classification_loss": 0.6631370782852173,
      "epoch": 1.4688524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 448,
      "total_loss": 0.6631370782852173
    },
    {
      "classification_loss": 0.7208870053291321,
      "epoch": 1.4721311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 449,
      "total_loss": 0.7208870053291321
    },
    {
      "classification_loss": 0.6590541005134583,
      "epoch": 1.4754098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 450,
      "total_loss": 0.6590541005134583
    },
    {
      "classification_loss": 0.6917712688446045,
      "epoch": 1.478688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 451,
      "total_loss": 0.6917712688446045
    },
    {
      "classification_loss": 0.6612716317176819,
      "epoch": 1.481967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 452,
      "total_loss": 0.6612716317176819
    },
    {
      "classification_loss": 0.6466686725616455,
      "epoch": 1.4852459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 453,
      "total_loss": 0.6466686725616455
    },
    {
      "classification_loss": 0.7037209868431091,
      "epoch": 1.4885245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 454,
      "total_loss": 0.7037209868431091
    },
    {
      "classification_loss": 0.6972444653511047,
      "epoch": 1.4918032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 455,
      "total_loss": 0.6972444653511047
    },
    {
      "classification_loss": 0.6700567603111267,
      "epoch": 1.4950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 456,
      "total_loss": 0.6700567603111267
    },
    {
      "classification_loss": 0.6633701324462891,
      "epoch": 1.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 457,
      "total_loss": 0.6633701324462891
    },
    {
      "classification_loss": 0.6491206884384155,
      "epoch": 1.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 458,
      "total_loss": 0.6491206884384155
    },
    {
      "classification_loss": 0.6789048910140991,
      "epoch": 1.5049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 459,
      "total_loss": 0.6789048910140991
    },
    {
      "classification_loss": 0.6670783758163452,
      "epoch": 1.5081967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 460,
      "total_loss": 0.6670783758163452
    },
    {
      "classification_loss": 0.6931024193763733,
      "epoch": 1.5114754098360654,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 461,
      "total_loss": 0.6931024193763733
    },
    {
      "classification_loss": 0.6490392088890076,
      "epoch": 1.5147540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 462,
      "total_loss": 0.6490392088890076
    },
    {
      "classification_loss": 0.6664279699325562,
      "epoch": 1.518032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 463,
      "total_loss": 0.6664279699325562
    },
    {
      "classification_loss": 0.6806185245513916,
      "epoch": 1.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 464,
      "total_loss": 0.6806185245513916
    },
    {
      "classification_loss": 0.664716362953186,
      "epoch": 1.5245901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 465,
      "total_loss": 0.664716362953186
    },
    {
      "classification_loss": 0.698867678642273,
      "epoch": 1.5278688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 466,
      "total_loss": 0.698867678642273
    },
    {
      "classification_loss": 0.6802564859390259,
      "epoch": 1.5311475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 467,
      "total_loss": 0.6802564859390259
    },
    {
      "classification_loss": 0.6575250029563904,
      "epoch": 1.5344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 468,
      "total_loss": 0.6575250029563904
    },
    {
      "classification_loss": 0.6499452590942383,
      "epoch": 1.5377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 469,
      "total_loss": 0.6499452590942383
    },
    {
      "classification_loss": 0.6493350863456726,
      "epoch": 1.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 470,
      "total_loss": 0.6493350863456726
    },
    {
      "classification_loss": 0.6850734353065491,
      "epoch": 1.544262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 471,
      "total_loss": 0.6850734353065491
    },
    {
      "classification_loss": 0.685588538646698,
      "epoch": 1.5475409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 472,
      "total_loss": 0.685588538646698
    },
    {
      "classification_loss": 0.6741653680801392,
      "epoch": 1.5508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 473,
      "total_loss": 0.6741653680801392
    },
    {
      "classification_loss": 0.6693263649940491,
      "epoch": 1.5540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 474,
      "total_loss": 0.6693263649940491
    },
    {
      "classification_loss": 0.6361807584762573,
      "epoch": 1.5573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 475,
      "total_loss": 0.6361807584762573
    },
    {
      "classification_loss": 0.6861531734466553,
      "epoch": 1.5606557377049182,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 476,
      "total_loss": 0.6861531734466553
    },
    {
      "classification_loss": 0.6727224588394165,
      "epoch": 1.5639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 477,
      "total_loss": 0.6727224588394165
    },
    {
      "classification_loss": 0.6791217923164368,
      "epoch": 1.5672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 478,
      "total_loss": 0.6791217923164368
    },
    {
      "classification_loss": 0.6783818006515503,
      "epoch": 1.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 479,
      "total_loss": 0.6783818006515503
    },
    {
      "classification_loss": 0.6727819442749023,
      "epoch": 1.5737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 480,
      "total_loss": 0.6727819442749023
    },
    {
      "classification_loss": 0.6507512927055359,
      "epoch": 1.5770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 481,
      "total_loss": 0.6507512927055359
    },
    {
      "classification_loss": 0.6598182320594788,
      "epoch": 1.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 482,
      "total_loss": 0.6598182320594788
    },
    {
      "classification_loss": 0.7080186605453491,
      "epoch": 1.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 483,
      "total_loss": 0.7080186605453491
    },
    {
      "classification_loss": 0.6588483452796936,
      "epoch": 1.5868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 484,
      "total_loss": 0.6588483452796936
    },
    {
      "classification_loss": 0.6870830059051514,
      "epoch": 1.5901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 485,
      "total_loss": 0.6870830059051514
    },
    {
      "classification_loss": 0.6846591234207153,
      "epoch": 1.5934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 486,
      "total_loss": 0.6846591234207153
    },
    {
      "classification_loss": 0.6748862862586975,
      "epoch": 1.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 487,
      "total_loss": 0.6748862862586975
    },
    {
      "classification_loss": 0.7161657810211182,
      "epoch": 1.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 488,
      "total_loss": 0.7161657810211182
    },
    {
      "classification_loss": 0.6010173559188843,
      "epoch": 1.6032786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 489,
      "total_loss": 0.6010173559188843
    },
    {
      "classification_loss": 0.7074069380760193,
      "epoch": 1.6065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 490,
      "total_loss": 0.7074069380760193
    },
    {
      "classification_loss": 0.6102820634841919,
      "epoch": 1.6098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 491,
      "total_loss": 0.6102820634841919
    },
    {
      "classification_loss": 0.6559180021286011,
      "epoch": 1.6131147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 492,
      "total_loss": 0.6559180021286011
    },
    {
      "classification_loss": 0.6920071244239807,
      "epoch": 1.6163934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 493,
      "total_loss": 0.6920071244239807
    },
    {
      "classification_loss": 0.7153034210205078,
      "epoch": 1.6196721311475408,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 494,
      "total_loss": 0.7153034210205078
    },
    {
      "classification_loss": 0.6373955011367798,
      "epoch": 1.6229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 495,
      "total_loss": 0.6373955011367798
    },
    {
      "classification_loss": 0.7230664491653442,
      "epoch": 1.6262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 496,
      "total_loss": 0.7230664491653442
    },
    {
      "classification_loss": 0.6953338384628296,
      "epoch": 1.6295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 497,
      "total_loss": 0.6953338384628296
    },
    {
      "classification_loss": 0.7308003902435303,
      "epoch": 1.6327868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 498,
      "total_loss": 0.7308003902435303
    },
    {
      "classification_loss": 0.6706781983375549,
      "epoch": 1.6360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 499,
      "total_loss": 0.6706781983375549
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 4.780510902404785,
      "learning_rate": 0.0001867,
      "loss": 0.6746,
      "step": 500
    },
    {
      "classification_loss": 0.6798039078712463,
      "epoch": 1.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 500,
      "total_loss": 0.6798039078712463
    },
    {
      "classification_loss": 0.6738409996032715,
      "epoch": 1.6426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 501,
      "total_loss": 0.6738409996032715
    },
    {
      "classification_loss": 0.6516898274421692,
      "epoch": 1.6459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 502,
      "total_loss": 0.6516898274421692
    },
    {
      "classification_loss": 0.6703016757965088,
      "epoch": 1.6491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 503,
      "total_loss": 0.6703016757965088
    },
    {
      "classification_loss": 0.6703382134437561,
      "epoch": 1.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 504,
      "total_loss": 0.6703382134437561
    },
    {
      "classification_loss": 0.663578987121582,
      "epoch": 1.6557377049180326,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 505,
      "total_loss": 0.663578987121582
    },
    {
      "classification_loss": 0.6078974008560181,
      "epoch": 1.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 506,
      "total_loss": 0.6078974008560181
    },
    {
      "classification_loss": 0.7326939702033997,
      "epoch": 1.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 507,
      "total_loss": 0.7326939702033997
    },
    {
      "classification_loss": 0.662992537021637,
      "epoch": 1.6655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 508,
      "total_loss": 0.662992537021637
    },
    {
      "classification_loss": 0.681625247001648,
      "epoch": 1.6688524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 509,
      "total_loss": 0.681625247001648
    },
    {
      "classification_loss": 0.7295600771903992,
      "epoch": 1.6721311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 510,
      "total_loss": 0.7295600771903992
    },
    {
      "classification_loss": 0.6505188345909119,
      "epoch": 1.6754098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 511,
      "total_loss": 0.6505188345909119
    },
    {
      "classification_loss": 0.6835789084434509,
      "epoch": 1.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 512,
      "total_loss": 0.6835789084434509
    },
    {
      "classification_loss": 0.6999694108963013,
      "epoch": 1.681967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 513,
      "total_loss": 0.6999694108963013
    },
    {
      "classification_loss": 0.702979326248169,
      "epoch": 1.6852459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 514,
      "total_loss": 0.702979326248169
    },
    {
      "classification_loss": 0.6814655065536499,
      "epoch": 1.6885245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 515,
      "total_loss": 0.6814655065536499
    },
    {
      "classification_loss": 0.6421952247619629,
      "epoch": 1.6918032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 516,
      "total_loss": 0.6421952247619629
    },
    {
      "classification_loss": 0.6581999659538269,
      "epoch": 1.6950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 517,
      "total_loss": 0.6581999659538269
    },
    {
      "classification_loss": 0.6725009679794312,
      "epoch": 1.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 518,
      "total_loss": 0.6725009679794312
    },
    {
      "classification_loss": 0.6322433948516846,
      "epoch": 1.7016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 519,
      "total_loss": 0.6322433948516846
    },
    {
      "classification_loss": 0.6700465679168701,
      "epoch": 1.7049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 520,
      "total_loss": 0.6700465679168701
    },
    {
      "classification_loss": 0.6905934810638428,
      "epoch": 1.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 521,
      "total_loss": 0.6905934810638428
    },
    {
      "classification_loss": 0.7540953159332275,
      "epoch": 1.7114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 522,
      "total_loss": 0.7540953159332275
    },
    {
      "classification_loss": 0.6420707106590271,
      "epoch": 1.7147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 523,
      "total_loss": 0.6420707106590271
    },
    {
      "classification_loss": 0.5714407563209534,
      "epoch": 1.7180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 524,
      "total_loss": 0.5714407563209534
    },
    {
      "classification_loss": 0.7148767709732056,
      "epoch": 1.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 525,
      "total_loss": 0.7148767709732056
    },
    {
      "classification_loss": 0.6644479632377625,
      "epoch": 1.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 526,
      "total_loss": 0.6644479632377625
    },
    {
      "classification_loss": 0.7138468623161316,
      "epoch": 1.7278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 527,
      "total_loss": 0.7138468623161316
    },
    {
      "classification_loss": 0.6345535516738892,
      "epoch": 1.7311475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 528,
      "total_loss": 0.6345535516738892
    },
    {
      "classification_loss": 0.6038643717765808,
      "epoch": 1.7344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 529,
      "total_loss": 0.6038643717765808
    },
    {
      "classification_loss": 0.6814008951187134,
      "epoch": 1.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 530,
      "total_loss": 0.6814008951187134
    },
    {
      "classification_loss": 0.6362941265106201,
      "epoch": 1.7409836065573772,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 531,
      "total_loss": 0.6362941265106201
    },
    {
      "classification_loss": 0.7082619071006775,
      "epoch": 1.7442622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 532,
      "total_loss": 0.7082619071006775
    },
    {
      "classification_loss": 0.6938539743423462,
      "epoch": 1.7475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 533,
      "total_loss": 0.6938539743423462
    },
    {
      "classification_loss": 0.6531975865364075,
      "epoch": 1.7508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 534,
      "total_loss": 0.6531975865364075
    },
    {
      "classification_loss": 0.6834739446640015,
      "epoch": 1.7540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 535,
      "total_loss": 0.6834739446640015
    },
    {
      "classification_loss": 0.6975390315055847,
      "epoch": 1.7573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 536,
      "total_loss": 0.6975390315055847
    },
    {
      "classification_loss": 0.6900414228439331,
      "epoch": 1.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 537,
      "total_loss": 0.6900414228439331
    },
    {
      "classification_loss": 0.6336277723312378,
      "epoch": 1.7639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 538,
      "total_loss": 0.6336277723312378
    },
    {
      "classification_loss": 0.7405732274055481,
      "epoch": 1.7672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 539,
      "total_loss": 0.7405732274055481
    },
    {
      "classification_loss": 0.6851773262023926,
      "epoch": 1.7704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 540,
      "total_loss": 0.6851773262023926
    },
    {
      "classification_loss": 0.7003178596496582,
      "epoch": 1.7737704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 541,
      "total_loss": 0.7003178596496582
    },
    {
      "classification_loss": 0.6997108459472656,
      "epoch": 1.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 542,
      "total_loss": 0.6997108459472656
    },
    {
      "classification_loss": 0.6415879726409912,
      "epoch": 1.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 543,
      "total_loss": 0.6415879726409912
    },
    {
      "classification_loss": 0.6660112738609314,
      "epoch": 1.7836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 544,
      "total_loss": 0.6660112738609314
    },
    {
      "classification_loss": 0.6419232487678528,
      "epoch": 1.7868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 545,
      "total_loss": 0.6419232487678528
    },
    {
      "classification_loss": 0.6708616614341736,
      "epoch": 1.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 546,
      "total_loss": 0.6708616614341736
    },
    {
      "classification_loss": 0.6144054532051086,
      "epoch": 1.7934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 547,
      "total_loss": 0.6144054532051086
    },
    {
      "classification_loss": 0.6643661856651306,
      "epoch": 1.7967213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 548,
      "total_loss": 0.6643661856651306
    },
    {
      "classification_loss": 0.6591456532478333,
      "epoch": 1.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 549,
      "total_loss": 0.6591456532478333
    },
    {
      "classification_loss": 0.6356680393218994,
      "epoch": 1.8032786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 550,
      "total_loss": 0.6356680393218994
    },
    {
      "classification_loss": 0.6776261329650879,
      "epoch": 1.8065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 551,
      "total_loss": 0.6776261329650879
    },
    {
      "classification_loss": 0.665436863899231,
      "epoch": 1.8098360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 552,
      "total_loss": 0.665436863899231
    },
    {
      "classification_loss": 0.6696509718894958,
      "epoch": 1.8131147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 553,
      "total_loss": 0.6696509718894958
    },
    {
      "classification_loss": 0.7067769765853882,
      "epoch": 1.8163934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 554,
      "total_loss": 0.7067769765853882
    },
    {
      "classification_loss": 0.6365448236465454,
      "epoch": 1.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 555,
      "total_loss": 0.6365448236465454
    },
    {
      "classification_loss": 0.670056939125061,
      "epoch": 1.8229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 556,
      "total_loss": 0.670056939125061
    },
    {
      "classification_loss": 0.6689658761024475,
      "epoch": 1.8262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 557,
      "total_loss": 0.6689658761024475
    },
    {
      "classification_loss": 0.6404631733894348,
      "epoch": 1.8295081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 558,
      "total_loss": 0.6404631733894348
    },
    {
      "classification_loss": 0.6449511647224426,
      "epoch": 1.8327868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 559,
      "total_loss": 0.6449511647224426
    },
    {
      "classification_loss": 0.6766822338104248,
      "epoch": 1.8360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 560,
      "total_loss": 0.6766822338104248
    },
    {
      "classification_loss": 0.6835570931434631,
      "epoch": 1.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 561,
      "total_loss": 0.6835570931434631
    },
    {
      "classification_loss": 0.7257384657859802,
      "epoch": 1.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 562,
      "total_loss": 0.7257384657859802
    },
    {
      "classification_loss": 0.6392423510551453,
      "epoch": 1.8459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 563,
      "total_loss": 0.6392423510551453
    },
    {
      "classification_loss": 0.632548987865448,
      "epoch": 1.8491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 564,
      "total_loss": 0.632548987865448
    },
    {
      "classification_loss": 0.6389024257659912,
      "epoch": 1.8524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 565,
      "total_loss": 0.6389024257659912
    },
    {
      "classification_loss": 0.6338834166526794,
      "epoch": 1.8557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 566,
      "total_loss": 0.6338834166526794
    },
    {
      "classification_loss": 0.6967529058456421,
      "epoch": 1.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 567,
      "total_loss": 0.6967529058456421
    },
    {
      "classification_loss": 0.6266933679580688,
      "epoch": 1.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 568,
      "total_loss": 0.6266933679580688
    },
    {
      "classification_loss": 0.6823803186416626,
      "epoch": 1.8655737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 569,
      "total_loss": 0.6823803186416626
    },
    {
      "classification_loss": 0.6547815203666687,
      "epoch": 1.8688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 570,
      "total_loss": 0.6547815203666687
    },
    {
      "classification_loss": 0.7114624977111816,
      "epoch": 1.8721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 571,
      "total_loss": 0.7114624977111816
    },
    {
      "classification_loss": 0.6536729335784912,
      "epoch": 1.8754098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 572,
      "total_loss": 0.6536729335784912
    },
    {
      "classification_loss": 0.6964762210845947,
      "epoch": 1.8786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 573,
      "total_loss": 0.6964762210845947
    },
    {
      "classification_loss": 0.6321980357170105,
      "epoch": 1.8819672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 574,
      "total_loss": 0.6321980357170105
    },
    {
      "classification_loss": 0.6329523921012878,
      "epoch": 1.8852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 575,
      "total_loss": 0.6329523921012878
    },
    {
      "classification_loss": 0.6911779642105103,
      "epoch": 1.8885245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 576,
      "total_loss": 0.6911779642105103
    },
    {
      "classification_loss": 0.7042400240898132,
      "epoch": 1.8918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 577,
      "total_loss": 0.7042400240898132
    },
    {
      "classification_loss": 0.620142936706543,
      "epoch": 1.8950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 578,
      "total_loss": 0.620142936706543
    },
    {
      "classification_loss": 0.6199340224266052,
      "epoch": 1.8983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 579,
      "total_loss": 0.6199340224266052
    },
    {
      "classification_loss": 0.6962715983390808,
      "epoch": 1.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 580,
      "total_loss": 0.6962715983390808
    },
    {
      "classification_loss": 0.6757364273071289,
      "epoch": 1.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 581,
      "total_loss": 0.6757364273071289
    },
    {
      "classification_loss": 0.6484354734420776,
      "epoch": 1.9081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 582,
      "total_loss": 0.6484354734420776
    },
    {
      "classification_loss": 0.6717698574066162,
      "epoch": 1.9114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 583,
      "total_loss": 0.6717698574066162
    },
    {
      "classification_loss": 0.6871111989021301,
      "epoch": 1.9147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 584,
      "total_loss": 0.6871111989021301
    },
    {
      "classification_loss": 0.6578736901283264,
      "epoch": 1.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 585,
      "total_loss": 0.6578736901283264
    },
    {
      "classification_loss": 0.6707973480224609,
      "epoch": 1.9213114754098362,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 586,
      "total_loss": 0.6707973480224609
    },
    {
      "classification_loss": 0.6894813179969788,
      "epoch": 1.9245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 587,
      "total_loss": 0.6894813179969788
    },
    {
      "classification_loss": 0.6331295371055603,
      "epoch": 1.9278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 588,
      "total_loss": 0.6331295371055603
    },
    {
      "classification_loss": 0.6556650996208191,
      "epoch": 1.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 589,
      "total_loss": 0.6556650996208191
    },
    {
      "classification_loss": 0.6872742772102356,
      "epoch": 1.9344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 590,
      "total_loss": 0.6872742772102356
    },
    {
      "classification_loss": 0.6499640345573425,
      "epoch": 1.9377049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 591,
      "total_loss": 0.6499640345573425
    },
    {
      "classification_loss": 0.613507091999054,
      "epoch": 1.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 592,
      "total_loss": 0.613507091999054
    },
    {
      "classification_loss": 0.6725738048553467,
      "epoch": 1.9442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 593,
      "total_loss": 0.6725738048553467
    },
    {
      "classification_loss": 0.7270599603652954,
      "epoch": 1.9475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 594,
      "total_loss": 0.7270599603652954
    },
    {
      "classification_loss": 0.6765421032905579,
      "epoch": 1.9508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 595,
      "total_loss": 0.6765421032905579
    },
    {
      "classification_loss": 0.6274402737617493,
      "epoch": 1.9540983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 596,
      "total_loss": 0.6274402737617493
    },
    {
      "classification_loss": 0.6870592832565308,
      "epoch": 1.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 597,
      "total_loss": 0.6870592832565308
    },
    {
      "classification_loss": 0.671206533908844,
      "epoch": 1.960655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 598,
      "total_loss": 0.671206533908844
    },
    {
      "classification_loss": 0.6408132314682007,
      "epoch": 1.9639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 599,
      "total_loss": 0.6408132314682007
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 2.5866174697875977,
      "learning_rate": 0.00018336666666666666,
      "loss": 0.6678,
      "step": 600
    },
    {
      "classification_loss": 0.6467112898826599,
      "epoch": 1.9672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 600,
      "total_loss": 0.6467112898826599
    },
    {
      "classification_loss": 0.6963127255439758,
      "epoch": 1.9704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 601,
      "total_loss": 0.6963127255439758
    },
    {
      "classification_loss": 0.6747451424598694,
      "epoch": 1.9737704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 602,
      "total_loss": 0.6747451424598694
    },
    {
      "classification_loss": 0.6750808358192444,
      "epoch": 1.9770491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 603,
      "total_loss": 0.6750808358192444
    },
    {
      "classification_loss": 0.6371378302574158,
      "epoch": 1.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 604,
      "total_loss": 0.6371378302574158
    },
    {
      "classification_loss": 0.6340317726135254,
      "epoch": 1.9836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 605,
      "total_loss": 0.6340317726135254
    },
    {
      "classification_loss": 0.6922329664230347,
      "epoch": 1.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 606,
      "total_loss": 0.6922329664230347
    },
    {
      "classification_loss": 0.6333170533180237,
      "epoch": 1.9901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 607,
      "total_loss": 0.6333170533180237
    },
    {
      "classification_loss": 0.6631103754043579,
      "epoch": 1.9934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 608,
      "total_loss": 0.6631103754043579
    },
    {
      "classification_loss": 0.7463656067848206,
      "epoch": 1.9967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 609,
      "total_loss": 0.7463656067848206
    },
    {
      "classification_loss": 0.7521437406539917,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7521437406539917
    },
    {
      "classification_loss": 0.7435628771781921,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7435628771781921
    },
    {
      "classification_loss": 0.741253674030304,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.741253674030304
    },
    {
      "classification_loss": 0.763762354850769,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.763762354850769
    },
    {
      "classification_loss": 0.7267618775367737,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7267618775367737
    },
    {
      "classification_loss": 0.7344383001327515,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7344383001327515
    },
    {
      "classification_loss": 0.7400405406951904,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7400405406951904
    },
    {
      "classification_loss": 0.7122156620025635,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.7122156620025635
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.389,
      "eval_f1": 0.1027900146842878,
      "eval_loss": 0.7399217486381531,
      "eval_precision": 0.6862745098039216,
      "eval_recall": 0.05555555555555555,
      "eval_runtime": 5.9904,
      "eval_samples_per_second": 166.935,
      "eval_steps_per_second": 1.335,
      "step": 610
    },
    {
      "classification_loss": 0.6520331501960754,
      "epoch": 2.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 610,
      "total_loss": 0.6520331501960754
    },
    {
      "classification_loss": 0.6423784494400024,
      "epoch": 2.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 611,
      "total_loss": 0.6423784494400024
    },
    {
      "classification_loss": 0.6053074598312378,
      "epoch": 2.0065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 612,
      "total_loss": 0.6053074598312378
    },
    {
      "classification_loss": 0.5889111161231995,
      "epoch": 2.0098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 613,
      "total_loss": 0.5889111161231995
    },
    {
      "classification_loss": 0.6307178735733032,
      "epoch": 2.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 614,
      "total_loss": 0.6307178735733032
    },
    {
      "classification_loss": 0.7059490084648132,
      "epoch": 2.0163934426229506,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 615,
      "total_loss": 0.7059490084648132
    },
    {
      "classification_loss": 0.6091319918632507,
      "epoch": 2.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 616,
      "total_loss": 0.6091319918632507
    },
    {
      "classification_loss": 0.6122727990150452,
      "epoch": 2.0229508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 617,
      "total_loss": 0.6122727990150452
    },
    {
      "classification_loss": 0.6368649005889893,
      "epoch": 2.0262295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 618,
      "total_loss": 0.6368649005889893
    },
    {
      "classification_loss": 0.664544403553009,
      "epoch": 2.0295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 619,
      "total_loss": 0.664544403553009
    },
    {
      "classification_loss": 0.6196258664131165,
      "epoch": 2.0327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 620,
      "total_loss": 0.6196258664131165
    },
    {
      "classification_loss": 0.7017029523849487,
      "epoch": 2.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 621,
      "total_loss": 0.7017029523849487
    },
    {
      "classification_loss": 0.6405217051506042,
      "epoch": 2.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 622,
      "total_loss": 0.6405217051506042
    },
    {
      "classification_loss": 0.5752021074295044,
      "epoch": 2.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 623,
      "total_loss": 0.5752021074295044
    },
    {
      "classification_loss": 0.6312670111656189,
      "epoch": 2.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 624,
      "total_loss": 0.6312670111656189
    },
    {
      "classification_loss": 0.6342020630836487,
      "epoch": 2.0491803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 625,
      "total_loss": 0.6342020630836487
    },
    {
      "classification_loss": 0.6810859441757202,
      "epoch": 2.0524590163934424,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 626,
      "total_loss": 0.6810859441757202
    },
    {
      "classification_loss": 0.6694324016571045,
      "epoch": 2.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 627,
      "total_loss": 0.6694324016571045
    },
    {
      "classification_loss": 0.5900853872299194,
      "epoch": 2.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 628,
      "total_loss": 0.5900853872299194
    },
    {
      "classification_loss": 0.6419001817703247,
      "epoch": 2.0622950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 629,
      "total_loss": 0.6419001817703247
    },
    {
      "classification_loss": 0.6685182452201843,
      "epoch": 2.0655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 630,
      "total_loss": 0.6685182452201843
    },
    {
      "classification_loss": 0.6527522802352905,
      "epoch": 2.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 631,
      "total_loss": 0.6527522802352905
    },
    {
      "classification_loss": 0.6275098919868469,
      "epoch": 2.0721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 632,
      "total_loss": 0.6275098919868469
    },
    {
      "classification_loss": 0.6363979578018188,
      "epoch": 2.0754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 633,
      "total_loss": 0.6363979578018188
    },
    {
      "classification_loss": 0.6989892721176147,
      "epoch": 2.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 634,
      "total_loss": 0.6989892721176147
    },
    {
      "classification_loss": 0.6662885546684265,
      "epoch": 2.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 635,
      "total_loss": 0.6662885546684265
    },
    {
      "classification_loss": 0.6186323165893555,
      "epoch": 2.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 636,
      "total_loss": 0.6186323165893555
    },
    {
      "classification_loss": 0.681086003780365,
      "epoch": 2.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 637,
      "total_loss": 0.681086003780365
    },
    {
      "classification_loss": 0.5973480343818665,
      "epoch": 2.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 638,
      "total_loss": 0.5973480343818665
    },
    {
      "classification_loss": 0.6127945780754089,
      "epoch": 2.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 639,
      "total_loss": 0.6127945780754089
    },
    {
      "classification_loss": 0.6166046857833862,
      "epoch": 2.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 640,
      "total_loss": 0.6166046857833862
    },
    {
      "classification_loss": 0.7296397089958191,
      "epoch": 2.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 641,
      "total_loss": 0.7296397089958191
    },
    {
      "classification_loss": 0.6046603322029114,
      "epoch": 2.1049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 642,
      "total_loss": 0.6046603322029114
    },
    {
      "classification_loss": 0.6351684331893921,
      "epoch": 2.1081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 643,
      "total_loss": 0.6351684331893921
    },
    {
      "classification_loss": 0.6777194738388062,
      "epoch": 2.1114754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 644,
      "total_loss": 0.6777194738388062
    },
    {
      "classification_loss": 0.608546793460846,
      "epoch": 2.1147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 645,
      "total_loss": 0.608546793460846
    },
    {
      "classification_loss": 0.5731123089790344,
      "epoch": 2.1180327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 646,
      "total_loss": 0.5731123089790344
    },
    {
      "classification_loss": 0.6157625913619995,
      "epoch": 2.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 647,
      "total_loss": 0.6157625913619995
    },
    {
      "classification_loss": 0.6742538809776306,
      "epoch": 2.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 648,
      "total_loss": 0.6742538809776306
    },
    {
      "classification_loss": 0.5543784499168396,
      "epoch": 2.1278688524590166,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 649,
      "total_loss": 0.5543784499168396
    },
    {
      "classification_loss": 0.6416159272193909,
      "epoch": 2.1311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 650,
      "total_loss": 0.6416159272193909
    },
    {
      "classification_loss": 0.6636183857917786,
      "epoch": 2.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 651,
      "total_loss": 0.6636183857917786
    },
    {
      "classification_loss": 0.7281912565231323,
      "epoch": 2.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 652,
      "total_loss": 0.7281912565231323
    },
    {
      "classification_loss": 0.6609664559364319,
      "epoch": 2.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 653,
      "total_loss": 0.6609664559364319
    },
    {
      "classification_loss": 0.7208912372589111,
      "epoch": 2.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 654,
      "total_loss": 0.7208912372589111
    },
    {
      "classification_loss": 0.6357686519622803,
      "epoch": 2.1475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 655,
      "total_loss": 0.6357686519622803
    },
    {
      "classification_loss": 0.6465966105461121,
      "epoch": 2.1508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 656,
      "total_loss": 0.6465966105461121
    },
    {
      "classification_loss": 0.6632183790206909,
      "epoch": 2.1540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 657,
      "total_loss": 0.6632183790206909
    },
    {
      "classification_loss": 0.7014584541320801,
      "epoch": 2.1573770491803277,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 658,
      "total_loss": 0.7014584541320801
    },
    {
      "classification_loss": 0.6379348635673523,
      "epoch": 2.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 659,
      "total_loss": 0.6379348635673523
    },
    {
      "classification_loss": 0.6287696957588196,
      "epoch": 2.1639344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 660,
      "total_loss": 0.6287696957588196
    },
    {
      "classification_loss": 0.6621063947677612,
      "epoch": 2.1672131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 661,
      "total_loss": 0.6621063947677612
    },
    {
      "classification_loss": 0.6251619458198547,
      "epoch": 2.1704918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 662,
      "total_loss": 0.6251619458198547
    },
    {
      "classification_loss": 0.5917546153068542,
      "epoch": 2.1737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 663,
      "total_loss": 0.5917546153068542
    },
    {
      "classification_loss": 0.6364070177078247,
      "epoch": 2.177049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 664,
      "total_loss": 0.6364070177078247
    },
    {
      "classification_loss": 0.6229299306869507,
      "epoch": 2.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 665,
      "total_loss": 0.6229299306869507
    },
    {
      "classification_loss": 0.603290319442749,
      "epoch": 2.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 666,
      "total_loss": 0.603290319442749
    },
    {
      "classification_loss": 0.6712124347686768,
      "epoch": 2.1868852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 667,
      "total_loss": 0.6712124347686768
    },
    {
      "classification_loss": 0.6622190475463867,
      "epoch": 2.1901639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 668,
      "total_loss": 0.6622190475463867
    },
    {
      "classification_loss": 0.6293405294418335,
      "epoch": 2.1934426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 669,
      "total_loss": 0.6293405294418335
    },
    {
      "classification_loss": 0.6544433832168579,
      "epoch": 2.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 670,
      "total_loss": 0.6544433832168579
    },
    {
      "classification_loss": 0.6557403206825256,
      "epoch": 2.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 671,
      "total_loss": 0.6557403206825256
    },
    {
      "classification_loss": 0.6503519415855408,
      "epoch": 2.2032786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 672,
      "total_loss": 0.6503519415855408
    },
    {
      "classification_loss": 0.6752119660377502,
      "epoch": 2.2065573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 673,
      "total_loss": 0.6752119660377502
    },
    {
      "classification_loss": 0.6439279913902283,
      "epoch": 2.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 674,
      "total_loss": 0.6439279913902283
    },
    {
      "classification_loss": 0.6061301827430725,
      "epoch": 2.2131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 675,
      "total_loss": 0.6061301827430725
    },
    {
      "classification_loss": 0.6402472257614136,
      "epoch": 2.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 676,
      "total_loss": 0.6402472257614136
    },
    {
      "classification_loss": 0.6655811667442322,
      "epoch": 2.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 677,
      "total_loss": 0.6655811667442322
    },
    {
      "classification_loss": 0.6362366676330566,
      "epoch": 2.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 678,
      "total_loss": 0.6362366676330566
    },
    {
      "classification_loss": 0.6889700293540955,
      "epoch": 2.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 679,
      "total_loss": 0.6889700293540955
    },
    {
      "classification_loss": 0.6633920073509216,
      "epoch": 2.2295081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 680,
      "total_loss": 0.6633920073509216
    },
    {
      "classification_loss": 0.6790302991867065,
      "epoch": 2.2327868852459014,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 681,
      "total_loss": 0.6790302991867065
    },
    {
      "classification_loss": 0.6755275726318359,
      "epoch": 2.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 682,
      "total_loss": 0.6755275726318359
    },
    {
      "classification_loss": 0.6033339500427246,
      "epoch": 2.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 683,
      "total_loss": 0.6033339500427246
    },
    {
      "classification_loss": 0.6290706992149353,
      "epoch": 2.2426229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 684,
      "total_loss": 0.6290706992149353
    },
    {
      "classification_loss": 0.6768598556518555,
      "epoch": 2.2459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 685,
      "total_loss": 0.6768598556518555
    },
    {
      "classification_loss": 0.7705265283584595,
      "epoch": 2.2491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 686,
      "total_loss": 0.7705265283584595
    },
    {
      "classification_loss": 0.7038679718971252,
      "epoch": 2.2524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 687,
      "total_loss": 0.7038679718971252
    },
    {
      "classification_loss": 0.6418219804763794,
      "epoch": 2.2557377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 688,
      "total_loss": 0.6418219804763794
    },
    {
      "classification_loss": 0.6359134316444397,
      "epoch": 2.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 689,
      "total_loss": 0.6359134316444397
    },
    {
      "classification_loss": 0.7144468426704407,
      "epoch": 2.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 690,
      "total_loss": 0.7144468426704407
    },
    {
      "classification_loss": 0.6699197292327881,
      "epoch": 2.265573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 691,
      "total_loss": 0.6699197292327881
    },
    {
      "classification_loss": 0.6238967180252075,
      "epoch": 2.2688524590163937,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 692,
      "total_loss": 0.6238967180252075
    },
    {
      "classification_loss": 0.6489255428314209,
      "epoch": 2.2721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 693,
      "total_loss": 0.6489255428314209
    },
    {
      "classification_loss": 0.6157221794128418,
      "epoch": 2.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 694,
      "total_loss": 0.6157221794128418
    },
    {
      "classification_loss": 0.6476417183876038,
      "epoch": 2.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 695,
      "total_loss": 0.6476417183876038
    },
    {
      "classification_loss": 0.6163961887359619,
      "epoch": 2.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 696,
      "total_loss": 0.6163961887359619
    },
    {
      "classification_loss": 0.6184711456298828,
      "epoch": 2.2852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 697,
      "total_loss": 0.6184711456298828
    },
    {
      "classification_loss": 0.7043271064758301,
      "epoch": 2.2885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 698,
      "total_loss": 0.7043271064758301
    },
    {
      "classification_loss": 0.6633787155151367,
      "epoch": 2.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 699,
      "total_loss": 0.6633787155151367
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 5.344283103942871,
      "learning_rate": 0.00018003333333333334,
      "loss": 0.6494,
      "step": 700
    },
    {
      "classification_loss": 0.6015912294387817,
      "epoch": 2.2950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 700,
      "total_loss": 0.6015912294387817
    },
    {
      "classification_loss": 0.6313098669052124,
      "epoch": 2.2983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 701,
      "total_loss": 0.6313098669052124
    },
    {
      "classification_loss": 0.6559452414512634,
      "epoch": 2.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 702,
      "total_loss": 0.6559452414512634
    },
    {
      "classification_loss": 0.6160898804664612,
      "epoch": 2.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 703,
      "total_loss": 0.6160898804664612
    },
    {
      "classification_loss": 0.6739492416381836,
      "epoch": 2.3081967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 704,
      "total_loss": 0.6739492416381836
    },
    {
      "classification_loss": 0.6791262030601501,
      "epoch": 2.3114754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 705,
      "total_loss": 0.6791262030601501
    },
    {
      "classification_loss": 0.6436153650283813,
      "epoch": 2.314754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 706,
      "total_loss": 0.6436153650283813
    },
    {
      "classification_loss": 0.636262834072113,
      "epoch": 2.318032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 707,
      "total_loss": 0.636262834072113
    },
    {
      "classification_loss": 0.6206358075141907,
      "epoch": 2.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 708,
      "total_loss": 0.6206358075141907
    },
    {
      "classification_loss": 0.6354017853736877,
      "epoch": 2.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 709,
      "total_loss": 0.6354017853736877
    },
    {
      "classification_loss": 0.6266064047813416,
      "epoch": 2.3278688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 710,
      "total_loss": 0.6266064047813416
    },
    {
      "classification_loss": 0.6030377745628357,
      "epoch": 2.3311475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 711,
      "total_loss": 0.6030377745628357
    },
    {
      "classification_loss": 0.7067434787750244,
      "epoch": 2.3344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 712,
      "total_loss": 0.7067434787750244
    },
    {
      "classification_loss": 0.653399646282196,
      "epoch": 2.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 713,
      "total_loss": 0.653399646282196
    },
    {
      "classification_loss": 0.6295281648635864,
      "epoch": 2.3409836065573773,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 714,
      "total_loss": 0.6295281648635864
    },
    {
      "classification_loss": 0.5760452151298523,
      "epoch": 2.3442622950819674,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 715,
      "total_loss": 0.5760452151298523
    },
    {
      "classification_loss": 0.6848753690719604,
      "epoch": 2.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 716,
      "total_loss": 0.6848753690719604
    },
    {
      "classification_loss": 0.6319652199745178,
      "epoch": 2.3508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 717,
      "total_loss": 0.6319652199745178
    },
    {
      "classification_loss": 0.6993268728256226,
      "epoch": 2.3540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 718,
      "total_loss": 0.6993268728256226
    },
    {
      "classification_loss": 0.6004312038421631,
      "epoch": 2.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 719,
      "total_loss": 0.6004312038421631
    },
    {
      "classification_loss": 0.6745848655700684,
      "epoch": 2.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 720,
      "total_loss": 0.6745848655700684
    },
    {
      "classification_loss": 0.6830859780311584,
      "epoch": 2.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 721,
      "total_loss": 0.6830859780311584
    },
    {
      "classification_loss": 0.5681923627853394,
      "epoch": 2.3672131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 722,
      "total_loss": 0.5681923627853394
    },
    {
      "classification_loss": 0.6823729872703552,
      "epoch": 2.3704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 723,
      "total_loss": 0.6823729872703552
    },
    {
      "classification_loss": 0.6283948421478271,
      "epoch": 2.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 724,
      "total_loss": 0.6283948421478271
    },
    {
      "classification_loss": 0.605022668838501,
      "epoch": 2.3770491803278686,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 725,
      "total_loss": 0.605022668838501
    },
    {
      "classification_loss": 0.6485809683799744,
      "epoch": 2.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 726,
      "total_loss": 0.6485809683799744
    },
    {
      "classification_loss": 0.673221230506897,
      "epoch": 2.3836065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 727,
      "total_loss": 0.673221230506897
    },
    {
      "classification_loss": 0.6369732618331909,
      "epoch": 2.3868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 728,
      "total_loss": 0.6369732618331909
    },
    {
      "classification_loss": 0.6934646368026733,
      "epoch": 2.3901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 729,
      "total_loss": 0.6934646368026733
    },
    {
      "classification_loss": 0.6480852961540222,
      "epoch": 2.3934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 730,
      "total_loss": 0.6480852961540222
    },
    {
      "classification_loss": 0.6743218898773193,
      "epoch": 2.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 731,
      "total_loss": 0.6743218898773193
    },
    {
      "classification_loss": 0.6566219329833984,
      "epoch": 2.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 732,
      "total_loss": 0.6566219329833984
    },
    {
      "classification_loss": 0.5913503766059875,
      "epoch": 2.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 733,
      "total_loss": 0.5913503766059875
    },
    {
      "classification_loss": 0.6156702637672424,
      "epoch": 2.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 734,
      "total_loss": 0.6156702637672424
    },
    {
      "classification_loss": 0.7036681771278381,
      "epoch": 2.4098360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 735,
      "total_loss": 0.7036681771278381
    },
    {
      "classification_loss": 0.6936730742454529,
      "epoch": 2.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 736,
      "total_loss": 0.6936730742454529
    },
    {
      "classification_loss": 0.6418623924255371,
      "epoch": 2.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 737,
      "total_loss": 0.6418623924255371
    },
    {
      "classification_loss": 0.6957152485847473,
      "epoch": 2.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 738,
      "total_loss": 0.6957152485847473
    },
    {
      "classification_loss": 0.6273118853569031,
      "epoch": 2.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 739,
      "total_loss": 0.6273118853569031
    },
    {
      "classification_loss": 0.6374371647834778,
      "epoch": 2.4262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 740,
      "total_loss": 0.6374371647834778
    },
    {
      "classification_loss": 0.6537522673606873,
      "epoch": 2.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 741,
      "total_loss": 0.6537522673606873
    },
    {
      "classification_loss": 0.5974616408348083,
      "epoch": 2.4327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 742,
      "total_loss": 0.5974616408348083
    },
    {
      "classification_loss": 0.6037794351577759,
      "epoch": 2.4360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 743,
      "total_loss": 0.6037794351577759
    },
    {
      "classification_loss": 0.6868628263473511,
      "epoch": 2.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 744,
      "total_loss": 0.6868628263473511
    },
    {
      "classification_loss": 0.6581462621688843,
      "epoch": 2.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 745,
      "total_loss": 0.6581462621688843
    },
    {
      "classification_loss": 0.6530681252479553,
      "epoch": 2.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 746,
      "total_loss": 0.6530681252479553
    },
    {
      "classification_loss": 0.642918586730957,
      "epoch": 2.4491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 747,
      "total_loss": 0.642918586730957
    },
    {
      "classification_loss": 0.6546857357025146,
      "epoch": 2.4524590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 748,
      "total_loss": 0.6546857357025146
    },
    {
      "classification_loss": 0.6840333938598633,
      "epoch": 2.455737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 749,
      "total_loss": 0.6840333938598633
    },
    {
      "classification_loss": 0.6529117822647095,
      "epoch": 2.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 750,
      "total_loss": 0.6529117822647095
    },
    {
      "classification_loss": 0.6581474542617798,
      "epoch": 2.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 751,
      "total_loss": 0.6581474542617798
    },
    {
      "classification_loss": 0.6244432330131531,
      "epoch": 2.4655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 752,
      "total_loss": 0.6244432330131531
    },
    {
      "classification_loss": 0.6419389247894287,
      "epoch": 2.4688524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 753,
      "total_loss": 0.6419389247894287
    },
    {
      "classification_loss": 0.6826913356781006,
      "epoch": 2.4721311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 754,
      "total_loss": 0.6826913356781006
    },
    {
      "classification_loss": 0.6254174709320068,
      "epoch": 2.4754098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 755,
      "total_loss": 0.6254174709320068
    },
    {
      "classification_loss": 0.6638511419296265,
      "epoch": 2.4786885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 756,
      "total_loss": 0.6638511419296265
    },
    {
      "classification_loss": 0.642062783241272,
      "epoch": 2.4819672131147543,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 757,
      "total_loss": 0.642062783241272
    },
    {
      "classification_loss": 0.6375603675842285,
      "epoch": 2.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 758,
      "total_loss": 0.6375603675842285
    },
    {
      "classification_loss": 0.644275426864624,
      "epoch": 2.4885245901639346,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 759,
      "total_loss": 0.644275426864624
    },
    {
      "classification_loss": 0.6752374172210693,
      "epoch": 2.4918032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 760,
      "total_loss": 0.6752374172210693
    },
    {
      "classification_loss": 0.6247467398643494,
      "epoch": 2.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 761,
      "total_loss": 0.6247467398643494
    },
    {
      "classification_loss": 0.6735555529594421,
      "epoch": 2.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 762,
      "total_loss": 0.6735555529594421
    },
    {
      "classification_loss": 0.6276712417602539,
      "epoch": 2.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 763,
      "total_loss": 0.6276712417602539
    },
    {
      "classification_loss": 0.6891867518424988,
      "epoch": 2.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 764,
      "total_loss": 0.6891867518424988
    },
    {
      "classification_loss": 0.7071112990379333,
      "epoch": 2.5081967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 765,
      "total_loss": 0.7071112990379333
    },
    {
      "classification_loss": 0.6198432445526123,
      "epoch": 2.5114754098360654,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 766,
      "total_loss": 0.6198432445526123
    },
    {
      "classification_loss": 0.647577702999115,
      "epoch": 2.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 767,
      "total_loss": 0.647577702999115
    },
    {
      "classification_loss": 0.6843294501304626,
      "epoch": 2.5180327868852457,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 768,
      "total_loss": 0.6843294501304626
    },
    {
      "classification_loss": 0.6392567157745361,
      "epoch": 2.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 769,
      "total_loss": 0.6392567157745361
    },
    {
      "classification_loss": 0.6806952953338623,
      "epoch": 2.5245901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 770,
      "total_loss": 0.6806952953338623
    },
    {
      "classification_loss": 0.5686100125312805,
      "epoch": 2.5278688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 771,
      "total_loss": 0.5686100125312805
    },
    {
      "classification_loss": 0.6038901805877686,
      "epoch": 2.5311475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 772,
      "total_loss": 0.6038901805877686
    },
    {
      "classification_loss": 0.6205811500549316,
      "epoch": 2.5344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 773,
      "total_loss": 0.6205811500549316
    },
    {
      "classification_loss": 0.5908520221710205,
      "epoch": 2.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 774,
      "total_loss": 0.5908520221710205
    },
    {
      "classification_loss": 0.6034255623817444,
      "epoch": 2.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 775,
      "total_loss": 0.6034255623817444
    },
    {
      "classification_loss": 0.648836076259613,
      "epoch": 2.544262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 776,
      "total_loss": 0.648836076259613
    },
    {
      "classification_loss": 0.7126756310462952,
      "epoch": 2.5475409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 777,
      "total_loss": 0.7126756310462952
    },
    {
      "classification_loss": 0.6650545001029968,
      "epoch": 2.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 778,
      "total_loss": 0.6650545001029968
    },
    {
      "classification_loss": 0.6158191561698914,
      "epoch": 2.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 779,
      "total_loss": 0.6158191561698914
    },
    {
      "classification_loss": 0.6380303502082825,
      "epoch": 2.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 780,
      "total_loss": 0.6380303502082825
    },
    {
      "classification_loss": 0.6430254578590393,
      "epoch": 2.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 781,
      "total_loss": 0.6430254578590393
    },
    {
      "classification_loss": 0.7424637675285339,
      "epoch": 2.5639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 782,
      "total_loss": 0.7424637675285339
    },
    {
      "classification_loss": 0.6411867737770081,
      "epoch": 2.5672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 783,
      "total_loss": 0.6411867737770081
    },
    {
      "classification_loss": 0.6482566595077515,
      "epoch": 2.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 784,
      "total_loss": 0.6482566595077515
    },
    {
      "classification_loss": 0.6574856042861938,
      "epoch": 2.5737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 785,
      "total_loss": 0.6574856042861938
    },
    {
      "classification_loss": 0.6309465169906616,
      "epoch": 2.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 786,
      "total_loss": 0.6309465169906616
    },
    {
      "classification_loss": 0.6034931540489197,
      "epoch": 2.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 787,
      "total_loss": 0.6034931540489197
    },
    {
      "classification_loss": 0.6567918658256531,
      "epoch": 2.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 788,
      "total_loss": 0.6567918658256531
    },
    {
      "classification_loss": 0.6430277824401855,
      "epoch": 2.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 789,
      "total_loss": 0.6430277824401855
    },
    {
      "classification_loss": 0.6831601858139038,
      "epoch": 2.5901639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 790,
      "total_loss": 0.6831601858139038
    },
    {
      "classification_loss": 0.644782304763794,
      "epoch": 2.5934426229508194,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 791,
      "total_loss": 0.644782304763794
    },
    {
      "classification_loss": 0.6441203355789185,
      "epoch": 2.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 792,
      "total_loss": 0.6441203355789185
    },
    {
      "classification_loss": 0.5802457332611084,
      "epoch": 2.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 793,
      "total_loss": 0.5802457332611084
    },
    {
      "classification_loss": 0.6385731101036072,
      "epoch": 2.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 794,
      "total_loss": 0.6385731101036072
    },
    {
      "classification_loss": 0.5878680348396301,
      "epoch": 2.6065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 795,
      "total_loss": 0.5878680348396301
    },
    {
      "classification_loss": 0.5290157198905945,
      "epoch": 2.6098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 796,
      "total_loss": 0.5290157198905945
    },
    {
      "classification_loss": 0.609389066696167,
      "epoch": 2.6131147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 797,
      "total_loss": 0.609389066696167
    },
    {
      "classification_loss": 0.7104659080505371,
      "epoch": 2.6163934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 798,
      "total_loss": 0.7104659080505371
    },
    {
      "classification_loss": 0.5846385955810547,
      "epoch": 2.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 799,
      "total_loss": 0.5846385955810547
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 1.482114553451538,
      "learning_rate": 0.00017669999999999999,
      "loss": 0.6441,
      "step": 800
    },
    {
      "classification_loss": 0.6165276765823364,
      "epoch": 2.6229508196721314,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 800,
      "total_loss": 0.6165276765823364
    },
    {
      "classification_loss": 0.6798444986343384,
      "epoch": 2.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 801,
      "total_loss": 0.6798444986343384
    },
    {
      "classification_loss": 0.671801745891571,
      "epoch": 2.6295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 802,
      "total_loss": 0.671801745891571
    },
    {
      "classification_loss": 0.6536487340927124,
      "epoch": 2.6327868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 803,
      "total_loss": 0.6536487340927124
    },
    {
      "classification_loss": 0.5797766447067261,
      "epoch": 2.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 804,
      "total_loss": 0.5797766447067261
    },
    {
      "classification_loss": 0.5981506109237671,
      "epoch": 2.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 805,
      "total_loss": 0.5981506109237671
    },
    {
      "classification_loss": 0.6688668131828308,
      "epoch": 2.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 806,
      "total_loss": 0.6688668131828308
    },
    {
      "classification_loss": 0.6629514694213867,
      "epoch": 2.6459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 807,
      "total_loss": 0.6629514694213867
    },
    {
      "classification_loss": 0.6459838151931763,
      "epoch": 2.6491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 808,
      "total_loss": 0.6459838151931763
    },
    {
      "classification_loss": 0.5677611231803894,
      "epoch": 2.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 809,
      "total_loss": 0.5677611231803894
    },
    {
      "classification_loss": 0.6546405553817749,
      "epoch": 2.6557377049180326,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 810,
      "total_loss": 0.6546405553817749
    },
    {
      "classification_loss": 0.632031261920929,
      "epoch": 2.6590163934426227,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 811,
      "total_loss": 0.632031261920929
    },
    {
      "classification_loss": 0.7074254155158997,
      "epoch": 2.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 812,
      "total_loss": 0.7074254155158997
    },
    {
      "classification_loss": 0.5981698632240295,
      "epoch": 2.6655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 813,
      "total_loss": 0.5981698632240295
    },
    {
      "classification_loss": 0.6755303144454956,
      "epoch": 2.6688524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 814,
      "total_loss": 0.6755303144454956
    },
    {
      "classification_loss": 0.6654611229896545,
      "epoch": 2.6721311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 815,
      "total_loss": 0.6654611229896545
    },
    {
      "classification_loss": 0.6948223114013672,
      "epoch": 2.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 816,
      "total_loss": 0.6948223114013672
    },
    {
      "classification_loss": 0.649530827999115,
      "epoch": 2.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 817,
      "total_loss": 0.649530827999115
    },
    {
      "classification_loss": 0.6528067588806152,
      "epoch": 2.681967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 818,
      "total_loss": 0.6528067588806152
    },
    {
      "classification_loss": 0.7650780081748962,
      "epoch": 2.685245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 819,
      "total_loss": 0.7650780081748962
    },
    {
      "classification_loss": 0.6585376262664795,
      "epoch": 2.6885245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 820,
      "total_loss": 0.6585376262664795
    },
    {
      "classification_loss": 0.6575019359588623,
      "epoch": 2.6918032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 821,
      "total_loss": 0.6575019359588623
    },
    {
      "classification_loss": 0.6250102519989014,
      "epoch": 2.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 822,
      "total_loss": 0.6250102519989014
    },
    {
      "classification_loss": 0.6061476469039917,
      "epoch": 2.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 823,
      "total_loss": 0.6061476469039917
    },
    {
      "classification_loss": 0.6287143230438232,
      "epoch": 2.7016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 824,
      "total_loss": 0.6287143230438232
    },
    {
      "classification_loss": 0.6821833848953247,
      "epoch": 2.7049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 825,
      "total_loss": 0.6821833848953247
    },
    {
      "classification_loss": 0.6674641370773315,
      "epoch": 2.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 826,
      "total_loss": 0.6674641370773315
    },
    {
      "classification_loss": 0.6783576011657715,
      "epoch": 2.7114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 827,
      "total_loss": 0.6783576011657715
    },
    {
      "classification_loss": 0.6821754574775696,
      "epoch": 2.7147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 828,
      "total_loss": 0.6821754574775696
    },
    {
      "classification_loss": 0.5874418020248413,
      "epoch": 2.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 829,
      "total_loss": 0.5874418020248413
    },
    {
      "classification_loss": 0.6580792665481567,
      "epoch": 2.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 830,
      "total_loss": 0.6580792665481567
    },
    {
      "classification_loss": 0.7029463052749634,
      "epoch": 2.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 831,
      "total_loss": 0.7029463052749634
    },
    {
      "classification_loss": 0.6528286337852478,
      "epoch": 2.7278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 832,
      "total_loss": 0.6528286337852478
    },
    {
      "classification_loss": 0.6596006751060486,
      "epoch": 2.7311475409836063,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 833,
      "total_loss": 0.6596006751060486
    },
    {
      "classification_loss": 0.5583503842353821,
      "epoch": 2.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 834,
      "total_loss": 0.5583503842353821
    },
    {
      "classification_loss": 0.6728929877281189,
      "epoch": 2.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 835,
      "total_loss": 0.6728929877281189
    },
    {
      "classification_loss": 0.640954852104187,
      "epoch": 2.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 836,
      "total_loss": 0.640954852104187
    },
    {
      "classification_loss": 0.6514449119567871,
      "epoch": 2.7442622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 837,
      "total_loss": 0.6514449119567871
    },
    {
      "classification_loss": 0.6648597717285156,
      "epoch": 2.7475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 838,
      "total_loss": 0.6648597717285156
    },
    {
      "classification_loss": 0.6474226713180542,
      "epoch": 2.7508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 839,
      "total_loss": 0.6474226713180542
    },
    {
      "classification_loss": 0.6880812644958496,
      "epoch": 2.7540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 840,
      "total_loss": 0.6880812644958496
    },
    {
      "classification_loss": 0.6593073010444641,
      "epoch": 2.7573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 841,
      "total_loss": 0.6593073010444641
    },
    {
      "classification_loss": 0.684220016002655,
      "epoch": 2.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 842,
      "total_loss": 0.684220016002655
    },
    {
      "classification_loss": 0.6175960302352905,
      "epoch": 2.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 843,
      "total_loss": 0.6175960302352905
    },
    {
      "classification_loss": 0.7068725824356079,
      "epoch": 2.7672131147540986,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 844,
      "total_loss": 0.7068725824356079
    },
    {
      "classification_loss": 0.5608829259872437,
      "epoch": 2.7704918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 845,
      "total_loss": 0.5608829259872437
    },
    {
      "classification_loss": 0.6269100308418274,
      "epoch": 2.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 846,
      "total_loss": 0.6269100308418274
    },
    {
      "classification_loss": 0.5393357276916504,
      "epoch": 2.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 847,
      "total_loss": 0.5393357276916504
    },
    {
      "classification_loss": 0.6503341197967529,
      "epoch": 2.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 848,
      "total_loss": 0.6503341197967529
    },
    {
      "classification_loss": 0.6777204871177673,
      "epoch": 2.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 849,
      "total_loss": 0.6777204871177673
    },
    {
      "classification_loss": 0.6062805652618408,
      "epoch": 2.7868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 850,
      "total_loss": 0.6062805652618408
    },
    {
      "classification_loss": 0.6439261436462402,
      "epoch": 2.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 851,
      "total_loss": 0.6439261436462402
    },
    {
      "classification_loss": 0.6762831807136536,
      "epoch": 2.7934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 852,
      "total_loss": 0.6762831807136536
    },
    {
      "classification_loss": 0.68703693151474,
      "epoch": 2.7967213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 853,
      "total_loss": 0.68703693151474
    },
    {
      "classification_loss": 0.7455493807792664,
      "epoch": 2.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 854,
      "total_loss": 0.7455493807792664
    },
    {
      "classification_loss": 0.6454305648803711,
      "epoch": 2.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 855,
      "total_loss": 0.6454305648803711
    },
    {
      "classification_loss": 0.7326847910881042,
      "epoch": 2.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 856,
      "total_loss": 0.7326847910881042
    },
    {
      "classification_loss": 0.6488208770751953,
      "epoch": 2.8098360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 857,
      "total_loss": 0.6488208770751953
    },
    {
      "classification_loss": 0.652259111404419,
      "epoch": 2.8131147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 858,
      "total_loss": 0.652259111404419
    },
    {
      "classification_loss": 0.6303403973579407,
      "epoch": 2.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 859,
      "total_loss": 0.6303403973579407
    },
    {
      "classification_loss": 0.6200801134109497,
      "epoch": 2.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 860,
      "total_loss": 0.6200801134109497
    },
    {
      "classification_loss": 0.5335289239883423,
      "epoch": 2.822950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 861,
      "total_loss": 0.5335289239883423
    },
    {
      "classification_loss": 0.5886074304580688,
      "epoch": 2.8262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 862,
      "total_loss": 0.5886074304580688
    },
    {
      "classification_loss": 0.6773108243942261,
      "epoch": 2.8295081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 863,
      "total_loss": 0.6773108243942261
    },
    {
      "classification_loss": 0.6562666296958923,
      "epoch": 2.8327868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 864,
      "total_loss": 0.6562666296958923
    },
    {
      "classification_loss": 0.6234915256500244,
      "epoch": 2.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 865,
      "total_loss": 0.6234915256500244
    },
    {
      "classification_loss": 0.6734471321105957,
      "epoch": 2.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 866,
      "total_loss": 0.6734471321105957
    },
    {
      "classification_loss": 0.5595992207527161,
      "epoch": 2.8426229508196723,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 867,
      "total_loss": 0.5595992207527161
    },
    {
      "classification_loss": 0.584645688533783,
      "epoch": 2.8459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 868,
      "total_loss": 0.584645688533783
    },
    {
      "classification_loss": 0.6149096488952637,
      "epoch": 2.8491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 869,
      "total_loss": 0.6149096488952637
    },
    {
      "classification_loss": 0.7014881372451782,
      "epoch": 2.8524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 870,
      "total_loss": 0.7014881372451782
    },
    {
      "classification_loss": 0.6081861853599548,
      "epoch": 2.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 871,
      "total_loss": 0.6081861853599548
    },
    {
      "classification_loss": 0.6137315630912781,
      "epoch": 2.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 872,
      "total_loss": 0.6137315630912781
    },
    {
      "classification_loss": 0.6450225710868835,
      "epoch": 2.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 873,
      "total_loss": 0.6450225710868835
    },
    {
      "classification_loss": 0.617633044719696,
      "epoch": 2.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 874,
      "total_loss": 0.617633044719696
    },
    {
      "classification_loss": 0.6157092452049255,
      "epoch": 2.8688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 875,
      "total_loss": 0.6157092452049255
    },
    {
      "classification_loss": 0.6017945408821106,
      "epoch": 2.8721311475409834,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 876,
      "total_loss": 0.6017945408821106
    },
    {
      "classification_loss": 0.7463010549545288,
      "epoch": 2.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 877,
      "total_loss": 0.7463010549545288
    },
    {
      "classification_loss": 0.6346688270568848,
      "epoch": 2.8786885245901637,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 878,
      "total_loss": 0.6346688270568848
    },
    {
      "classification_loss": 0.7352220416069031,
      "epoch": 2.8819672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 879,
      "total_loss": 0.7352220416069031
    },
    {
      "classification_loss": 0.6773791313171387,
      "epoch": 2.8852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 880,
      "total_loss": 0.6773791313171387
    },
    {
      "classification_loss": 0.6793453097343445,
      "epoch": 2.8885245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 881,
      "total_loss": 0.6793453097343445
    },
    {
      "classification_loss": 0.6323679685592651,
      "epoch": 2.8918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 882,
      "total_loss": 0.6323679685592651
    },
    {
      "classification_loss": 0.6817277073860168,
      "epoch": 2.8950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 883,
      "total_loss": 0.6817277073860168
    },
    {
      "classification_loss": 0.631052553653717,
      "epoch": 2.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 884,
      "total_loss": 0.631052553653717
    },
    {
      "classification_loss": 0.6746972799301147,
      "epoch": 2.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 885,
      "total_loss": 0.6746972799301147
    },
    {
      "classification_loss": 0.708028256893158,
      "epoch": 2.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 886,
      "total_loss": 0.708028256893158
    },
    {
      "classification_loss": 0.6278062462806702,
      "epoch": 2.9081967213114757,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 887,
      "total_loss": 0.6278062462806702
    },
    {
      "classification_loss": 0.6293867230415344,
      "epoch": 2.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 888,
      "total_loss": 0.6293867230415344
    },
    {
      "classification_loss": 0.6529548764228821,
      "epoch": 2.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 889,
      "total_loss": 0.6529548764228821
    },
    {
      "classification_loss": 0.6471044421195984,
      "epoch": 2.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 890,
      "total_loss": 0.6471044421195984
    },
    {
      "classification_loss": 0.6408422589302063,
      "epoch": 2.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 891,
      "total_loss": 0.6408422589302063
    },
    {
      "classification_loss": 0.6021150946617126,
      "epoch": 2.9245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 892,
      "total_loss": 0.6021150946617126
    },
    {
      "classification_loss": 0.6501173377037048,
      "epoch": 2.9278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 893,
      "total_loss": 0.6501173377037048
    },
    {
      "classification_loss": 0.6190425753593445,
      "epoch": 2.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 894,
      "total_loss": 0.6190425753593445
    },
    {
      "classification_loss": 0.7293383479118347,
      "epoch": 2.9344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 895,
      "total_loss": 0.7293383479118347
    },
    {
      "classification_loss": 0.7526530623435974,
      "epoch": 2.9377049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 896,
      "total_loss": 0.7526530623435974
    },
    {
      "classification_loss": 0.6091666221618652,
      "epoch": 2.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 897,
      "total_loss": 0.6091666221618652
    },
    {
      "classification_loss": 0.6777676343917847,
      "epoch": 2.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 898,
      "total_loss": 0.6777676343917847
    },
    {
      "classification_loss": 0.6265581846237183,
      "epoch": 2.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 899,
      "total_loss": 0.6265581846237183
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 1.4460543394088745,
      "learning_rate": 0.0001733666666666667,
      "loss": 0.649,
      "step": 900
    },
    {
      "classification_loss": 0.5869249105453491,
      "epoch": 2.9508196721311473,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 900,
      "total_loss": 0.5869249105453491
    },
    {
      "classification_loss": 0.5750132203102112,
      "epoch": 2.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 901,
      "total_loss": 0.5750132203102112
    },
    {
      "classification_loss": 0.5730440020561218,
      "epoch": 2.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 902,
      "total_loss": 0.5730440020561218
    },
    {
      "classification_loss": 0.6622456908226013,
      "epoch": 2.960655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 903,
      "total_loss": 0.6622456908226013
    },
    {
      "classification_loss": 0.617550790309906,
      "epoch": 2.963934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 904,
      "total_loss": 0.617550790309906
    },
    {
      "classification_loss": 0.6462339758872986,
      "epoch": 2.9672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 905,
      "total_loss": 0.6462339758872986
    },
    {
      "classification_loss": 0.6930297017097473,
      "epoch": 2.9704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 906,
      "total_loss": 0.6930297017097473
    },
    {
      "classification_loss": 0.6748668551445007,
      "epoch": 2.9737704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 907,
      "total_loss": 0.6748668551445007
    },
    {
      "classification_loss": 0.6548202037811279,
      "epoch": 2.9770491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 908,
      "total_loss": 0.6548202037811279
    },
    {
      "classification_loss": 0.6681627035140991,
      "epoch": 2.9803278688524593,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 909,
      "total_loss": 0.6681627035140991
    },
    {
      "classification_loss": 0.5931771397590637,
      "epoch": 2.9836065573770494,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 910,
      "total_loss": 0.5931771397590637
    },
    {
      "classification_loss": 0.6538668274879456,
      "epoch": 2.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 911,
      "total_loss": 0.6538668274879456
    },
    {
      "classification_loss": 0.6365863084793091,
      "epoch": 2.9901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 912,
      "total_loss": 0.6365863084793091
    },
    {
      "classification_loss": 0.5810474157333374,
      "epoch": 2.9934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 913,
      "total_loss": 0.5810474157333374
    },
    {
      "classification_loss": 0.6142060160636902,
      "epoch": 2.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 914,
      "total_loss": 0.6142060160636902
    },
    {
      "classification_loss": 0.8145330548286438,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.8145330548286438
    },
    {
      "classification_loss": 0.7951130270957947,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.7951130270957947
    },
    {
      "classification_loss": 0.7848591208457947,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.7848591208457947
    },
    {
      "classification_loss": 0.8307070136070251,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.8307070136070251
    },
    {
      "classification_loss": 0.7606319189071655,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.7606319189071655
    },
    {
      "classification_loss": 0.7783709764480591,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.7783709764480591
    },
    {
      "classification_loss": 0.7842420935630798,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.7842420935630798
    },
    {
      "classification_loss": 0.740864634513855,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.740864634513855
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.375,
      "eval_f1": 0.03400309119010819,
      "eval_loss": 0.7872523665428162,
      "eval_precision": 0.6470588235294118,
      "eval_recall": 0.01746031746031746,
      "eval_runtime": 6.0174,
      "eval_samples_per_second": 166.186,
      "eval_steps_per_second": 1.329,
      "step": 915
    },
    {
      "classification_loss": 0.6391879320144653,
      "epoch": 3.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 915,
      "total_loss": 0.6391879320144653
    },
    {
      "classification_loss": 0.6081079840660095,
      "epoch": 3.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 916,
      "total_loss": 0.6081079840660095
    },
    {
      "classification_loss": 0.6723644137382507,
      "epoch": 3.0065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 917,
      "total_loss": 0.6723644137382507
    },
    {
      "classification_loss": 0.6447715759277344,
      "epoch": 3.0098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 918,
      "total_loss": 0.6447715759277344
    },
    {
      "classification_loss": 0.6658512949943542,
      "epoch": 3.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 919,
      "total_loss": 0.6658512949943542
    },
    {
      "classification_loss": 0.5669940114021301,
      "epoch": 3.0163934426229506,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 920,
      "total_loss": 0.5669940114021301
    },
    {
      "classification_loss": 0.7018253803253174,
      "epoch": 3.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 921,
      "total_loss": 0.7018253803253174
    },
    {
      "classification_loss": 0.5741744637489319,
      "epoch": 3.0229508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 922,
      "total_loss": 0.5741744637489319
    },
    {
      "classification_loss": 0.6204573512077332,
      "epoch": 3.0262295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 923,
      "total_loss": 0.6204573512077332
    },
    {
      "classification_loss": 0.6704285740852356,
      "epoch": 3.0295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 924,
      "total_loss": 0.6704285740852356
    },
    {
      "classification_loss": 0.6762174963951111,
      "epoch": 3.0327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 925,
      "total_loss": 0.6762174963951111
    },
    {
      "classification_loss": 0.5830672383308411,
      "epoch": 3.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 926,
      "total_loss": 0.5830672383308411
    },
    {
      "classification_loss": 0.6026861667633057,
      "epoch": 3.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 927,
      "total_loss": 0.6026861667633057
    },
    {
      "classification_loss": 0.6512871384620667,
      "epoch": 3.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 928,
      "total_loss": 0.6512871384620667
    },
    {
      "classification_loss": 0.602051317691803,
      "epoch": 3.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 929,
      "total_loss": 0.602051317691803
    },
    {
      "classification_loss": 0.6075294613838196,
      "epoch": 3.0491803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 930,
      "total_loss": 0.6075294613838196
    },
    {
      "classification_loss": 0.6545624136924744,
      "epoch": 3.0524590163934424,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 931,
      "total_loss": 0.6545624136924744
    },
    {
      "classification_loss": 0.6966668367385864,
      "epoch": 3.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 932,
      "total_loss": 0.6966668367385864
    },
    {
      "classification_loss": 0.5700237154960632,
      "epoch": 3.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 933,
      "total_loss": 0.5700237154960632
    },
    {
      "classification_loss": 0.608841598033905,
      "epoch": 3.0622950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 934,
      "total_loss": 0.608841598033905
    },
    {
      "classification_loss": 0.6373609304428101,
      "epoch": 3.0655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 935,
      "total_loss": 0.6373609304428101
    },
    {
      "classification_loss": 0.742216944694519,
      "epoch": 3.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 936,
      "total_loss": 0.742216944694519
    },
    {
      "classification_loss": 0.6519098877906799,
      "epoch": 3.0721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 937,
      "total_loss": 0.6519098877906799
    },
    {
      "classification_loss": 0.6123955845832825,
      "epoch": 3.0754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 938,
      "total_loss": 0.6123955845832825
    },
    {
      "classification_loss": 0.6014568209648132,
      "epoch": 3.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 939,
      "total_loss": 0.6014568209648132
    },
    {
      "classification_loss": 0.5809444189071655,
      "epoch": 3.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 940,
      "total_loss": 0.5809444189071655
    },
    {
      "classification_loss": 0.6497688293457031,
      "epoch": 3.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 941,
      "total_loss": 0.6497688293457031
    },
    {
      "classification_loss": 0.6174978017807007,
      "epoch": 3.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 942,
      "total_loss": 0.6174978017807007
    },
    {
      "classification_loss": 0.6269055008888245,
      "epoch": 3.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 943,
      "total_loss": 0.6269055008888245
    },
    {
      "classification_loss": 0.5952149033546448,
      "epoch": 3.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 944,
      "total_loss": 0.5952149033546448
    },
    {
      "classification_loss": 0.6380160450935364,
      "epoch": 3.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 945,
      "total_loss": 0.6380160450935364
    },
    {
      "classification_loss": 0.6470086574554443,
      "epoch": 3.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 946,
      "total_loss": 0.6470086574554443
    },
    {
      "classification_loss": 0.6282336711883545,
      "epoch": 3.1049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 947,
      "total_loss": 0.6282336711883545
    },
    {
      "classification_loss": 0.6267358660697937,
      "epoch": 3.1081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 948,
      "total_loss": 0.6267358660697937
    },
    {
      "classification_loss": 0.6368218064308167,
      "epoch": 3.1114754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 949,
      "total_loss": 0.6368218064308167
    },
    {
      "classification_loss": 0.5747142434120178,
      "epoch": 3.1147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 950,
      "total_loss": 0.5747142434120178
    },
    {
      "classification_loss": 0.6117197275161743,
      "epoch": 3.1180327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 951,
      "total_loss": 0.6117197275161743
    },
    {
      "classification_loss": 0.632226824760437,
      "epoch": 3.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 952,
      "total_loss": 0.632226824760437
    },
    {
      "classification_loss": 0.5954176187515259,
      "epoch": 3.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 953,
      "total_loss": 0.5954176187515259
    },
    {
      "classification_loss": 0.6407992839813232,
      "epoch": 3.1278688524590166,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 954,
      "total_loss": 0.6407992839813232
    },
    {
      "classification_loss": 0.5929293036460876,
      "epoch": 3.1311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 955,
      "total_loss": 0.5929293036460876
    },
    {
      "classification_loss": 0.5927863717079163,
      "epoch": 3.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 956,
      "total_loss": 0.5927863717079163
    },
    {
      "classification_loss": 0.559292733669281,
      "epoch": 3.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 957,
      "total_loss": 0.559292733669281
    },
    {
      "classification_loss": 0.5586149096488953,
      "epoch": 3.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 958,
      "total_loss": 0.5586149096488953
    },
    {
      "classification_loss": 0.7186868786811829,
      "epoch": 3.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 959,
      "total_loss": 0.7186868786811829
    },
    {
      "classification_loss": 0.7261694669723511,
      "epoch": 3.1475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 960,
      "total_loss": 0.7261694669723511
    },
    {
      "classification_loss": 0.5767861604690552,
      "epoch": 3.1508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 961,
      "total_loss": 0.5767861604690552
    },
    {
      "classification_loss": 0.5827582478523254,
      "epoch": 3.1540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 962,
      "total_loss": 0.5827582478523254
    },
    {
      "classification_loss": 0.6350870132446289,
      "epoch": 3.1573770491803277,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 963,
      "total_loss": 0.6350870132446289
    },
    {
      "classification_loss": 0.6064724922180176,
      "epoch": 3.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 964,
      "total_loss": 0.6064724922180176
    },
    {
      "classification_loss": 0.5499287843704224,
      "epoch": 3.1639344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 965,
      "total_loss": 0.5499287843704224
    },
    {
      "classification_loss": 0.6468144655227661,
      "epoch": 3.1672131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 966,
      "total_loss": 0.6468144655227661
    },
    {
      "classification_loss": 0.521653950214386,
      "epoch": 3.1704918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 967,
      "total_loss": 0.521653950214386
    },
    {
      "classification_loss": 0.6805787086486816,
      "epoch": 3.1737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 968,
      "total_loss": 0.6805787086486816
    },
    {
      "classification_loss": 0.6390178799629211,
      "epoch": 3.177049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 969,
      "total_loss": 0.6390178799629211
    },
    {
      "classification_loss": 0.6033177971839905,
      "epoch": 3.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 970,
      "total_loss": 0.6033177971839905
    },
    {
      "classification_loss": 0.6594963073730469,
      "epoch": 3.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 971,
      "total_loss": 0.6594963073730469
    },
    {
      "classification_loss": 0.5286180377006531,
      "epoch": 3.1868852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 972,
      "total_loss": 0.5286180377006531
    },
    {
      "classification_loss": 0.7068979144096375,
      "epoch": 3.1901639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 973,
      "total_loss": 0.7068979144096375
    },
    {
      "classification_loss": 0.5527566075325012,
      "epoch": 3.1934426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 974,
      "total_loss": 0.5527566075325012
    },
    {
      "classification_loss": 0.6204661726951599,
      "epoch": 3.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 975,
      "total_loss": 0.6204661726951599
    },
    {
      "classification_loss": 0.6108192801475525,
      "epoch": 3.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 976,
      "total_loss": 0.6108192801475525
    },
    {
      "classification_loss": 0.5753327012062073,
      "epoch": 3.2032786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 977,
      "total_loss": 0.5753327012062073
    },
    {
      "classification_loss": 0.6134668588638306,
      "epoch": 3.2065573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 978,
      "total_loss": 0.6134668588638306
    },
    {
      "classification_loss": 0.6153162121772766,
      "epoch": 3.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 979,
      "total_loss": 0.6153162121772766
    },
    {
      "classification_loss": 0.5831570029258728,
      "epoch": 3.2131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 980,
      "total_loss": 0.5831570029258728
    },
    {
      "classification_loss": 0.6439107060432434,
      "epoch": 3.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 981,
      "total_loss": 0.6439107060432434
    },
    {
      "classification_loss": 0.6118214726448059,
      "epoch": 3.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 982,
      "total_loss": 0.6118214726448059
    },
    {
      "classification_loss": 0.6288046836853027,
      "epoch": 3.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 983,
      "total_loss": 0.6288046836853027
    },
    {
      "classification_loss": 0.6458501815795898,
      "epoch": 3.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 984,
      "total_loss": 0.6458501815795898
    },
    {
      "classification_loss": 0.5964792370796204,
      "epoch": 3.2295081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 985,
      "total_loss": 0.5964792370796204
    },
    {
      "classification_loss": 0.6127866506576538,
      "epoch": 3.2327868852459014,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 986,
      "total_loss": 0.6127866506576538
    },
    {
      "classification_loss": 0.6554199457168579,
      "epoch": 3.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 987,
      "total_loss": 0.6554199457168579
    },
    {
      "classification_loss": 0.6423786282539368,
      "epoch": 3.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 988,
      "total_loss": 0.6423786282539368
    },
    {
      "classification_loss": 0.5882832407951355,
      "epoch": 3.2426229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 989,
      "total_loss": 0.5882832407951355
    },
    {
      "classification_loss": 0.5678666234016418,
      "epoch": 3.2459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 990,
      "total_loss": 0.5678666234016418
    },
    {
      "classification_loss": 0.6802240610122681,
      "epoch": 3.2491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 991,
      "total_loss": 0.6802240610122681
    },
    {
      "classification_loss": 0.543483555316925,
      "epoch": 3.2524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 992,
      "total_loss": 0.543483555316925
    },
    {
      "classification_loss": 0.6963410377502441,
      "epoch": 3.2557377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 993,
      "total_loss": 0.6963410377502441
    },
    {
      "classification_loss": 0.6023328304290771,
      "epoch": 3.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 994,
      "total_loss": 0.6023328304290771
    },
    {
      "classification_loss": 0.5815756916999817,
      "epoch": 3.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 995,
      "total_loss": 0.5815756916999817
    },
    {
      "classification_loss": 0.5731878280639648,
      "epoch": 3.265573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 996,
      "total_loss": 0.5731878280639648
    },
    {
      "classification_loss": 0.5729439854621887,
      "epoch": 3.2688524590163937,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 997,
      "total_loss": 0.5729439854621887
    },
    {
      "classification_loss": 0.6187911033630371,
      "epoch": 3.2721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 998,
      "total_loss": 0.6187911033630371
    },
    {
      "classification_loss": 0.5907732248306274,
      "epoch": 3.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 999,
      "total_loss": 0.5907732248306274
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 5.53153657913208,
      "learning_rate": 0.00017003333333333334,
      "loss": 0.6211,
      "step": 1000
    },
    {
      "classification_loss": 0.6306383013725281,
      "epoch": 3.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1000,
      "total_loss": 0.6306383013725281
    },
    {
      "classification_loss": 0.6699001789093018,
      "epoch": 3.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1001,
      "total_loss": 0.6699001789093018
    },
    {
      "classification_loss": 0.6348069310188293,
      "epoch": 3.2852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1002,
      "total_loss": 0.6348069310188293
    },
    {
      "classification_loss": 0.7274527549743652,
      "epoch": 3.2885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1003,
      "total_loss": 0.7274527549743652
    },
    {
      "classification_loss": 0.7048348784446716,
      "epoch": 3.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1004,
      "total_loss": 0.7048348784446716
    },
    {
      "classification_loss": 0.6323686242103577,
      "epoch": 3.2950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1005,
      "total_loss": 0.6323686242103577
    },
    {
      "classification_loss": 0.7063965797424316,
      "epoch": 3.2983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1006,
      "total_loss": 0.7063965797424316
    },
    {
      "classification_loss": 0.6382759213447571,
      "epoch": 3.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1007,
      "total_loss": 0.6382759213447571
    },
    {
      "classification_loss": 0.5665464401245117,
      "epoch": 3.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1008,
      "total_loss": 0.5665464401245117
    },
    {
      "classification_loss": 0.6729834675788879,
      "epoch": 3.3081967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1009,
      "total_loss": 0.6729834675788879
    },
    {
      "classification_loss": 0.695097029209137,
      "epoch": 3.3114754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1010,
      "total_loss": 0.695097029209137
    },
    {
      "classification_loss": 0.6395645141601562,
      "epoch": 3.314754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1011,
      "total_loss": 0.6395645141601562
    },
    {
      "classification_loss": 0.637386679649353,
      "epoch": 3.318032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1012,
      "total_loss": 0.637386679649353
    },
    {
      "classification_loss": 0.6634384393692017,
      "epoch": 3.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1013,
      "total_loss": 0.6634384393692017
    },
    {
      "classification_loss": 0.6133981943130493,
      "epoch": 3.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1014,
      "total_loss": 0.6133981943130493
    },
    {
      "classification_loss": 0.6239176988601685,
      "epoch": 3.3278688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1015,
      "total_loss": 0.6239176988601685
    },
    {
      "classification_loss": 0.5201412439346313,
      "epoch": 3.3311475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1016,
      "total_loss": 0.5201412439346313
    },
    {
      "classification_loss": 0.6052525043487549,
      "epoch": 3.3344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1017,
      "total_loss": 0.6052525043487549
    },
    {
      "classification_loss": 0.584935188293457,
      "epoch": 3.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1018,
      "total_loss": 0.584935188293457
    },
    {
      "classification_loss": 0.6371868848800659,
      "epoch": 3.3409836065573773,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1019,
      "total_loss": 0.6371868848800659
    },
    {
      "classification_loss": 0.596892237663269,
      "epoch": 3.3442622950819674,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1020,
      "total_loss": 0.596892237663269
    },
    {
      "classification_loss": 0.6822124123573303,
      "epoch": 3.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1021,
      "total_loss": 0.6822124123573303
    },
    {
      "classification_loss": 0.7165191769599915,
      "epoch": 3.3508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1022,
      "total_loss": 0.7165191769599915
    },
    {
      "classification_loss": 0.6081511974334717,
      "epoch": 3.3540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1023,
      "total_loss": 0.6081511974334717
    },
    {
      "classification_loss": 0.6222435235977173,
      "epoch": 3.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1024,
      "total_loss": 0.6222435235977173
    },
    {
      "classification_loss": 0.6680335998535156,
      "epoch": 3.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1025,
      "total_loss": 0.6680335998535156
    },
    {
      "classification_loss": 0.6703540086746216,
      "epoch": 3.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1026,
      "total_loss": 0.6703540086746216
    },
    {
      "classification_loss": 0.6134849190711975,
      "epoch": 3.3672131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1027,
      "total_loss": 0.6134849190711975
    },
    {
      "classification_loss": 0.5712637901306152,
      "epoch": 3.3704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1028,
      "total_loss": 0.5712637901306152
    },
    {
      "classification_loss": 0.6804757714271545,
      "epoch": 3.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1029,
      "total_loss": 0.6804757714271545
    },
    {
      "classification_loss": 0.5528501272201538,
      "epoch": 3.3770491803278686,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1030,
      "total_loss": 0.5528501272201538
    },
    {
      "classification_loss": 0.5479506850242615,
      "epoch": 3.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1031,
      "total_loss": 0.5479506850242615
    },
    {
      "classification_loss": 0.5959928035736084,
      "epoch": 3.3836065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1032,
      "total_loss": 0.5959928035736084
    },
    {
      "classification_loss": 0.5815926194190979,
      "epoch": 3.3868852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1033,
      "total_loss": 0.5815926194190979
    },
    {
      "classification_loss": 0.6203131079673767,
      "epoch": 3.3901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1034,
      "total_loss": 0.6203131079673767
    },
    {
      "classification_loss": 0.6791132688522339,
      "epoch": 3.3934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1035,
      "total_loss": 0.6791132688522339
    },
    {
      "classification_loss": 0.6327658295631409,
      "epoch": 3.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1036,
      "total_loss": 0.6327658295631409
    },
    {
      "classification_loss": 0.6739094853401184,
      "epoch": 3.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1037,
      "total_loss": 0.6739094853401184
    },
    {
      "classification_loss": 0.6896265149116516,
      "epoch": 3.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1038,
      "total_loss": 0.6896265149116516
    },
    {
      "classification_loss": 0.6339268684387207,
      "epoch": 3.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1039,
      "total_loss": 0.6339268684387207
    },
    {
      "classification_loss": 0.6379804611206055,
      "epoch": 3.4098360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1040,
      "total_loss": 0.6379804611206055
    },
    {
      "classification_loss": 0.5847087502479553,
      "epoch": 3.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1041,
      "total_loss": 0.5847087502479553
    },
    {
      "classification_loss": 0.6166040301322937,
      "epoch": 3.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1042,
      "total_loss": 0.6166040301322937
    },
    {
      "classification_loss": 0.5847687125205994,
      "epoch": 3.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1043,
      "total_loss": 0.5847687125205994
    },
    {
      "classification_loss": 0.6352771520614624,
      "epoch": 3.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1044,
      "total_loss": 0.6352771520614624
    },
    {
      "classification_loss": 0.6246709823608398,
      "epoch": 3.4262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1045,
      "total_loss": 0.6246709823608398
    },
    {
      "classification_loss": 0.635512113571167,
      "epoch": 3.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1046,
      "total_loss": 0.635512113571167
    },
    {
      "classification_loss": 0.671753466129303,
      "epoch": 3.4327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1047,
      "total_loss": 0.671753466129303
    },
    {
      "classification_loss": 0.691548764705658,
      "epoch": 3.4360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1048,
      "total_loss": 0.691548764705658
    },
    {
      "classification_loss": 0.6960029006004333,
      "epoch": 3.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1049,
      "total_loss": 0.6960029006004333
    },
    {
      "classification_loss": 0.5964454412460327,
      "epoch": 3.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1050,
      "total_loss": 0.5964454412460327
    },
    {
      "classification_loss": 0.578647792339325,
      "epoch": 3.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1051,
      "total_loss": 0.578647792339325
    },
    {
      "classification_loss": 0.6500298976898193,
      "epoch": 3.4491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1052,
      "total_loss": 0.6500298976898193
    },
    {
      "classification_loss": 0.6424834132194519,
      "epoch": 3.4524590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1053,
      "total_loss": 0.6424834132194519
    },
    {
      "classification_loss": 0.6384720802307129,
      "epoch": 3.455737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1054,
      "total_loss": 0.6384720802307129
    },
    {
      "classification_loss": 0.6169339418411255,
      "epoch": 3.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1055,
      "total_loss": 0.6169339418411255
    },
    {
      "classification_loss": 0.6252519488334656,
      "epoch": 3.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1056,
      "total_loss": 0.6252519488334656
    },
    {
      "classification_loss": 0.6755489706993103,
      "epoch": 3.4655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1057,
      "total_loss": 0.6755489706993103
    },
    {
      "classification_loss": 0.6152545213699341,
      "epoch": 3.4688524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1058,
      "total_loss": 0.6152545213699341
    },
    {
      "classification_loss": 0.6246526837348938,
      "epoch": 3.4721311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1059,
      "total_loss": 0.6246526837348938
    },
    {
      "classification_loss": 0.5910590291023254,
      "epoch": 3.4754098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1060,
      "total_loss": 0.5910590291023254
    },
    {
      "classification_loss": 0.5544180870056152,
      "epoch": 3.4786885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1061,
      "total_loss": 0.5544180870056152
    },
    {
      "classification_loss": 0.5343322157859802,
      "epoch": 3.4819672131147543,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1062,
      "total_loss": 0.5343322157859802
    },
    {
      "classification_loss": 0.6027756333351135,
      "epoch": 3.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1063,
      "total_loss": 0.6027756333351135
    },
    {
      "classification_loss": 0.6711416244506836,
      "epoch": 3.4885245901639346,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1064,
      "total_loss": 0.6711416244506836
    },
    {
      "classification_loss": 0.6919649243354797,
      "epoch": 3.4918032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1065,
      "total_loss": 0.6919649243354797
    },
    {
      "classification_loss": 0.7710225582122803,
      "epoch": 3.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1066,
      "total_loss": 0.7710225582122803
    },
    {
      "classification_loss": 0.7296631932258606,
      "epoch": 3.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1067,
      "total_loss": 0.7296631932258606
    },
    {
      "classification_loss": 0.6448307037353516,
      "epoch": 3.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1068,
      "total_loss": 0.6448307037353516
    },
    {
      "classification_loss": 0.6578924655914307,
      "epoch": 3.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1069,
      "total_loss": 0.6578924655914307
    },
    {
      "classification_loss": 0.6385699510574341,
      "epoch": 3.5081967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1070,
      "total_loss": 0.6385699510574341
    },
    {
      "classification_loss": 0.5746889710426331,
      "epoch": 3.5114754098360654,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1071,
      "total_loss": 0.5746889710426331
    },
    {
      "classification_loss": 0.6259164214134216,
      "epoch": 3.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1072,
      "total_loss": 0.6259164214134216
    },
    {
      "classification_loss": 0.5777879357337952,
      "epoch": 3.5180327868852457,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1073,
      "total_loss": 0.5777879357337952
    },
    {
      "classification_loss": 0.5789260864257812,
      "epoch": 3.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1074,
      "total_loss": 0.5789260864257812
    },
    {
      "classification_loss": 0.6240569353103638,
      "epoch": 3.5245901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1075,
      "total_loss": 0.6240569353103638
    },
    {
      "classification_loss": 0.6227736473083496,
      "epoch": 3.5278688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1076,
      "total_loss": 0.6227736473083496
    },
    {
      "classification_loss": 0.6418671607971191,
      "epoch": 3.5311475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1077,
      "total_loss": 0.6418671607971191
    },
    {
      "classification_loss": 0.6324038505554199,
      "epoch": 3.5344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1078,
      "total_loss": 0.6324038505554199
    },
    {
      "classification_loss": 0.5862008333206177,
      "epoch": 3.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1079,
      "total_loss": 0.5862008333206177
    },
    {
      "classification_loss": 0.6539157629013062,
      "epoch": 3.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1080,
      "total_loss": 0.6539157629013062
    },
    {
      "classification_loss": 0.580960214138031,
      "epoch": 3.544262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1081,
      "total_loss": 0.580960214138031
    },
    {
      "classification_loss": 0.6045177578926086,
      "epoch": 3.5475409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1082,
      "total_loss": 0.6045177578926086
    },
    {
      "classification_loss": 0.5970606803894043,
      "epoch": 3.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1083,
      "total_loss": 0.5970606803894043
    },
    {
      "classification_loss": 0.6491187810897827,
      "epoch": 3.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1084,
      "total_loss": 0.6491187810897827
    },
    {
      "classification_loss": 0.6440609693527222,
      "epoch": 3.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1085,
      "total_loss": 0.6440609693527222
    },
    {
      "classification_loss": 0.6120240092277527,
      "epoch": 3.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1086,
      "total_loss": 0.6120240092277527
    },
    {
      "classification_loss": 0.6401466131210327,
      "epoch": 3.5639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1087,
      "total_loss": 0.6401466131210327
    },
    {
      "classification_loss": 0.6333215832710266,
      "epoch": 3.5672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1088,
      "total_loss": 0.6333215832710266
    },
    {
      "classification_loss": 0.6450108289718628,
      "epoch": 3.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1089,
      "total_loss": 0.6450108289718628
    },
    {
      "classification_loss": 0.6707785129547119,
      "epoch": 3.5737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1090,
      "total_loss": 0.6707785129547119
    },
    {
      "classification_loss": 0.5530345439910889,
      "epoch": 3.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1091,
      "total_loss": 0.5530345439910889
    },
    {
      "classification_loss": 0.591323733329773,
      "epoch": 3.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1092,
      "total_loss": 0.591323733329773
    },
    {
      "classification_loss": 0.6768133044242859,
      "epoch": 3.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1093,
      "total_loss": 0.6768133044242859
    },
    {
      "classification_loss": 0.7086431980133057,
      "epoch": 3.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1094,
      "total_loss": 0.7086431980133057
    },
    {
      "classification_loss": 0.5802810788154602,
      "epoch": 3.5901639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1095,
      "total_loss": 0.5802810788154602
    },
    {
      "classification_loss": 0.6960800886154175,
      "epoch": 3.5934426229508194,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1096,
      "total_loss": 0.6960800886154175
    },
    {
      "classification_loss": 0.6731969714164734,
      "epoch": 3.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1097,
      "total_loss": 0.6731969714164734
    },
    {
      "classification_loss": 0.6278107762336731,
      "epoch": 3.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1098,
      "total_loss": 0.6278107762336731
    },
    {
      "classification_loss": 0.6283719539642334,
      "epoch": 3.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1099,
      "total_loss": 0.6283719539642334
    },
    {
      "epoch": 3.6065573770491803,
      "grad_norm": 2.5482726097106934,
      "learning_rate": 0.0001667,
      "loss": 0.633,
      "step": 1100
    },
    {
      "classification_loss": 0.6095505356788635,
      "epoch": 3.6065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1100,
      "total_loss": 0.6095505356788635
    },
    {
      "classification_loss": 0.625938355922699,
      "epoch": 3.6098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1101,
      "total_loss": 0.625938355922699
    },
    {
      "classification_loss": 0.6475554704666138,
      "epoch": 3.6131147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1102,
      "total_loss": 0.6475554704666138
    },
    {
      "classification_loss": 0.6618005633354187,
      "epoch": 3.6163934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1103,
      "total_loss": 0.6618005633354187
    },
    {
      "classification_loss": 0.6485204100608826,
      "epoch": 3.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1104,
      "total_loss": 0.6485204100608826
    },
    {
      "classification_loss": 0.6137438416481018,
      "epoch": 3.6229508196721314,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1105,
      "total_loss": 0.6137438416481018
    },
    {
      "classification_loss": 0.6468526124954224,
      "epoch": 3.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1106,
      "total_loss": 0.6468526124954224
    },
    {
      "classification_loss": 0.6746812462806702,
      "epoch": 3.6295081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1107,
      "total_loss": 0.6746812462806702
    },
    {
      "classification_loss": 0.6366666555404663,
      "epoch": 3.6327868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1108,
      "total_loss": 0.6366666555404663
    },
    {
      "classification_loss": 0.6180174946784973,
      "epoch": 3.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1109,
      "total_loss": 0.6180174946784973
    },
    {
      "classification_loss": 0.7323210835456848,
      "epoch": 3.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1110,
      "total_loss": 0.7323210835456848
    },
    {
      "classification_loss": 0.6590652465820312,
      "epoch": 3.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1111,
      "total_loss": 0.6590652465820312
    },
    {
      "classification_loss": 0.61629718542099,
      "epoch": 3.6459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1112,
      "total_loss": 0.61629718542099
    },
    {
      "classification_loss": 0.6367692947387695,
      "epoch": 3.6491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1113,
      "total_loss": 0.6367692947387695
    },
    {
      "classification_loss": 0.586384117603302,
      "epoch": 3.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1114,
      "total_loss": 0.586384117603302
    },
    {
      "classification_loss": 0.6681204438209534,
      "epoch": 3.6557377049180326,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1115,
      "total_loss": 0.6681204438209534
    },
    {
      "classification_loss": 0.6824667453765869,
      "epoch": 3.6590163934426227,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1116,
      "total_loss": 0.6824667453765869
    },
    {
      "classification_loss": 0.5717865824699402,
      "epoch": 3.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1117,
      "total_loss": 0.5717865824699402
    },
    {
      "classification_loss": 0.5906731486320496,
      "epoch": 3.6655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1118,
      "total_loss": 0.5906731486320496
    },
    {
      "classification_loss": 0.5703739523887634,
      "epoch": 3.6688524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1119,
      "total_loss": 0.5703739523887634
    },
    {
      "classification_loss": 0.6369026303291321,
      "epoch": 3.6721311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1120,
      "total_loss": 0.6369026303291321
    },
    {
      "classification_loss": 0.6672720909118652,
      "epoch": 3.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1121,
      "total_loss": 0.6672720909118652
    },
    {
      "classification_loss": 0.6268528699874878,
      "epoch": 3.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1122,
      "total_loss": 0.6268528699874878
    },
    {
      "classification_loss": 0.6185177564620972,
      "epoch": 3.681967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1123,
      "total_loss": 0.6185177564620972
    },
    {
      "classification_loss": 0.6006613373756409,
      "epoch": 3.685245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1124,
      "total_loss": 0.6006613373756409
    },
    {
      "classification_loss": 0.5987418293952942,
      "epoch": 3.6885245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1125,
      "total_loss": 0.5987418293952942
    },
    {
      "classification_loss": 0.6049272418022156,
      "epoch": 3.6918032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1126,
      "total_loss": 0.6049272418022156
    },
    {
      "classification_loss": 0.5849695205688477,
      "epoch": 3.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1127,
      "total_loss": 0.5849695205688477
    },
    {
      "classification_loss": 0.638906717300415,
      "epoch": 3.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1128,
      "total_loss": 0.638906717300415
    },
    {
      "classification_loss": 0.6042098999023438,
      "epoch": 3.7016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1129,
      "total_loss": 0.6042098999023438
    },
    {
      "classification_loss": 0.5965882539749146,
      "epoch": 3.7049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1130,
      "total_loss": 0.5965882539749146
    },
    {
      "classification_loss": 0.6358504295349121,
      "epoch": 3.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1131,
      "total_loss": 0.6358504295349121
    },
    {
      "classification_loss": 0.6960458159446716,
      "epoch": 3.7114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1132,
      "total_loss": 0.6960458159446716
    },
    {
      "classification_loss": 0.5966853499412537,
      "epoch": 3.7147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1133,
      "total_loss": 0.5966853499412537
    },
    {
      "classification_loss": 0.6270977258682251,
      "epoch": 3.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1134,
      "total_loss": 0.6270977258682251
    },
    {
      "classification_loss": 0.6230767369270325,
      "epoch": 3.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1135,
      "total_loss": 0.6230767369270325
    },
    {
      "classification_loss": 0.5947087407112122,
      "epoch": 3.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1136,
      "total_loss": 0.5947087407112122
    },
    {
      "classification_loss": 0.6746556162834167,
      "epoch": 3.7278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1137,
      "total_loss": 0.6746556162834167
    },
    {
      "classification_loss": 0.5611866116523743,
      "epoch": 3.7311475409836063,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1138,
      "total_loss": 0.5611866116523743
    },
    {
      "classification_loss": 0.6133644580841064,
      "epoch": 3.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1139,
      "total_loss": 0.6133644580841064
    },
    {
      "classification_loss": 0.7137611508369446,
      "epoch": 3.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1140,
      "total_loss": 0.7137611508369446
    },
    {
      "classification_loss": 0.6152480244636536,
      "epoch": 3.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1141,
      "total_loss": 0.6152480244636536
    },
    {
      "classification_loss": 0.6030460000038147,
      "epoch": 3.7442622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1142,
      "total_loss": 0.6030460000038147
    },
    {
      "classification_loss": 0.5855371356010437,
      "epoch": 3.7475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1143,
      "total_loss": 0.5855371356010437
    },
    {
      "classification_loss": 0.5615608096122742,
      "epoch": 3.7508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1144,
      "total_loss": 0.5615608096122742
    },
    {
      "classification_loss": 0.5946676135063171,
      "epoch": 3.7540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1145,
      "total_loss": 0.5946676135063171
    },
    {
      "classification_loss": 0.6503653526306152,
      "epoch": 3.7573770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1146,
      "total_loss": 0.6503653526306152
    },
    {
      "classification_loss": 0.605129599571228,
      "epoch": 3.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1147,
      "total_loss": 0.605129599571228
    },
    {
      "classification_loss": 0.6871640682220459,
      "epoch": 3.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1148,
      "total_loss": 0.6871640682220459
    },
    {
      "classification_loss": 0.6971414685249329,
      "epoch": 3.7672131147540986,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1149,
      "total_loss": 0.6971414685249329
    },
    {
      "classification_loss": 0.6062591075897217,
      "epoch": 3.7704918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1150,
      "total_loss": 0.6062591075897217
    },
    {
      "classification_loss": 0.5507655143737793,
      "epoch": 3.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1151,
      "total_loss": 0.5507655143737793
    },
    {
      "classification_loss": 0.6464734673500061,
      "epoch": 3.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1152,
      "total_loss": 0.6464734673500061
    },
    {
      "classification_loss": 0.6584529280662537,
      "epoch": 3.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1153,
      "total_loss": 0.6584529280662537
    },
    {
      "classification_loss": 0.6397233009338379,
      "epoch": 3.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1154,
      "total_loss": 0.6397233009338379
    },
    {
      "classification_loss": 0.5783952474594116,
      "epoch": 3.7868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1155,
      "total_loss": 0.5783952474594116
    },
    {
      "classification_loss": 0.6954275369644165,
      "epoch": 3.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1156,
      "total_loss": 0.6954275369644165
    },
    {
      "classification_loss": 0.5760709643363953,
      "epoch": 3.7934426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1157,
      "total_loss": 0.5760709643363953
    },
    {
      "classification_loss": 0.5879453420639038,
      "epoch": 3.7967213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1158,
      "total_loss": 0.5879453420639038
    },
    {
      "classification_loss": 0.6791242957115173,
      "epoch": 3.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1159,
      "total_loss": 0.6791242957115173
    },
    {
      "classification_loss": 0.6437327265739441,
      "epoch": 3.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1160,
      "total_loss": 0.6437327265739441
    },
    {
      "classification_loss": 0.6242661476135254,
      "epoch": 3.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1161,
      "total_loss": 0.6242661476135254
    },
    {
      "classification_loss": 0.5995579957962036,
      "epoch": 3.8098360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1162,
      "total_loss": 0.5995579957962036
    },
    {
      "classification_loss": 0.582169234752655,
      "epoch": 3.8131147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1163,
      "total_loss": 0.582169234752655
    },
    {
      "classification_loss": 0.7383379936218262,
      "epoch": 3.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1164,
      "total_loss": 0.7383379936218262
    },
    {
      "classification_loss": 0.5368362069129944,
      "epoch": 3.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1165,
      "total_loss": 0.5368362069129944
    },
    {
      "classification_loss": 0.6785664558410645,
      "epoch": 3.822950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1166,
      "total_loss": 0.6785664558410645
    },
    {
      "classification_loss": 0.6297599077224731,
      "epoch": 3.8262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1167,
      "total_loss": 0.6297599077224731
    },
    {
      "classification_loss": 0.5851531624794006,
      "epoch": 3.8295081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1168,
      "total_loss": 0.5851531624794006
    },
    {
      "classification_loss": 0.6387592554092407,
      "epoch": 3.8327868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1169,
      "total_loss": 0.6387592554092407
    },
    {
      "classification_loss": 0.5942277908325195,
      "epoch": 3.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1170,
      "total_loss": 0.5942277908325195
    },
    {
      "classification_loss": 0.6418381333351135,
      "epoch": 3.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1171,
      "total_loss": 0.6418381333351135
    },
    {
      "classification_loss": 0.5826167464256287,
      "epoch": 3.8426229508196723,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1172,
      "total_loss": 0.5826167464256287
    },
    {
      "classification_loss": 0.6670812368392944,
      "epoch": 3.8459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1173,
      "total_loss": 0.6670812368392944
    },
    {
      "classification_loss": 0.6416741013526917,
      "epoch": 3.8491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1174,
      "total_loss": 0.6416741013526917
    },
    {
      "classification_loss": 0.586075484752655,
      "epoch": 3.8524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1175,
      "total_loss": 0.586075484752655
    },
    {
      "classification_loss": 0.6535174250602722,
      "epoch": 3.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1176,
      "total_loss": 0.6535174250602722
    },
    {
      "classification_loss": 0.6581873893737793,
      "epoch": 3.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1177,
      "total_loss": 0.6581873893737793
    },
    {
      "classification_loss": 0.670222282409668,
      "epoch": 3.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1178,
      "total_loss": 0.670222282409668
    },
    {
      "classification_loss": 0.6480275392532349,
      "epoch": 3.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1179,
      "total_loss": 0.6480275392532349
    },
    {
      "classification_loss": 0.5734622478485107,
      "epoch": 3.8688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1180,
      "total_loss": 0.5734622478485107
    },
    {
      "classification_loss": 0.5949715375900269,
      "epoch": 3.8721311475409834,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1181,
      "total_loss": 0.5949715375900269
    },
    {
      "classification_loss": 0.6463958621025085,
      "epoch": 3.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1182,
      "total_loss": 0.6463958621025085
    },
    {
      "classification_loss": 0.6758001446723938,
      "epoch": 3.8786885245901637,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1183,
      "total_loss": 0.6758001446723938
    },
    {
      "classification_loss": 0.6267231702804565,
      "epoch": 3.8819672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1184,
      "total_loss": 0.6267231702804565
    },
    {
      "classification_loss": 0.5824413299560547,
      "epoch": 3.8852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1185,
      "total_loss": 0.5824413299560547
    },
    {
      "classification_loss": 0.6618664860725403,
      "epoch": 3.8885245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1186,
      "total_loss": 0.6618664860725403
    },
    {
      "classification_loss": 0.6948312520980835,
      "epoch": 3.8918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1187,
      "total_loss": 0.6948312520980835
    },
    {
      "classification_loss": 0.6204938292503357,
      "epoch": 3.8950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1188,
      "total_loss": 0.6204938292503357
    },
    {
      "classification_loss": 0.62480628490448,
      "epoch": 3.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1189,
      "total_loss": 0.62480628490448
    },
    {
      "classification_loss": 0.6303942203521729,
      "epoch": 3.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1190,
      "total_loss": 0.6303942203521729
    },
    {
      "classification_loss": 0.6034244894981384,
      "epoch": 3.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1191,
      "total_loss": 0.6034244894981384
    },
    {
      "classification_loss": 0.6057844161987305,
      "epoch": 3.9081967213114757,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1192,
      "total_loss": 0.6057844161987305
    },
    {
      "classification_loss": 0.6032863259315491,
      "epoch": 3.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1193,
      "total_loss": 0.6032863259315491
    },
    {
      "classification_loss": 0.5982041358947754,
      "epoch": 3.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1194,
      "total_loss": 0.5982041358947754
    },
    {
      "classification_loss": 0.5758277773857117,
      "epoch": 3.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1195,
      "total_loss": 0.5758277773857117
    },
    {
      "classification_loss": 0.5942794680595398,
      "epoch": 3.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1196,
      "total_loss": 0.5942794680595398
    },
    {
      "classification_loss": 0.6323970556259155,
      "epoch": 3.9245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1197,
      "total_loss": 0.6323970556259155
    },
    {
      "classification_loss": 0.7095960378646851,
      "epoch": 3.9278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1198,
      "total_loss": 0.7095960378646851
    },
    {
      "classification_loss": 0.6213348507881165,
      "epoch": 3.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1199,
      "total_loss": 0.6213348507881165
    },
    {
      "epoch": 3.9344262295081966,
      "grad_norm": 4.178915977478027,
      "learning_rate": 0.00016336666666666666,
      "loss": 0.6271,
      "step": 1200
    },
    {
      "classification_loss": 0.6185882091522217,
      "epoch": 3.9344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1200,
      "total_loss": 0.6185882091522217
    },
    {
      "classification_loss": 0.6030643582344055,
      "epoch": 3.9377049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1201,
      "total_loss": 0.6030643582344055
    },
    {
      "classification_loss": 0.636794924736023,
      "epoch": 3.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1202,
      "total_loss": 0.636794924736023
    },
    {
      "classification_loss": 0.6624141931533813,
      "epoch": 3.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1203,
      "total_loss": 0.6624141931533813
    },
    {
      "classification_loss": 0.6549594402313232,
      "epoch": 3.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1204,
      "total_loss": 0.6549594402313232
    },
    {
      "classification_loss": 0.641276478767395,
      "epoch": 3.9508196721311473,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1205,
      "total_loss": 0.641276478767395
    },
    {
      "classification_loss": 0.6116706728935242,
      "epoch": 3.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1206,
      "total_loss": 0.6116706728935242
    },
    {
      "classification_loss": 0.5953999161720276,
      "epoch": 3.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1207,
      "total_loss": 0.5953999161720276
    },
    {
      "classification_loss": 0.63658607006073,
      "epoch": 3.960655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1208,
      "total_loss": 0.63658607006073
    },
    {
      "classification_loss": 0.5810570120811462,
      "epoch": 3.963934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1209,
      "total_loss": 0.5810570120811462
    },
    {
      "classification_loss": 0.6099850535392761,
      "epoch": 3.9672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1210,
      "total_loss": 0.6099850535392761
    },
    {
      "classification_loss": 0.6335389018058777,
      "epoch": 3.9704918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1211,
      "total_loss": 0.6335389018058777
    },
    {
      "classification_loss": 0.6076453924179077,
      "epoch": 3.9737704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1212,
      "total_loss": 0.6076453924179077
    },
    {
      "classification_loss": 0.7183029651641846,
      "epoch": 3.9770491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1213,
      "total_loss": 0.7183029651641846
    },
    {
      "classification_loss": 0.6700876951217651,
      "epoch": 3.9803278688524593,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1214,
      "total_loss": 0.6700876951217651
    },
    {
      "classification_loss": 0.5573686361312866,
      "epoch": 3.9836065573770494,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1215,
      "total_loss": 0.5573686361312866
    },
    {
      "classification_loss": 0.6862971186637878,
      "epoch": 3.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1216,
      "total_loss": 0.6862971186637878
    },
    {
      "classification_loss": 0.6296688914299011,
      "epoch": 3.9901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1217,
      "total_loss": 0.6296688914299011
    },
    {
      "classification_loss": 0.6013713479042053,
      "epoch": 3.9934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1218,
      "total_loss": 0.6013713479042053
    },
    {
      "classification_loss": 0.6257572174072266,
      "epoch": 3.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1219,
      "total_loss": 0.6257572174072266
    },
    {
      "classification_loss": 0.8643482327461243,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.8643482327461243
    },
    {
      "classification_loss": 0.8351956009864807,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.8351956009864807
    },
    {
      "classification_loss": 0.8148803114891052,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.8148803114891052
    },
    {
      "classification_loss": 0.9006140828132629,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.9006140828132629
    },
    {
      "classification_loss": 0.7979602217674255,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.7979602217674255
    },
    {
      "classification_loss": 0.8121334910392761,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.8121334910392761
    },
    {
      "classification_loss": 0.8156680464744568,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.8156680464744568
    },
    {
      "classification_loss": 0.7639850378036499,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.7639850378036499
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.009448818897637795,
      "eval_loss": 0.82707679271698,
      "eval_precision": 0.6,
      "eval_recall": 0.004761904761904762,
      "eval_runtime": 6.0096,
      "eval_samples_per_second": 166.4,
      "eval_steps_per_second": 1.331,
      "step": 1220
    },
    {
      "classification_loss": 0.5334285497665405,
      "epoch": 4.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1220,
      "total_loss": 0.5334285497665405
    },
    {
      "classification_loss": 0.5034911036491394,
      "epoch": 4.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1221,
      "total_loss": 0.5034911036491394
    },
    {
      "classification_loss": 0.6219667196273804,
      "epoch": 4.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1222,
      "total_loss": 0.6219667196273804
    },
    {
      "classification_loss": 0.6639007329940796,
      "epoch": 4.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1223,
      "total_loss": 0.6639007329940796
    },
    {
      "classification_loss": 0.5670825242996216,
      "epoch": 4.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1224,
      "total_loss": 0.5670825242996216
    },
    {
      "classification_loss": 0.6064474582672119,
      "epoch": 4.016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1225,
      "total_loss": 0.6064474582672119
    },
    {
      "classification_loss": 0.600990355014801,
      "epoch": 4.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1226,
      "total_loss": 0.600990355014801
    },
    {
      "classification_loss": 0.6724435687065125,
      "epoch": 4.022950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1227,
      "total_loss": 0.6724435687065125
    },
    {
      "classification_loss": 0.6395429372787476,
      "epoch": 4.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1228,
      "total_loss": 0.6395429372787476
    },
    {
      "classification_loss": 0.6191545128822327,
      "epoch": 4.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1229,
      "total_loss": 0.6191545128822327
    },
    {
      "classification_loss": 0.6119126081466675,
      "epoch": 4.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1230,
      "total_loss": 0.6119126081466675
    },
    {
      "classification_loss": 0.5728321671485901,
      "epoch": 4.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1231,
      "total_loss": 0.5728321671485901
    },
    {
      "classification_loss": 0.6168491840362549,
      "epoch": 4.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1232,
      "total_loss": 0.6168491840362549
    },
    {
      "classification_loss": 0.5322439670562744,
      "epoch": 4.0426229508196725,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1233,
      "total_loss": 0.5322439670562744
    },
    {
      "classification_loss": 0.6310785412788391,
      "epoch": 4.045901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1234,
      "total_loss": 0.6310785412788391
    },
    {
      "classification_loss": 0.5981759428977966,
      "epoch": 4.049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1235,
      "total_loss": 0.5981759428977966
    },
    {
      "classification_loss": 0.6710205078125,
      "epoch": 4.052459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1236,
      "total_loss": 0.6710205078125
    },
    {
      "classification_loss": 0.5856115818023682,
      "epoch": 4.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1237,
      "total_loss": 0.5856115818023682
    },
    {
      "classification_loss": 0.7196425795555115,
      "epoch": 4.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1238,
      "total_loss": 0.7196425795555115
    },
    {
      "classification_loss": 0.6252133846282959,
      "epoch": 4.062295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1239,
      "total_loss": 0.6252133846282959
    },
    {
      "classification_loss": 0.6539038419723511,
      "epoch": 4.065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1240,
      "total_loss": 0.6539038419723511
    },
    {
      "classification_loss": 0.6334773302078247,
      "epoch": 4.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1241,
      "total_loss": 0.6334773302078247
    },
    {
      "classification_loss": 0.617982804775238,
      "epoch": 4.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1242,
      "total_loss": 0.617982804775238
    },
    {
      "classification_loss": 0.5753446817398071,
      "epoch": 4.075409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1243,
      "total_loss": 0.5753446817398071
    },
    {
      "classification_loss": 0.5648188591003418,
      "epoch": 4.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1244,
      "total_loss": 0.5648188591003418
    },
    {
      "classification_loss": 0.5744845271110535,
      "epoch": 4.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1245,
      "total_loss": 0.5744845271110535
    },
    {
      "classification_loss": 0.6341339349746704,
      "epoch": 4.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1246,
      "total_loss": 0.6341339349746704
    },
    {
      "classification_loss": 0.6062183380126953,
      "epoch": 4.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1247,
      "total_loss": 0.6062183380126953
    },
    {
      "classification_loss": 0.5677247643470764,
      "epoch": 4.091803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1248,
      "total_loss": 0.5677247643470764
    },
    {
      "classification_loss": 0.7205540537834167,
      "epoch": 4.0950819672131145,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1249,
      "total_loss": 0.7205540537834167
    },
    {
      "classification_loss": 0.6465232372283936,
      "epoch": 4.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1250,
      "total_loss": 0.6465232372283936
    },
    {
      "classification_loss": 0.6824342608451843,
      "epoch": 4.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1251,
      "total_loss": 0.6824342608451843
    },
    {
      "classification_loss": 0.7030136585235596,
      "epoch": 4.104918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1252,
      "total_loss": 0.7030136585235596
    },
    {
      "classification_loss": 0.5458102226257324,
      "epoch": 4.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1253,
      "total_loss": 0.5458102226257324
    },
    {
      "classification_loss": 0.6348831653594971,
      "epoch": 4.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1254,
      "total_loss": 0.6348831653594971
    },
    {
      "classification_loss": 0.6759592890739441,
      "epoch": 4.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1255,
      "total_loss": 0.6759592890739441
    },
    {
      "classification_loss": 0.6993638873100281,
      "epoch": 4.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1256,
      "total_loss": 0.6993638873100281
    },
    {
      "classification_loss": 0.6387314200401306,
      "epoch": 4.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1257,
      "total_loss": 0.6387314200401306
    },
    {
      "classification_loss": 0.6291816830635071,
      "epoch": 4.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1258,
      "total_loss": 0.6291816830635071
    },
    {
      "classification_loss": 0.5713538527488708,
      "epoch": 4.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1259,
      "total_loss": 0.5713538527488708
    },
    {
      "classification_loss": 0.589431881904602,
      "epoch": 4.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1260,
      "total_loss": 0.589431881904602
    },
    {
      "classification_loss": 0.5916886925697327,
      "epoch": 4.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1261,
      "total_loss": 0.5916886925697327
    },
    {
      "classification_loss": 0.7394014596939087,
      "epoch": 4.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1262,
      "total_loss": 0.7394014596939087
    },
    {
      "classification_loss": 0.5497375130653381,
      "epoch": 4.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1263,
      "total_loss": 0.5497375130653381
    },
    {
      "classification_loss": 0.668899655342102,
      "epoch": 4.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1264,
      "total_loss": 0.668899655342102
    },
    {
      "classification_loss": 0.5826314091682434,
      "epoch": 4.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1265,
      "total_loss": 0.5826314091682434
    },
    {
      "classification_loss": 0.6912441849708557,
      "epoch": 4.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1266,
      "total_loss": 0.6912441849708557
    },
    {
      "classification_loss": 0.5986135601997375,
      "epoch": 4.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1267,
      "total_loss": 0.5986135601997375
    },
    {
      "classification_loss": 0.587160587310791,
      "epoch": 4.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1268,
      "total_loss": 0.587160587310791
    },
    {
      "classification_loss": 0.6477934718132019,
      "epoch": 4.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1269,
      "total_loss": 0.6477934718132019
    },
    {
      "classification_loss": 0.6364204287528992,
      "epoch": 4.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1270,
      "total_loss": 0.6364204287528992
    },
    {
      "classification_loss": 0.5965926647186279,
      "epoch": 4.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1271,
      "total_loss": 0.5965926647186279
    },
    {
      "classification_loss": 0.627007246017456,
      "epoch": 4.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1272,
      "total_loss": 0.627007246017456
    },
    {
      "classification_loss": 0.6698298454284668,
      "epoch": 4.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1273,
      "total_loss": 0.6698298454284668
    },
    {
      "classification_loss": 0.5672253370285034,
      "epoch": 4.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1274,
      "total_loss": 0.5672253370285034
    },
    {
      "classification_loss": 0.5495153665542603,
      "epoch": 4.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1275,
      "total_loss": 0.5495153665542603
    },
    {
      "classification_loss": 0.6188547611236572,
      "epoch": 4.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1276,
      "total_loss": 0.6188547611236572
    },
    {
      "classification_loss": 0.5170352458953857,
      "epoch": 4.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1277,
      "total_loss": 0.5170352458953857
    },
    {
      "classification_loss": 0.6557828187942505,
      "epoch": 4.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1278,
      "total_loss": 0.6557828187942505
    },
    {
      "classification_loss": 0.5736050009727478,
      "epoch": 4.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1279,
      "total_loss": 0.5736050009727478
    },
    {
      "classification_loss": 0.6362711787223816,
      "epoch": 4.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1280,
      "total_loss": 0.6362711787223816
    },
    {
      "classification_loss": 0.6022069454193115,
      "epoch": 4.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1281,
      "total_loss": 0.6022069454193115
    },
    {
      "classification_loss": 0.5939323306083679,
      "epoch": 4.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1282,
      "total_loss": 0.5939323306083679
    },
    {
      "classification_loss": 0.6000717878341675,
      "epoch": 4.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1283,
      "total_loss": 0.6000717878341675
    },
    {
      "classification_loss": 0.6810312867164612,
      "epoch": 4.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1284,
      "total_loss": 0.6810312867164612
    },
    {
      "classification_loss": 0.5926063060760498,
      "epoch": 4.213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1285,
      "total_loss": 0.5926063060760498
    },
    {
      "classification_loss": 0.6172260642051697,
      "epoch": 4.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1286,
      "total_loss": 0.6172260642051697
    },
    {
      "classification_loss": 0.6978726387023926,
      "epoch": 4.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1287,
      "total_loss": 0.6978726387023926
    },
    {
      "classification_loss": 0.5408263206481934,
      "epoch": 4.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1288,
      "total_loss": 0.5408263206481934
    },
    {
      "classification_loss": 0.5898886919021606,
      "epoch": 4.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1289,
      "total_loss": 0.5898886919021606
    },
    {
      "classification_loss": 0.6914870142936707,
      "epoch": 4.229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1290,
      "total_loss": 0.6914870142936707
    },
    {
      "classification_loss": 0.6059459447860718,
      "epoch": 4.232786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1291,
      "total_loss": 0.6059459447860718
    },
    {
      "classification_loss": 0.6174843311309814,
      "epoch": 4.2360655737704915,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1292,
      "total_loss": 0.6174843311309814
    },
    {
      "classification_loss": 0.4993628263473511,
      "epoch": 4.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1293,
      "total_loss": 0.4993628263473511
    },
    {
      "classification_loss": 0.5477465987205505,
      "epoch": 4.242622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1294,
      "total_loss": 0.5477465987205505
    },
    {
      "classification_loss": 0.6513434648513794,
      "epoch": 4.245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1295,
      "total_loss": 0.6513434648513794
    },
    {
      "classification_loss": 0.6152762770652771,
      "epoch": 4.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1296,
      "total_loss": 0.6152762770652771
    },
    {
      "classification_loss": 0.6048642992973328,
      "epoch": 4.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1297,
      "total_loss": 0.6048642992973328
    },
    {
      "classification_loss": 0.649816632270813,
      "epoch": 4.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1298,
      "total_loss": 0.649816632270813
    },
    {
      "classification_loss": 0.6367855668067932,
      "epoch": 4.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1299,
      "total_loss": 0.6367855668067932
    },
    {
      "epoch": 4.262295081967213,
      "grad_norm": 1.664127230644226,
      "learning_rate": 0.00016003333333333334,
      "loss": 0.6188,
      "step": 1300
    },
    {
      "classification_loss": 0.6370482444763184,
      "epoch": 4.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1300,
      "total_loss": 0.6370482444763184
    },
    {
      "classification_loss": 0.5862963199615479,
      "epoch": 4.2655737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1301,
      "total_loss": 0.5862963199615479
    },
    {
      "classification_loss": 0.590988278388977,
      "epoch": 4.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1302,
      "total_loss": 0.590988278388977
    },
    {
      "classification_loss": 0.7040570378303528,
      "epoch": 4.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1303,
      "total_loss": 0.7040570378303528
    },
    {
      "classification_loss": 0.6336939930915833,
      "epoch": 4.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1304,
      "total_loss": 0.6336939930915833
    },
    {
      "classification_loss": 0.6391438841819763,
      "epoch": 4.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1305,
      "total_loss": 0.6391438841819763
    },
    {
      "classification_loss": 0.641226589679718,
      "epoch": 4.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1306,
      "total_loss": 0.641226589679718
    },
    {
      "classification_loss": 0.5670445561408997,
      "epoch": 4.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1307,
      "total_loss": 0.5670445561408997
    },
    {
      "classification_loss": 0.5640461444854736,
      "epoch": 4.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1308,
      "total_loss": 0.5640461444854736
    },
    {
      "classification_loss": 0.5655810236930847,
      "epoch": 4.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1309,
      "total_loss": 0.5655810236930847
    },
    {
      "classification_loss": 0.6442525386810303,
      "epoch": 4.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1310,
      "total_loss": 0.6442525386810303
    },
    {
      "classification_loss": 0.699187695980072,
      "epoch": 4.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1311,
      "total_loss": 0.699187695980072
    },
    {
      "classification_loss": 0.5997182130813599,
      "epoch": 4.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1312,
      "total_loss": 0.5997182130813599
    },
    {
      "classification_loss": 0.6317111253738403,
      "epoch": 4.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1313,
      "total_loss": 0.6317111253738403
    },
    {
      "classification_loss": 0.6238917708396912,
      "epoch": 4.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1314,
      "total_loss": 0.6238917708396912
    },
    {
      "classification_loss": 0.560796856880188,
      "epoch": 4.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1315,
      "total_loss": 0.560796856880188
    },
    {
      "classification_loss": 0.5513686537742615,
      "epoch": 4.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1316,
      "total_loss": 0.5513686537742615
    },
    {
      "classification_loss": 0.6047563552856445,
      "epoch": 4.3180327868852455,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1317,
      "total_loss": 0.6047563552856445
    },
    {
      "classification_loss": 0.5721820592880249,
      "epoch": 4.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1318,
      "total_loss": 0.5721820592880249
    },
    {
      "classification_loss": 0.7131564021110535,
      "epoch": 4.324590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1319,
      "total_loss": 0.7131564021110535
    },
    {
      "classification_loss": 0.632783830165863,
      "epoch": 4.327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1320,
      "total_loss": 0.632783830165863
    },
    {
      "classification_loss": 0.6432363390922546,
      "epoch": 4.331147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1321,
      "total_loss": 0.6432363390922546
    },
    {
      "classification_loss": 0.5497670769691467,
      "epoch": 4.334426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1322,
      "total_loss": 0.5497670769691467
    },
    {
      "classification_loss": 0.5885797142982483,
      "epoch": 4.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1323,
      "total_loss": 0.5885797142982483
    },
    {
      "classification_loss": 0.5626479387283325,
      "epoch": 4.340983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1324,
      "total_loss": 0.5626479387283325
    },
    {
      "classification_loss": 0.6483970880508423,
      "epoch": 4.344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1325,
      "total_loss": 0.6483970880508423
    },
    {
      "classification_loss": 0.5798713564872742,
      "epoch": 4.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1326,
      "total_loss": 0.5798713564872742
    },
    {
      "classification_loss": 0.617935299873352,
      "epoch": 4.350819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1327,
      "total_loss": 0.617935299873352
    },
    {
      "classification_loss": 0.625336766242981,
      "epoch": 4.354098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1328,
      "total_loss": 0.625336766242981
    },
    {
      "classification_loss": 0.6306458115577698,
      "epoch": 4.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1329,
      "total_loss": 0.6306458115577698
    },
    {
      "classification_loss": 0.6256660223007202,
      "epoch": 4.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1330,
      "total_loss": 0.6256660223007202
    },
    {
      "classification_loss": 0.661848247051239,
      "epoch": 4.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1331,
      "total_loss": 0.661848247051239
    },
    {
      "classification_loss": 0.5774208903312683,
      "epoch": 4.367213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1332,
      "total_loss": 0.5774208903312683
    },
    {
      "classification_loss": 0.5757571458816528,
      "epoch": 4.370491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1333,
      "total_loss": 0.5757571458816528
    },
    {
      "classification_loss": 0.6148219704627991,
      "epoch": 4.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1334,
      "total_loss": 0.6148219704627991
    },
    {
      "classification_loss": 0.6338549256324768,
      "epoch": 4.377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1335,
      "total_loss": 0.6338549256324768
    },
    {
      "classification_loss": 0.6287692785263062,
      "epoch": 4.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1336,
      "total_loss": 0.6287692785263062
    },
    {
      "classification_loss": 0.504151463508606,
      "epoch": 4.383606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1337,
      "total_loss": 0.504151463508606
    },
    {
      "classification_loss": 0.7237502932548523,
      "epoch": 4.386885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1338,
      "total_loss": 0.7237502932548523
    },
    {
      "classification_loss": 0.6263548135757446,
      "epoch": 4.390163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1339,
      "total_loss": 0.6263548135757446
    },
    {
      "classification_loss": 0.6338133811950684,
      "epoch": 4.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1340,
      "total_loss": 0.6338133811950684
    },
    {
      "classification_loss": 0.6325380206108093,
      "epoch": 4.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1341,
      "total_loss": 0.6325380206108093
    },
    {
      "classification_loss": 0.6752043962478638,
      "epoch": 4.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1342,
      "total_loss": 0.6752043962478638
    },
    {
      "classification_loss": 0.6438328623771667,
      "epoch": 4.4032786885245905,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1343,
      "total_loss": 0.6438328623771667
    },
    {
      "classification_loss": 0.6784514784812927,
      "epoch": 4.406557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1344,
      "total_loss": 0.6784514784812927
    },
    {
      "classification_loss": 0.6900307536125183,
      "epoch": 4.409836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1345,
      "total_loss": 0.6900307536125183
    },
    {
      "classification_loss": 0.6430552005767822,
      "epoch": 4.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1346,
      "total_loss": 0.6430552005767822
    },
    {
      "classification_loss": 0.6332566738128662,
      "epoch": 4.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1347,
      "total_loss": 0.6332566738128662
    },
    {
      "classification_loss": 0.5686779022216797,
      "epoch": 4.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1348,
      "total_loss": 0.5686779022216797
    },
    {
      "classification_loss": 0.6242983341217041,
      "epoch": 4.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1349,
      "total_loss": 0.6242983341217041
    },
    {
      "classification_loss": 0.5511518120765686,
      "epoch": 4.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1350,
      "total_loss": 0.5511518120765686
    },
    {
      "classification_loss": 0.6525681614875793,
      "epoch": 4.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1351,
      "total_loss": 0.6525681614875793
    },
    {
      "classification_loss": 0.5969465374946594,
      "epoch": 4.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1352,
      "total_loss": 0.5969465374946594
    },
    {
      "classification_loss": 0.6676412224769592,
      "epoch": 4.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1353,
      "total_loss": 0.6676412224769592
    },
    {
      "classification_loss": 0.6152837872505188,
      "epoch": 4.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1354,
      "total_loss": 0.6152837872505188
    },
    {
      "classification_loss": 0.5457140803337097,
      "epoch": 4.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1355,
      "total_loss": 0.5457140803337097
    },
    {
      "classification_loss": 0.5779566168785095,
      "epoch": 4.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1356,
      "total_loss": 0.5779566168785095
    },
    {
      "classification_loss": 0.570010244846344,
      "epoch": 4.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1357,
      "total_loss": 0.570010244846344
    },
    {
      "classification_loss": 0.5641583800315857,
      "epoch": 4.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1358,
      "total_loss": 0.5641583800315857
    },
    {
      "classification_loss": 0.49657219648361206,
      "epoch": 4.4557377049180324,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1359,
      "total_loss": 0.49657219648361206
    },
    {
      "classification_loss": 0.6227476596832275,
      "epoch": 4.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1360,
      "total_loss": 0.6227476596832275
    },
    {
      "classification_loss": 0.5842375159263611,
      "epoch": 4.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1361,
      "total_loss": 0.5842375159263611
    },
    {
      "classification_loss": 0.6218135952949524,
      "epoch": 4.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1362,
      "total_loss": 0.6218135952949524
    },
    {
      "classification_loss": 0.59451824426651,
      "epoch": 4.468852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1363,
      "total_loss": 0.59451824426651
    },
    {
      "classification_loss": 0.6106052994728088,
      "epoch": 4.472131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1364,
      "total_loss": 0.6106052994728088
    },
    {
      "classification_loss": 0.5999407172203064,
      "epoch": 4.475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1365,
      "total_loss": 0.5999407172203064
    },
    {
      "classification_loss": 0.6557719111442566,
      "epoch": 4.478688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1366,
      "total_loss": 0.6557719111442566
    },
    {
      "classification_loss": 0.6020012497901917,
      "epoch": 4.481967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1367,
      "total_loss": 0.6020012497901917
    },
    {
      "classification_loss": 0.5742073059082031,
      "epoch": 4.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1368,
      "total_loss": 0.5742073059082031
    },
    {
      "classification_loss": 0.5899466276168823,
      "epoch": 4.488524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1369,
      "total_loss": 0.5899466276168823
    },
    {
      "classification_loss": 0.5193959474563599,
      "epoch": 4.491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1370,
      "total_loss": 0.5193959474563599
    },
    {
      "classification_loss": 0.5596458315849304,
      "epoch": 4.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1371,
      "total_loss": 0.5596458315849304
    },
    {
      "classification_loss": 0.6320549249649048,
      "epoch": 4.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1372,
      "total_loss": 0.6320549249649048
    },
    {
      "classification_loss": 0.5676828622817993,
      "epoch": 4.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1373,
      "total_loss": 0.5676828622817993
    },
    {
      "classification_loss": 0.5696626305580139,
      "epoch": 4.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1374,
      "total_loss": 0.5696626305580139
    },
    {
      "classification_loss": 0.6719072461128235,
      "epoch": 4.508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1375,
      "total_loss": 0.6719072461128235
    },
    {
      "classification_loss": 0.622886061668396,
      "epoch": 4.511475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1376,
      "total_loss": 0.622886061668396
    },
    {
      "classification_loss": 0.5999605059623718,
      "epoch": 4.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1377,
      "total_loss": 0.5999605059623718
    },
    {
      "classification_loss": 0.5925474762916565,
      "epoch": 4.518032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1378,
      "total_loss": 0.5925474762916565
    },
    {
      "classification_loss": 0.5273272395133972,
      "epoch": 4.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1379,
      "total_loss": 0.5273272395133972
    },
    {
      "classification_loss": 0.5912189483642578,
      "epoch": 4.524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1380,
      "total_loss": 0.5912189483642578
    },
    {
      "classification_loss": 0.6253887414932251,
      "epoch": 4.527868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1381,
      "total_loss": 0.6253887414932251
    },
    {
      "classification_loss": 0.6320371627807617,
      "epoch": 4.531147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1382,
      "total_loss": 0.6320371627807617
    },
    {
      "classification_loss": 0.6162731051445007,
      "epoch": 4.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1383,
      "total_loss": 0.6162731051445007
    },
    {
      "classification_loss": 0.6810347437858582,
      "epoch": 4.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1384,
      "total_loss": 0.6810347437858582
    },
    {
      "classification_loss": 0.6418379545211792,
      "epoch": 4.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1385,
      "total_loss": 0.6418379545211792
    },
    {
      "classification_loss": 0.6949424147605896,
      "epoch": 4.5442622950819676,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1386,
      "total_loss": 0.6949424147605896
    },
    {
      "classification_loss": 0.652403712272644,
      "epoch": 4.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1387,
      "total_loss": 0.652403712272644
    },
    {
      "classification_loss": 0.6912940740585327,
      "epoch": 4.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1388,
      "total_loss": 0.6912940740585327
    },
    {
      "classification_loss": 0.6709737181663513,
      "epoch": 4.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1389,
      "total_loss": 0.6709737181663513
    },
    {
      "classification_loss": 0.516912043094635,
      "epoch": 4.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1390,
      "total_loss": 0.516912043094635
    },
    {
      "classification_loss": 0.6007283926010132,
      "epoch": 4.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1391,
      "total_loss": 0.6007283926010132
    },
    {
      "classification_loss": 0.6521639823913574,
      "epoch": 4.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1392,
      "total_loss": 0.6521639823913574
    },
    {
      "classification_loss": 0.5566262602806091,
      "epoch": 4.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1393,
      "total_loss": 0.5566262602806091
    },
    {
      "classification_loss": 0.6835458278656006,
      "epoch": 4.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1394,
      "total_loss": 0.6835458278656006
    },
    {
      "classification_loss": 0.7109161615371704,
      "epoch": 4.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1395,
      "total_loss": 0.7109161615371704
    },
    {
      "classification_loss": 0.6480072140693665,
      "epoch": 4.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1396,
      "total_loss": 0.6480072140693665
    },
    {
      "classification_loss": 0.5362540483474731,
      "epoch": 4.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1397,
      "total_loss": 0.5362540483474731
    },
    {
      "classification_loss": 0.6556361317634583,
      "epoch": 4.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1398,
      "total_loss": 0.6556361317634583
    },
    {
      "classification_loss": 0.6665355563163757,
      "epoch": 4.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1399,
      "total_loss": 0.6665355563163757
    },
    {
      "epoch": 4.590163934426229,
      "grad_norm": 2.022935628890991,
      "learning_rate": 0.00015670000000000001,
      "loss": 0.6149,
      "step": 1400
    },
    {
      "classification_loss": 0.5802262425422668,
      "epoch": 4.590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1400,
      "total_loss": 0.5802262425422668
    },
    {
      "classification_loss": 0.602824866771698,
      "epoch": 4.593442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1401,
      "total_loss": 0.602824866771698
    },
    {
      "classification_loss": 0.5065091252326965,
      "epoch": 4.5967213114754095,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1402,
      "total_loss": 0.5065091252326965
    },
    {
      "classification_loss": 0.6327073574066162,
      "epoch": 4.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1403,
      "total_loss": 0.6327073574066162
    },
    {
      "classification_loss": 0.6406164765357971,
      "epoch": 4.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1404,
      "total_loss": 0.6406164765357971
    },
    {
      "classification_loss": 0.7187238931655884,
      "epoch": 4.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1405,
      "total_loss": 0.7187238931655884
    },
    {
      "classification_loss": 0.6656099557876587,
      "epoch": 4.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1406,
      "total_loss": 0.6656099557876587
    },
    {
      "classification_loss": 0.6848244071006775,
      "epoch": 4.613114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1407,
      "total_loss": 0.6848244071006775
    },
    {
      "classification_loss": 0.534838080406189,
      "epoch": 4.616393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1408,
      "total_loss": 0.534838080406189
    },
    {
      "classification_loss": 0.6082494258880615,
      "epoch": 4.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1409,
      "total_loss": 0.6082494258880615
    },
    {
      "classification_loss": 0.5394712686538696,
      "epoch": 4.622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1410,
      "total_loss": 0.5394712686538696
    },
    {
      "classification_loss": 0.6804863214492798,
      "epoch": 4.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1411,
      "total_loss": 0.6804863214492798
    },
    {
      "classification_loss": 0.6429297924041748,
      "epoch": 4.629508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1412,
      "total_loss": 0.6429297924041748
    },
    {
      "classification_loss": 0.6630289554595947,
      "epoch": 4.632786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1413,
      "total_loss": 0.6630289554595947
    },
    {
      "classification_loss": 0.5708599090576172,
      "epoch": 4.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1414,
      "total_loss": 0.5708599090576172
    },
    {
      "classification_loss": 0.7441596984863281,
      "epoch": 4.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1415,
      "total_loss": 0.7441596984863281
    },
    {
      "classification_loss": 0.5457546710968018,
      "epoch": 4.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1416,
      "total_loss": 0.5457546710968018
    },
    {
      "classification_loss": 0.6295934319496155,
      "epoch": 4.645901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1417,
      "total_loss": 0.6295934319496155
    },
    {
      "classification_loss": 0.6232603192329407,
      "epoch": 4.649180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1418,
      "total_loss": 0.6232603192329407
    },
    {
      "classification_loss": 0.6330050826072693,
      "epoch": 4.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1419,
      "total_loss": 0.6330050826072693
    },
    {
      "classification_loss": 0.5723171234130859,
      "epoch": 4.655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1420,
      "total_loss": 0.5723171234130859
    },
    {
      "classification_loss": 0.5773890614509583,
      "epoch": 4.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1421,
      "total_loss": 0.5773890614509583
    },
    {
      "classification_loss": 0.6340546011924744,
      "epoch": 4.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1422,
      "total_loss": 0.6340546011924744
    },
    {
      "classification_loss": 0.5603237152099609,
      "epoch": 4.665573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1423,
      "total_loss": 0.5603237152099609
    },
    {
      "classification_loss": 0.6813889145851135,
      "epoch": 4.668852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1424,
      "total_loss": 0.6813889145851135
    },
    {
      "classification_loss": 0.5734073519706726,
      "epoch": 4.672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1425,
      "total_loss": 0.5734073519706726
    },
    {
      "classification_loss": 0.6716152429580688,
      "epoch": 4.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1426,
      "total_loss": 0.6716152429580688
    },
    {
      "classification_loss": 0.5833923816680908,
      "epoch": 4.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1427,
      "total_loss": 0.5833923816680908
    },
    {
      "classification_loss": 0.6378040313720703,
      "epoch": 4.6819672131147545,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1428,
      "total_loss": 0.6378040313720703
    },
    {
      "classification_loss": 0.657463788986206,
      "epoch": 4.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1429,
      "total_loss": 0.657463788986206
    },
    {
      "classification_loss": 0.5945281386375427,
      "epoch": 4.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1430,
      "total_loss": 0.5945281386375427
    },
    {
      "classification_loss": 0.6690351366996765,
      "epoch": 4.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1431,
      "total_loss": 0.6690351366996765
    },
    {
      "classification_loss": 0.612931489944458,
      "epoch": 4.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1432,
      "total_loss": 0.612931489944458
    },
    {
      "classification_loss": 0.6456058621406555,
      "epoch": 4.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1433,
      "total_loss": 0.6456058621406555
    },
    {
      "classification_loss": 0.6302449703216553,
      "epoch": 4.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1434,
      "total_loss": 0.6302449703216553
    },
    {
      "classification_loss": 0.5479193925857544,
      "epoch": 4.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1435,
      "total_loss": 0.5479193925857544
    },
    {
      "classification_loss": 0.6021906137466431,
      "epoch": 4.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1436,
      "total_loss": 0.6021906137466431
    },
    {
      "classification_loss": 0.6155139803886414,
      "epoch": 4.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1437,
      "total_loss": 0.6155139803886414
    },
    {
      "classification_loss": 0.535419762134552,
      "epoch": 4.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1438,
      "total_loss": 0.535419762134552
    },
    {
      "classification_loss": 0.596276044845581,
      "epoch": 4.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1439,
      "total_loss": 0.596276044845581
    },
    {
      "classification_loss": 0.5838643908500671,
      "epoch": 4.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1440,
      "total_loss": 0.5838643908500671
    },
    {
      "classification_loss": 0.5823084712028503,
      "epoch": 4.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1441,
      "total_loss": 0.5823084712028503
    },
    {
      "classification_loss": 0.5719428658485413,
      "epoch": 4.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1442,
      "total_loss": 0.5719428658485413
    },
    {
      "classification_loss": 0.589242160320282,
      "epoch": 4.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1443,
      "total_loss": 0.589242160320282
    },
    {
      "classification_loss": 0.6964853405952454,
      "epoch": 4.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1444,
      "total_loss": 0.6964853405952454
    },
    {
      "classification_loss": 0.6596203446388245,
      "epoch": 4.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1445,
      "total_loss": 0.6596203446388245
    },
    {
      "classification_loss": 0.5999756455421448,
      "epoch": 4.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1446,
      "total_loss": 0.5999756455421448
    },
    {
      "classification_loss": 0.6108867526054382,
      "epoch": 4.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1447,
      "total_loss": 0.6108867526054382
    },
    {
      "classification_loss": 0.5542850494384766,
      "epoch": 4.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1448,
      "total_loss": 0.5542850494384766
    },
    {
      "classification_loss": 0.678331196308136,
      "epoch": 4.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1449,
      "total_loss": 0.678331196308136
    },
    {
      "classification_loss": 0.5807459354400635,
      "epoch": 4.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1450,
      "total_loss": 0.5807459354400635
    },
    {
      "classification_loss": 0.49327757954597473,
      "epoch": 4.757377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1451,
      "total_loss": 0.49327757954597473
    },
    {
      "classification_loss": 0.5539350509643555,
      "epoch": 4.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1452,
      "total_loss": 0.5539350509643555
    },
    {
      "classification_loss": 0.6757616400718689,
      "epoch": 4.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1453,
      "total_loss": 0.6757616400718689
    },
    {
      "classification_loss": 0.5822446346282959,
      "epoch": 4.767213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1454,
      "total_loss": 0.5822446346282959
    },
    {
      "classification_loss": 0.6334037780761719,
      "epoch": 4.770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1455,
      "total_loss": 0.6334037780761719
    },
    {
      "classification_loss": 0.6515371799468994,
      "epoch": 4.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1456,
      "total_loss": 0.6515371799468994
    },
    {
      "classification_loss": 0.5325434803962708,
      "epoch": 4.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1457,
      "total_loss": 0.5325434803962708
    },
    {
      "classification_loss": 0.643088161945343,
      "epoch": 4.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1458,
      "total_loss": 0.643088161945343
    },
    {
      "classification_loss": 0.591598629951477,
      "epoch": 4.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1459,
      "total_loss": 0.591598629951477
    },
    {
      "classification_loss": 0.5771383047103882,
      "epoch": 4.786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1460,
      "total_loss": 0.5771383047103882
    },
    {
      "classification_loss": 0.6282232999801636,
      "epoch": 4.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1461,
      "total_loss": 0.6282232999801636
    },
    {
      "classification_loss": 0.6169959902763367,
      "epoch": 4.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1462,
      "total_loss": 0.6169959902763367
    },
    {
      "classification_loss": 0.597118616104126,
      "epoch": 4.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1463,
      "total_loss": 0.597118616104126
    },
    {
      "classification_loss": 0.6193616390228271,
      "epoch": 4.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1464,
      "total_loss": 0.6193616390228271
    },
    {
      "classification_loss": 0.7381879091262817,
      "epoch": 4.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1465,
      "total_loss": 0.7381879091262817
    },
    {
      "classification_loss": 0.6327188611030579,
      "epoch": 4.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1466,
      "total_loss": 0.6327188611030579
    },
    {
      "classification_loss": 0.601210355758667,
      "epoch": 4.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1467,
      "total_loss": 0.601210355758667
    },
    {
      "classification_loss": 0.6204874515533447,
      "epoch": 4.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1468,
      "total_loss": 0.6204874515533447
    },
    {
      "classification_loss": 0.6089308261871338,
      "epoch": 4.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1469,
      "total_loss": 0.6089308261871338
    },
    {
      "classification_loss": 0.6305131912231445,
      "epoch": 4.8196721311475414,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1470,
      "total_loss": 0.6305131912231445
    },
    {
      "classification_loss": 0.6772041320800781,
      "epoch": 4.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1471,
      "total_loss": 0.6772041320800781
    },
    {
      "classification_loss": 0.6538732051849365,
      "epoch": 4.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1472,
      "total_loss": 0.6538732051849365
    },
    {
      "classification_loss": 0.6183979511260986,
      "epoch": 4.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1473,
      "total_loss": 0.6183979511260986
    },
    {
      "classification_loss": 0.5237435698509216,
      "epoch": 4.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1474,
      "total_loss": 0.5237435698509216
    },
    {
      "classification_loss": 0.679257869720459,
      "epoch": 4.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1475,
      "total_loss": 0.679257869720459
    },
    {
      "classification_loss": 0.5708352327346802,
      "epoch": 4.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1476,
      "total_loss": 0.5708352327346802
    },
    {
      "classification_loss": 0.6174558401107788,
      "epoch": 4.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1477,
      "total_loss": 0.6174558401107788
    },
    {
      "classification_loss": 0.631921648979187,
      "epoch": 4.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1478,
      "total_loss": 0.631921648979187
    },
    {
      "classification_loss": 0.5952916145324707,
      "epoch": 4.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1479,
      "total_loss": 0.5952916145324707
    },
    {
      "classification_loss": 0.572384774684906,
      "epoch": 4.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1480,
      "total_loss": 0.572384774684906
    },
    {
      "classification_loss": 0.6426143646240234,
      "epoch": 4.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1481,
      "total_loss": 0.6426143646240234
    },
    {
      "classification_loss": 0.6005951762199402,
      "epoch": 4.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1482,
      "total_loss": 0.6005951762199402
    },
    {
      "classification_loss": 0.6066238880157471,
      "epoch": 4.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1483,
      "total_loss": 0.6066238880157471
    },
    {
      "classification_loss": 0.6129755973815918,
      "epoch": 4.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1484,
      "total_loss": 0.6129755973815918
    },
    {
      "classification_loss": 0.7210013270378113,
      "epoch": 4.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1485,
      "total_loss": 0.7210013270378113
    },
    {
      "classification_loss": 0.6132560968399048,
      "epoch": 4.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1486,
      "total_loss": 0.6132560968399048
    },
    {
      "classification_loss": 0.6648959517478943,
      "epoch": 4.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1487,
      "total_loss": 0.6648959517478943
    },
    {
      "classification_loss": 0.579983115196228,
      "epoch": 4.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1488,
      "total_loss": 0.579983115196228
    },
    {
      "classification_loss": 0.6198024153709412,
      "epoch": 4.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1489,
      "total_loss": 0.6198024153709412
    },
    {
      "classification_loss": 0.5582086443901062,
      "epoch": 4.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1490,
      "total_loss": 0.5582086443901062
    },
    {
      "classification_loss": 0.5637299418449402,
      "epoch": 4.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1491,
      "total_loss": 0.5637299418449402
    },
    {
      "classification_loss": 0.6098572611808777,
      "epoch": 4.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1492,
      "total_loss": 0.6098572611808777
    },
    {
      "classification_loss": 0.5764316916465759,
      "epoch": 4.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1493,
      "total_loss": 0.5764316916465759
    },
    {
      "classification_loss": 0.6418242454528809,
      "epoch": 4.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1494,
      "total_loss": 0.6418242454528809
    },
    {
      "classification_loss": 0.5161649584770203,
      "epoch": 4.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1495,
      "total_loss": 0.5161649584770203
    },
    {
      "classification_loss": 0.5547545552253723,
      "epoch": 4.9049180327868855,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1496,
      "total_loss": 0.5547545552253723
    },
    {
      "classification_loss": 0.6770390868186951,
      "epoch": 4.908196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1497,
      "total_loss": 0.6770390868186951
    },
    {
      "classification_loss": 0.5151958465576172,
      "epoch": 4.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1498,
      "total_loss": 0.5151958465576172
    },
    {
      "classification_loss": 0.6009490489959717,
      "epoch": 4.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1499,
      "total_loss": 0.6009490489959717
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 3.3738842010498047,
      "learning_rate": 0.0001533666666666667,
      "loss": 0.612,
      "step": 1500
    },
    {
      "classification_loss": 0.5180524587631226,
      "epoch": 4.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1500,
      "total_loss": 0.5180524587631226
    },
    {
      "classification_loss": 0.6664366126060486,
      "epoch": 4.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1501,
      "total_loss": 0.6664366126060486
    },
    {
      "classification_loss": 0.6937834024429321,
      "epoch": 4.924590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1502,
      "total_loss": 0.6937834024429321
    },
    {
      "classification_loss": 0.7206858992576599,
      "epoch": 4.927868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1503,
      "total_loss": 0.7206858992576599
    },
    {
      "classification_loss": 0.6322591304779053,
      "epoch": 4.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1504,
      "total_loss": 0.6322591304779053
    },
    {
      "classification_loss": 0.629467785358429,
      "epoch": 4.934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1505,
      "total_loss": 0.629467785358429
    },
    {
      "classification_loss": 0.6099069118499756,
      "epoch": 4.937704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1506,
      "total_loss": 0.6099069118499756
    },
    {
      "classification_loss": 0.579878568649292,
      "epoch": 4.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1507,
      "total_loss": 0.579878568649292
    },
    {
      "classification_loss": 0.6222012042999268,
      "epoch": 4.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1508,
      "total_loss": 0.6222012042999268
    },
    {
      "classification_loss": 0.5786590576171875,
      "epoch": 4.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1509,
      "total_loss": 0.5786590576171875
    },
    {
      "classification_loss": 0.5829073786735535,
      "epoch": 4.950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1510,
      "total_loss": 0.5829073786735535
    },
    {
      "classification_loss": 0.6704398989677429,
      "epoch": 4.954098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1511,
      "total_loss": 0.6704398989677429
    },
    {
      "classification_loss": 0.6392284631729126,
      "epoch": 4.9573770491803275,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1512,
      "total_loss": 0.6392284631729126
    },
    {
      "classification_loss": 0.5982922911643982,
      "epoch": 4.9606557377049185,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1513,
      "total_loss": 0.5982922911643982
    },
    {
      "classification_loss": 0.648367702960968,
      "epoch": 4.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1514,
      "total_loss": 0.648367702960968
    },
    {
      "classification_loss": 0.5569722652435303,
      "epoch": 4.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1515,
      "total_loss": 0.5569722652435303
    },
    {
      "classification_loss": 0.6504996418952942,
      "epoch": 4.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1516,
      "total_loss": 0.6504996418952942
    },
    {
      "classification_loss": 0.5489656329154968,
      "epoch": 4.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1517,
      "total_loss": 0.5489656329154968
    },
    {
      "classification_loss": 0.5668359994888306,
      "epoch": 4.977049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1518,
      "total_loss": 0.5668359994888306
    },
    {
      "classification_loss": 0.6903090476989746,
      "epoch": 4.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1519,
      "total_loss": 0.6903090476989746
    },
    {
      "classification_loss": 0.5722302198410034,
      "epoch": 4.983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1520,
      "total_loss": 0.5722302198410034
    },
    {
      "classification_loss": 0.619776725769043,
      "epoch": 4.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1521,
      "total_loss": 0.619776725769043
    },
    {
      "classification_loss": 0.6290905475616455,
      "epoch": 4.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1522,
      "total_loss": 0.6290905475616455
    },
    {
      "classification_loss": 0.607042670249939,
      "epoch": 4.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1523,
      "total_loss": 0.607042670249939
    },
    {
      "classification_loss": 0.5477498173713684,
      "epoch": 4.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1524,
      "total_loss": 0.5477498173713684
    },
    {
      "classification_loss": 0.8396775722503662,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.8396775722503662
    },
    {
      "classification_loss": 0.8147397041320801,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.8147397041320801
    },
    {
      "classification_loss": 0.8098332285881042,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.8098332285881042
    },
    {
      "classification_loss": 0.8876641988754272,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.8876641988754272
    },
    {
      "classification_loss": 0.7906672358512878,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.7906672358512878
    },
    {
      "classification_loss": 0.7953630089759827,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.7953630089759827
    },
    {
      "classification_loss": 0.8067747354507446,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.8067747354507446
    },
    {
      "classification_loss": 0.7500905394554138,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.7500905394554138
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.377,
      "eval_f1": 0.043010752688172046,
      "eval_loss": 0.8133336305618286,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.022222222222222223,
      "eval_runtime": 6.0307,
      "eval_samples_per_second": 165.818,
      "eval_steps_per_second": 1.327,
      "step": 1525
    },
    {
      "classification_loss": 0.5608336925506592,
      "epoch": 5.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1525,
      "total_loss": 0.5608336925506592
    },
    {
      "classification_loss": 0.5898687839508057,
      "epoch": 5.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1526,
      "total_loss": 0.5898687839508057
    },
    {
      "classification_loss": 0.6637603044509888,
      "epoch": 5.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1527,
      "total_loss": 0.6637603044509888
    },
    {
      "classification_loss": 0.593955934047699,
      "epoch": 5.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1528,
      "total_loss": 0.593955934047699
    },
    {
      "classification_loss": 0.6609741449356079,
      "epoch": 5.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1529,
      "total_loss": 0.6609741449356079
    },
    {
      "classification_loss": 0.5648731589317322,
      "epoch": 5.016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1530,
      "total_loss": 0.5648731589317322
    },
    {
      "classification_loss": 0.5929698944091797,
      "epoch": 5.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1531,
      "total_loss": 0.5929698944091797
    },
    {
      "classification_loss": 0.5762847661972046,
      "epoch": 5.022950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1532,
      "total_loss": 0.5762847661972046
    },
    {
      "classification_loss": 0.5371336340904236,
      "epoch": 5.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1533,
      "total_loss": 0.5371336340904236
    },
    {
      "classification_loss": 0.5840566754341125,
      "epoch": 5.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1534,
      "total_loss": 0.5840566754341125
    },
    {
      "classification_loss": 0.602897584438324,
      "epoch": 5.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1535,
      "total_loss": 0.602897584438324
    },
    {
      "classification_loss": 0.5043368935585022,
      "epoch": 5.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1536,
      "total_loss": 0.5043368935585022
    },
    {
      "classification_loss": 0.5269388556480408,
      "epoch": 5.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1537,
      "total_loss": 0.5269388556480408
    },
    {
      "classification_loss": 0.6331909894943237,
      "epoch": 5.0426229508196725,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1538,
      "total_loss": 0.6331909894943237
    },
    {
      "classification_loss": 0.6130141019821167,
      "epoch": 5.045901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1539,
      "total_loss": 0.6130141019821167
    },
    {
      "classification_loss": 0.5986696481704712,
      "epoch": 5.049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1540,
      "total_loss": 0.5986696481704712
    },
    {
      "classification_loss": 0.6080790162086487,
      "epoch": 5.052459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1541,
      "total_loss": 0.6080790162086487
    },
    {
      "classification_loss": 0.6772029399871826,
      "epoch": 5.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1542,
      "total_loss": 0.6772029399871826
    },
    {
      "classification_loss": 0.5647454857826233,
      "epoch": 5.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1543,
      "total_loss": 0.5647454857826233
    },
    {
      "classification_loss": 0.5856652855873108,
      "epoch": 5.062295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1544,
      "total_loss": 0.5856652855873108
    },
    {
      "classification_loss": 0.5962874293327332,
      "epoch": 5.065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1545,
      "total_loss": 0.5962874293327332
    },
    {
      "classification_loss": 0.5992951989173889,
      "epoch": 5.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1546,
      "total_loss": 0.5992951989173889
    },
    {
      "classification_loss": 0.6053336262702942,
      "epoch": 5.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1547,
      "total_loss": 0.6053336262702942
    },
    {
      "classification_loss": 0.5976468920707703,
      "epoch": 5.075409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1548,
      "total_loss": 0.5976468920707703
    },
    {
      "classification_loss": 0.6101208329200745,
      "epoch": 5.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1549,
      "total_loss": 0.6101208329200745
    },
    {
      "classification_loss": 0.6728189587593079,
      "epoch": 5.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1550,
      "total_loss": 0.6728189587593079
    },
    {
      "classification_loss": 0.5777475833892822,
      "epoch": 5.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1551,
      "total_loss": 0.5777475833892822
    },
    {
      "classification_loss": 0.4995563328266144,
      "epoch": 5.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1552,
      "total_loss": 0.4995563328266144
    },
    {
      "classification_loss": 0.5589964389801025,
      "epoch": 5.091803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1553,
      "total_loss": 0.5589964389801025
    },
    {
      "classification_loss": 0.5891236066818237,
      "epoch": 5.0950819672131145,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1554,
      "total_loss": 0.5891236066818237
    },
    {
      "classification_loss": 0.6093260049819946,
      "epoch": 5.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1555,
      "total_loss": 0.6093260049819946
    },
    {
      "classification_loss": 0.6040255427360535,
      "epoch": 5.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1556,
      "total_loss": 0.6040255427360535
    },
    {
      "classification_loss": 0.5608054995536804,
      "epoch": 5.104918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1557,
      "total_loss": 0.5608054995536804
    },
    {
      "classification_loss": 0.5738340020179749,
      "epoch": 5.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1558,
      "total_loss": 0.5738340020179749
    },
    {
      "classification_loss": 0.574418306350708,
      "epoch": 5.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1559,
      "total_loss": 0.574418306350708
    },
    {
      "classification_loss": 0.560662031173706,
      "epoch": 5.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1560,
      "total_loss": 0.560662031173706
    },
    {
      "classification_loss": 0.5616984367370605,
      "epoch": 5.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1561,
      "total_loss": 0.5616984367370605
    },
    {
      "classification_loss": 0.6527803540229797,
      "epoch": 5.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1562,
      "total_loss": 0.6527803540229797
    },
    {
      "classification_loss": 0.5562193989753723,
      "epoch": 5.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1563,
      "total_loss": 0.5562193989753723
    },
    {
      "classification_loss": 0.4718753397464752,
      "epoch": 5.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1564,
      "total_loss": 0.4718753397464752
    },
    {
      "classification_loss": 0.5704919695854187,
      "epoch": 5.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1565,
      "total_loss": 0.5704919695854187
    },
    {
      "classification_loss": 0.6324613094329834,
      "epoch": 5.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1566,
      "total_loss": 0.6324613094329834
    },
    {
      "classification_loss": 0.5951934456825256,
      "epoch": 5.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1567,
      "total_loss": 0.5951934456825256
    },
    {
      "classification_loss": 0.5582968592643738,
      "epoch": 5.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1568,
      "total_loss": 0.5582968592643738
    },
    {
      "classification_loss": 0.5497429966926575,
      "epoch": 5.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1569,
      "total_loss": 0.5497429966926575
    },
    {
      "classification_loss": 0.6545443534851074,
      "epoch": 5.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1570,
      "total_loss": 0.6545443534851074
    },
    {
      "classification_loss": 0.5451280474662781,
      "epoch": 5.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1571,
      "total_loss": 0.5451280474662781
    },
    {
      "classification_loss": 0.6512765288352966,
      "epoch": 5.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1572,
      "total_loss": 0.6512765288352966
    },
    {
      "classification_loss": 0.5509798526763916,
      "epoch": 5.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1573,
      "total_loss": 0.5509798526763916
    },
    {
      "classification_loss": 0.5744193196296692,
      "epoch": 5.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1574,
      "total_loss": 0.5744193196296692
    },
    {
      "classification_loss": 0.6578912138938904,
      "epoch": 5.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1575,
      "total_loss": 0.6578912138938904
    },
    {
      "classification_loss": 0.6630329489707947,
      "epoch": 5.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1576,
      "total_loss": 0.6630329489707947
    },
    {
      "classification_loss": 0.6306357383728027,
      "epoch": 5.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1577,
      "total_loss": 0.6306357383728027
    },
    {
      "classification_loss": 0.5530909895896912,
      "epoch": 5.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1578,
      "total_loss": 0.5530909895896912
    },
    {
      "classification_loss": 0.5886719822883606,
      "epoch": 5.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1579,
      "total_loss": 0.5886719822883606
    },
    {
      "classification_loss": 0.6155627965927124,
      "epoch": 5.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1580,
      "total_loss": 0.6155627965927124
    },
    {
      "classification_loss": 0.6304884552955627,
      "epoch": 5.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1581,
      "total_loss": 0.6304884552955627
    },
    {
      "classification_loss": 0.6037725806236267,
      "epoch": 5.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1582,
      "total_loss": 0.6037725806236267
    },
    {
      "classification_loss": 0.622494637966156,
      "epoch": 5.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1583,
      "total_loss": 0.622494637966156
    },
    {
      "classification_loss": 0.5899410247802734,
      "epoch": 5.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1584,
      "total_loss": 0.5899410247802734
    },
    {
      "classification_loss": 0.7251695990562439,
      "epoch": 5.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1585,
      "total_loss": 0.7251695990562439
    },
    {
      "classification_loss": 0.5426695346832275,
      "epoch": 5.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1586,
      "total_loss": 0.5426695346832275
    },
    {
      "classification_loss": 0.6821722984313965,
      "epoch": 5.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1587,
      "total_loss": 0.6821722984313965
    },
    {
      "classification_loss": 0.6697131991386414,
      "epoch": 5.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1588,
      "total_loss": 0.6697131991386414
    },
    {
      "classification_loss": 0.5591906905174255,
      "epoch": 5.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1589,
      "total_loss": 0.5591906905174255
    },
    {
      "classification_loss": 0.660535454750061,
      "epoch": 5.213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1590,
      "total_loss": 0.660535454750061
    },
    {
      "classification_loss": 0.6295778155326843,
      "epoch": 5.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1591,
      "total_loss": 0.6295778155326843
    },
    {
      "classification_loss": 0.5362180471420288,
      "epoch": 5.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1592,
      "total_loss": 0.5362180471420288
    },
    {
      "classification_loss": 0.6859857439994812,
      "epoch": 5.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1593,
      "total_loss": 0.6859857439994812
    },
    {
      "classification_loss": 0.6794723868370056,
      "epoch": 5.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1594,
      "total_loss": 0.6794723868370056
    },
    {
      "classification_loss": 0.6883529424667358,
      "epoch": 5.229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1595,
      "total_loss": 0.6883529424667358
    },
    {
      "classification_loss": 0.5358390212059021,
      "epoch": 5.232786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1596,
      "total_loss": 0.5358390212059021
    },
    {
      "classification_loss": 0.6095877289772034,
      "epoch": 5.2360655737704915,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1597,
      "total_loss": 0.6095877289772034
    },
    {
      "classification_loss": 0.5070148706436157,
      "epoch": 5.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1598,
      "total_loss": 0.5070148706436157
    },
    {
      "classification_loss": 0.5653550028800964,
      "epoch": 5.242622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1599,
      "total_loss": 0.5653550028800964
    },
    {
      "epoch": 5.245901639344262,
      "grad_norm": 1.6196744441986084,
      "learning_rate": 0.00015003333333333334,
      "loss": 0.6017,
      "step": 1600
    },
    {
      "classification_loss": 0.5777466297149658,
      "epoch": 5.245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1600,
      "total_loss": 0.5777466297149658
    },
    {
      "classification_loss": 0.5001081228256226,
      "epoch": 5.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1601,
      "total_loss": 0.5001081228256226
    },
    {
      "classification_loss": 0.49101752042770386,
      "epoch": 5.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1602,
      "total_loss": 0.49101752042770386
    },
    {
      "classification_loss": 0.5569146871566772,
      "epoch": 5.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1603,
      "total_loss": 0.5569146871566772
    },
    {
      "classification_loss": 0.6671104431152344,
      "epoch": 5.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1604,
      "total_loss": 0.6671104431152344
    },
    {
      "classification_loss": 0.5830817222595215,
      "epoch": 5.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1605,
      "total_loss": 0.5830817222595215
    },
    {
      "classification_loss": 0.4943763315677643,
      "epoch": 5.2655737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1606,
      "total_loss": 0.4943763315677643
    },
    {
      "classification_loss": 0.5794508457183838,
      "epoch": 5.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1607,
      "total_loss": 0.5794508457183838
    },
    {
      "classification_loss": 0.6015356779098511,
      "epoch": 5.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1608,
      "total_loss": 0.6015356779098511
    },
    {
      "classification_loss": 0.6085029244422913,
      "epoch": 5.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1609,
      "total_loss": 0.6085029244422913
    },
    {
      "classification_loss": 0.6482090950012207,
      "epoch": 5.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1610,
      "total_loss": 0.6482090950012207
    },
    {
      "classification_loss": 0.5961523056030273,
      "epoch": 5.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1611,
      "total_loss": 0.5961523056030273
    },
    {
      "classification_loss": 0.7050100564956665,
      "epoch": 5.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1612,
      "total_loss": 0.7050100564956665
    },
    {
      "classification_loss": 0.576784610748291,
      "epoch": 5.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1613,
      "total_loss": 0.576784610748291
    },
    {
      "classification_loss": 0.6166484355926514,
      "epoch": 5.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1614,
      "total_loss": 0.6166484355926514
    },
    {
      "classification_loss": 0.5398461222648621,
      "epoch": 5.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1615,
      "total_loss": 0.5398461222648621
    },
    {
      "classification_loss": 0.5468605756759644,
      "epoch": 5.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1616,
      "total_loss": 0.5468605756759644
    },
    {
      "classification_loss": 0.5693497657775879,
      "epoch": 5.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1617,
      "total_loss": 0.5693497657775879
    },
    {
      "classification_loss": 0.49168848991394043,
      "epoch": 5.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1618,
      "total_loss": 0.49168848991394043
    },
    {
      "classification_loss": 0.6423971652984619,
      "epoch": 5.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1619,
      "total_loss": 0.6423971652984619
    },
    {
      "classification_loss": 0.5992878079414368,
      "epoch": 5.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1620,
      "total_loss": 0.5992878079414368
    },
    {
      "classification_loss": 0.5967979431152344,
      "epoch": 5.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1621,
      "total_loss": 0.5967979431152344
    },
    {
      "classification_loss": 0.5879791378974915,
      "epoch": 5.3180327868852455,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1622,
      "total_loss": 0.5879791378974915
    },
    {
      "classification_loss": 0.6241641044616699,
      "epoch": 5.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1623,
      "total_loss": 0.6241641044616699
    },
    {
      "classification_loss": 0.6980471014976501,
      "epoch": 5.324590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1624,
      "total_loss": 0.6980471014976501
    },
    {
      "classification_loss": 0.5684847831726074,
      "epoch": 5.327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1625,
      "total_loss": 0.5684847831726074
    },
    {
      "classification_loss": 0.6320127844810486,
      "epoch": 5.331147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1626,
      "total_loss": 0.6320127844810486
    },
    {
      "classification_loss": 0.6152425408363342,
      "epoch": 5.334426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1627,
      "total_loss": 0.6152425408363342
    },
    {
      "classification_loss": 0.5110061764717102,
      "epoch": 5.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1628,
      "total_loss": 0.5110061764717102
    },
    {
      "classification_loss": 0.5750390291213989,
      "epoch": 5.340983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1629,
      "total_loss": 0.5750390291213989
    },
    {
      "classification_loss": 0.6328524947166443,
      "epoch": 5.344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1630,
      "total_loss": 0.6328524947166443
    },
    {
      "classification_loss": 0.6433120369911194,
      "epoch": 5.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1631,
      "total_loss": 0.6433120369911194
    },
    {
      "classification_loss": 0.6108385920524597,
      "epoch": 5.350819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1632,
      "total_loss": 0.6108385920524597
    },
    {
      "classification_loss": 0.5302122235298157,
      "epoch": 5.354098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1633,
      "total_loss": 0.5302122235298157
    },
    {
      "classification_loss": 0.569660484790802,
      "epoch": 5.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1634,
      "total_loss": 0.569660484790802
    },
    {
      "classification_loss": 0.5546441674232483,
      "epoch": 5.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1635,
      "total_loss": 0.5546441674232483
    },
    {
      "classification_loss": 0.6399850249290466,
      "epoch": 5.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1636,
      "total_loss": 0.6399850249290466
    },
    {
      "classification_loss": 0.6427546739578247,
      "epoch": 5.367213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1637,
      "total_loss": 0.6427546739578247
    },
    {
      "classification_loss": 0.6320439577102661,
      "epoch": 5.370491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1638,
      "total_loss": 0.6320439577102661
    },
    {
      "classification_loss": 0.6394643187522888,
      "epoch": 5.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1639,
      "total_loss": 0.6394643187522888
    },
    {
      "classification_loss": 0.6342782974243164,
      "epoch": 5.377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1640,
      "total_loss": 0.6342782974243164
    },
    {
      "classification_loss": 0.5587713718414307,
      "epoch": 5.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1641,
      "total_loss": 0.5587713718414307
    },
    {
      "classification_loss": 0.5247108936309814,
      "epoch": 5.383606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1642,
      "total_loss": 0.5247108936309814
    },
    {
      "classification_loss": 0.6050195097923279,
      "epoch": 5.386885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1643,
      "total_loss": 0.6050195097923279
    },
    {
      "classification_loss": 0.5530580878257751,
      "epoch": 5.390163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1644,
      "total_loss": 0.5530580878257751
    },
    {
      "classification_loss": 0.5912889838218689,
      "epoch": 5.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1645,
      "total_loss": 0.5912889838218689
    },
    {
      "classification_loss": 0.6289838552474976,
      "epoch": 5.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1646,
      "total_loss": 0.6289838552474976
    },
    {
      "classification_loss": 0.5532776713371277,
      "epoch": 5.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1647,
      "total_loss": 0.5532776713371277
    },
    {
      "classification_loss": 0.6154069900512695,
      "epoch": 5.4032786885245905,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1648,
      "total_loss": 0.6154069900512695
    },
    {
      "classification_loss": 0.5850673913955688,
      "epoch": 5.406557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1649,
      "total_loss": 0.5850673913955688
    },
    {
      "classification_loss": 0.6587686538696289,
      "epoch": 5.409836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1650,
      "total_loss": 0.6587686538696289
    },
    {
      "classification_loss": 0.7529624700546265,
      "epoch": 5.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1651,
      "total_loss": 0.7529624700546265
    },
    {
      "classification_loss": 0.7050322890281677,
      "epoch": 5.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1652,
      "total_loss": 0.7050322890281677
    },
    {
      "classification_loss": 0.6511422991752625,
      "epoch": 5.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1653,
      "total_loss": 0.6511422991752625
    },
    {
      "classification_loss": 0.5750051140785217,
      "epoch": 5.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1654,
      "total_loss": 0.5750051140785217
    },
    {
      "classification_loss": 0.5509589910507202,
      "epoch": 5.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1655,
      "total_loss": 0.5509589910507202
    },
    {
      "classification_loss": 0.5702080130577087,
      "epoch": 5.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1656,
      "total_loss": 0.5702080130577087
    },
    {
      "classification_loss": 0.5930655002593994,
      "epoch": 5.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1657,
      "total_loss": 0.5930655002593994
    },
    {
      "classification_loss": 0.6670597791671753,
      "epoch": 5.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1658,
      "total_loss": 0.6670597791671753
    },
    {
      "classification_loss": 0.5344065427780151,
      "epoch": 5.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1659,
      "total_loss": 0.5344065427780151
    },
    {
      "classification_loss": 0.5460860729217529,
      "epoch": 5.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1660,
      "total_loss": 0.5460860729217529
    },
    {
      "classification_loss": 0.6024317145347595,
      "epoch": 5.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1661,
      "total_loss": 0.6024317145347595
    },
    {
      "classification_loss": 0.613056480884552,
      "epoch": 5.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1662,
      "total_loss": 0.613056480884552
    },
    {
      "classification_loss": 0.5895558595657349,
      "epoch": 5.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1663,
      "total_loss": 0.5895558595657349
    },
    {
      "classification_loss": 0.5755303502082825,
      "epoch": 5.4557377049180324,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1664,
      "total_loss": 0.5755303502082825
    },
    {
      "classification_loss": 0.626845121383667,
      "epoch": 5.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1665,
      "total_loss": 0.626845121383667
    },
    {
      "classification_loss": 0.6045891046524048,
      "epoch": 5.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1666,
      "total_loss": 0.6045891046524048
    },
    {
      "classification_loss": 0.5554234385490417,
      "epoch": 5.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1667,
      "total_loss": 0.5554234385490417
    },
    {
      "classification_loss": 0.5260471701622009,
      "epoch": 5.468852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1668,
      "total_loss": 0.5260471701622009
    },
    {
      "classification_loss": 0.5812584757804871,
      "epoch": 5.472131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1669,
      "total_loss": 0.5812584757804871
    },
    {
      "classification_loss": 0.6239568591117859,
      "epoch": 5.475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1670,
      "total_loss": 0.6239568591117859
    },
    {
      "classification_loss": 0.5184000730514526,
      "epoch": 5.478688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1671,
      "total_loss": 0.5184000730514526
    },
    {
      "classification_loss": 0.6587947010993958,
      "epoch": 5.481967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1672,
      "total_loss": 0.6587947010993958
    },
    {
      "classification_loss": 0.5460141897201538,
      "epoch": 5.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1673,
      "total_loss": 0.5460141897201538
    },
    {
      "classification_loss": 0.585055947303772,
      "epoch": 5.488524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1674,
      "total_loss": 0.585055947303772
    },
    {
      "classification_loss": 0.522449791431427,
      "epoch": 5.491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1675,
      "total_loss": 0.522449791431427
    },
    {
      "classification_loss": 0.6672071218490601,
      "epoch": 5.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1676,
      "total_loss": 0.6672071218490601
    },
    {
      "classification_loss": 0.6076526045799255,
      "epoch": 5.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1677,
      "total_loss": 0.6076526045799255
    },
    {
      "classification_loss": 0.5779394507408142,
      "epoch": 5.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1678,
      "total_loss": 0.5779394507408142
    },
    {
      "classification_loss": 0.6194155216217041,
      "epoch": 5.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1679,
      "total_loss": 0.6194155216217041
    },
    {
      "classification_loss": 0.5409916043281555,
      "epoch": 5.508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1680,
      "total_loss": 0.5409916043281555
    },
    {
      "classification_loss": 0.5870317816734314,
      "epoch": 5.511475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1681,
      "total_loss": 0.5870317816734314
    },
    {
      "classification_loss": 0.6525362730026245,
      "epoch": 5.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1682,
      "total_loss": 0.6525362730026245
    },
    {
      "classification_loss": 0.6839011907577515,
      "epoch": 5.518032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1683,
      "total_loss": 0.6839011907577515
    },
    {
      "classification_loss": 0.6016508340835571,
      "epoch": 5.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1684,
      "total_loss": 0.6016508340835571
    },
    {
      "classification_loss": 0.6618828177452087,
      "epoch": 5.524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1685,
      "total_loss": 0.6618828177452087
    },
    {
      "classification_loss": 0.6105896234512329,
      "epoch": 5.527868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1686,
      "total_loss": 0.6105896234512329
    },
    {
      "classification_loss": 0.5134607553482056,
      "epoch": 5.531147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1687,
      "total_loss": 0.5134607553482056
    },
    {
      "classification_loss": 0.5308201313018799,
      "epoch": 5.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1688,
      "total_loss": 0.5308201313018799
    },
    {
      "classification_loss": 0.5711118578910828,
      "epoch": 5.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1689,
      "total_loss": 0.5711118578910828
    },
    {
      "classification_loss": 0.538690984249115,
      "epoch": 5.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1690,
      "total_loss": 0.538690984249115
    },
    {
      "classification_loss": 0.6983269453048706,
      "epoch": 5.5442622950819676,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1691,
      "total_loss": 0.6983269453048706
    },
    {
      "classification_loss": 0.6079597473144531,
      "epoch": 5.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1692,
      "total_loss": 0.6079597473144531
    },
    {
      "classification_loss": 0.5836083889007568,
      "epoch": 5.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1693,
      "total_loss": 0.5836083889007568
    },
    {
      "classification_loss": 0.609467625617981,
      "epoch": 5.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1694,
      "total_loss": 0.609467625617981
    },
    {
      "classification_loss": 0.6502703428268433,
      "epoch": 5.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1695,
      "total_loss": 0.6502703428268433
    },
    {
      "classification_loss": 0.6099626421928406,
      "epoch": 5.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1696,
      "total_loss": 0.6099626421928406
    },
    {
      "classification_loss": 0.6460134983062744,
      "epoch": 5.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1697,
      "total_loss": 0.6460134983062744
    },
    {
      "classification_loss": 0.489798367023468,
      "epoch": 5.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1698,
      "total_loss": 0.489798367023468
    },
    {
      "classification_loss": 0.6280614137649536,
      "epoch": 5.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1699,
      "total_loss": 0.6280614137649536
    },
    {
      "epoch": 5.573770491803279,
      "grad_norm": 6.2505784034729,
      "learning_rate": 0.00014670000000000002,
      "loss": 0.5957,
      "step": 1700
    },
    {
      "classification_loss": 0.6168277263641357,
      "epoch": 5.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1700,
      "total_loss": 0.6168277263641357
    },
    {
      "classification_loss": 0.569088339805603,
      "epoch": 5.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1701,
      "total_loss": 0.569088339805603
    },
    {
      "classification_loss": 0.648637592792511,
      "epoch": 5.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1702,
      "total_loss": 0.648637592792511
    },
    {
      "classification_loss": 0.598726212978363,
      "epoch": 5.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1703,
      "total_loss": 0.598726212978363
    },
    {
      "classification_loss": 0.6538802981376648,
      "epoch": 5.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1704,
      "total_loss": 0.6538802981376648
    },
    {
      "classification_loss": 0.6928440928459167,
      "epoch": 5.590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1705,
      "total_loss": 0.6928440928459167
    },
    {
      "classification_loss": 0.619903028011322,
      "epoch": 5.593442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1706,
      "total_loss": 0.619903028011322
    },
    {
      "classification_loss": 0.6174445152282715,
      "epoch": 5.5967213114754095,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1707,
      "total_loss": 0.6174445152282715
    },
    {
      "classification_loss": 0.5855605602264404,
      "epoch": 5.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1708,
      "total_loss": 0.5855605602264404
    },
    {
      "classification_loss": 0.5358385443687439,
      "epoch": 5.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1709,
      "total_loss": 0.5358385443687439
    },
    {
      "classification_loss": 0.5965628623962402,
      "epoch": 5.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1710,
      "total_loss": 0.5965628623962402
    },
    {
      "classification_loss": 0.6421135663986206,
      "epoch": 5.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1711,
      "total_loss": 0.6421135663986206
    },
    {
      "classification_loss": 0.6769149303436279,
      "epoch": 5.613114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1712,
      "total_loss": 0.6769149303436279
    },
    {
      "classification_loss": 0.5638856291770935,
      "epoch": 5.616393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1713,
      "total_loss": 0.5638856291770935
    },
    {
      "classification_loss": 0.6148120164871216,
      "epoch": 5.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1714,
      "total_loss": 0.6148120164871216
    },
    {
      "classification_loss": 0.5803239941596985,
      "epoch": 5.622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1715,
      "total_loss": 0.5803239941596985
    },
    {
      "classification_loss": 0.5448226928710938,
      "epoch": 5.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1716,
      "total_loss": 0.5448226928710938
    },
    {
      "classification_loss": 0.5740092396736145,
      "epoch": 5.629508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1717,
      "total_loss": 0.5740092396736145
    },
    {
      "classification_loss": 0.6490640044212341,
      "epoch": 5.632786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1718,
      "total_loss": 0.6490640044212341
    },
    {
      "classification_loss": 0.7030341029167175,
      "epoch": 5.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1719,
      "total_loss": 0.7030341029167175
    },
    {
      "classification_loss": 0.6349772810935974,
      "epoch": 5.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1720,
      "total_loss": 0.6349772810935974
    },
    {
      "classification_loss": 0.5856825709342957,
      "epoch": 5.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1721,
      "total_loss": 0.5856825709342957
    },
    {
      "classification_loss": 0.5687947869300842,
      "epoch": 5.645901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1722,
      "total_loss": 0.5687947869300842
    },
    {
      "classification_loss": 0.5528814196586609,
      "epoch": 5.649180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1723,
      "total_loss": 0.5528814196586609
    },
    {
      "classification_loss": 0.5379759073257446,
      "epoch": 5.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1724,
      "total_loss": 0.5379759073257446
    },
    {
      "classification_loss": 0.5430747270584106,
      "epoch": 5.655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1725,
      "total_loss": 0.5430747270584106
    },
    {
      "classification_loss": 0.6067262887954712,
      "epoch": 5.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1726,
      "total_loss": 0.6067262887954712
    },
    {
      "classification_loss": 0.6796644926071167,
      "epoch": 5.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1727,
      "total_loss": 0.6796644926071167
    },
    {
      "classification_loss": 0.7075309753417969,
      "epoch": 5.665573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1728,
      "total_loss": 0.7075309753417969
    },
    {
      "classification_loss": 0.5711971521377563,
      "epoch": 5.668852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1729,
      "total_loss": 0.5711971521377563
    },
    {
      "classification_loss": 0.5904287099838257,
      "epoch": 5.672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1730,
      "total_loss": 0.5904287099838257
    },
    {
      "classification_loss": 0.599726140499115,
      "epoch": 5.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1731,
      "total_loss": 0.599726140499115
    },
    {
      "classification_loss": 0.5482950210571289,
      "epoch": 5.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1732,
      "total_loss": 0.5482950210571289
    },
    {
      "classification_loss": 0.5941221117973328,
      "epoch": 5.6819672131147545,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1733,
      "total_loss": 0.5941221117973328
    },
    {
      "classification_loss": 0.5605884790420532,
      "epoch": 5.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1734,
      "total_loss": 0.5605884790420532
    },
    {
      "classification_loss": 0.5846195816993713,
      "epoch": 5.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1735,
      "total_loss": 0.5846195816993713
    },
    {
      "classification_loss": 0.6859638094902039,
      "epoch": 5.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1736,
      "total_loss": 0.6859638094902039
    },
    {
      "classification_loss": 0.612999677658081,
      "epoch": 5.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1737,
      "total_loss": 0.612999677658081
    },
    {
      "classification_loss": 0.5501219630241394,
      "epoch": 5.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1738,
      "total_loss": 0.5501219630241394
    },
    {
      "classification_loss": 0.6329747438430786,
      "epoch": 5.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1739,
      "total_loss": 0.6329747438430786
    },
    {
      "classification_loss": 0.5631535649299622,
      "epoch": 5.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1740,
      "total_loss": 0.5631535649299622
    },
    {
      "classification_loss": 0.6147648096084595,
      "epoch": 5.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1741,
      "total_loss": 0.6147648096084595
    },
    {
      "classification_loss": 0.5803424119949341,
      "epoch": 5.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1742,
      "total_loss": 0.5803424119949341
    },
    {
      "classification_loss": 0.6038102507591248,
      "epoch": 5.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1743,
      "total_loss": 0.6038102507591248
    },
    {
      "classification_loss": 0.5899420976638794,
      "epoch": 5.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1744,
      "total_loss": 0.5899420976638794
    },
    {
      "classification_loss": 0.5981983542442322,
      "epoch": 5.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1745,
      "total_loss": 0.5981983542442322
    },
    {
      "classification_loss": 0.5904481410980225,
      "epoch": 5.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1746,
      "total_loss": 0.5904481410980225
    },
    {
      "classification_loss": 0.5451491475105286,
      "epoch": 5.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1747,
      "total_loss": 0.5451491475105286
    },
    {
      "classification_loss": 0.6547409892082214,
      "epoch": 5.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1748,
      "total_loss": 0.6547409892082214
    },
    {
      "classification_loss": 0.6354094743728638,
      "epoch": 5.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1749,
      "total_loss": 0.6354094743728638
    },
    {
      "classification_loss": 0.5885980129241943,
      "epoch": 5.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1750,
      "total_loss": 0.5885980129241943
    },
    {
      "classification_loss": 0.6005251407623291,
      "epoch": 5.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1751,
      "total_loss": 0.6005251407623291
    },
    {
      "classification_loss": 0.5781897902488708,
      "epoch": 5.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1752,
      "total_loss": 0.5781897902488708
    },
    {
      "classification_loss": 0.5871270895004272,
      "epoch": 5.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1753,
      "total_loss": 0.5871270895004272
    },
    {
      "classification_loss": 0.5617706775665283,
      "epoch": 5.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1754,
      "total_loss": 0.5617706775665283
    },
    {
      "classification_loss": 0.6762306094169617,
      "epoch": 5.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1755,
      "total_loss": 0.6762306094169617
    },
    {
      "classification_loss": 0.6594526767730713,
      "epoch": 5.757377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1756,
      "total_loss": 0.6594526767730713
    },
    {
      "classification_loss": 0.541719377040863,
      "epoch": 5.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1757,
      "total_loss": 0.541719377040863
    },
    {
      "classification_loss": 0.5071882605552673,
      "epoch": 5.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1758,
      "total_loss": 0.5071882605552673
    },
    {
      "classification_loss": 0.6398782730102539,
      "epoch": 5.767213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1759,
      "total_loss": 0.6398782730102539
    },
    {
      "classification_loss": 0.630033552646637,
      "epoch": 5.770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1760,
      "total_loss": 0.630033552646637
    },
    {
      "classification_loss": 0.5538896918296814,
      "epoch": 5.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1761,
      "total_loss": 0.5538896918296814
    },
    {
      "classification_loss": 0.6129533052444458,
      "epoch": 5.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1762,
      "total_loss": 0.6129533052444458
    },
    {
      "classification_loss": 0.5386292338371277,
      "epoch": 5.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1763,
      "total_loss": 0.5386292338371277
    },
    {
      "classification_loss": 0.5751042366027832,
      "epoch": 5.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1764,
      "total_loss": 0.5751042366027832
    },
    {
      "classification_loss": 0.584256112575531,
      "epoch": 5.786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1765,
      "total_loss": 0.584256112575531
    },
    {
      "classification_loss": 0.6217102408409119,
      "epoch": 5.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1766,
      "total_loss": 0.6217102408409119
    },
    {
      "classification_loss": 0.6146299839019775,
      "epoch": 5.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1767,
      "total_loss": 0.6146299839019775
    },
    {
      "classification_loss": 0.6316826343536377,
      "epoch": 5.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1768,
      "total_loss": 0.6316826343536377
    },
    {
      "classification_loss": 0.539649248123169,
      "epoch": 5.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1769,
      "total_loss": 0.539649248123169
    },
    {
      "classification_loss": 0.589898407459259,
      "epoch": 5.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1770,
      "total_loss": 0.589898407459259
    },
    {
      "classification_loss": 0.5364210605621338,
      "epoch": 5.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1771,
      "total_loss": 0.5364210605621338
    },
    {
      "classification_loss": 0.6198354363441467,
      "epoch": 5.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1772,
      "total_loss": 0.6198354363441467
    },
    {
      "classification_loss": 0.5677297711372375,
      "epoch": 5.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1773,
      "total_loss": 0.5677297711372375
    },
    {
      "classification_loss": 0.6901080012321472,
      "epoch": 5.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1774,
      "total_loss": 0.6901080012321472
    },
    {
      "classification_loss": 0.6357269883155823,
      "epoch": 5.8196721311475414,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1775,
      "total_loss": 0.6357269883155823
    },
    {
      "classification_loss": 0.6435679793357849,
      "epoch": 5.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1776,
      "total_loss": 0.6435679793357849
    },
    {
      "classification_loss": 0.5804790258407593,
      "epoch": 5.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1777,
      "total_loss": 0.5804790258407593
    },
    {
      "classification_loss": 0.5719375014305115,
      "epoch": 5.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1778,
      "total_loss": 0.5719375014305115
    },
    {
      "classification_loss": 0.5505544543266296,
      "epoch": 5.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1779,
      "total_loss": 0.5505544543266296
    },
    {
      "classification_loss": 0.567344069480896,
      "epoch": 5.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1780,
      "total_loss": 0.567344069480896
    },
    {
      "classification_loss": 0.5311126112937927,
      "epoch": 5.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1781,
      "total_loss": 0.5311126112937927
    },
    {
      "classification_loss": 0.6182644963264465,
      "epoch": 5.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1782,
      "total_loss": 0.6182644963264465
    },
    {
      "classification_loss": 0.5775355100631714,
      "epoch": 5.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1783,
      "total_loss": 0.5775355100631714
    },
    {
      "classification_loss": 0.6243841648101807,
      "epoch": 5.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1784,
      "total_loss": 0.6243841648101807
    },
    {
      "classification_loss": 0.5559186935424805,
      "epoch": 5.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1785,
      "total_loss": 0.5559186935424805
    },
    {
      "classification_loss": 0.5799004435539246,
      "epoch": 5.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1786,
      "total_loss": 0.5799004435539246
    },
    {
      "classification_loss": 0.5299907326698303,
      "epoch": 5.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1787,
      "total_loss": 0.5299907326698303
    },
    {
      "classification_loss": 0.6376186609268188,
      "epoch": 5.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1788,
      "total_loss": 0.6376186609268188
    },
    {
      "classification_loss": 0.7200932502746582,
      "epoch": 5.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1789,
      "total_loss": 0.7200932502746582
    },
    {
      "classification_loss": 0.6536538600921631,
      "epoch": 5.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1790,
      "total_loss": 0.6536538600921631
    },
    {
      "classification_loss": 0.5474568605422974,
      "epoch": 5.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1791,
      "total_loss": 0.5474568605422974
    },
    {
      "classification_loss": 0.5269936919212341,
      "epoch": 5.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1792,
      "total_loss": 0.5269936919212341
    },
    {
      "classification_loss": 0.6184963583946228,
      "epoch": 5.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1793,
      "total_loss": 0.6184963583946228
    },
    {
      "classification_loss": 0.5621777772903442,
      "epoch": 5.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1794,
      "total_loss": 0.5621777772903442
    },
    {
      "classification_loss": 0.6894485950469971,
      "epoch": 5.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1795,
      "total_loss": 0.6894485950469971
    },
    {
      "classification_loss": 0.5489555597305298,
      "epoch": 5.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1796,
      "total_loss": 0.5489555597305298
    },
    {
      "classification_loss": 0.6226036548614502,
      "epoch": 5.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1797,
      "total_loss": 0.6226036548614502
    },
    {
      "classification_loss": 0.6058671474456787,
      "epoch": 5.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1798,
      "total_loss": 0.6058671474456787
    },
    {
      "classification_loss": 0.6273713707923889,
      "epoch": 5.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1799,
      "total_loss": 0.6273713707923889
    },
    {
      "epoch": 5.901639344262295,
      "grad_norm": 3.3945908546447754,
      "learning_rate": 0.00014336666666666666,
      "loss": 0.5998,
      "step": 1800
    },
    {
      "classification_loss": 0.6965091228485107,
      "epoch": 5.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1800,
      "total_loss": 0.6965091228485107
    },
    {
      "classification_loss": 0.6683136224746704,
      "epoch": 5.9049180327868855,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1801,
      "total_loss": 0.6683136224746704
    },
    {
      "classification_loss": 0.7167962789535522,
      "epoch": 5.908196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1802,
      "total_loss": 0.7167962789535522
    },
    {
      "classification_loss": 0.652079701423645,
      "epoch": 5.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1803,
      "total_loss": 0.652079701423645
    },
    {
      "classification_loss": 0.6228280067443848,
      "epoch": 5.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1804,
      "total_loss": 0.6228280067443848
    },
    {
      "classification_loss": 0.6171314716339111,
      "epoch": 5.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1805,
      "total_loss": 0.6171314716339111
    },
    {
      "classification_loss": 0.5892067551612854,
      "epoch": 5.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1806,
      "total_loss": 0.5892067551612854
    },
    {
      "classification_loss": 0.5876856446266174,
      "epoch": 5.924590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1807,
      "total_loss": 0.5876856446266174
    },
    {
      "classification_loss": 0.5734573602676392,
      "epoch": 5.927868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1808,
      "total_loss": 0.5734573602676392
    },
    {
      "classification_loss": 0.6094684600830078,
      "epoch": 5.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1809,
      "total_loss": 0.6094684600830078
    },
    {
      "classification_loss": 0.5346488356590271,
      "epoch": 5.934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1810,
      "total_loss": 0.5346488356590271
    },
    {
      "classification_loss": 0.6426770091056824,
      "epoch": 5.937704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1811,
      "total_loss": 0.6426770091056824
    },
    {
      "classification_loss": 0.680649995803833,
      "epoch": 5.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1812,
      "total_loss": 0.680649995803833
    },
    {
      "classification_loss": 0.5894228219985962,
      "epoch": 5.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1813,
      "total_loss": 0.5894228219985962
    },
    {
      "classification_loss": 0.61036616563797,
      "epoch": 5.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1814,
      "total_loss": 0.61036616563797
    },
    {
      "classification_loss": 0.5727936625480652,
      "epoch": 5.950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1815,
      "total_loss": 0.5727936625480652
    },
    {
      "classification_loss": 0.6465556025505066,
      "epoch": 5.954098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1816,
      "total_loss": 0.6465556025505066
    },
    {
      "classification_loss": 0.6269751191139221,
      "epoch": 5.9573770491803275,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1817,
      "total_loss": 0.6269751191139221
    },
    {
      "classification_loss": 0.6000234484672546,
      "epoch": 5.9606557377049185,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1818,
      "total_loss": 0.6000234484672546
    },
    {
      "classification_loss": 0.6318621039390564,
      "epoch": 5.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1819,
      "total_loss": 0.6318621039390564
    },
    {
      "classification_loss": 0.5729424357414246,
      "epoch": 5.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1820,
      "total_loss": 0.5729424357414246
    },
    {
      "classification_loss": 0.5367099046707153,
      "epoch": 5.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1821,
      "total_loss": 0.5367099046707153
    },
    {
      "classification_loss": 0.5751940011978149,
      "epoch": 5.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1822,
      "total_loss": 0.5751940011978149
    },
    {
      "classification_loss": 0.6209040880203247,
      "epoch": 5.977049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1823,
      "total_loss": 0.6209040880203247
    },
    {
      "classification_loss": 0.5242931842803955,
      "epoch": 5.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1824,
      "total_loss": 0.5242931842803955
    },
    {
      "classification_loss": 0.6472184658050537,
      "epoch": 5.983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1825,
      "total_loss": 0.6472184658050537
    },
    {
      "classification_loss": 0.6001814603805542,
      "epoch": 5.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1826,
      "total_loss": 0.6001814603805542
    },
    {
      "classification_loss": 0.6469470262527466,
      "epoch": 5.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1827,
      "total_loss": 0.6469470262527466
    },
    {
      "classification_loss": 0.6065701246261597,
      "epoch": 5.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1828,
      "total_loss": 0.6065701246261597
    },
    {
      "classification_loss": 0.540103018283844,
      "epoch": 5.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1829,
      "total_loss": 0.540103018283844
    },
    {
      "classification_loss": 0.9223126769065857,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.9223126769065857
    },
    {
      "classification_loss": 0.8773455023765564,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.8773455023765564
    },
    {
      "classification_loss": 0.8705511689186096,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.8705511689186096
    },
    {
      "classification_loss": 0.971167266368866,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.971167266368866
    },
    {
      "classification_loss": 0.8472620844841003,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.8472620844841003
    },
    {
      "classification_loss": 0.8481663465499878,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.8481663465499878
    },
    {
      "classification_loss": 0.8678667545318604,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.8678667545318604
    },
    {
      "classification_loss": 0.7939452528953552,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.7939452528953552
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.372,
      "eval_f1": 0.01875,
      "eval_loss": 0.8767682909965515,
      "eval_precision": 0.6,
      "eval_recall": 0.009523809523809525,
      "eval_runtime": 5.9935,
      "eval_samples_per_second": 166.847,
      "eval_steps_per_second": 1.335,
      "step": 1830
    },
    {
      "classification_loss": 0.5806073546409607,
      "epoch": 6.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1830,
      "total_loss": 0.5806073546409607
    },
    {
      "classification_loss": 0.5727645754814148,
      "epoch": 6.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1831,
      "total_loss": 0.5727645754814148
    },
    {
      "classification_loss": 0.6193816065788269,
      "epoch": 6.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1832,
      "total_loss": 0.6193816065788269
    },
    {
      "classification_loss": 0.5132774710655212,
      "epoch": 6.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1833,
      "total_loss": 0.5132774710655212
    },
    {
      "classification_loss": 0.5332643389701843,
      "epoch": 6.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1834,
      "total_loss": 0.5332643389701843
    },
    {
      "classification_loss": 0.5313779711723328,
      "epoch": 6.016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1835,
      "total_loss": 0.5313779711723328
    },
    {
      "classification_loss": 0.6494385600090027,
      "epoch": 6.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1836,
      "total_loss": 0.6494385600090027
    },
    {
      "classification_loss": 0.6109398603439331,
      "epoch": 6.022950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1837,
      "total_loss": 0.6109398603439331
    },
    {
      "classification_loss": 0.5384947657585144,
      "epoch": 6.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1838,
      "total_loss": 0.5384947657585144
    },
    {
      "classification_loss": 0.5542232990264893,
      "epoch": 6.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1839,
      "total_loss": 0.5542232990264893
    },
    {
      "classification_loss": 0.4974783957004547,
      "epoch": 6.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1840,
      "total_loss": 0.4974783957004547
    },
    {
      "classification_loss": 0.5605330467224121,
      "epoch": 6.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1841,
      "total_loss": 0.5605330467224121
    },
    {
      "classification_loss": 0.491926372051239,
      "epoch": 6.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1842,
      "total_loss": 0.491926372051239
    },
    {
      "classification_loss": 0.5700345039367676,
      "epoch": 6.0426229508196725,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1843,
      "total_loss": 0.5700345039367676
    },
    {
      "classification_loss": 0.5685234665870667,
      "epoch": 6.045901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1844,
      "total_loss": 0.5685234665870667
    },
    {
      "classification_loss": 0.6149701476097107,
      "epoch": 6.049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1845,
      "total_loss": 0.6149701476097107
    },
    {
      "classification_loss": 0.5446391701698303,
      "epoch": 6.052459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1846,
      "total_loss": 0.5446391701698303
    },
    {
      "classification_loss": 0.6101577281951904,
      "epoch": 6.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1847,
      "total_loss": 0.6101577281951904
    },
    {
      "classification_loss": 0.6116995215415955,
      "epoch": 6.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1848,
      "total_loss": 0.6116995215415955
    },
    {
      "classification_loss": 0.6348393559455872,
      "epoch": 6.062295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1849,
      "total_loss": 0.6348393559455872
    },
    {
      "classification_loss": 0.6396308541297913,
      "epoch": 6.065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1850,
      "total_loss": 0.6396308541297913
    },
    {
      "classification_loss": 0.602004885673523,
      "epoch": 6.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1851,
      "total_loss": 0.602004885673523
    },
    {
      "classification_loss": 0.6164206862449646,
      "epoch": 6.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1852,
      "total_loss": 0.6164206862449646
    },
    {
      "classification_loss": 0.6425511837005615,
      "epoch": 6.075409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1853,
      "total_loss": 0.6425511837005615
    },
    {
      "classification_loss": 0.5975652933120728,
      "epoch": 6.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1854,
      "total_loss": 0.5975652933120728
    },
    {
      "classification_loss": 0.6076561212539673,
      "epoch": 6.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1855,
      "total_loss": 0.6076561212539673
    },
    {
      "classification_loss": 0.5834212899208069,
      "epoch": 6.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1856,
      "total_loss": 0.5834212899208069
    },
    {
      "classification_loss": 0.6368065476417542,
      "epoch": 6.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1857,
      "total_loss": 0.6368065476417542
    },
    {
      "classification_loss": 0.583351731300354,
      "epoch": 6.091803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1858,
      "total_loss": 0.583351731300354
    },
    {
      "classification_loss": 0.6321721076965332,
      "epoch": 6.0950819672131145,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1859,
      "total_loss": 0.6321721076965332
    },
    {
      "classification_loss": 0.5170990228652954,
      "epoch": 6.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1860,
      "total_loss": 0.5170990228652954
    },
    {
      "classification_loss": 0.5834342837333679,
      "epoch": 6.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1861,
      "total_loss": 0.5834342837333679
    },
    {
      "classification_loss": 0.5538958311080933,
      "epoch": 6.104918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1862,
      "total_loss": 0.5538958311080933
    },
    {
      "classification_loss": 0.6229912638664246,
      "epoch": 6.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1863,
      "total_loss": 0.6229912638664246
    },
    {
      "classification_loss": 0.6181129813194275,
      "epoch": 6.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1864,
      "total_loss": 0.6181129813194275
    },
    {
      "classification_loss": 0.5402867794036865,
      "epoch": 6.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1865,
      "total_loss": 0.5402867794036865
    },
    {
      "classification_loss": 0.5469902753829956,
      "epoch": 6.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1866,
      "total_loss": 0.5469902753829956
    },
    {
      "classification_loss": 0.5949777364730835,
      "epoch": 6.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1867,
      "total_loss": 0.5949777364730835
    },
    {
      "classification_loss": 0.5586543679237366,
      "epoch": 6.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1868,
      "total_loss": 0.5586543679237366
    },
    {
      "classification_loss": 0.4780302345752716,
      "epoch": 6.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1869,
      "total_loss": 0.4780302345752716
    },
    {
      "classification_loss": 0.500116765499115,
      "epoch": 6.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1870,
      "total_loss": 0.500116765499115
    },
    {
      "classification_loss": 0.5443543791770935,
      "epoch": 6.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1871,
      "total_loss": 0.5443543791770935
    },
    {
      "classification_loss": 0.5768535733222961,
      "epoch": 6.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1872,
      "total_loss": 0.5768535733222961
    },
    {
      "classification_loss": 0.5914469361305237,
      "epoch": 6.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1873,
      "total_loss": 0.5914469361305237
    },
    {
      "classification_loss": 0.6304324269294739,
      "epoch": 6.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1874,
      "total_loss": 0.6304324269294739
    },
    {
      "classification_loss": 0.5553825497627258,
      "epoch": 6.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1875,
      "total_loss": 0.5553825497627258
    },
    {
      "classification_loss": 0.5185739398002625,
      "epoch": 6.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1876,
      "total_loss": 0.5185739398002625
    },
    {
      "classification_loss": 0.5272107720375061,
      "epoch": 6.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1877,
      "total_loss": 0.5272107720375061
    },
    {
      "classification_loss": 0.6043519377708435,
      "epoch": 6.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1878,
      "total_loss": 0.6043519377708435
    },
    {
      "classification_loss": 0.5187537670135498,
      "epoch": 6.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1879,
      "total_loss": 0.5187537670135498
    },
    {
      "classification_loss": 0.5832049250602722,
      "epoch": 6.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1880,
      "total_loss": 0.5832049250602722
    },
    {
      "classification_loss": 0.6544439792633057,
      "epoch": 6.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1881,
      "total_loss": 0.6544439792633057
    },
    {
      "classification_loss": 0.6024925708770752,
      "epoch": 6.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1882,
      "total_loss": 0.6024925708770752
    },
    {
      "classification_loss": 0.5679277777671814,
      "epoch": 6.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1883,
      "total_loss": 0.5679277777671814
    },
    {
      "classification_loss": 0.5478244423866272,
      "epoch": 6.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1884,
      "total_loss": 0.5478244423866272
    },
    {
      "classification_loss": 0.6260948777198792,
      "epoch": 6.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1885,
      "total_loss": 0.6260948777198792
    },
    {
      "classification_loss": 0.5369112491607666,
      "epoch": 6.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1886,
      "total_loss": 0.5369112491607666
    },
    {
      "classification_loss": 0.5367147326469421,
      "epoch": 6.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1887,
      "total_loss": 0.5367147326469421
    },
    {
      "classification_loss": 0.6226917505264282,
      "epoch": 6.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1888,
      "total_loss": 0.6226917505264282
    },
    {
      "classification_loss": 0.5993525981903076,
      "epoch": 6.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1889,
      "total_loss": 0.5993525981903076
    },
    {
      "classification_loss": 0.5488818883895874,
      "epoch": 6.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1890,
      "total_loss": 0.5488818883895874
    },
    {
      "classification_loss": 0.6540742516517639,
      "epoch": 6.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1891,
      "total_loss": 0.6540742516517639
    },
    {
      "classification_loss": 0.625725269317627,
      "epoch": 6.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1892,
      "total_loss": 0.625725269317627
    },
    {
      "classification_loss": 0.6317040920257568,
      "epoch": 6.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1893,
      "total_loss": 0.6317040920257568
    },
    {
      "classification_loss": 0.6296610832214355,
      "epoch": 6.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1894,
      "total_loss": 0.6296610832214355
    },
    {
      "classification_loss": 0.5539137125015259,
      "epoch": 6.213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1895,
      "total_loss": 0.5539137125015259
    },
    {
      "classification_loss": 0.5299625396728516,
      "epoch": 6.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1896,
      "total_loss": 0.5299625396728516
    },
    {
      "classification_loss": 0.5695436596870422,
      "epoch": 6.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1897,
      "total_loss": 0.5695436596870422
    },
    {
      "classification_loss": 0.5134169459342957,
      "epoch": 6.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1898,
      "total_loss": 0.5134169459342957
    },
    {
      "classification_loss": 0.5446102023124695,
      "epoch": 6.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1899,
      "total_loss": 0.5446102023124695
    },
    {
      "epoch": 6.229508196721311,
      "grad_norm": 1.3727295398712158,
      "learning_rate": 0.00014003333333333334,
      "loss": 0.5875,
      "step": 1900
    },
    {
      "classification_loss": 0.6240277886390686,
      "epoch": 6.229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1900,
      "total_loss": 0.6240277886390686
    },
    {
      "classification_loss": 0.5774996876716614,
      "epoch": 6.232786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1901,
      "total_loss": 0.5774996876716614
    },
    {
      "classification_loss": 0.646736741065979,
      "epoch": 6.2360655737704915,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1902,
      "total_loss": 0.646736741065979
    },
    {
      "classification_loss": 0.5251232981681824,
      "epoch": 6.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1903,
      "total_loss": 0.5251232981681824
    },
    {
      "classification_loss": 0.6265149712562561,
      "epoch": 6.242622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1904,
      "total_loss": 0.6265149712562561
    },
    {
      "classification_loss": 0.626054048538208,
      "epoch": 6.245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1905,
      "total_loss": 0.626054048538208
    },
    {
      "classification_loss": 0.5940521359443665,
      "epoch": 6.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1906,
      "total_loss": 0.5940521359443665
    },
    {
      "classification_loss": 0.4617633819580078,
      "epoch": 6.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1907,
      "total_loss": 0.4617633819580078
    },
    {
      "classification_loss": 0.5318429470062256,
      "epoch": 6.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1908,
      "total_loss": 0.5318429470062256
    },
    {
      "classification_loss": 0.5834463238716125,
      "epoch": 6.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1909,
      "total_loss": 0.5834463238716125
    },
    {
      "classification_loss": 0.6350163221359253,
      "epoch": 6.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1910,
      "total_loss": 0.6350163221359253
    },
    {
      "classification_loss": 0.6146199703216553,
      "epoch": 6.2655737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1911,
      "total_loss": 0.6146199703216553
    },
    {
      "classification_loss": 0.6650277376174927,
      "epoch": 6.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1912,
      "total_loss": 0.6650277376174927
    },
    {
      "classification_loss": 0.5551496148109436,
      "epoch": 6.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1913,
      "total_loss": 0.5551496148109436
    },
    {
      "classification_loss": 0.4558360278606415,
      "epoch": 6.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1914,
      "total_loss": 0.4558360278606415
    },
    {
      "classification_loss": 0.44717907905578613,
      "epoch": 6.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1915,
      "total_loss": 0.44717907905578613
    },
    {
      "classification_loss": 0.6407036781311035,
      "epoch": 6.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1916,
      "total_loss": 0.6407036781311035
    },
    {
      "classification_loss": 0.6548159718513489,
      "epoch": 6.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1917,
      "total_loss": 0.6548159718513489
    },
    {
      "classification_loss": 0.4670025110244751,
      "epoch": 6.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1918,
      "total_loss": 0.4670025110244751
    },
    {
      "classification_loss": 0.6161987781524658,
      "epoch": 6.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1919,
      "total_loss": 0.6161987781524658
    },
    {
      "classification_loss": 0.5905726552009583,
      "epoch": 6.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1920,
      "total_loss": 0.5905726552009583
    },
    {
      "classification_loss": 0.5576467514038086,
      "epoch": 6.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1921,
      "total_loss": 0.5576467514038086
    },
    {
      "classification_loss": 0.5574254989624023,
      "epoch": 6.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1922,
      "total_loss": 0.5574254989624023
    },
    {
      "classification_loss": 0.5616351962089539,
      "epoch": 6.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1923,
      "total_loss": 0.5616351962089539
    },
    {
      "classification_loss": 0.6259167194366455,
      "epoch": 6.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1924,
      "total_loss": 0.6259167194366455
    },
    {
      "classification_loss": 0.5386627912521362,
      "epoch": 6.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1925,
      "total_loss": 0.5386627912521362
    },
    {
      "classification_loss": 0.5435369610786438,
      "epoch": 6.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1926,
      "total_loss": 0.5435369610786438
    },
    {
      "classification_loss": 0.5857653021812439,
      "epoch": 6.3180327868852455,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1927,
      "total_loss": 0.5857653021812439
    },
    {
      "classification_loss": 0.5258879065513611,
      "epoch": 6.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1928,
      "total_loss": 0.5258879065513611
    },
    {
      "classification_loss": 0.5490608215332031,
      "epoch": 6.324590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1929,
      "total_loss": 0.5490608215332031
    },
    {
      "classification_loss": 0.6998987197875977,
      "epoch": 6.327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1930,
      "total_loss": 0.6998987197875977
    },
    {
      "classification_loss": 0.7557983994483948,
      "epoch": 6.331147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1931,
      "total_loss": 0.7557983994483948
    },
    {
      "classification_loss": 0.5007653832435608,
      "epoch": 6.334426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1932,
      "total_loss": 0.5007653832435608
    },
    {
      "classification_loss": 0.5121027827262878,
      "epoch": 6.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1933,
      "total_loss": 0.5121027827262878
    },
    {
      "classification_loss": 0.5641094446182251,
      "epoch": 6.340983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1934,
      "total_loss": 0.5641094446182251
    },
    {
      "classification_loss": 0.593713104724884,
      "epoch": 6.344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1935,
      "total_loss": 0.593713104724884
    },
    {
      "classification_loss": 0.6435331106185913,
      "epoch": 6.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1936,
      "total_loss": 0.6435331106185913
    },
    {
      "classification_loss": 0.703556478023529,
      "epoch": 6.350819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1937,
      "total_loss": 0.703556478023529
    },
    {
      "classification_loss": 0.5276748538017273,
      "epoch": 6.354098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1938,
      "total_loss": 0.5276748538017273
    },
    {
      "classification_loss": 0.6556780934333801,
      "epoch": 6.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1939,
      "total_loss": 0.6556780934333801
    },
    {
      "classification_loss": 0.49953287839889526,
      "epoch": 6.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1940,
      "total_loss": 0.49953287839889526
    },
    {
      "classification_loss": 0.6837586760520935,
      "epoch": 6.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1941,
      "total_loss": 0.6837586760520935
    },
    {
      "classification_loss": 0.6509231328964233,
      "epoch": 6.367213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1942,
      "total_loss": 0.6509231328964233
    },
    {
      "classification_loss": 0.5488735437393188,
      "epoch": 6.370491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1943,
      "total_loss": 0.5488735437393188
    },
    {
      "classification_loss": 0.639371931552887,
      "epoch": 6.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1944,
      "total_loss": 0.639371931552887
    },
    {
      "classification_loss": 0.5333353877067566,
      "epoch": 6.377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1945,
      "total_loss": 0.5333353877067566
    },
    {
      "classification_loss": 0.5831144452095032,
      "epoch": 6.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1946,
      "total_loss": 0.5831144452095032
    },
    {
      "classification_loss": 0.4963662028312683,
      "epoch": 6.383606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1947,
      "total_loss": 0.4963662028312683
    },
    {
      "classification_loss": 0.672589123249054,
      "epoch": 6.386885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1948,
      "total_loss": 0.672589123249054
    },
    {
      "classification_loss": 0.5263398885726929,
      "epoch": 6.390163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1949,
      "total_loss": 0.5263398885726929
    },
    {
      "classification_loss": 0.4639035761356354,
      "epoch": 6.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1950,
      "total_loss": 0.4639035761356354
    },
    {
      "classification_loss": 0.5975196361541748,
      "epoch": 6.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1951,
      "total_loss": 0.5975196361541748
    },
    {
      "classification_loss": 0.6428701281547546,
      "epoch": 6.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1952,
      "total_loss": 0.6428701281547546
    },
    {
      "classification_loss": 0.5944926142692566,
      "epoch": 6.4032786885245905,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1953,
      "total_loss": 0.5944926142692566
    },
    {
      "classification_loss": 0.7282991409301758,
      "epoch": 6.406557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1954,
      "total_loss": 0.7282991409301758
    },
    {
      "classification_loss": 0.6860831379890442,
      "epoch": 6.409836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1955,
      "total_loss": 0.6860831379890442
    },
    {
      "classification_loss": 0.5990201234817505,
      "epoch": 6.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1956,
      "total_loss": 0.5990201234817505
    },
    {
      "classification_loss": 0.5639192461967468,
      "epoch": 6.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1957,
      "total_loss": 0.5639192461967468
    },
    {
      "classification_loss": 0.6694509387016296,
      "epoch": 6.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1958,
      "total_loss": 0.6694509387016296
    },
    {
      "classification_loss": 0.6682469248771667,
      "epoch": 6.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1959,
      "total_loss": 0.6682469248771667
    },
    {
      "classification_loss": 0.5653190016746521,
      "epoch": 6.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1960,
      "total_loss": 0.5653190016746521
    },
    {
      "classification_loss": 0.5196607708930969,
      "epoch": 6.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1961,
      "total_loss": 0.5196607708930969
    },
    {
      "classification_loss": 0.5413677096366882,
      "epoch": 6.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1962,
      "total_loss": 0.5413677096366882
    },
    {
      "classification_loss": 0.5406394600868225,
      "epoch": 6.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1963,
      "total_loss": 0.5406394600868225
    },
    {
      "classification_loss": 0.5935238599777222,
      "epoch": 6.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1964,
      "total_loss": 0.5935238599777222
    },
    {
      "classification_loss": 0.6249373555183411,
      "epoch": 6.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1965,
      "total_loss": 0.6249373555183411
    },
    {
      "classification_loss": 0.583785355091095,
      "epoch": 6.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1966,
      "total_loss": 0.583785355091095
    },
    {
      "classification_loss": 0.5291670560836792,
      "epoch": 6.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1967,
      "total_loss": 0.5291670560836792
    },
    {
      "classification_loss": 0.49045923352241516,
      "epoch": 6.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1968,
      "total_loss": 0.49045923352241516
    },
    {
      "classification_loss": 0.5749019384384155,
      "epoch": 6.4557377049180324,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1969,
      "total_loss": 0.5749019384384155
    },
    {
      "classification_loss": 0.6093562245368958,
      "epoch": 6.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1970,
      "total_loss": 0.6093562245368958
    },
    {
      "classification_loss": 0.5469800233840942,
      "epoch": 6.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1971,
      "total_loss": 0.5469800233840942
    },
    {
      "classification_loss": 0.5206718444824219,
      "epoch": 6.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1972,
      "total_loss": 0.5206718444824219
    },
    {
      "classification_loss": 0.5375683903694153,
      "epoch": 6.468852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1973,
      "total_loss": 0.5375683903694153
    },
    {
      "classification_loss": 0.579902708530426,
      "epoch": 6.472131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1974,
      "total_loss": 0.579902708530426
    },
    {
      "classification_loss": 0.5228362679481506,
      "epoch": 6.475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1975,
      "total_loss": 0.5228362679481506
    },
    {
      "classification_loss": 0.6066150069236755,
      "epoch": 6.478688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1976,
      "total_loss": 0.6066150069236755
    },
    {
      "classification_loss": 0.48448503017425537,
      "epoch": 6.481967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1977,
      "total_loss": 0.48448503017425537
    },
    {
      "classification_loss": 0.6770217418670654,
      "epoch": 6.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1978,
      "total_loss": 0.6770217418670654
    },
    {
      "classification_loss": 0.47574952244758606,
      "epoch": 6.488524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1979,
      "total_loss": 0.47574952244758606
    },
    {
      "classification_loss": 0.497102290391922,
      "epoch": 6.491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1980,
      "total_loss": 0.497102290391922
    },
    {
      "classification_loss": 0.6027023792266846,
      "epoch": 6.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1981,
      "total_loss": 0.6027023792266846
    },
    {
      "classification_loss": 0.5244691371917725,
      "epoch": 6.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1982,
      "total_loss": 0.5244691371917725
    },
    {
      "classification_loss": 0.6051304340362549,
      "epoch": 6.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1983,
      "total_loss": 0.6051304340362549
    },
    {
      "classification_loss": 0.6525186896324158,
      "epoch": 6.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1984,
      "total_loss": 0.6525186896324158
    },
    {
      "classification_loss": 0.4799674451351166,
      "epoch": 6.508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1985,
      "total_loss": 0.4799674451351166
    },
    {
      "classification_loss": 0.6086431741714478,
      "epoch": 6.511475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1986,
      "total_loss": 0.6086431741714478
    },
    {
      "classification_loss": 0.615989625453949,
      "epoch": 6.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1987,
      "total_loss": 0.615989625453949
    },
    {
      "classification_loss": 0.6696933507919312,
      "epoch": 6.518032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1988,
      "total_loss": 0.6696933507919312
    },
    {
      "classification_loss": 0.5169110298156738,
      "epoch": 6.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1989,
      "total_loss": 0.5169110298156738
    },
    {
      "classification_loss": 0.5121592879295349,
      "epoch": 6.524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1990,
      "total_loss": 0.5121592879295349
    },
    {
      "classification_loss": 0.48339328169822693,
      "epoch": 6.527868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1991,
      "total_loss": 0.48339328169822693
    },
    {
      "classification_loss": 0.4601117968559265,
      "epoch": 6.531147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1992,
      "total_loss": 0.4601117968559265
    },
    {
      "classification_loss": 0.6889253258705139,
      "epoch": 6.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1993,
      "total_loss": 0.6889253258705139
    },
    {
      "classification_loss": 0.6248493194580078,
      "epoch": 6.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1994,
      "total_loss": 0.6248493194580078
    },
    {
      "classification_loss": 0.48045387864112854,
      "epoch": 6.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1995,
      "total_loss": 0.48045387864112854
    },
    {
      "classification_loss": 0.5777323842048645,
      "epoch": 6.5442622950819676,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1996,
      "total_loss": 0.5777323842048645
    },
    {
      "classification_loss": 0.6006425023078918,
      "epoch": 6.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1997,
      "total_loss": 0.6006425023078918
    },
    {
      "classification_loss": 0.5898413062095642,
      "epoch": 6.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1998,
      "total_loss": 0.5898413062095642
    },
    {
      "classification_loss": 0.6662626266479492,
      "epoch": 6.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 1999,
      "total_loss": 0.6662626266479492
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 2.9474213123321533,
      "learning_rate": 0.00013670000000000002,
      "loss": 0.5797,
      "step": 2000
    },
    {
      "classification_loss": 0.7436827421188354,
      "epoch": 6.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2000,
      "total_loss": 0.7436827421188354
    },
    {
      "classification_loss": 0.5597279667854309,
      "epoch": 6.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2001,
      "total_loss": 0.5597279667854309
    },
    {
      "classification_loss": 0.5750166773796082,
      "epoch": 6.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2002,
      "total_loss": 0.5750166773796082
    },
    {
      "classification_loss": 0.599388062953949,
      "epoch": 6.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2003,
      "total_loss": 0.599388062953949
    },
    {
      "classification_loss": 0.6171501874923706,
      "epoch": 6.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2004,
      "total_loss": 0.6171501874923706
    },
    {
      "classification_loss": 0.5993971228599548,
      "epoch": 6.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2005,
      "total_loss": 0.5993971228599548
    },
    {
      "classification_loss": 0.5589185953140259,
      "epoch": 6.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2006,
      "total_loss": 0.5589185953140259
    },
    {
      "classification_loss": 0.5836004614830017,
      "epoch": 6.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2007,
      "total_loss": 0.5836004614830017
    },
    {
      "classification_loss": 0.6420932412147522,
      "epoch": 6.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2008,
      "total_loss": 0.6420932412147522
    },
    {
      "classification_loss": 0.5580072402954102,
      "epoch": 6.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2009,
      "total_loss": 0.5580072402954102
    },
    {
      "classification_loss": 0.6760755181312561,
      "epoch": 6.590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2010,
      "total_loss": 0.6760755181312561
    },
    {
      "classification_loss": 0.6618524193763733,
      "epoch": 6.593442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2011,
      "total_loss": 0.6618524193763733
    },
    {
      "classification_loss": 0.573767364025116,
      "epoch": 6.5967213114754095,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2012,
      "total_loss": 0.573767364025116
    },
    {
      "classification_loss": 0.5814428925514221,
      "epoch": 6.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2013,
      "total_loss": 0.5814428925514221
    },
    {
      "classification_loss": 0.613120973110199,
      "epoch": 6.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2014,
      "total_loss": 0.613120973110199
    },
    {
      "classification_loss": 0.6347377896308899,
      "epoch": 6.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2015,
      "total_loss": 0.6347377896308899
    },
    {
      "classification_loss": 0.6108342409133911,
      "epoch": 6.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2016,
      "total_loss": 0.6108342409133911
    },
    {
      "classification_loss": 0.5582910180091858,
      "epoch": 6.613114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2017,
      "total_loss": 0.5582910180091858
    },
    {
      "classification_loss": 0.48864954710006714,
      "epoch": 6.616393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2018,
      "total_loss": 0.48864954710006714
    },
    {
      "classification_loss": 0.6938738822937012,
      "epoch": 6.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2019,
      "total_loss": 0.6938738822937012
    },
    {
      "classification_loss": 0.5748821496963501,
      "epoch": 6.622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2020,
      "total_loss": 0.5748821496963501
    },
    {
      "classification_loss": 0.5322710275650024,
      "epoch": 6.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2021,
      "total_loss": 0.5322710275650024
    },
    {
      "classification_loss": 0.6518084406852722,
      "epoch": 6.629508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2022,
      "total_loss": 0.6518084406852722
    },
    {
      "classification_loss": 0.567948043346405,
      "epoch": 6.632786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2023,
      "total_loss": 0.567948043346405
    },
    {
      "classification_loss": 0.525667130947113,
      "epoch": 6.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2024,
      "total_loss": 0.525667130947113
    },
    {
      "classification_loss": 0.56888347864151,
      "epoch": 6.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2025,
      "total_loss": 0.56888347864151
    },
    {
      "classification_loss": 0.5018640756607056,
      "epoch": 6.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2026,
      "total_loss": 0.5018640756607056
    },
    {
      "classification_loss": 0.571433424949646,
      "epoch": 6.645901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2027,
      "total_loss": 0.571433424949646
    },
    {
      "classification_loss": 0.544545590877533,
      "epoch": 6.649180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2028,
      "total_loss": 0.544545590877533
    },
    {
      "classification_loss": 0.5788822174072266,
      "epoch": 6.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2029,
      "total_loss": 0.5788822174072266
    },
    {
      "classification_loss": 0.5623259544372559,
      "epoch": 6.655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2030,
      "total_loss": 0.5623259544372559
    },
    {
      "classification_loss": 0.5050141215324402,
      "epoch": 6.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2031,
      "total_loss": 0.5050141215324402
    },
    {
      "classification_loss": 0.5579201579093933,
      "epoch": 6.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2032,
      "total_loss": 0.5579201579093933
    },
    {
      "classification_loss": 0.5360819101333618,
      "epoch": 6.665573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2033,
      "total_loss": 0.5360819101333618
    },
    {
      "classification_loss": 0.6458388566970825,
      "epoch": 6.668852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2034,
      "total_loss": 0.6458388566970825
    },
    {
      "classification_loss": 0.586941659450531,
      "epoch": 6.672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2035,
      "total_loss": 0.586941659450531
    },
    {
      "classification_loss": 0.6860268115997314,
      "epoch": 6.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2036,
      "total_loss": 0.6860268115997314
    },
    {
      "classification_loss": 0.48096951842308044,
      "epoch": 6.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2037,
      "total_loss": 0.48096951842308044
    },
    {
      "classification_loss": 0.5633184909820557,
      "epoch": 6.6819672131147545,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2038,
      "total_loss": 0.5633184909820557
    },
    {
      "classification_loss": 0.5635315775871277,
      "epoch": 6.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2039,
      "total_loss": 0.5635315775871277
    },
    {
      "classification_loss": 0.5826411843299866,
      "epoch": 6.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2040,
      "total_loss": 0.5826411843299866
    },
    {
      "classification_loss": 0.5847616195678711,
      "epoch": 6.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2041,
      "total_loss": 0.5847616195678711
    },
    {
      "classification_loss": 0.6057602763175964,
      "epoch": 6.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2042,
      "total_loss": 0.6057602763175964
    },
    {
      "classification_loss": 0.47946634888648987,
      "epoch": 6.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2043,
      "total_loss": 0.47946634888648987
    },
    {
      "classification_loss": 0.5664223432540894,
      "epoch": 6.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2044,
      "total_loss": 0.5664223432540894
    },
    {
      "classification_loss": 0.6467429995536804,
      "epoch": 6.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2045,
      "total_loss": 0.6467429995536804
    },
    {
      "classification_loss": 0.7101477384567261,
      "epoch": 6.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2046,
      "total_loss": 0.7101477384567261
    },
    {
      "classification_loss": 0.6228910684585571,
      "epoch": 6.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2047,
      "total_loss": 0.6228910684585571
    },
    {
      "classification_loss": 0.6009197235107422,
      "epoch": 6.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2048,
      "total_loss": 0.6009197235107422
    },
    {
      "classification_loss": 0.5124306678771973,
      "epoch": 6.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2049,
      "total_loss": 0.5124306678771973
    },
    {
      "classification_loss": 0.43942391872406006,
      "epoch": 6.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2050,
      "total_loss": 0.43942391872406006
    },
    {
      "classification_loss": 0.6207420825958252,
      "epoch": 6.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2051,
      "total_loss": 0.6207420825958252
    },
    {
      "classification_loss": 0.5555984973907471,
      "epoch": 6.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2052,
      "total_loss": 0.5555984973907471
    },
    {
      "classification_loss": 0.5483368039131165,
      "epoch": 6.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2053,
      "total_loss": 0.5483368039131165
    },
    {
      "classification_loss": 0.5060427188873291,
      "epoch": 6.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2054,
      "total_loss": 0.5060427188873291
    },
    {
      "classification_loss": 0.5161533355712891,
      "epoch": 6.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2055,
      "total_loss": 0.5161533355712891
    },
    {
      "classification_loss": 0.5859631896018982,
      "epoch": 6.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2056,
      "total_loss": 0.5859631896018982
    },
    {
      "classification_loss": 0.5864253044128418,
      "epoch": 6.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2057,
      "total_loss": 0.5864253044128418
    },
    {
      "classification_loss": 0.5226268768310547,
      "epoch": 6.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2058,
      "total_loss": 0.5226268768310547
    },
    {
      "classification_loss": 0.6186783313751221,
      "epoch": 6.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2059,
      "total_loss": 0.6186783313751221
    },
    {
      "classification_loss": 0.5270388126373291,
      "epoch": 6.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2060,
      "total_loss": 0.5270388126373291
    },
    {
      "classification_loss": 0.5138880610466003,
      "epoch": 6.757377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2061,
      "total_loss": 0.5138880610466003
    },
    {
      "classification_loss": 0.6065405607223511,
      "epoch": 6.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2062,
      "total_loss": 0.6065405607223511
    },
    {
      "classification_loss": 0.6352490782737732,
      "epoch": 6.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2063,
      "total_loss": 0.6352490782737732
    },
    {
      "classification_loss": 0.608647882938385,
      "epoch": 6.767213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2064,
      "total_loss": 0.608647882938385
    },
    {
      "classification_loss": 0.707066535949707,
      "epoch": 6.770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2065,
      "total_loss": 0.707066535949707
    },
    {
      "classification_loss": 0.6488556265830994,
      "epoch": 6.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2066,
      "total_loss": 0.6488556265830994
    },
    {
      "classification_loss": 0.5585483312606812,
      "epoch": 6.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2067,
      "total_loss": 0.5585483312606812
    },
    {
      "classification_loss": 0.578680157661438,
      "epoch": 6.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2068,
      "total_loss": 0.578680157661438
    },
    {
      "classification_loss": 0.5029004812240601,
      "epoch": 6.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2069,
      "total_loss": 0.5029004812240601
    },
    {
      "classification_loss": 0.6499390602111816,
      "epoch": 6.786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2070,
      "total_loss": 0.6499390602111816
    },
    {
      "classification_loss": 0.6298267841339111,
      "epoch": 6.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2071,
      "total_loss": 0.6298267841339111
    },
    {
      "classification_loss": 0.6127386689186096,
      "epoch": 6.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2072,
      "total_loss": 0.6127386689186096
    },
    {
      "classification_loss": 0.6436683535575867,
      "epoch": 6.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2073,
      "total_loss": 0.6436683535575867
    },
    {
      "classification_loss": 0.5444150567054749,
      "epoch": 6.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2074,
      "total_loss": 0.5444150567054749
    },
    {
      "classification_loss": 0.5528721809387207,
      "epoch": 6.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2075,
      "total_loss": 0.5528721809387207
    },
    {
      "classification_loss": 0.6114223599433899,
      "epoch": 6.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2076,
      "total_loss": 0.6114223599433899
    },
    {
      "classification_loss": 0.4814441502094269,
      "epoch": 6.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2077,
      "total_loss": 0.4814441502094269
    },
    {
      "classification_loss": 0.5243132710456848,
      "epoch": 6.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2078,
      "total_loss": 0.5243132710456848
    },
    {
      "classification_loss": 0.640124499797821,
      "epoch": 6.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2079,
      "total_loss": 0.640124499797821
    },
    {
      "classification_loss": 0.5728432536125183,
      "epoch": 6.8196721311475414,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2080,
      "total_loss": 0.5728432536125183
    },
    {
      "classification_loss": 0.5809564590454102,
      "epoch": 6.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2081,
      "total_loss": 0.5809564590454102
    },
    {
      "classification_loss": 0.5452730059623718,
      "epoch": 6.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2082,
      "total_loss": 0.5452730059623718
    },
    {
      "classification_loss": 0.49213486909866333,
      "epoch": 6.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2083,
      "total_loss": 0.49213486909866333
    },
    {
      "classification_loss": 0.5895675420761108,
      "epoch": 6.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2084,
      "total_loss": 0.5895675420761108
    },
    {
      "classification_loss": 0.625373125076294,
      "epoch": 6.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2085,
      "total_loss": 0.625373125076294
    },
    {
      "classification_loss": 0.6014280319213867,
      "epoch": 6.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2086,
      "total_loss": 0.6014280319213867
    },
    {
      "classification_loss": 0.5518819689750671,
      "epoch": 6.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2087,
      "total_loss": 0.5518819689750671
    },
    {
      "classification_loss": 0.6500796675682068,
      "epoch": 6.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2088,
      "total_loss": 0.6500796675682068
    },
    {
      "classification_loss": 0.6509298086166382,
      "epoch": 6.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2089,
      "total_loss": 0.6509298086166382
    },
    {
      "classification_loss": 0.5926067233085632,
      "epoch": 6.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2090,
      "total_loss": 0.5926067233085632
    },
    {
      "classification_loss": 0.6556008458137512,
      "epoch": 6.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2091,
      "total_loss": 0.6556008458137512
    },
    {
      "classification_loss": 0.6229910850524902,
      "epoch": 6.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2092,
      "total_loss": 0.6229910850524902
    },
    {
      "classification_loss": 0.5674539804458618,
      "epoch": 6.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2093,
      "total_loss": 0.5674539804458618
    },
    {
      "classification_loss": 0.6323913335800171,
      "epoch": 6.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2094,
      "total_loss": 0.6323913335800171
    },
    {
      "classification_loss": 0.5893818736076355,
      "epoch": 6.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2095,
      "total_loss": 0.5893818736076355
    },
    {
      "classification_loss": 0.5363665819168091,
      "epoch": 6.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2096,
      "total_loss": 0.5363665819168091
    },
    {
      "classification_loss": 0.5964040160179138,
      "epoch": 6.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2097,
      "total_loss": 0.5964040160179138
    },
    {
      "classification_loss": 0.5231974720954895,
      "epoch": 6.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2098,
      "total_loss": 0.5231974720954895
    },
    {
      "classification_loss": 0.5569753646850586,
      "epoch": 6.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2099,
      "total_loss": 0.5569753646850586
    },
    {
      "epoch": 6.885245901639344,
      "grad_norm": 6.427957057952881,
      "learning_rate": 0.00013336666666666666,
      "loss": 0.5836,
      "step": 2100
    },
    {
      "classification_loss": 0.5096527338027954,
      "epoch": 6.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2100,
      "total_loss": 0.5096527338027954
    },
    {
      "classification_loss": 0.5969736576080322,
      "epoch": 6.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2101,
      "total_loss": 0.5969736576080322
    },
    {
      "classification_loss": 0.6810275316238403,
      "epoch": 6.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2102,
      "total_loss": 0.6810275316238403
    },
    {
      "classification_loss": 0.6406946778297424,
      "epoch": 6.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2103,
      "total_loss": 0.6406946778297424
    },
    {
      "classification_loss": 0.5494080781936646,
      "epoch": 6.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2104,
      "total_loss": 0.5494080781936646
    },
    {
      "classification_loss": 0.629777729511261,
      "epoch": 6.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2105,
      "total_loss": 0.629777729511261
    },
    {
      "classification_loss": 0.681940495967865,
      "epoch": 6.9049180327868855,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2106,
      "total_loss": 0.681940495967865
    },
    {
      "classification_loss": 0.6487393379211426,
      "epoch": 6.908196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2107,
      "total_loss": 0.6487393379211426
    },
    {
      "classification_loss": 0.626671552658081,
      "epoch": 6.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2108,
      "total_loss": 0.626671552658081
    },
    {
      "classification_loss": 0.5741936564445496,
      "epoch": 6.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2109,
      "total_loss": 0.5741936564445496
    },
    {
      "classification_loss": 0.5792255401611328,
      "epoch": 6.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2110,
      "total_loss": 0.5792255401611328
    },
    {
      "classification_loss": 0.6487634181976318,
      "epoch": 6.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2111,
      "total_loss": 0.6487634181976318
    },
    {
      "classification_loss": 0.6320961713790894,
      "epoch": 6.924590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2112,
      "total_loss": 0.6320961713790894
    },
    {
      "classification_loss": 0.5962474346160889,
      "epoch": 6.927868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2113,
      "total_loss": 0.5962474346160889
    },
    {
      "classification_loss": 0.5486433506011963,
      "epoch": 6.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2114,
      "total_loss": 0.5486433506011963
    },
    {
      "classification_loss": 0.5775031447410583,
      "epoch": 6.934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2115,
      "total_loss": 0.5775031447410583
    },
    {
      "classification_loss": 0.5805951952934265,
      "epoch": 6.937704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2116,
      "total_loss": 0.5805951952934265
    },
    {
      "classification_loss": 0.5411761403083801,
      "epoch": 6.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2117,
      "total_loss": 0.5411761403083801
    },
    {
      "classification_loss": 0.6263130307197571,
      "epoch": 6.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2118,
      "total_loss": 0.6263130307197571
    },
    {
      "classification_loss": 0.683358371257782,
      "epoch": 6.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2119,
      "total_loss": 0.683358371257782
    },
    {
      "classification_loss": 0.6976550221443176,
      "epoch": 6.950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2120,
      "total_loss": 0.6976550221443176
    },
    {
      "classification_loss": 0.5971542596817017,
      "epoch": 6.954098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2121,
      "total_loss": 0.5971542596817017
    },
    {
      "classification_loss": 0.5799683332443237,
      "epoch": 6.9573770491803275,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2122,
      "total_loss": 0.5799683332443237
    },
    {
      "classification_loss": 0.572638988494873,
      "epoch": 6.9606557377049185,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2123,
      "total_loss": 0.572638988494873
    },
    {
      "classification_loss": 0.49484556913375854,
      "epoch": 6.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2124,
      "total_loss": 0.49484556913375854
    },
    {
      "classification_loss": 0.6596946716308594,
      "epoch": 6.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2125,
      "total_loss": 0.6596946716308594
    },
    {
      "classification_loss": 0.6206018924713135,
      "epoch": 6.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2126,
      "total_loss": 0.6206018924713135
    },
    {
      "classification_loss": 0.6198456287384033,
      "epoch": 6.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2127,
      "total_loss": 0.6198456287384033
    },
    {
      "classification_loss": 0.5676701664924622,
      "epoch": 6.977049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2128,
      "total_loss": 0.5676701664924622
    },
    {
      "classification_loss": 0.5738524794578552,
      "epoch": 6.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2129,
      "total_loss": 0.5738524794578552
    },
    {
      "classification_loss": 0.5069800615310669,
      "epoch": 6.983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2130,
      "total_loss": 0.5069800615310669
    },
    {
      "classification_loss": 0.5972415804862976,
      "epoch": 6.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2131,
      "total_loss": 0.5972415804862976
    },
    {
      "classification_loss": 0.6393265724182129,
      "epoch": 6.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2132,
      "total_loss": 0.6393265724182129
    },
    {
      "classification_loss": 0.5486496090888977,
      "epoch": 6.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2133,
      "total_loss": 0.5486496090888977
    },
    {
      "classification_loss": 0.47165313363075256,
      "epoch": 6.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2134,
      "total_loss": 0.47165313363075256
    },
    {
      "classification_loss": 1.0402005910873413,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 1.0402005910873413
    },
    {
      "classification_loss": 0.9970782399177551,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.9970782399177551
    },
    {
      "classification_loss": 0.961433470249176,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.961433470249176
    },
    {
      "classification_loss": 1.1085749864578247,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 1.1085749864578247
    },
    {
      "classification_loss": 0.9497223496437073,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.9497223496437073
    },
    {
      "classification_loss": 0.9361813068389893,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.9361813068389893
    },
    {
      "classification_loss": 0.9766021370887756,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.9766021370887756
    },
    {
      "classification_loss": 0.8762876987457275,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.8762876987457275
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.369,
      "eval_f1": 0.006299212598425197,
      "eval_loss": 0.9832673668861389,
      "eval_precision": 0.4,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0408,
      "eval_samples_per_second": 165.541,
      "eval_steps_per_second": 1.324,
      "step": 2135
    },
    {
      "classification_loss": 0.4707390069961548,
      "epoch": 7.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2135,
      "total_loss": 0.4707390069961548
    },
    {
      "classification_loss": 0.5991479158401489,
      "epoch": 7.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2136,
      "total_loss": 0.5991479158401489
    },
    {
      "classification_loss": 0.6056131720542908,
      "epoch": 7.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2137,
      "total_loss": 0.6056131720542908
    },
    {
      "classification_loss": 0.5610402226448059,
      "epoch": 7.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2138,
      "total_loss": 0.5610402226448059
    },
    {
      "classification_loss": 0.4882742464542389,
      "epoch": 7.0131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2139,
      "total_loss": 0.4882742464542389
    },
    {
      "classification_loss": 0.5914344191551208,
      "epoch": 7.016393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2140,
      "total_loss": 0.5914344191551208
    },
    {
      "classification_loss": 0.5904706120491028,
      "epoch": 7.019672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2141,
      "total_loss": 0.5904706120491028
    },
    {
      "classification_loss": 0.5244733691215515,
      "epoch": 7.022950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2142,
      "total_loss": 0.5244733691215515
    },
    {
      "classification_loss": 0.5827012658119202,
      "epoch": 7.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2143,
      "total_loss": 0.5827012658119202
    },
    {
      "classification_loss": 0.5759416818618774,
      "epoch": 7.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2144,
      "total_loss": 0.5759416818618774
    },
    {
      "classification_loss": 0.5376010537147522,
      "epoch": 7.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2145,
      "total_loss": 0.5376010537147522
    },
    {
      "classification_loss": 0.6185182929039001,
      "epoch": 7.036065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2146,
      "total_loss": 0.6185182929039001
    },
    {
      "classification_loss": 0.6511136889457703,
      "epoch": 7.039344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2147,
      "total_loss": 0.6511136889457703
    },
    {
      "classification_loss": 0.5457909107208252,
      "epoch": 7.0426229508196725,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2148,
      "total_loss": 0.5457909107208252
    },
    {
      "classification_loss": 0.6425703763961792,
      "epoch": 7.045901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2149,
      "total_loss": 0.6425703763961792
    },
    {
      "classification_loss": 0.5583280920982361,
      "epoch": 7.049180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2150,
      "total_loss": 0.5583280920982361
    },
    {
      "classification_loss": 0.587374210357666,
      "epoch": 7.052459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2151,
      "total_loss": 0.587374210357666
    },
    {
      "classification_loss": 0.5665491819381714,
      "epoch": 7.055737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2152,
      "total_loss": 0.5665491819381714
    },
    {
      "classification_loss": 0.5753453373908997,
      "epoch": 7.059016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2153,
      "total_loss": 0.5753453373908997
    },
    {
      "classification_loss": 0.5835581421852112,
      "epoch": 7.062295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2154,
      "total_loss": 0.5835581421852112
    },
    {
      "classification_loss": 0.5734714865684509,
      "epoch": 7.065573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2155,
      "total_loss": 0.5734714865684509
    },
    {
      "classification_loss": 0.5199705362319946,
      "epoch": 7.0688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2156,
      "total_loss": 0.5199705362319946
    },
    {
      "classification_loss": 0.7241769433021545,
      "epoch": 7.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2157,
      "total_loss": 0.7241769433021545
    },
    {
      "classification_loss": 0.6044909358024597,
      "epoch": 7.075409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2158,
      "total_loss": 0.6044909358024597
    },
    {
      "classification_loss": 0.6461160182952881,
      "epoch": 7.078688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2159,
      "total_loss": 0.6461160182952881
    },
    {
      "classification_loss": 0.5472989678382874,
      "epoch": 7.081967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2160,
      "total_loss": 0.5472989678382874
    },
    {
      "classification_loss": 0.5083603262901306,
      "epoch": 7.085245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2161,
      "total_loss": 0.5083603262901306
    },
    {
      "classification_loss": 0.5274423360824585,
      "epoch": 7.088524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2162,
      "total_loss": 0.5274423360824585
    },
    {
      "classification_loss": 0.6032254099845886,
      "epoch": 7.091803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2163,
      "total_loss": 0.6032254099845886
    },
    {
      "classification_loss": 0.5337405204772949,
      "epoch": 7.0950819672131145,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2164,
      "total_loss": 0.5337405204772949
    },
    {
      "classification_loss": 0.5576338171958923,
      "epoch": 7.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2165,
      "total_loss": 0.5576338171958923
    },
    {
      "classification_loss": 0.6209521889686584,
      "epoch": 7.101639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2166,
      "total_loss": 0.6209521889686584
    },
    {
      "classification_loss": 0.4655783772468567,
      "epoch": 7.104918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2167,
      "total_loss": 0.4655783772468567
    },
    {
      "classification_loss": 0.6478050351142883,
      "epoch": 7.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2168,
      "total_loss": 0.6478050351142883
    },
    {
      "classification_loss": 0.5341127514839172,
      "epoch": 7.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2169,
      "total_loss": 0.5341127514839172
    },
    {
      "classification_loss": 0.5395431518554688,
      "epoch": 7.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2170,
      "total_loss": 0.5395431518554688
    },
    {
      "classification_loss": 0.5408276915550232,
      "epoch": 7.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2171,
      "total_loss": 0.5408276915550232
    },
    {
      "classification_loss": 0.5330021381378174,
      "epoch": 7.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2172,
      "total_loss": 0.5330021381378174
    },
    {
      "classification_loss": 0.5812336802482605,
      "epoch": 7.1245901639344265,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2173,
      "total_loss": 0.5812336802482605
    },
    {
      "classification_loss": 0.6621126532554626,
      "epoch": 7.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2174,
      "total_loss": 0.6621126532554626
    },
    {
      "classification_loss": 0.5687897205352783,
      "epoch": 7.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2175,
      "total_loss": 0.5687897205352783
    },
    {
      "classification_loss": 0.4927796423435211,
      "epoch": 7.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2176,
      "total_loss": 0.4927796423435211
    },
    {
      "classification_loss": 0.6075738072395325,
      "epoch": 7.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2177,
      "total_loss": 0.6075738072395325
    },
    {
      "classification_loss": 0.49745163321495056,
      "epoch": 7.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2178,
      "total_loss": 0.49745163321495056
    },
    {
      "classification_loss": 0.49895718693733215,
      "epoch": 7.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2179,
      "total_loss": 0.49895718693733215
    },
    {
      "classification_loss": 0.5805128216743469,
      "epoch": 7.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2180,
      "total_loss": 0.5805128216743469
    },
    {
      "classification_loss": 0.5606132745742798,
      "epoch": 7.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2181,
      "total_loss": 0.5606132745742798
    },
    {
      "classification_loss": 0.5280190110206604,
      "epoch": 7.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2182,
      "total_loss": 0.5280190110206604
    },
    {
      "classification_loss": 0.6365953683853149,
      "epoch": 7.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2183,
      "total_loss": 0.6365953683853149
    },
    {
      "classification_loss": 0.5111026167869568,
      "epoch": 7.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2184,
      "total_loss": 0.5111026167869568
    },
    {
      "classification_loss": 0.6415678858757019,
      "epoch": 7.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2185,
      "total_loss": 0.6415678858757019
    },
    {
      "classification_loss": 0.5382848978042603,
      "epoch": 7.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2186,
      "total_loss": 0.5382848978042603
    },
    {
      "classification_loss": 0.576820969581604,
      "epoch": 7.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2187,
      "total_loss": 0.576820969581604
    },
    {
      "classification_loss": 0.4970181882381439,
      "epoch": 7.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2188,
      "total_loss": 0.4970181882381439
    },
    {
      "classification_loss": 0.629335343837738,
      "epoch": 7.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2189,
      "total_loss": 0.629335343837738
    },
    {
      "classification_loss": 0.547424852848053,
      "epoch": 7.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2190,
      "total_loss": 0.547424852848053
    },
    {
      "classification_loss": 0.5409608483314514,
      "epoch": 7.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2191,
      "total_loss": 0.5409608483314514
    },
    {
      "classification_loss": 0.45569947361946106,
      "epoch": 7.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2192,
      "total_loss": 0.45569947361946106
    },
    {
      "classification_loss": 0.6152675151824951,
      "epoch": 7.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2193,
      "total_loss": 0.6152675151824951
    },
    {
      "classification_loss": 0.5844441652297974,
      "epoch": 7.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2194,
      "total_loss": 0.5844441652297974
    },
    {
      "classification_loss": 0.52587890625,
      "epoch": 7.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2195,
      "total_loss": 0.52587890625
    },
    {
      "classification_loss": 0.5617908835411072,
      "epoch": 7.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2196,
      "total_loss": 0.5617908835411072
    },
    {
      "classification_loss": 0.6851930022239685,
      "epoch": 7.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2197,
      "total_loss": 0.6851930022239685
    },
    {
      "classification_loss": 0.5567874908447266,
      "epoch": 7.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2198,
      "total_loss": 0.5567874908447266
    },
    {
      "classification_loss": 0.5328878164291382,
      "epoch": 7.2098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2199,
      "total_loss": 0.5328878164291382
    },
    {
      "epoch": 7.213114754098361,
      "grad_norm": 6.9794816970825195,
      "learning_rate": 0.00013003333333333334,
      "loss": 0.578,
      "step": 2200
    },
    {
      "classification_loss": 0.5524949431419373,
      "epoch": 7.213114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2200,
      "total_loss": 0.5524949431419373
    },
    {
      "classification_loss": 0.6515294909477234,
      "epoch": 7.216393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2201,
      "total_loss": 0.6515294909477234
    },
    {
      "classification_loss": 0.5295615196228027,
      "epoch": 7.219672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2202,
      "total_loss": 0.5295615196228027
    },
    {
      "classification_loss": 0.5485080480575562,
      "epoch": 7.222950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2203,
      "total_loss": 0.5485080480575562
    },
    {
      "classification_loss": 0.49933579564094543,
      "epoch": 7.226229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2204,
      "total_loss": 0.49933579564094543
    },
    {
      "classification_loss": 0.6376144289970398,
      "epoch": 7.229508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2205,
      "total_loss": 0.6376144289970398
    },
    {
      "classification_loss": 0.5514587163925171,
      "epoch": 7.232786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2206,
      "total_loss": 0.5514587163925171
    },
    {
      "classification_loss": 0.5564182996749878,
      "epoch": 7.2360655737704915,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2207,
      "total_loss": 0.5564182996749878
    },
    {
      "classification_loss": 0.5019485354423523,
      "epoch": 7.239344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2208,
      "total_loss": 0.5019485354423523
    },
    {
      "classification_loss": 0.5780033469200134,
      "epoch": 7.242622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2209,
      "total_loss": 0.5780033469200134
    },
    {
      "classification_loss": 0.5423639416694641,
      "epoch": 7.245901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2210,
      "total_loss": 0.5423639416694641
    },
    {
      "classification_loss": 0.528286337852478,
      "epoch": 7.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2211,
      "total_loss": 0.528286337852478
    },
    {
      "classification_loss": 0.5892131328582764,
      "epoch": 7.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2212,
      "total_loss": 0.5892131328582764
    },
    {
      "classification_loss": 0.5853229761123657,
      "epoch": 7.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2213,
      "total_loss": 0.5853229761123657
    },
    {
      "classification_loss": 0.525056004524231,
      "epoch": 7.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2214,
      "total_loss": 0.525056004524231
    },
    {
      "classification_loss": 0.5357018113136292,
      "epoch": 7.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2215,
      "total_loss": 0.5357018113136292
    },
    {
      "classification_loss": 0.5258357524871826,
      "epoch": 7.2655737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2216,
      "total_loss": 0.5258357524871826
    },
    {
      "classification_loss": 0.48814067244529724,
      "epoch": 7.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2217,
      "total_loss": 0.48814067244529724
    },
    {
      "classification_loss": 0.5596319437026978,
      "epoch": 7.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2218,
      "total_loss": 0.5596319437026978
    },
    {
      "classification_loss": 0.47210779786109924,
      "epoch": 7.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2219,
      "total_loss": 0.47210779786109924
    },
    {
      "classification_loss": 0.5685082674026489,
      "epoch": 7.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2220,
      "total_loss": 0.5685082674026489
    },
    {
      "classification_loss": 0.51787930727005,
      "epoch": 7.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2221,
      "total_loss": 0.51787930727005
    },
    {
      "classification_loss": 0.5860518217086792,
      "epoch": 7.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2222,
      "total_loss": 0.5860518217086792
    },
    {
      "classification_loss": 0.6863916516304016,
      "epoch": 7.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2223,
      "total_loss": 0.6863916516304016
    },
    {
      "classification_loss": 0.5421153903007507,
      "epoch": 7.2918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2224,
      "total_loss": 0.5421153903007507
    },
    {
      "classification_loss": 0.5348601341247559,
      "epoch": 7.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2225,
      "total_loss": 0.5348601341247559
    },
    {
      "classification_loss": 0.46573564410209656,
      "epoch": 7.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2226,
      "total_loss": 0.46573564410209656
    },
    {
      "classification_loss": 0.5414952635765076,
      "epoch": 7.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2227,
      "total_loss": 0.5414952635765076
    },
    {
      "classification_loss": 0.6008152961730957,
      "epoch": 7.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2228,
      "total_loss": 0.6008152961730957
    },
    {
      "classification_loss": 0.6117206811904907,
      "epoch": 7.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2229,
      "total_loss": 0.6117206811904907
    },
    {
      "classification_loss": 0.6033264994621277,
      "epoch": 7.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2230,
      "total_loss": 0.6033264994621277
    },
    {
      "classification_loss": 0.5582627058029175,
      "epoch": 7.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2231,
      "total_loss": 0.5582627058029175
    },
    {
      "classification_loss": 0.644048810005188,
      "epoch": 7.3180327868852455,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2232,
      "total_loss": 0.644048810005188
    },
    {
      "classification_loss": 0.5769757032394409,
      "epoch": 7.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2233,
      "total_loss": 0.5769757032394409
    },
    {
      "classification_loss": 0.5439237952232361,
      "epoch": 7.324590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2234,
      "total_loss": 0.5439237952232361
    },
    {
      "classification_loss": 0.5787501931190491,
      "epoch": 7.327868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2235,
      "total_loss": 0.5787501931190491
    },
    {
      "classification_loss": 0.5392086505889893,
      "epoch": 7.331147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2236,
      "total_loss": 0.5392086505889893
    },
    {
      "classification_loss": 0.5943610072135925,
      "epoch": 7.334426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2237,
      "total_loss": 0.5943610072135925
    },
    {
      "classification_loss": 0.5948960185050964,
      "epoch": 7.337704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2238,
      "total_loss": 0.5948960185050964
    },
    {
      "classification_loss": 0.6819850206375122,
      "epoch": 7.340983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2239,
      "total_loss": 0.6819850206375122
    },
    {
      "classification_loss": 0.44412434101104736,
      "epoch": 7.344262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2240,
      "total_loss": 0.44412434101104736
    },
    {
      "classification_loss": 0.5980879664421082,
      "epoch": 7.3475409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2241,
      "total_loss": 0.5980879664421082
    },
    {
      "classification_loss": 0.6502677798271179,
      "epoch": 7.350819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2242,
      "total_loss": 0.6502677798271179
    },
    {
      "classification_loss": 0.5705165863037109,
      "epoch": 7.354098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2243,
      "total_loss": 0.5705165863037109
    },
    {
      "classification_loss": 0.5198127627372742,
      "epoch": 7.357377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2244,
      "total_loss": 0.5198127627372742
    },
    {
      "classification_loss": 0.5154420137405396,
      "epoch": 7.360655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2245,
      "total_loss": 0.5154420137405396
    },
    {
      "classification_loss": 0.5489954352378845,
      "epoch": 7.363934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2246,
      "total_loss": 0.5489954352378845
    },
    {
      "classification_loss": 0.5655993819236755,
      "epoch": 7.367213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2247,
      "total_loss": 0.5655993819236755
    },
    {
      "classification_loss": 0.6460086107254028,
      "epoch": 7.370491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2248,
      "total_loss": 0.6460086107254028
    },
    {
      "classification_loss": 0.5605905055999756,
      "epoch": 7.3737704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2249,
      "total_loss": 0.5605905055999756
    },
    {
      "classification_loss": 0.49057555198669434,
      "epoch": 7.377049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2250,
      "total_loss": 0.49057555198669434
    },
    {
      "classification_loss": 0.5831191539764404,
      "epoch": 7.380327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2251,
      "total_loss": 0.5831191539764404
    },
    {
      "classification_loss": 0.5738532543182373,
      "epoch": 7.383606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2252,
      "total_loss": 0.5738532543182373
    },
    {
      "classification_loss": 0.5404742956161499,
      "epoch": 7.386885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2253,
      "total_loss": 0.5404742956161499
    },
    {
      "classification_loss": 0.7213970422744751,
      "epoch": 7.390163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2254,
      "total_loss": 0.7213970422744751
    },
    {
      "classification_loss": 0.6502588391304016,
      "epoch": 7.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2255,
      "total_loss": 0.6502588391304016
    },
    {
      "classification_loss": 0.5779232382774353,
      "epoch": 7.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2256,
      "total_loss": 0.5779232382774353
    },
    {
      "classification_loss": 0.5479434132575989,
      "epoch": 7.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2257,
      "total_loss": 0.5479434132575989
    },
    {
      "classification_loss": 0.5781263113021851,
      "epoch": 7.4032786885245905,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2258,
      "total_loss": 0.5781263113021851
    },
    {
      "classification_loss": 0.6134321689605713,
      "epoch": 7.406557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2259,
      "total_loss": 0.6134321689605713
    },
    {
      "classification_loss": 0.6116001605987549,
      "epoch": 7.409836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2260,
      "total_loss": 0.6116001605987549
    },
    {
      "classification_loss": 0.5729891061782837,
      "epoch": 7.413114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2261,
      "total_loss": 0.5729891061782837
    },
    {
      "classification_loss": 0.5627657175064087,
      "epoch": 7.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2262,
      "total_loss": 0.5627657175064087
    },
    {
      "classification_loss": 0.601779580116272,
      "epoch": 7.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2263,
      "total_loss": 0.601779580116272
    },
    {
      "classification_loss": 0.6282982230186462,
      "epoch": 7.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2264,
      "total_loss": 0.6282982230186462
    },
    {
      "classification_loss": 0.6351989507675171,
      "epoch": 7.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2265,
      "total_loss": 0.6351989507675171
    },
    {
      "classification_loss": 0.5781704187393188,
      "epoch": 7.4295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2266,
      "total_loss": 0.5781704187393188
    },
    {
      "classification_loss": 0.6696004271507263,
      "epoch": 7.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2267,
      "total_loss": 0.6696004271507263
    },
    {
      "classification_loss": 0.5621824264526367,
      "epoch": 7.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2268,
      "total_loss": 0.5621824264526367
    },
    {
      "classification_loss": 0.5609009861946106,
      "epoch": 7.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2269,
      "total_loss": 0.5609009861946106
    },
    {
      "classification_loss": 0.5890737771987915,
      "epoch": 7.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2270,
      "total_loss": 0.5890737771987915
    },
    {
      "classification_loss": 0.5718053579330444,
      "epoch": 7.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2271,
      "total_loss": 0.5718053579330444
    },
    {
      "classification_loss": 0.49598175287246704,
      "epoch": 7.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2272,
      "total_loss": 0.49598175287246704
    },
    {
      "classification_loss": 0.5271434187889099,
      "epoch": 7.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2273,
      "total_loss": 0.5271434187889099
    },
    {
      "classification_loss": 0.4816433787345886,
      "epoch": 7.4557377049180324,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2274,
      "total_loss": 0.4816433787345886
    },
    {
      "classification_loss": 0.660227358341217,
      "epoch": 7.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2275,
      "total_loss": 0.660227358341217
    },
    {
      "classification_loss": 0.498272567987442,
      "epoch": 7.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2276,
      "total_loss": 0.498272567987442
    },
    {
      "classification_loss": 0.49814528226852417,
      "epoch": 7.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2277,
      "total_loss": 0.49814528226852417
    },
    {
      "classification_loss": 0.6038525700569153,
      "epoch": 7.468852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2278,
      "total_loss": 0.6038525700569153
    },
    {
      "classification_loss": 0.7057598233222961,
      "epoch": 7.472131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2279,
      "total_loss": 0.7057598233222961
    },
    {
      "classification_loss": 0.5535172820091248,
      "epoch": 7.475409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2280,
      "total_loss": 0.5535172820091248
    },
    {
      "classification_loss": 0.5167403221130371,
      "epoch": 7.478688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2281,
      "total_loss": 0.5167403221130371
    },
    {
      "classification_loss": 0.5380799174308777,
      "epoch": 7.481967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2282,
      "total_loss": 0.5380799174308777
    },
    {
      "classification_loss": 0.4951641261577606,
      "epoch": 7.4852459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2283,
      "total_loss": 0.4951641261577606
    },
    {
      "classification_loss": 0.48081108927726746,
      "epoch": 7.488524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2284,
      "total_loss": 0.48081108927726746
    },
    {
      "classification_loss": 0.6443471312522888,
      "epoch": 7.491803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2285,
      "total_loss": 0.6443471312522888
    },
    {
      "classification_loss": 0.568490743637085,
      "epoch": 7.495081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2286,
      "total_loss": 0.568490743637085
    },
    {
      "classification_loss": 0.6145883202552795,
      "epoch": 7.498360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2287,
      "total_loss": 0.6145883202552795
    },
    {
      "classification_loss": 0.5329365134239197,
      "epoch": 7.501639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2288,
      "total_loss": 0.5329365134239197
    },
    {
      "classification_loss": 0.5401083827018738,
      "epoch": 7.504918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2289,
      "total_loss": 0.5401083827018738
    },
    {
      "classification_loss": 0.5305216312408447,
      "epoch": 7.508196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2290,
      "total_loss": 0.5305216312408447
    },
    {
      "classification_loss": 0.5198214054107666,
      "epoch": 7.511475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2291,
      "total_loss": 0.5198214054107666
    },
    {
      "classification_loss": 0.5961601734161377,
      "epoch": 7.5147540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2292,
      "total_loss": 0.5961601734161377
    },
    {
      "classification_loss": 0.5292035937309265,
      "epoch": 7.518032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2293,
      "total_loss": 0.5292035937309265
    },
    {
      "classification_loss": 0.5479442477226257,
      "epoch": 7.521311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2294,
      "total_loss": 0.5479442477226257
    },
    {
      "classification_loss": 0.6112058758735657,
      "epoch": 7.524590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2295,
      "total_loss": 0.6112058758735657
    },
    {
      "classification_loss": 0.4884969890117645,
      "epoch": 7.527868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2296,
      "total_loss": 0.4884969890117645
    },
    {
      "classification_loss": 0.6506357192993164,
      "epoch": 7.531147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2297,
      "total_loss": 0.6506357192993164
    },
    {
      "classification_loss": 0.4600687623023987,
      "epoch": 7.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2298,
      "total_loss": 0.4600687623023987
    },
    {
      "classification_loss": 0.5504701137542725,
      "epoch": 7.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2299,
      "total_loss": 0.5504701137542725
    },
    {
      "epoch": 7.540983606557377,
      "grad_norm": 6.208115100860596,
      "learning_rate": 0.0001267,
      "loss": 0.5661,
      "step": 2300
    },
    {
      "classification_loss": 0.6858718991279602,
      "epoch": 7.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2300,
      "total_loss": 0.6858718991279602
    },
    {
      "classification_loss": 0.5898471474647522,
      "epoch": 7.5442622950819676,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2301,
      "total_loss": 0.5898471474647522
    },
    {
      "classification_loss": 0.5724513530731201,
      "epoch": 7.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2302,
      "total_loss": 0.5724513530731201
    },
    {
      "classification_loss": 0.48747649788856506,
      "epoch": 7.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2303,
      "total_loss": 0.48747649788856506
    },
    {
      "classification_loss": 0.5737395882606506,
      "epoch": 7.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2304,
      "total_loss": 0.5737395882606506
    },
    {
      "classification_loss": 0.5396084785461426,
      "epoch": 7.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2305,
      "total_loss": 0.5396084785461426
    },
    {
      "classification_loss": 0.6353602409362793,
      "epoch": 7.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2306,
      "total_loss": 0.6353602409362793
    },
    {
      "classification_loss": 0.5507383942604065,
      "epoch": 7.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2307,
      "total_loss": 0.5507383942604065
    },
    {
      "classification_loss": 0.7028002142906189,
      "epoch": 7.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2308,
      "total_loss": 0.7028002142906189
    },
    {
      "classification_loss": 0.6868891716003418,
      "epoch": 7.5704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2309,
      "total_loss": 0.6868891716003418
    },
    {
      "classification_loss": 0.7001339197158813,
      "epoch": 7.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2310,
      "total_loss": 0.7001339197158813
    },
    {
      "classification_loss": 0.6240736842155457,
      "epoch": 7.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2311,
      "total_loss": 0.6240736842155457
    },
    {
      "classification_loss": 0.598909854888916,
      "epoch": 7.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2312,
      "total_loss": 0.598909854888916
    },
    {
      "classification_loss": 0.5275033712387085,
      "epoch": 7.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2313,
      "total_loss": 0.5275033712387085
    },
    {
      "classification_loss": 0.5113428831100464,
      "epoch": 7.586885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2314,
      "total_loss": 0.5113428831100464
    },
    {
      "classification_loss": 0.5316034555435181,
      "epoch": 7.590163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2315,
      "total_loss": 0.5316034555435181
    },
    {
      "classification_loss": 0.5069210529327393,
      "epoch": 7.593442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2316,
      "total_loss": 0.5069210529327393
    },
    {
      "classification_loss": 0.5570452809333801,
      "epoch": 7.5967213114754095,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2317,
      "total_loss": 0.5570452809333801
    },
    {
      "classification_loss": 0.6254701018333435,
      "epoch": 7.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2318,
      "total_loss": 0.6254701018333435
    },
    {
      "classification_loss": 0.5270934104919434,
      "epoch": 7.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2319,
      "total_loss": 0.5270934104919434
    },
    {
      "classification_loss": 0.4844239354133606,
      "epoch": 7.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2320,
      "total_loss": 0.4844239354133606
    },
    {
      "classification_loss": 0.6216107606887817,
      "epoch": 7.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2321,
      "total_loss": 0.6216107606887817
    },
    {
      "classification_loss": 0.5160002708435059,
      "epoch": 7.613114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2322,
      "total_loss": 0.5160002708435059
    },
    {
      "classification_loss": 0.584312379360199,
      "epoch": 7.616393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2323,
      "total_loss": 0.584312379360199
    },
    {
      "classification_loss": 0.5811940431594849,
      "epoch": 7.619672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2324,
      "total_loss": 0.5811940431594849
    },
    {
      "classification_loss": 0.6101306676864624,
      "epoch": 7.622950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2325,
      "total_loss": 0.6101306676864624
    },
    {
      "classification_loss": 0.5355810523033142,
      "epoch": 7.6262295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2326,
      "total_loss": 0.5355810523033142
    },
    {
      "classification_loss": 0.6276939511299133,
      "epoch": 7.629508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2327,
      "total_loss": 0.6276939511299133
    },
    {
      "classification_loss": 0.5846216678619385,
      "epoch": 7.632786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2328,
      "total_loss": 0.5846216678619385
    },
    {
      "classification_loss": 0.4954984188079834,
      "epoch": 7.636065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2329,
      "total_loss": 0.4954984188079834
    },
    {
      "classification_loss": 0.5104235410690308,
      "epoch": 7.639344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2330,
      "total_loss": 0.5104235410690308
    },
    {
      "classification_loss": 0.5491158962249756,
      "epoch": 7.642622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2331,
      "total_loss": 0.5491158962249756
    },
    {
      "classification_loss": 0.4625127911567688,
      "epoch": 7.645901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2332,
      "total_loss": 0.4625127911567688
    },
    {
      "classification_loss": 0.5557581782341003,
      "epoch": 7.649180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2333,
      "total_loss": 0.5557581782341003
    },
    {
      "classification_loss": 0.5384508371353149,
      "epoch": 7.6524590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2334,
      "total_loss": 0.5384508371353149
    },
    {
      "classification_loss": 0.4919852614402771,
      "epoch": 7.655737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2335,
      "total_loss": 0.4919852614402771
    },
    {
      "classification_loss": 0.6782453060150146,
      "epoch": 7.659016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2336,
      "total_loss": 0.6782453060150146
    },
    {
      "classification_loss": 0.5256725549697876,
      "epoch": 7.662295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2337,
      "total_loss": 0.5256725549697876
    },
    {
      "classification_loss": 0.6136186718940735,
      "epoch": 7.665573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2338,
      "total_loss": 0.6136186718940735
    },
    {
      "classification_loss": 0.521780252456665,
      "epoch": 7.668852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2339,
      "total_loss": 0.521780252456665
    },
    {
      "classification_loss": 0.46130579710006714,
      "epoch": 7.672131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2340,
      "total_loss": 0.46130579710006714
    },
    {
      "classification_loss": 0.6295310854911804,
      "epoch": 7.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2341,
      "total_loss": 0.6295310854911804
    },
    {
      "classification_loss": 0.5995913743972778,
      "epoch": 7.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2342,
      "total_loss": 0.5995913743972778
    },
    {
      "classification_loss": 0.5408451557159424,
      "epoch": 7.6819672131147545,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2343,
      "total_loss": 0.5408451557159424
    },
    {
      "classification_loss": 0.7051999568939209,
      "epoch": 7.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2344,
      "total_loss": 0.7051999568939209
    },
    {
      "classification_loss": 0.5327130556106567,
      "epoch": 7.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2345,
      "total_loss": 0.5327130556106567
    },
    {
      "classification_loss": 0.5327492356300354,
      "epoch": 7.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2346,
      "total_loss": 0.5327492356300354
    },
    {
      "classification_loss": 0.5523941516876221,
      "epoch": 7.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2347,
      "total_loss": 0.5523941516876221
    },
    {
      "classification_loss": 0.560577392578125,
      "epoch": 7.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2348,
      "total_loss": 0.560577392578125
    },
    {
      "classification_loss": 0.6008943319320679,
      "epoch": 7.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2349,
      "total_loss": 0.6008943319320679
    },
    {
      "classification_loss": 0.5893581509590149,
      "epoch": 7.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2350,
      "total_loss": 0.5893581509590149
    },
    {
      "classification_loss": 0.5166263580322266,
      "epoch": 7.7081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2351,
      "total_loss": 0.5166263580322266
    },
    {
      "classification_loss": 0.6325685381889343,
      "epoch": 7.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2352,
      "total_loss": 0.6325685381889343
    },
    {
      "classification_loss": 0.6248944997787476,
      "epoch": 7.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2353,
      "total_loss": 0.6248944997787476
    },
    {
      "classification_loss": 0.6213352680206299,
      "epoch": 7.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2354,
      "total_loss": 0.6213352680206299
    },
    {
      "classification_loss": 0.6722404360771179,
      "epoch": 7.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2355,
      "total_loss": 0.6722404360771179
    },
    {
      "classification_loss": 0.45331719517707825,
      "epoch": 7.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2356,
      "total_loss": 0.45331719517707825
    },
    {
      "classification_loss": 0.6431810855865479,
      "epoch": 7.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2357,
      "total_loss": 0.6431810855865479
    },
    {
      "classification_loss": 0.5451889634132385,
      "epoch": 7.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2358,
      "total_loss": 0.5451889634132385
    },
    {
      "classification_loss": 0.5269446969032288,
      "epoch": 7.7344262295081965,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2359,
      "total_loss": 0.5269446969032288
    },
    {
      "classification_loss": 0.5178192853927612,
      "epoch": 7.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2360,
      "total_loss": 0.5178192853927612
    },
    {
      "classification_loss": 0.6579251289367676,
      "epoch": 7.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2361,
      "total_loss": 0.6579251289367676
    },
    {
      "classification_loss": 0.5794812440872192,
      "epoch": 7.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2362,
      "total_loss": 0.5794812440872192
    },
    {
      "classification_loss": 0.6233168840408325,
      "epoch": 7.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2363,
      "total_loss": 0.6233168840408325
    },
    {
      "classification_loss": 0.6624091267585754,
      "epoch": 7.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2364,
      "total_loss": 0.6624091267585754
    },
    {
      "classification_loss": 0.5549938678741455,
      "epoch": 7.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2365,
      "total_loss": 0.5549938678741455
    },
    {
      "classification_loss": 0.5458521842956543,
      "epoch": 7.757377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2366,
      "total_loss": 0.5458521842956543
    },
    {
      "classification_loss": 0.6124333143234253,
      "epoch": 7.760655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2367,
      "total_loss": 0.6124333143234253
    },
    {
      "classification_loss": 0.5890825986862183,
      "epoch": 7.7639344262295085,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2368,
      "total_loss": 0.5890825986862183
    },
    {
      "classification_loss": 0.49716317653656006,
      "epoch": 7.767213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2369,
      "total_loss": 0.49716317653656006
    },
    {
      "classification_loss": 0.5425688624382019,
      "epoch": 7.770491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2370,
      "total_loss": 0.5425688624382019
    },
    {
      "classification_loss": 0.5102477073669434,
      "epoch": 7.773770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2371,
      "total_loss": 0.5102477073669434
    },
    {
      "classification_loss": 0.5512252449989319,
      "epoch": 7.777049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2372,
      "total_loss": 0.5512252449989319
    },
    {
      "classification_loss": 0.6157832741737366,
      "epoch": 7.780327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2373,
      "total_loss": 0.6157832741737366
    },
    {
      "classification_loss": 0.5494519472122192,
      "epoch": 7.783606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2374,
      "total_loss": 0.5494519472122192
    },
    {
      "classification_loss": 0.47852298617362976,
      "epoch": 7.786885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2375,
      "total_loss": 0.47852298617362976
    },
    {
      "classification_loss": 0.6101050972938538,
      "epoch": 7.7901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2376,
      "total_loss": 0.6101050972938538
    },
    {
      "classification_loss": 0.515971839427948,
      "epoch": 7.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2377,
      "total_loss": 0.515971839427948
    },
    {
      "classification_loss": 0.5914016962051392,
      "epoch": 7.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2378,
      "total_loss": 0.5914016962051392
    },
    {
      "classification_loss": 0.620405912399292,
      "epoch": 7.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2379,
      "total_loss": 0.620405912399292
    },
    {
      "classification_loss": 0.6113471388816833,
      "epoch": 7.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2380,
      "total_loss": 0.6113471388816833
    },
    {
      "classification_loss": 0.6214811205863953,
      "epoch": 7.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2381,
      "total_loss": 0.6214811205863953
    },
    {
      "classification_loss": 0.5689966678619385,
      "epoch": 7.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2382,
      "total_loss": 0.5689966678619385
    },
    {
      "classification_loss": 0.6812896728515625,
      "epoch": 7.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2383,
      "total_loss": 0.6812896728515625
    },
    {
      "classification_loss": 0.501908540725708,
      "epoch": 7.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2384,
      "total_loss": 0.501908540725708
    },
    {
      "classification_loss": 0.6184002757072449,
      "epoch": 7.8196721311475414,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2385,
      "total_loss": 0.6184002757072449
    },
    {
      "classification_loss": 0.544994056224823,
      "epoch": 7.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2386,
      "total_loss": 0.544994056224823
    },
    {
      "classification_loss": 0.5120457410812378,
      "epoch": 7.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2387,
      "total_loss": 0.5120457410812378
    },
    {
      "classification_loss": 0.5580939054489136,
      "epoch": 7.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2388,
      "total_loss": 0.5580939054489136
    },
    {
      "classification_loss": 0.5847702622413635,
      "epoch": 7.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2389,
      "total_loss": 0.5847702622413635
    },
    {
      "classification_loss": 0.5289652347564697,
      "epoch": 7.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2390,
      "total_loss": 0.5289652347564697
    },
    {
      "classification_loss": 0.5734578967094421,
      "epoch": 7.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2391,
      "total_loss": 0.5734578967094421
    },
    {
      "classification_loss": 0.5484541058540344,
      "epoch": 7.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2392,
      "total_loss": 0.5484541058540344
    },
    {
      "classification_loss": 0.6352186799049377,
      "epoch": 7.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2393,
      "total_loss": 0.6352186799049377
    },
    {
      "classification_loss": 0.6385919451713562,
      "epoch": 7.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2394,
      "total_loss": 0.6385919451713562
    },
    {
      "classification_loss": 0.5308370590209961,
      "epoch": 7.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2395,
      "total_loss": 0.5308370590209961
    },
    {
      "classification_loss": 0.5314186215400696,
      "epoch": 7.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2396,
      "total_loss": 0.5314186215400696
    },
    {
      "classification_loss": 0.5933178067207336,
      "epoch": 7.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2397,
      "total_loss": 0.5933178067207336
    },
    {
      "classification_loss": 0.5505536198616028,
      "epoch": 7.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2398,
      "total_loss": 0.5505536198616028
    },
    {
      "classification_loss": 0.5348497629165649,
      "epoch": 7.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2399,
      "total_loss": 0.5348497629165649
    },
    {
      "epoch": 7.868852459016393,
      "grad_norm": 8.305474281311035,
      "learning_rate": 0.00012336666666666667,
      "loss": 0.5726,
      "step": 2400
    },
    {
      "classification_loss": 0.5232796669006348,
      "epoch": 7.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2400,
      "total_loss": 0.5232796669006348
    },
    {
      "classification_loss": 0.546960711479187,
      "epoch": 7.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2401,
      "total_loss": 0.546960711479187
    },
    {
      "classification_loss": 0.6505337953567505,
      "epoch": 7.8754098360655735,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2402,
      "total_loss": 0.6505337953567505
    },
    {
      "classification_loss": 0.5075053572654724,
      "epoch": 7.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2403,
      "total_loss": 0.5075053572654724
    },
    {
      "classification_loss": 0.572057843208313,
      "epoch": 7.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2404,
      "total_loss": 0.572057843208313
    },
    {
      "classification_loss": 0.6156010031700134,
      "epoch": 7.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2405,
      "total_loss": 0.6156010031700134
    },
    {
      "classification_loss": 0.6448472738265991,
      "epoch": 7.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2406,
      "total_loss": 0.6448472738265991
    },
    {
      "classification_loss": 0.5809255838394165,
      "epoch": 7.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2407,
      "total_loss": 0.5809255838394165
    },
    {
      "classification_loss": 0.6329923868179321,
      "epoch": 7.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2408,
      "total_loss": 0.6329923868179321
    },
    {
      "classification_loss": 0.5024585723876953,
      "epoch": 7.898360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2409,
      "total_loss": 0.5024585723876953
    },
    {
      "classification_loss": 0.5823358297348022,
      "epoch": 7.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2410,
      "total_loss": 0.5823358297348022
    },
    {
      "classification_loss": 0.5991610288619995,
      "epoch": 7.9049180327868855,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2411,
      "total_loss": 0.5991610288619995
    },
    {
      "classification_loss": 0.6443155407905579,
      "epoch": 7.908196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2412,
      "total_loss": 0.6443155407905579
    },
    {
      "classification_loss": 0.5438965559005737,
      "epoch": 7.911475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2413,
      "total_loss": 0.5438965559005737
    },
    {
      "classification_loss": 0.4911649227142334,
      "epoch": 7.914754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2414,
      "total_loss": 0.4911649227142334
    },
    {
      "classification_loss": 0.4709755480289459,
      "epoch": 7.918032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2415,
      "total_loss": 0.4709755480289459
    },
    {
      "classification_loss": 0.6250196099281311,
      "epoch": 7.921311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2416,
      "total_loss": 0.6250196099281311
    },
    {
      "classification_loss": 0.5630298852920532,
      "epoch": 7.924590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2417,
      "total_loss": 0.5630298852920532
    },
    {
      "classification_loss": 0.6950063109397888,
      "epoch": 7.927868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2418,
      "total_loss": 0.6950063109397888
    },
    {
      "classification_loss": 0.5232666730880737,
      "epoch": 7.9311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2419,
      "total_loss": 0.5232666730880737
    },
    {
      "classification_loss": 0.5885245203971863,
      "epoch": 7.934426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2420,
      "total_loss": 0.5885245203971863
    },
    {
      "classification_loss": 0.5985798835754395,
      "epoch": 7.937704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2421,
      "total_loss": 0.5985798835754395
    },
    {
      "classification_loss": 0.5374253392219543,
      "epoch": 7.940983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2422,
      "total_loss": 0.5374253392219543
    },
    {
      "classification_loss": 0.4955742657184601,
      "epoch": 7.944262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2423,
      "total_loss": 0.4955742657184601
    },
    {
      "classification_loss": 0.5285370349884033,
      "epoch": 7.947540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2424,
      "total_loss": 0.5285370349884033
    },
    {
      "classification_loss": 0.5201652646064758,
      "epoch": 7.950819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2425,
      "total_loss": 0.5201652646064758
    },
    {
      "classification_loss": 0.5915061235427856,
      "epoch": 7.954098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2426,
      "total_loss": 0.5915061235427856
    },
    {
      "classification_loss": 0.5560798048973083,
      "epoch": 7.9573770491803275,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2427,
      "total_loss": 0.5560798048973083
    },
    {
      "classification_loss": 0.6253147125244141,
      "epoch": 7.9606557377049185,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2428,
      "total_loss": 0.6253147125244141
    },
    {
      "classification_loss": 0.5793600082397461,
      "epoch": 7.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2429,
      "total_loss": 0.5793600082397461
    },
    {
      "classification_loss": 0.5487241744995117,
      "epoch": 7.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2430,
      "total_loss": 0.5487241744995117
    },
    {
      "classification_loss": 0.5573931932449341,
      "epoch": 7.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2431,
      "total_loss": 0.5573931932449341
    },
    {
      "classification_loss": 0.5380932688713074,
      "epoch": 7.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2432,
      "total_loss": 0.5380932688713074
    },
    {
      "classification_loss": 0.5733785629272461,
      "epoch": 7.977049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2433,
      "total_loss": 0.5733785629272461
    },
    {
      "classification_loss": 0.6513859629631042,
      "epoch": 7.980327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2434,
      "total_loss": 0.6513859629631042
    },
    {
      "classification_loss": 0.5484557747840881,
      "epoch": 7.983606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2435,
      "total_loss": 0.5484557747840881
    },
    {
      "classification_loss": 0.6530421376228333,
      "epoch": 7.9868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2436,
      "total_loss": 0.6530421376228333
    },
    {
      "classification_loss": 0.5303828120231628,
      "epoch": 7.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2437,
      "total_loss": 0.5303828120231628
    },
    {
      "classification_loss": 0.5408068299293518,
      "epoch": 7.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2438,
      "total_loss": 0.5408068299293518
    },
    {
      "classification_loss": 0.6691458225250244,
      "epoch": 7.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2439,
      "total_loss": 0.6691458225250244
    },
    {
      "classification_loss": 1.0691382884979248,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 1.0691382884979248
    },
    {
      "classification_loss": 1.0142409801483154,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 1.0142409801483154
    },
    {
      "classification_loss": 0.9931458234786987,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 0.9931458234786987
    },
    {
      "classification_loss": 1.1447004079818726,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 1.1447004079818726
    },
    {
      "classification_loss": 0.9821296334266663,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 0.9821296334266663
    },
    {
      "classification_loss": 0.9668598175048828,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 0.9668598175048828
    },
    {
      "classification_loss": 1.0090714693069458,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 1.0090714693069458
    },
    {
      "classification_loss": 0.8966590166091919,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 0.8966590166091919
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.369,
      "eval_f1": 0.015600624024960999,
      "eval_loss": 1.012201189994812,
      "eval_precision": 0.45454545454545453,
      "eval_recall": 0.007936507936507936,
      "eval_runtime": 6.0565,
      "eval_samples_per_second": 165.111,
      "eval_steps_per_second": 1.321,
      "step": 2440
    },
    {
      "classification_loss": 0.5335308313369751,
      "epoch": 8.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2440,
      "total_loss": 0.5335308313369751
    },
    {
      "classification_loss": 0.5762004256248474,
      "epoch": 8.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2441,
      "total_loss": 0.5762004256248474
    },
    {
      "classification_loss": 0.49685782194137573,
      "epoch": 8.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2442,
      "total_loss": 0.49685782194137573
    },
    {
      "classification_loss": 0.6658268570899963,
      "epoch": 8.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2443,
      "total_loss": 0.6658268570899963
    },
    {
      "classification_loss": 0.5262457728385925,
      "epoch": 8.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2444,
      "total_loss": 0.5262457728385925
    },
    {
      "classification_loss": 0.6063991189002991,
      "epoch": 8.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2445,
      "total_loss": 0.6063991189002991
    },
    {
      "classification_loss": 0.49910053610801697,
      "epoch": 8.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2446,
      "total_loss": 0.49910053610801697
    },
    {
      "classification_loss": 0.5511797666549683,
      "epoch": 8.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2447,
      "total_loss": 0.5511797666549683
    },
    {
      "classification_loss": 0.6194086670875549,
      "epoch": 8.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2448,
      "total_loss": 0.6194086670875549
    },
    {
      "classification_loss": 0.5610674619674683,
      "epoch": 8.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2449,
      "total_loss": 0.5610674619674683
    },
    {
      "classification_loss": 0.5454822182655334,
      "epoch": 8.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2450,
      "total_loss": 0.5454822182655334
    },
    {
      "classification_loss": 0.5441275835037231,
      "epoch": 8.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2451,
      "total_loss": 0.5441275835037231
    },
    {
      "classification_loss": 0.4660572409629822,
      "epoch": 8.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2452,
      "total_loss": 0.4660572409629822
    },
    {
      "classification_loss": 0.6007605791091919,
      "epoch": 8.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2453,
      "total_loss": 0.6007605791091919
    },
    {
      "classification_loss": 0.5549875497817993,
      "epoch": 8.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2454,
      "total_loss": 0.5549875497817993
    },
    {
      "classification_loss": 0.6643986701965332,
      "epoch": 8.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2455,
      "total_loss": 0.6643986701965332
    },
    {
      "classification_loss": 0.6296296119689941,
      "epoch": 8.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2456,
      "total_loss": 0.6296296119689941
    },
    {
      "classification_loss": 0.5407782793045044,
      "epoch": 8.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2457,
      "total_loss": 0.5407782793045044
    },
    {
      "classification_loss": 0.5486066341400146,
      "epoch": 8.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2458,
      "total_loss": 0.5486066341400146
    },
    {
      "classification_loss": 0.5477995872497559,
      "epoch": 8.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2459,
      "total_loss": 0.5477995872497559
    },
    {
      "classification_loss": 0.5712262988090515,
      "epoch": 8.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2460,
      "total_loss": 0.5712262988090515
    },
    {
      "classification_loss": 0.5865802764892578,
      "epoch": 8.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2461,
      "total_loss": 0.5865802764892578
    },
    {
      "classification_loss": 0.5369113087654114,
      "epoch": 8.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2462,
      "total_loss": 0.5369113087654114
    },
    {
      "classification_loss": 0.5798335671424866,
      "epoch": 8.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2463,
      "total_loss": 0.5798335671424866
    },
    {
      "classification_loss": 0.5513685941696167,
      "epoch": 8.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2464,
      "total_loss": 0.5513685941696167
    },
    {
      "classification_loss": 0.6601158976554871,
      "epoch": 8.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2465,
      "total_loss": 0.6601158976554871
    },
    {
      "classification_loss": 0.5407547950744629,
      "epoch": 8.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2466,
      "total_loss": 0.5407547950744629
    },
    {
      "classification_loss": 0.5706619024276733,
      "epoch": 8.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2467,
      "total_loss": 0.5706619024276733
    },
    {
      "classification_loss": 0.6066640019416809,
      "epoch": 8.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2468,
      "total_loss": 0.6066640019416809
    },
    {
      "classification_loss": 0.578977644443512,
      "epoch": 8.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2469,
      "total_loss": 0.578977644443512
    },
    {
      "classification_loss": 0.5104995965957642,
      "epoch": 8.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2470,
      "total_loss": 0.5104995965957642
    },
    {
      "classification_loss": 0.6109991073608398,
      "epoch": 8.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2471,
      "total_loss": 0.6109991073608398
    },
    {
      "classification_loss": 0.5259830951690674,
      "epoch": 8.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2472,
      "total_loss": 0.5259830951690674
    },
    {
      "classification_loss": 0.5526278018951416,
      "epoch": 8.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2473,
      "total_loss": 0.5526278018951416
    },
    {
      "classification_loss": 0.4994576871395111,
      "epoch": 8.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2474,
      "total_loss": 0.4994576871395111
    },
    {
      "classification_loss": 0.5071125030517578,
      "epoch": 8.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2475,
      "total_loss": 0.5071125030517578
    },
    {
      "classification_loss": 0.5700750350952148,
      "epoch": 8.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2476,
      "total_loss": 0.5700750350952148
    },
    {
      "classification_loss": 0.5082499980926514,
      "epoch": 8.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2477,
      "total_loss": 0.5082499980926514
    },
    {
      "classification_loss": 0.5971486568450928,
      "epoch": 8.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2478,
      "total_loss": 0.5971486568450928
    },
    {
      "classification_loss": 0.5747028589248657,
      "epoch": 8.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2479,
      "total_loss": 0.5747028589248657
    },
    {
      "classification_loss": 0.5017568469047546,
      "epoch": 8.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2480,
      "total_loss": 0.5017568469047546
    },
    {
      "classification_loss": 0.5920302271842957,
      "epoch": 8.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2481,
      "total_loss": 0.5920302271842957
    },
    {
      "classification_loss": 0.5807187557220459,
      "epoch": 8.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2482,
      "total_loss": 0.5807187557220459
    },
    {
      "classification_loss": 0.5754826664924622,
      "epoch": 8.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2483,
      "total_loss": 0.5754826664924622
    },
    {
      "classification_loss": 0.4784248173236847,
      "epoch": 8.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2484,
      "total_loss": 0.4784248173236847
    },
    {
      "classification_loss": 0.5454680323600769,
      "epoch": 8.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2485,
      "total_loss": 0.5454680323600769
    },
    {
      "classification_loss": 0.5445441603660583,
      "epoch": 8.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2486,
      "total_loss": 0.5445441603660583
    },
    {
      "classification_loss": 0.5540918111801147,
      "epoch": 8.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2487,
      "total_loss": 0.5540918111801147
    },
    {
      "classification_loss": 0.642774224281311,
      "epoch": 8.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2488,
      "total_loss": 0.642774224281311
    },
    {
      "classification_loss": 0.6372629404067993,
      "epoch": 8.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2489,
      "total_loss": 0.6372629404067993
    },
    {
      "classification_loss": 0.5395329594612122,
      "epoch": 8.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2490,
      "total_loss": 0.5395329594612122
    },
    {
      "classification_loss": 0.5519292950630188,
      "epoch": 8.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2491,
      "total_loss": 0.5519292950630188
    },
    {
      "classification_loss": 0.565375030040741,
      "epoch": 8.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2492,
      "total_loss": 0.565375030040741
    },
    {
      "classification_loss": 0.596045970916748,
      "epoch": 8.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2493,
      "total_loss": 0.596045970916748
    },
    {
      "classification_loss": 0.6034154891967773,
      "epoch": 8.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2494,
      "total_loss": 0.6034154891967773
    },
    {
      "classification_loss": 0.6066752076148987,
      "epoch": 8.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2495,
      "total_loss": 0.6066752076148987
    },
    {
      "classification_loss": 0.5329082608222961,
      "epoch": 8.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2496,
      "total_loss": 0.5329082608222961
    },
    {
      "classification_loss": 0.5365599393844604,
      "epoch": 8.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2497,
      "total_loss": 0.5365599393844604
    },
    {
      "classification_loss": 0.5943535566329956,
      "epoch": 8.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2498,
      "total_loss": 0.5943535566329956
    },
    {
      "classification_loss": 0.6042722463607788,
      "epoch": 8.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2499,
      "total_loss": 0.6042722463607788
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 4.517157077789307,
      "learning_rate": 0.00012003333333333333,
      "loss": 0.5685,
      "step": 2500
    },
    {
      "classification_loss": 0.5502733588218689,
      "epoch": 8.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2500,
      "total_loss": 0.5502733588218689
    },
    {
      "classification_loss": 0.5610815286636353,
      "epoch": 8.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2501,
      "total_loss": 0.5610815286636353
    },
    {
      "classification_loss": 0.5933879017829895,
      "epoch": 8.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2502,
      "total_loss": 0.5933879017829895
    },
    {
      "classification_loss": 0.5429368615150452,
      "epoch": 8.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2503,
      "total_loss": 0.5429368615150452
    },
    {
      "classification_loss": 0.557059109210968,
      "epoch": 8.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2504,
      "total_loss": 0.557059109210968
    },
    {
      "classification_loss": 0.5590247511863708,
      "epoch": 8.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2505,
      "total_loss": 0.5590247511863708
    },
    {
      "classification_loss": 0.5588234663009644,
      "epoch": 8.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2506,
      "total_loss": 0.5588234663009644
    },
    {
      "classification_loss": 0.5423924326896667,
      "epoch": 8.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2507,
      "total_loss": 0.5423924326896667
    },
    {
      "classification_loss": 0.4340052008628845,
      "epoch": 8.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2508,
      "total_loss": 0.4340052008628845
    },
    {
      "classification_loss": 0.6316401362419128,
      "epoch": 8.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2509,
      "total_loss": 0.6316401362419128
    },
    {
      "classification_loss": 0.5050626397132874,
      "epoch": 8.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2510,
      "total_loss": 0.5050626397132874
    },
    {
      "classification_loss": 0.5844964385032654,
      "epoch": 8.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2511,
      "total_loss": 0.5844964385032654
    },
    {
      "classification_loss": 0.5803350210189819,
      "epoch": 8.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2512,
      "total_loss": 0.5803350210189819
    },
    {
      "classification_loss": 0.4817778170108795,
      "epoch": 8.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2513,
      "total_loss": 0.4817778170108795
    },
    {
      "classification_loss": 0.5166798233985901,
      "epoch": 8.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2514,
      "total_loss": 0.5166798233985901
    },
    {
      "classification_loss": 0.5340793132781982,
      "epoch": 8.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2515,
      "total_loss": 0.5340793132781982
    },
    {
      "classification_loss": 0.5281272530555725,
      "epoch": 8.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2516,
      "total_loss": 0.5281272530555725
    },
    {
      "classification_loss": 0.5332891941070557,
      "epoch": 8.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2517,
      "total_loss": 0.5332891941070557
    },
    {
      "classification_loss": 0.5879948139190674,
      "epoch": 8.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2518,
      "total_loss": 0.5879948139190674
    },
    {
      "classification_loss": 0.5658348202705383,
      "epoch": 8.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2519,
      "total_loss": 0.5658348202705383
    },
    {
      "classification_loss": 0.7082619071006775,
      "epoch": 8.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2520,
      "total_loss": 0.7082619071006775
    },
    {
      "classification_loss": 0.5653806924819946,
      "epoch": 8.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2521,
      "total_loss": 0.5653806924819946
    },
    {
      "classification_loss": 0.5417163372039795,
      "epoch": 8.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2522,
      "total_loss": 0.5417163372039795
    },
    {
      "classification_loss": 0.5735213756561279,
      "epoch": 8.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2523,
      "total_loss": 0.5735213756561279
    },
    {
      "classification_loss": 0.6679170727729797,
      "epoch": 8.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2524,
      "total_loss": 0.6679170727729797
    },
    {
      "classification_loss": 0.5972663164138794,
      "epoch": 8.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2525,
      "total_loss": 0.5972663164138794
    },
    {
      "classification_loss": 0.5860581994056702,
      "epoch": 8.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2526,
      "total_loss": 0.5860581994056702
    },
    {
      "classification_loss": 0.6624018549919128,
      "epoch": 8.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2527,
      "total_loss": 0.6624018549919128
    },
    {
      "classification_loss": 0.5264933705329895,
      "epoch": 8.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2528,
      "total_loss": 0.5264933705329895
    },
    {
      "classification_loss": 0.579050600528717,
      "epoch": 8.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2529,
      "total_loss": 0.579050600528717
    },
    {
      "classification_loss": 0.5634455680847168,
      "epoch": 8.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2530,
      "total_loss": 0.5634455680847168
    },
    {
      "classification_loss": 0.43845033645629883,
      "epoch": 8.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2531,
      "total_loss": 0.43845033645629883
    },
    {
      "classification_loss": 0.5761643648147583,
      "epoch": 8.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2532,
      "total_loss": 0.5761643648147583
    },
    {
      "classification_loss": 0.5386481881141663,
      "epoch": 8.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2533,
      "total_loss": 0.5386481881141663
    },
    {
      "classification_loss": 0.5270894765853882,
      "epoch": 8.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2534,
      "total_loss": 0.5270894765853882
    },
    {
      "classification_loss": 0.5623530149459839,
      "epoch": 8.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2535,
      "total_loss": 0.5623530149459839
    },
    {
      "classification_loss": 0.5676231384277344,
      "epoch": 8.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2536,
      "total_loss": 0.5676231384277344
    },
    {
      "classification_loss": 0.5054765939712524,
      "epoch": 8.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2537,
      "total_loss": 0.5054765939712524
    },
    {
      "classification_loss": 0.572622537612915,
      "epoch": 8.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2538,
      "total_loss": 0.572622537612915
    },
    {
      "classification_loss": 0.60471111536026,
      "epoch": 8.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2539,
      "total_loss": 0.60471111536026
    },
    {
      "classification_loss": 0.4884118139743805,
      "epoch": 8.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2540,
      "total_loss": 0.4884118139743805
    },
    {
      "classification_loss": 0.5218202471733093,
      "epoch": 8.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2541,
      "total_loss": 0.5218202471733093
    },
    {
      "classification_loss": 0.6099585294723511,
      "epoch": 8.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2542,
      "total_loss": 0.6099585294723511
    },
    {
      "classification_loss": 0.6475998759269714,
      "epoch": 8.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2543,
      "total_loss": 0.6475998759269714
    },
    {
      "classification_loss": 0.5722740292549133,
      "epoch": 8.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2544,
      "total_loss": 0.5722740292549133
    },
    {
      "classification_loss": 0.6032428741455078,
      "epoch": 8.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2545,
      "total_loss": 0.6032428741455078
    },
    {
      "classification_loss": 0.47435545921325684,
      "epoch": 8.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2546,
      "total_loss": 0.47435545921325684
    },
    {
      "classification_loss": 0.49068111181259155,
      "epoch": 8.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2547,
      "total_loss": 0.49068111181259155
    },
    {
      "classification_loss": 0.6166911721229553,
      "epoch": 8.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2548,
      "total_loss": 0.6166911721229553
    },
    {
      "classification_loss": 0.4779173731803894,
      "epoch": 8.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2549,
      "total_loss": 0.4779173731803894
    },
    {
      "classification_loss": 0.6493651866912842,
      "epoch": 8.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2550,
      "total_loss": 0.6493651866912842
    },
    {
      "classification_loss": 0.5025948882102966,
      "epoch": 8.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2551,
      "total_loss": 0.5025948882102966
    },
    {
      "classification_loss": 0.6004607081413269,
      "epoch": 8.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2552,
      "total_loss": 0.6004607081413269
    },
    {
      "classification_loss": 0.5092342495918274,
      "epoch": 8.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2553,
      "total_loss": 0.5092342495918274
    },
    {
      "classification_loss": 0.5332644581794739,
      "epoch": 8.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2554,
      "total_loss": 0.5332644581794739
    },
    {
      "classification_loss": 0.43595558404922485,
      "epoch": 8.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2555,
      "total_loss": 0.43595558404922485
    },
    {
      "classification_loss": 0.6175357103347778,
      "epoch": 8.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2556,
      "total_loss": 0.6175357103347778
    },
    {
      "classification_loss": 0.3998844623565674,
      "epoch": 8.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2557,
      "total_loss": 0.3998844623565674
    },
    {
      "classification_loss": 0.6134693026542664,
      "epoch": 8.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2558,
      "total_loss": 0.6134693026542664
    },
    {
      "classification_loss": 0.5929528474807739,
      "epoch": 8.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2559,
      "total_loss": 0.5929528474807739
    },
    {
      "classification_loss": 0.556860625743866,
      "epoch": 8.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2560,
      "total_loss": 0.556860625743866
    },
    {
      "classification_loss": 0.6090914011001587,
      "epoch": 8.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2561,
      "total_loss": 0.6090914011001587
    },
    {
      "classification_loss": 0.5528510808944702,
      "epoch": 8.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2562,
      "total_loss": 0.5528510808944702
    },
    {
      "classification_loss": 0.5801843404769897,
      "epoch": 8.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2563,
      "total_loss": 0.5801843404769897
    },
    {
      "classification_loss": 0.6372520327568054,
      "epoch": 8.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2564,
      "total_loss": 0.6372520327568054
    },
    {
      "classification_loss": 0.5807353258132935,
      "epoch": 8.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2565,
      "total_loss": 0.5807353258132935
    },
    {
      "classification_loss": 0.5693910121917725,
      "epoch": 8.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2566,
      "total_loss": 0.5693910121917725
    },
    {
      "classification_loss": 0.6001967191696167,
      "epoch": 8.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2567,
      "total_loss": 0.6001967191696167
    },
    {
      "classification_loss": 0.5451159477233887,
      "epoch": 8.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2568,
      "total_loss": 0.5451159477233887
    },
    {
      "classification_loss": 0.5412941575050354,
      "epoch": 8.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2569,
      "total_loss": 0.5412941575050354
    },
    {
      "classification_loss": 0.6805163025856018,
      "epoch": 8.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2570,
      "total_loss": 0.6805163025856018
    },
    {
      "classification_loss": 0.55403733253479,
      "epoch": 8.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2571,
      "total_loss": 0.55403733253479
    },
    {
      "classification_loss": 0.5472201108932495,
      "epoch": 8.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2572,
      "total_loss": 0.5472201108932495
    },
    {
      "classification_loss": 0.507259726524353,
      "epoch": 8.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2573,
      "total_loss": 0.507259726524353
    },
    {
      "classification_loss": 0.5646419525146484,
      "epoch": 8.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2574,
      "total_loss": 0.5646419525146484
    },
    {
      "classification_loss": 0.5617126226425171,
      "epoch": 8.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2575,
      "total_loss": 0.5617126226425171
    },
    {
      "classification_loss": 0.5133474469184875,
      "epoch": 8.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2576,
      "total_loss": 0.5133474469184875
    },
    {
      "classification_loss": 0.5027801990509033,
      "epoch": 8.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2577,
      "total_loss": 0.5027801990509033
    },
    {
      "classification_loss": 0.47762373089790344,
      "epoch": 8.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2578,
      "total_loss": 0.47762373089790344
    },
    {
      "classification_loss": 0.5268617272377014,
      "epoch": 8.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2579,
      "total_loss": 0.5268617272377014
    },
    {
      "classification_loss": 0.5834780931472778,
      "epoch": 8.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2580,
      "total_loss": 0.5834780931472778
    },
    {
      "classification_loss": 0.5978280305862427,
      "epoch": 8.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2581,
      "total_loss": 0.5978280305862427
    },
    {
      "classification_loss": 0.46464109420776367,
      "epoch": 8.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2582,
      "total_loss": 0.46464109420776367
    },
    {
      "classification_loss": 0.5153454542160034,
      "epoch": 8.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2583,
      "total_loss": 0.5153454542160034
    },
    {
      "classification_loss": 0.6021790504455566,
      "epoch": 8.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2584,
      "total_loss": 0.6021790504455566
    },
    {
      "classification_loss": 0.40891531109809875,
      "epoch": 8.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2585,
      "total_loss": 0.40891531109809875
    },
    {
      "classification_loss": 0.6536176204681396,
      "epoch": 8.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2586,
      "total_loss": 0.6536176204681396
    },
    {
      "classification_loss": 0.43089383840560913,
      "epoch": 8.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2587,
      "total_loss": 0.43089383840560913
    },
    {
      "classification_loss": 0.5743654370307922,
      "epoch": 8.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2588,
      "total_loss": 0.5743654370307922
    },
    {
      "classification_loss": 0.5913465619087219,
      "epoch": 8.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2589,
      "total_loss": 0.5913465619087219
    },
    {
      "classification_loss": 0.5595514178276062,
      "epoch": 8.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2590,
      "total_loss": 0.5595514178276062
    },
    {
      "classification_loss": 0.5900551676750183,
      "epoch": 8.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2591,
      "total_loss": 0.5900551676750183
    },
    {
      "classification_loss": 0.5685039758682251,
      "epoch": 8.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2592,
      "total_loss": 0.5685039758682251
    },
    {
      "classification_loss": 0.5732414722442627,
      "epoch": 8.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2593,
      "total_loss": 0.5732414722442627
    },
    {
      "classification_loss": 0.512809693813324,
      "epoch": 8.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2594,
      "total_loss": 0.512809693813324
    },
    {
      "classification_loss": 0.5555989742279053,
      "epoch": 8.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2595,
      "total_loss": 0.5555989742279053
    },
    {
      "classification_loss": 0.5261139273643494,
      "epoch": 8.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2596,
      "total_loss": 0.5261139273643494
    },
    {
      "classification_loss": 0.5491750836372375,
      "epoch": 8.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2597,
      "total_loss": 0.5491750836372375
    },
    {
      "classification_loss": 0.6279679536819458,
      "epoch": 8.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2598,
      "total_loss": 0.6279679536819458
    },
    {
      "classification_loss": 0.5480722784996033,
      "epoch": 8.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2599,
      "total_loss": 0.5480722784996033
    },
    {
      "epoch": 8.524590163934427,
      "grad_norm": 8.306851387023926,
      "learning_rate": 0.0001167,
      "loss": 0.5561,
      "step": 2600
    },
    {
      "classification_loss": 0.6435266733169556,
      "epoch": 8.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2600,
      "total_loss": 0.6435266733169556
    },
    {
      "classification_loss": 0.5735030770301819,
      "epoch": 8.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2601,
      "total_loss": 0.5735030770301819
    },
    {
      "classification_loss": 0.49433472752571106,
      "epoch": 8.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2602,
      "total_loss": 0.49433472752571106
    },
    {
      "classification_loss": 0.5324224233627319,
      "epoch": 8.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2603,
      "total_loss": 0.5324224233627319
    },
    {
      "classification_loss": 0.4265919029712677,
      "epoch": 8.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2604,
      "total_loss": 0.4265919029712677
    },
    {
      "classification_loss": 0.5799862742424011,
      "epoch": 8.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2605,
      "total_loss": 0.5799862742424011
    },
    {
      "classification_loss": 0.4503971040248871,
      "epoch": 8.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2606,
      "total_loss": 0.4503971040248871
    },
    {
      "classification_loss": 0.5003231763839722,
      "epoch": 8.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2607,
      "total_loss": 0.5003231763839722
    },
    {
      "classification_loss": 0.5632386207580566,
      "epoch": 8.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2608,
      "total_loss": 0.5632386207580566
    },
    {
      "classification_loss": 0.6303255558013916,
      "epoch": 8.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2609,
      "total_loss": 0.6303255558013916
    },
    {
      "classification_loss": 0.5431650876998901,
      "epoch": 8.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2610,
      "total_loss": 0.5431650876998901
    },
    {
      "classification_loss": 0.6658192873001099,
      "epoch": 8.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2611,
      "total_loss": 0.6658192873001099
    },
    {
      "classification_loss": 0.5939891934394836,
      "epoch": 8.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2612,
      "total_loss": 0.5939891934394836
    },
    {
      "classification_loss": 0.684768557548523,
      "epoch": 8.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2613,
      "total_loss": 0.684768557548523
    },
    {
      "classification_loss": 0.5176624059677124,
      "epoch": 8.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2614,
      "total_loss": 0.5176624059677124
    },
    {
      "classification_loss": 0.6068459153175354,
      "epoch": 8.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2615,
      "total_loss": 0.6068459153175354
    },
    {
      "classification_loss": 0.5721566081047058,
      "epoch": 8.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2616,
      "total_loss": 0.5721566081047058
    },
    {
      "classification_loss": 0.5489401817321777,
      "epoch": 8.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2617,
      "total_loss": 0.5489401817321777
    },
    {
      "classification_loss": 0.4933029115200043,
      "epoch": 8.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2618,
      "total_loss": 0.4933029115200043
    },
    {
      "classification_loss": 0.5152390599250793,
      "epoch": 8.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2619,
      "total_loss": 0.5152390599250793
    },
    {
      "classification_loss": 0.5758959054946899,
      "epoch": 8.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2620,
      "total_loss": 0.5758959054946899
    },
    {
      "classification_loss": 0.5442864298820496,
      "epoch": 8.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2621,
      "total_loss": 0.5442864298820496
    },
    {
      "classification_loss": 0.6730744242668152,
      "epoch": 8.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2622,
      "total_loss": 0.6730744242668152
    },
    {
      "classification_loss": 0.5642246007919312,
      "epoch": 8.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2623,
      "total_loss": 0.5642246007919312
    },
    {
      "classification_loss": 0.587101936340332,
      "epoch": 8.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2624,
      "total_loss": 0.587101936340332
    },
    {
      "classification_loss": 0.5355125069618225,
      "epoch": 8.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2625,
      "total_loss": 0.5355125069618225
    },
    {
      "classification_loss": 0.5278054475784302,
      "epoch": 8.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2626,
      "total_loss": 0.5278054475784302
    },
    {
      "classification_loss": 0.5546113848686218,
      "epoch": 8.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2627,
      "total_loss": 0.5546113848686218
    },
    {
      "classification_loss": 0.578937828540802,
      "epoch": 8.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2628,
      "total_loss": 0.578937828540802
    },
    {
      "classification_loss": 0.5251083970069885,
      "epoch": 8.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2629,
      "total_loss": 0.5251083970069885
    },
    {
      "classification_loss": 0.5620476007461548,
      "epoch": 8.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2630,
      "total_loss": 0.5620476007461548
    },
    {
      "classification_loss": 0.48914095759391785,
      "epoch": 8.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2631,
      "total_loss": 0.48914095759391785
    },
    {
      "classification_loss": 0.4990544319152832,
      "epoch": 8.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2632,
      "total_loss": 0.4990544319152832
    },
    {
      "classification_loss": 0.6676207780838013,
      "epoch": 8.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2633,
      "total_loss": 0.6676207780838013
    },
    {
      "classification_loss": 0.6194925904273987,
      "epoch": 8.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2634,
      "total_loss": 0.6194925904273987
    },
    {
      "classification_loss": 0.5608984231948853,
      "epoch": 8.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2635,
      "total_loss": 0.5608984231948853
    },
    {
      "classification_loss": 0.6320306658744812,
      "epoch": 8.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2636,
      "total_loss": 0.6320306658744812
    },
    {
      "classification_loss": 0.5602055788040161,
      "epoch": 8.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2637,
      "total_loss": 0.5602055788040161
    },
    {
      "classification_loss": 0.5465646982192993,
      "epoch": 8.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2638,
      "total_loss": 0.5465646982192993
    },
    {
      "classification_loss": 0.5172892808914185,
      "epoch": 8.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2639,
      "total_loss": 0.5172892808914185
    },
    {
      "classification_loss": 0.5097327828407288,
      "epoch": 8.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2640,
      "total_loss": 0.5097327828407288
    },
    {
      "classification_loss": 0.5293120741844177,
      "epoch": 8.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2641,
      "total_loss": 0.5293120741844177
    },
    {
      "classification_loss": 0.4883858263492584,
      "epoch": 8.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2642,
      "total_loss": 0.4883858263492584
    },
    {
      "classification_loss": 0.6097027063369751,
      "epoch": 8.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2643,
      "total_loss": 0.6097027063369751
    },
    {
      "classification_loss": 0.46107035875320435,
      "epoch": 8.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2644,
      "total_loss": 0.46107035875320435
    },
    {
      "classification_loss": 0.45522984862327576,
      "epoch": 8.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2645,
      "total_loss": 0.45522984862327576
    },
    {
      "classification_loss": 0.6146140694618225,
      "epoch": 8.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2646,
      "total_loss": 0.6146140694618225
    },
    {
      "classification_loss": 0.5223099589347839,
      "epoch": 8.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2647,
      "total_loss": 0.5223099589347839
    },
    {
      "classification_loss": 0.6119247674942017,
      "epoch": 8.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2648,
      "total_loss": 0.6119247674942017
    },
    {
      "classification_loss": 0.5527375340461731,
      "epoch": 8.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2649,
      "total_loss": 0.5527375340461731
    },
    {
      "classification_loss": 0.4529242515563965,
      "epoch": 8.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2650,
      "total_loss": 0.4529242515563965
    },
    {
      "classification_loss": 0.622572660446167,
      "epoch": 8.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2651,
      "total_loss": 0.622572660446167
    },
    {
      "classification_loss": 0.6053886413574219,
      "epoch": 8.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2652,
      "total_loss": 0.6053886413574219
    },
    {
      "classification_loss": 0.601036787033081,
      "epoch": 8.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2653,
      "total_loss": 0.601036787033081
    },
    {
      "classification_loss": 0.5945942997932434,
      "epoch": 8.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2654,
      "total_loss": 0.5945942997932434
    },
    {
      "classification_loss": 0.4935416579246521,
      "epoch": 8.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2655,
      "total_loss": 0.4935416579246521
    },
    {
      "classification_loss": 0.6694904565811157,
      "epoch": 8.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2656,
      "total_loss": 0.6694904565811157
    },
    {
      "classification_loss": 0.46701258420944214,
      "epoch": 8.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2657,
      "total_loss": 0.46701258420944214
    },
    {
      "classification_loss": 0.5326805710792542,
      "epoch": 8.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2658,
      "total_loss": 0.5326805710792542
    },
    {
      "classification_loss": 0.5344864726066589,
      "epoch": 8.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2659,
      "total_loss": 0.5344864726066589
    },
    {
      "classification_loss": 0.5610731244087219,
      "epoch": 8.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2660,
      "total_loss": 0.5610731244087219
    },
    {
      "classification_loss": 0.5851795077323914,
      "epoch": 8.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2661,
      "total_loss": 0.5851795077323914
    },
    {
      "classification_loss": 0.5563251376152039,
      "epoch": 8.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2662,
      "total_loss": 0.5563251376152039
    },
    {
      "classification_loss": 0.5556401610374451,
      "epoch": 8.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2663,
      "total_loss": 0.5556401610374451
    },
    {
      "classification_loss": 0.4966570734977722,
      "epoch": 8.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2664,
      "total_loss": 0.4966570734977722
    },
    {
      "classification_loss": 0.5691511034965515,
      "epoch": 8.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2665,
      "total_loss": 0.5691511034965515
    },
    {
      "classification_loss": 0.5389782786369324,
      "epoch": 8.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2666,
      "total_loss": 0.5389782786369324
    },
    {
      "classification_loss": 0.5024240016937256,
      "epoch": 8.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2667,
      "total_loss": 0.5024240016937256
    },
    {
      "classification_loss": 0.5598163604736328,
      "epoch": 8.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2668,
      "total_loss": 0.5598163604736328
    },
    {
      "classification_loss": 0.6565058827400208,
      "epoch": 8.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2669,
      "total_loss": 0.6565058827400208
    },
    {
      "classification_loss": 0.5815478563308716,
      "epoch": 8.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2670,
      "total_loss": 0.5815478563308716
    },
    {
      "classification_loss": 0.5158980488777161,
      "epoch": 8.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2671,
      "total_loss": 0.5158980488777161
    },
    {
      "classification_loss": 0.5441024303436279,
      "epoch": 8.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2672,
      "total_loss": 0.5441024303436279
    },
    {
      "classification_loss": 0.6689147353172302,
      "epoch": 8.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2673,
      "total_loss": 0.6689147353172302
    },
    {
      "classification_loss": 0.5881687998771667,
      "epoch": 8.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2674,
      "total_loss": 0.5881687998771667
    },
    {
      "classification_loss": 0.5989114046096802,
      "epoch": 8.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2675,
      "total_loss": 0.5989114046096802
    },
    {
      "classification_loss": 0.5349488258361816,
      "epoch": 8.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2676,
      "total_loss": 0.5349488258361816
    },
    {
      "classification_loss": 0.5758686065673828,
      "epoch": 8.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2677,
      "total_loss": 0.5758686065673828
    },
    {
      "classification_loss": 0.49933984875679016,
      "epoch": 8.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2678,
      "total_loss": 0.49933984875679016
    },
    {
      "classification_loss": 0.5254527926445007,
      "epoch": 8.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2679,
      "total_loss": 0.5254527926445007
    },
    {
      "classification_loss": 0.4857981503009796,
      "epoch": 8.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2680,
      "total_loss": 0.4857981503009796
    },
    {
      "classification_loss": 0.5421969890594482,
      "epoch": 8.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2681,
      "total_loss": 0.5421969890594482
    },
    {
      "classification_loss": 0.5368865132331848,
      "epoch": 8.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2682,
      "total_loss": 0.5368865132331848
    },
    {
      "classification_loss": 0.6164904832839966,
      "epoch": 8.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2683,
      "total_loss": 0.6164904832839966
    },
    {
      "classification_loss": 0.533890962600708,
      "epoch": 8.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2684,
      "total_loss": 0.533890962600708
    },
    {
      "classification_loss": 0.5073270797729492,
      "epoch": 8.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2685,
      "total_loss": 0.5073270797729492
    },
    {
      "classification_loss": 0.5071517825126648,
      "epoch": 8.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2686,
      "total_loss": 0.5071517825126648
    },
    {
      "classification_loss": 0.5268471837043762,
      "epoch": 8.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2687,
      "total_loss": 0.5268471837043762
    },
    {
      "classification_loss": 0.5430021286010742,
      "epoch": 8.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2688,
      "total_loss": 0.5430021286010742
    },
    {
      "classification_loss": 0.6113044619560242,
      "epoch": 8.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2689,
      "total_loss": 0.6113044619560242
    },
    {
      "classification_loss": 0.5992573499679565,
      "epoch": 8.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2690,
      "total_loss": 0.5992573499679565
    },
    {
      "classification_loss": 0.49422603845596313,
      "epoch": 8.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2691,
      "total_loss": 0.49422603845596313
    },
    {
      "classification_loss": 0.5490959286689758,
      "epoch": 8.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2692,
      "total_loss": 0.5490959286689758
    },
    {
      "classification_loss": 0.6214194297790527,
      "epoch": 8.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2693,
      "total_loss": 0.6214194297790527
    },
    {
      "classification_loss": 0.5899640321731567,
      "epoch": 8.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2694,
      "total_loss": 0.5899640321731567
    },
    {
      "classification_loss": 0.5887312293052673,
      "epoch": 8.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2695,
      "total_loss": 0.5887312293052673
    },
    {
      "classification_loss": 0.5560663938522339,
      "epoch": 8.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2696,
      "total_loss": 0.5560663938522339
    },
    {
      "classification_loss": 0.5493330359458923,
      "epoch": 8.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2697,
      "total_loss": 0.5493330359458923
    },
    {
      "classification_loss": 0.5381516218185425,
      "epoch": 8.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2698,
      "total_loss": 0.5381516218185425
    },
    {
      "classification_loss": 0.5354241728782654,
      "epoch": 8.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2699,
      "total_loss": 0.5354241728782654
    },
    {
      "epoch": 8.852459016393443,
      "grad_norm": 2.4590742588043213,
      "learning_rate": 0.00011336666666666667,
      "loss": 0.5563,
      "step": 2700
    },
    {
      "classification_loss": 0.5009130239486694,
      "epoch": 8.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2700,
      "total_loss": 0.5009130239486694
    },
    {
      "classification_loss": 0.5303728580474854,
      "epoch": 8.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2701,
      "total_loss": 0.5303728580474854
    },
    {
      "classification_loss": 0.4989229142665863,
      "epoch": 8.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2702,
      "total_loss": 0.4989229142665863
    },
    {
      "classification_loss": 0.5229856967926025,
      "epoch": 8.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2703,
      "total_loss": 0.5229856967926025
    },
    {
      "classification_loss": 0.6478533744812012,
      "epoch": 8.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2704,
      "total_loss": 0.6478533744812012
    },
    {
      "classification_loss": 0.5927898287773132,
      "epoch": 8.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2705,
      "total_loss": 0.5927898287773132
    },
    {
      "classification_loss": 0.5358039140701294,
      "epoch": 8.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2706,
      "total_loss": 0.5358039140701294
    },
    {
      "classification_loss": 0.5520663857460022,
      "epoch": 8.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2707,
      "total_loss": 0.5520663857460022
    },
    {
      "classification_loss": 0.5720054507255554,
      "epoch": 8.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2708,
      "total_loss": 0.5720054507255554
    },
    {
      "classification_loss": 0.4465739130973816,
      "epoch": 8.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2709,
      "total_loss": 0.4465739130973816
    },
    {
      "classification_loss": 0.6545365452766418,
      "epoch": 8.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2710,
      "total_loss": 0.6545365452766418
    },
    {
      "classification_loss": 0.6333674192428589,
      "epoch": 8.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2711,
      "total_loss": 0.6333674192428589
    },
    {
      "classification_loss": 0.7207651734352112,
      "epoch": 8.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2712,
      "total_loss": 0.7207651734352112
    },
    {
      "classification_loss": 0.6543338298797607,
      "epoch": 8.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2713,
      "total_loss": 0.6543338298797607
    },
    {
      "classification_loss": 0.5114970803260803,
      "epoch": 8.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2714,
      "total_loss": 0.5114970803260803
    },
    {
      "classification_loss": 0.5265055298805237,
      "epoch": 8.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2715,
      "total_loss": 0.5265055298805237
    },
    {
      "classification_loss": 0.520232617855072,
      "epoch": 8.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2716,
      "total_loss": 0.520232617855072
    },
    {
      "classification_loss": 0.5214136242866516,
      "epoch": 8.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2717,
      "total_loss": 0.5214136242866516
    },
    {
      "classification_loss": 0.5387507677078247,
      "epoch": 8.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2718,
      "total_loss": 0.5387507677078247
    },
    {
      "classification_loss": 0.6655678153038025,
      "epoch": 8.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2719,
      "total_loss": 0.6655678153038025
    },
    {
      "classification_loss": 0.5284861922264099,
      "epoch": 8.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2720,
      "total_loss": 0.5284861922264099
    },
    {
      "classification_loss": 0.5110558271408081,
      "epoch": 8.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2721,
      "total_loss": 0.5110558271408081
    },
    {
      "classification_loss": 0.5555310249328613,
      "epoch": 8.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2722,
      "total_loss": 0.5555310249328613
    },
    {
      "classification_loss": 0.6501743197441101,
      "epoch": 8.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2723,
      "total_loss": 0.6501743197441101
    },
    {
      "classification_loss": 0.5883737802505493,
      "epoch": 8.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2724,
      "total_loss": 0.5883737802505493
    },
    {
      "classification_loss": 0.5687418580055237,
      "epoch": 8.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2725,
      "total_loss": 0.5687418580055237
    },
    {
      "classification_loss": 0.636519730091095,
      "epoch": 8.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2726,
      "total_loss": 0.636519730091095
    },
    {
      "classification_loss": 0.5408340096473694,
      "epoch": 8.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2727,
      "total_loss": 0.5408340096473694
    },
    {
      "classification_loss": 0.5321012735366821,
      "epoch": 8.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2728,
      "total_loss": 0.5321012735366821
    },
    {
      "classification_loss": 0.6517240405082703,
      "epoch": 8.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2729,
      "total_loss": 0.6517240405082703
    },
    {
      "classification_loss": 0.8030033111572266,
      "epoch": 8.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2730,
      "total_loss": 0.8030033111572266
    },
    {
      "classification_loss": 0.4893200993537903,
      "epoch": 8.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2731,
      "total_loss": 0.4893200993537903
    },
    {
      "classification_loss": 0.5671110153198242,
      "epoch": 8.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2732,
      "total_loss": 0.5671110153198242
    },
    {
      "classification_loss": 0.5322285294532776,
      "epoch": 8.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2733,
      "total_loss": 0.5322285294532776
    },
    {
      "classification_loss": 0.5203766226768494,
      "epoch": 8.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2734,
      "total_loss": 0.5203766226768494
    },
    {
      "classification_loss": 0.6988220810890198,
      "epoch": 8.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2735,
      "total_loss": 0.6988220810890198
    },
    {
      "classification_loss": 0.511073112487793,
      "epoch": 8.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2736,
      "total_loss": 0.511073112487793
    },
    {
      "classification_loss": 0.5053878426551819,
      "epoch": 8.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2737,
      "total_loss": 0.5053878426551819
    },
    {
      "classification_loss": 0.5916095972061157,
      "epoch": 8.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2738,
      "total_loss": 0.5916095972061157
    },
    {
      "classification_loss": 0.5371720790863037,
      "epoch": 8.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2739,
      "total_loss": 0.5371720790863037
    },
    {
      "classification_loss": 0.48391151428222656,
      "epoch": 8.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2740,
      "total_loss": 0.48391151428222656
    },
    {
      "classification_loss": 0.5823243260383606,
      "epoch": 8.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2741,
      "total_loss": 0.5823243260383606
    },
    {
      "classification_loss": 0.5833265781402588,
      "epoch": 8.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2742,
      "total_loss": 0.5833265781402588
    },
    {
      "classification_loss": 0.526820719242096,
      "epoch": 8.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2743,
      "total_loss": 0.526820719242096
    },
    {
      "classification_loss": 0.4609139859676361,
      "epoch": 8.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2744,
      "total_loss": 0.4609139859676361
    },
    {
      "classification_loss": 1.2383499145507812,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.2383499145507812
    },
    {
      "classification_loss": 1.1803537607192993,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.1803537607192993
    },
    {
      "classification_loss": 1.118000864982605,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.118000864982605
    },
    {
      "classification_loss": 1.333445429801941,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.333445429801941
    },
    {
      "classification_loss": 1.1208500862121582,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.1208500862121582
    },
    {
      "classification_loss": 1.0928339958190918,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.0928339958190918
    },
    {
      "classification_loss": 1.1614996194839478,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.1614996194839478
    },
    {
      "classification_loss": 1.018301248550415,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 1.018301248550415
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.1613060235977173,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.027,
      "eval_samples_per_second": 165.92,
      "eval_steps_per_second": 1.327,
      "step": 2745
    },
    {
      "classification_loss": 0.5660812854766846,
      "epoch": 9.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2745,
      "total_loss": 0.5660812854766846
    },
    {
      "classification_loss": 0.5800219178199768,
      "epoch": 9.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2746,
      "total_loss": 0.5800219178199768
    },
    {
      "classification_loss": 0.4893024265766144,
      "epoch": 9.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2747,
      "total_loss": 0.4893024265766144
    },
    {
      "classification_loss": 0.4353390336036682,
      "epoch": 9.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2748,
      "total_loss": 0.4353390336036682
    },
    {
      "classification_loss": 0.5694252848625183,
      "epoch": 9.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2749,
      "total_loss": 0.5694252848625183
    },
    {
      "classification_loss": 0.5315185189247131,
      "epoch": 9.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2750,
      "total_loss": 0.5315185189247131
    },
    {
      "classification_loss": 0.563161313533783,
      "epoch": 9.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2751,
      "total_loss": 0.563161313533783
    },
    {
      "classification_loss": 0.5552076101303101,
      "epoch": 9.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2752,
      "total_loss": 0.5552076101303101
    },
    {
      "classification_loss": 0.4883742928504944,
      "epoch": 9.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2753,
      "total_loss": 0.4883742928504944
    },
    {
      "classification_loss": 0.5634414553642273,
      "epoch": 9.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2754,
      "total_loss": 0.5634414553642273
    },
    {
      "classification_loss": 0.5049605965614319,
      "epoch": 9.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2755,
      "total_loss": 0.5049605965614319
    },
    {
      "classification_loss": 0.45219886302948,
      "epoch": 9.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2756,
      "total_loss": 0.45219886302948
    },
    {
      "classification_loss": 0.5014464855194092,
      "epoch": 9.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2757,
      "total_loss": 0.5014464855194092
    },
    {
      "classification_loss": 0.6305350661277771,
      "epoch": 9.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2758,
      "total_loss": 0.6305350661277771
    },
    {
      "classification_loss": 0.5228270888328552,
      "epoch": 9.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2759,
      "total_loss": 0.5228270888328552
    },
    {
      "classification_loss": 0.4855872392654419,
      "epoch": 9.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2760,
      "total_loss": 0.4855872392654419
    },
    {
      "classification_loss": 0.5291854739189148,
      "epoch": 9.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2761,
      "total_loss": 0.5291854739189148
    },
    {
      "classification_loss": 0.5875654816627502,
      "epoch": 9.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2762,
      "total_loss": 0.5875654816627502
    },
    {
      "classification_loss": 0.5094217658042908,
      "epoch": 9.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2763,
      "total_loss": 0.5094217658042908
    },
    {
      "classification_loss": 0.5006648302078247,
      "epoch": 9.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2764,
      "total_loss": 0.5006648302078247
    },
    {
      "classification_loss": 0.6010997295379639,
      "epoch": 9.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2765,
      "total_loss": 0.6010997295379639
    },
    {
      "classification_loss": 0.5390805602073669,
      "epoch": 9.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2766,
      "total_loss": 0.5390805602073669
    },
    {
      "classification_loss": 0.4763098955154419,
      "epoch": 9.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2767,
      "total_loss": 0.4763098955154419
    },
    {
      "classification_loss": 0.5282713770866394,
      "epoch": 9.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2768,
      "total_loss": 0.5282713770866394
    },
    {
      "classification_loss": 0.5354728102684021,
      "epoch": 9.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2769,
      "total_loss": 0.5354728102684021
    },
    {
      "classification_loss": 0.5092763900756836,
      "epoch": 9.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2770,
      "total_loss": 0.5092763900756836
    },
    {
      "classification_loss": 0.4853096306324005,
      "epoch": 9.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2771,
      "total_loss": 0.4853096306324005
    },
    {
      "classification_loss": 0.5668113231658936,
      "epoch": 9.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2772,
      "total_loss": 0.5668113231658936
    },
    {
      "classification_loss": 0.5630008578300476,
      "epoch": 9.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2773,
      "total_loss": 0.5630008578300476
    },
    {
      "classification_loss": 0.6383935809135437,
      "epoch": 9.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2774,
      "total_loss": 0.6383935809135437
    },
    {
      "classification_loss": 0.695457935333252,
      "epoch": 9.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2775,
      "total_loss": 0.695457935333252
    },
    {
      "classification_loss": 0.4853021800518036,
      "epoch": 9.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2776,
      "total_loss": 0.4853021800518036
    },
    {
      "classification_loss": 0.600199818611145,
      "epoch": 9.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2777,
      "total_loss": 0.600199818611145
    },
    {
      "classification_loss": 0.5397692918777466,
      "epoch": 9.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2778,
      "total_loss": 0.5397692918777466
    },
    {
      "classification_loss": 0.5936592817306519,
      "epoch": 9.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2779,
      "total_loss": 0.5936592817306519
    },
    {
      "classification_loss": 0.5027781128883362,
      "epoch": 9.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2780,
      "total_loss": 0.5027781128883362
    },
    {
      "classification_loss": 0.49639594554901123,
      "epoch": 9.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2781,
      "total_loss": 0.49639594554901123
    },
    {
      "classification_loss": 0.5704616904258728,
      "epoch": 9.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2782,
      "total_loss": 0.5704616904258728
    },
    {
      "classification_loss": 0.4262610673904419,
      "epoch": 9.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2783,
      "total_loss": 0.4262610673904419
    },
    {
      "classification_loss": 0.5713049173355103,
      "epoch": 9.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2784,
      "total_loss": 0.5713049173355103
    },
    {
      "classification_loss": 0.5595952868461609,
      "epoch": 9.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2785,
      "total_loss": 0.5595952868461609
    },
    {
      "classification_loss": 0.4857293665409088,
      "epoch": 9.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2786,
      "total_loss": 0.4857293665409088
    },
    {
      "classification_loss": 0.6179490685462952,
      "epoch": 9.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2787,
      "total_loss": 0.6179490685462952
    },
    {
      "classification_loss": 0.5944830179214478,
      "epoch": 9.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2788,
      "total_loss": 0.5944830179214478
    },
    {
      "classification_loss": 0.5966960191726685,
      "epoch": 9.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2789,
      "total_loss": 0.5966960191726685
    },
    {
      "classification_loss": 0.6450739502906799,
      "epoch": 9.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2790,
      "total_loss": 0.6450739502906799
    },
    {
      "classification_loss": 0.465382844209671,
      "epoch": 9.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2791,
      "total_loss": 0.465382844209671
    },
    {
      "classification_loss": 0.5139840841293335,
      "epoch": 9.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2792,
      "total_loss": 0.5139840841293335
    },
    {
      "classification_loss": 0.529486894607544,
      "epoch": 9.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2793,
      "total_loss": 0.529486894607544
    },
    {
      "classification_loss": 0.544867217540741,
      "epoch": 9.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2794,
      "total_loss": 0.544867217540741
    },
    {
      "classification_loss": 0.5549365878105164,
      "epoch": 9.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2795,
      "total_loss": 0.5549365878105164
    },
    {
      "classification_loss": 0.4958975315093994,
      "epoch": 9.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2796,
      "total_loss": 0.4958975315093994
    },
    {
      "classification_loss": 0.5574198365211487,
      "epoch": 9.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2797,
      "total_loss": 0.5574198365211487
    },
    {
      "classification_loss": 0.563704788684845,
      "epoch": 9.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2798,
      "total_loss": 0.563704788684845
    },
    {
      "classification_loss": 0.5922948122024536,
      "epoch": 9.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2799,
      "total_loss": 0.5922948122024536
    },
    {
      "epoch": 9.180327868852459,
      "grad_norm": 3.936828851699829,
      "learning_rate": 0.00011003333333333334,
      "loss": 0.5531,
      "step": 2800
    },
    {
      "classification_loss": 0.5219700932502747,
      "epoch": 9.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2800,
      "total_loss": 0.5219700932502747
    },
    {
      "classification_loss": 0.45271483063697815,
      "epoch": 9.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2801,
      "total_loss": 0.45271483063697815
    },
    {
      "classification_loss": 0.5707777738571167,
      "epoch": 9.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2802,
      "total_loss": 0.5707777738571167
    },
    {
      "classification_loss": 0.6926514506340027,
      "epoch": 9.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2803,
      "total_loss": 0.6926514506340027
    },
    {
      "classification_loss": 0.5953269600868225,
      "epoch": 9.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2804,
      "total_loss": 0.5953269600868225
    },
    {
      "classification_loss": 0.4402094781398773,
      "epoch": 9.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2805,
      "total_loss": 0.4402094781398773
    },
    {
      "classification_loss": 0.518785834312439,
      "epoch": 9.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2806,
      "total_loss": 0.518785834312439
    },
    {
      "classification_loss": 0.4354954957962036,
      "epoch": 9.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2807,
      "total_loss": 0.4354954957962036
    },
    {
      "classification_loss": 0.599039614200592,
      "epoch": 9.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2808,
      "total_loss": 0.599039614200592
    },
    {
      "classification_loss": 0.5932432413101196,
      "epoch": 9.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2809,
      "total_loss": 0.5932432413101196
    },
    {
      "classification_loss": 0.5323976278305054,
      "epoch": 9.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2810,
      "total_loss": 0.5323976278305054
    },
    {
      "classification_loss": 0.5555816292762756,
      "epoch": 9.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2811,
      "total_loss": 0.5555816292762756
    },
    {
      "classification_loss": 0.5765585899353027,
      "epoch": 9.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2812,
      "total_loss": 0.5765585899353027
    },
    {
      "classification_loss": 0.5557593703269958,
      "epoch": 9.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2813,
      "total_loss": 0.5557593703269958
    },
    {
      "classification_loss": 0.5350565314292908,
      "epoch": 9.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2814,
      "total_loss": 0.5350565314292908
    },
    {
      "classification_loss": 0.5248481631278992,
      "epoch": 9.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2815,
      "total_loss": 0.5248481631278992
    },
    {
      "classification_loss": 0.5972167253494263,
      "epoch": 9.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2816,
      "total_loss": 0.5972167253494263
    },
    {
      "classification_loss": 0.6633172035217285,
      "epoch": 9.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2817,
      "total_loss": 0.6633172035217285
    },
    {
      "classification_loss": 0.6191170811653137,
      "epoch": 9.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2818,
      "total_loss": 0.6191170811653137
    },
    {
      "classification_loss": 0.5668046474456787,
      "epoch": 9.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2819,
      "total_loss": 0.5668046474456787
    },
    {
      "classification_loss": 0.5640729069709778,
      "epoch": 9.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2820,
      "total_loss": 0.5640729069709778
    },
    {
      "classification_loss": 0.5802074074745178,
      "epoch": 9.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2821,
      "total_loss": 0.5802074074745178
    },
    {
      "classification_loss": 0.5849432349205017,
      "epoch": 9.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2822,
      "total_loss": 0.5849432349205017
    },
    {
      "classification_loss": 0.5942031145095825,
      "epoch": 9.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2823,
      "total_loss": 0.5942031145095825
    },
    {
      "classification_loss": 0.5823737382888794,
      "epoch": 9.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2824,
      "total_loss": 0.5823737382888794
    },
    {
      "classification_loss": 0.6096738576889038,
      "epoch": 9.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2825,
      "total_loss": 0.6096738576889038
    },
    {
      "classification_loss": 0.5356236100196838,
      "epoch": 9.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2826,
      "total_loss": 0.5356236100196838
    },
    {
      "classification_loss": 0.486564964056015,
      "epoch": 9.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2827,
      "total_loss": 0.486564964056015
    },
    {
      "classification_loss": 0.5550647974014282,
      "epoch": 9.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2828,
      "total_loss": 0.5550647974014282
    },
    {
      "classification_loss": 0.5731899738311768,
      "epoch": 9.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2829,
      "total_loss": 0.5731899738311768
    },
    {
      "classification_loss": 0.5613238215446472,
      "epoch": 9.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2830,
      "total_loss": 0.5613238215446472
    },
    {
      "classification_loss": 0.5269684791564941,
      "epoch": 9.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2831,
      "total_loss": 0.5269684791564941
    },
    {
      "classification_loss": 0.56743985414505,
      "epoch": 9.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2832,
      "total_loss": 0.56743985414505
    },
    {
      "classification_loss": 0.43762341141700745,
      "epoch": 9.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2833,
      "total_loss": 0.43762341141700745
    },
    {
      "classification_loss": 0.5354925990104675,
      "epoch": 9.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2834,
      "total_loss": 0.5354925990104675
    },
    {
      "classification_loss": 0.5559893250465393,
      "epoch": 9.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2835,
      "total_loss": 0.5559893250465393
    },
    {
      "classification_loss": 0.513863742351532,
      "epoch": 9.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2836,
      "total_loss": 0.513863742351532
    },
    {
      "classification_loss": 0.686331033706665,
      "epoch": 9.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2837,
      "total_loss": 0.686331033706665
    },
    {
      "classification_loss": 0.49501824378967285,
      "epoch": 9.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2838,
      "total_loss": 0.49501824378967285
    },
    {
      "classification_loss": 0.5029228925704956,
      "epoch": 9.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2839,
      "total_loss": 0.5029228925704956
    },
    {
      "classification_loss": 0.5019320845603943,
      "epoch": 9.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2840,
      "total_loss": 0.5019320845603943
    },
    {
      "classification_loss": 0.5348790884017944,
      "epoch": 9.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2841,
      "total_loss": 0.5348790884017944
    },
    {
      "classification_loss": 0.600530207157135,
      "epoch": 9.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2842,
      "total_loss": 0.600530207157135
    },
    {
      "classification_loss": 0.53294438123703,
      "epoch": 9.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2843,
      "total_loss": 0.53294438123703
    },
    {
      "classification_loss": 0.5746873617172241,
      "epoch": 9.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2844,
      "total_loss": 0.5746873617172241
    },
    {
      "classification_loss": 0.533234179019928,
      "epoch": 9.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2845,
      "total_loss": 0.533234179019928
    },
    {
      "classification_loss": 0.5835236310958862,
      "epoch": 9.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2846,
      "total_loss": 0.5835236310958862
    },
    {
      "classification_loss": 0.547407329082489,
      "epoch": 9.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2847,
      "total_loss": 0.547407329082489
    },
    {
      "classification_loss": 0.5277396440505981,
      "epoch": 9.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2848,
      "total_loss": 0.5277396440505981
    },
    {
      "classification_loss": 0.5680034756660461,
      "epoch": 9.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2849,
      "total_loss": 0.5680034756660461
    },
    {
      "classification_loss": 0.5807998776435852,
      "epoch": 9.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2850,
      "total_loss": 0.5807998776435852
    },
    {
      "classification_loss": 0.5664036273956299,
      "epoch": 9.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2851,
      "total_loss": 0.5664036273956299
    },
    {
      "classification_loss": 0.5618075132369995,
      "epoch": 9.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2852,
      "total_loss": 0.5618075132369995
    },
    {
      "classification_loss": 0.5059137940406799,
      "epoch": 9.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2853,
      "total_loss": 0.5059137940406799
    },
    {
      "classification_loss": 0.5130093693733215,
      "epoch": 9.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2854,
      "total_loss": 0.5130093693733215
    },
    {
      "classification_loss": 0.5228539109230042,
      "epoch": 9.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2855,
      "total_loss": 0.5228539109230042
    },
    {
      "classification_loss": 0.5925768613815308,
      "epoch": 9.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2856,
      "total_loss": 0.5925768613815308
    },
    {
      "classification_loss": 0.6031990647315979,
      "epoch": 9.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2857,
      "total_loss": 0.6031990647315979
    },
    {
      "classification_loss": 0.58106529712677,
      "epoch": 9.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2858,
      "total_loss": 0.58106529712677
    },
    {
      "classification_loss": 0.4543772339820862,
      "epoch": 9.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2859,
      "total_loss": 0.4543772339820862
    },
    {
      "classification_loss": 0.507408082485199,
      "epoch": 9.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2860,
      "total_loss": 0.507408082485199
    },
    {
      "classification_loss": 0.6049045920372009,
      "epoch": 9.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2861,
      "total_loss": 0.6049045920372009
    },
    {
      "classification_loss": 0.5380851030349731,
      "epoch": 9.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2862,
      "total_loss": 0.5380851030349731
    },
    {
      "classification_loss": 0.5679389238357544,
      "epoch": 9.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2863,
      "total_loss": 0.5679389238357544
    },
    {
      "classification_loss": 0.6076105237007141,
      "epoch": 9.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2864,
      "total_loss": 0.6076105237007141
    },
    {
      "classification_loss": 0.5645461678504944,
      "epoch": 9.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2865,
      "total_loss": 0.5645461678504944
    },
    {
      "classification_loss": 0.4691527485847473,
      "epoch": 9.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2866,
      "total_loss": 0.4691527485847473
    },
    {
      "classification_loss": 0.6313549876213074,
      "epoch": 9.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2867,
      "total_loss": 0.6313549876213074
    },
    {
      "classification_loss": 0.4861345887184143,
      "epoch": 9.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2868,
      "total_loss": 0.4861345887184143
    },
    {
      "classification_loss": 0.5927546620368958,
      "epoch": 9.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2869,
      "total_loss": 0.5927546620368958
    },
    {
      "classification_loss": 0.53998863697052,
      "epoch": 9.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2870,
      "total_loss": 0.53998863697052
    },
    {
      "classification_loss": 0.5880774259567261,
      "epoch": 9.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2871,
      "total_loss": 0.5880774259567261
    },
    {
      "classification_loss": 0.4660242199897766,
      "epoch": 9.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2872,
      "total_loss": 0.4660242199897766
    },
    {
      "classification_loss": 0.5997165441513062,
      "epoch": 9.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2873,
      "total_loss": 0.5997165441513062
    },
    {
      "classification_loss": 0.519141435623169,
      "epoch": 9.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2874,
      "total_loss": 0.519141435623169
    },
    {
      "classification_loss": 0.5626758933067322,
      "epoch": 9.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2875,
      "total_loss": 0.5626758933067322
    },
    {
      "classification_loss": 0.4981306791305542,
      "epoch": 9.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2876,
      "total_loss": 0.4981306791305542
    },
    {
      "classification_loss": 0.6449567079544067,
      "epoch": 9.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2877,
      "total_loss": 0.6449567079544067
    },
    {
      "classification_loss": 0.5307846069335938,
      "epoch": 9.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2878,
      "total_loss": 0.5307846069335938
    },
    {
      "classification_loss": 0.4855753779411316,
      "epoch": 9.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2879,
      "total_loss": 0.4855753779411316
    },
    {
      "classification_loss": 0.5544257760047913,
      "epoch": 9.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2880,
      "total_loss": 0.5544257760047913
    },
    {
      "classification_loss": 0.5599453449249268,
      "epoch": 9.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2881,
      "total_loss": 0.5599453449249268
    },
    {
      "classification_loss": 0.5653978586196899,
      "epoch": 9.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2882,
      "total_loss": 0.5653978586196899
    },
    {
      "classification_loss": 0.43524667620658875,
      "epoch": 9.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2883,
      "total_loss": 0.43524667620658875
    },
    {
      "classification_loss": 0.6091921925544739,
      "epoch": 9.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2884,
      "total_loss": 0.6091921925544739
    },
    {
      "classification_loss": 0.4867774546146393,
      "epoch": 9.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2885,
      "total_loss": 0.4867774546146393
    },
    {
      "classification_loss": 0.6341556310653687,
      "epoch": 9.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2886,
      "total_loss": 0.6341556310653687
    },
    {
      "classification_loss": 0.5120766758918762,
      "epoch": 9.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2887,
      "total_loss": 0.5120766758918762
    },
    {
      "classification_loss": 0.5307943224906921,
      "epoch": 9.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2888,
      "total_loss": 0.5307943224906921
    },
    {
      "classification_loss": 0.47675225138664246,
      "epoch": 9.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2889,
      "total_loss": 0.47675225138664246
    },
    {
      "classification_loss": 0.5853420495986938,
      "epoch": 9.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2890,
      "total_loss": 0.5853420495986938
    },
    {
      "classification_loss": 0.46665164828300476,
      "epoch": 9.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2891,
      "total_loss": 0.46665164828300476
    },
    {
      "classification_loss": 0.49177855253219604,
      "epoch": 9.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2892,
      "total_loss": 0.49177855253219604
    },
    {
      "classification_loss": 0.5643212199211121,
      "epoch": 9.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2893,
      "total_loss": 0.5643212199211121
    },
    {
      "classification_loss": 0.4837818741798401,
      "epoch": 9.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2894,
      "total_loss": 0.4837818741798401
    },
    {
      "classification_loss": 0.5693506002426147,
      "epoch": 9.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2895,
      "total_loss": 0.5693506002426147
    },
    {
      "classification_loss": 0.5358092188835144,
      "epoch": 9.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2896,
      "total_loss": 0.5358092188835144
    },
    {
      "classification_loss": 0.5240539908409119,
      "epoch": 9.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2897,
      "total_loss": 0.5240539908409119
    },
    {
      "classification_loss": 0.5954419374465942,
      "epoch": 9.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2898,
      "total_loss": 0.5954419374465942
    },
    {
      "classification_loss": 0.4624165892601013,
      "epoch": 9.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2899,
      "total_loss": 0.4624165892601013
    },
    {
      "epoch": 9.508196721311476,
      "grad_norm": 1.6149169206619263,
      "learning_rate": 0.0001067,
      "loss": 0.5483,
      "step": 2900
    },
    {
      "classification_loss": 0.5078837871551514,
      "epoch": 9.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2900,
      "total_loss": 0.5078837871551514
    },
    {
      "classification_loss": 0.5096739530563354,
      "epoch": 9.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2901,
      "total_loss": 0.5096739530563354
    },
    {
      "classification_loss": 0.4414732754230499,
      "epoch": 9.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2902,
      "total_loss": 0.4414732754230499
    },
    {
      "classification_loss": 0.5398454070091248,
      "epoch": 9.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2903,
      "total_loss": 0.5398454070091248
    },
    {
      "classification_loss": 0.3516318202018738,
      "epoch": 9.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2904,
      "total_loss": 0.3516318202018738
    },
    {
      "classification_loss": 0.4628913700580597,
      "epoch": 9.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2905,
      "total_loss": 0.4628913700580597
    },
    {
      "classification_loss": 0.5350911021232605,
      "epoch": 9.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2906,
      "total_loss": 0.5350911021232605
    },
    {
      "classification_loss": 0.6426953673362732,
      "epoch": 9.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2907,
      "total_loss": 0.6426953673362732
    },
    {
      "classification_loss": 0.5499653816223145,
      "epoch": 9.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2908,
      "total_loss": 0.5499653816223145
    },
    {
      "classification_loss": 0.5372492671012878,
      "epoch": 9.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2909,
      "total_loss": 0.5372492671012878
    },
    {
      "classification_loss": 0.4775365889072418,
      "epoch": 9.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2910,
      "total_loss": 0.4775365889072418
    },
    {
      "classification_loss": 0.4707467555999756,
      "epoch": 9.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2911,
      "total_loss": 0.4707467555999756
    },
    {
      "classification_loss": 0.6076457500457764,
      "epoch": 9.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2912,
      "total_loss": 0.6076457500457764
    },
    {
      "classification_loss": 0.5163448452949524,
      "epoch": 9.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2913,
      "total_loss": 0.5163448452949524
    },
    {
      "classification_loss": 0.47210925817489624,
      "epoch": 9.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2914,
      "total_loss": 0.47210925817489624
    },
    {
      "classification_loss": 0.5521431565284729,
      "epoch": 9.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2915,
      "total_loss": 0.5521431565284729
    },
    {
      "classification_loss": 0.5750752687454224,
      "epoch": 9.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2916,
      "total_loss": 0.5750752687454224
    },
    {
      "classification_loss": 0.5596713423728943,
      "epoch": 9.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2917,
      "total_loss": 0.5596713423728943
    },
    {
      "classification_loss": 0.6133546233177185,
      "epoch": 9.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2918,
      "total_loss": 0.6133546233177185
    },
    {
      "classification_loss": 0.590685248374939,
      "epoch": 9.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2919,
      "total_loss": 0.590685248374939
    },
    {
      "classification_loss": 0.5116970539093018,
      "epoch": 9.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2920,
      "total_loss": 0.5116970539093018
    },
    {
      "classification_loss": 0.5916395783424377,
      "epoch": 9.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2921,
      "total_loss": 0.5916395783424377
    },
    {
      "classification_loss": 0.6981865167617798,
      "epoch": 9.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2922,
      "total_loss": 0.6981865167617798
    },
    {
      "classification_loss": 0.6648785471916199,
      "epoch": 9.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2923,
      "total_loss": 0.6648785471916199
    },
    {
      "classification_loss": 0.4595361351966858,
      "epoch": 9.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2924,
      "total_loss": 0.4595361351966858
    },
    {
      "classification_loss": 0.5108148455619812,
      "epoch": 9.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2925,
      "total_loss": 0.5108148455619812
    },
    {
      "classification_loss": 0.5445529818534851,
      "epoch": 9.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2926,
      "total_loss": 0.5445529818534851
    },
    {
      "classification_loss": 0.4182073771953583,
      "epoch": 9.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2927,
      "total_loss": 0.4182073771953583
    },
    {
      "classification_loss": 0.5607838034629822,
      "epoch": 9.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2928,
      "total_loss": 0.5607838034629822
    },
    {
      "classification_loss": 0.4596565067768097,
      "epoch": 9.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2929,
      "total_loss": 0.4596565067768097
    },
    {
      "classification_loss": 0.4725610315799713,
      "epoch": 9.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2930,
      "total_loss": 0.4725610315799713
    },
    {
      "classification_loss": 0.5518617630004883,
      "epoch": 9.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2931,
      "total_loss": 0.5518617630004883
    },
    {
      "classification_loss": 0.5128154158592224,
      "epoch": 9.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2932,
      "total_loss": 0.5128154158592224
    },
    {
      "classification_loss": 0.5515576004981995,
      "epoch": 9.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2933,
      "total_loss": 0.5515576004981995
    },
    {
      "classification_loss": 0.41754013299942017,
      "epoch": 9.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2934,
      "total_loss": 0.41754013299942017
    },
    {
      "classification_loss": 0.6875981688499451,
      "epoch": 9.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2935,
      "total_loss": 0.6875981688499451
    },
    {
      "classification_loss": 0.5542705655097961,
      "epoch": 9.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2936,
      "total_loss": 0.5542705655097961
    },
    {
      "classification_loss": 0.57802814245224,
      "epoch": 9.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2937,
      "total_loss": 0.57802814245224
    },
    {
      "classification_loss": 0.4797399044036865,
      "epoch": 9.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2938,
      "total_loss": 0.4797399044036865
    },
    {
      "classification_loss": 0.6156114339828491,
      "epoch": 9.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2939,
      "total_loss": 0.6156114339828491
    },
    {
      "classification_loss": 0.6001197099685669,
      "epoch": 9.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2940,
      "total_loss": 0.6001197099685669
    },
    {
      "classification_loss": 0.5884175896644592,
      "epoch": 9.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2941,
      "total_loss": 0.5884175896644592
    },
    {
      "classification_loss": 0.6524062752723694,
      "epoch": 9.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2942,
      "total_loss": 0.6524062752723694
    },
    {
      "classification_loss": 0.5821985602378845,
      "epoch": 9.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2943,
      "total_loss": 0.5821985602378845
    },
    {
      "classification_loss": 0.5984433889389038,
      "epoch": 9.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2944,
      "total_loss": 0.5984433889389038
    },
    {
      "classification_loss": 0.4874887764453888,
      "epoch": 9.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2945,
      "total_loss": 0.4874887764453888
    },
    {
      "classification_loss": 0.5915125608444214,
      "epoch": 9.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2946,
      "total_loss": 0.5915125608444214
    },
    {
      "classification_loss": 0.5089606642723083,
      "epoch": 9.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2947,
      "total_loss": 0.5089606642723083
    },
    {
      "classification_loss": 0.5720461010932922,
      "epoch": 9.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2948,
      "total_loss": 0.5720461010932922
    },
    {
      "classification_loss": 0.6067649126052856,
      "epoch": 9.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2949,
      "total_loss": 0.6067649126052856
    },
    {
      "classification_loss": 0.5487341284751892,
      "epoch": 9.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2950,
      "total_loss": 0.5487341284751892
    },
    {
      "classification_loss": 0.49887269735336304,
      "epoch": 9.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2951,
      "total_loss": 0.49887269735336304
    },
    {
      "classification_loss": 0.545790433883667,
      "epoch": 9.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2952,
      "total_loss": 0.545790433883667
    },
    {
      "classification_loss": 0.547538161277771,
      "epoch": 9.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2953,
      "total_loss": 0.547538161277771
    },
    {
      "classification_loss": 0.6121485233306885,
      "epoch": 9.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2954,
      "total_loss": 0.6121485233306885
    },
    {
      "classification_loss": 0.4991917312145233,
      "epoch": 9.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2955,
      "total_loss": 0.4991917312145233
    },
    {
      "classification_loss": 0.5422083735466003,
      "epoch": 9.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2956,
      "total_loss": 0.5422083735466003
    },
    {
      "classification_loss": 0.5232663154602051,
      "epoch": 9.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2957,
      "total_loss": 0.5232663154602051
    },
    {
      "classification_loss": 0.5509979128837585,
      "epoch": 9.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2958,
      "total_loss": 0.5509979128837585
    },
    {
      "classification_loss": 0.5567930936813354,
      "epoch": 9.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2959,
      "total_loss": 0.5567930936813354
    },
    {
      "classification_loss": 0.5280882716178894,
      "epoch": 9.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2960,
      "total_loss": 0.5280882716178894
    },
    {
      "classification_loss": 0.5096531510353088,
      "epoch": 9.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2961,
      "total_loss": 0.5096531510353088
    },
    {
      "classification_loss": 0.5920853018760681,
      "epoch": 9.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2962,
      "total_loss": 0.5920853018760681
    },
    {
      "classification_loss": 0.5150614380836487,
      "epoch": 9.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2963,
      "total_loss": 0.5150614380836487
    },
    {
      "classification_loss": 0.5710028409957886,
      "epoch": 9.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2964,
      "total_loss": 0.5710028409957886
    },
    {
      "classification_loss": 0.626639187335968,
      "epoch": 9.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2965,
      "total_loss": 0.626639187335968
    },
    {
      "classification_loss": 0.5475066304206848,
      "epoch": 9.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2966,
      "total_loss": 0.5475066304206848
    },
    {
      "classification_loss": 0.5529766082763672,
      "epoch": 9.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2967,
      "total_loss": 0.5529766082763672
    },
    {
      "classification_loss": 0.5723605155944824,
      "epoch": 9.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2968,
      "total_loss": 0.5723605155944824
    },
    {
      "classification_loss": 0.5017871260643005,
      "epoch": 9.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2969,
      "total_loss": 0.5017871260643005
    },
    {
      "classification_loss": 0.548379123210907,
      "epoch": 9.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2970,
      "total_loss": 0.548379123210907
    },
    {
      "classification_loss": 0.573656439781189,
      "epoch": 9.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2971,
      "total_loss": 0.573656439781189
    },
    {
      "classification_loss": 0.5462585091590881,
      "epoch": 9.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2972,
      "total_loss": 0.5462585091590881
    },
    {
      "classification_loss": 0.5723769664764404,
      "epoch": 9.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2973,
      "total_loss": 0.5723769664764404
    },
    {
      "classification_loss": 0.5832054018974304,
      "epoch": 9.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2974,
      "total_loss": 0.5832054018974304
    },
    {
      "classification_loss": 0.5101685523986816,
      "epoch": 9.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2975,
      "total_loss": 0.5101685523986816
    },
    {
      "classification_loss": 0.44957873225212097,
      "epoch": 9.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2976,
      "total_loss": 0.44957873225212097
    },
    {
      "classification_loss": 0.5575901865959167,
      "epoch": 9.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2977,
      "total_loss": 0.5575901865959167
    },
    {
      "classification_loss": 0.5057681798934937,
      "epoch": 9.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2978,
      "total_loss": 0.5057681798934937
    },
    {
      "classification_loss": 0.4616491198539734,
      "epoch": 9.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2979,
      "total_loss": 0.4616491198539734
    },
    {
      "classification_loss": 0.6481639742851257,
      "epoch": 9.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2980,
      "total_loss": 0.6481639742851257
    },
    {
      "classification_loss": 0.5392469167709351,
      "epoch": 9.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2981,
      "total_loss": 0.5392469167709351
    },
    {
      "classification_loss": 0.5132929086685181,
      "epoch": 9.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2982,
      "total_loss": 0.5132929086685181
    },
    {
      "classification_loss": 0.5741735100746155,
      "epoch": 9.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2983,
      "total_loss": 0.5741735100746155
    },
    {
      "classification_loss": 0.5241321325302124,
      "epoch": 9.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2984,
      "total_loss": 0.5241321325302124
    },
    {
      "classification_loss": 0.563521146774292,
      "epoch": 9.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2985,
      "total_loss": 0.563521146774292
    },
    {
      "classification_loss": 0.5747140049934387,
      "epoch": 9.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2986,
      "total_loss": 0.5747140049934387
    },
    {
      "classification_loss": 0.4802917242050171,
      "epoch": 9.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2987,
      "total_loss": 0.4802917242050171
    },
    {
      "classification_loss": 0.5493273138999939,
      "epoch": 9.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2988,
      "total_loss": 0.5493273138999939
    },
    {
      "classification_loss": 0.5186940431594849,
      "epoch": 9.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2989,
      "total_loss": 0.5186940431594849
    },
    {
      "classification_loss": 0.5083839893341064,
      "epoch": 9.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2990,
      "total_loss": 0.5083839893341064
    },
    {
      "classification_loss": 0.520956814289093,
      "epoch": 9.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2991,
      "total_loss": 0.520956814289093
    },
    {
      "classification_loss": 0.5374530553817749,
      "epoch": 9.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2992,
      "total_loss": 0.5374530553817749
    },
    {
      "classification_loss": 0.582970380783081,
      "epoch": 9.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2993,
      "total_loss": 0.582970380783081
    },
    {
      "classification_loss": 0.5605817437171936,
      "epoch": 9.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2994,
      "total_loss": 0.5605817437171936
    },
    {
      "classification_loss": 0.6618307828903198,
      "epoch": 9.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2995,
      "total_loss": 0.6618307828903198
    },
    {
      "classification_loss": 0.6049196124076843,
      "epoch": 9.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2996,
      "total_loss": 0.6049196124076843
    },
    {
      "classification_loss": 0.6005850434303284,
      "epoch": 9.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2997,
      "total_loss": 0.6005850434303284
    },
    {
      "classification_loss": 0.6334008574485779,
      "epoch": 9.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2998,
      "total_loss": 0.6334008574485779
    },
    {
      "classification_loss": 0.6887758374214172,
      "epoch": 9.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 2999,
      "total_loss": 0.6887758374214172
    },
    {
      "epoch": 9.836065573770492,
      "grad_norm": 4.363923072814941,
      "learning_rate": 0.00010336666666666668,
      "loss": 0.5478,
      "step": 3000
    },
    {
      "classification_loss": 0.6263953447341919,
      "epoch": 9.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3000,
      "total_loss": 0.6263953447341919
    },
    {
      "classification_loss": 0.5725831985473633,
      "epoch": 9.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3001,
      "total_loss": 0.5725831985473633
    },
    {
      "classification_loss": 0.5175486207008362,
      "epoch": 9.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3002,
      "total_loss": 0.5175486207008362
    },
    {
      "classification_loss": 0.5358838438987732,
      "epoch": 9.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3003,
      "total_loss": 0.5358838438987732
    },
    {
      "classification_loss": 0.5371708869934082,
      "epoch": 9.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3004,
      "total_loss": 0.5371708869934082
    },
    {
      "classification_loss": 0.45420998334884644,
      "epoch": 9.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3005,
      "total_loss": 0.45420998334884644
    },
    {
      "classification_loss": 0.5922546982765198,
      "epoch": 9.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3006,
      "total_loss": 0.5922546982765198
    },
    {
      "classification_loss": 0.4514184296131134,
      "epoch": 9.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3007,
      "total_loss": 0.4514184296131134
    },
    {
      "classification_loss": 0.593077540397644,
      "epoch": 9.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3008,
      "total_loss": 0.593077540397644
    },
    {
      "classification_loss": 0.5584707260131836,
      "epoch": 9.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3009,
      "total_loss": 0.5584707260131836
    },
    {
      "classification_loss": 0.5503756999969482,
      "epoch": 9.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3010,
      "total_loss": 0.5503756999969482
    },
    {
      "classification_loss": 0.40253448486328125,
      "epoch": 9.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3011,
      "total_loss": 0.40253448486328125
    },
    {
      "classification_loss": 0.6062096357345581,
      "epoch": 9.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3012,
      "total_loss": 0.6062096357345581
    },
    {
      "classification_loss": 0.5849326252937317,
      "epoch": 9.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3013,
      "total_loss": 0.5849326252937317
    },
    {
      "classification_loss": 0.5131246447563171,
      "epoch": 9.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3014,
      "total_loss": 0.5131246447563171
    },
    {
      "classification_loss": 0.47539547085762024,
      "epoch": 9.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3015,
      "total_loss": 0.47539547085762024
    },
    {
      "classification_loss": 0.4543718099594116,
      "epoch": 9.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3016,
      "total_loss": 0.4543718099594116
    },
    {
      "classification_loss": 0.5492370128631592,
      "epoch": 9.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3017,
      "total_loss": 0.5492370128631592
    },
    {
      "classification_loss": 0.46826353669166565,
      "epoch": 9.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3018,
      "total_loss": 0.46826353669166565
    },
    {
      "classification_loss": 0.5959601998329163,
      "epoch": 9.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3019,
      "total_loss": 0.5959601998329163
    },
    {
      "classification_loss": 0.5962521433830261,
      "epoch": 9.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3020,
      "total_loss": 0.5962521433830261
    },
    {
      "classification_loss": 0.5096560120582581,
      "epoch": 9.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3021,
      "total_loss": 0.5096560120582581
    },
    {
      "classification_loss": 0.5386738181114197,
      "epoch": 9.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3022,
      "total_loss": 0.5386738181114197
    },
    {
      "classification_loss": 0.5018627047538757,
      "epoch": 9.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3023,
      "total_loss": 0.5018627047538757
    },
    {
      "classification_loss": 0.4171256721019745,
      "epoch": 9.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3024,
      "total_loss": 0.4171256721019745
    },
    {
      "classification_loss": 0.6150687336921692,
      "epoch": 9.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3025,
      "total_loss": 0.6150687336921692
    },
    {
      "classification_loss": 0.6396713256835938,
      "epoch": 9.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3026,
      "total_loss": 0.6396713256835938
    },
    {
      "classification_loss": 0.5461227893829346,
      "epoch": 9.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3027,
      "total_loss": 0.5461227893829346
    },
    {
      "classification_loss": 0.5366770029067993,
      "epoch": 9.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3028,
      "total_loss": 0.5366770029067993
    },
    {
      "classification_loss": 0.6482165455818176,
      "epoch": 9.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3029,
      "total_loss": 0.6482165455818176
    },
    {
      "classification_loss": 0.5785496830940247,
      "epoch": 9.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3030,
      "total_loss": 0.5785496830940247
    },
    {
      "classification_loss": 0.5331398844718933,
      "epoch": 9.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3031,
      "total_loss": 0.5331398844718933
    },
    {
      "classification_loss": 0.5099960565567017,
      "epoch": 9.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3032,
      "total_loss": 0.5099960565567017
    },
    {
      "classification_loss": 0.5088269710540771,
      "epoch": 9.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3033,
      "total_loss": 0.5088269710540771
    },
    {
      "classification_loss": 0.6064779162406921,
      "epoch": 9.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3034,
      "total_loss": 0.6064779162406921
    },
    {
      "classification_loss": 0.5254529118537903,
      "epoch": 9.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3035,
      "total_loss": 0.5254529118537903
    },
    {
      "classification_loss": 0.45097866654396057,
      "epoch": 9.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3036,
      "total_loss": 0.45097866654396057
    },
    {
      "classification_loss": 0.5874088406562805,
      "epoch": 9.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3037,
      "total_loss": 0.5874088406562805
    },
    {
      "classification_loss": 0.6741394400596619,
      "epoch": 9.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3038,
      "total_loss": 0.6741394400596619
    },
    {
      "classification_loss": 0.49122536182403564,
      "epoch": 9.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3039,
      "total_loss": 0.49122536182403564
    },
    {
      "classification_loss": 0.5359402894973755,
      "epoch": 9.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3040,
      "total_loss": 0.5359402894973755
    },
    {
      "classification_loss": 0.6375181674957275,
      "epoch": 9.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3041,
      "total_loss": 0.6375181674957275
    },
    {
      "classification_loss": 0.5386343002319336,
      "epoch": 9.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3042,
      "total_loss": 0.5386343002319336
    },
    {
      "classification_loss": 0.5114045143127441,
      "epoch": 9.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3043,
      "total_loss": 0.5114045143127441
    },
    {
      "classification_loss": 0.6377732753753662,
      "epoch": 9.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3044,
      "total_loss": 0.6377732753753662
    },
    {
      "classification_loss": 0.568931519985199,
      "epoch": 9.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3045,
      "total_loss": 0.568931519985199
    },
    {
      "classification_loss": 0.5390684604644775,
      "epoch": 9.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3046,
      "total_loss": 0.5390684604644775
    },
    {
      "classification_loss": 0.5029708743095398,
      "epoch": 9.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3047,
      "total_loss": 0.5029708743095398
    },
    {
      "classification_loss": 0.5801330804824829,
      "epoch": 9.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3048,
      "total_loss": 0.5801330804824829
    },
    {
      "classification_loss": 0.539425790309906,
      "epoch": 9.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3049,
      "total_loss": 0.539425790309906
    },
    {
      "classification_loss": 1.315337061882019,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.315337061882019
    },
    {
      "classification_loss": 1.252416968345642,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.252416968345642
    },
    {
      "classification_loss": 1.1854854822158813,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.1854854822158813
    },
    {
      "classification_loss": 1.4310857057571411,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.4310857057571411
    },
    {
      "classification_loss": 1.1833645105361938,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.1833645105361938
    },
    {
      "classification_loss": 1.162623643875122,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.162623643875122
    },
    {
      "classification_loss": 1.2346965074539185,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.2346965074539185
    },
    {
      "classification_loss": 1.061720609664917,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 1.061720609664917
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.009448818897637795,
      "eval_loss": 1.2323402166366577,
      "eval_precision": 0.6,
      "eval_recall": 0.004761904761904762,
      "eval_runtime": 6.0012,
      "eval_samples_per_second": 166.634,
      "eval_steps_per_second": 1.333,
      "step": 3050
    },
    {
      "classification_loss": 0.5585190057754517,
      "epoch": 10.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3050,
      "total_loss": 0.5585190057754517
    },
    {
      "classification_loss": 0.5167592167854309,
      "epoch": 10.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3051,
      "total_loss": 0.5167592167854309
    },
    {
      "classification_loss": 0.5812942385673523,
      "epoch": 10.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3052,
      "total_loss": 0.5812942385673523
    },
    {
      "classification_loss": 0.6135699152946472,
      "epoch": 10.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3053,
      "total_loss": 0.6135699152946472
    },
    {
      "classification_loss": 0.6332794427871704,
      "epoch": 10.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3054,
      "total_loss": 0.6332794427871704
    },
    {
      "classification_loss": 0.6250237226486206,
      "epoch": 10.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3055,
      "total_loss": 0.6250237226486206
    },
    {
      "classification_loss": 0.5606337785720825,
      "epoch": 10.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3056,
      "total_loss": 0.5606337785720825
    },
    {
      "classification_loss": 0.4739517569541931,
      "epoch": 10.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3057,
      "total_loss": 0.4739517569541931
    },
    {
      "classification_loss": 0.5023469924926758,
      "epoch": 10.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3058,
      "total_loss": 0.5023469924926758
    },
    {
      "classification_loss": 0.5239759087562561,
      "epoch": 10.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3059,
      "total_loss": 0.5239759087562561
    },
    {
      "classification_loss": 0.544569730758667,
      "epoch": 10.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3060,
      "total_loss": 0.544569730758667
    },
    {
      "classification_loss": 0.4504774510860443,
      "epoch": 10.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3061,
      "total_loss": 0.4504774510860443
    },
    {
      "classification_loss": 0.5188162326812744,
      "epoch": 10.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3062,
      "total_loss": 0.5188162326812744
    },
    {
      "classification_loss": 0.5804712176322937,
      "epoch": 10.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3063,
      "total_loss": 0.5804712176322937
    },
    {
      "classification_loss": 0.5186001062393188,
      "epoch": 10.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3064,
      "total_loss": 0.5186001062393188
    },
    {
      "classification_loss": 0.537545919418335,
      "epoch": 10.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3065,
      "total_loss": 0.537545919418335
    },
    {
      "classification_loss": 0.44436410069465637,
      "epoch": 10.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3066,
      "total_loss": 0.44436410069465637
    },
    {
      "classification_loss": 0.4779721796512604,
      "epoch": 10.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3067,
      "total_loss": 0.4779721796512604
    },
    {
      "classification_loss": 0.452500581741333,
      "epoch": 10.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3068,
      "total_loss": 0.452500581741333
    },
    {
      "classification_loss": 0.6566808819770813,
      "epoch": 10.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3069,
      "total_loss": 0.6566808819770813
    },
    {
      "classification_loss": 0.4434141218662262,
      "epoch": 10.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3070,
      "total_loss": 0.4434141218662262
    },
    {
      "classification_loss": 0.5609543919563293,
      "epoch": 10.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3071,
      "total_loss": 0.5609543919563293
    },
    {
      "classification_loss": 0.6038334965705872,
      "epoch": 10.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3072,
      "total_loss": 0.6038334965705872
    },
    {
      "classification_loss": 0.5172891020774841,
      "epoch": 10.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3073,
      "total_loss": 0.5172891020774841
    },
    {
      "classification_loss": 0.5890527963638306,
      "epoch": 10.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3074,
      "total_loss": 0.5890527963638306
    },
    {
      "classification_loss": 0.5434616208076477,
      "epoch": 10.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3075,
      "total_loss": 0.5434616208076477
    },
    {
      "classification_loss": 0.5902769565582275,
      "epoch": 10.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3076,
      "total_loss": 0.5902769565582275
    },
    {
      "classification_loss": 0.5470064282417297,
      "epoch": 10.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3077,
      "total_loss": 0.5470064282417297
    },
    {
      "classification_loss": 0.49817222356796265,
      "epoch": 10.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3078,
      "total_loss": 0.49817222356796265
    },
    {
      "classification_loss": 0.4208587408065796,
      "epoch": 10.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3079,
      "total_loss": 0.4208587408065796
    },
    {
      "classification_loss": 0.5100795030593872,
      "epoch": 10.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3080,
      "total_loss": 0.5100795030593872
    },
    {
      "classification_loss": 0.5513923764228821,
      "epoch": 10.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3081,
      "total_loss": 0.5513923764228821
    },
    {
      "classification_loss": 0.485399067401886,
      "epoch": 10.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3082,
      "total_loss": 0.485399067401886
    },
    {
      "classification_loss": 0.47825074195861816,
      "epoch": 10.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3083,
      "total_loss": 0.47825074195861816
    },
    {
      "classification_loss": 0.46440720558166504,
      "epoch": 10.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3084,
      "total_loss": 0.46440720558166504
    },
    {
      "classification_loss": 0.4979894459247589,
      "epoch": 10.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3085,
      "total_loss": 0.4979894459247589
    },
    {
      "classification_loss": 0.5337590575218201,
      "epoch": 10.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3086,
      "total_loss": 0.5337590575218201
    },
    {
      "classification_loss": 0.44646915793418884,
      "epoch": 10.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3087,
      "total_loss": 0.44646915793418884
    },
    {
      "classification_loss": 0.46437761187553406,
      "epoch": 10.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3088,
      "total_loss": 0.46437761187553406
    },
    {
      "classification_loss": 0.534161388874054,
      "epoch": 10.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3089,
      "total_loss": 0.534161388874054
    },
    {
      "classification_loss": 0.42575180530548096,
      "epoch": 10.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3090,
      "total_loss": 0.42575180530548096
    },
    {
      "classification_loss": 0.531206488609314,
      "epoch": 10.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3091,
      "total_loss": 0.531206488609314
    },
    {
      "classification_loss": 0.538765549659729,
      "epoch": 10.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3092,
      "total_loss": 0.538765549659729
    },
    {
      "classification_loss": 0.532417893409729,
      "epoch": 10.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3093,
      "total_loss": 0.532417893409729
    },
    {
      "classification_loss": 0.49041104316711426,
      "epoch": 10.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3094,
      "total_loss": 0.49041104316711426
    },
    {
      "classification_loss": 0.5922170877456665,
      "epoch": 10.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3095,
      "total_loss": 0.5922170877456665
    },
    {
      "classification_loss": 0.5655179619789124,
      "epoch": 10.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3096,
      "total_loss": 0.5655179619789124
    },
    {
      "classification_loss": 0.5481525659561157,
      "epoch": 10.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3097,
      "total_loss": 0.5481525659561157
    },
    {
      "classification_loss": 0.4564822018146515,
      "epoch": 10.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3098,
      "total_loss": 0.4564822018146515
    },
    {
      "classification_loss": 0.5475074052810669,
      "epoch": 10.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3099,
      "total_loss": 0.5475074052810669
    },
    {
      "epoch": 10.163934426229508,
      "grad_norm": 5.808535099029541,
      "learning_rate": 0.00010003333333333333,
      "loss": 0.5353,
      "step": 3100
    },
    {
      "classification_loss": 0.5033072233200073,
      "epoch": 10.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3100,
      "total_loss": 0.5033072233200073
    },
    {
      "classification_loss": 0.7066625356674194,
      "epoch": 10.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3101,
      "total_loss": 0.7066625356674194
    },
    {
      "classification_loss": 0.5302122235298157,
      "epoch": 10.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3102,
      "total_loss": 0.5302122235298157
    },
    {
      "classification_loss": 0.5139956474304199,
      "epoch": 10.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3103,
      "total_loss": 0.5139956474304199
    },
    {
      "classification_loss": 0.5592950582504272,
      "epoch": 10.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3104,
      "total_loss": 0.5592950582504272
    },
    {
      "classification_loss": 0.49301186203956604,
      "epoch": 10.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3105,
      "total_loss": 0.49301186203956604
    },
    {
      "classification_loss": 0.597277820110321,
      "epoch": 10.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3106,
      "total_loss": 0.597277820110321
    },
    {
      "classification_loss": 0.7034754157066345,
      "epoch": 10.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3107,
      "total_loss": 0.7034754157066345
    },
    {
      "classification_loss": 0.49745872616767883,
      "epoch": 10.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3108,
      "total_loss": 0.49745872616767883
    },
    {
      "classification_loss": 0.66401207447052,
      "epoch": 10.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3109,
      "total_loss": 0.66401207447052
    },
    {
      "classification_loss": 0.5420095324516296,
      "epoch": 10.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3110,
      "total_loss": 0.5420095324516296
    },
    {
      "classification_loss": 0.5529798269271851,
      "epoch": 10.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3111,
      "total_loss": 0.5529798269271851
    },
    {
      "classification_loss": 0.5439601540565491,
      "epoch": 10.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3112,
      "total_loss": 0.5439601540565491
    },
    {
      "classification_loss": 0.502209484577179,
      "epoch": 10.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3113,
      "total_loss": 0.502209484577179
    },
    {
      "classification_loss": 0.5891510248184204,
      "epoch": 10.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3114,
      "total_loss": 0.5891510248184204
    },
    {
      "classification_loss": 0.5019792914390564,
      "epoch": 10.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3115,
      "total_loss": 0.5019792914390564
    },
    {
      "classification_loss": 0.4729744791984558,
      "epoch": 10.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3116,
      "total_loss": 0.4729744791984558
    },
    {
      "classification_loss": 0.6112383604049683,
      "epoch": 10.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3117,
      "total_loss": 0.6112383604049683
    },
    {
      "classification_loss": 0.5131836533546448,
      "epoch": 10.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3118,
      "total_loss": 0.5131836533546448
    },
    {
      "classification_loss": 0.4946509301662445,
      "epoch": 10.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3119,
      "total_loss": 0.4946509301662445
    },
    {
      "classification_loss": 0.5350556969642639,
      "epoch": 10.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3120,
      "total_loss": 0.5350556969642639
    },
    {
      "classification_loss": 0.5108381509780884,
      "epoch": 10.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3121,
      "total_loss": 0.5108381509780884
    },
    {
      "classification_loss": 0.47347506880760193,
      "epoch": 10.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3122,
      "total_loss": 0.47347506880760193
    },
    {
      "classification_loss": 0.5011521577835083,
      "epoch": 10.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3123,
      "total_loss": 0.5011521577835083
    },
    {
      "classification_loss": 0.5973693132400513,
      "epoch": 10.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3124,
      "total_loss": 0.5973693132400513
    },
    {
      "classification_loss": 0.4861893653869629,
      "epoch": 10.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3125,
      "total_loss": 0.4861893653869629
    },
    {
      "classification_loss": 0.45852819085121155,
      "epoch": 10.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3126,
      "total_loss": 0.45852819085121155
    },
    {
      "classification_loss": 0.5062610507011414,
      "epoch": 10.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3127,
      "total_loss": 0.5062610507011414
    },
    {
      "classification_loss": 0.6088679432868958,
      "epoch": 10.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3128,
      "total_loss": 0.6088679432868958
    },
    {
      "classification_loss": 0.4911157786846161,
      "epoch": 10.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3129,
      "total_loss": 0.4911157786846161
    },
    {
      "classification_loss": 0.5011259913444519,
      "epoch": 10.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3130,
      "total_loss": 0.5011259913444519
    },
    {
      "classification_loss": 0.63545823097229,
      "epoch": 10.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3131,
      "total_loss": 0.63545823097229
    },
    {
      "classification_loss": 0.5377953052520752,
      "epoch": 10.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3132,
      "total_loss": 0.5377953052520752
    },
    {
      "classification_loss": 0.6155110597610474,
      "epoch": 10.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3133,
      "total_loss": 0.6155110597610474
    },
    {
      "classification_loss": 0.46641451120376587,
      "epoch": 10.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3134,
      "total_loss": 0.46641451120376587
    },
    {
      "classification_loss": 0.5865561366081238,
      "epoch": 10.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3135,
      "total_loss": 0.5865561366081238
    },
    {
      "classification_loss": 0.4703580439090729,
      "epoch": 10.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3136,
      "total_loss": 0.4703580439090729
    },
    {
      "classification_loss": 0.5671036243438721,
      "epoch": 10.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3137,
      "total_loss": 0.5671036243438721
    },
    {
      "classification_loss": 0.5725928544998169,
      "epoch": 10.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3138,
      "total_loss": 0.5725928544998169
    },
    {
      "classification_loss": 0.5410823822021484,
      "epoch": 10.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3139,
      "total_loss": 0.5410823822021484
    },
    {
      "classification_loss": 0.48406076431274414,
      "epoch": 10.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3140,
      "total_loss": 0.48406076431274414
    },
    {
      "classification_loss": 0.55756676197052,
      "epoch": 10.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3141,
      "total_loss": 0.55756676197052
    },
    {
      "classification_loss": 0.5374376773834229,
      "epoch": 10.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3142,
      "total_loss": 0.5374376773834229
    },
    {
      "classification_loss": 0.5738806128501892,
      "epoch": 10.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3143,
      "total_loss": 0.5738806128501892
    },
    {
      "classification_loss": 0.5245816707611084,
      "epoch": 10.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3144,
      "total_loss": 0.5245816707611084
    },
    {
      "classification_loss": 0.4912411868572235,
      "epoch": 10.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3145,
      "total_loss": 0.4912411868572235
    },
    {
      "classification_loss": 0.42475879192352295,
      "epoch": 10.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3146,
      "total_loss": 0.42475879192352295
    },
    {
      "classification_loss": 0.6057547330856323,
      "epoch": 10.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3147,
      "total_loss": 0.6057547330856323
    },
    {
      "classification_loss": 0.4235420823097229,
      "epoch": 10.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3148,
      "total_loss": 0.4235420823097229
    },
    {
      "classification_loss": 0.5601687431335449,
      "epoch": 10.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3149,
      "total_loss": 0.5601687431335449
    },
    {
      "classification_loss": 0.539758563041687,
      "epoch": 10.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3150,
      "total_loss": 0.539758563041687
    },
    {
      "classification_loss": 0.5633925199508667,
      "epoch": 10.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3151,
      "total_loss": 0.5633925199508667
    },
    {
      "classification_loss": 0.5245622992515564,
      "epoch": 10.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3152,
      "total_loss": 0.5245622992515564
    },
    {
      "classification_loss": 0.5713598132133484,
      "epoch": 10.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3153,
      "total_loss": 0.5713598132133484
    },
    {
      "classification_loss": 0.5614864230155945,
      "epoch": 10.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3154,
      "total_loss": 0.5614864230155945
    },
    {
      "classification_loss": 0.6023693084716797,
      "epoch": 10.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3155,
      "total_loss": 0.6023693084716797
    },
    {
      "classification_loss": 0.5790193676948547,
      "epoch": 10.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3156,
      "total_loss": 0.5790193676948547
    },
    {
      "classification_loss": 0.46447575092315674,
      "epoch": 10.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3157,
      "total_loss": 0.46447575092315674
    },
    {
      "classification_loss": 0.571775496006012,
      "epoch": 10.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3158,
      "total_loss": 0.571775496006012
    },
    {
      "classification_loss": 0.5349812507629395,
      "epoch": 10.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3159,
      "total_loss": 0.5349812507629395
    },
    {
      "classification_loss": 0.4572931230068207,
      "epoch": 10.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3160,
      "total_loss": 0.4572931230068207
    },
    {
      "classification_loss": 0.6241995692253113,
      "epoch": 10.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3161,
      "total_loss": 0.6241995692253113
    },
    {
      "classification_loss": 0.4532637298107147,
      "epoch": 10.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3162,
      "total_loss": 0.4532637298107147
    },
    {
      "classification_loss": 0.5727502703666687,
      "epoch": 10.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3163,
      "total_loss": 0.5727502703666687
    },
    {
      "classification_loss": 0.6677555441856384,
      "epoch": 10.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3164,
      "total_loss": 0.6677555441856384
    },
    {
      "classification_loss": 0.6566665172576904,
      "epoch": 10.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3165,
      "total_loss": 0.6566665172576904
    },
    {
      "classification_loss": 0.5346360802650452,
      "epoch": 10.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3166,
      "total_loss": 0.5346360802650452
    },
    {
      "classification_loss": 0.4667595624923706,
      "epoch": 10.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3167,
      "total_loss": 0.4667595624923706
    },
    {
      "classification_loss": 0.5416405200958252,
      "epoch": 10.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3168,
      "total_loss": 0.5416405200958252
    },
    {
      "classification_loss": 0.4584421217441559,
      "epoch": 10.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3169,
      "total_loss": 0.4584421217441559
    },
    {
      "classification_loss": 0.49939021468162537,
      "epoch": 10.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3170,
      "total_loss": 0.49939021468162537
    },
    {
      "classification_loss": 0.5819193124771118,
      "epoch": 10.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3171,
      "total_loss": 0.5819193124771118
    },
    {
      "classification_loss": 0.5564653873443604,
      "epoch": 10.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3172,
      "total_loss": 0.5564653873443604
    },
    {
      "classification_loss": 0.552484929561615,
      "epoch": 10.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3173,
      "total_loss": 0.552484929561615
    },
    {
      "classification_loss": 0.5957385897636414,
      "epoch": 10.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3174,
      "total_loss": 0.5957385897636414
    },
    {
      "classification_loss": 0.5896109938621521,
      "epoch": 10.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3175,
      "total_loss": 0.5896109938621521
    },
    {
      "classification_loss": 0.5068563222885132,
      "epoch": 10.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3176,
      "total_loss": 0.5068563222885132
    },
    {
      "classification_loss": 0.5180625319480896,
      "epoch": 10.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3177,
      "total_loss": 0.5180625319480896
    },
    {
      "classification_loss": 0.488609254360199,
      "epoch": 10.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3178,
      "total_loss": 0.488609254360199
    },
    {
      "classification_loss": 0.5187978148460388,
      "epoch": 10.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3179,
      "total_loss": 0.5187978148460388
    },
    {
      "classification_loss": 0.571561872959137,
      "epoch": 10.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3180,
      "total_loss": 0.571561872959137
    },
    {
      "classification_loss": 0.43060392141342163,
      "epoch": 10.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3181,
      "total_loss": 0.43060392141342163
    },
    {
      "classification_loss": 0.5117114186286926,
      "epoch": 10.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3182,
      "total_loss": 0.5117114186286926
    },
    {
      "classification_loss": 0.38518136739730835,
      "epoch": 10.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3183,
      "total_loss": 0.38518136739730835
    },
    {
      "classification_loss": 0.5784398317337036,
      "epoch": 10.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3184,
      "total_loss": 0.5784398317337036
    },
    {
      "classification_loss": 0.5725519061088562,
      "epoch": 10.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3185,
      "total_loss": 0.5725519061088562
    },
    {
      "classification_loss": 0.5479760766029358,
      "epoch": 10.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3186,
      "total_loss": 0.5479760766029358
    },
    {
      "classification_loss": 0.5949059724807739,
      "epoch": 10.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3187,
      "total_loss": 0.5949059724807739
    },
    {
      "classification_loss": 0.5480918884277344,
      "epoch": 10.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3188,
      "total_loss": 0.5480918884277344
    },
    {
      "classification_loss": 0.57415771484375,
      "epoch": 10.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3189,
      "total_loss": 0.57415771484375
    },
    {
      "classification_loss": 0.6005857586860657,
      "epoch": 10.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3190,
      "total_loss": 0.6005857586860657
    },
    {
      "classification_loss": 0.567719042301178,
      "epoch": 10.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3191,
      "total_loss": 0.567719042301178
    },
    {
      "classification_loss": 0.484910249710083,
      "epoch": 10.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3192,
      "total_loss": 0.484910249710083
    },
    {
      "classification_loss": 0.5349029302597046,
      "epoch": 10.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3193,
      "total_loss": 0.5349029302597046
    },
    {
      "classification_loss": 0.6219490766525269,
      "epoch": 10.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3194,
      "total_loss": 0.6219490766525269
    },
    {
      "classification_loss": 0.46181246638298035,
      "epoch": 10.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3195,
      "total_loss": 0.46181246638298035
    },
    {
      "classification_loss": 0.6181867122650146,
      "epoch": 10.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3196,
      "total_loss": 0.6181867122650146
    },
    {
      "classification_loss": 0.489253431558609,
      "epoch": 10.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3197,
      "total_loss": 0.489253431558609
    },
    {
      "classification_loss": 0.5787531137466431,
      "epoch": 10.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3198,
      "total_loss": 0.5787531137466431
    },
    {
      "classification_loss": 0.600668728351593,
      "epoch": 10.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3199,
      "total_loss": 0.600668728351593
    },
    {
      "epoch": 10.491803278688524,
      "grad_norm": 2.2480199337005615,
      "learning_rate": 9.67e-05,
      "loss": 0.5417,
      "step": 3200
    },
    {
      "classification_loss": 0.4810469448566437,
      "epoch": 10.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3200,
      "total_loss": 0.4810469448566437
    },
    {
      "classification_loss": 0.5891783833503723,
      "epoch": 10.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3201,
      "total_loss": 0.5891783833503723
    },
    {
      "classification_loss": 0.440164715051651,
      "epoch": 10.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3202,
      "total_loss": 0.440164715051651
    },
    {
      "classification_loss": 0.5283153653144836,
      "epoch": 10.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3203,
      "total_loss": 0.5283153653144836
    },
    {
      "classification_loss": 0.5479808449745178,
      "epoch": 10.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3204,
      "total_loss": 0.5479808449745178
    },
    {
      "classification_loss": 0.48461318016052246,
      "epoch": 10.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3205,
      "total_loss": 0.48461318016052246
    },
    {
      "classification_loss": 0.4792037904262543,
      "epoch": 10.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3206,
      "total_loss": 0.4792037904262543
    },
    {
      "classification_loss": 0.5906230807304382,
      "epoch": 10.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3207,
      "total_loss": 0.5906230807304382
    },
    {
      "classification_loss": 0.5083034634590149,
      "epoch": 10.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3208,
      "total_loss": 0.5083034634590149
    },
    {
      "classification_loss": 0.564676821231842,
      "epoch": 10.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3209,
      "total_loss": 0.564676821231842
    },
    {
      "classification_loss": 0.5438753962516785,
      "epoch": 10.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3210,
      "total_loss": 0.5438753962516785
    },
    {
      "classification_loss": 0.4380866587162018,
      "epoch": 10.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3211,
      "total_loss": 0.4380866587162018
    },
    {
      "classification_loss": 0.47985371947288513,
      "epoch": 10.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3212,
      "total_loss": 0.47985371947288513
    },
    {
      "classification_loss": 0.4819614291191101,
      "epoch": 10.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3213,
      "total_loss": 0.4819614291191101
    },
    {
      "classification_loss": 0.4160548746585846,
      "epoch": 10.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3214,
      "total_loss": 0.4160548746585846
    },
    {
      "classification_loss": 0.5732541680335999,
      "epoch": 10.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3215,
      "total_loss": 0.5732541680335999
    },
    {
      "classification_loss": 0.5746781229972839,
      "epoch": 10.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3216,
      "total_loss": 0.5746781229972839
    },
    {
      "classification_loss": 0.4509330689907074,
      "epoch": 10.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3217,
      "total_loss": 0.4509330689907074
    },
    {
      "classification_loss": 0.5178341865539551,
      "epoch": 10.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3218,
      "total_loss": 0.5178341865539551
    },
    {
      "classification_loss": 0.5494186878204346,
      "epoch": 10.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3219,
      "total_loss": 0.5494186878204346
    },
    {
      "classification_loss": 0.5473563075065613,
      "epoch": 10.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3220,
      "total_loss": 0.5473563075065613
    },
    {
      "classification_loss": 0.5723955035209656,
      "epoch": 10.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3221,
      "total_loss": 0.5723955035209656
    },
    {
      "classification_loss": 0.514056384563446,
      "epoch": 10.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3222,
      "total_loss": 0.514056384563446
    },
    {
      "classification_loss": 0.5531362891197205,
      "epoch": 10.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3223,
      "total_loss": 0.5531362891197205
    },
    {
      "classification_loss": 0.5906227827072144,
      "epoch": 10.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3224,
      "total_loss": 0.5906227827072144
    },
    {
      "classification_loss": 0.5661094188690186,
      "epoch": 10.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3225,
      "total_loss": 0.5661094188690186
    },
    {
      "classification_loss": 0.5172545313835144,
      "epoch": 10.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3226,
      "total_loss": 0.5172545313835144
    },
    {
      "classification_loss": 0.6408933997154236,
      "epoch": 10.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3227,
      "total_loss": 0.6408933997154236
    },
    {
      "classification_loss": 0.49655866622924805,
      "epoch": 10.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3228,
      "total_loss": 0.49655866622924805
    },
    {
      "classification_loss": 0.5016624331474304,
      "epoch": 10.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3229,
      "total_loss": 0.5016624331474304
    },
    {
      "classification_loss": 0.5334887504577637,
      "epoch": 10.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3230,
      "total_loss": 0.5334887504577637
    },
    {
      "classification_loss": 0.4818671643733978,
      "epoch": 10.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3231,
      "total_loss": 0.4818671643733978
    },
    {
      "classification_loss": 0.4747026562690735,
      "epoch": 10.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3232,
      "total_loss": 0.4747026562690735
    },
    {
      "classification_loss": 0.6186278462409973,
      "epoch": 10.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3233,
      "total_loss": 0.6186278462409973
    },
    {
      "classification_loss": 0.5185611844062805,
      "epoch": 10.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3234,
      "total_loss": 0.5185611844062805
    },
    {
      "classification_loss": 0.5521673560142517,
      "epoch": 10.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3235,
      "total_loss": 0.5521673560142517
    },
    {
      "classification_loss": 0.5469722747802734,
      "epoch": 10.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3236,
      "total_loss": 0.5469722747802734
    },
    {
      "classification_loss": 0.5243014693260193,
      "epoch": 10.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3237,
      "total_loss": 0.5243014693260193
    },
    {
      "classification_loss": 0.5082218647003174,
      "epoch": 10.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3238,
      "total_loss": 0.5082218647003174
    },
    {
      "classification_loss": 0.5175495147705078,
      "epoch": 10.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3239,
      "total_loss": 0.5175495147705078
    },
    {
      "classification_loss": 0.5298448204994202,
      "epoch": 10.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3240,
      "total_loss": 0.5298448204994202
    },
    {
      "classification_loss": 0.5271924734115601,
      "epoch": 10.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3241,
      "total_loss": 0.5271924734115601
    },
    {
      "classification_loss": 0.47215309739112854,
      "epoch": 10.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3242,
      "total_loss": 0.47215309739112854
    },
    {
      "classification_loss": 0.615861713886261,
      "epoch": 10.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3243,
      "total_loss": 0.615861713886261
    },
    {
      "classification_loss": 0.5514841079711914,
      "epoch": 10.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3244,
      "total_loss": 0.5514841079711914
    },
    {
      "classification_loss": 0.5787597298622131,
      "epoch": 10.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3245,
      "total_loss": 0.5787597298622131
    },
    {
      "classification_loss": 0.5607947707176208,
      "epoch": 10.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3246,
      "total_loss": 0.5607947707176208
    },
    {
      "classification_loss": 0.45356863737106323,
      "epoch": 10.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3247,
      "total_loss": 0.45356863737106323
    },
    {
      "classification_loss": 0.5034403204917908,
      "epoch": 10.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3248,
      "total_loss": 0.5034403204917908
    },
    {
      "classification_loss": 0.49151602387428284,
      "epoch": 10.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3249,
      "total_loss": 0.49151602387428284
    },
    {
      "classification_loss": 0.6223282814025879,
      "epoch": 10.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3250,
      "total_loss": 0.6223282814025879
    },
    {
      "classification_loss": 0.48941895365715027,
      "epoch": 10.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3251,
      "total_loss": 0.48941895365715027
    },
    {
      "classification_loss": 0.46030494570732117,
      "epoch": 10.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3252,
      "total_loss": 0.46030494570732117
    },
    {
      "classification_loss": 0.4787260890007019,
      "epoch": 10.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3253,
      "total_loss": 0.4787260890007019
    },
    {
      "classification_loss": 0.4362707734107971,
      "epoch": 10.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3254,
      "total_loss": 0.4362707734107971
    },
    {
      "classification_loss": 0.43654555082321167,
      "epoch": 10.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3255,
      "total_loss": 0.43654555082321167
    },
    {
      "classification_loss": 0.6658895611763,
      "epoch": 10.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3256,
      "total_loss": 0.6658895611763
    },
    {
      "classification_loss": 0.6137716174125671,
      "epoch": 10.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3257,
      "total_loss": 0.6137716174125671
    },
    {
      "classification_loss": 0.5676758885383606,
      "epoch": 10.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3258,
      "total_loss": 0.5676758885383606
    },
    {
      "classification_loss": 0.5730286240577698,
      "epoch": 10.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3259,
      "total_loss": 0.5730286240577698
    },
    {
      "classification_loss": 0.46062421798706055,
      "epoch": 10.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3260,
      "total_loss": 0.46062421798706055
    },
    {
      "classification_loss": 0.4451919198036194,
      "epoch": 10.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3261,
      "total_loss": 0.4451919198036194
    },
    {
      "classification_loss": 0.583337128162384,
      "epoch": 10.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3262,
      "total_loss": 0.583337128162384
    },
    {
      "classification_loss": 0.6294957399368286,
      "epoch": 10.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3263,
      "total_loss": 0.6294957399368286
    },
    {
      "classification_loss": 0.6132055521011353,
      "epoch": 10.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3264,
      "total_loss": 0.6132055521011353
    },
    {
      "classification_loss": 0.5533393621444702,
      "epoch": 10.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3265,
      "total_loss": 0.5533393621444702
    },
    {
      "classification_loss": 0.4130241572856903,
      "epoch": 10.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3266,
      "total_loss": 0.4130241572856903
    },
    {
      "classification_loss": 0.6419994235038757,
      "epoch": 10.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3267,
      "total_loss": 0.6419994235038757
    },
    {
      "classification_loss": 0.4959430992603302,
      "epoch": 10.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3268,
      "total_loss": 0.4959430992603302
    },
    {
      "classification_loss": 0.5145115256309509,
      "epoch": 10.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3269,
      "total_loss": 0.5145115256309509
    },
    {
      "classification_loss": 0.6308116912841797,
      "epoch": 10.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3270,
      "total_loss": 0.6308116912841797
    },
    {
      "classification_loss": 0.5672852396965027,
      "epoch": 10.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3271,
      "total_loss": 0.5672852396965027
    },
    {
      "classification_loss": 0.5068480372428894,
      "epoch": 10.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3272,
      "total_loss": 0.5068480372428894
    },
    {
      "classification_loss": 0.6030270457267761,
      "epoch": 10.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3273,
      "total_loss": 0.6030270457267761
    },
    {
      "classification_loss": 0.6289059519767761,
      "epoch": 10.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3274,
      "total_loss": 0.6289059519767761
    },
    {
      "classification_loss": 0.5834506154060364,
      "epoch": 10.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3275,
      "total_loss": 0.5834506154060364
    },
    {
      "classification_loss": 0.47674956917762756,
      "epoch": 10.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3276,
      "total_loss": 0.47674956917762756
    },
    {
      "classification_loss": 0.5093349814414978,
      "epoch": 10.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3277,
      "total_loss": 0.5093349814414978
    },
    {
      "classification_loss": 0.5903341174125671,
      "epoch": 10.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3278,
      "total_loss": 0.5903341174125671
    },
    {
      "classification_loss": 0.4460608661174774,
      "epoch": 10.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3279,
      "total_loss": 0.4460608661174774
    },
    {
      "classification_loss": 0.5433955788612366,
      "epoch": 10.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3280,
      "total_loss": 0.5433955788612366
    },
    {
      "classification_loss": 0.7452305555343628,
      "epoch": 10.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3281,
      "total_loss": 0.7452305555343628
    },
    {
      "classification_loss": 0.5736077427864075,
      "epoch": 10.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3282,
      "total_loss": 0.5736077427864075
    },
    {
      "classification_loss": 0.4364880323410034,
      "epoch": 10.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3283,
      "total_loss": 0.4364880323410034
    },
    {
      "classification_loss": 0.5976078510284424,
      "epoch": 10.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3284,
      "total_loss": 0.5976078510284424
    },
    {
      "classification_loss": 0.5551433563232422,
      "epoch": 10.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3285,
      "total_loss": 0.5551433563232422
    },
    {
      "classification_loss": 0.5378670692443848,
      "epoch": 10.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3286,
      "total_loss": 0.5378670692443848
    },
    {
      "classification_loss": 0.5290780663490295,
      "epoch": 10.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3287,
      "total_loss": 0.5290780663490295
    },
    {
      "classification_loss": 0.6005119681358337,
      "epoch": 10.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3288,
      "total_loss": 0.6005119681358337
    },
    {
      "classification_loss": 0.6792011260986328,
      "epoch": 10.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3289,
      "total_loss": 0.6792011260986328
    },
    {
      "classification_loss": 0.4569478929042816,
      "epoch": 10.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3290,
      "total_loss": 0.4569478929042816
    },
    {
      "classification_loss": 0.6054799556732178,
      "epoch": 10.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3291,
      "total_loss": 0.6054799556732178
    },
    {
      "classification_loss": 0.4852016568183899,
      "epoch": 10.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3292,
      "total_loss": 0.4852016568183899
    },
    {
      "classification_loss": 0.5282685160636902,
      "epoch": 10.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3293,
      "total_loss": 0.5282685160636902
    },
    {
      "classification_loss": 0.40106073021888733,
      "epoch": 10.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3294,
      "total_loss": 0.40106073021888733
    },
    {
      "classification_loss": 0.46586138010025024,
      "epoch": 10.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3295,
      "total_loss": 0.46586138010025024
    },
    {
      "classification_loss": 0.5768444538116455,
      "epoch": 10.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3296,
      "total_loss": 0.5768444538116455
    },
    {
      "classification_loss": 0.4914739727973938,
      "epoch": 10.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3297,
      "total_loss": 0.4914739727973938
    },
    {
      "classification_loss": 0.6305003762245178,
      "epoch": 10.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3298,
      "total_loss": 0.6305003762245178
    },
    {
      "classification_loss": 0.6319124698638916,
      "epoch": 10.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3299,
      "total_loss": 0.6319124698638916
    },
    {
      "epoch": 10.819672131147541,
      "grad_norm": 6.6445794105529785,
      "learning_rate": 9.336666666666667e-05,
      "loss": 0.5361,
      "step": 3300
    },
    {
      "classification_loss": 0.5714423656463623,
      "epoch": 10.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3300,
      "total_loss": 0.5714423656463623
    },
    {
      "classification_loss": 0.5696502923965454,
      "epoch": 10.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3301,
      "total_loss": 0.5696502923965454
    },
    {
      "classification_loss": 0.5795506834983826,
      "epoch": 10.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3302,
      "total_loss": 0.5795506834983826
    },
    {
      "classification_loss": 0.46390217542648315,
      "epoch": 10.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3303,
      "total_loss": 0.46390217542648315
    },
    {
      "classification_loss": 0.47446656227111816,
      "epoch": 10.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3304,
      "total_loss": 0.47446656227111816
    },
    {
      "classification_loss": 0.5453193783760071,
      "epoch": 10.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3305,
      "total_loss": 0.5453193783760071
    },
    {
      "classification_loss": 0.6690057516098022,
      "epoch": 10.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3306,
      "total_loss": 0.6690057516098022
    },
    {
      "classification_loss": 0.6648238897323608,
      "epoch": 10.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3307,
      "total_loss": 0.6648238897323608
    },
    {
      "classification_loss": 0.530947744846344,
      "epoch": 10.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3308,
      "total_loss": 0.530947744846344
    },
    {
      "classification_loss": 0.6139731407165527,
      "epoch": 10.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3309,
      "total_loss": 0.6139731407165527
    },
    {
      "classification_loss": 0.5624094009399414,
      "epoch": 10.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3310,
      "total_loss": 0.5624094009399414
    },
    {
      "classification_loss": 0.530674397945404,
      "epoch": 10.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3311,
      "total_loss": 0.530674397945404
    },
    {
      "classification_loss": 0.5223616361618042,
      "epoch": 10.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3312,
      "total_loss": 0.5223616361618042
    },
    {
      "classification_loss": 0.5096617937088013,
      "epoch": 10.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3313,
      "total_loss": 0.5096617937088013
    },
    {
      "classification_loss": 0.5581821203231812,
      "epoch": 10.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3314,
      "total_loss": 0.5581821203231812
    },
    {
      "classification_loss": 0.4695660173892975,
      "epoch": 10.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3315,
      "total_loss": 0.4695660173892975
    },
    {
      "classification_loss": 0.49442949891090393,
      "epoch": 10.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3316,
      "total_loss": 0.49442949891090393
    },
    {
      "classification_loss": 0.4810444116592407,
      "epoch": 10.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3317,
      "total_loss": 0.4810444116592407
    },
    {
      "classification_loss": 0.56352698802948,
      "epoch": 10.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3318,
      "total_loss": 0.56352698802948
    },
    {
      "classification_loss": 0.4879767596721649,
      "epoch": 10.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3319,
      "total_loss": 0.4879767596721649
    },
    {
      "classification_loss": 0.5098764300346375,
      "epoch": 10.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3320,
      "total_loss": 0.5098764300346375
    },
    {
      "classification_loss": 0.533379077911377,
      "epoch": 10.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3321,
      "total_loss": 0.533379077911377
    },
    {
      "classification_loss": 0.5206994414329529,
      "epoch": 10.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3322,
      "total_loss": 0.5206994414329529
    },
    {
      "classification_loss": 0.5939053893089294,
      "epoch": 10.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3323,
      "total_loss": 0.5939053893089294
    },
    {
      "classification_loss": 0.5258772373199463,
      "epoch": 10.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3324,
      "total_loss": 0.5258772373199463
    },
    {
      "classification_loss": 0.45243504643440247,
      "epoch": 10.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3325,
      "total_loss": 0.45243504643440247
    },
    {
      "classification_loss": 0.49451807141304016,
      "epoch": 10.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3326,
      "total_loss": 0.49451807141304016
    },
    {
      "classification_loss": 0.4655503034591675,
      "epoch": 10.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3327,
      "total_loss": 0.4655503034591675
    },
    {
      "classification_loss": 0.5330281257629395,
      "epoch": 10.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3328,
      "total_loss": 0.5330281257629395
    },
    {
      "classification_loss": 0.573670506477356,
      "epoch": 10.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3329,
      "total_loss": 0.573670506477356
    },
    {
      "classification_loss": 0.5435936450958252,
      "epoch": 10.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3330,
      "total_loss": 0.5435936450958252
    },
    {
      "classification_loss": 0.4780236780643463,
      "epoch": 10.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3331,
      "total_loss": 0.4780236780643463
    },
    {
      "classification_loss": 0.540805995464325,
      "epoch": 10.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3332,
      "total_loss": 0.540805995464325
    },
    {
      "classification_loss": 0.5554242730140686,
      "epoch": 10.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3333,
      "total_loss": 0.5554242730140686
    },
    {
      "classification_loss": 0.446575403213501,
      "epoch": 10.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3334,
      "total_loss": 0.446575403213501
    },
    {
      "classification_loss": 0.5110572576522827,
      "epoch": 10.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3335,
      "total_loss": 0.5110572576522827
    },
    {
      "classification_loss": 0.5316653847694397,
      "epoch": 10.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3336,
      "total_loss": 0.5316653847694397
    },
    {
      "classification_loss": 0.5000712275505066,
      "epoch": 10.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3337,
      "total_loss": 0.5000712275505066
    },
    {
      "classification_loss": 0.5142024755477905,
      "epoch": 10.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3338,
      "total_loss": 0.5142024755477905
    },
    {
      "classification_loss": 0.6297337412834167,
      "epoch": 10.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3339,
      "total_loss": 0.6297337412834167
    },
    {
      "classification_loss": 0.5333670377731323,
      "epoch": 10.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3340,
      "total_loss": 0.5333670377731323
    },
    {
      "classification_loss": 0.4879244565963745,
      "epoch": 10.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3341,
      "total_loss": 0.4879244565963745
    },
    {
      "classification_loss": 0.5588049292564392,
      "epoch": 10.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3342,
      "total_loss": 0.5588049292564392
    },
    {
      "classification_loss": 0.5633084774017334,
      "epoch": 10.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3343,
      "total_loss": 0.5633084774017334
    },
    {
      "classification_loss": 0.48823174834251404,
      "epoch": 10.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3344,
      "total_loss": 0.48823174834251404
    },
    {
      "classification_loss": 0.6322342753410339,
      "epoch": 10.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3345,
      "total_loss": 0.6322342753410339
    },
    {
      "classification_loss": 0.5160883069038391,
      "epoch": 10.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3346,
      "total_loss": 0.5160883069038391
    },
    {
      "classification_loss": 0.4771488904953003,
      "epoch": 10.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3347,
      "total_loss": 0.4771488904953003
    },
    {
      "classification_loss": 0.7238430380821228,
      "epoch": 10.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3348,
      "total_loss": 0.7238430380821228
    },
    {
      "classification_loss": 0.5841585397720337,
      "epoch": 10.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3349,
      "total_loss": 0.5841585397720337
    },
    {
      "classification_loss": 0.6437661051750183,
      "epoch": 10.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3350,
      "total_loss": 0.6437661051750183
    },
    {
      "classification_loss": 0.4608781635761261,
      "epoch": 10.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3351,
      "total_loss": 0.4608781635761261
    },
    {
      "classification_loss": 0.5453946590423584,
      "epoch": 10.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3352,
      "total_loss": 0.5453946590423584
    },
    {
      "classification_loss": 0.4694192111492157,
      "epoch": 10.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3353,
      "total_loss": 0.4694192111492157
    },
    {
      "classification_loss": 0.3717816472053528,
      "epoch": 10.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3354,
      "total_loss": 0.3717816472053528
    },
    {
      "classification_loss": 1.3901783227920532,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.3901783227920532
    },
    {
      "classification_loss": 1.336917519569397,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.336917519569397
    },
    {
      "classification_loss": 1.2451521158218384,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.2451521158218384
    },
    {
      "classification_loss": 1.5174601078033447,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.5174601078033447
    },
    {
      "classification_loss": 1.258068323135376,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.258068323135376
    },
    {
      "classification_loss": 1.2300138473510742,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.2300138473510742
    },
    {
      "classification_loss": 1.3122013807296753,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.3122013807296753
    },
    {
      "classification_loss": 1.1276739835739136,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 1.1276739835739136
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.3063970804214478,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.1009,
      "eval_samples_per_second": 163.91,
      "eval_steps_per_second": 1.311,
      "step": 3355
    },
    {
      "classification_loss": 0.654751181602478,
      "epoch": 11.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3355,
      "total_loss": 0.654751181602478
    },
    {
      "classification_loss": 0.505094587802887,
      "epoch": 11.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3356,
      "total_loss": 0.505094587802887
    },
    {
      "classification_loss": 0.5691789984703064,
      "epoch": 11.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3357,
      "total_loss": 0.5691789984703064
    },
    {
      "classification_loss": 0.6136031746864319,
      "epoch": 11.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3358,
      "total_loss": 0.6136031746864319
    },
    {
      "classification_loss": 0.4447278380393982,
      "epoch": 11.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3359,
      "total_loss": 0.4447278380393982
    },
    {
      "classification_loss": 0.5764855146408081,
      "epoch": 11.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3360,
      "total_loss": 0.5764855146408081
    },
    {
      "classification_loss": 0.5106446146965027,
      "epoch": 11.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3361,
      "total_loss": 0.5106446146965027
    },
    {
      "classification_loss": 0.5840457677841187,
      "epoch": 11.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3362,
      "total_loss": 0.5840457677841187
    },
    {
      "classification_loss": 0.5498422384262085,
      "epoch": 11.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3363,
      "total_loss": 0.5498422384262085
    },
    {
      "classification_loss": 0.44675418734550476,
      "epoch": 11.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3364,
      "total_loss": 0.44675418734550476
    },
    {
      "classification_loss": 0.45955491065979004,
      "epoch": 11.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3365,
      "total_loss": 0.45955491065979004
    },
    {
      "classification_loss": 0.492186039686203,
      "epoch": 11.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3366,
      "total_loss": 0.492186039686203
    },
    {
      "classification_loss": 0.5799483060836792,
      "epoch": 11.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3367,
      "total_loss": 0.5799483060836792
    },
    {
      "classification_loss": 0.5754382014274597,
      "epoch": 11.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3368,
      "total_loss": 0.5754382014274597
    },
    {
      "classification_loss": 0.6577573418617249,
      "epoch": 11.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3369,
      "total_loss": 0.6577573418617249
    },
    {
      "classification_loss": 0.4367808699607849,
      "epoch": 11.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3370,
      "total_loss": 0.4367808699607849
    },
    {
      "classification_loss": 0.5366358160972595,
      "epoch": 11.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3371,
      "total_loss": 0.5366358160972595
    },
    {
      "classification_loss": 0.48315346240997314,
      "epoch": 11.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3372,
      "total_loss": 0.48315346240997314
    },
    {
      "classification_loss": 0.5131757855415344,
      "epoch": 11.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3373,
      "total_loss": 0.5131757855415344
    },
    {
      "classification_loss": 0.5160472989082336,
      "epoch": 11.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3374,
      "total_loss": 0.5160472989082336
    },
    {
      "classification_loss": 0.6033745408058167,
      "epoch": 11.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3375,
      "total_loss": 0.6033745408058167
    },
    {
      "classification_loss": 0.6016981601715088,
      "epoch": 11.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3376,
      "total_loss": 0.6016981601715088
    },
    {
      "classification_loss": 0.46739667654037476,
      "epoch": 11.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3377,
      "total_loss": 0.46739667654037476
    },
    {
      "classification_loss": 0.4718925654888153,
      "epoch": 11.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3378,
      "total_loss": 0.4718925654888153
    },
    {
      "classification_loss": 0.6550418734550476,
      "epoch": 11.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3379,
      "total_loss": 0.6550418734550476
    },
    {
      "classification_loss": 0.5299564003944397,
      "epoch": 11.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3380,
      "total_loss": 0.5299564003944397
    },
    {
      "classification_loss": 0.4812183678150177,
      "epoch": 11.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3381,
      "total_loss": 0.4812183678150177
    },
    {
      "classification_loss": 0.5889936089515686,
      "epoch": 11.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3382,
      "total_loss": 0.5889936089515686
    },
    {
      "classification_loss": 0.4524674117565155,
      "epoch": 11.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3383,
      "total_loss": 0.4524674117565155
    },
    {
      "classification_loss": 0.47881293296813965,
      "epoch": 11.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3384,
      "total_loss": 0.47881293296813965
    },
    {
      "classification_loss": 0.5610412359237671,
      "epoch": 11.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3385,
      "total_loss": 0.5610412359237671
    },
    {
      "classification_loss": 0.5381697416305542,
      "epoch": 11.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3386,
      "total_loss": 0.5381697416305542
    },
    {
      "classification_loss": 0.44715598225593567,
      "epoch": 11.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3387,
      "total_loss": 0.44715598225593567
    },
    {
      "classification_loss": 0.4418672025203705,
      "epoch": 11.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3388,
      "total_loss": 0.4418672025203705
    },
    {
      "classification_loss": 0.48757636547088623,
      "epoch": 11.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3389,
      "total_loss": 0.48757636547088623
    },
    {
      "classification_loss": 0.5047896504402161,
      "epoch": 11.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3390,
      "total_loss": 0.5047896504402161
    },
    {
      "classification_loss": 0.6140788197517395,
      "epoch": 11.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3391,
      "total_loss": 0.6140788197517395
    },
    {
      "classification_loss": 0.5721727609634399,
      "epoch": 11.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3392,
      "total_loss": 0.5721727609634399
    },
    {
      "classification_loss": 0.4958856999874115,
      "epoch": 11.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3393,
      "total_loss": 0.4958856999874115
    },
    {
      "classification_loss": 0.6135939955711365,
      "epoch": 11.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3394,
      "total_loss": 0.6135939955711365
    },
    {
      "classification_loss": 0.4624774754047394,
      "epoch": 11.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3395,
      "total_loss": 0.4624774754047394
    },
    {
      "classification_loss": 0.4457404911518097,
      "epoch": 11.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3396,
      "total_loss": 0.4457404911518097
    },
    {
      "classification_loss": 0.5184400677680969,
      "epoch": 11.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3397,
      "total_loss": 0.5184400677680969
    },
    {
      "classification_loss": 0.5053041577339172,
      "epoch": 11.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3398,
      "total_loss": 0.5053041577339172
    },
    {
      "classification_loss": 0.4725807309150696,
      "epoch": 11.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3399,
      "total_loss": 0.4725807309150696
    },
    {
      "epoch": 11.147540983606557,
      "grad_norm": 3.807875871658325,
      "learning_rate": 9.003333333333333e-05,
      "loss": 0.5309,
      "step": 3400
    },
    {
      "classification_loss": 0.546812117099762,
      "epoch": 11.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3400,
      "total_loss": 0.546812117099762
    },
    {
      "classification_loss": 0.4389881491661072,
      "epoch": 11.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3401,
      "total_loss": 0.4389881491661072
    },
    {
      "classification_loss": 0.5011883974075317,
      "epoch": 11.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3402,
      "total_loss": 0.5011883974075317
    },
    {
      "classification_loss": 0.5256667137145996,
      "epoch": 11.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3403,
      "total_loss": 0.5256667137145996
    },
    {
      "classification_loss": 0.5019293427467346,
      "epoch": 11.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3404,
      "total_loss": 0.5019293427467346
    },
    {
      "classification_loss": 0.5469171404838562,
      "epoch": 11.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3405,
      "total_loss": 0.5469171404838562
    },
    {
      "classification_loss": 0.5799971222877502,
      "epoch": 11.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3406,
      "total_loss": 0.5799971222877502
    },
    {
      "classification_loss": 0.5865099430084229,
      "epoch": 11.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3407,
      "total_loss": 0.5865099430084229
    },
    {
      "classification_loss": 0.49061161279678345,
      "epoch": 11.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3408,
      "total_loss": 0.49061161279678345
    },
    {
      "classification_loss": 0.4893561899662018,
      "epoch": 11.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3409,
      "total_loss": 0.4893561899662018
    },
    {
      "classification_loss": 0.5822404623031616,
      "epoch": 11.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3410,
      "total_loss": 0.5822404623031616
    },
    {
      "classification_loss": 0.5191117525100708,
      "epoch": 11.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3411,
      "total_loss": 0.5191117525100708
    },
    {
      "classification_loss": 0.49602460861206055,
      "epoch": 11.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3412,
      "total_loss": 0.49602460861206055
    },
    {
      "classification_loss": 0.5221657752990723,
      "epoch": 11.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3413,
      "total_loss": 0.5221657752990723
    },
    {
      "classification_loss": 0.47209498286247253,
      "epoch": 11.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3414,
      "total_loss": 0.47209498286247253
    },
    {
      "classification_loss": 0.4966249167919159,
      "epoch": 11.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3415,
      "total_loss": 0.4966249167919159
    },
    {
      "classification_loss": 0.5168919563293457,
      "epoch": 11.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3416,
      "total_loss": 0.5168919563293457
    },
    {
      "classification_loss": 0.3744823932647705,
      "epoch": 11.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3417,
      "total_loss": 0.3744823932647705
    },
    {
      "classification_loss": 0.5246391296386719,
      "epoch": 11.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3418,
      "total_loss": 0.5246391296386719
    },
    {
      "classification_loss": 0.4351333975791931,
      "epoch": 11.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3419,
      "total_loss": 0.4351333975791931
    },
    {
      "classification_loss": 0.5636444687843323,
      "epoch": 11.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3420,
      "total_loss": 0.5636444687843323
    },
    {
      "classification_loss": 0.49111881852149963,
      "epoch": 11.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3421,
      "total_loss": 0.49111881852149963
    },
    {
      "classification_loss": 0.427394300699234,
      "epoch": 11.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3422,
      "total_loss": 0.427394300699234
    },
    {
      "classification_loss": 0.5500521063804626,
      "epoch": 11.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3423,
      "total_loss": 0.5500521063804626
    },
    {
      "classification_loss": 0.5351814031600952,
      "epoch": 11.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3424,
      "total_loss": 0.5351814031600952
    },
    {
      "classification_loss": 0.5059558153152466,
      "epoch": 11.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3425,
      "total_loss": 0.5059558153152466
    },
    {
      "classification_loss": 0.4771519899368286,
      "epoch": 11.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3426,
      "total_loss": 0.4771519899368286
    },
    {
      "classification_loss": 0.6271514892578125,
      "epoch": 11.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3427,
      "total_loss": 0.6271514892578125
    },
    {
      "classification_loss": 0.45588231086730957,
      "epoch": 11.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3428,
      "total_loss": 0.45588231086730957
    },
    {
      "classification_loss": 0.5238447785377502,
      "epoch": 11.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3429,
      "total_loss": 0.5238447785377502
    },
    {
      "classification_loss": 0.5761480927467346,
      "epoch": 11.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3430,
      "total_loss": 0.5761480927467346
    },
    {
      "classification_loss": 0.4190768599510193,
      "epoch": 11.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3431,
      "total_loss": 0.4190768599510193
    },
    {
      "classification_loss": 0.47920453548431396,
      "epoch": 11.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3432,
      "total_loss": 0.47920453548431396
    },
    {
      "classification_loss": 0.4950348138809204,
      "epoch": 11.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3433,
      "total_loss": 0.4950348138809204
    },
    {
      "classification_loss": 0.5445258617401123,
      "epoch": 11.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3434,
      "total_loss": 0.5445258617401123
    },
    {
      "classification_loss": 0.5504898428916931,
      "epoch": 11.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3435,
      "total_loss": 0.5504898428916931
    },
    {
      "classification_loss": 0.5737035870552063,
      "epoch": 11.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3436,
      "total_loss": 0.5737035870552063
    },
    {
      "classification_loss": 0.43797174096107483,
      "epoch": 11.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3437,
      "total_loss": 0.43797174096107483
    },
    {
      "classification_loss": 0.6034064292907715,
      "epoch": 11.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3438,
      "total_loss": 0.6034064292907715
    },
    {
      "classification_loss": 0.5787467956542969,
      "epoch": 11.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3439,
      "total_loss": 0.5787467956542969
    },
    {
      "classification_loss": 0.544396162033081,
      "epoch": 11.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3440,
      "total_loss": 0.544396162033081
    },
    {
      "classification_loss": 0.4757559895515442,
      "epoch": 11.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3441,
      "total_loss": 0.4757559895515442
    },
    {
      "classification_loss": 0.5523852705955505,
      "epoch": 11.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3442,
      "total_loss": 0.5523852705955505
    },
    {
      "classification_loss": 0.6080646514892578,
      "epoch": 11.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3443,
      "total_loss": 0.6080646514892578
    },
    {
      "classification_loss": 0.4914720952510834,
      "epoch": 11.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3444,
      "total_loss": 0.4914720952510834
    },
    {
      "classification_loss": 0.4597235918045044,
      "epoch": 11.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3445,
      "total_loss": 0.4597235918045044
    },
    {
      "classification_loss": 0.40229129791259766,
      "epoch": 11.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3446,
      "total_loss": 0.40229129791259766
    },
    {
      "classification_loss": 0.5474204421043396,
      "epoch": 11.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3447,
      "total_loss": 0.5474204421043396
    },
    {
      "classification_loss": 0.4924682378768921,
      "epoch": 11.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3448,
      "total_loss": 0.4924682378768921
    },
    {
      "classification_loss": 0.6043768525123596,
      "epoch": 11.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3449,
      "total_loss": 0.6043768525123596
    },
    {
      "classification_loss": 0.40631332993507385,
      "epoch": 11.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3450,
      "total_loss": 0.40631332993507385
    },
    {
      "classification_loss": 0.4686659872531891,
      "epoch": 11.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3451,
      "total_loss": 0.4686659872531891
    },
    {
      "classification_loss": 0.5152181386947632,
      "epoch": 11.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3452,
      "total_loss": 0.5152181386947632
    },
    {
      "classification_loss": 0.4990590214729309,
      "epoch": 11.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3453,
      "total_loss": 0.4990590214729309
    },
    {
      "classification_loss": 0.4332149624824524,
      "epoch": 11.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3454,
      "total_loss": 0.4332149624824524
    },
    {
      "classification_loss": 0.42731475830078125,
      "epoch": 11.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3455,
      "total_loss": 0.42731475830078125
    },
    {
      "classification_loss": 0.6299895644187927,
      "epoch": 11.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3456,
      "total_loss": 0.6299895644187927
    },
    {
      "classification_loss": 0.6221224069595337,
      "epoch": 11.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3457,
      "total_loss": 0.6221224069595337
    },
    {
      "classification_loss": 0.4815097749233246,
      "epoch": 11.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3458,
      "total_loss": 0.4815097749233246
    },
    {
      "classification_loss": 0.4961635172367096,
      "epoch": 11.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3459,
      "total_loss": 0.4961635172367096
    },
    {
      "classification_loss": 0.5661773681640625,
      "epoch": 11.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3460,
      "total_loss": 0.5661773681640625
    },
    {
      "classification_loss": 0.6249797940254211,
      "epoch": 11.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3461,
      "total_loss": 0.6249797940254211
    },
    {
      "classification_loss": 0.5446173548698425,
      "epoch": 11.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3462,
      "total_loss": 0.5446173548698425
    },
    {
      "classification_loss": 0.5078389048576355,
      "epoch": 11.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3463,
      "total_loss": 0.5078389048576355
    },
    {
      "classification_loss": 0.5618076920509338,
      "epoch": 11.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3464,
      "total_loss": 0.5618076920509338
    },
    {
      "classification_loss": 0.5440830588340759,
      "epoch": 11.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3465,
      "total_loss": 0.5440830588340759
    },
    {
      "classification_loss": 0.5238789319992065,
      "epoch": 11.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3466,
      "total_loss": 0.5238789319992065
    },
    {
      "classification_loss": 0.5351424217224121,
      "epoch": 11.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3467,
      "total_loss": 0.5351424217224121
    },
    {
      "classification_loss": 0.49842703342437744,
      "epoch": 11.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3468,
      "total_loss": 0.49842703342437744
    },
    {
      "classification_loss": 0.5380966663360596,
      "epoch": 11.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3469,
      "total_loss": 0.5380966663360596
    },
    {
      "classification_loss": 0.5856225490570068,
      "epoch": 11.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3470,
      "total_loss": 0.5856225490570068
    },
    {
      "classification_loss": 0.5980781316757202,
      "epoch": 11.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3471,
      "total_loss": 0.5980781316757202
    },
    {
      "classification_loss": 0.5544828772544861,
      "epoch": 11.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3472,
      "total_loss": 0.5544828772544861
    },
    {
      "classification_loss": 0.5650336146354675,
      "epoch": 11.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3473,
      "total_loss": 0.5650336146354675
    },
    {
      "classification_loss": 0.4995613992214203,
      "epoch": 11.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3474,
      "total_loss": 0.4995613992214203
    },
    {
      "classification_loss": 0.5340366959571838,
      "epoch": 11.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3475,
      "total_loss": 0.5340366959571838
    },
    {
      "classification_loss": 0.5075204372406006,
      "epoch": 11.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3476,
      "total_loss": 0.5075204372406006
    },
    {
      "classification_loss": 0.4868507981300354,
      "epoch": 11.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3477,
      "total_loss": 0.4868507981300354
    },
    {
      "classification_loss": 0.5116320252418518,
      "epoch": 11.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3478,
      "total_loss": 0.5116320252418518
    },
    {
      "classification_loss": 0.4651239514350891,
      "epoch": 11.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3479,
      "total_loss": 0.4651239514350891
    },
    {
      "classification_loss": 0.4478665292263031,
      "epoch": 11.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3480,
      "total_loss": 0.4478665292263031
    },
    {
      "classification_loss": 0.5055918097496033,
      "epoch": 11.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3481,
      "total_loss": 0.5055918097496033
    },
    {
      "classification_loss": 0.6385985016822815,
      "epoch": 11.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3482,
      "total_loss": 0.6385985016822815
    },
    {
      "classification_loss": 0.4816756248474121,
      "epoch": 11.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3483,
      "total_loss": 0.4816756248474121
    },
    {
      "classification_loss": 0.47685810923576355,
      "epoch": 11.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3484,
      "total_loss": 0.47685810923576355
    },
    {
      "classification_loss": 0.49225494265556335,
      "epoch": 11.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3485,
      "total_loss": 0.49225494265556335
    },
    {
      "classification_loss": 0.5075005888938904,
      "epoch": 11.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3486,
      "total_loss": 0.5075005888938904
    },
    {
      "classification_loss": 0.6011018753051758,
      "epoch": 11.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3487,
      "total_loss": 0.6011018753051758
    },
    {
      "classification_loss": 0.47430601716041565,
      "epoch": 11.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3488,
      "total_loss": 0.47430601716041565
    },
    {
      "classification_loss": 0.5405604839324951,
      "epoch": 11.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3489,
      "total_loss": 0.5405604839324951
    },
    {
      "classification_loss": 0.469714879989624,
      "epoch": 11.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3490,
      "total_loss": 0.469714879989624
    },
    {
      "classification_loss": 0.5783681869506836,
      "epoch": 11.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3491,
      "total_loss": 0.5783681869506836
    },
    {
      "classification_loss": 0.40501999855041504,
      "epoch": 11.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3492,
      "total_loss": 0.40501999855041504
    },
    {
      "classification_loss": 0.5368857383728027,
      "epoch": 11.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3493,
      "total_loss": 0.5368857383728027
    },
    {
      "classification_loss": 0.5197435617446899,
      "epoch": 11.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3494,
      "total_loss": 0.5197435617446899
    },
    {
      "classification_loss": 0.5441873669624329,
      "epoch": 11.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3495,
      "total_loss": 0.5441873669624329
    },
    {
      "classification_loss": 0.532417356967926,
      "epoch": 11.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3496,
      "total_loss": 0.532417356967926
    },
    {
      "classification_loss": 0.5145276784896851,
      "epoch": 11.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3497,
      "total_loss": 0.5145276784896851
    },
    {
      "classification_loss": 0.5010762810707092,
      "epoch": 11.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3498,
      "total_loss": 0.5010762810707092
    },
    {
      "classification_loss": 0.5499690771102905,
      "epoch": 11.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3499,
      "total_loss": 0.5499690771102905
    },
    {
      "epoch": 11.475409836065573,
      "grad_norm": 10.965052604675293,
      "learning_rate": 8.67e-05,
      "loss": 0.5179,
      "step": 3500
    },
    {
      "classification_loss": 0.4155350923538208,
      "epoch": 11.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3500,
      "total_loss": 0.4155350923538208
    },
    {
      "classification_loss": 0.558325469493866,
      "epoch": 11.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3501,
      "total_loss": 0.558325469493866
    },
    {
      "classification_loss": 0.5283980965614319,
      "epoch": 11.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3502,
      "total_loss": 0.5283980965614319
    },
    {
      "classification_loss": 0.4499737322330475,
      "epoch": 11.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3503,
      "total_loss": 0.4499737322330475
    },
    {
      "classification_loss": 0.4366765320301056,
      "epoch": 11.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3504,
      "total_loss": 0.4366765320301056
    },
    {
      "classification_loss": 0.5836792588233948,
      "epoch": 11.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3505,
      "total_loss": 0.5836792588233948
    },
    {
      "classification_loss": 0.5785377025604248,
      "epoch": 11.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3506,
      "total_loss": 0.5785377025604248
    },
    {
      "classification_loss": 0.5148053169250488,
      "epoch": 11.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3507,
      "total_loss": 0.5148053169250488
    },
    {
      "classification_loss": 0.43743160367012024,
      "epoch": 11.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3508,
      "total_loss": 0.43743160367012024
    },
    {
      "classification_loss": 0.46546855568885803,
      "epoch": 11.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3509,
      "total_loss": 0.46546855568885803
    },
    {
      "classification_loss": 0.5292288661003113,
      "epoch": 11.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3510,
      "total_loss": 0.5292288661003113
    },
    {
      "classification_loss": 0.525631308555603,
      "epoch": 11.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3511,
      "total_loss": 0.525631308555603
    },
    {
      "classification_loss": 0.529913067817688,
      "epoch": 11.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3512,
      "total_loss": 0.529913067817688
    },
    {
      "classification_loss": 0.49617666006088257,
      "epoch": 11.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3513,
      "total_loss": 0.49617666006088257
    },
    {
      "classification_loss": 0.6692146062850952,
      "epoch": 11.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3514,
      "total_loss": 0.6692146062850952
    },
    {
      "classification_loss": 0.5527485609054565,
      "epoch": 11.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3515,
      "total_loss": 0.5527485609054565
    },
    {
      "classification_loss": 0.5140305161476135,
      "epoch": 11.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3516,
      "total_loss": 0.5140305161476135
    },
    {
      "classification_loss": 0.466027170419693,
      "epoch": 11.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3517,
      "total_loss": 0.466027170419693
    },
    {
      "classification_loss": 0.5357466340065002,
      "epoch": 11.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3518,
      "total_loss": 0.5357466340065002
    },
    {
      "classification_loss": 0.5286053419113159,
      "epoch": 11.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3519,
      "total_loss": 0.5286053419113159
    },
    {
      "classification_loss": 0.46724191308021545,
      "epoch": 11.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3520,
      "total_loss": 0.46724191308021545
    },
    {
      "classification_loss": 0.46017101407051086,
      "epoch": 11.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3521,
      "total_loss": 0.46017101407051086
    },
    {
      "classification_loss": 0.4976899027824402,
      "epoch": 11.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3522,
      "total_loss": 0.4976899027824402
    },
    {
      "classification_loss": 0.5077558159828186,
      "epoch": 11.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3523,
      "total_loss": 0.5077558159828186
    },
    {
      "classification_loss": 0.5703049302101135,
      "epoch": 11.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3524,
      "total_loss": 0.5703049302101135
    },
    {
      "classification_loss": 0.4787542223930359,
      "epoch": 11.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3525,
      "total_loss": 0.4787542223930359
    },
    {
      "classification_loss": 0.5802005529403687,
      "epoch": 11.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3526,
      "total_loss": 0.5802005529403687
    },
    {
      "classification_loss": 0.5753827691078186,
      "epoch": 11.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3527,
      "total_loss": 0.5753827691078186
    },
    {
      "classification_loss": 0.5400807857513428,
      "epoch": 11.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3528,
      "total_loss": 0.5400807857513428
    },
    {
      "classification_loss": 0.5405388474464417,
      "epoch": 11.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3529,
      "total_loss": 0.5405388474464417
    },
    {
      "classification_loss": 0.5494630336761475,
      "epoch": 11.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3530,
      "total_loss": 0.5494630336761475
    },
    {
      "classification_loss": 0.5293156504631042,
      "epoch": 11.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3531,
      "total_loss": 0.5293156504631042
    },
    {
      "classification_loss": 0.46087712049484253,
      "epoch": 11.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3532,
      "total_loss": 0.46087712049484253
    },
    {
      "classification_loss": 0.43772590160369873,
      "epoch": 11.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3533,
      "total_loss": 0.43772590160369873
    },
    {
      "classification_loss": 0.5617334842681885,
      "epoch": 11.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3534,
      "total_loss": 0.5617334842681885
    },
    {
      "classification_loss": 0.5805970430374146,
      "epoch": 11.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3535,
      "total_loss": 0.5805970430374146
    },
    {
      "classification_loss": 0.5793629288673401,
      "epoch": 11.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3536,
      "total_loss": 0.5793629288673401
    },
    {
      "classification_loss": 0.4923422336578369,
      "epoch": 11.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3537,
      "total_loss": 0.4923422336578369
    },
    {
      "classification_loss": 0.6151841878890991,
      "epoch": 11.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3538,
      "total_loss": 0.6151841878890991
    },
    {
      "classification_loss": 0.5540061593055725,
      "epoch": 11.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3539,
      "total_loss": 0.5540061593055725
    },
    {
      "classification_loss": 0.533654510974884,
      "epoch": 11.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3540,
      "total_loss": 0.533654510974884
    },
    {
      "classification_loss": 0.6542882919311523,
      "epoch": 11.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3541,
      "total_loss": 0.6542882919311523
    },
    {
      "classification_loss": 0.41440173983573914,
      "epoch": 11.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3542,
      "total_loss": 0.41440173983573914
    },
    {
      "classification_loss": 0.5556746125221252,
      "epoch": 11.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3543,
      "total_loss": 0.5556746125221252
    },
    {
      "classification_loss": 0.6281255483627319,
      "epoch": 11.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3544,
      "total_loss": 0.6281255483627319
    },
    {
      "classification_loss": 0.39866316318511963,
      "epoch": 11.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3545,
      "total_loss": 0.39866316318511963
    },
    {
      "classification_loss": 0.5747032165527344,
      "epoch": 11.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3546,
      "total_loss": 0.5747032165527344
    },
    {
      "classification_loss": 0.6294774413108826,
      "epoch": 11.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3547,
      "total_loss": 0.6294774413108826
    },
    {
      "classification_loss": 0.5788281559944153,
      "epoch": 11.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3548,
      "total_loss": 0.5788281559944153
    },
    {
      "classification_loss": 0.673770010471344,
      "epoch": 11.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3549,
      "total_loss": 0.673770010471344
    },
    {
      "classification_loss": 0.5738404393196106,
      "epoch": 11.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3550,
      "total_loss": 0.5738404393196106
    },
    {
      "classification_loss": 0.4654189944267273,
      "epoch": 11.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3551,
      "total_loss": 0.4654189944267273
    },
    {
      "classification_loss": 0.6284212470054626,
      "epoch": 11.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3552,
      "total_loss": 0.6284212470054626
    },
    {
      "classification_loss": 0.5869506597518921,
      "epoch": 11.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3553,
      "total_loss": 0.5869506597518921
    },
    {
      "classification_loss": 0.5122547745704651,
      "epoch": 11.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3554,
      "total_loss": 0.5122547745704651
    },
    {
      "classification_loss": 0.4967614710330963,
      "epoch": 11.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3555,
      "total_loss": 0.4967614710330963
    },
    {
      "classification_loss": 0.5160235166549683,
      "epoch": 11.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3556,
      "total_loss": 0.5160235166549683
    },
    {
      "classification_loss": 0.5747277140617371,
      "epoch": 11.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3557,
      "total_loss": 0.5747277140617371
    },
    {
      "classification_loss": 0.44082483649253845,
      "epoch": 11.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3558,
      "total_loss": 0.44082483649253845
    },
    {
      "classification_loss": 0.47091901302337646,
      "epoch": 11.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3559,
      "total_loss": 0.47091901302337646
    },
    {
      "classification_loss": 0.47003719210624695,
      "epoch": 11.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3560,
      "total_loss": 0.47003719210624695
    },
    {
      "classification_loss": 0.5489908456802368,
      "epoch": 11.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3561,
      "total_loss": 0.5489908456802368
    },
    {
      "classification_loss": 0.5663037300109863,
      "epoch": 11.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3562,
      "total_loss": 0.5663037300109863
    },
    {
      "classification_loss": 0.5855233073234558,
      "epoch": 11.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3563,
      "total_loss": 0.5855233073234558
    },
    {
      "classification_loss": 0.5502440929412842,
      "epoch": 11.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3564,
      "total_loss": 0.5502440929412842
    },
    {
      "classification_loss": 0.5086163282394409,
      "epoch": 11.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3565,
      "total_loss": 0.5086163282394409
    },
    {
      "classification_loss": 0.5506377816200256,
      "epoch": 11.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3566,
      "total_loss": 0.5506377816200256
    },
    {
      "classification_loss": 0.48998191952705383,
      "epoch": 11.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3567,
      "total_loss": 0.48998191952705383
    },
    {
      "classification_loss": 0.5296469330787659,
      "epoch": 11.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3568,
      "total_loss": 0.5296469330787659
    },
    {
      "classification_loss": 0.556885838508606,
      "epoch": 11.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3569,
      "total_loss": 0.556885838508606
    },
    {
      "classification_loss": 0.48804718255996704,
      "epoch": 11.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3570,
      "total_loss": 0.48804718255996704
    },
    {
      "classification_loss": 0.4774549603462219,
      "epoch": 11.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3571,
      "total_loss": 0.4774549603462219
    },
    {
      "classification_loss": 0.49375155568122864,
      "epoch": 11.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3572,
      "total_loss": 0.49375155568122864
    },
    {
      "classification_loss": 0.39521366357803345,
      "epoch": 11.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3573,
      "total_loss": 0.39521366357803345
    },
    {
      "classification_loss": 0.572236955165863,
      "epoch": 11.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3574,
      "total_loss": 0.572236955165863
    },
    {
      "classification_loss": 0.4798475503921509,
      "epoch": 11.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3575,
      "total_loss": 0.4798475503921509
    },
    {
      "classification_loss": 0.4636564254760742,
      "epoch": 11.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3576,
      "total_loss": 0.4636564254760742
    },
    {
      "classification_loss": 0.4566679894924164,
      "epoch": 11.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3577,
      "total_loss": 0.4566679894924164
    },
    {
      "classification_loss": 0.4267556071281433,
      "epoch": 11.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3578,
      "total_loss": 0.4267556071281433
    },
    {
      "classification_loss": 0.46664002537727356,
      "epoch": 11.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3579,
      "total_loss": 0.46664002537727356
    },
    {
      "classification_loss": 0.6829304695129395,
      "epoch": 11.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3580,
      "total_loss": 0.6829304695129395
    },
    {
      "classification_loss": 0.5545834898948669,
      "epoch": 11.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3581,
      "total_loss": 0.5545834898948669
    },
    {
      "classification_loss": 0.5332854390144348,
      "epoch": 11.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3582,
      "total_loss": 0.5332854390144348
    },
    {
      "classification_loss": 0.5257386565208435,
      "epoch": 11.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3583,
      "total_loss": 0.5257386565208435
    },
    {
      "classification_loss": 0.5390626788139343,
      "epoch": 11.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3584,
      "total_loss": 0.5390626788139343
    },
    {
      "classification_loss": 0.631712019443512,
      "epoch": 11.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3585,
      "total_loss": 0.631712019443512
    },
    {
      "classification_loss": 0.417496919631958,
      "epoch": 11.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3586,
      "total_loss": 0.417496919631958
    },
    {
      "classification_loss": 0.6753613352775574,
      "epoch": 11.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3587,
      "total_loss": 0.6753613352775574
    },
    {
      "classification_loss": 0.5670234560966492,
      "epoch": 11.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3588,
      "total_loss": 0.5670234560966492
    },
    {
      "classification_loss": 0.4972529411315918,
      "epoch": 11.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3589,
      "total_loss": 0.4972529411315918
    },
    {
      "classification_loss": 0.5973869562149048,
      "epoch": 11.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3590,
      "total_loss": 0.5973869562149048
    },
    {
      "classification_loss": 0.4764882028102875,
      "epoch": 11.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3591,
      "total_loss": 0.4764882028102875
    },
    {
      "classification_loss": 0.4724501967430115,
      "epoch": 11.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3592,
      "total_loss": 0.4724501967430115
    },
    {
      "classification_loss": 0.626560628414154,
      "epoch": 11.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3593,
      "total_loss": 0.626560628414154
    },
    {
      "classification_loss": 0.4388572573661804,
      "epoch": 11.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3594,
      "total_loss": 0.4388572573661804
    },
    {
      "classification_loss": 0.5242199301719666,
      "epoch": 11.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3595,
      "total_loss": 0.5242199301719666
    },
    {
      "classification_loss": 0.4323151707649231,
      "epoch": 11.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3596,
      "total_loss": 0.4323151707649231
    },
    {
      "classification_loss": 0.483235239982605,
      "epoch": 11.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3597,
      "total_loss": 0.483235239982605
    },
    {
      "classification_loss": 0.5967265367507935,
      "epoch": 11.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3598,
      "total_loss": 0.5967265367507935
    },
    {
      "classification_loss": 0.6105524897575378,
      "epoch": 11.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3599,
      "total_loss": 0.6105524897575378
    },
    {
      "epoch": 11.80327868852459,
      "grad_norm": 8.289998054504395,
      "learning_rate": 8.336666666666667e-05,
      "loss": 0.5276,
      "step": 3600
    },
    {
      "classification_loss": 0.45877325534820557,
      "epoch": 11.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3600,
      "total_loss": 0.45877325534820557
    },
    {
      "classification_loss": 0.44443774223327637,
      "epoch": 11.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3601,
      "total_loss": 0.44443774223327637
    },
    {
      "classification_loss": 0.5699129700660706,
      "epoch": 11.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3602,
      "total_loss": 0.5699129700660706
    },
    {
      "classification_loss": 0.5327812433242798,
      "epoch": 11.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3603,
      "total_loss": 0.5327812433242798
    },
    {
      "classification_loss": 0.5341499447822571,
      "epoch": 11.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3604,
      "total_loss": 0.5341499447822571
    },
    {
      "classification_loss": 0.5878030061721802,
      "epoch": 11.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3605,
      "total_loss": 0.5878030061721802
    },
    {
      "classification_loss": 0.33346498012542725,
      "epoch": 11.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3606,
      "total_loss": 0.33346498012542725
    },
    {
      "classification_loss": 0.5246413946151733,
      "epoch": 11.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3607,
      "total_loss": 0.5246413946151733
    },
    {
      "classification_loss": 0.6057416796684265,
      "epoch": 11.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3608,
      "total_loss": 0.6057416796684265
    },
    {
      "classification_loss": 0.6283618807792664,
      "epoch": 11.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3609,
      "total_loss": 0.6283618807792664
    },
    {
      "classification_loss": 0.62630295753479,
      "epoch": 11.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3610,
      "total_loss": 0.62630295753479
    },
    {
      "classification_loss": 0.4021734297275543,
      "epoch": 11.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3611,
      "total_loss": 0.4021734297275543
    },
    {
      "classification_loss": 0.383846640586853,
      "epoch": 11.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3612,
      "total_loss": 0.383846640586853
    },
    {
      "classification_loss": 0.6014724373817444,
      "epoch": 11.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3613,
      "total_loss": 0.6014724373817444
    },
    {
      "classification_loss": 0.6458129286766052,
      "epoch": 11.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3614,
      "total_loss": 0.6458129286766052
    },
    {
      "classification_loss": 0.5833487510681152,
      "epoch": 11.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3615,
      "total_loss": 0.5833487510681152
    },
    {
      "classification_loss": 0.46376144886016846,
      "epoch": 11.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3616,
      "total_loss": 0.46376144886016846
    },
    {
      "classification_loss": 0.45613181591033936,
      "epoch": 11.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3617,
      "total_loss": 0.45613181591033936
    },
    {
      "classification_loss": 0.4752466678619385,
      "epoch": 11.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3618,
      "total_loss": 0.4752466678619385
    },
    {
      "classification_loss": 0.5425326228141785,
      "epoch": 11.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3619,
      "total_loss": 0.5425326228141785
    },
    {
      "classification_loss": 0.5672391653060913,
      "epoch": 11.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3620,
      "total_loss": 0.5672391653060913
    },
    {
      "classification_loss": 0.5174610018730164,
      "epoch": 11.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3621,
      "total_loss": 0.5174610018730164
    },
    {
      "classification_loss": 0.45575380325317383,
      "epoch": 11.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3622,
      "total_loss": 0.45575380325317383
    },
    {
      "classification_loss": 0.44237378239631653,
      "epoch": 11.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3623,
      "total_loss": 0.44237378239631653
    },
    {
      "classification_loss": 0.6138019561767578,
      "epoch": 11.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3624,
      "total_loss": 0.6138019561767578
    },
    {
      "classification_loss": 0.4497637152671814,
      "epoch": 11.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3625,
      "total_loss": 0.4497637152671814
    },
    {
      "classification_loss": 0.538509726524353,
      "epoch": 11.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3626,
      "total_loss": 0.538509726524353
    },
    {
      "classification_loss": 0.6922003626823425,
      "epoch": 11.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3627,
      "total_loss": 0.6922003626823425
    },
    {
      "classification_loss": 0.6107171773910522,
      "epoch": 11.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3628,
      "total_loss": 0.6107171773910522
    },
    {
      "classification_loss": 0.538289487361908,
      "epoch": 11.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3629,
      "total_loss": 0.538289487361908
    },
    {
      "classification_loss": 0.5007404685020447,
      "epoch": 11.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3630,
      "total_loss": 0.5007404685020447
    },
    {
      "classification_loss": 0.5418016910552979,
      "epoch": 11.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3631,
      "total_loss": 0.5418016910552979
    },
    {
      "classification_loss": 0.5029659867286682,
      "epoch": 11.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3632,
      "total_loss": 0.5029659867286682
    },
    {
      "classification_loss": 0.5957906246185303,
      "epoch": 11.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3633,
      "total_loss": 0.5957906246185303
    },
    {
      "classification_loss": 0.4637444019317627,
      "epoch": 11.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3634,
      "total_loss": 0.4637444019317627
    },
    {
      "classification_loss": 0.5543392896652222,
      "epoch": 11.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3635,
      "total_loss": 0.5543392896652222
    },
    {
      "classification_loss": 0.43485745787620544,
      "epoch": 11.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3636,
      "total_loss": 0.43485745787620544
    },
    {
      "classification_loss": 0.42015600204467773,
      "epoch": 11.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3637,
      "total_loss": 0.42015600204467773
    },
    {
      "classification_loss": 0.5925341844558716,
      "epoch": 11.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3638,
      "total_loss": 0.5925341844558716
    },
    {
      "classification_loss": 0.639492392539978,
      "epoch": 11.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3639,
      "total_loss": 0.639492392539978
    },
    {
      "classification_loss": 0.48027870059013367,
      "epoch": 11.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3640,
      "total_loss": 0.48027870059013367
    },
    {
      "classification_loss": 0.5633711814880371,
      "epoch": 11.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3641,
      "total_loss": 0.5633711814880371
    },
    {
      "classification_loss": 0.43616440892219543,
      "epoch": 11.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3642,
      "total_loss": 0.43616440892219543
    },
    {
      "classification_loss": 0.4355948567390442,
      "epoch": 11.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3643,
      "total_loss": 0.4355948567390442
    },
    {
      "classification_loss": 0.5584198236465454,
      "epoch": 11.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3644,
      "total_loss": 0.5584198236465454
    },
    {
      "classification_loss": 0.5629221200942993,
      "epoch": 11.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3645,
      "total_loss": 0.5629221200942993
    },
    {
      "classification_loss": 0.43770405650138855,
      "epoch": 11.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3646,
      "total_loss": 0.43770405650138855
    },
    {
      "classification_loss": 0.5457817316055298,
      "epoch": 11.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3647,
      "total_loss": 0.5457817316055298
    },
    {
      "classification_loss": 0.4317658245563507,
      "epoch": 11.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3648,
      "total_loss": 0.4317658245563507
    },
    {
      "classification_loss": 0.5313367247581482,
      "epoch": 11.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3649,
      "total_loss": 0.5313367247581482
    },
    {
      "classification_loss": 0.6053413152694702,
      "epoch": 11.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3650,
      "total_loss": 0.6053413152694702
    },
    {
      "classification_loss": 0.5137290954589844,
      "epoch": 11.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3651,
      "total_loss": 0.5137290954589844
    },
    {
      "classification_loss": 0.47546786069869995,
      "epoch": 11.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3652,
      "total_loss": 0.47546786069869995
    },
    {
      "classification_loss": 0.47054046392440796,
      "epoch": 11.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3653,
      "total_loss": 0.47054046392440796
    },
    {
      "classification_loss": 0.5065155625343323,
      "epoch": 11.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3654,
      "total_loss": 0.5065155625343323
    },
    {
      "classification_loss": 0.443704217672348,
      "epoch": 11.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3655,
      "total_loss": 0.443704217672348
    },
    {
      "classification_loss": 0.5578964352607727,
      "epoch": 11.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3656,
      "total_loss": 0.5578964352607727
    },
    {
      "classification_loss": 0.6398449540138245,
      "epoch": 11.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3657,
      "total_loss": 0.6398449540138245
    },
    {
      "classification_loss": 0.5183622241020203,
      "epoch": 11.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3658,
      "total_loss": 0.5183622241020203
    },
    {
      "classification_loss": 0.5815315842628479,
      "epoch": 11.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3659,
      "total_loss": 0.5815315842628479
    },
    {
      "classification_loss": 1.4608299732208252,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.4608299732208252
    },
    {
      "classification_loss": 1.4028325080871582,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.4028325080871582
    },
    {
      "classification_loss": 1.282482385635376,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.282482385635376
    },
    {
      "classification_loss": 1.5832576751708984,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.5832576751708984
    },
    {
      "classification_loss": 1.309212327003479,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.309212327003479
    },
    {
      "classification_loss": 1.2792366743087769,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.2792366743087769
    },
    {
      "classification_loss": 1.3685706853866577,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.3685706853866577
    },
    {
      "classification_loss": 1.1730753183364868,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 1.1730753183364868
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.3618618249893188,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0019,
      "eval_samples_per_second": 166.615,
      "eval_steps_per_second": 1.333,
      "step": 3660
    },
    {
      "classification_loss": 0.5497298836708069,
      "epoch": 12.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3660,
      "total_loss": 0.5497298836708069
    },
    {
      "classification_loss": 0.5607463717460632,
      "epoch": 12.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3661,
      "total_loss": 0.5607463717460632
    },
    {
      "classification_loss": 0.6316307783126831,
      "epoch": 12.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3662,
      "total_loss": 0.6316307783126831
    },
    {
      "classification_loss": 0.5270794034004211,
      "epoch": 12.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3663,
      "total_loss": 0.5270794034004211
    },
    {
      "classification_loss": 0.5830478668212891,
      "epoch": 12.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3664,
      "total_loss": 0.5830478668212891
    },
    {
      "classification_loss": 0.546310544013977,
      "epoch": 12.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3665,
      "total_loss": 0.546310544013977
    },
    {
      "classification_loss": 0.4836080074310303,
      "epoch": 12.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3666,
      "total_loss": 0.4836080074310303
    },
    {
      "classification_loss": 0.4972177743911743,
      "epoch": 12.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3667,
      "total_loss": 0.4972177743911743
    },
    {
      "classification_loss": 0.5099195241928101,
      "epoch": 12.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3668,
      "total_loss": 0.5099195241928101
    },
    {
      "classification_loss": 0.42930471897125244,
      "epoch": 12.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3669,
      "total_loss": 0.42930471897125244
    },
    {
      "classification_loss": 0.5888103246688843,
      "epoch": 12.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3670,
      "total_loss": 0.5888103246688843
    },
    {
      "classification_loss": 0.47248440980911255,
      "epoch": 12.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3671,
      "total_loss": 0.47248440980911255
    },
    {
      "classification_loss": 0.4410948157310486,
      "epoch": 12.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3672,
      "total_loss": 0.4410948157310486
    },
    {
      "classification_loss": 0.533689022064209,
      "epoch": 12.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3673,
      "total_loss": 0.533689022064209
    },
    {
      "classification_loss": 0.47688940167427063,
      "epoch": 12.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3674,
      "total_loss": 0.47688940167427063
    },
    {
      "classification_loss": 0.5967416167259216,
      "epoch": 12.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3675,
      "total_loss": 0.5967416167259216
    },
    {
      "classification_loss": 0.5417003631591797,
      "epoch": 12.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3676,
      "total_loss": 0.5417003631591797
    },
    {
      "classification_loss": 0.5314239859580994,
      "epoch": 12.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3677,
      "total_loss": 0.5314239859580994
    },
    {
      "classification_loss": 0.5089980363845825,
      "epoch": 12.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3678,
      "total_loss": 0.5089980363845825
    },
    {
      "classification_loss": 0.548126220703125,
      "epoch": 12.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3679,
      "total_loss": 0.548126220703125
    },
    {
      "classification_loss": 0.486234188079834,
      "epoch": 12.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3680,
      "total_loss": 0.486234188079834
    },
    {
      "classification_loss": 0.4769039750099182,
      "epoch": 12.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3681,
      "total_loss": 0.4769039750099182
    },
    {
      "classification_loss": 0.5155824422836304,
      "epoch": 12.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3682,
      "total_loss": 0.5155824422836304
    },
    {
      "classification_loss": 0.5065223574638367,
      "epoch": 12.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3683,
      "total_loss": 0.5065223574638367
    },
    {
      "classification_loss": 0.5112970471382141,
      "epoch": 12.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3684,
      "total_loss": 0.5112970471382141
    },
    {
      "classification_loss": 0.4272017180919647,
      "epoch": 12.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3685,
      "total_loss": 0.4272017180919647
    },
    {
      "classification_loss": 0.5222491025924683,
      "epoch": 12.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3686,
      "total_loss": 0.5222491025924683
    },
    {
      "classification_loss": 0.5411540865898132,
      "epoch": 12.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3687,
      "total_loss": 0.5411540865898132
    },
    {
      "classification_loss": 0.5545658469200134,
      "epoch": 12.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3688,
      "total_loss": 0.5545658469200134
    },
    {
      "classification_loss": 0.4694003164768219,
      "epoch": 12.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3689,
      "total_loss": 0.4694003164768219
    },
    {
      "classification_loss": 0.5155884623527527,
      "epoch": 12.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3690,
      "total_loss": 0.5155884623527527
    },
    {
      "classification_loss": 0.5266646146774292,
      "epoch": 12.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3691,
      "total_loss": 0.5266646146774292
    },
    {
      "classification_loss": 0.5571755766868591,
      "epoch": 12.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3692,
      "total_loss": 0.5571755766868591
    },
    {
      "classification_loss": 0.47103351354599,
      "epoch": 12.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3693,
      "total_loss": 0.47103351354599
    },
    {
      "classification_loss": 0.4302116930484772,
      "epoch": 12.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3694,
      "total_loss": 0.4302116930484772
    },
    {
      "classification_loss": 0.5298781991004944,
      "epoch": 12.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3695,
      "total_loss": 0.5298781991004944
    },
    {
      "classification_loss": 0.550039529800415,
      "epoch": 12.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3696,
      "total_loss": 0.550039529800415
    },
    {
      "classification_loss": 0.5547771453857422,
      "epoch": 12.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3697,
      "total_loss": 0.5547771453857422
    },
    {
      "classification_loss": 0.5189502239227295,
      "epoch": 12.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3698,
      "total_loss": 0.5189502239227295
    },
    {
      "classification_loss": 0.439380019903183,
      "epoch": 12.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3699,
      "total_loss": 0.439380019903183
    },
    {
      "epoch": 12.131147540983607,
      "grad_norm": 6.129464149475098,
      "learning_rate": 8.003333333333333e-05,
      "loss": 0.5203,
      "step": 3700
    },
    {
      "classification_loss": 0.44162026047706604,
      "epoch": 12.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3700,
      "total_loss": 0.44162026047706604
    },
    {
      "classification_loss": 0.5425286293029785,
      "epoch": 12.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3701,
      "total_loss": 0.5425286293029785
    },
    {
      "classification_loss": 0.5168098211288452,
      "epoch": 12.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3702,
      "total_loss": 0.5168098211288452
    },
    {
      "classification_loss": 0.48061272501945496,
      "epoch": 12.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3703,
      "total_loss": 0.48061272501945496
    },
    {
      "classification_loss": 0.5025319457054138,
      "epoch": 12.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3704,
      "total_loss": 0.5025319457054138
    },
    {
      "classification_loss": 0.4990026354789734,
      "epoch": 12.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3705,
      "total_loss": 0.4990026354789734
    },
    {
      "classification_loss": 0.5026513934135437,
      "epoch": 12.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3706,
      "total_loss": 0.5026513934135437
    },
    {
      "classification_loss": 0.4881485104560852,
      "epoch": 12.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3707,
      "total_loss": 0.4881485104560852
    },
    {
      "classification_loss": 0.5634443759918213,
      "epoch": 12.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3708,
      "total_loss": 0.5634443759918213
    },
    {
      "classification_loss": 0.43560802936553955,
      "epoch": 12.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3709,
      "total_loss": 0.43560802936553955
    },
    {
      "classification_loss": 0.5433388352394104,
      "epoch": 12.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3710,
      "total_loss": 0.5433388352394104
    },
    {
      "classification_loss": 0.5845645070075989,
      "epoch": 12.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3711,
      "total_loss": 0.5845645070075989
    },
    {
      "classification_loss": 0.4155750870704651,
      "epoch": 12.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3712,
      "total_loss": 0.4155750870704651
    },
    {
      "classification_loss": 0.48878955841064453,
      "epoch": 12.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3713,
      "total_loss": 0.48878955841064453
    },
    {
      "classification_loss": 0.43909361958503723,
      "epoch": 12.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3714,
      "total_loss": 0.43909361958503723
    },
    {
      "classification_loss": 0.5149415135383606,
      "epoch": 12.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3715,
      "total_loss": 0.5149415135383606
    },
    {
      "classification_loss": 0.5601958632469177,
      "epoch": 12.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3716,
      "total_loss": 0.5601958632469177
    },
    {
      "classification_loss": 0.3951490819454193,
      "epoch": 12.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3717,
      "total_loss": 0.3951490819454193
    },
    {
      "classification_loss": 0.47241875529289246,
      "epoch": 12.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3718,
      "total_loss": 0.47241875529289246
    },
    {
      "classification_loss": 0.5192077159881592,
      "epoch": 12.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3719,
      "total_loss": 0.5192077159881592
    },
    {
      "classification_loss": 0.5186925530433655,
      "epoch": 12.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3720,
      "total_loss": 0.5186925530433655
    },
    {
      "classification_loss": 0.5805129408836365,
      "epoch": 12.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3721,
      "total_loss": 0.5805129408836365
    },
    {
      "classification_loss": 0.5450239181518555,
      "epoch": 12.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3722,
      "total_loss": 0.5450239181518555
    },
    {
      "classification_loss": 0.5091195702552795,
      "epoch": 12.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3723,
      "total_loss": 0.5091195702552795
    },
    {
      "classification_loss": 0.5375261902809143,
      "epoch": 12.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3724,
      "total_loss": 0.5375261902809143
    },
    {
      "classification_loss": 0.3654705584049225,
      "epoch": 12.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3725,
      "total_loss": 0.3654705584049225
    },
    {
      "classification_loss": 0.5100066065788269,
      "epoch": 12.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3726,
      "total_loss": 0.5100066065788269
    },
    {
      "classification_loss": 0.43396463990211487,
      "epoch": 12.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3727,
      "total_loss": 0.43396463990211487
    },
    {
      "classification_loss": 0.5408626794815063,
      "epoch": 12.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3728,
      "total_loss": 0.5408626794815063
    },
    {
      "classification_loss": 0.3886127173900604,
      "epoch": 12.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3729,
      "total_loss": 0.3886127173900604
    },
    {
      "classification_loss": 0.5074259042739868,
      "epoch": 12.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3730,
      "total_loss": 0.5074259042739868
    },
    {
      "classification_loss": 0.5360576510429382,
      "epoch": 12.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3731,
      "total_loss": 0.5360576510429382
    },
    {
      "classification_loss": 0.5289793014526367,
      "epoch": 12.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3732,
      "total_loss": 0.5289793014526367
    },
    {
      "classification_loss": 0.35057780146598816,
      "epoch": 12.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3733,
      "total_loss": 0.35057780146598816
    },
    {
      "classification_loss": 0.4291919767856598,
      "epoch": 12.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3734,
      "total_loss": 0.4291919767856598
    },
    {
      "classification_loss": 0.5489800572395325,
      "epoch": 12.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3735,
      "total_loss": 0.5489800572395325
    },
    {
      "classification_loss": 0.5006178021430969,
      "epoch": 12.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3736,
      "total_loss": 0.5006178021430969
    },
    {
      "classification_loss": 0.4402357339859009,
      "epoch": 12.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3737,
      "total_loss": 0.4402357339859009
    },
    {
      "classification_loss": 0.5434743165969849,
      "epoch": 12.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3738,
      "total_loss": 0.5434743165969849
    },
    {
      "classification_loss": 0.5276076793670654,
      "epoch": 12.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3739,
      "total_loss": 0.5276076793670654
    },
    {
      "classification_loss": 0.463058739900589,
      "epoch": 12.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3740,
      "total_loss": 0.463058739900589
    },
    {
      "classification_loss": 0.5698980689048767,
      "epoch": 12.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3741,
      "total_loss": 0.5698980689048767
    },
    {
      "classification_loss": 0.44650161266326904,
      "epoch": 12.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3742,
      "total_loss": 0.44650161266326904
    },
    {
      "classification_loss": 0.5475205183029175,
      "epoch": 12.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3743,
      "total_loss": 0.5475205183029175
    },
    {
      "classification_loss": 0.6196858286857605,
      "epoch": 12.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3744,
      "total_loss": 0.6196858286857605
    },
    {
      "classification_loss": 0.53550785779953,
      "epoch": 12.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3745,
      "total_loss": 0.53550785779953
    },
    {
      "classification_loss": 0.5056672096252441,
      "epoch": 12.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3746,
      "total_loss": 0.5056672096252441
    },
    {
      "classification_loss": 0.6915140748023987,
      "epoch": 12.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3747,
      "total_loss": 0.6915140748023987
    },
    {
      "classification_loss": 0.6070795059204102,
      "epoch": 12.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3748,
      "total_loss": 0.6070795059204102
    },
    {
      "classification_loss": 0.602502703666687,
      "epoch": 12.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3749,
      "total_loss": 0.602502703666687
    },
    {
      "classification_loss": 0.5720640420913696,
      "epoch": 12.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3750,
      "total_loss": 0.5720640420913696
    },
    {
      "classification_loss": 0.5625340938568115,
      "epoch": 12.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3751,
      "total_loss": 0.5625340938568115
    },
    {
      "classification_loss": 0.46162915229797363,
      "epoch": 12.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3752,
      "total_loss": 0.46162915229797363
    },
    {
      "classification_loss": 0.5668914914131165,
      "epoch": 12.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3753,
      "total_loss": 0.5668914914131165
    },
    {
      "classification_loss": 0.4498509466648102,
      "epoch": 12.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3754,
      "total_loss": 0.4498509466648102
    },
    {
      "classification_loss": 0.659119188785553,
      "epoch": 12.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3755,
      "total_loss": 0.659119188785553
    },
    {
      "classification_loss": 0.4529082179069519,
      "epoch": 12.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3756,
      "total_loss": 0.4529082179069519
    },
    {
      "classification_loss": 0.4950714409351349,
      "epoch": 12.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3757,
      "total_loss": 0.4950714409351349
    },
    {
      "classification_loss": 0.5088431239128113,
      "epoch": 12.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3758,
      "total_loss": 0.5088431239128113
    },
    {
      "classification_loss": 0.5024163722991943,
      "epoch": 12.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3759,
      "total_loss": 0.5024163722991943
    },
    {
      "classification_loss": 0.5934358835220337,
      "epoch": 12.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3760,
      "total_loss": 0.5934358835220337
    },
    {
      "classification_loss": 0.619417130947113,
      "epoch": 12.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3761,
      "total_loss": 0.619417130947113
    },
    {
      "classification_loss": 0.46762993931770325,
      "epoch": 12.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3762,
      "total_loss": 0.46762993931770325
    },
    {
      "classification_loss": 0.5262574553489685,
      "epoch": 12.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3763,
      "total_loss": 0.5262574553489685
    },
    {
      "classification_loss": 0.4964136481285095,
      "epoch": 12.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3764,
      "total_loss": 0.4964136481285095
    },
    {
      "classification_loss": 0.42568239569664,
      "epoch": 12.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3765,
      "total_loss": 0.42568239569664
    },
    {
      "classification_loss": 0.4910212755203247,
      "epoch": 12.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3766,
      "total_loss": 0.4910212755203247
    },
    {
      "classification_loss": 0.5263689756393433,
      "epoch": 12.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3767,
      "total_loss": 0.5263689756393433
    },
    {
      "classification_loss": 0.42922306060791016,
      "epoch": 12.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3768,
      "total_loss": 0.42922306060791016
    },
    {
      "classification_loss": 0.5918927788734436,
      "epoch": 12.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3769,
      "total_loss": 0.5918927788734436
    },
    {
      "classification_loss": 0.6199436783790588,
      "epoch": 12.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3770,
      "total_loss": 0.6199436783790588
    },
    {
      "classification_loss": 0.5496135950088501,
      "epoch": 12.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3771,
      "total_loss": 0.5496135950088501
    },
    {
      "classification_loss": 0.5034494996070862,
      "epoch": 12.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3772,
      "total_loss": 0.5034494996070862
    },
    {
      "classification_loss": 0.5429078936576843,
      "epoch": 12.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3773,
      "total_loss": 0.5429078936576843
    },
    {
      "classification_loss": 0.5184768438339233,
      "epoch": 12.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3774,
      "total_loss": 0.5184768438339233
    },
    {
      "classification_loss": 0.6826832890510559,
      "epoch": 12.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3775,
      "total_loss": 0.6826832890510559
    },
    {
      "classification_loss": 0.4881000518798828,
      "epoch": 12.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3776,
      "total_loss": 0.4881000518798828
    },
    {
      "classification_loss": 0.5336534380912781,
      "epoch": 12.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3777,
      "total_loss": 0.5336534380912781
    },
    {
      "classification_loss": 0.553753137588501,
      "epoch": 12.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3778,
      "total_loss": 0.553753137588501
    },
    {
      "classification_loss": 0.5689342021942139,
      "epoch": 12.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3779,
      "total_loss": 0.5689342021942139
    },
    {
      "classification_loss": 0.505174994468689,
      "epoch": 12.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3780,
      "total_loss": 0.505174994468689
    },
    {
      "classification_loss": 0.5321757793426514,
      "epoch": 12.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3781,
      "total_loss": 0.5321757793426514
    },
    {
      "classification_loss": 0.5399300456047058,
      "epoch": 12.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3782,
      "total_loss": 0.5399300456047058
    },
    {
      "classification_loss": 0.5469511151313782,
      "epoch": 12.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3783,
      "total_loss": 0.5469511151313782
    },
    {
      "classification_loss": 0.4583088457584381,
      "epoch": 12.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3784,
      "total_loss": 0.4583088457584381
    },
    {
      "classification_loss": 0.5264213681221008,
      "epoch": 12.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3785,
      "total_loss": 0.5264213681221008
    },
    {
      "classification_loss": 0.5005916357040405,
      "epoch": 12.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3786,
      "total_loss": 0.5005916357040405
    },
    {
      "classification_loss": 0.4891742467880249,
      "epoch": 12.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3787,
      "total_loss": 0.4891742467880249
    },
    {
      "classification_loss": 0.4562338888645172,
      "epoch": 12.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3788,
      "total_loss": 0.4562338888645172
    },
    {
      "classification_loss": 0.5268865823745728,
      "epoch": 12.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3789,
      "total_loss": 0.5268865823745728
    },
    {
      "classification_loss": 0.4893379807472229,
      "epoch": 12.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3790,
      "total_loss": 0.4893379807472229
    },
    {
      "classification_loss": 0.5069856643676758,
      "epoch": 12.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3791,
      "total_loss": 0.5069856643676758
    },
    {
      "classification_loss": 0.4960522949695587,
      "epoch": 12.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3792,
      "total_loss": 0.4960522949695587
    },
    {
      "classification_loss": 0.5531282424926758,
      "epoch": 12.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3793,
      "total_loss": 0.5531282424926758
    },
    {
      "classification_loss": 0.6307432055473328,
      "epoch": 12.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3794,
      "total_loss": 0.6307432055473328
    },
    {
      "classification_loss": 0.5418772101402283,
      "epoch": 12.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3795,
      "total_loss": 0.5418772101402283
    },
    {
      "classification_loss": 0.6111716032028198,
      "epoch": 12.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3796,
      "total_loss": 0.6111716032028198
    },
    {
      "classification_loss": 0.47012490034103394,
      "epoch": 12.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3797,
      "total_loss": 0.47012490034103394
    },
    {
      "classification_loss": 0.44669219851493835,
      "epoch": 12.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3798,
      "total_loss": 0.44669219851493835
    },
    {
      "classification_loss": 0.49904847145080566,
      "epoch": 12.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3799,
      "total_loss": 0.49904847145080566
    },
    {
      "epoch": 12.459016393442623,
      "grad_norm": 4.840291500091553,
      "learning_rate": 7.670000000000001e-05,
      "loss": 0.5163,
      "step": 3800
    },
    {
      "classification_loss": 0.4955753982067108,
      "epoch": 12.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3800,
      "total_loss": 0.4955753982067108
    },
    {
      "classification_loss": 0.5042761564254761,
      "epoch": 12.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3801,
      "total_loss": 0.5042761564254761
    },
    {
      "classification_loss": 0.44972971081733704,
      "epoch": 12.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3802,
      "total_loss": 0.44972971081733704
    },
    {
      "classification_loss": 0.4427716135978699,
      "epoch": 12.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3803,
      "total_loss": 0.4427716135978699
    },
    {
      "classification_loss": 0.510321855545044,
      "epoch": 12.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3804,
      "total_loss": 0.510321855545044
    },
    {
      "classification_loss": 0.38914087414741516,
      "epoch": 12.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3805,
      "total_loss": 0.38914087414741516
    },
    {
      "classification_loss": 0.49229109287261963,
      "epoch": 12.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3806,
      "total_loss": 0.49229109287261963
    },
    {
      "classification_loss": 0.5634152889251709,
      "epoch": 12.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3807,
      "total_loss": 0.5634152889251709
    },
    {
      "classification_loss": 0.5994427800178528,
      "epoch": 12.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3808,
      "total_loss": 0.5994427800178528
    },
    {
      "classification_loss": 0.5629324913024902,
      "epoch": 12.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3809,
      "total_loss": 0.5629324913024902
    },
    {
      "classification_loss": 0.518980860710144,
      "epoch": 12.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3810,
      "total_loss": 0.518980860710144
    },
    {
      "classification_loss": 0.44681432843208313,
      "epoch": 12.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3811,
      "total_loss": 0.44681432843208313
    },
    {
      "classification_loss": 0.5315157771110535,
      "epoch": 12.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3812,
      "total_loss": 0.5315157771110535
    },
    {
      "classification_loss": 0.5398890376091003,
      "epoch": 12.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3813,
      "total_loss": 0.5398890376091003
    },
    {
      "classification_loss": 0.42278045415878296,
      "epoch": 12.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3814,
      "total_loss": 0.42278045415878296
    },
    {
      "classification_loss": 0.607927143573761,
      "epoch": 12.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3815,
      "total_loss": 0.607927143573761
    },
    {
      "classification_loss": 0.6051762104034424,
      "epoch": 12.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3816,
      "total_loss": 0.6051762104034424
    },
    {
      "classification_loss": 0.535939633846283,
      "epoch": 12.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3817,
      "total_loss": 0.535939633846283
    },
    {
      "classification_loss": 0.5014488101005554,
      "epoch": 12.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3818,
      "total_loss": 0.5014488101005554
    },
    {
      "classification_loss": 0.45430827140808105,
      "epoch": 12.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3819,
      "total_loss": 0.45430827140808105
    },
    {
      "classification_loss": 0.44709455966949463,
      "epoch": 12.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3820,
      "total_loss": 0.44709455966949463
    },
    {
      "classification_loss": 0.4885229766368866,
      "epoch": 12.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3821,
      "total_loss": 0.4885229766368866
    },
    {
      "classification_loss": 0.489230215549469,
      "epoch": 12.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3822,
      "total_loss": 0.489230215549469
    },
    {
      "classification_loss": 0.45777276158332825,
      "epoch": 12.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3823,
      "total_loss": 0.45777276158332825
    },
    {
      "classification_loss": 0.5453975200653076,
      "epoch": 12.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3824,
      "total_loss": 0.5453975200653076
    },
    {
      "classification_loss": 0.46146097779273987,
      "epoch": 12.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3825,
      "total_loss": 0.46146097779273987
    },
    {
      "classification_loss": 0.4666716158390045,
      "epoch": 12.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3826,
      "total_loss": 0.4666716158390045
    },
    {
      "classification_loss": 0.44798800349235535,
      "epoch": 12.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3827,
      "total_loss": 0.44798800349235535
    },
    {
      "classification_loss": 0.4759604334831238,
      "epoch": 12.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3828,
      "total_loss": 0.4759604334831238
    },
    {
      "classification_loss": 0.5422424674034119,
      "epoch": 12.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3829,
      "total_loss": 0.5422424674034119
    },
    {
      "classification_loss": 0.5840961933135986,
      "epoch": 12.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3830,
      "total_loss": 0.5840961933135986
    },
    {
      "classification_loss": 0.47586220502853394,
      "epoch": 12.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3831,
      "total_loss": 0.47586220502853394
    },
    {
      "classification_loss": 0.6527755260467529,
      "epoch": 12.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3832,
      "total_loss": 0.6527755260467529
    },
    {
      "classification_loss": 0.5357672572135925,
      "epoch": 12.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3833,
      "total_loss": 0.5357672572135925
    },
    {
      "classification_loss": 0.6603693962097168,
      "epoch": 12.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3834,
      "total_loss": 0.6603693962097168
    },
    {
      "classification_loss": 0.5302991271018982,
      "epoch": 12.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3835,
      "total_loss": 0.5302991271018982
    },
    {
      "classification_loss": 0.42858409881591797,
      "epoch": 12.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3836,
      "total_loss": 0.42858409881591797
    },
    {
      "classification_loss": 0.5161190629005432,
      "epoch": 12.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3837,
      "total_loss": 0.5161190629005432
    },
    {
      "classification_loss": 0.49181801080703735,
      "epoch": 12.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3838,
      "total_loss": 0.49181801080703735
    },
    {
      "classification_loss": 0.37822839617729187,
      "epoch": 12.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3839,
      "total_loss": 0.37822839617729187
    },
    {
      "classification_loss": 0.4602614939212799,
      "epoch": 12.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3840,
      "total_loss": 0.4602614939212799
    },
    {
      "classification_loss": 0.49133622646331787,
      "epoch": 12.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3841,
      "total_loss": 0.49133622646331787
    },
    {
      "classification_loss": 0.3943224847316742,
      "epoch": 12.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3842,
      "total_loss": 0.3943224847316742
    },
    {
      "classification_loss": 0.4001427888870239,
      "epoch": 12.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3843,
      "total_loss": 0.4001427888870239
    },
    {
      "classification_loss": 0.5380191802978516,
      "epoch": 12.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3844,
      "total_loss": 0.5380191802978516
    },
    {
      "classification_loss": 0.4828146696090698,
      "epoch": 12.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3845,
      "total_loss": 0.4828146696090698
    },
    {
      "classification_loss": 0.6885141730308533,
      "epoch": 12.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3846,
      "total_loss": 0.6885141730308533
    },
    {
      "classification_loss": 0.4778958559036255,
      "epoch": 12.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3847,
      "total_loss": 0.4778958559036255
    },
    {
      "classification_loss": 0.5593018531799316,
      "epoch": 12.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3848,
      "total_loss": 0.5593018531799316
    },
    {
      "classification_loss": 0.5872398018836975,
      "epoch": 12.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3849,
      "total_loss": 0.5872398018836975
    },
    {
      "classification_loss": 0.5455579161643982,
      "epoch": 12.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3850,
      "total_loss": 0.5455579161643982
    },
    {
      "classification_loss": 0.5504338145256042,
      "epoch": 12.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3851,
      "total_loss": 0.5504338145256042
    },
    {
      "classification_loss": 0.4842168092727661,
      "epoch": 12.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3852,
      "total_loss": 0.4842168092727661
    },
    {
      "classification_loss": 0.47196751832962036,
      "epoch": 12.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3853,
      "total_loss": 0.47196751832962036
    },
    {
      "classification_loss": 0.4771009385585785,
      "epoch": 12.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3854,
      "total_loss": 0.4771009385585785
    },
    {
      "classification_loss": 0.4601222574710846,
      "epoch": 12.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3855,
      "total_loss": 0.4601222574710846
    },
    {
      "classification_loss": 0.43097689747810364,
      "epoch": 12.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3856,
      "total_loss": 0.43097689747810364
    },
    {
      "classification_loss": 0.48030006885528564,
      "epoch": 12.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3857,
      "total_loss": 0.48030006885528564
    },
    {
      "classification_loss": 0.6401932239532471,
      "epoch": 12.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3858,
      "total_loss": 0.6401932239532471
    },
    {
      "classification_loss": 0.4557470977306366,
      "epoch": 12.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3859,
      "total_loss": 0.4557470977306366
    },
    {
      "classification_loss": 0.5285252332687378,
      "epoch": 12.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3860,
      "total_loss": 0.5285252332687378
    },
    {
      "classification_loss": 0.5096005797386169,
      "epoch": 12.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3861,
      "total_loss": 0.5096005797386169
    },
    {
      "classification_loss": 0.5616098046302795,
      "epoch": 12.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3862,
      "total_loss": 0.5616098046302795
    },
    {
      "classification_loss": 0.4701429605484009,
      "epoch": 12.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3863,
      "total_loss": 0.4701429605484009
    },
    {
      "classification_loss": 0.45472726225852966,
      "epoch": 12.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3864,
      "total_loss": 0.45472726225852966
    },
    {
      "classification_loss": 0.5775205492973328,
      "epoch": 12.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3865,
      "total_loss": 0.5775205492973328
    },
    {
      "classification_loss": 0.4987364411354065,
      "epoch": 12.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3866,
      "total_loss": 0.4987364411354065
    },
    {
      "classification_loss": 0.45469969511032104,
      "epoch": 12.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3867,
      "total_loss": 0.45469969511032104
    },
    {
      "classification_loss": 0.5332730412483215,
      "epoch": 12.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3868,
      "total_loss": 0.5332730412483215
    },
    {
      "classification_loss": 0.39552929997444153,
      "epoch": 12.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3869,
      "total_loss": 0.39552929997444153
    },
    {
      "classification_loss": 0.4329032897949219,
      "epoch": 12.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3870,
      "total_loss": 0.4329032897949219
    },
    {
      "classification_loss": 0.4781147539615631,
      "epoch": 12.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3871,
      "total_loss": 0.4781147539615631
    },
    {
      "classification_loss": 0.4524456262588501,
      "epoch": 12.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3872,
      "total_loss": 0.4524456262588501
    },
    {
      "classification_loss": 0.5278371572494507,
      "epoch": 12.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3873,
      "total_loss": 0.5278371572494507
    },
    {
      "classification_loss": 0.4883809983730316,
      "epoch": 12.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3874,
      "total_loss": 0.4883809983730316
    },
    {
      "classification_loss": 0.487229585647583,
      "epoch": 12.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3875,
      "total_loss": 0.487229585647583
    },
    {
      "classification_loss": 0.6674491167068481,
      "epoch": 12.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3876,
      "total_loss": 0.6674491167068481
    },
    {
      "classification_loss": 0.5487484931945801,
      "epoch": 12.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3877,
      "total_loss": 0.5487484931945801
    },
    {
      "classification_loss": 0.42109787464141846,
      "epoch": 12.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3878,
      "total_loss": 0.42109787464141846
    },
    {
      "classification_loss": 0.44050854444503784,
      "epoch": 12.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3879,
      "total_loss": 0.44050854444503784
    },
    {
      "classification_loss": 0.5942000150680542,
      "epoch": 12.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3880,
      "total_loss": 0.5942000150680542
    },
    {
      "classification_loss": 0.5745701193809509,
      "epoch": 12.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3881,
      "total_loss": 0.5745701193809509
    },
    {
      "classification_loss": 0.4403977394104004,
      "epoch": 12.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3882,
      "total_loss": 0.4403977394104004
    },
    {
      "classification_loss": 0.47200897336006165,
      "epoch": 12.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3883,
      "total_loss": 0.47200897336006165
    },
    {
      "classification_loss": 0.6356886625289917,
      "epoch": 12.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3884,
      "total_loss": 0.6356886625289917
    },
    {
      "classification_loss": 0.49169251322746277,
      "epoch": 12.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3885,
      "total_loss": 0.49169251322746277
    },
    {
      "classification_loss": 0.4043234884738922,
      "epoch": 12.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3886,
      "total_loss": 0.4043234884738922
    },
    {
      "classification_loss": 0.5060336589813232,
      "epoch": 12.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3887,
      "total_loss": 0.5060336589813232
    },
    {
      "classification_loss": 0.43327710032463074,
      "epoch": 12.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3888,
      "total_loss": 0.43327710032463074
    },
    {
      "classification_loss": 0.48588457703590393,
      "epoch": 12.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3889,
      "total_loss": 0.48588457703590393
    },
    {
      "classification_loss": 0.49974748492240906,
      "epoch": 12.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3890,
      "total_loss": 0.49974748492240906
    },
    {
      "classification_loss": 0.510768473148346,
      "epoch": 12.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3891,
      "total_loss": 0.510768473148346
    },
    {
      "classification_loss": 0.5975073575973511,
      "epoch": 12.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3892,
      "total_loss": 0.5975073575973511
    },
    {
      "classification_loss": 0.5135979652404785,
      "epoch": 12.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3893,
      "total_loss": 0.5135979652404785
    },
    {
      "classification_loss": 0.4953233003616333,
      "epoch": 12.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3894,
      "total_loss": 0.4953233003616333
    },
    {
      "classification_loss": 0.4520559012889862,
      "epoch": 12.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3895,
      "total_loss": 0.4520559012889862
    },
    {
      "classification_loss": 0.5067039132118225,
      "epoch": 12.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3896,
      "total_loss": 0.5067039132118225
    },
    {
      "classification_loss": 0.4896236062049866,
      "epoch": 12.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3897,
      "total_loss": 0.4896236062049866
    },
    {
      "classification_loss": 0.5330423712730408,
      "epoch": 12.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3898,
      "total_loss": 0.5330423712730408
    },
    {
      "classification_loss": 0.4651161730289459,
      "epoch": 12.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3899,
      "total_loss": 0.4651161730289459
    },
    {
      "epoch": 12.78688524590164,
      "grad_norm": 3.0199825763702393,
      "learning_rate": 7.336666666666667e-05,
      "loss": 0.5036,
      "step": 3900
    },
    {
      "classification_loss": 0.6253734230995178,
      "epoch": 12.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3900,
      "total_loss": 0.6253734230995178
    },
    {
      "classification_loss": 0.5937443375587463,
      "epoch": 12.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3901,
      "total_loss": 0.5937443375587463
    },
    {
      "classification_loss": 0.4465736150741577,
      "epoch": 12.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3902,
      "total_loss": 0.4465736150741577
    },
    {
      "classification_loss": 0.5046699047088623,
      "epoch": 12.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3903,
      "total_loss": 0.5046699047088623
    },
    {
      "classification_loss": 0.5567765235900879,
      "epoch": 12.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3904,
      "total_loss": 0.5567765235900879
    },
    {
      "classification_loss": 0.6041994690895081,
      "epoch": 12.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3905,
      "total_loss": 0.6041994690895081
    },
    {
      "classification_loss": 0.4716850221157074,
      "epoch": 12.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3906,
      "total_loss": 0.4716850221157074
    },
    {
      "classification_loss": 0.5107192397117615,
      "epoch": 12.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3907,
      "total_loss": 0.5107192397117615
    },
    {
      "classification_loss": 0.48239049315452576,
      "epoch": 12.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3908,
      "total_loss": 0.48239049315452576
    },
    {
      "classification_loss": 0.46863895654678345,
      "epoch": 12.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3909,
      "total_loss": 0.46863895654678345
    },
    {
      "classification_loss": 0.5722959637641907,
      "epoch": 12.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3910,
      "total_loss": 0.5722959637641907
    },
    {
      "classification_loss": 0.5627384185791016,
      "epoch": 12.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3911,
      "total_loss": 0.5627384185791016
    },
    {
      "classification_loss": 0.5079644322395325,
      "epoch": 12.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3912,
      "total_loss": 0.5079644322395325
    },
    {
      "classification_loss": 0.5776451230049133,
      "epoch": 12.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3913,
      "total_loss": 0.5776451230049133
    },
    {
      "classification_loss": 0.44190776348114014,
      "epoch": 12.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3914,
      "total_loss": 0.44190776348114014
    },
    {
      "classification_loss": 0.6082673072814941,
      "epoch": 12.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3915,
      "total_loss": 0.6082673072814941
    },
    {
      "classification_loss": 0.5474902391433716,
      "epoch": 12.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3916,
      "total_loss": 0.5474902391433716
    },
    {
      "classification_loss": 0.6344180107116699,
      "epoch": 12.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3917,
      "total_loss": 0.6344180107116699
    },
    {
      "classification_loss": 0.5944835543632507,
      "epoch": 12.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3918,
      "total_loss": 0.5944835543632507
    },
    {
      "classification_loss": 0.4784379303455353,
      "epoch": 12.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3919,
      "total_loss": 0.4784379303455353
    },
    {
      "classification_loss": 0.51161789894104,
      "epoch": 12.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3920,
      "total_loss": 0.51161789894104
    },
    {
      "classification_loss": 0.5491020083427429,
      "epoch": 12.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3921,
      "total_loss": 0.5491020083427429
    },
    {
      "classification_loss": 0.5450841784477234,
      "epoch": 12.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3922,
      "total_loss": 0.5450841784477234
    },
    {
      "classification_loss": 0.5343703031539917,
      "epoch": 12.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3923,
      "total_loss": 0.5343703031539917
    },
    {
      "classification_loss": 0.517112672328949,
      "epoch": 12.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3924,
      "total_loss": 0.517112672328949
    },
    {
      "classification_loss": 0.5546894669532776,
      "epoch": 12.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3925,
      "total_loss": 0.5546894669532776
    },
    {
      "classification_loss": 0.4764215350151062,
      "epoch": 12.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3926,
      "total_loss": 0.4764215350151062
    },
    {
      "classification_loss": 0.478997141122818,
      "epoch": 12.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3927,
      "total_loss": 0.478997141122818
    },
    {
      "classification_loss": 0.5632720589637756,
      "epoch": 12.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3928,
      "total_loss": 0.5632720589637756
    },
    {
      "classification_loss": 0.5575581789016724,
      "epoch": 12.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3929,
      "total_loss": 0.5575581789016724
    },
    {
      "classification_loss": 0.49859437346458435,
      "epoch": 12.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3930,
      "total_loss": 0.49859437346458435
    },
    {
      "classification_loss": 0.5258904099464417,
      "epoch": 12.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3931,
      "total_loss": 0.5258904099464417
    },
    {
      "classification_loss": 0.48552921414375305,
      "epoch": 12.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3932,
      "total_loss": 0.48552921414375305
    },
    {
      "classification_loss": 0.5788512229919434,
      "epoch": 12.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3933,
      "total_loss": 0.5788512229919434
    },
    {
      "classification_loss": 0.4832412302494049,
      "epoch": 12.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3934,
      "total_loss": 0.4832412302494049
    },
    {
      "classification_loss": 0.5401496887207031,
      "epoch": 12.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3935,
      "total_loss": 0.5401496887207031
    },
    {
      "classification_loss": 0.49949318170547485,
      "epoch": 12.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3936,
      "total_loss": 0.49949318170547485
    },
    {
      "classification_loss": 0.5247149467468262,
      "epoch": 12.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3937,
      "total_loss": 0.5247149467468262
    },
    {
      "classification_loss": 0.4409429132938385,
      "epoch": 12.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3938,
      "total_loss": 0.4409429132938385
    },
    {
      "classification_loss": 0.5068633556365967,
      "epoch": 12.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3939,
      "total_loss": 0.5068633556365967
    },
    {
      "classification_loss": 0.47569093108177185,
      "epoch": 12.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3940,
      "total_loss": 0.47569093108177185
    },
    {
      "classification_loss": 0.48542189598083496,
      "epoch": 12.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3941,
      "total_loss": 0.48542189598083496
    },
    {
      "classification_loss": 0.5996792912483215,
      "epoch": 12.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3942,
      "total_loss": 0.5996792912483215
    },
    {
      "classification_loss": 0.556789755821228,
      "epoch": 12.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3943,
      "total_loss": 0.556789755821228
    },
    {
      "classification_loss": 0.4387529194355011,
      "epoch": 12.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3944,
      "total_loss": 0.4387529194355011
    },
    {
      "classification_loss": 0.5292719602584839,
      "epoch": 12.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3945,
      "total_loss": 0.5292719602584839
    },
    {
      "classification_loss": 0.5340689420700073,
      "epoch": 12.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3946,
      "total_loss": 0.5340689420700073
    },
    {
      "classification_loss": 0.522803783416748,
      "epoch": 12.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3947,
      "total_loss": 0.522803783416748
    },
    {
      "classification_loss": 0.5204935073852539,
      "epoch": 12.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3948,
      "total_loss": 0.5204935073852539
    },
    {
      "classification_loss": 0.6350208520889282,
      "epoch": 12.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3949,
      "total_loss": 0.6350208520889282
    },
    {
      "classification_loss": 0.5871183276176453,
      "epoch": 12.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3950,
      "total_loss": 0.5871183276176453
    },
    {
      "classification_loss": 0.5170576572418213,
      "epoch": 12.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3951,
      "total_loss": 0.5170576572418213
    },
    {
      "classification_loss": 0.4904143810272217,
      "epoch": 12.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3952,
      "total_loss": 0.4904143810272217
    },
    {
      "classification_loss": 0.4797550439834595,
      "epoch": 12.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3953,
      "total_loss": 0.4797550439834595
    },
    {
      "classification_loss": 0.5780386924743652,
      "epoch": 12.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3954,
      "total_loss": 0.5780386924743652
    },
    {
      "classification_loss": 0.5048678517341614,
      "epoch": 12.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3955,
      "total_loss": 0.5048678517341614
    },
    {
      "classification_loss": 0.4962044358253479,
      "epoch": 12.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3956,
      "total_loss": 0.4962044358253479
    },
    {
      "classification_loss": 0.5177876353263855,
      "epoch": 12.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3957,
      "total_loss": 0.5177876353263855
    },
    {
      "classification_loss": 0.46083810925483704,
      "epoch": 12.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3958,
      "total_loss": 0.46083810925483704
    },
    {
      "classification_loss": 0.5583218336105347,
      "epoch": 12.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3959,
      "total_loss": 0.5583218336105347
    },
    {
      "classification_loss": 0.49102020263671875,
      "epoch": 12.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3960,
      "total_loss": 0.49102020263671875
    },
    {
      "classification_loss": 0.4681495428085327,
      "epoch": 12.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3961,
      "total_loss": 0.4681495428085327
    },
    {
      "classification_loss": 0.4749245047569275,
      "epoch": 12.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3962,
      "total_loss": 0.4749245047569275
    },
    {
      "classification_loss": 0.4129735231399536,
      "epoch": 12.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3963,
      "total_loss": 0.4129735231399536
    },
    {
      "classification_loss": 0.5069157481193542,
      "epoch": 12.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3964,
      "total_loss": 0.5069157481193542
    },
    {
      "classification_loss": 1.4025381803512573,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.4025381803512573
    },
    {
      "classification_loss": 1.340073823928833,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.340073823928833
    },
    {
      "classification_loss": 1.2352204322814941,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.2352204322814941
    },
    {
      "classification_loss": 1.5140236616134644,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.5140236616134644
    },
    {
      "classification_loss": 1.2580435276031494,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.2580435276031494
    },
    {
      "classification_loss": 1.23164963722229,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.23164963722229
    },
    {
      "classification_loss": 1.3057878017425537,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.3057878017425537
    },
    {
      "classification_loss": 1.1249405145645142,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 1.1249405145645142
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.3057729005813599,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0159,
      "eval_samples_per_second": 166.227,
      "eval_steps_per_second": 1.33,
      "step": 3965
    },
    {
      "classification_loss": 0.5109131932258606,
      "epoch": 13.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3965,
      "total_loss": 0.5109131932258606
    },
    {
      "classification_loss": 0.5116044282913208,
      "epoch": 13.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3966,
      "total_loss": 0.5116044282913208
    },
    {
      "classification_loss": 0.5408904552459717,
      "epoch": 13.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3967,
      "total_loss": 0.5408904552459717
    },
    {
      "classification_loss": 0.4050176739692688,
      "epoch": 13.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3968,
      "total_loss": 0.4050176739692688
    },
    {
      "classification_loss": 0.541136622428894,
      "epoch": 13.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3969,
      "total_loss": 0.541136622428894
    },
    {
      "classification_loss": 0.5110555291175842,
      "epoch": 13.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3970,
      "total_loss": 0.5110555291175842
    },
    {
      "classification_loss": 0.4829651713371277,
      "epoch": 13.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3971,
      "total_loss": 0.4829651713371277
    },
    {
      "classification_loss": 0.4962296783924103,
      "epoch": 13.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3972,
      "total_loss": 0.4962296783924103
    },
    {
      "classification_loss": 0.495137095451355,
      "epoch": 13.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3973,
      "total_loss": 0.495137095451355
    },
    {
      "classification_loss": 0.5089589953422546,
      "epoch": 13.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3974,
      "total_loss": 0.5089589953422546
    },
    {
      "classification_loss": 0.5194775462150574,
      "epoch": 13.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3975,
      "total_loss": 0.5194775462150574
    },
    {
      "classification_loss": 0.4072166383266449,
      "epoch": 13.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3976,
      "total_loss": 0.4072166383266449
    },
    {
      "classification_loss": 0.42485472559928894,
      "epoch": 13.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3977,
      "total_loss": 0.42485472559928894
    },
    {
      "classification_loss": 0.5421530604362488,
      "epoch": 13.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3978,
      "total_loss": 0.5421530604362488
    },
    {
      "classification_loss": 0.5268351435661316,
      "epoch": 13.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3979,
      "total_loss": 0.5268351435661316
    },
    {
      "classification_loss": 0.5640673041343689,
      "epoch": 13.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3980,
      "total_loss": 0.5640673041343689
    },
    {
      "classification_loss": 0.5618473291397095,
      "epoch": 13.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3981,
      "total_loss": 0.5618473291397095
    },
    {
      "classification_loss": 0.43377360701560974,
      "epoch": 13.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3982,
      "total_loss": 0.43377360701560974
    },
    {
      "classification_loss": 0.45271459221839905,
      "epoch": 13.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3983,
      "total_loss": 0.45271459221839905
    },
    {
      "classification_loss": 0.4977647066116333,
      "epoch": 13.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3984,
      "total_loss": 0.4977647066116333
    },
    {
      "classification_loss": 0.5228177309036255,
      "epoch": 13.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3985,
      "total_loss": 0.5228177309036255
    },
    {
      "classification_loss": 0.4437287747859955,
      "epoch": 13.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3986,
      "total_loss": 0.4437287747859955
    },
    {
      "classification_loss": 0.5444748997688293,
      "epoch": 13.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3987,
      "total_loss": 0.5444748997688293
    },
    {
      "classification_loss": 0.42394739389419556,
      "epoch": 13.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3988,
      "total_loss": 0.42394739389419556
    },
    {
      "classification_loss": 0.4332513213157654,
      "epoch": 13.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3989,
      "total_loss": 0.4332513213157654
    },
    {
      "classification_loss": 0.5230198502540588,
      "epoch": 13.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3990,
      "total_loss": 0.5230198502540588
    },
    {
      "classification_loss": 0.43777114152908325,
      "epoch": 13.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3991,
      "total_loss": 0.43777114152908325
    },
    {
      "classification_loss": 0.4889317750930786,
      "epoch": 13.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3992,
      "total_loss": 0.4889317750930786
    },
    {
      "classification_loss": 0.5985386371612549,
      "epoch": 13.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3993,
      "total_loss": 0.5985386371612549
    },
    {
      "classification_loss": 0.489407479763031,
      "epoch": 13.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3994,
      "total_loss": 0.489407479763031
    },
    {
      "classification_loss": 0.4441041350364685,
      "epoch": 13.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3995,
      "total_loss": 0.4441041350364685
    },
    {
      "classification_loss": 0.43567776679992676,
      "epoch": 13.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3996,
      "total_loss": 0.43567776679992676
    },
    {
      "classification_loss": 0.4276183545589447,
      "epoch": 13.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3997,
      "total_loss": 0.4276183545589447
    },
    {
      "classification_loss": 0.4144277572631836,
      "epoch": 13.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3998,
      "total_loss": 0.4144277572631836
    },
    {
      "classification_loss": 0.51400226354599,
      "epoch": 13.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 3999,
      "total_loss": 0.51400226354599
    },
    {
      "epoch": 13.114754098360656,
      "grad_norm": 6.822834014892578,
      "learning_rate": 7.003333333333335e-05,
      "loss": 0.5108,
      "step": 4000
    },
    {
      "classification_loss": 0.41028279066085815,
      "epoch": 13.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4000,
      "total_loss": 0.41028279066085815
    },
    {
      "classification_loss": 0.5308510661125183,
      "epoch": 13.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4001,
      "total_loss": 0.5308510661125183
    },
    {
      "classification_loss": 0.5502628087997437,
      "epoch": 13.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4002,
      "total_loss": 0.5502628087997437
    },
    {
      "classification_loss": 0.5449755191802979,
      "epoch": 13.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4003,
      "total_loss": 0.5449755191802979
    },
    {
      "classification_loss": 0.4650071859359741,
      "epoch": 13.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4004,
      "total_loss": 0.4650071859359741
    },
    {
      "classification_loss": 0.4625898003578186,
      "epoch": 13.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4005,
      "total_loss": 0.4625898003578186
    },
    {
      "classification_loss": 0.5194489359855652,
      "epoch": 13.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4006,
      "total_loss": 0.5194489359855652
    },
    {
      "classification_loss": 0.4938923120498657,
      "epoch": 13.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4007,
      "total_loss": 0.4938923120498657
    },
    {
      "classification_loss": 0.5094542503356934,
      "epoch": 13.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4008,
      "total_loss": 0.5094542503356934
    },
    {
      "classification_loss": 0.42839914560317993,
      "epoch": 13.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4009,
      "total_loss": 0.42839914560317993
    },
    {
      "classification_loss": 0.40158507227897644,
      "epoch": 13.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4010,
      "total_loss": 0.40158507227897644
    },
    {
      "classification_loss": 0.4609396457672119,
      "epoch": 13.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4011,
      "total_loss": 0.4609396457672119
    },
    {
      "classification_loss": 0.38044825196266174,
      "epoch": 13.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4012,
      "total_loss": 0.38044825196266174
    },
    {
      "classification_loss": 0.4431244432926178,
      "epoch": 13.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4013,
      "total_loss": 0.4431244432926178
    },
    {
      "classification_loss": 0.41281425952911377,
      "epoch": 13.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4014,
      "total_loss": 0.41281425952911377
    },
    {
      "classification_loss": 0.45450228452682495,
      "epoch": 13.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4015,
      "total_loss": 0.45450228452682495
    },
    {
      "classification_loss": 0.4811192452907562,
      "epoch": 13.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4016,
      "total_loss": 0.4811192452907562
    },
    {
      "classification_loss": 0.6783161163330078,
      "epoch": 13.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4017,
      "total_loss": 0.6783161163330078
    },
    {
      "classification_loss": 0.488648921251297,
      "epoch": 13.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4018,
      "total_loss": 0.488648921251297
    },
    {
      "classification_loss": 0.5002680420875549,
      "epoch": 13.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4019,
      "total_loss": 0.5002680420875549
    },
    {
      "classification_loss": 0.7420567870140076,
      "epoch": 13.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4020,
      "total_loss": 0.7420567870140076
    },
    {
      "classification_loss": 0.5861940979957581,
      "epoch": 13.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4021,
      "total_loss": 0.5861940979957581
    },
    {
      "classification_loss": 0.4848611354827881,
      "epoch": 13.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4022,
      "total_loss": 0.4848611354827881
    },
    {
      "classification_loss": 0.5397035479545593,
      "epoch": 13.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4023,
      "total_loss": 0.5397035479545593
    },
    {
      "classification_loss": 0.6043245792388916,
      "epoch": 13.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4024,
      "total_loss": 0.6043245792388916
    },
    {
      "classification_loss": 0.5520217418670654,
      "epoch": 13.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4025,
      "total_loss": 0.5520217418670654
    },
    {
      "classification_loss": 0.5728035569190979,
      "epoch": 13.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4026,
      "total_loss": 0.5728035569190979
    },
    {
      "classification_loss": 0.5225415229797363,
      "epoch": 13.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4027,
      "total_loss": 0.5225415229797363
    },
    {
      "classification_loss": 0.3722742795944214,
      "epoch": 13.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4028,
      "total_loss": 0.3722742795944214
    },
    {
      "classification_loss": 0.552164614200592,
      "epoch": 13.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4029,
      "total_loss": 0.552164614200592
    },
    {
      "classification_loss": 0.45986565947532654,
      "epoch": 13.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4030,
      "total_loss": 0.45986565947532654
    },
    {
      "classification_loss": 0.5590738654136658,
      "epoch": 13.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4031,
      "total_loss": 0.5590738654136658
    },
    {
      "classification_loss": 0.513266384601593,
      "epoch": 13.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4032,
      "total_loss": 0.513266384601593
    },
    {
      "classification_loss": 0.43824222683906555,
      "epoch": 13.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4033,
      "total_loss": 0.43824222683906555
    },
    {
      "classification_loss": 0.5164970755577087,
      "epoch": 13.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4034,
      "total_loss": 0.5164970755577087
    },
    {
      "classification_loss": 0.5273389220237732,
      "epoch": 13.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4035,
      "total_loss": 0.5273389220237732
    },
    {
      "classification_loss": 0.43119117617607117,
      "epoch": 13.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4036,
      "total_loss": 0.43119117617607117
    },
    {
      "classification_loss": 0.367462694644928,
      "epoch": 13.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4037,
      "total_loss": 0.367462694644928
    },
    {
      "classification_loss": 0.3726162016391754,
      "epoch": 13.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4038,
      "total_loss": 0.3726162016391754
    },
    {
      "classification_loss": 0.39545291662216187,
      "epoch": 13.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4039,
      "total_loss": 0.39545291662216187
    },
    {
      "classification_loss": 0.48730987310409546,
      "epoch": 13.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4040,
      "total_loss": 0.48730987310409546
    },
    {
      "classification_loss": 0.479563444852829,
      "epoch": 13.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4041,
      "total_loss": 0.479563444852829
    },
    {
      "classification_loss": 0.44414788484573364,
      "epoch": 13.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4042,
      "total_loss": 0.44414788484573364
    },
    {
      "classification_loss": 0.5367428660392761,
      "epoch": 13.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4043,
      "total_loss": 0.5367428660392761
    },
    {
      "classification_loss": 0.49185577034950256,
      "epoch": 13.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4044,
      "total_loss": 0.49185577034950256
    },
    {
      "classification_loss": 0.43117091059684753,
      "epoch": 13.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4045,
      "total_loss": 0.43117091059684753
    },
    {
      "classification_loss": 0.3950210213661194,
      "epoch": 13.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4046,
      "total_loss": 0.3950210213661194
    },
    {
      "classification_loss": 0.5472242832183838,
      "epoch": 13.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4047,
      "total_loss": 0.5472242832183838
    },
    {
      "classification_loss": 0.4708177149295807,
      "epoch": 13.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4048,
      "total_loss": 0.4708177149295807
    },
    {
      "classification_loss": 0.5987157821655273,
      "epoch": 13.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4049,
      "total_loss": 0.5987157821655273
    },
    {
      "classification_loss": 0.5494778752326965,
      "epoch": 13.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4050,
      "total_loss": 0.5494778752326965
    },
    {
      "classification_loss": 0.4604821801185608,
      "epoch": 13.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4051,
      "total_loss": 0.4604821801185608
    },
    {
      "classification_loss": 0.5277498364448547,
      "epoch": 13.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4052,
      "total_loss": 0.5277498364448547
    },
    {
      "classification_loss": 0.5956029295921326,
      "epoch": 13.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4053,
      "total_loss": 0.5956029295921326
    },
    {
      "classification_loss": 0.49869316816329956,
      "epoch": 13.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4054,
      "total_loss": 0.49869316816329956
    },
    {
      "classification_loss": 0.530602753162384,
      "epoch": 13.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4055,
      "total_loss": 0.530602753162384
    },
    {
      "classification_loss": 0.4890933334827423,
      "epoch": 13.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4056,
      "total_loss": 0.4890933334827423
    },
    {
      "classification_loss": 0.45964935421943665,
      "epoch": 13.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4057,
      "total_loss": 0.45964935421943665
    },
    {
      "classification_loss": 0.5021873712539673,
      "epoch": 13.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4058,
      "total_loss": 0.5021873712539673
    },
    {
      "classification_loss": 0.5400785207748413,
      "epoch": 13.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4059,
      "total_loss": 0.5400785207748413
    },
    {
      "classification_loss": 0.43413108587265015,
      "epoch": 13.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4060,
      "total_loss": 0.43413108587265015
    },
    {
      "classification_loss": 0.45400291681289673,
      "epoch": 13.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4061,
      "total_loss": 0.45400291681289673
    },
    {
      "classification_loss": 0.4576936960220337,
      "epoch": 13.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4062,
      "total_loss": 0.4576936960220337
    },
    {
      "classification_loss": 0.524922788143158,
      "epoch": 13.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4063,
      "total_loss": 0.524922788143158
    },
    {
      "classification_loss": 0.5217539072036743,
      "epoch": 13.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4064,
      "total_loss": 0.5217539072036743
    },
    {
      "classification_loss": 0.5408427715301514,
      "epoch": 13.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4065,
      "total_loss": 0.5408427715301514
    },
    {
      "classification_loss": 0.5469903349876404,
      "epoch": 13.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4066,
      "total_loss": 0.5469903349876404
    },
    {
      "classification_loss": 0.5348281264305115,
      "epoch": 13.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4067,
      "total_loss": 0.5348281264305115
    },
    {
      "classification_loss": 0.6378066539764404,
      "epoch": 13.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4068,
      "total_loss": 0.6378066539764404
    },
    {
      "classification_loss": 0.5809779167175293,
      "epoch": 13.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4069,
      "total_loss": 0.5809779167175293
    },
    {
      "classification_loss": 0.5140360593795776,
      "epoch": 13.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4070,
      "total_loss": 0.5140360593795776
    },
    {
      "classification_loss": 0.46734267473220825,
      "epoch": 13.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4071,
      "total_loss": 0.46734267473220825
    },
    {
      "classification_loss": 0.6127943396568298,
      "epoch": 13.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4072,
      "total_loss": 0.6127943396568298
    },
    {
      "classification_loss": 0.39313894510269165,
      "epoch": 13.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4073,
      "total_loss": 0.39313894510269165
    },
    {
      "classification_loss": 0.5549536943435669,
      "epoch": 13.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4074,
      "total_loss": 0.5549536943435669
    },
    {
      "classification_loss": 0.4466589689254761,
      "epoch": 13.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4075,
      "total_loss": 0.4466589689254761
    },
    {
      "classification_loss": 0.4462922215461731,
      "epoch": 13.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4076,
      "total_loss": 0.4462922215461731
    },
    {
      "classification_loss": 0.5101755857467651,
      "epoch": 13.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4077,
      "total_loss": 0.5101755857467651
    },
    {
      "classification_loss": 0.6400394439697266,
      "epoch": 13.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4078,
      "total_loss": 0.6400394439697266
    },
    {
      "classification_loss": 0.5592935681343079,
      "epoch": 13.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4079,
      "total_loss": 0.5592935681343079
    },
    {
      "classification_loss": 0.5999318361282349,
      "epoch": 13.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4080,
      "total_loss": 0.5999318361282349
    },
    {
      "classification_loss": 0.5509443283081055,
      "epoch": 13.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4081,
      "total_loss": 0.5509443283081055
    },
    {
      "classification_loss": 0.5602629780769348,
      "epoch": 13.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4082,
      "total_loss": 0.5602629780769348
    },
    {
      "classification_loss": 0.4280557930469513,
      "epoch": 13.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4083,
      "total_loss": 0.4280557930469513
    },
    {
      "classification_loss": 0.5675225257873535,
      "epoch": 13.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4084,
      "total_loss": 0.5675225257873535
    },
    {
      "classification_loss": 0.5442700982093811,
      "epoch": 13.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4085,
      "total_loss": 0.5442700982093811
    },
    {
      "classification_loss": 0.4254087507724762,
      "epoch": 13.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4086,
      "total_loss": 0.4254087507724762
    },
    {
      "classification_loss": 0.5210984945297241,
      "epoch": 13.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4087,
      "total_loss": 0.5210984945297241
    },
    {
      "classification_loss": 0.44444525241851807,
      "epoch": 13.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4088,
      "total_loss": 0.44444525241851807
    },
    {
      "classification_loss": 0.478808730840683,
      "epoch": 13.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4089,
      "total_loss": 0.478808730840683
    },
    {
      "classification_loss": 0.5137799382209778,
      "epoch": 13.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4090,
      "total_loss": 0.5137799382209778
    },
    {
      "classification_loss": 0.4716576635837555,
      "epoch": 13.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4091,
      "total_loss": 0.4716576635837555
    },
    {
      "classification_loss": 0.4478553235530853,
      "epoch": 13.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4092,
      "total_loss": 0.4478553235530853
    },
    {
      "classification_loss": 0.48420771956443787,
      "epoch": 13.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4093,
      "total_loss": 0.48420771956443787
    },
    {
      "classification_loss": 0.5301187634468079,
      "epoch": 13.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4094,
      "total_loss": 0.5301187634468079
    },
    {
      "classification_loss": 0.4920782446861267,
      "epoch": 13.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4095,
      "total_loss": 0.4920782446861267
    },
    {
      "classification_loss": 0.584419846534729,
      "epoch": 13.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4096,
      "total_loss": 0.584419846534729
    },
    {
      "classification_loss": 0.5296769142150879,
      "epoch": 13.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4097,
      "total_loss": 0.5296769142150879
    },
    {
      "classification_loss": 0.5254337191581726,
      "epoch": 13.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4098,
      "total_loss": 0.5254337191581726
    },
    {
      "classification_loss": 0.6132187843322754,
      "epoch": 13.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4099,
      "total_loss": 0.6132187843322754
    },
    {
      "epoch": 13.442622950819672,
      "grad_norm": 5.011270523071289,
      "learning_rate": 6.670000000000001e-05,
      "loss": 0.5045,
      "step": 4100
    },
    {
      "classification_loss": 0.44511309266090393,
      "epoch": 13.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4100,
      "total_loss": 0.44511309266090393
    },
    {
      "classification_loss": 0.40173330903053284,
      "epoch": 13.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4101,
      "total_loss": 0.40173330903053284
    },
    {
      "classification_loss": 0.4515630304813385,
      "epoch": 13.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4102,
      "total_loss": 0.4515630304813385
    },
    {
      "classification_loss": 0.49901083111763,
      "epoch": 13.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4103,
      "total_loss": 0.49901083111763
    },
    {
      "classification_loss": 0.44568416476249695,
      "epoch": 13.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4104,
      "total_loss": 0.44568416476249695
    },
    {
      "classification_loss": 0.5455937385559082,
      "epoch": 13.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4105,
      "total_loss": 0.5455937385559082
    },
    {
      "classification_loss": 0.5061362385749817,
      "epoch": 13.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4106,
      "total_loss": 0.5061362385749817
    },
    {
      "classification_loss": 0.4940812587738037,
      "epoch": 13.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4107,
      "total_loss": 0.4940812587738037
    },
    {
      "classification_loss": 0.4688369035720825,
      "epoch": 13.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4108,
      "total_loss": 0.4688369035720825
    },
    {
      "classification_loss": 0.45718708634376526,
      "epoch": 13.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4109,
      "total_loss": 0.45718708634376526
    },
    {
      "classification_loss": 0.4489749073982239,
      "epoch": 13.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4110,
      "total_loss": 0.4489749073982239
    },
    {
      "classification_loss": 0.4636717736721039,
      "epoch": 13.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4111,
      "total_loss": 0.4636717736721039
    },
    {
      "classification_loss": 0.5216878056526184,
      "epoch": 13.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4112,
      "total_loss": 0.5216878056526184
    },
    {
      "classification_loss": 0.4707498550415039,
      "epoch": 13.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4113,
      "total_loss": 0.4707498550415039
    },
    {
      "classification_loss": 0.538223385810852,
      "epoch": 13.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4114,
      "total_loss": 0.538223385810852
    },
    {
      "classification_loss": 0.5040995478630066,
      "epoch": 13.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4115,
      "total_loss": 0.5040995478630066
    },
    {
      "classification_loss": 0.48581185936927795,
      "epoch": 13.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4116,
      "total_loss": 0.48581185936927795
    },
    {
      "classification_loss": 0.513787567615509,
      "epoch": 13.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4117,
      "total_loss": 0.513787567615509
    },
    {
      "classification_loss": 0.4773317277431488,
      "epoch": 13.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4118,
      "total_loss": 0.4773317277431488
    },
    {
      "classification_loss": 0.5653969049453735,
      "epoch": 13.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4119,
      "total_loss": 0.5653969049453735
    },
    {
      "classification_loss": 0.3824958801269531,
      "epoch": 13.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4120,
      "total_loss": 0.3824958801269531
    },
    {
      "classification_loss": 0.42317086458206177,
      "epoch": 13.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4121,
      "total_loss": 0.42317086458206177
    },
    {
      "classification_loss": 0.48645493388175964,
      "epoch": 13.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4122,
      "total_loss": 0.48645493388175964
    },
    {
      "classification_loss": 0.5499904155731201,
      "epoch": 13.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4123,
      "total_loss": 0.5499904155731201
    },
    {
      "classification_loss": 0.5301997065544128,
      "epoch": 13.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4124,
      "total_loss": 0.5301997065544128
    },
    {
      "classification_loss": 0.3507173955440521,
      "epoch": 13.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4125,
      "total_loss": 0.3507173955440521
    },
    {
      "classification_loss": 0.46400392055511475,
      "epoch": 13.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4126,
      "total_loss": 0.46400392055511475
    },
    {
      "classification_loss": 0.4290098249912262,
      "epoch": 13.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4127,
      "total_loss": 0.4290098249912262
    },
    {
      "classification_loss": 0.43097251653671265,
      "epoch": 13.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4128,
      "total_loss": 0.43097251653671265
    },
    {
      "classification_loss": 0.46105334162712097,
      "epoch": 13.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4129,
      "total_loss": 0.46105334162712097
    },
    {
      "classification_loss": 0.5761398673057556,
      "epoch": 13.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4130,
      "total_loss": 0.5761398673057556
    },
    {
      "classification_loss": 0.5418669581413269,
      "epoch": 13.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4131,
      "total_loss": 0.5418669581413269
    },
    {
      "classification_loss": 0.41725337505340576,
      "epoch": 13.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4132,
      "total_loss": 0.41725337505340576
    },
    {
      "classification_loss": 0.5364355444908142,
      "epoch": 13.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4133,
      "total_loss": 0.5364355444908142
    },
    {
      "classification_loss": 0.517575204372406,
      "epoch": 13.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4134,
      "total_loss": 0.517575204372406
    },
    {
      "classification_loss": 0.4183984100818634,
      "epoch": 13.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4135,
      "total_loss": 0.4183984100818634
    },
    {
      "classification_loss": 0.40811285376548767,
      "epoch": 13.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4136,
      "total_loss": 0.40811285376548767
    },
    {
      "classification_loss": 0.5590072274208069,
      "epoch": 13.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4137,
      "total_loss": 0.5590072274208069
    },
    {
      "classification_loss": 0.522343635559082,
      "epoch": 13.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4138,
      "total_loss": 0.522343635559082
    },
    {
      "classification_loss": 0.5749589204788208,
      "epoch": 13.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4139,
      "total_loss": 0.5749589204788208
    },
    {
      "classification_loss": 0.45536303520202637,
      "epoch": 13.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4140,
      "total_loss": 0.45536303520202637
    },
    {
      "classification_loss": 0.4523577392101288,
      "epoch": 13.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4141,
      "total_loss": 0.4523577392101288
    },
    {
      "classification_loss": 0.4846172332763672,
      "epoch": 13.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4142,
      "total_loss": 0.4846172332763672
    },
    {
      "classification_loss": 0.4230419397354126,
      "epoch": 13.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4143,
      "total_loss": 0.4230419397354126
    },
    {
      "classification_loss": 0.45448246598243713,
      "epoch": 13.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4144,
      "total_loss": 0.45448246598243713
    },
    {
      "classification_loss": 0.5256075263023376,
      "epoch": 13.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4145,
      "total_loss": 0.5256075263023376
    },
    {
      "classification_loss": 0.5254417061805725,
      "epoch": 13.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4146,
      "total_loss": 0.5254417061805725
    },
    {
      "classification_loss": 0.5502920746803284,
      "epoch": 13.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4147,
      "total_loss": 0.5502920746803284
    },
    {
      "classification_loss": 0.5954965353012085,
      "epoch": 13.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4148,
      "total_loss": 0.5954965353012085
    },
    {
      "classification_loss": 0.5648369193077087,
      "epoch": 13.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4149,
      "total_loss": 0.5648369193077087
    },
    {
      "classification_loss": 0.4684191048145294,
      "epoch": 13.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4150,
      "total_loss": 0.4684191048145294
    },
    {
      "classification_loss": 0.5162039399147034,
      "epoch": 13.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4151,
      "total_loss": 0.5162039399147034
    },
    {
      "classification_loss": 0.4910724461078644,
      "epoch": 13.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4152,
      "total_loss": 0.4910724461078644
    },
    {
      "classification_loss": 0.42743027210235596,
      "epoch": 13.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4153,
      "total_loss": 0.42743027210235596
    },
    {
      "classification_loss": 0.5475562810897827,
      "epoch": 13.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4154,
      "total_loss": 0.5475562810897827
    },
    {
      "classification_loss": 0.48287472128868103,
      "epoch": 13.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4155,
      "total_loss": 0.48287472128868103
    },
    {
      "classification_loss": 0.527048647403717,
      "epoch": 13.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4156,
      "total_loss": 0.527048647403717
    },
    {
      "classification_loss": 0.5260329842567444,
      "epoch": 13.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4157,
      "total_loss": 0.5260329842567444
    },
    {
      "classification_loss": 0.4873068332672119,
      "epoch": 13.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4158,
      "total_loss": 0.4873068332672119
    },
    {
      "classification_loss": 0.5947262644767761,
      "epoch": 13.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4159,
      "total_loss": 0.5947262644767761
    },
    {
      "classification_loss": 0.523922324180603,
      "epoch": 13.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4160,
      "total_loss": 0.523922324180603
    },
    {
      "classification_loss": 0.49450716376304626,
      "epoch": 13.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4161,
      "total_loss": 0.49450716376304626
    },
    {
      "classification_loss": 0.49285152554512024,
      "epoch": 13.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4162,
      "total_loss": 0.49285152554512024
    },
    {
      "classification_loss": 0.4424491226673126,
      "epoch": 13.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4163,
      "total_loss": 0.4424491226673126
    },
    {
      "classification_loss": 0.5738807916641235,
      "epoch": 13.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4164,
      "total_loss": 0.5738807916641235
    },
    {
      "classification_loss": 0.5035802125930786,
      "epoch": 13.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4165,
      "total_loss": 0.5035802125930786
    },
    {
      "classification_loss": 0.5224716067314148,
      "epoch": 13.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4166,
      "total_loss": 0.5224716067314148
    },
    {
      "classification_loss": 0.5112830400466919,
      "epoch": 13.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4167,
      "total_loss": 0.5112830400466919
    },
    {
      "classification_loss": 0.4975115656852722,
      "epoch": 13.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4168,
      "total_loss": 0.4975115656852722
    },
    {
      "classification_loss": 0.6101583242416382,
      "epoch": 13.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4169,
      "total_loss": 0.6101583242416382
    },
    {
      "classification_loss": 0.5969375371932983,
      "epoch": 13.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4170,
      "total_loss": 0.5969375371932983
    },
    {
      "classification_loss": 0.4128219187259674,
      "epoch": 13.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4171,
      "total_loss": 0.4128219187259674
    },
    {
      "classification_loss": 0.514593780040741,
      "epoch": 13.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4172,
      "total_loss": 0.514593780040741
    },
    {
      "classification_loss": 0.5668172836303711,
      "epoch": 13.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4173,
      "total_loss": 0.5668172836303711
    },
    {
      "classification_loss": 0.47062164545059204,
      "epoch": 13.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4174,
      "total_loss": 0.47062164545059204
    },
    {
      "classification_loss": 0.5282190442085266,
      "epoch": 13.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4175,
      "total_loss": 0.5282190442085266
    },
    {
      "classification_loss": 0.5615265369415283,
      "epoch": 13.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4176,
      "total_loss": 0.5615265369415283
    },
    {
      "classification_loss": 0.4555566608905792,
      "epoch": 13.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4177,
      "total_loss": 0.4555566608905792
    },
    {
      "classification_loss": 0.46588265895843506,
      "epoch": 13.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4178,
      "total_loss": 0.46588265895843506
    },
    {
      "classification_loss": 0.4960823655128479,
      "epoch": 13.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4179,
      "total_loss": 0.4960823655128479
    },
    {
      "classification_loss": 0.46958377957344055,
      "epoch": 13.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4180,
      "total_loss": 0.46958377957344055
    },
    {
      "classification_loss": 0.6092825531959534,
      "epoch": 13.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4181,
      "total_loss": 0.6092825531959534
    },
    {
      "classification_loss": 0.40577182173728943,
      "epoch": 13.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4182,
      "total_loss": 0.40577182173728943
    },
    {
      "classification_loss": 0.7692617774009705,
      "epoch": 13.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4183,
      "total_loss": 0.7692617774009705
    },
    {
      "classification_loss": 0.476235568523407,
      "epoch": 13.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4184,
      "total_loss": 0.476235568523407
    },
    {
      "classification_loss": 0.5322825312614441,
      "epoch": 13.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4185,
      "total_loss": 0.5322825312614441
    },
    {
      "classification_loss": 0.51583331823349,
      "epoch": 13.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4186,
      "total_loss": 0.51583331823349
    },
    {
      "classification_loss": 0.4915167987346649,
      "epoch": 13.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4187,
      "total_loss": 0.4915167987346649
    },
    {
      "classification_loss": 0.46940603852272034,
      "epoch": 13.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4188,
      "total_loss": 0.46940603852272034
    },
    {
      "classification_loss": 0.42147472500801086,
      "epoch": 13.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4189,
      "total_loss": 0.42147472500801086
    },
    {
      "classification_loss": 0.6068501472473145,
      "epoch": 13.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4190,
      "total_loss": 0.6068501472473145
    },
    {
      "classification_loss": 0.4361307919025421,
      "epoch": 13.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4191,
      "total_loss": 0.4361307919025421
    },
    {
      "classification_loss": 0.5145301818847656,
      "epoch": 13.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4192,
      "total_loss": 0.5145301818847656
    },
    {
      "classification_loss": 0.484024316072464,
      "epoch": 13.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4193,
      "total_loss": 0.484024316072464
    },
    {
      "classification_loss": 0.4761311113834381,
      "epoch": 13.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4194,
      "total_loss": 0.4761311113834381
    },
    {
      "classification_loss": 0.39327025413513184,
      "epoch": 13.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4195,
      "total_loss": 0.39327025413513184
    },
    {
      "classification_loss": 0.41773152351379395,
      "epoch": 13.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4196,
      "total_loss": 0.41773152351379395
    },
    {
      "classification_loss": 0.48579204082489014,
      "epoch": 13.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4197,
      "total_loss": 0.48579204082489014
    },
    {
      "classification_loss": 0.6589035391807556,
      "epoch": 13.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4198,
      "total_loss": 0.6589035391807556
    },
    {
      "classification_loss": 0.4488253891468048,
      "epoch": 13.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4199,
      "total_loss": 0.4488253891468048
    },
    {
      "epoch": 13.770491803278688,
      "grad_norm": 2.0471770763397217,
      "learning_rate": 6.336666666666667e-05,
      "loss": 0.4971,
      "step": 4200
    },
    {
      "classification_loss": 0.4927680790424347,
      "epoch": 13.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4200,
      "total_loss": 0.4927680790424347
    },
    {
      "classification_loss": 0.39745137095451355,
      "epoch": 13.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4201,
      "total_loss": 0.39745137095451355
    },
    {
      "classification_loss": 0.5487041473388672,
      "epoch": 13.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4202,
      "total_loss": 0.5487041473388672
    },
    {
      "classification_loss": 0.47761496901512146,
      "epoch": 13.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4203,
      "total_loss": 0.47761496901512146
    },
    {
      "classification_loss": 0.4614180326461792,
      "epoch": 13.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4204,
      "total_loss": 0.4614180326461792
    },
    {
      "classification_loss": 0.5691576600074768,
      "epoch": 13.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4205,
      "total_loss": 0.5691576600074768
    },
    {
      "classification_loss": 0.6463402509689331,
      "epoch": 13.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4206,
      "total_loss": 0.6463402509689331
    },
    {
      "classification_loss": 0.5204415917396545,
      "epoch": 13.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4207,
      "total_loss": 0.5204415917396545
    },
    {
      "classification_loss": 0.5120370984077454,
      "epoch": 13.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4208,
      "total_loss": 0.5120370984077454
    },
    {
      "classification_loss": 0.42668992280960083,
      "epoch": 13.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4209,
      "total_loss": 0.42668992280960083
    },
    {
      "classification_loss": 0.5026845335960388,
      "epoch": 13.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4210,
      "total_loss": 0.5026845335960388
    },
    {
      "classification_loss": 0.6375883221626282,
      "epoch": 13.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4211,
      "total_loss": 0.6375883221626282
    },
    {
      "classification_loss": 0.4535788297653198,
      "epoch": 13.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4212,
      "total_loss": 0.4535788297653198
    },
    {
      "classification_loss": 0.5377675294876099,
      "epoch": 13.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4213,
      "total_loss": 0.5377675294876099
    },
    {
      "classification_loss": 0.672599732875824,
      "epoch": 13.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4214,
      "total_loss": 0.672599732875824
    },
    {
      "classification_loss": 0.45690208673477173,
      "epoch": 13.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4215,
      "total_loss": 0.45690208673477173
    },
    {
      "classification_loss": 0.4846758544445038,
      "epoch": 13.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4216,
      "total_loss": 0.4846758544445038
    },
    {
      "classification_loss": 0.5170856714248657,
      "epoch": 13.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4217,
      "total_loss": 0.5170856714248657
    },
    {
      "classification_loss": 0.5968883037567139,
      "epoch": 13.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4218,
      "total_loss": 0.5968883037567139
    },
    {
      "classification_loss": 0.5168989896774292,
      "epoch": 13.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4219,
      "total_loss": 0.5168989896774292
    },
    {
      "classification_loss": 0.44585350155830383,
      "epoch": 13.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4220,
      "total_loss": 0.44585350155830383
    },
    {
      "classification_loss": 0.5123683214187622,
      "epoch": 13.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4221,
      "total_loss": 0.5123683214187622
    },
    {
      "classification_loss": 0.44387510418891907,
      "epoch": 13.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4222,
      "total_loss": 0.44387510418891907
    },
    {
      "classification_loss": 0.5094762444496155,
      "epoch": 13.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4223,
      "total_loss": 0.5094762444496155
    },
    {
      "classification_loss": 0.521549642086029,
      "epoch": 13.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4224,
      "total_loss": 0.521549642086029
    },
    {
      "classification_loss": 0.5287794470787048,
      "epoch": 13.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4225,
      "total_loss": 0.5287794470787048
    },
    {
      "classification_loss": 0.5248768925666809,
      "epoch": 13.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4226,
      "total_loss": 0.5248768925666809
    },
    {
      "classification_loss": 0.4318316876888275,
      "epoch": 13.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4227,
      "total_loss": 0.4318316876888275
    },
    {
      "classification_loss": 0.5160222053527832,
      "epoch": 13.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4228,
      "total_loss": 0.5160222053527832
    },
    {
      "classification_loss": 0.47534769773483276,
      "epoch": 13.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4229,
      "total_loss": 0.47534769773483276
    },
    {
      "classification_loss": 0.47193074226379395,
      "epoch": 13.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4230,
      "total_loss": 0.47193074226379395
    },
    {
      "classification_loss": 0.4449710249900818,
      "epoch": 13.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4231,
      "total_loss": 0.4449710249900818
    },
    {
      "classification_loss": 0.6168580651283264,
      "epoch": 13.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4232,
      "total_loss": 0.6168580651283264
    },
    {
      "classification_loss": 0.5507241487503052,
      "epoch": 13.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4233,
      "total_loss": 0.5507241487503052
    },
    {
      "classification_loss": 0.4269886016845703,
      "epoch": 13.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4234,
      "total_loss": 0.4269886016845703
    },
    {
      "classification_loss": 0.4924097955226898,
      "epoch": 13.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4235,
      "total_loss": 0.4924097955226898
    },
    {
      "classification_loss": 0.4440977871417999,
      "epoch": 13.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4236,
      "total_loss": 0.4440977871417999
    },
    {
      "classification_loss": 0.4475119411945343,
      "epoch": 13.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4237,
      "total_loss": 0.4475119411945343
    },
    {
      "classification_loss": 0.5594527721405029,
      "epoch": 13.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4238,
      "total_loss": 0.5594527721405029
    },
    {
      "classification_loss": 0.44401976466178894,
      "epoch": 13.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4239,
      "total_loss": 0.44401976466178894
    },
    {
      "classification_loss": 0.510798454284668,
      "epoch": 13.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4240,
      "total_loss": 0.510798454284668
    },
    {
      "classification_loss": 0.564009428024292,
      "epoch": 13.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4241,
      "total_loss": 0.564009428024292
    },
    {
      "classification_loss": 0.5403923392295837,
      "epoch": 13.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4242,
      "total_loss": 0.5403923392295837
    },
    {
      "classification_loss": 0.49400097131729126,
      "epoch": 13.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4243,
      "total_loss": 0.49400097131729126
    },
    {
      "classification_loss": 0.5293446779251099,
      "epoch": 13.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4244,
      "total_loss": 0.5293446779251099
    },
    {
      "classification_loss": 0.37555062770843506,
      "epoch": 13.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4245,
      "total_loss": 0.37555062770843506
    },
    {
      "classification_loss": 0.4642302095890045,
      "epoch": 13.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4246,
      "total_loss": 0.4642302095890045
    },
    {
      "classification_loss": 0.5261225700378418,
      "epoch": 13.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4247,
      "total_loss": 0.5261225700378418
    },
    {
      "classification_loss": 0.5702124834060669,
      "epoch": 13.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4248,
      "total_loss": 0.5702124834060669
    },
    {
      "classification_loss": 0.4771704077720642,
      "epoch": 13.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4249,
      "total_loss": 0.4771704077720642
    },
    {
      "classification_loss": 0.4835054278373718,
      "epoch": 13.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4250,
      "total_loss": 0.4835054278373718
    },
    {
      "classification_loss": 0.4307333528995514,
      "epoch": 13.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4251,
      "total_loss": 0.4307333528995514
    },
    {
      "classification_loss": 0.5076484084129333,
      "epoch": 13.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4252,
      "total_loss": 0.5076484084129333
    },
    {
      "classification_loss": 0.5513827204704285,
      "epoch": 13.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4253,
      "total_loss": 0.5513827204704285
    },
    {
      "classification_loss": 0.5409956574440002,
      "epoch": 13.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4254,
      "total_loss": 0.5409956574440002
    },
    {
      "classification_loss": 0.5751200318336487,
      "epoch": 13.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4255,
      "total_loss": 0.5751200318336487
    },
    {
      "classification_loss": 0.4905782639980316,
      "epoch": 13.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4256,
      "total_loss": 0.4905782639980316
    },
    {
      "classification_loss": 0.512112021446228,
      "epoch": 13.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4257,
      "total_loss": 0.512112021446228
    },
    {
      "classification_loss": 0.5067369937896729,
      "epoch": 13.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4258,
      "total_loss": 0.5067369937896729
    },
    {
      "classification_loss": 0.5463883280754089,
      "epoch": 13.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4259,
      "total_loss": 0.5463883280754089
    },
    {
      "classification_loss": 0.4988252818584442,
      "epoch": 13.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4260,
      "total_loss": 0.4988252818584442
    },
    {
      "classification_loss": 0.4570406675338745,
      "epoch": 13.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4261,
      "total_loss": 0.4570406675338745
    },
    {
      "classification_loss": 0.5171557664871216,
      "epoch": 13.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4262,
      "total_loss": 0.5171557664871216
    },
    {
      "classification_loss": 0.3417873978614807,
      "epoch": 13.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4263,
      "total_loss": 0.3417873978614807
    },
    {
      "classification_loss": 0.48450204730033875,
      "epoch": 13.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4264,
      "total_loss": 0.48450204730033875
    },
    {
      "classification_loss": 0.7407434582710266,
      "epoch": 13.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4265,
      "total_loss": 0.7407434582710266
    },
    {
      "classification_loss": 0.4499565660953522,
      "epoch": 13.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4266,
      "total_loss": 0.4499565660953522
    },
    {
      "classification_loss": 0.4928438663482666,
      "epoch": 13.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4267,
      "total_loss": 0.4928438663482666
    },
    {
      "classification_loss": 0.4342941343784332,
      "epoch": 13.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4268,
      "total_loss": 0.4342941343784332
    },
    {
      "classification_loss": 0.5045384764671326,
      "epoch": 13.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4269,
      "total_loss": 0.5045384764671326
    },
    {
      "classification_loss": 1.4594539403915405,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.4594539403915405
    },
    {
      "classification_loss": 1.3925877809524536,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.3925877809524536
    },
    {
      "classification_loss": 1.2792644500732422,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.2792644500732422
    },
    {
      "classification_loss": 1.5845664739608765,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.5845664739608765
    },
    {
      "classification_loss": 1.3057137727737427,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.3057137727737427
    },
    {
      "classification_loss": 1.279724359512329,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.279724359512329
    },
    {
      "classification_loss": 1.3666858673095703,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.3666858673095703
    },
    {
      "classification_loss": 1.171428918838501,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 1.171428918838501
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.3593320846557617,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0316,
      "eval_samples_per_second": 165.794,
      "eval_steps_per_second": 1.326,
      "step": 4270
    },
    {
      "classification_loss": 0.47090381383895874,
      "epoch": 14.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4270,
      "total_loss": 0.47090381383895874
    },
    {
      "classification_loss": 0.5037862062454224,
      "epoch": 14.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4271,
      "total_loss": 0.5037862062454224
    },
    {
      "classification_loss": 0.49913835525512695,
      "epoch": 14.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4272,
      "total_loss": 0.49913835525512695
    },
    {
      "classification_loss": 0.4110943078994751,
      "epoch": 14.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4273,
      "total_loss": 0.4110943078994751
    },
    {
      "classification_loss": 0.42742857336997986,
      "epoch": 14.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4274,
      "total_loss": 0.42742857336997986
    },
    {
      "classification_loss": 0.4433046877384186,
      "epoch": 14.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4275,
      "total_loss": 0.4433046877384186
    },
    {
      "classification_loss": 0.5838263034820557,
      "epoch": 14.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4276,
      "total_loss": 0.5838263034820557
    },
    {
      "classification_loss": 0.46781179308891296,
      "epoch": 14.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4277,
      "total_loss": 0.46781179308891296
    },
    {
      "classification_loss": 0.42915594577789307,
      "epoch": 14.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4278,
      "total_loss": 0.42915594577789307
    },
    {
      "classification_loss": 0.5673881769180298,
      "epoch": 14.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4279,
      "total_loss": 0.5673881769180298
    },
    {
      "classification_loss": 0.414989709854126,
      "epoch": 14.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4280,
      "total_loss": 0.414989709854126
    },
    {
      "classification_loss": 0.5409266352653503,
      "epoch": 14.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4281,
      "total_loss": 0.5409266352653503
    },
    {
      "classification_loss": 0.4924386739730835,
      "epoch": 14.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4282,
      "total_loss": 0.4924386739730835
    },
    {
      "classification_loss": 0.4230496883392334,
      "epoch": 14.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4283,
      "total_loss": 0.4230496883392334
    },
    {
      "classification_loss": 0.6261221170425415,
      "epoch": 14.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4284,
      "total_loss": 0.6261221170425415
    },
    {
      "classification_loss": 0.44023817777633667,
      "epoch": 14.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4285,
      "total_loss": 0.44023817777633667
    },
    {
      "classification_loss": 0.38674578070640564,
      "epoch": 14.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4286,
      "total_loss": 0.38674578070640564
    },
    {
      "classification_loss": 0.477866530418396,
      "epoch": 14.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4287,
      "total_loss": 0.477866530418396
    },
    {
      "classification_loss": 0.37626129388809204,
      "epoch": 14.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4288,
      "total_loss": 0.37626129388809204
    },
    {
      "classification_loss": 0.5152627229690552,
      "epoch": 14.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4289,
      "total_loss": 0.5152627229690552
    },
    {
      "classification_loss": 0.4717426300048828,
      "epoch": 14.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4290,
      "total_loss": 0.4717426300048828
    },
    {
      "classification_loss": 0.4729452431201935,
      "epoch": 14.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4291,
      "total_loss": 0.4729452431201935
    },
    {
      "classification_loss": 0.457906037569046,
      "epoch": 14.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4292,
      "total_loss": 0.457906037569046
    },
    {
      "classification_loss": 0.48675310611724854,
      "epoch": 14.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4293,
      "total_loss": 0.48675310611724854
    },
    {
      "classification_loss": 0.5527383089065552,
      "epoch": 14.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4294,
      "total_loss": 0.5527383089065552
    },
    {
      "classification_loss": 0.5471757650375366,
      "epoch": 14.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4295,
      "total_loss": 0.5471757650375366
    },
    {
      "classification_loss": 0.5210289359092712,
      "epoch": 14.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4296,
      "total_loss": 0.5210289359092712
    },
    {
      "classification_loss": 0.5500873923301697,
      "epoch": 14.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4297,
      "total_loss": 0.5500873923301697
    },
    {
      "classification_loss": 0.4189600944519043,
      "epoch": 14.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4298,
      "total_loss": 0.4189600944519043
    },
    {
      "classification_loss": 0.4878149926662445,
      "epoch": 14.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4299,
      "total_loss": 0.4878149926662445
    },
    {
      "epoch": 14.098360655737705,
      "grad_norm": 9.407206535339355,
      "learning_rate": 6.003333333333334e-05,
      "loss": 0.4982,
      "step": 4300
    },
    {
      "classification_loss": 0.5964123010635376,
      "epoch": 14.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4300,
      "total_loss": 0.5964123010635376
    },
    {
      "classification_loss": 0.5386185646057129,
      "epoch": 14.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4301,
      "total_loss": 0.5386185646057129
    },
    {
      "classification_loss": 0.5326945185661316,
      "epoch": 14.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4302,
      "total_loss": 0.5326945185661316
    },
    {
      "classification_loss": 0.5255881547927856,
      "epoch": 14.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4303,
      "total_loss": 0.5255881547927856
    },
    {
      "classification_loss": 0.5322799682617188,
      "epoch": 14.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4304,
      "total_loss": 0.5322799682617188
    },
    {
      "classification_loss": 0.4049673080444336,
      "epoch": 14.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4305,
      "total_loss": 0.4049673080444336
    },
    {
      "classification_loss": 0.43452396988868713,
      "epoch": 14.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4306,
      "total_loss": 0.43452396988868713
    },
    {
      "classification_loss": 0.6010621190071106,
      "epoch": 14.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4307,
      "total_loss": 0.6010621190071106
    },
    {
      "classification_loss": 0.5297679305076599,
      "epoch": 14.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4308,
      "total_loss": 0.5297679305076599
    },
    {
      "classification_loss": 0.4644378423690796,
      "epoch": 14.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4309,
      "total_loss": 0.4644378423690796
    },
    {
      "classification_loss": 0.5652788281440735,
      "epoch": 14.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4310,
      "total_loss": 0.5652788281440735
    },
    {
      "classification_loss": 0.5369836688041687,
      "epoch": 14.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4311,
      "total_loss": 0.5369836688041687
    },
    {
      "classification_loss": 0.5130319595336914,
      "epoch": 14.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4312,
      "total_loss": 0.5130319595336914
    },
    {
      "classification_loss": 0.5089904069900513,
      "epoch": 14.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4313,
      "total_loss": 0.5089904069900513
    },
    {
      "classification_loss": 0.4644201695919037,
      "epoch": 14.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4314,
      "total_loss": 0.4644201695919037
    },
    {
      "classification_loss": 0.5445089340209961,
      "epoch": 14.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4315,
      "total_loss": 0.5445089340209961
    },
    {
      "classification_loss": 0.43070095777511597,
      "epoch": 14.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4316,
      "total_loss": 0.43070095777511597
    },
    {
      "classification_loss": 0.4153176248073578,
      "epoch": 14.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4317,
      "total_loss": 0.4153176248073578
    },
    {
      "classification_loss": 0.49361446499824524,
      "epoch": 14.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4318,
      "total_loss": 0.49361446499824524
    },
    {
      "classification_loss": 0.5118064880371094,
      "epoch": 14.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4319,
      "total_loss": 0.5118064880371094
    },
    {
      "classification_loss": 0.4888233542442322,
      "epoch": 14.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4320,
      "total_loss": 0.4888233542442322
    },
    {
      "classification_loss": 0.4648274779319763,
      "epoch": 14.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4321,
      "total_loss": 0.4648274779319763
    },
    {
      "classification_loss": 0.5492948293685913,
      "epoch": 14.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4322,
      "total_loss": 0.5492948293685913
    },
    {
      "classification_loss": 0.5203582048416138,
      "epoch": 14.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4323,
      "total_loss": 0.5203582048416138
    },
    {
      "classification_loss": 0.4575172960758209,
      "epoch": 14.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4324,
      "total_loss": 0.4575172960758209
    },
    {
      "classification_loss": 0.40992018580436707,
      "epoch": 14.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4325,
      "total_loss": 0.40992018580436707
    },
    {
      "classification_loss": 0.5552701950073242,
      "epoch": 14.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4326,
      "total_loss": 0.5552701950073242
    },
    {
      "classification_loss": 0.505172610282898,
      "epoch": 14.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4327,
      "total_loss": 0.505172610282898
    },
    {
      "classification_loss": 0.42575961351394653,
      "epoch": 14.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4328,
      "total_loss": 0.42575961351394653
    },
    {
      "classification_loss": 0.40564867854118347,
      "epoch": 14.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4329,
      "total_loss": 0.40564867854118347
    },
    {
      "classification_loss": 0.5042856931686401,
      "epoch": 14.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4330,
      "total_loss": 0.5042856931686401
    },
    {
      "classification_loss": 0.5005970597267151,
      "epoch": 14.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4331,
      "total_loss": 0.5005970597267151
    },
    {
      "classification_loss": 0.3581388592720032,
      "epoch": 14.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4332,
      "total_loss": 0.3581388592720032
    },
    {
      "classification_loss": 0.46781203150749207,
      "epoch": 14.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4333,
      "total_loss": 0.46781203150749207
    },
    {
      "classification_loss": 0.384010374546051,
      "epoch": 14.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4334,
      "total_loss": 0.384010374546051
    },
    {
      "classification_loss": 0.45593488216400146,
      "epoch": 14.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4335,
      "total_loss": 0.45593488216400146
    },
    {
      "classification_loss": 0.4378299117088318,
      "epoch": 14.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4336,
      "total_loss": 0.4378299117088318
    },
    {
      "classification_loss": 0.49053966999053955,
      "epoch": 14.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4337,
      "total_loss": 0.49053966999053955
    },
    {
      "classification_loss": 0.5578229427337646,
      "epoch": 14.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4338,
      "total_loss": 0.5578229427337646
    },
    {
      "classification_loss": 0.46780428290367126,
      "epoch": 14.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4339,
      "total_loss": 0.46780428290367126
    },
    {
      "classification_loss": 0.525784969329834,
      "epoch": 14.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4340,
      "total_loss": 0.525784969329834
    },
    {
      "classification_loss": 0.4812765121459961,
      "epoch": 14.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4341,
      "total_loss": 0.4812765121459961
    },
    {
      "classification_loss": 0.41815924644470215,
      "epoch": 14.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4342,
      "total_loss": 0.41815924644470215
    },
    {
      "classification_loss": 0.4737517535686493,
      "epoch": 14.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4343,
      "total_loss": 0.4737517535686493
    },
    {
      "classification_loss": 0.53839111328125,
      "epoch": 14.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4344,
      "total_loss": 0.53839111328125
    },
    {
      "classification_loss": 0.517730176448822,
      "epoch": 14.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4345,
      "total_loss": 0.517730176448822
    },
    {
      "classification_loss": 0.511628270149231,
      "epoch": 14.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4346,
      "total_loss": 0.511628270149231
    },
    {
      "classification_loss": 0.5591030120849609,
      "epoch": 14.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4347,
      "total_loss": 0.5591030120849609
    },
    {
      "classification_loss": 0.48761725425720215,
      "epoch": 14.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4348,
      "total_loss": 0.48761725425720215
    },
    {
      "classification_loss": 0.4567500948905945,
      "epoch": 14.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4349,
      "total_loss": 0.4567500948905945
    },
    {
      "classification_loss": 0.5127284526824951,
      "epoch": 14.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4350,
      "total_loss": 0.5127284526824951
    },
    {
      "classification_loss": 0.4940010607242584,
      "epoch": 14.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4351,
      "total_loss": 0.4940010607242584
    },
    {
      "classification_loss": 0.4660974144935608,
      "epoch": 14.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4352,
      "total_loss": 0.4660974144935608
    },
    {
      "classification_loss": 0.39827853441238403,
      "epoch": 14.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4353,
      "total_loss": 0.39827853441238403
    },
    {
      "classification_loss": 0.44616207480430603,
      "epoch": 14.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4354,
      "total_loss": 0.44616207480430603
    },
    {
      "classification_loss": 0.427913099527359,
      "epoch": 14.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4355,
      "total_loss": 0.427913099527359
    },
    {
      "classification_loss": 0.4605768620967865,
      "epoch": 14.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4356,
      "total_loss": 0.4605768620967865
    },
    {
      "classification_loss": 0.42600756883621216,
      "epoch": 14.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4357,
      "total_loss": 0.42600756883621216
    },
    {
      "classification_loss": 0.49110153317451477,
      "epoch": 14.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4358,
      "total_loss": 0.49110153317451477
    },
    {
      "classification_loss": 0.4459620416164398,
      "epoch": 14.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4359,
      "total_loss": 0.4459620416164398
    },
    {
      "classification_loss": 0.4412800967693329,
      "epoch": 14.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4360,
      "total_loss": 0.4412800967693329
    },
    {
      "classification_loss": 0.4346994161605835,
      "epoch": 14.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4361,
      "total_loss": 0.4346994161605835
    },
    {
      "classification_loss": 0.48035940527915955,
      "epoch": 14.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4362,
      "total_loss": 0.48035940527915955
    },
    {
      "classification_loss": 0.45082253217697144,
      "epoch": 14.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4363,
      "total_loss": 0.45082253217697144
    },
    {
      "classification_loss": 0.5327374339103699,
      "epoch": 14.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4364,
      "total_loss": 0.5327374339103699
    },
    {
      "classification_loss": 0.4466026723384857,
      "epoch": 14.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4365,
      "total_loss": 0.4466026723384857
    },
    {
      "classification_loss": 0.5304703116416931,
      "epoch": 14.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4366,
      "total_loss": 0.5304703116416931
    },
    {
      "classification_loss": 0.3845662772655487,
      "epoch": 14.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4367,
      "total_loss": 0.3845662772655487
    },
    {
      "classification_loss": 0.42928120493888855,
      "epoch": 14.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4368,
      "total_loss": 0.42928120493888855
    },
    {
      "classification_loss": 0.4329742193222046,
      "epoch": 14.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4369,
      "total_loss": 0.4329742193222046
    },
    {
      "classification_loss": 0.5455375909805298,
      "epoch": 14.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4370,
      "total_loss": 0.5455375909805298
    },
    {
      "classification_loss": 0.4904404878616333,
      "epoch": 14.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4371,
      "total_loss": 0.4904404878616333
    },
    {
      "classification_loss": 0.5236863493919373,
      "epoch": 14.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4372,
      "total_loss": 0.5236863493919373
    },
    {
      "classification_loss": 0.521845817565918,
      "epoch": 14.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4373,
      "total_loss": 0.521845817565918
    },
    {
      "classification_loss": 0.41959133744239807,
      "epoch": 14.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4374,
      "total_loss": 0.41959133744239807
    },
    {
      "classification_loss": 0.4988008141517639,
      "epoch": 14.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4375,
      "total_loss": 0.4988008141517639
    },
    {
      "classification_loss": 0.6505768299102783,
      "epoch": 14.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4376,
      "total_loss": 0.6505768299102783
    },
    {
      "classification_loss": 0.4986475110054016,
      "epoch": 14.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4377,
      "total_loss": 0.4986475110054016
    },
    {
      "classification_loss": 0.46468573808670044,
      "epoch": 14.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4378,
      "total_loss": 0.46468573808670044
    },
    {
      "classification_loss": 0.44242438673973083,
      "epoch": 14.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4379,
      "total_loss": 0.44242438673973083
    },
    {
      "classification_loss": 0.46368056535720825,
      "epoch": 14.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4380,
      "total_loss": 0.46368056535720825
    },
    {
      "classification_loss": 0.4577747583389282,
      "epoch": 14.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4381,
      "total_loss": 0.4577747583389282
    },
    {
      "classification_loss": 0.4727718234062195,
      "epoch": 14.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4382,
      "total_loss": 0.4727718234062195
    },
    {
      "classification_loss": 0.5460659265518188,
      "epoch": 14.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4383,
      "total_loss": 0.5460659265518188
    },
    {
      "classification_loss": 0.5497384071350098,
      "epoch": 14.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4384,
      "total_loss": 0.5497384071350098
    },
    {
      "classification_loss": 0.439922958612442,
      "epoch": 14.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4385,
      "total_loss": 0.439922958612442
    },
    {
      "classification_loss": 0.51437908411026,
      "epoch": 14.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4386,
      "total_loss": 0.51437908411026
    },
    {
      "classification_loss": 0.5035186409950256,
      "epoch": 14.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4387,
      "total_loss": 0.5035186409950256
    },
    {
      "classification_loss": 0.43875059485435486,
      "epoch": 14.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4388,
      "total_loss": 0.43875059485435486
    },
    {
      "classification_loss": 0.5318362712860107,
      "epoch": 14.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4389,
      "total_loss": 0.5318362712860107
    },
    {
      "classification_loss": 0.48625460267066956,
      "epoch": 14.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4390,
      "total_loss": 0.48625460267066956
    },
    {
      "classification_loss": 0.5808608531951904,
      "epoch": 14.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4391,
      "total_loss": 0.5808608531951904
    },
    {
      "classification_loss": 0.41692954301834106,
      "epoch": 14.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4392,
      "total_loss": 0.41692954301834106
    },
    {
      "classification_loss": 0.4956337511539459,
      "epoch": 14.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4393,
      "total_loss": 0.4956337511539459
    },
    {
      "classification_loss": 0.43104276061058044,
      "epoch": 14.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4394,
      "total_loss": 0.43104276061058044
    },
    {
      "classification_loss": 0.4508121907711029,
      "epoch": 14.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4395,
      "total_loss": 0.4508121907711029
    },
    {
      "classification_loss": 0.5635393857955933,
      "epoch": 14.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4396,
      "total_loss": 0.5635393857955933
    },
    {
      "classification_loss": 0.5259109735488892,
      "epoch": 14.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4397,
      "total_loss": 0.5259109735488892
    },
    {
      "classification_loss": 0.4599400460720062,
      "epoch": 14.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4398,
      "total_loss": 0.4599400460720062
    },
    {
      "classification_loss": 0.5157333016395569,
      "epoch": 14.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4399,
      "total_loss": 0.5157333016395569
    },
    {
      "epoch": 14.426229508196721,
      "grad_norm": 3.5583608150482178,
      "learning_rate": 5.6699999999999996e-05,
      "loss": 0.4856,
      "step": 4400
    },
    {
      "classification_loss": 0.39174389839172363,
      "epoch": 14.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4400,
      "total_loss": 0.39174389839172363
    },
    {
      "classification_loss": 0.4632032811641693,
      "epoch": 14.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4401,
      "total_loss": 0.4632032811641693
    },
    {
      "classification_loss": 0.4744209349155426,
      "epoch": 14.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4402,
      "total_loss": 0.4744209349155426
    },
    {
      "classification_loss": 0.4052504301071167,
      "epoch": 14.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4403,
      "total_loss": 0.4052504301071167
    },
    {
      "classification_loss": 0.38331931829452515,
      "epoch": 14.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4404,
      "total_loss": 0.38331931829452515
    },
    {
      "classification_loss": 0.5286383628845215,
      "epoch": 14.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4405,
      "total_loss": 0.5286383628845215
    },
    {
      "classification_loss": 0.3665016293525696,
      "epoch": 14.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4406,
      "total_loss": 0.3665016293525696
    },
    {
      "classification_loss": 0.5261944532394409,
      "epoch": 14.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4407,
      "total_loss": 0.5261944532394409
    },
    {
      "classification_loss": 0.5194829106330872,
      "epoch": 14.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4408,
      "total_loss": 0.5194829106330872
    },
    {
      "classification_loss": 0.55523681640625,
      "epoch": 14.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4409,
      "total_loss": 0.55523681640625
    },
    {
      "classification_loss": 0.427969753742218,
      "epoch": 14.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4410,
      "total_loss": 0.427969753742218
    },
    {
      "classification_loss": 0.47285252809524536,
      "epoch": 14.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4411,
      "total_loss": 0.47285252809524536
    },
    {
      "classification_loss": 0.5659176111221313,
      "epoch": 14.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4412,
      "total_loss": 0.5659176111221313
    },
    {
      "classification_loss": 0.5259534120559692,
      "epoch": 14.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4413,
      "total_loss": 0.5259534120559692
    },
    {
      "classification_loss": 0.4843628406524658,
      "epoch": 14.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4414,
      "total_loss": 0.4843628406524658
    },
    {
      "classification_loss": 0.5453277230262756,
      "epoch": 14.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4415,
      "total_loss": 0.5453277230262756
    },
    {
      "classification_loss": 0.5736134648323059,
      "epoch": 14.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4416,
      "total_loss": 0.5736134648323059
    },
    {
      "classification_loss": 0.3861754834651947,
      "epoch": 14.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4417,
      "total_loss": 0.3861754834651947
    },
    {
      "classification_loss": 0.4978468120098114,
      "epoch": 14.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4418,
      "total_loss": 0.4978468120098114
    },
    {
      "classification_loss": 0.5000290870666504,
      "epoch": 14.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4419,
      "total_loss": 0.5000290870666504
    },
    {
      "classification_loss": 0.5972808003425598,
      "epoch": 14.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4420,
      "total_loss": 0.5972808003425598
    },
    {
      "classification_loss": 0.45462775230407715,
      "epoch": 14.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4421,
      "total_loss": 0.45462775230407715
    },
    {
      "classification_loss": 0.3838020861148834,
      "epoch": 14.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4422,
      "total_loss": 0.3838020861148834
    },
    {
      "classification_loss": 0.49961617588996887,
      "epoch": 14.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4423,
      "total_loss": 0.49961617588996887
    },
    {
      "classification_loss": 0.4704190194606781,
      "epoch": 14.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4424,
      "total_loss": 0.4704190194606781
    },
    {
      "classification_loss": 0.5938969254493713,
      "epoch": 14.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4425,
      "total_loss": 0.5938969254493713
    },
    {
      "classification_loss": 0.5456703305244446,
      "epoch": 14.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4426,
      "total_loss": 0.5456703305244446
    },
    {
      "classification_loss": 0.5918775796890259,
      "epoch": 14.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4427,
      "total_loss": 0.5918775796890259
    },
    {
      "classification_loss": 0.47330647706985474,
      "epoch": 14.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4428,
      "total_loss": 0.47330647706985474
    },
    {
      "classification_loss": 0.6904550194740295,
      "epoch": 14.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4429,
      "total_loss": 0.6904550194740295
    },
    {
      "classification_loss": 0.5618271827697754,
      "epoch": 14.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4430,
      "total_loss": 0.5618271827697754
    },
    {
      "classification_loss": 0.6201024055480957,
      "epoch": 14.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4431,
      "total_loss": 0.6201024055480957
    },
    {
      "classification_loss": 0.5703907608985901,
      "epoch": 14.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4432,
      "total_loss": 0.5703907608985901
    },
    {
      "classification_loss": 0.4958845376968384,
      "epoch": 14.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4433,
      "total_loss": 0.4958845376968384
    },
    {
      "classification_loss": 0.4891321659088135,
      "epoch": 14.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4434,
      "total_loss": 0.4891321659088135
    },
    {
      "classification_loss": 0.49098265171051025,
      "epoch": 14.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4435,
      "total_loss": 0.49098265171051025
    },
    {
      "classification_loss": 0.4454416334629059,
      "epoch": 14.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4436,
      "total_loss": 0.4454416334629059
    },
    {
      "classification_loss": 0.4075280427932739,
      "epoch": 14.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4437,
      "total_loss": 0.4075280427932739
    },
    {
      "classification_loss": 0.5307500958442688,
      "epoch": 14.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4438,
      "total_loss": 0.5307500958442688
    },
    {
      "classification_loss": 0.5557721257209778,
      "epoch": 14.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4439,
      "total_loss": 0.5557721257209778
    },
    {
      "classification_loss": 0.5784192085266113,
      "epoch": 14.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4440,
      "total_loss": 0.5784192085266113
    },
    {
      "classification_loss": 0.40445423126220703,
      "epoch": 14.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4441,
      "total_loss": 0.40445423126220703
    },
    {
      "classification_loss": 0.4267071485519409,
      "epoch": 14.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4442,
      "total_loss": 0.4267071485519409
    },
    {
      "classification_loss": 0.4605395197868347,
      "epoch": 14.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4443,
      "total_loss": 0.4605395197868347
    },
    {
      "classification_loss": 0.5078439116477966,
      "epoch": 14.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4444,
      "total_loss": 0.5078439116477966
    },
    {
      "classification_loss": 0.4464048445224762,
      "epoch": 14.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4445,
      "total_loss": 0.4464048445224762
    },
    {
      "classification_loss": 0.41702374815940857,
      "epoch": 14.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4446,
      "total_loss": 0.41702374815940857
    },
    {
      "classification_loss": 0.46037235856056213,
      "epoch": 14.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4447,
      "total_loss": 0.46037235856056213
    },
    {
      "classification_loss": 0.5947274565696716,
      "epoch": 14.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4448,
      "total_loss": 0.5947274565696716
    },
    {
      "classification_loss": 0.524986743927002,
      "epoch": 14.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4449,
      "total_loss": 0.524986743927002
    },
    {
      "classification_loss": 0.49664077162742615,
      "epoch": 14.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4450,
      "total_loss": 0.49664077162742615
    },
    {
      "classification_loss": 0.5469804406166077,
      "epoch": 14.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4451,
      "total_loss": 0.5469804406166077
    },
    {
      "classification_loss": 0.4639449417591095,
      "epoch": 14.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4452,
      "total_loss": 0.4639449417591095
    },
    {
      "classification_loss": 0.4816971719264984,
      "epoch": 14.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4453,
      "total_loss": 0.4816971719264984
    },
    {
      "classification_loss": 0.44817882776260376,
      "epoch": 14.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4454,
      "total_loss": 0.44817882776260376
    },
    {
      "classification_loss": 0.5600945949554443,
      "epoch": 14.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4455,
      "total_loss": 0.5600945949554443
    },
    {
      "classification_loss": 0.5406144857406616,
      "epoch": 14.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4456,
      "total_loss": 0.5406144857406616
    },
    {
      "classification_loss": 0.4699132740497589,
      "epoch": 14.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4457,
      "total_loss": 0.4699132740497589
    },
    {
      "classification_loss": 0.4764138162136078,
      "epoch": 14.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4458,
      "total_loss": 0.4764138162136078
    },
    {
      "classification_loss": 0.4750473201274872,
      "epoch": 14.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4459,
      "total_loss": 0.4750473201274872
    },
    {
      "classification_loss": 0.5099356174468994,
      "epoch": 14.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4460,
      "total_loss": 0.5099356174468994
    },
    {
      "classification_loss": 0.5697116255760193,
      "epoch": 14.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4461,
      "total_loss": 0.5697116255760193
    },
    {
      "classification_loss": 0.5224270820617676,
      "epoch": 14.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4462,
      "total_loss": 0.5224270820617676
    },
    {
      "classification_loss": 0.39897966384887695,
      "epoch": 14.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4463,
      "total_loss": 0.39897966384887695
    },
    {
      "classification_loss": 0.4699830412864685,
      "epoch": 14.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4464,
      "total_loss": 0.4699830412864685
    },
    {
      "classification_loss": 0.3802470564842224,
      "epoch": 14.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4465,
      "total_loss": 0.3802470564842224
    },
    {
      "classification_loss": 0.5293246507644653,
      "epoch": 14.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4466,
      "total_loss": 0.5293246507644653
    },
    {
      "classification_loss": 0.5064591765403748,
      "epoch": 14.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4467,
      "total_loss": 0.5064591765403748
    },
    {
      "classification_loss": 0.4991530478000641,
      "epoch": 14.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4468,
      "total_loss": 0.4991530478000641
    },
    {
      "classification_loss": 0.43013280630111694,
      "epoch": 14.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4469,
      "total_loss": 0.43013280630111694
    },
    {
      "classification_loss": 0.5399504899978638,
      "epoch": 14.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4470,
      "total_loss": 0.5399504899978638
    },
    {
      "classification_loss": 0.5172273516654968,
      "epoch": 14.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4471,
      "total_loss": 0.5172273516654968
    },
    {
      "classification_loss": 0.5672284364700317,
      "epoch": 14.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4472,
      "total_loss": 0.5672284364700317
    },
    {
      "classification_loss": 0.5799813866615295,
      "epoch": 14.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4473,
      "total_loss": 0.5799813866615295
    },
    {
      "classification_loss": 0.46629971265792847,
      "epoch": 14.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4474,
      "total_loss": 0.46629971265792847
    },
    {
      "classification_loss": 0.4595431387424469,
      "epoch": 14.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4475,
      "total_loss": 0.4595431387424469
    },
    {
      "classification_loss": 0.4481015205383301,
      "epoch": 14.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4476,
      "total_loss": 0.4481015205383301
    },
    {
      "classification_loss": 0.410857230424881,
      "epoch": 14.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4477,
      "total_loss": 0.410857230424881
    },
    {
      "classification_loss": 0.4136858582496643,
      "epoch": 14.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4478,
      "total_loss": 0.4136858582496643
    },
    {
      "classification_loss": 0.4435369372367859,
      "epoch": 14.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4479,
      "total_loss": 0.4435369372367859
    },
    {
      "classification_loss": 0.43272972106933594,
      "epoch": 14.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4480,
      "total_loss": 0.43272972106933594
    },
    {
      "classification_loss": 0.5201524496078491,
      "epoch": 14.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4481,
      "total_loss": 0.5201524496078491
    },
    {
      "classification_loss": 0.43906131386756897,
      "epoch": 14.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4482,
      "total_loss": 0.43906131386756897
    },
    {
      "classification_loss": 0.5681101679801941,
      "epoch": 14.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4483,
      "total_loss": 0.5681101679801941
    },
    {
      "classification_loss": 0.5073002576828003,
      "epoch": 14.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4484,
      "total_loss": 0.5073002576828003
    },
    {
      "classification_loss": 0.5155487060546875,
      "epoch": 14.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4485,
      "total_loss": 0.5155487060546875
    },
    {
      "classification_loss": 0.493859201669693,
      "epoch": 14.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4486,
      "total_loss": 0.493859201669693
    },
    {
      "classification_loss": 0.38420867919921875,
      "epoch": 14.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4487,
      "total_loss": 0.38420867919921875
    },
    {
      "classification_loss": 0.5061206817626953,
      "epoch": 14.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4488,
      "total_loss": 0.5061206817626953
    },
    {
      "classification_loss": 0.4449296295642853,
      "epoch": 14.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4489,
      "total_loss": 0.4449296295642853
    },
    {
      "classification_loss": 0.45585671067237854,
      "epoch": 14.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4490,
      "total_loss": 0.45585671067237854
    },
    {
      "classification_loss": 0.44760674238204956,
      "epoch": 14.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4491,
      "total_loss": 0.44760674238204956
    },
    {
      "classification_loss": 0.4782850742340088,
      "epoch": 14.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4492,
      "total_loss": 0.4782850742340088
    },
    {
      "classification_loss": 0.44593536853790283,
      "epoch": 14.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4493,
      "total_loss": 0.44593536853790283
    },
    {
      "classification_loss": 0.502074122428894,
      "epoch": 14.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4494,
      "total_loss": 0.502074122428894
    },
    {
      "classification_loss": 0.4978230595588684,
      "epoch": 14.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4495,
      "total_loss": 0.4978230595588684
    },
    {
      "classification_loss": 0.49885833263397217,
      "epoch": 14.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4496,
      "total_loss": 0.49885833263397217
    },
    {
      "classification_loss": 0.5336387157440186,
      "epoch": 14.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4497,
      "total_loss": 0.5336387157440186
    },
    {
      "classification_loss": 0.5210801362991333,
      "epoch": 14.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4498,
      "total_loss": 0.5210801362991333
    },
    {
      "classification_loss": 0.5258210897445679,
      "epoch": 14.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4499,
      "total_loss": 0.5258210897445679
    },
    {
      "epoch": 14.754098360655737,
      "grad_norm": 5.892699718475342,
      "learning_rate": 5.3366666666666665e-05,
      "loss": 0.4923,
      "step": 4500
    },
    {
      "classification_loss": 0.48718249797821045,
      "epoch": 14.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4500,
      "total_loss": 0.48718249797821045
    },
    {
      "classification_loss": 0.5437373518943787,
      "epoch": 14.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4501,
      "total_loss": 0.5437373518943787
    },
    {
      "classification_loss": 0.5262546539306641,
      "epoch": 14.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4502,
      "total_loss": 0.5262546539306641
    },
    {
      "classification_loss": 0.602523148059845,
      "epoch": 14.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4503,
      "total_loss": 0.602523148059845
    },
    {
      "classification_loss": 0.4872363209724426,
      "epoch": 14.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4504,
      "total_loss": 0.4872363209724426
    },
    {
      "classification_loss": 0.5256165862083435,
      "epoch": 14.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4505,
      "total_loss": 0.5256165862083435
    },
    {
      "classification_loss": 0.5233718156814575,
      "epoch": 14.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4506,
      "total_loss": 0.5233718156814575
    },
    {
      "classification_loss": 0.584532618522644,
      "epoch": 14.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4507,
      "total_loss": 0.584532618522644
    },
    {
      "classification_loss": 0.644731879234314,
      "epoch": 14.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4508,
      "total_loss": 0.644731879234314
    },
    {
      "classification_loss": 0.5083270072937012,
      "epoch": 14.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4509,
      "total_loss": 0.5083270072937012
    },
    {
      "classification_loss": 0.5275099277496338,
      "epoch": 14.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4510,
      "total_loss": 0.5275099277496338
    },
    {
      "classification_loss": 0.562190055847168,
      "epoch": 14.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4511,
      "total_loss": 0.562190055847168
    },
    {
      "classification_loss": 0.43950656056404114,
      "epoch": 14.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4512,
      "total_loss": 0.43950656056404114
    },
    {
      "classification_loss": 0.4800325036048889,
      "epoch": 14.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4513,
      "total_loss": 0.4800325036048889
    },
    {
      "classification_loss": 0.4898339509963989,
      "epoch": 14.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4514,
      "total_loss": 0.4898339509963989
    },
    {
      "classification_loss": 0.5549983978271484,
      "epoch": 14.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4515,
      "total_loss": 0.5549983978271484
    },
    {
      "classification_loss": 0.5067779421806335,
      "epoch": 14.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4516,
      "total_loss": 0.5067779421806335
    },
    {
      "classification_loss": 0.4946601688861847,
      "epoch": 14.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4517,
      "total_loss": 0.4946601688861847
    },
    {
      "classification_loss": 0.5162394046783447,
      "epoch": 14.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4518,
      "total_loss": 0.5162394046783447
    },
    {
      "classification_loss": 0.4917454719543457,
      "epoch": 14.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4519,
      "total_loss": 0.4917454719543457
    },
    {
      "classification_loss": 0.5136456489562988,
      "epoch": 14.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4520,
      "total_loss": 0.5136456489562988
    },
    {
      "classification_loss": 0.5684161186218262,
      "epoch": 14.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4521,
      "total_loss": 0.5684161186218262
    },
    {
      "classification_loss": 0.4714359641075134,
      "epoch": 14.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4522,
      "total_loss": 0.4714359641075134
    },
    {
      "classification_loss": 0.4313327372074127,
      "epoch": 14.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4523,
      "total_loss": 0.4313327372074127
    },
    {
      "classification_loss": 0.5715529918670654,
      "epoch": 14.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4524,
      "total_loss": 0.5715529918670654
    },
    {
      "classification_loss": 0.5324084758758545,
      "epoch": 14.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4525,
      "total_loss": 0.5324084758758545
    },
    {
      "classification_loss": 0.6126763224601746,
      "epoch": 14.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4526,
      "total_loss": 0.6126763224601746
    },
    {
      "classification_loss": 0.405012845993042,
      "epoch": 14.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4527,
      "total_loss": 0.405012845993042
    },
    {
      "classification_loss": 0.5288869738578796,
      "epoch": 14.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4528,
      "total_loss": 0.5288869738578796
    },
    {
      "classification_loss": 0.5406131148338318,
      "epoch": 14.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4529,
      "total_loss": 0.5406131148338318
    },
    {
      "classification_loss": 0.5071097016334534,
      "epoch": 14.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4530,
      "total_loss": 0.5071097016334534
    },
    {
      "classification_loss": 0.5064776539802551,
      "epoch": 14.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4531,
      "total_loss": 0.5064776539802551
    },
    {
      "classification_loss": 0.4293738603591919,
      "epoch": 14.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4532,
      "total_loss": 0.4293738603591919
    },
    {
      "classification_loss": 0.5011094212532043,
      "epoch": 14.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4533,
      "total_loss": 0.5011094212532043
    },
    {
      "classification_loss": 0.5070741176605225,
      "epoch": 14.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4534,
      "total_loss": 0.5070741176605225
    },
    {
      "classification_loss": 0.5150816440582275,
      "epoch": 14.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4535,
      "total_loss": 0.5150816440582275
    },
    {
      "classification_loss": 0.4627530872821808,
      "epoch": 14.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4536,
      "total_loss": 0.4627530872821808
    },
    {
      "classification_loss": 0.4199177026748657,
      "epoch": 14.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4537,
      "total_loss": 0.4199177026748657
    },
    {
      "classification_loss": 0.46691036224365234,
      "epoch": 14.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4538,
      "total_loss": 0.46691036224365234
    },
    {
      "classification_loss": 0.4823284149169922,
      "epoch": 14.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4539,
      "total_loss": 0.4823284149169922
    },
    {
      "classification_loss": 0.49122732877731323,
      "epoch": 14.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4540,
      "total_loss": 0.49122732877731323
    },
    {
      "classification_loss": 0.44677403569221497,
      "epoch": 14.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4541,
      "total_loss": 0.44677403569221497
    },
    {
      "classification_loss": 0.4742159843444824,
      "epoch": 14.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4542,
      "total_loss": 0.4742159843444824
    },
    {
      "classification_loss": 0.4274960458278656,
      "epoch": 14.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4543,
      "total_loss": 0.4274960458278656
    },
    {
      "classification_loss": 0.5794095396995544,
      "epoch": 14.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4544,
      "total_loss": 0.5794095396995544
    },
    {
      "classification_loss": 0.4823579788208008,
      "epoch": 14.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4545,
      "total_loss": 0.4823579788208008
    },
    {
      "classification_loss": 0.5643433928489685,
      "epoch": 14.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4546,
      "total_loss": 0.5643433928489685
    },
    {
      "classification_loss": 0.5224317908287048,
      "epoch": 14.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4547,
      "total_loss": 0.5224317908287048
    },
    {
      "classification_loss": 0.5012015700340271,
      "epoch": 14.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4548,
      "total_loss": 0.5012015700340271
    },
    {
      "classification_loss": 0.48816928267478943,
      "epoch": 14.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4549,
      "total_loss": 0.48816928267478943
    },
    {
      "classification_loss": 0.4653017222881317,
      "epoch": 14.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4550,
      "total_loss": 0.4653017222881317
    },
    {
      "classification_loss": 0.6251146197319031,
      "epoch": 14.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4551,
      "total_loss": 0.6251146197319031
    },
    {
      "classification_loss": 0.44644251465797424,
      "epoch": 14.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4552,
      "total_loss": 0.44644251465797424
    },
    {
      "classification_loss": 0.46864184737205505,
      "epoch": 14.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4553,
      "total_loss": 0.46864184737205505
    },
    {
      "classification_loss": 0.5352412462234497,
      "epoch": 14.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4554,
      "total_loss": 0.5352412462234497
    },
    {
      "classification_loss": 0.43470504879951477,
      "epoch": 14.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4555,
      "total_loss": 0.43470504879951477
    },
    {
      "classification_loss": 0.5018236637115479,
      "epoch": 14.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4556,
      "total_loss": 0.5018236637115479
    },
    {
      "classification_loss": 0.5043249130249023,
      "epoch": 14.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4557,
      "total_loss": 0.5043249130249023
    },
    {
      "classification_loss": 0.4094025492668152,
      "epoch": 14.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4558,
      "total_loss": 0.4094025492668152
    },
    {
      "classification_loss": 0.43617314100265503,
      "epoch": 14.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4559,
      "total_loss": 0.43617314100265503
    },
    {
      "classification_loss": 0.4434250593185425,
      "epoch": 14.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4560,
      "total_loss": 0.4434250593185425
    },
    {
      "classification_loss": 0.5188879370689392,
      "epoch": 14.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4561,
      "total_loss": 0.5188879370689392
    },
    {
      "classification_loss": 0.5235214233398438,
      "epoch": 14.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4562,
      "total_loss": 0.5235214233398438
    },
    {
      "classification_loss": 0.529132068157196,
      "epoch": 14.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4563,
      "total_loss": 0.529132068157196
    },
    {
      "classification_loss": 0.5645317435264587,
      "epoch": 14.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4564,
      "total_loss": 0.5645317435264587
    },
    {
      "classification_loss": 0.5229336619377136,
      "epoch": 14.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4565,
      "total_loss": 0.5229336619377136
    },
    {
      "classification_loss": 0.47179245948791504,
      "epoch": 14.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4566,
      "total_loss": 0.47179245948791504
    },
    {
      "classification_loss": 0.5134865045547485,
      "epoch": 14.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4567,
      "total_loss": 0.5134865045547485
    },
    {
      "classification_loss": 0.49647220969200134,
      "epoch": 14.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4568,
      "total_loss": 0.49647220969200134
    },
    {
      "classification_loss": 0.4979427456855774,
      "epoch": 14.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4569,
      "total_loss": 0.4979427456855774
    },
    {
      "classification_loss": 0.4421330988407135,
      "epoch": 14.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4570,
      "total_loss": 0.4421330988407135
    },
    {
      "classification_loss": 0.5220168232917786,
      "epoch": 14.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4571,
      "total_loss": 0.5220168232917786
    },
    {
      "classification_loss": 0.518612802028656,
      "epoch": 14.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4572,
      "total_loss": 0.518612802028656
    },
    {
      "classification_loss": 0.4834193289279938,
      "epoch": 14.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4573,
      "total_loss": 0.4834193289279938
    },
    {
      "classification_loss": 0.6153156757354736,
      "epoch": 14.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4574,
      "total_loss": 0.6153156757354736
    },
    {
      "classification_loss": 1.3873344659805298,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.3873344659805298
    },
    {
      "classification_loss": 1.3321986198425293,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.3321986198425293
    },
    {
      "classification_loss": 1.2143974304199219,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.2143974304199219
    },
    {
      "classification_loss": 1.5039399862289429,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.5039399862289429
    },
    {
      "classification_loss": 1.2359596490859985,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.2359596490859985
    },
    {
      "classification_loss": 1.2257392406463623,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.2257392406463623
    },
    {
      "classification_loss": 1.2991982698440552,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.2991982698440552
    },
    {
      "classification_loss": 1.1100102663040161,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 1.1100102663040161
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.2928833961486816,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0006,
      "eval_samples_per_second": 166.65,
      "eval_steps_per_second": 1.333,
      "step": 4575
    },
    {
      "classification_loss": 0.4780076742172241,
      "epoch": 15.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4575,
      "total_loss": 0.4780076742172241
    },
    {
      "classification_loss": 0.4833579957485199,
      "epoch": 15.00327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4576,
      "total_loss": 0.4833579957485199
    },
    {
      "classification_loss": 0.510753333568573,
      "epoch": 15.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4577,
      "total_loss": 0.510753333568573
    },
    {
      "classification_loss": 0.5533168315887451,
      "epoch": 15.00983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4578,
      "total_loss": 0.5533168315887451
    },
    {
      "classification_loss": 0.4440343379974365,
      "epoch": 15.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4579,
      "total_loss": 0.4440343379974365
    },
    {
      "classification_loss": 0.42520883679389954,
      "epoch": 15.01639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4580,
      "total_loss": 0.42520883679389954
    },
    {
      "classification_loss": 0.46754154562950134,
      "epoch": 15.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4581,
      "total_loss": 0.46754154562950134
    },
    {
      "classification_loss": 0.37619656324386597,
      "epoch": 15.02295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4582,
      "total_loss": 0.37619656324386597
    },
    {
      "classification_loss": 0.5776329636573792,
      "epoch": 15.026229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4583,
      "total_loss": 0.5776329636573792
    },
    {
      "classification_loss": 0.5126063227653503,
      "epoch": 15.029508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4584,
      "total_loss": 0.5126063227653503
    },
    {
      "classification_loss": 0.47452670335769653,
      "epoch": 15.032786885245901,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4585,
      "total_loss": 0.47452670335769653
    },
    {
      "classification_loss": 0.47397446632385254,
      "epoch": 15.036065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4586,
      "total_loss": 0.47397446632385254
    },
    {
      "classification_loss": 0.4922623932361603,
      "epoch": 15.039344262295081,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4587,
      "total_loss": 0.4922623932361603
    },
    {
      "classification_loss": 0.4644213020801544,
      "epoch": 15.042622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4588,
      "total_loss": 0.4644213020801544
    },
    {
      "classification_loss": 0.42525598406791687,
      "epoch": 15.045901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4589,
      "total_loss": 0.42525598406791687
    },
    {
      "classification_loss": 0.5529019832611084,
      "epoch": 15.049180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4590,
      "total_loss": 0.5529019832611084
    },
    {
      "classification_loss": 0.6557067632675171,
      "epoch": 15.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4591,
      "total_loss": 0.6557067632675171
    },
    {
      "classification_loss": 0.5463777184486389,
      "epoch": 15.055737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4592,
      "total_loss": 0.5463777184486389
    },
    {
      "classification_loss": 0.402462363243103,
      "epoch": 15.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4593,
      "total_loss": 0.402462363243103
    },
    {
      "classification_loss": 0.4953753352165222,
      "epoch": 15.062295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4594,
      "total_loss": 0.4953753352165222
    },
    {
      "classification_loss": 0.4694611132144928,
      "epoch": 15.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4595,
      "total_loss": 0.4694611132144928
    },
    {
      "classification_loss": 0.6704500317573547,
      "epoch": 15.068852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4596,
      "total_loss": 0.6704500317573547
    },
    {
      "classification_loss": 0.4839767515659332,
      "epoch": 15.072131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4597,
      "total_loss": 0.4839767515659332
    },
    {
      "classification_loss": 0.4704627990722656,
      "epoch": 15.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4598,
      "total_loss": 0.4704627990722656
    },
    {
      "classification_loss": 0.48516571521759033,
      "epoch": 15.078688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4599,
      "total_loss": 0.48516571521759033
    },
    {
      "epoch": 15.081967213114755,
      "grad_norm": 1.9292680025100708,
      "learning_rate": 5.0033333333333334e-05,
      "loss": 0.5033,
      "step": 4600
    },
    {
      "classification_loss": 0.521124541759491,
      "epoch": 15.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4600,
      "total_loss": 0.521124541759491
    },
    {
      "classification_loss": 0.5108663439750671,
      "epoch": 15.085245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4601,
      "total_loss": 0.5108663439750671
    },
    {
      "classification_loss": 0.4258970022201538,
      "epoch": 15.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4602,
      "total_loss": 0.4258970022201538
    },
    {
      "classification_loss": 0.4420468211174011,
      "epoch": 15.091803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4603,
      "total_loss": 0.4420468211174011
    },
    {
      "classification_loss": 0.4337904751300812,
      "epoch": 15.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4604,
      "total_loss": 0.4337904751300812
    },
    {
      "classification_loss": 0.4696873724460602,
      "epoch": 15.098360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4605,
      "total_loss": 0.4696873724460602
    },
    {
      "classification_loss": 0.46084538102149963,
      "epoch": 15.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4606,
      "total_loss": 0.46084538102149963
    },
    {
      "classification_loss": 0.47920963168144226,
      "epoch": 15.104918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4607,
      "total_loss": 0.47920963168144226
    },
    {
      "classification_loss": 0.516329288482666,
      "epoch": 15.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4608,
      "total_loss": 0.516329288482666
    },
    {
      "classification_loss": 0.5408979654312134,
      "epoch": 15.111475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4609,
      "total_loss": 0.5408979654312134
    },
    {
      "classification_loss": 0.5681267976760864,
      "epoch": 15.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4610,
      "total_loss": 0.5681267976760864
    },
    {
      "classification_loss": 0.6190972924232483,
      "epoch": 15.118032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4611,
      "total_loss": 0.6190972924232483
    },
    {
      "classification_loss": 0.5504134297370911,
      "epoch": 15.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4612,
      "total_loss": 0.5504134297370911
    },
    {
      "classification_loss": 0.47503867745399475,
      "epoch": 15.124590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4613,
      "total_loss": 0.47503867745399475
    },
    {
      "classification_loss": 0.4897715151309967,
      "epoch": 15.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4614,
      "total_loss": 0.4897715151309967
    },
    {
      "classification_loss": 0.38667356967926025,
      "epoch": 15.131147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4615,
      "total_loss": 0.38667356967926025
    },
    {
      "classification_loss": 0.5033454298973083,
      "epoch": 15.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4616,
      "total_loss": 0.5033454298973083
    },
    {
      "classification_loss": 0.545772135257721,
      "epoch": 15.137704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4617,
      "total_loss": 0.545772135257721
    },
    {
      "classification_loss": 0.36636701226234436,
      "epoch": 15.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4618,
      "total_loss": 0.36636701226234436
    },
    {
      "classification_loss": 0.4680016040802002,
      "epoch": 15.144262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4619,
      "total_loss": 0.4680016040802002
    },
    {
      "classification_loss": 0.5838804244995117,
      "epoch": 15.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4620,
      "total_loss": 0.5838804244995117
    },
    {
      "classification_loss": 0.4496949315071106,
      "epoch": 15.150819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4621,
      "total_loss": 0.4496949315071106
    },
    {
      "classification_loss": 0.5920618176460266,
      "epoch": 15.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4622,
      "total_loss": 0.5920618176460266
    },
    {
      "classification_loss": 0.4228947162628174,
      "epoch": 15.157377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4623,
      "total_loss": 0.4228947162628174
    },
    {
      "classification_loss": 0.4007875919342041,
      "epoch": 15.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4624,
      "total_loss": 0.4007875919342041
    },
    {
      "classification_loss": 0.4933492839336395,
      "epoch": 15.163934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4625,
      "total_loss": 0.4933492839336395
    },
    {
      "classification_loss": 0.5414682626724243,
      "epoch": 15.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4626,
      "total_loss": 0.5414682626724243
    },
    {
      "classification_loss": 0.555360734462738,
      "epoch": 15.170491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4627,
      "total_loss": 0.555360734462738
    },
    {
      "classification_loss": 0.4336940050125122,
      "epoch": 15.173770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4628,
      "total_loss": 0.4336940050125122
    },
    {
      "classification_loss": 0.4505828619003296,
      "epoch": 15.177049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4629,
      "total_loss": 0.4505828619003296
    },
    {
      "classification_loss": 0.36544716358184814,
      "epoch": 15.180327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4630,
      "total_loss": 0.36544716358184814
    },
    {
      "classification_loss": 0.43682730197906494,
      "epoch": 15.183606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4631,
      "total_loss": 0.43682730197906494
    },
    {
      "classification_loss": 0.33234691619873047,
      "epoch": 15.186885245901639,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4632,
      "total_loss": 0.33234691619873047
    },
    {
      "classification_loss": 0.5004079937934875,
      "epoch": 15.190163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4633,
      "total_loss": 0.5004079937934875
    },
    {
      "classification_loss": 0.5598180890083313,
      "epoch": 15.193442622950819,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4634,
      "total_loss": 0.5598180890083313
    },
    {
      "classification_loss": 0.4065869450569153,
      "epoch": 15.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4635,
      "total_loss": 0.4065869450569153
    },
    {
      "classification_loss": 0.3874923586845398,
      "epoch": 15.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4636,
      "total_loss": 0.3874923586845398
    },
    {
      "classification_loss": 0.41763100028038025,
      "epoch": 15.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4637,
      "total_loss": 0.41763100028038025
    },
    {
      "classification_loss": 0.5046965479850769,
      "epoch": 15.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4638,
      "total_loss": 0.5046965479850769
    },
    {
      "classification_loss": 0.37194880843162537,
      "epoch": 15.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4639,
      "total_loss": 0.37194880843162537
    },
    {
      "classification_loss": 0.4285712242126465,
      "epoch": 15.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4640,
      "total_loss": 0.4285712242126465
    },
    {
      "classification_loss": 0.41132456064224243,
      "epoch": 15.216393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4641,
      "total_loss": 0.41132456064224243
    },
    {
      "classification_loss": 0.5914973020553589,
      "epoch": 15.219672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4642,
      "total_loss": 0.5914973020553589
    },
    {
      "classification_loss": 0.5473711490631104,
      "epoch": 15.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4643,
      "total_loss": 0.5473711490631104
    },
    {
      "classification_loss": 0.6777726411819458,
      "epoch": 15.226229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4644,
      "total_loss": 0.6777726411819458
    },
    {
      "classification_loss": 0.48481473326683044,
      "epoch": 15.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4645,
      "total_loss": 0.48481473326683044
    },
    {
      "classification_loss": 0.4657825827598572,
      "epoch": 15.232786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4646,
      "total_loss": 0.4657825827598572
    },
    {
      "classification_loss": 0.42003634572029114,
      "epoch": 15.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4647,
      "total_loss": 0.42003634572029114
    },
    {
      "classification_loss": 0.5209051370620728,
      "epoch": 15.239344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4648,
      "total_loss": 0.5209051370620728
    },
    {
      "classification_loss": 0.5355286598205566,
      "epoch": 15.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4649,
      "total_loss": 0.5355286598205566
    },
    {
      "classification_loss": 0.5306094288825989,
      "epoch": 15.245901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4650,
      "total_loss": 0.5306094288825989
    },
    {
      "classification_loss": 0.5318588614463806,
      "epoch": 15.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4651,
      "total_loss": 0.5318588614463806
    },
    {
      "classification_loss": 0.5339964628219604,
      "epoch": 15.252459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4652,
      "total_loss": 0.5339964628219604
    },
    {
      "classification_loss": 0.5023229122161865,
      "epoch": 15.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4653,
      "total_loss": 0.5023229122161865
    },
    {
      "classification_loss": 0.4375187158584595,
      "epoch": 15.259016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4654,
      "total_loss": 0.4375187158584595
    },
    {
      "classification_loss": 0.43573495745658875,
      "epoch": 15.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4655,
      "total_loss": 0.43573495745658875
    },
    {
      "classification_loss": 0.4750310778617859,
      "epoch": 15.265573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4656,
      "total_loss": 0.4750310778617859
    },
    {
      "classification_loss": 0.4821999967098236,
      "epoch": 15.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4657,
      "total_loss": 0.4821999967098236
    },
    {
      "classification_loss": 0.49492785334587097,
      "epoch": 15.272131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4658,
      "total_loss": 0.49492785334587097
    },
    {
      "classification_loss": 0.3767666518688202,
      "epoch": 15.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4659,
      "total_loss": 0.3767666518688202
    },
    {
      "classification_loss": 0.5887026190757751,
      "epoch": 15.278688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4660,
      "total_loss": 0.5887026190757751
    },
    {
      "classification_loss": 0.4644800126552582,
      "epoch": 15.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4661,
      "total_loss": 0.4644800126552582
    },
    {
      "classification_loss": 0.5331427454948425,
      "epoch": 15.285245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4662,
      "total_loss": 0.5331427454948425
    },
    {
      "classification_loss": 0.5742923021316528,
      "epoch": 15.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4663,
      "total_loss": 0.5742923021316528
    },
    {
      "classification_loss": 0.49390700459480286,
      "epoch": 15.291803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4664,
      "total_loss": 0.49390700459480286
    },
    {
      "classification_loss": 0.44262415170669556,
      "epoch": 15.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4665,
      "total_loss": 0.44262415170669556
    },
    {
      "classification_loss": 0.38462913036346436,
      "epoch": 15.298360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4666,
      "total_loss": 0.38462913036346436
    },
    {
      "classification_loss": 0.5387542843818665,
      "epoch": 15.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4667,
      "total_loss": 0.5387542843818665
    },
    {
      "classification_loss": 0.6342350840568542,
      "epoch": 15.304918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4668,
      "total_loss": 0.6342350840568542
    },
    {
      "classification_loss": 0.4984501302242279,
      "epoch": 15.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4669,
      "total_loss": 0.4984501302242279
    },
    {
      "classification_loss": 0.5554506778717041,
      "epoch": 15.311475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4670,
      "total_loss": 0.5554506778717041
    },
    {
      "classification_loss": 0.37189412117004395,
      "epoch": 15.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4671,
      "total_loss": 0.37189412117004395
    },
    {
      "classification_loss": 0.545163631439209,
      "epoch": 15.318032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4672,
      "total_loss": 0.545163631439209
    },
    {
      "classification_loss": 0.36983850598335266,
      "epoch": 15.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4673,
      "total_loss": 0.36983850598335266
    },
    {
      "classification_loss": 0.6444646716117859,
      "epoch": 15.324590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4674,
      "total_loss": 0.6444646716117859
    },
    {
      "classification_loss": 0.46405553817749023,
      "epoch": 15.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4675,
      "total_loss": 0.46405553817749023
    },
    {
      "classification_loss": 0.35467344522476196,
      "epoch": 15.331147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4676,
      "total_loss": 0.35467344522476196
    },
    {
      "classification_loss": 0.47281575202941895,
      "epoch": 15.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4677,
      "total_loss": 0.47281575202941895
    },
    {
      "classification_loss": 0.5718819499015808,
      "epoch": 15.337704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4678,
      "total_loss": 0.5718819499015808
    },
    {
      "classification_loss": 0.4694647789001465,
      "epoch": 15.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4679,
      "total_loss": 0.4694647789001465
    },
    {
      "classification_loss": 0.5314255952835083,
      "epoch": 15.344262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4680,
      "total_loss": 0.5314255952835083
    },
    {
      "classification_loss": 0.5502088665962219,
      "epoch": 15.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4681,
      "total_loss": 0.5502088665962219
    },
    {
      "classification_loss": 0.6193054914474487,
      "epoch": 15.350819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4682,
      "total_loss": 0.6193054914474487
    },
    {
      "classification_loss": 0.5701892375946045,
      "epoch": 15.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4683,
      "total_loss": 0.5701892375946045
    },
    {
      "classification_loss": 0.46796518564224243,
      "epoch": 15.357377049180329,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4684,
      "total_loss": 0.46796518564224243
    },
    {
      "classification_loss": 0.4664404094219208,
      "epoch": 15.360655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4685,
      "total_loss": 0.4664404094219208
    },
    {
      "classification_loss": 0.4500393569469452,
      "epoch": 15.363934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4686,
      "total_loss": 0.4500393569469452
    },
    {
      "classification_loss": 0.4805666208267212,
      "epoch": 15.3672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4687,
      "total_loss": 0.4805666208267212
    },
    {
      "classification_loss": 0.5265698432922363,
      "epoch": 15.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4688,
      "total_loss": 0.5265698432922363
    },
    {
      "classification_loss": 0.5525344610214233,
      "epoch": 15.37377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4689,
      "total_loss": 0.5525344610214233
    },
    {
      "classification_loss": 0.7059560418128967,
      "epoch": 15.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4690,
      "total_loss": 0.7059560418128967
    },
    {
      "classification_loss": 0.5504849553108215,
      "epoch": 15.38032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4691,
      "total_loss": 0.5504849553108215
    },
    {
      "classification_loss": 0.5357562303543091,
      "epoch": 15.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4692,
      "total_loss": 0.5357562303543091
    },
    {
      "classification_loss": 0.5831184387207031,
      "epoch": 15.38688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4693,
      "total_loss": 0.5831184387207031
    },
    {
      "classification_loss": 0.4665854573249817,
      "epoch": 15.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4694,
      "total_loss": 0.4665854573249817
    },
    {
      "classification_loss": 0.48059430718421936,
      "epoch": 15.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4695,
      "total_loss": 0.48059430718421936
    },
    {
      "classification_loss": 0.5016520023345947,
      "epoch": 15.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4696,
      "total_loss": 0.5016520023345947
    },
    {
      "classification_loss": 0.5006550550460815,
      "epoch": 15.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4697,
      "total_loss": 0.5006550550460815
    },
    {
      "classification_loss": 0.48779046535491943,
      "epoch": 15.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4698,
      "total_loss": 0.48779046535491943
    },
    {
      "classification_loss": 0.42140641808509827,
      "epoch": 15.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4699,
      "total_loss": 0.42140641808509827
    },
    {
      "epoch": 15.40983606557377,
      "grad_norm": 4.84916353225708,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 0.4929,
      "step": 4700
    },
    {
      "classification_loss": 0.5004045963287354,
      "epoch": 15.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4700,
      "total_loss": 0.5004045963287354
    },
    {
      "classification_loss": 0.3930519223213196,
      "epoch": 15.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4701,
      "total_loss": 0.3930519223213196
    },
    {
      "classification_loss": 0.4756892919540405,
      "epoch": 15.416393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4702,
      "total_loss": 0.4756892919540405
    },
    {
      "classification_loss": 0.5036397576332092,
      "epoch": 15.419672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4703,
      "total_loss": 0.5036397576332092
    },
    {
      "classification_loss": 0.4672212302684784,
      "epoch": 15.422950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4704,
      "total_loss": 0.4672212302684784
    },
    {
      "classification_loss": 0.4440053105354309,
      "epoch": 15.426229508196721,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4705,
      "total_loss": 0.4440053105354309
    },
    {
      "classification_loss": 0.43572354316711426,
      "epoch": 15.429508196721311,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4706,
      "total_loss": 0.43572354316711426
    },
    {
      "classification_loss": 0.5892589092254639,
      "epoch": 15.432786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4707,
      "total_loss": 0.5892589092254639
    },
    {
      "classification_loss": 0.45751819014549255,
      "epoch": 15.436065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4708,
      "total_loss": 0.45751819014549255
    },
    {
      "classification_loss": 0.5092678070068359,
      "epoch": 15.439344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4709,
      "total_loss": 0.5092678070068359
    },
    {
      "classification_loss": 0.45167237520217896,
      "epoch": 15.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4710,
      "total_loss": 0.45167237520217896
    },
    {
      "classification_loss": 0.51832515001297,
      "epoch": 15.445901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4711,
      "total_loss": 0.51832515001297
    },
    {
      "classification_loss": 0.45900771021842957,
      "epoch": 15.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4712,
      "total_loss": 0.45900771021842957
    },
    {
      "classification_loss": 0.45158934593200684,
      "epoch": 15.452459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4713,
      "total_loss": 0.45158934593200684
    },
    {
      "classification_loss": 0.4444085657596588,
      "epoch": 15.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4714,
      "total_loss": 0.4444085657596588
    },
    {
      "classification_loss": 0.5780373215675354,
      "epoch": 15.459016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4715,
      "total_loss": 0.5780373215675354
    },
    {
      "classification_loss": 0.410942405462265,
      "epoch": 15.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4716,
      "total_loss": 0.410942405462265
    },
    {
      "classification_loss": 0.429562509059906,
      "epoch": 15.465573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4717,
      "total_loss": 0.429562509059906
    },
    {
      "classification_loss": 0.43112534284591675,
      "epoch": 15.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4718,
      "total_loss": 0.43112534284591675
    },
    {
      "classification_loss": 0.529061496257782,
      "epoch": 15.472131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4719,
      "total_loss": 0.529061496257782
    },
    {
      "classification_loss": 0.41750359535217285,
      "epoch": 15.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4720,
      "total_loss": 0.41750359535217285
    },
    {
      "classification_loss": 0.45590856671333313,
      "epoch": 15.478688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4721,
      "total_loss": 0.45590856671333313
    },
    {
      "classification_loss": 0.5291042923927307,
      "epoch": 15.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4722,
      "total_loss": 0.5291042923927307
    },
    {
      "classification_loss": 0.548725962638855,
      "epoch": 15.485245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4723,
      "total_loss": 0.548725962638855
    },
    {
      "classification_loss": 0.37881505489349365,
      "epoch": 15.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4724,
      "total_loss": 0.37881505489349365
    },
    {
      "classification_loss": 0.33975717425346375,
      "epoch": 15.491803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4725,
      "total_loss": 0.33975717425346375
    },
    {
      "classification_loss": 0.3373129963874817,
      "epoch": 15.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4726,
      "total_loss": 0.3373129963874817
    },
    {
      "classification_loss": 0.6062194108963013,
      "epoch": 15.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4727,
      "total_loss": 0.6062194108963013
    },
    {
      "classification_loss": 0.5651347637176514,
      "epoch": 15.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4728,
      "total_loss": 0.5651347637176514
    },
    {
      "classification_loss": 0.3915327489376068,
      "epoch": 15.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4729,
      "total_loss": 0.3915327489376068
    },
    {
      "classification_loss": 0.5624462366104126,
      "epoch": 15.508196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4730,
      "total_loss": 0.5624462366104126
    },
    {
      "classification_loss": 0.5071102380752563,
      "epoch": 15.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4731,
      "total_loss": 0.5071102380752563
    },
    {
      "classification_loss": 0.6662845611572266,
      "epoch": 15.514754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4732,
      "total_loss": 0.6662845611572266
    },
    {
      "classification_loss": 0.6742036938667297,
      "epoch": 15.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4733,
      "total_loss": 0.6742036938667297
    },
    {
      "classification_loss": 0.4900631606578827,
      "epoch": 15.521311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4734,
      "total_loss": 0.4900631606578827
    },
    {
      "classification_loss": 0.4892781674861908,
      "epoch": 15.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4735,
      "total_loss": 0.4892781674861908
    },
    {
      "classification_loss": 0.4697975516319275,
      "epoch": 15.527868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4736,
      "total_loss": 0.4697975516319275
    },
    {
      "classification_loss": 0.5221000909805298,
      "epoch": 15.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4737,
      "total_loss": 0.5221000909805298
    },
    {
      "classification_loss": 0.43626782298088074,
      "epoch": 15.534426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4738,
      "total_loss": 0.43626782298088074
    },
    {
      "classification_loss": 0.41346225142478943,
      "epoch": 15.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4739,
      "total_loss": 0.41346225142478943
    },
    {
      "classification_loss": 0.5246376395225525,
      "epoch": 15.540983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4740,
      "total_loss": 0.5246376395225525
    },
    {
      "classification_loss": 0.40026453137397766,
      "epoch": 15.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4741,
      "total_loss": 0.40026453137397766
    },
    {
      "classification_loss": 0.4384957551956177,
      "epoch": 15.547540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4742,
      "total_loss": 0.4384957551956177
    },
    {
      "classification_loss": 0.4298432171344757,
      "epoch": 15.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4743,
      "total_loss": 0.4298432171344757
    },
    {
      "classification_loss": 0.5767073035240173,
      "epoch": 15.554098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4744,
      "total_loss": 0.5767073035240173
    },
    {
      "classification_loss": 0.3515031933784485,
      "epoch": 15.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4745,
      "total_loss": 0.3515031933784485
    },
    {
      "classification_loss": 0.5738802552223206,
      "epoch": 15.560655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4746,
      "total_loss": 0.5738802552223206
    },
    {
      "classification_loss": 0.5287214517593384,
      "epoch": 15.563934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4747,
      "total_loss": 0.5287214517593384
    },
    {
      "classification_loss": 0.5178077220916748,
      "epoch": 15.567213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4748,
      "total_loss": 0.5178077220916748
    },
    {
      "classification_loss": 0.4983743727207184,
      "epoch": 15.570491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4749,
      "total_loss": 0.4983743727207184
    },
    {
      "classification_loss": 0.4144892990589142,
      "epoch": 15.573770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4750,
      "total_loss": 0.4144892990589142
    },
    {
      "classification_loss": 0.6870672702789307,
      "epoch": 15.577049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4751,
      "total_loss": 0.6870672702789307
    },
    {
      "classification_loss": 0.43416711688041687,
      "epoch": 15.580327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4752,
      "total_loss": 0.43416711688041687
    },
    {
      "classification_loss": 0.4476543962955475,
      "epoch": 15.583606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4753,
      "total_loss": 0.4476543962955475
    },
    {
      "classification_loss": 0.4771422743797302,
      "epoch": 15.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4754,
      "total_loss": 0.4771422743797302
    },
    {
      "classification_loss": 0.45435306429862976,
      "epoch": 15.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4755,
      "total_loss": 0.45435306429862976
    },
    {
      "classification_loss": 0.49384430050849915,
      "epoch": 15.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4756,
      "total_loss": 0.49384430050849915
    },
    {
      "classification_loss": 0.4217294454574585,
      "epoch": 15.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4757,
      "total_loss": 0.4217294454574585
    },
    {
      "classification_loss": 0.44930389523506165,
      "epoch": 15.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4758,
      "total_loss": 0.44930389523506165
    },
    {
      "classification_loss": 0.47592759132385254,
      "epoch": 15.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4759,
      "total_loss": 0.47592759132385254
    },
    {
      "classification_loss": 0.5034245252609253,
      "epoch": 15.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4760,
      "total_loss": 0.5034245252609253
    },
    {
      "classification_loss": 0.4587829113006592,
      "epoch": 15.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4761,
      "total_loss": 0.4587829113006592
    },
    {
      "classification_loss": 0.46977508068084717,
      "epoch": 15.61311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4762,
      "total_loss": 0.46977508068084717
    },
    {
      "classification_loss": 0.5406263470649719,
      "epoch": 15.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4763,
      "total_loss": 0.5406263470649719
    },
    {
      "classification_loss": 0.48884573578834534,
      "epoch": 15.61967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4764,
      "total_loss": 0.48884573578834534
    },
    {
      "classification_loss": 0.525346040725708,
      "epoch": 15.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4765,
      "total_loss": 0.525346040725708
    },
    {
      "classification_loss": 0.43662071228027344,
      "epoch": 15.62622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4766,
      "total_loss": 0.43662071228027344
    },
    {
      "classification_loss": 0.3643935024738312,
      "epoch": 15.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4767,
      "total_loss": 0.3643935024738312
    },
    {
      "classification_loss": 0.5251558423042297,
      "epoch": 15.6327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4768,
      "total_loss": 0.5251558423042297
    },
    {
      "classification_loss": 0.4482401907444,
      "epoch": 15.636065573770491,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4769,
      "total_loss": 0.4482401907444
    },
    {
      "classification_loss": 0.5336443185806274,
      "epoch": 15.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4770,
      "total_loss": 0.5336443185806274
    },
    {
      "classification_loss": 0.46571338176727295,
      "epoch": 15.642622950819671,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4771,
      "total_loss": 0.46571338176727295
    },
    {
      "classification_loss": 0.532585620880127,
      "epoch": 15.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4772,
      "total_loss": 0.532585620880127
    },
    {
      "classification_loss": 0.5236698389053345,
      "epoch": 15.649180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4773,
      "total_loss": 0.5236698389053345
    },
    {
      "classification_loss": 0.44856107234954834,
      "epoch": 15.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4774,
      "total_loss": 0.44856107234954834
    },
    {
      "classification_loss": 0.4880548417568207,
      "epoch": 15.655737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4775,
      "total_loss": 0.4880548417568207
    },
    {
      "classification_loss": 0.4761645197868347,
      "epoch": 15.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4776,
      "total_loss": 0.4761645197868347
    },
    {
      "classification_loss": 0.42838025093078613,
      "epoch": 15.662295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4777,
      "total_loss": 0.42838025093078613
    },
    {
      "classification_loss": 0.5447594523429871,
      "epoch": 15.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4778,
      "total_loss": 0.5447594523429871
    },
    {
      "classification_loss": 0.391371488571167,
      "epoch": 15.668852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4779,
      "total_loss": 0.391371488571167
    },
    {
      "classification_loss": 0.44142016768455505,
      "epoch": 15.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4780,
      "total_loss": 0.44142016768455505
    },
    {
      "classification_loss": 0.4181842505931854,
      "epoch": 15.675409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4781,
      "total_loss": 0.4181842505931854
    },
    {
      "classification_loss": 0.5016636848449707,
      "epoch": 15.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4782,
      "total_loss": 0.5016636848449707
    },
    {
      "classification_loss": 0.5436920523643494,
      "epoch": 15.681967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4783,
      "total_loss": 0.5436920523643494
    },
    {
      "classification_loss": 0.5237668752670288,
      "epoch": 15.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4784,
      "total_loss": 0.5237668752670288
    },
    {
      "classification_loss": 0.4491235315799713,
      "epoch": 15.688524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4785,
      "total_loss": 0.4491235315799713
    },
    {
      "classification_loss": 0.4780440032482147,
      "epoch": 15.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4786,
      "total_loss": 0.4780440032482147
    },
    {
      "classification_loss": 0.49070051312446594,
      "epoch": 15.695081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4787,
      "total_loss": 0.49070051312446594
    },
    {
      "classification_loss": 0.5323753952980042,
      "epoch": 15.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4788,
      "total_loss": 0.5323753952980042
    },
    {
      "classification_loss": 0.5866297483444214,
      "epoch": 15.701639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4789,
      "total_loss": 0.5866297483444214
    },
    {
      "classification_loss": 0.5029914379119873,
      "epoch": 15.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4790,
      "total_loss": 0.5029914379119873
    },
    {
      "classification_loss": 0.4580482244491577,
      "epoch": 15.708196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4791,
      "total_loss": 0.4580482244491577
    },
    {
      "classification_loss": 0.5276400446891785,
      "epoch": 15.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4792,
      "total_loss": 0.5276400446891785
    },
    {
      "classification_loss": 0.5716831684112549,
      "epoch": 15.714754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4793,
      "total_loss": 0.5716831684112549
    },
    {
      "classification_loss": 0.433497816324234,
      "epoch": 15.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4794,
      "total_loss": 0.433497816324234
    },
    {
      "classification_loss": 0.49446186423301697,
      "epoch": 15.721311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4795,
      "total_loss": 0.49446186423301697
    },
    {
      "classification_loss": 0.4739046096801758,
      "epoch": 15.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4796,
      "total_loss": 0.4739046096801758
    },
    {
      "classification_loss": 0.4369364082813263,
      "epoch": 15.727868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4797,
      "total_loss": 0.4369364082813263
    },
    {
      "classification_loss": 0.4986972212791443,
      "epoch": 15.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4798,
      "total_loss": 0.4986972212791443
    },
    {
      "classification_loss": 0.5183535218238831,
      "epoch": 15.734426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4799,
      "total_loss": 0.5183535218238831
    },
    {
      "epoch": 15.737704918032787,
      "grad_norm": 7.343439102172852,
      "learning_rate": 4.3366666666666666e-05,
      "loss": 0.4835,
      "step": 4800
    },
    {
      "classification_loss": 0.4660714268684387,
      "epoch": 15.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4800,
      "total_loss": 0.4660714268684387
    },
    {
      "classification_loss": 0.5003854632377625,
      "epoch": 15.740983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4801,
      "total_loss": 0.5003854632377625
    },
    {
      "classification_loss": 0.47275224328041077,
      "epoch": 15.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4802,
      "total_loss": 0.47275224328041077
    },
    {
      "classification_loss": 0.5287536978721619,
      "epoch": 15.747540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4803,
      "total_loss": 0.5287536978721619
    },
    {
      "classification_loss": 0.5203025341033936,
      "epoch": 15.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4804,
      "total_loss": 0.5203025341033936
    },
    {
      "classification_loss": 0.4459995925426483,
      "epoch": 15.754098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4805,
      "total_loss": 0.4459995925426483
    },
    {
      "classification_loss": 0.3996942639350891,
      "epoch": 15.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4806,
      "total_loss": 0.3996942639350891
    },
    {
      "classification_loss": 0.3885556757450104,
      "epoch": 15.760655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4807,
      "total_loss": 0.3885556757450104
    },
    {
      "classification_loss": 0.5110278129577637,
      "epoch": 15.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4808,
      "total_loss": 0.5110278129577637
    },
    {
      "classification_loss": 0.5289418697357178,
      "epoch": 15.767213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4809,
      "total_loss": 0.5289418697357178
    },
    {
      "classification_loss": 0.4209817051887512,
      "epoch": 15.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4810,
      "total_loss": 0.4209817051887512
    },
    {
      "classification_loss": 0.5528863072395325,
      "epoch": 15.773770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4811,
      "total_loss": 0.5528863072395325
    },
    {
      "classification_loss": 0.40458816289901733,
      "epoch": 15.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4812,
      "total_loss": 0.40458816289901733
    },
    {
      "classification_loss": 0.39129015803337097,
      "epoch": 15.780327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4813,
      "total_loss": 0.39129015803337097
    },
    {
      "classification_loss": 0.4679345190525055,
      "epoch": 15.783606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4814,
      "total_loss": 0.4679345190525055
    },
    {
      "classification_loss": 0.5763295292854309,
      "epoch": 15.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4815,
      "total_loss": 0.5763295292854309
    },
    {
      "classification_loss": 0.5598390698432922,
      "epoch": 15.790163934426229,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4816,
      "total_loss": 0.5598390698432922
    },
    {
      "classification_loss": 0.5657273530960083,
      "epoch": 15.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4817,
      "total_loss": 0.5657273530960083
    },
    {
      "classification_loss": 0.5113731622695923,
      "epoch": 15.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4818,
      "total_loss": 0.5113731622695923
    },
    {
      "classification_loss": 0.5494846701622009,
      "epoch": 15.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4819,
      "total_loss": 0.5494846701622009
    },
    {
      "classification_loss": 0.6068090796470642,
      "epoch": 15.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4820,
      "total_loss": 0.6068090796470642
    },
    {
      "classification_loss": 0.47395873069763184,
      "epoch": 15.806557377049181,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4821,
      "total_loss": 0.47395873069763184
    },
    {
      "classification_loss": 0.5511445999145508,
      "epoch": 15.809836065573771,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4822,
      "total_loss": 0.5511445999145508
    },
    {
      "classification_loss": 0.49786117672920227,
      "epoch": 15.813114754098361,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4823,
      "total_loss": 0.49786117672920227
    },
    {
      "classification_loss": 0.4843766391277313,
      "epoch": 15.816393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4824,
      "total_loss": 0.4843766391277313
    },
    {
      "classification_loss": 0.4393038749694824,
      "epoch": 15.819672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4825,
      "total_loss": 0.4393038749694824
    },
    {
      "classification_loss": 0.6311313509941101,
      "epoch": 15.822950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4826,
      "total_loss": 0.6311313509941101
    },
    {
      "classification_loss": 0.5885030031204224,
      "epoch": 15.826229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4827,
      "total_loss": 0.5885030031204224
    },
    {
      "classification_loss": 0.4868967533111572,
      "epoch": 15.829508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4828,
      "total_loss": 0.4868967533111572
    },
    {
      "classification_loss": 0.5641271471977234,
      "epoch": 15.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4829,
      "total_loss": 0.5641271471977234
    },
    {
      "classification_loss": 0.4583016037940979,
      "epoch": 15.836065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4830,
      "total_loss": 0.4583016037940979
    },
    {
      "classification_loss": 0.5084565281867981,
      "epoch": 15.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4831,
      "total_loss": 0.5084565281867981
    },
    {
      "classification_loss": 0.4679429531097412,
      "epoch": 15.842622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4832,
      "total_loss": 0.4679429531097412
    },
    {
      "classification_loss": 0.47534894943237305,
      "epoch": 15.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4833,
      "total_loss": 0.47534894943237305
    },
    {
      "classification_loss": 0.4179229438304901,
      "epoch": 15.849180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4834,
      "total_loss": 0.4179229438304901
    },
    {
      "classification_loss": 0.5634200572967529,
      "epoch": 15.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4835,
      "total_loss": 0.5634200572967529
    },
    {
      "classification_loss": 0.36607101559638977,
      "epoch": 15.855737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4836,
      "total_loss": 0.36607101559638977
    },
    {
      "classification_loss": 0.47070831060409546,
      "epoch": 15.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4837,
      "total_loss": 0.47070831060409546
    },
    {
      "classification_loss": 0.45331433415412903,
      "epoch": 15.862295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4838,
      "total_loss": 0.45331433415412903
    },
    {
      "classification_loss": 0.539533793926239,
      "epoch": 15.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4839,
      "total_loss": 0.539533793926239
    },
    {
      "classification_loss": 0.43313613533973694,
      "epoch": 15.868852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4840,
      "total_loss": 0.43313613533973694
    },
    {
      "classification_loss": 0.585189700126648,
      "epoch": 15.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4841,
      "total_loss": 0.585189700126648
    },
    {
      "classification_loss": 0.5251814126968384,
      "epoch": 15.875409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4842,
      "total_loss": 0.5251814126968384
    },
    {
      "classification_loss": 0.5820027589797974,
      "epoch": 15.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4843,
      "total_loss": 0.5820027589797974
    },
    {
      "classification_loss": 0.34505313634872437,
      "epoch": 15.881967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4844,
      "total_loss": 0.34505313634872437
    },
    {
      "classification_loss": 0.4901510775089264,
      "epoch": 15.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4845,
      "total_loss": 0.4901510775089264
    },
    {
      "classification_loss": 0.4539082646369934,
      "epoch": 15.888524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4846,
      "total_loss": 0.4539082646369934
    },
    {
      "classification_loss": 0.461471825838089,
      "epoch": 15.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4847,
      "total_loss": 0.461471825838089
    },
    {
      "classification_loss": 0.46146637201309204,
      "epoch": 15.895081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4848,
      "total_loss": 0.46146637201309204
    },
    {
      "classification_loss": 0.6015766263008118,
      "epoch": 15.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4849,
      "total_loss": 0.6015766263008118
    },
    {
      "classification_loss": 0.5534577965736389,
      "epoch": 15.901639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4850,
      "total_loss": 0.5534577965736389
    },
    {
      "classification_loss": 0.6381363868713379,
      "epoch": 15.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4851,
      "total_loss": 0.6381363868713379
    },
    {
      "classification_loss": 0.626654326915741,
      "epoch": 15.908196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4852,
      "total_loss": 0.626654326915741
    },
    {
      "classification_loss": 0.5047300457954407,
      "epoch": 15.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4853,
      "total_loss": 0.5047300457954407
    },
    {
      "classification_loss": 0.49471187591552734,
      "epoch": 15.914754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4854,
      "total_loss": 0.49471187591552734
    },
    {
      "classification_loss": 0.4463677704334259,
      "epoch": 15.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4855,
      "total_loss": 0.4463677704334259
    },
    {
      "classification_loss": 0.4995681643486023,
      "epoch": 15.921311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4856,
      "total_loss": 0.4995681643486023
    },
    {
      "classification_loss": 0.6004689335823059,
      "epoch": 15.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4857,
      "total_loss": 0.6004689335823059
    },
    {
      "classification_loss": 0.4021831452846527,
      "epoch": 15.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4858,
      "total_loss": 0.4021831452846527
    },
    {
      "classification_loss": 0.4003312587738037,
      "epoch": 15.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4859,
      "total_loss": 0.4003312587738037
    },
    {
      "classification_loss": 0.48314377665519714,
      "epoch": 15.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4860,
      "total_loss": 0.48314377665519714
    },
    {
      "classification_loss": 0.5660861134529114,
      "epoch": 15.937704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4861,
      "total_loss": 0.5660861134529114
    },
    {
      "classification_loss": 0.47037479281425476,
      "epoch": 15.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4862,
      "total_loss": 0.47037479281425476
    },
    {
      "classification_loss": 0.3748280704021454,
      "epoch": 15.944262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4863,
      "total_loss": 0.3748280704021454
    },
    {
      "classification_loss": 0.5069332718849182,
      "epoch": 15.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4864,
      "total_loss": 0.5069332718849182
    },
    {
      "classification_loss": 0.5247786641120911,
      "epoch": 15.950819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4865,
      "total_loss": 0.5247786641120911
    },
    {
      "classification_loss": 0.4573420286178589,
      "epoch": 15.954098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4866,
      "total_loss": 0.4573420286178589
    },
    {
      "classification_loss": 0.40183237195014954,
      "epoch": 15.957377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4867,
      "total_loss": 0.40183237195014954
    },
    {
      "classification_loss": 0.5759028196334839,
      "epoch": 15.960655737704919,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4868,
      "total_loss": 0.5759028196334839
    },
    {
      "classification_loss": 0.45708325505256653,
      "epoch": 15.963934426229509,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4869,
      "total_loss": 0.45708325505256653
    },
    {
      "classification_loss": 0.43996021151542664,
      "epoch": 15.967213114754099,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4870,
      "total_loss": 0.43996021151542664
    },
    {
      "classification_loss": 0.5070086121559143,
      "epoch": 15.970491803278689,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4871,
      "total_loss": 0.5070086121559143
    },
    {
      "classification_loss": 0.4339120388031006,
      "epoch": 15.973770491803279,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4872,
      "total_loss": 0.4339120388031006
    },
    {
      "classification_loss": 0.514643132686615,
      "epoch": 15.97704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4873,
      "total_loss": 0.514643132686615
    },
    {
      "classification_loss": 0.4957197308540344,
      "epoch": 15.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4874,
      "total_loss": 0.4957197308540344
    },
    {
      "classification_loss": 0.4062548279762268,
      "epoch": 15.98360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4875,
      "total_loss": 0.4062548279762268
    },
    {
      "classification_loss": 0.41077229380607605,
      "epoch": 15.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4876,
      "total_loss": 0.41077229380607605
    },
    {
      "classification_loss": 0.514982283115387,
      "epoch": 15.99016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4877,
      "total_loss": 0.514982283115387
    },
    {
      "classification_loss": 0.46468019485473633,
      "epoch": 15.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4878,
      "total_loss": 0.46468019485473633
    },
    {
      "classification_loss": 0.3628758192062378,
      "epoch": 15.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4879,
      "total_loss": 0.3628758192062378
    },
    {
      "classification_loss": 1.4166646003723145,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.4166646003723145
    },
    {
      "classification_loss": 1.347070574760437,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.347070574760437
    },
    {
      "classification_loss": 1.2438526153564453,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.2438526153564453
    },
    {
      "classification_loss": 1.5394483804702759,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.5394483804702759
    },
    {
      "classification_loss": 1.262710690498352,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.262710690498352
    },
    {
      "classification_loss": 1.2512435913085938,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.2512435913085938
    },
    {
      "classification_loss": 1.3295339345932007,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.3295339345932007
    },
    {
      "classification_loss": 1.129260540008545,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 1.129260540008545
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.3194302320480347,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0248,
      "eval_samples_per_second": 165.98,
      "eval_steps_per_second": 1.328,
      "step": 4880
    },
    {
      "classification_loss": 0.5326530337333679,
      "epoch": 16.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4880,
      "total_loss": 0.5326530337333679
    },
    {
      "classification_loss": 0.43822675943374634,
      "epoch": 16.003278688524592,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4881,
      "total_loss": 0.43822675943374634
    },
    {
      "classification_loss": 0.35641729831695557,
      "epoch": 16.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4882,
      "total_loss": 0.35641729831695557
    },
    {
      "classification_loss": 0.34915444254875183,
      "epoch": 16.009836065573772,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4883,
      "total_loss": 0.34915444254875183
    },
    {
      "classification_loss": 0.5221919417381287,
      "epoch": 16.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4884,
      "total_loss": 0.5221919417381287
    },
    {
      "classification_loss": 0.5156352519989014,
      "epoch": 16.016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4885,
      "total_loss": 0.5156352519989014
    },
    {
      "classification_loss": 0.3646883964538574,
      "epoch": 16.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4886,
      "total_loss": 0.3646883964538574
    },
    {
      "classification_loss": 0.49460363388061523,
      "epoch": 16.022950819672133,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4887,
      "total_loss": 0.49460363388061523
    },
    {
      "classification_loss": 0.5997026562690735,
      "epoch": 16.02622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4888,
      "total_loss": 0.5997026562690735
    },
    {
      "classification_loss": 0.4165801703929901,
      "epoch": 16.029508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4889,
      "total_loss": 0.4165801703929901
    },
    {
      "classification_loss": 0.42151036858558655,
      "epoch": 16.0327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4890,
      "total_loss": 0.42151036858558655
    },
    {
      "classification_loss": 0.507990300655365,
      "epoch": 16.036065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4891,
      "total_loss": 0.507990300655365
    },
    {
      "classification_loss": 0.6016276478767395,
      "epoch": 16.03934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4892,
      "total_loss": 0.6016276478767395
    },
    {
      "classification_loss": 0.39905866980552673,
      "epoch": 16.042622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4893,
      "total_loss": 0.39905866980552673
    },
    {
      "classification_loss": 0.5223903059959412,
      "epoch": 16.04590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4894,
      "total_loss": 0.5223903059959412
    },
    {
      "classification_loss": 0.37577471137046814,
      "epoch": 16.049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4895,
      "total_loss": 0.37577471137046814
    },
    {
      "classification_loss": 0.4116837680339813,
      "epoch": 16.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4896,
      "total_loss": 0.4116837680339813
    },
    {
      "classification_loss": 0.5175357460975647,
      "epoch": 16.055737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4897,
      "total_loss": 0.5175357460975647
    },
    {
      "classification_loss": 0.34621095657348633,
      "epoch": 16.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4898,
      "total_loss": 0.34621095657348633
    },
    {
      "classification_loss": 0.5856378674507141,
      "epoch": 16.062295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4899,
      "total_loss": 0.5856378674507141
    },
    {
      "epoch": 16.065573770491802,
      "grad_norm": 9.612466812133789,
      "learning_rate": 4.0033333333333335e-05,
      "loss": 0.4856,
      "step": 4900
    },
    {
      "classification_loss": 0.5478633046150208,
      "epoch": 16.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4900,
      "total_loss": 0.5478633046150208
    },
    {
      "classification_loss": 0.4120636284351349,
      "epoch": 16.068852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4901,
      "total_loss": 0.4120636284351349
    },
    {
      "classification_loss": 0.5763821005821228,
      "epoch": 16.072131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4902,
      "total_loss": 0.5763821005821228
    },
    {
      "classification_loss": 0.4342520833015442,
      "epoch": 16.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4903,
      "total_loss": 0.4342520833015442
    },
    {
      "classification_loss": 0.3505578637123108,
      "epoch": 16.078688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4904,
      "total_loss": 0.3505578637123108
    },
    {
      "classification_loss": 0.559218168258667,
      "epoch": 16.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4905,
      "total_loss": 0.559218168258667
    },
    {
      "classification_loss": 0.4529881775379181,
      "epoch": 16.085245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4906,
      "total_loss": 0.4529881775379181
    },
    {
      "classification_loss": 0.574903130531311,
      "epoch": 16.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4907,
      "total_loss": 0.574903130531311
    },
    {
      "classification_loss": 0.46757063269615173,
      "epoch": 16.091803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4908,
      "total_loss": 0.46757063269615173
    },
    {
      "classification_loss": 0.4718061685562134,
      "epoch": 16.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4909,
      "total_loss": 0.4718061685562134
    },
    {
      "classification_loss": 0.4747764766216278,
      "epoch": 16.098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4910,
      "total_loss": 0.4747764766216278
    },
    {
      "classification_loss": 0.5095009207725525,
      "epoch": 16.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4911,
      "total_loss": 0.5095009207725525
    },
    {
      "classification_loss": 0.36458781361579895,
      "epoch": 16.104918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4912,
      "total_loss": 0.36458781361579895
    },
    {
      "classification_loss": 0.5105099678039551,
      "epoch": 16.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4913,
      "total_loss": 0.5105099678039551
    },
    {
      "classification_loss": 0.39088672399520874,
      "epoch": 16.111475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4914,
      "total_loss": 0.39088672399520874
    },
    {
      "classification_loss": 0.42660650610923767,
      "epoch": 16.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4915,
      "total_loss": 0.42660650610923767
    },
    {
      "classification_loss": 0.4569493532180786,
      "epoch": 16.118032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4916,
      "total_loss": 0.4569493532180786
    },
    {
      "classification_loss": 0.48079612851142883,
      "epoch": 16.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4917,
      "total_loss": 0.48079612851142883
    },
    {
      "classification_loss": 0.623803436756134,
      "epoch": 16.124590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4918,
      "total_loss": 0.623803436756134
    },
    {
      "classification_loss": 0.5489811301231384,
      "epoch": 16.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4919,
      "total_loss": 0.5489811301231384
    },
    {
      "classification_loss": 0.4771437644958496,
      "epoch": 16.131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4920,
      "total_loss": 0.4771437644958496
    },
    {
      "classification_loss": 0.5328304171562195,
      "epoch": 16.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4921,
      "total_loss": 0.5328304171562195
    },
    {
      "classification_loss": 0.5980777740478516,
      "epoch": 16.137704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4922,
      "total_loss": 0.5980777740478516
    },
    {
      "classification_loss": 0.41696685552597046,
      "epoch": 16.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4923,
      "total_loss": 0.41696685552597046
    },
    {
      "classification_loss": 0.4933491349220276,
      "epoch": 16.14426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4924,
      "total_loss": 0.4933491349220276
    },
    {
      "classification_loss": 0.454263836145401,
      "epoch": 16.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4925,
      "total_loss": 0.454263836145401
    },
    {
      "classification_loss": 0.5074437260627747,
      "epoch": 16.15081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4926,
      "total_loss": 0.5074437260627747
    },
    {
      "classification_loss": 0.5388716459274292,
      "epoch": 16.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4927,
      "total_loss": 0.5388716459274292
    },
    {
      "classification_loss": 0.38536450266838074,
      "epoch": 16.15737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4928,
      "total_loss": 0.38536450266838074
    },
    {
      "classification_loss": 0.5955142974853516,
      "epoch": 16.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4929,
      "total_loss": 0.5955142974853516
    },
    {
      "classification_loss": 0.3734165132045746,
      "epoch": 16.16393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4930,
      "total_loss": 0.3734165132045746
    },
    {
      "classification_loss": 0.4243772029876709,
      "epoch": 16.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4931,
      "total_loss": 0.4243772029876709
    },
    {
      "classification_loss": 0.44691529870033264,
      "epoch": 16.17049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4932,
      "total_loss": 0.44691529870033264
    },
    {
      "classification_loss": 0.5041159391403198,
      "epoch": 16.17377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4933,
      "total_loss": 0.5041159391403198
    },
    {
      "classification_loss": 0.5446236729621887,
      "epoch": 16.17704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4934,
      "total_loss": 0.5446236729621887
    },
    {
      "classification_loss": 0.49920594692230225,
      "epoch": 16.18032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4935,
      "total_loss": 0.49920594692230225
    },
    {
      "classification_loss": 0.4700012803077698,
      "epoch": 16.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4936,
      "total_loss": 0.4700012803077698
    },
    {
      "classification_loss": 0.46435829997062683,
      "epoch": 16.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4937,
      "total_loss": 0.46435829997062683
    },
    {
      "classification_loss": 0.4779753088951111,
      "epoch": 16.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4938,
      "total_loss": 0.4779753088951111
    },
    {
      "classification_loss": 0.496260404586792,
      "epoch": 16.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4939,
      "total_loss": 0.496260404586792
    },
    {
      "classification_loss": 0.4763658940792084,
      "epoch": 16.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4940,
      "total_loss": 0.4763658940792084
    },
    {
      "classification_loss": 0.5873585343360901,
      "epoch": 16.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4941,
      "total_loss": 0.5873585343360901
    },
    {
      "classification_loss": 0.4060766398906708,
      "epoch": 16.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4942,
      "total_loss": 0.4060766398906708
    },
    {
      "classification_loss": 0.6416188478469849,
      "epoch": 16.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4943,
      "total_loss": 0.6416188478469849
    },
    {
      "classification_loss": 0.40058088302612305,
      "epoch": 16.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4944,
      "total_loss": 0.40058088302612305
    },
    {
      "classification_loss": 0.4711969494819641,
      "epoch": 16.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4945,
      "total_loss": 0.4711969494819641
    },
    {
      "classification_loss": 0.44092339277267456,
      "epoch": 16.21639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4946,
      "total_loss": 0.44092339277267456
    },
    {
      "classification_loss": 0.49237367510795593,
      "epoch": 16.21967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4947,
      "total_loss": 0.49237367510795593
    },
    {
      "classification_loss": 0.392971009016037,
      "epoch": 16.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4948,
      "total_loss": 0.392971009016037
    },
    {
      "classification_loss": 0.5391323566436768,
      "epoch": 16.22622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4949,
      "total_loss": 0.5391323566436768
    },
    {
      "classification_loss": 0.4240359961986542,
      "epoch": 16.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4950,
      "total_loss": 0.4240359961986542
    },
    {
      "classification_loss": 0.4092808663845062,
      "epoch": 16.2327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4951,
      "total_loss": 0.4092808663845062
    },
    {
      "classification_loss": 0.4993462562561035,
      "epoch": 16.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4952,
      "total_loss": 0.4993462562561035
    },
    {
      "classification_loss": 0.5119415521621704,
      "epoch": 16.23934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4953,
      "total_loss": 0.5119415521621704
    },
    {
      "classification_loss": 0.41913536190986633,
      "epoch": 16.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4954,
      "total_loss": 0.41913536190986633
    },
    {
      "classification_loss": 0.5309298038482666,
      "epoch": 16.24590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4955,
      "total_loss": 0.5309298038482666
    },
    {
      "classification_loss": 0.527768611907959,
      "epoch": 16.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4956,
      "total_loss": 0.527768611907959
    },
    {
      "classification_loss": 0.4527195692062378,
      "epoch": 16.25245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4957,
      "total_loss": 0.4527195692062378
    },
    {
      "classification_loss": 0.511828601360321,
      "epoch": 16.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4958,
      "total_loss": 0.511828601360321
    },
    {
      "classification_loss": 0.3947465419769287,
      "epoch": 16.25901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4959,
      "total_loss": 0.3947465419769287
    },
    {
      "classification_loss": 0.5177026391029358,
      "epoch": 16.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4960,
      "total_loss": 0.5177026391029358
    },
    {
      "classification_loss": 0.5363761186599731,
      "epoch": 16.2655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4961,
      "total_loss": 0.5363761186599731
    },
    {
      "classification_loss": 0.4943728744983673,
      "epoch": 16.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4962,
      "total_loss": 0.4943728744983673
    },
    {
      "classification_loss": 0.515194296836853,
      "epoch": 16.272131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4963,
      "total_loss": 0.515194296836853
    },
    {
      "classification_loss": 0.58246248960495,
      "epoch": 16.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4964,
      "total_loss": 0.58246248960495
    },
    {
      "classification_loss": 0.4192087650299072,
      "epoch": 16.278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4965,
      "total_loss": 0.4192087650299072
    },
    {
      "classification_loss": 0.33420488238334656,
      "epoch": 16.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4966,
      "total_loss": 0.33420488238334656
    },
    {
      "classification_loss": 0.5103205442428589,
      "epoch": 16.285245901639342,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4967,
      "total_loss": 0.5103205442428589
    },
    {
      "classification_loss": 0.6026871800422668,
      "epoch": 16.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4968,
      "total_loss": 0.6026871800422668
    },
    {
      "classification_loss": 0.4305727481842041,
      "epoch": 16.291803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4969,
      "total_loss": 0.4305727481842041
    },
    {
      "classification_loss": 0.5575262904167175,
      "epoch": 16.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4970,
      "total_loss": 0.5575262904167175
    },
    {
      "classification_loss": 0.44018325209617615,
      "epoch": 16.298360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4971,
      "total_loss": 0.44018325209617615
    },
    {
      "classification_loss": 0.5117371082305908,
      "epoch": 16.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4972,
      "total_loss": 0.5117371082305908
    },
    {
      "classification_loss": 0.36760732531547546,
      "epoch": 16.304918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4973,
      "total_loss": 0.36760732531547546
    },
    {
      "classification_loss": 0.4450256824493408,
      "epoch": 16.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4974,
      "total_loss": 0.4450256824493408
    },
    {
      "classification_loss": 0.4362146556377411,
      "epoch": 16.311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4975,
      "total_loss": 0.4362146556377411
    },
    {
      "classification_loss": 0.5463221669197083,
      "epoch": 16.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4976,
      "total_loss": 0.5463221669197083
    },
    {
      "classification_loss": 0.37669679522514343,
      "epoch": 16.318032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4977,
      "total_loss": 0.37669679522514343
    },
    {
      "classification_loss": 0.5349212288856506,
      "epoch": 16.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4978,
      "total_loss": 0.5349212288856506
    },
    {
      "classification_loss": 0.6059102416038513,
      "epoch": 16.324590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4979,
      "total_loss": 0.6059102416038513
    },
    {
      "classification_loss": 0.4890539348125458,
      "epoch": 16.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4980,
      "total_loss": 0.4890539348125458
    },
    {
      "classification_loss": 0.4640292823314667,
      "epoch": 16.331147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4981,
      "total_loss": 0.4640292823314667
    },
    {
      "classification_loss": 0.44559746980667114,
      "epoch": 16.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4982,
      "total_loss": 0.44559746980667114
    },
    {
      "classification_loss": 0.5196584463119507,
      "epoch": 16.337704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4983,
      "total_loss": 0.5196584463119507
    },
    {
      "classification_loss": 0.5118195414543152,
      "epoch": 16.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4984,
      "total_loss": 0.5118195414543152
    },
    {
      "classification_loss": 0.5263239145278931,
      "epoch": 16.34426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4985,
      "total_loss": 0.5263239145278931
    },
    {
      "classification_loss": 0.3859061002731323,
      "epoch": 16.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4986,
      "total_loss": 0.3859061002731323
    },
    {
      "classification_loss": 0.4778664708137512,
      "epoch": 16.35081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4987,
      "total_loss": 0.4778664708137512
    },
    {
      "classification_loss": 0.5681044459342957,
      "epoch": 16.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4988,
      "total_loss": 0.5681044459342957
    },
    {
      "classification_loss": 0.4599880278110504,
      "epoch": 16.35737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4989,
      "total_loss": 0.4599880278110504
    },
    {
      "classification_loss": 0.3853556215763092,
      "epoch": 16.360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4990,
      "total_loss": 0.3853556215763092
    },
    {
      "classification_loss": 0.4883091151714325,
      "epoch": 16.36393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4991,
      "total_loss": 0.4883091151714325
    },
    {
      "classification_loss": 0.510023832321167,
      "epoch": 16.367213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4992,
      "total_loss": 0.510023832321167
    },
    {
      "classification_loss": 0.42729729413986206,
      "epoch": 16.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4993,
      "total_loss": 0.42729729413986206
    },
    {
      "classification_loss": 0.553066074848175,
      "epoch": 16.373770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4994,
      "total_loss": 0.553066074848175
    },
    {
      "classification_loss": 0.5291788578033447,
      "epoch": 16.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4995,
      "total_loss": 0.5291788578033447
    },
    {
      "classification_loss": 0.4657953679561615,
      "epoch": 16.380327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4996,
      "total_loss": 0.4657953679561615
    },
    {
      "classification_loss": 0.555427074432373,
      "epoch": 16.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4997,
      "total_loss": 0.555427074432373
    },
    {
      "classification_loss": 0.4295606017112732,
      "epoch": 16.386885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4998,
      "total_loss": 0.4295606017112732
    },
    {
      "classification_loss": 0.4243597686290741,
      "epoch": 16.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 4999,
      "total_loss": 0.4243597686290741
    },
    {
      "epoch": 16.39344262295082,
      "grad_norm": 2.0237715244293213,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 0.4825,
      "step": 5000
    },
    {
      "classification_loss": 0.45443230867385864,
      "epoch": 16.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5000,
      "total_loss": 0.45443230867385864
    },
    {
      "classification_loss": 0.5360566973686218,
      "epoch": 16.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5001,
      "total_loss": 0.5360566973686218
    },
    {
      "classification_loss": 0.4524683952331543,
      "epoch": 16.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5002,
      "total_loss": 0.4524683952331543
    },
    {
      "classification_loss": 0.48183372616767883,
      "epoch": 16.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5003,
      "total_loss": 0.48183372616767883
    },
    {
      "classification_loss": 0.42859235405921936,
      "epoch": 16.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5004,
      "total_loss": 0.42859235405921936
    },
    {
      "classification_loss": 0.6212461590766907,
      "epoch": 16.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5005,
      "total_loss": 0.6212461590766907
    },
    {
      "classification_loss": 0.5165237188339233,
      "epoch": 16.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5006,
      "total_loss": 0.5165237188339233
    },
    {
      "classification_loss": 0.47891178727149963,
      "epoch": 16.41639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5007,
      "total_loss": 0.47891178727149963
    },
    {
      "classification_loss": 0.4655896723270416,
      "epoch": 16.41967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5008,
      "total_loss": 0.4655896723270416
    },
    {
      "classification_loss": 0.5153012871742249,
      "epoch": 16.42295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5009,
      "total_loss": 0.5153012871742249
    },
    {
      "classification_loss": 0.5925242900848389,
      "epoch": 16.42622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5010,
      "total_loss": 0.5925242900848389
    },
    {
      "classification_loss": 0.3907785713672638,
      "epoch": 16.42950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5011,
      "total_loss": 0.3907785713672638
    },
    {
      "classification_loss": 0.4935900568962097,
      "epoch": 16.432786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5012,
      "total_loss": 0.4935900568962097
    },
    {
      "classification_loss": 0.4166685938835144,
      "epoch": 16.43606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5013,
      "total_loss": 0.4166685938835144
    },
    {
      "classification_loss": 0.4789217710494995,
      "epoch": 16.439344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5014,
      "total_loss": 0.4789217710494995
    },
    {
      "classification_loss": 0.5628713965415955,
      "epoch": 16.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5015,
      "total_loss": 0.5628713965415955
    },
    {
      "classification_loss": 0.4721314609050751,
      "epoch": 16.445901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5016,
      "total_loss": 0.4721314609050751
    },
    {
      "classification_loss": 0.5023902058601379,
      "epoch": 16.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5017,
      "total_loss": 0.5023902058601379
    },
    {
      "classification_loss": 0.4424169361591339,
      "epoch": 16.452459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5018,
      "total_loss": 0.4424169361591339
    },
    {
      "classification_loss": 0.514051079750061,
      "epoch": 16.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5019,
      "total_loss": 0.514051079750061
    },
    {
      "classification_loss": 0.473375529050827,
      "epoch": 16.459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5020,
      "total_loss": 0.473375529050827
    },
    {
      "classification_loss": 0.4870744049549103,
      "epoch": 16.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5021,
      "total_loss": 0.4870744049549103
    },
    {
      "classification_loss": 0.478019118309021,
      "epoch": 16.465573770491805,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5022,
      "total_loss": 0.478019118309021
    },
    {
      "classification_loss": 0.5154613852500916,
      "epoch": 16.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5023,
      "total_loss": 0.5154613852500916
    },
    {
      "classification_loss": 0.45544078946113586,
      "epoch": 16.472131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5024,
      "total_loss": 0.45544078946113586
    },
    {
      "classification_loss": 0.48756372928619385,
      "epoch": 16.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5025,
      "total_loss": 0.48756372928619385
    },
    {
      "classification_loss": 0.5477169156074524,
      "epoch": 16.478688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5026,
      "total_loss": 0.5477169156074524
    },
    {
      "classification_loss": 0.5994890332221985,
      "epoch": 16.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5027,
      "total_loss": 0.5994890332221985
    },
    {
      "classification_loss": 0.4738636612892151,
      "epoch": 16.485245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5028,
      "total_loss": 0.4738636612892151
    },
    {
      "classification_loss": 0.4560324251651764,
      "epoch": 16.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5029,
      "total_loss": 0.4560324251651764
    },
    {
      "classification_loss": 0.4341045022010803,
      "epoch": 16.491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5030,
      "total_loss": 0.4341045022010803
    },
    {
      "classification_loss": 0.49433594942092896,
      "epoch": 16.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5031,
      "total_loss": 0.49433594942092896
    },
    {
      "classification_loss": 0.4623350203037262,
      "epoch": 16.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5032,
      "total_loss": 0.4623350203037262
    },
    {
      "classification_loss": 0.5083321332931519,
      "epoch": 16.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5033,
      "total_loss": 0.5083321332931519
    },
    {
      "classification_loss": 0.4668578803539276,
      "epoch": 16.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5034,
      "total_loss": 0.4668578803539276
    },
    {
      "classification_loss": 0.4464357793331146,
      "epoch": 16.508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5035,
      "total_loss": 0.4464357793331146
    },
    {
      "classification_loss": 0.5118799209594727,
      "epoch": 16.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5036,
      "total_loss": 0.5118799209594727
    },
    {
      "classification_loss": 0.5062384605407715,
      "epoch": 16.514754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5037,
      "total_loss": 0.5062384605407715
    },
    {
      "classification_loss": 0.505561351776123,
      "epoch": 16.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5038,
      "total_loss": 0.505561351776123
    },
    {
      "classification_loss": 0.47970864176750183,
      "epoch": 16.521311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5039,
      "total_loss": 0.47970864176750183
    },
    {
      "classification_loss": 0.548088788986206,
      "epoch": 16.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5040,
      "total_loss": 0.548088788986206
    },
    {
      "classification_loss": 0.4025603234767914,
      "epoch": 16.527868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5041,
      "total_loss": 0.4025603234767914
    },
    {
      "classification_loss": 0.43459558486938477,
      "epoch": 16.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5042,
      "total_loss": 0.43459558486938477
    },
    {
      "classification_loss": 0.4904540777206421,
      "epoch": 16.534426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5043,
      "total_loss": 0.4904540777206421
    },
    {
      "classification_loss": 0.5048555135726929,
      "epoch": 16.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5044,
      "total_loss": 0.5048555135726929
    },
    {
      "classification_loss": 0.49631911516189575,
      "epoch": 16.540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5045,
      "total_loss": 0.49631911516189575
    },
    {
      "classification_loss": 0.46743857860565186,
      "epoch": 16.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5046,
      "total_loss": 0.46743857860565186
    },
    {
      "classification_loss": 0.5428307056427002,
      "epoch": 16.547540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5047,
      "total_loss": 0.5428307056427002
    },
    {
      "classification_loss": 0.5347242951393127,
      "epoch": 16.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5048,
      "total_loss": 0.5347242951393127
    },
    {
      "classification_loss": 0.4370012581348419,
      "epoch": 16.554098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5049,
      "total_loss": 0.4370012581348419
    },
    {
      "classification_loss": 0.4429711699485779,
      "epoch": 16.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5050,
      "total_loss": 0.4429711699485779
    },
    {
      "classification_loss": 0.42446544766426086,
      "epoch": 16.560655737704916,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5051,
      "total_loss": 0.42446544766426086
    },
    {
      "classification_loss": 0.45191654562950134,
      "epoch": 16.56393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5052,
      "total_loss": 0.45191654562950134
    },
    {
      "classification_loss": 0.4530293941497803,
      "epoch": 16.567213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5053,
      "total_loss": 0.4530293941497803
    },
    {
      "classification_loss": 0.38925620913505554,
      "epoch": 16.57049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5054,
      "total_loss": 0.38925620913505554
    },
    {
      "classification_loss": 0.4459882080554962,
      "epoch": 16.57377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5055,
      "total_loss": 0.4459882080554962
    },
    {
      "classification_loss": 0.5349553823471069,
      "epoch": 16.57704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5056,
      "total_loss": 0.5349553823471069
    },
    {
      "classification_loss": 0.5106131434440613,
      "epoch": 16.58032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5057,
      "total_loss": 0.5106131434440613
    },
    {
      "classification_loss": 0.5264917612075806,
      "epoch": 16.58360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5058,
      "total_loss": 0.5264917612075806
    },
    {
      "classification_loss": 0.45252725481987,
      "epoch": 16.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5059,
      "total_loss": 0.45252725481987
    },
    {
      "classification_loss": 0.472574919462204,
      "epoch": 16.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5060,
      "total_loss": 0.472574919462204
    },
    {
      "classification_loss": 0.612838625907898,
      "epoch": 16.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5061,
      "total_loss": 0.612838625907898
    },
    {
      "classification_loss": 0.5019907355308533,
      "epoch": 16.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5062,
      "total_loss": 0.5019907355308533
    },
    {
      "classification_loss": 0.36659979820251465,
      "epoch": 16.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5063,
      "total_loss": 0.36659979820251465
    },
    {
      "classification_loss": 0.44958460330963135,
      "epoch": 16.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5064,
      "total_loss": 0.44958460330963135
    },
    {
      "classification_loss": 0.4984965920448303,
      "epoch": 16.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5065,
      "total_loss": 0.4984965920448303
    },
    {
      "classification_loss": 0.4627199172973633,
      "epoch": 16.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5066,
      "total_loss": 0.4627199172973633
    },
    {
      "classification_loss": 0.6066243648529053,
      "epoch": 16.613114754098362,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5067,
      "total_loss": 0.6066243648529053
    },
    {
      "classification_loss": 0.4234256446361542,
      "epoch": 16.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5068,
      "total_loss": 0.4234256446361542
    },
    {
      "classification_loss": 0.6162000298500061,
      "epoch": 16.619672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5069,
      "total_loss": 0.6162000298500061
    },
    {
      "classification_loss": 0.49263909459114075,
      "epoch": 16.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5070,
      "total_loss": 0.49263909459114075
    },
    {
      "classification_loss": 0.487044095993042,
      "epoch": 16.626229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5071,
      "total_loss": 0.487044095993042
    },
    {
      "classification_loss": 0.4063573479652405,
      "epoch": 16.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5072,
      "total_loss": 0.4063573479652405
    },
    {
      "classification_loss": 0.5332143902778625,
      "epoch": 16.632786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5073,
      "total_loss": 0.5332143902778625
    },
    {
      "classification_loss": 0.4335542917251587,
      "epoch": 16.63606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5074,
      "total_loss": 0.4335542917251587
    },
    {
      "classification_loss": 0.4860773980617523,
      "epoch": 16.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5075,
      "total_loss": 0.4860773980617523
    },
    {
      "classification_loss": 0.49346062541007996,
      "epoch": 16.64262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5076,
      "total_loss": 0.49346062541007996
    },
    {
      "classification_loss": 0.45821788907051086,
      "epoch": 16.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5077,
      "total_loss": 0.45821788907051086
    },
    {
      "classification_loss": 0.4613421559333801,
      "epoch": 16.64918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5078,
      "total_loss": 0.4613421559333801
    },
    {
      "classification_loss": 0.5381531715393066,
      "epoch": 16.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5079,
      "total_loss": 0.5381531715393066
    },
    {
      "classification_loss": 0.4417385458946228,
      "epoch": 16.65573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5080,
      "total_loss": 0.4417385458946228
    },
    {
      "classification_loss": 0.3559706211090088,
      "epoch": 16.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5081,
      "total_loss": 0.3559706211090088
    },
    {
      "classification_loss": 0.5287888646125793,
      "epoch": 16.662295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5082,
      "total_loss": 0.5287888646125793
    },
    {
      "classification_loss": 0.5160485506057739,
      "epoch": 16.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5083,
      "total_loss": 0.5160485506057739
    },
    {
      "classification_loss": 0.48359644412994385,
      "epoch": 16.668852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5084,
      "total_loss": 0.48359644412994385
    },
    {
      "classification_loss": 0.4061976671218872,
      "epoch": 16.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5085,
      "total_loss": 0.4061976671218872
    },
    {
      "classification_loss": 0.46556606888771057,
      "epoch": 16.675409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5086,
      "total_loss": 0.46556606888771057
    },
    {
      "classification_loss": 0.4899480640888214,
      "epoch": 16.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5087,
      "total_loss": 0.4899480640888214
    },
    {
      "classification_loss": 0.47396552562713623,
      "epoch": 16.681967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5088,
      "total_loss": 0.47396552562713623
    },
    {
      "classification_loss": 0.4737015962600708,
      "epoch": 16.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5089,
      "total_loss": 0.4737015962600708
    },
    {
      "classification_loss": 0.5398303866386414,
      "epoch": 16.688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5090,
      "total_loss": 0.5398303866386414
    },
    {
      "classification_loss": 0.5595307350158691,
      "epoch": 16.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5091,
      "total_loss": 0.5595307350158691
    },
    {
      "classification_loss": 0.5955363512039185,
      "epoch": 16.695081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5092,
      "total_loss": 0.5955363512039185
    },
    {
      "classification_loss": 0.531935453414917,
      "epoch": 16.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5093,
      "total_loss": 0.531935453414917
    },
    {
      "classification_loss": 0.5155067443847656,
      "epoch": 16.701639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5094,
      "total_loss": 0.5155067443847656
    },
    {
      "classification_loss": 0.503989577293396,
      "epoch": 16.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5095,
      "total_loss": 0.503989577293396
    },
    {
      "classification_loss": 0.33661824464797974,
      "epoch": 16.708196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5096,
      "total_loss": 0.33661824464797974
    },
    {
      "classification_loss": 0.3993193507194519,
      "epoch": 16.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5097,
      "total_loss": 0.3993193507194519
    },
    {
      "classification_loss": 0.5862541794776917,
      "epoch": 16.714754098360658,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5098,
      "total_loss": 0.5862541794776917
    },
    {
      "classification_loss": 0.5615648031234741,
      "epoch": 16.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5099,
      "total_loss": 0.5615648031234741
    },
    {
      "epoch": 16.721311475409838,
      "grad_norm": 2.018801212310791,
      "learning_rate": 3.336666666666667e-05,
      "loss": 0.4866,
      "step": 5100
    },
    {
      "classification_loss": 0.49060267210006714,
      "epoch": 16.721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5100,
      "total_loss": 0.49060267210006714
    },
    {
      "classification_loss": 0.37962350249290466,
      "epoch": 16.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5101,
      "total_loss": 0.37962350249290466
    },
    {
      "classification_loss": 0.49866434931755066,
      "epoch": 16.727868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5102,
      "total_loss": 0.49866434931755066
    },
    {
      "classification_loss": 0.5117188692092896,
      "epoch": 16.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5103,
      "total_loss": 0.5117188692092896
    },
    {
      "classification_loss": 0.4762536585330963,
      "epoch": 16.7344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5104,
      "total_loss": 0.4762536585330963
    },
    {
      "classification_loss": 0.40645211935043335,
      "epoch": 16.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5105,
      "total_loss": 0.40645211935043335
    },
    {
      "classification_loss": 0.38637980818748474,
      "epoch": 16.74098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5106,
      "total_loss": 0.38637980818748474
    },
    {
      "classification_loss": 0.5970403552055359,
      "epoch": 16.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5107,
      "total_loss": 0.5970403552055359
    },
    {
      "classification_loss": 0.5273289680480957,
      "epoch": 16.74754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5108,
      "total_loss": 0.5273289680480957
    },
    {
      "classification_loss": 0.45834463834762573,
      "epoch": 16.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5109,
      "total_loss": 0.45834463834762573
    },
    {
      "classification_loss": 0.47701093554496765,
      "epoch": 16.75409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5110,
      "total_loss": 0.47701093554496765
    },
    {
      "classification_loss": 0.46926766633987427,
      "epoch": 16.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5111,
      "total_loss": 0.46926766633987427
    },
    {
      "classification_loss": 0.44736239314079285,
      "epoch": 16.76065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5112,
      "total_loss": 0.44736239314079285
    },
    {
      "classification_loss": 0.4594833552837372,
      "epoch": 16.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5113,
      "total_loss": 0.4594833552837372
    },
    {
      "classification_loss": 0.3718079924583435,
      "epoch": 16.7672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5114,
      "total_loss": 0.3718079924583435
    },
    {
      "classification_loss": 0.4693378508090973,
      "epoch": 16.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5115,
      "total_loss": 0.4693378508090973
    },
    {
      "classification_loss": 0.48807740211486816,
      "epoch": 16.77377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5116,
      "total_loss": 0.48807740211486816
    },
    {
      "classification_loss": 0.539359986782074,
      "epoch": 16.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5117,
      "total_loss": 0.539359986782074
    },
    {
      "classification_loss": 0.5061773657798767,
      "epoch": 16.78032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5118,
      "total_loss": 0.5061773657798767
    },
    {
      "classification_loss": 0.5432889461517334,
      "epoch": 16.78360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5119,
      "total_loss": 0.5432889461517334
    },
    {
      "classification_loss": 0.5175632834434509,
      "epoch": 16.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5120,
      "total_loss": 0.5175632834434509
    },
    {
      "classification_loss": 0.4528592824935913,
      "epoch": 16.79016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5121,
      "total_loss": 0.4528592824935913
    },
    {
      "classification_loss": 0.672736644744873,
      "epoch": 16.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5122,
      "total_loss": 0.672736644744873
    },
    {
      "classification_loss": 0.5468082427978516,
      "epoch": 16.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5123,
      "total_loss": 0.5468082427978516
    },
    {
      "classification_loss": 0.6619550585746765,
      "epoch": 16.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5124,
      "total_loss": 0.6619550585746765
    },
    {
      "classification_loss": 0.47853314876556396,
      "epoch": 16.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5125,
      "total_loss": 0.47853314876556396
    },
    {
      "classification_loss": 0.5740900039672852,
      "epoch": 16.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5126,
      "total_loss": 0.5740900039672852
    },
    {
      "classification_loss": 0.4313872158527374,
      "epoch": 16.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5127,
      "total_loss": 0.4313872158527374
    },
    {
      "classification_loss": 0.49847689270973206,
      "epoch": 16.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5128,
      "total_loss": 0.49847689270973206
    },
    {
      "classification_loss": 0.4477476179599762,
      "epoch": 16.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5129,
      "total_loss": 0.4477476179599762
    },
    {
      "classification_loss": 0.4768868386745453,
      "epoch": 16.81967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5130,
      "total_loss": 0.4768868386745453
    },
    {
      "classification_loss": 0.4412102997303009,
      "epoch": 16.82295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5131,
      "total_loss": 0.4412102997303009
    },
    {
      "classification_loss": 0.49124017357826233,
      "epoch": 16.82622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5132,
      "total_loss": 0.49124017357826233
    },
    {
      "classification_loss": 0.5019802451133728,
      "epoch": 16.82950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5133,
      "total_loss": 0.5019802451133728
    },
    {
      "classification_loss": 0.5033193230628967,
      "epoch": 16.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5134,
      "total_loss": 0.5033193230628967
    },
    {
      "classification_loss": 0.496296763420105,
      "epoch": 16.83606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5135,
      "total_loss": 0.496296763420105
    },
    {
      "classification_loss": 0.5190072655677795,
      "epoch": 16.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5136,
      "total_loss": 0.5190072655677795
    },
    {
      "classification_loss": 0.5658615231513977,
      "epoch": 16.84262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5137,
      "total_loss": 0.5658615231513977
    },
    {
      "classification_loss": 0.44290852546691895,
      "epoch": 16.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5138,
      "total_loss": 0.44290852546691895
    },
    {
      "classification_loss": 0.5112549662590027,
      "epoch": 16.84918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5139,
      "total_loss": 0.5112549662590027
    },
    {
      "classification_loss": 0.36474162340164185,
      "epoch": 16.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5140,
      "total_loss": 0.36474162340164185
    },
    {
      "classification_loss": 0.5456720590591431,
      "epoch": 16.855737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5141,
      "total_loss": 0.5456720590591431
    },
    {
      "classification_loss": 0.4916170537471771,
      "epoch": 16.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5142,
      "total_loss": 0.4916170537471771
    },
    {
      "classification_loss": 0.4863434433937073,
      "epoch": 16.862295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5143,
      "total_loss": 0.4863434433937073
    },
    {
      "classification_loss": 0.43467503786087036,
      "epoch": 16.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5144,
      "total_loss": 0.43467503786087036
    },
    {
      "classification_loss": 0.4832005798816681,
      "epoch": 16.868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5145,
      "total_loss": 0.4832005798816681
    },
    {
      "classification_loss": 0.49177128076553345,
      "epoch": 16.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5146,
      "total_loss": 0.49177128076553345
    },
    {
      "classification_loss": 0.5485242605209351,
      "epoch": 16.875409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5147,
      "total_loss": 0.5485242605209351
    },
    {
      "classification_loss": 0.411724328994751,
      "epoch": 16.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5148,
      "total_loss": 0.411724328994751
    },
    {
      "classification_loss": 0.5588273406028748,
      "epoch": 16.881967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5149,
      "total_loss": 0.5588273406028748
    },
    {
      "classification_loss": 0.4014955461025238,
      "epoch": 16.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5150,
      "total_loss": 0.4014955461025238
    },
    {
      "classification_loss": 0.5516913533210754,
      "epoch": 16.888524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5151,
      "total_loss": 0.5516913533210754
    },
    {
      "classification_loss": 0.3844805061817169,
      "epoch": 16.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5152,
      "total_loss": 0.3844805061817169
    },
    {
      "classification_loss": 0.5185137987136841,
      "epoch": 16.895081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5153,
      "total_loss": 0.5185137987136841
    },
    {
      "classification_loss": 0.4376668930053711,
      "epoch": 16.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5154,
      "total_loss": 0.4376668930053711
    },
    {
      "classification_loss": 0.4372619390487671,
      "epoch": 16.901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5155,
      "total_loss": 0.4372619390487671
    },
    {
      "classification_loss": 0.5217275619506836,
      "epoch": 16.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5156,
      "total_loss": 0.5217275619506836
    },
    {
      "classification_loss": 0.41359415650367737,
      "epoch": 16.908196721311477,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5157,
      "total_loss": 0.41359415650367737
    },
    {
      "classification_loss": 0.4848344922065735,
      "epoch": 16.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5158,
      "total_loss": 0.4848344922065735
    },
    {
      "classification_loss": 0.44271785020828247,
      "epoch": 16.914754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5159,
      "total_loss": 0.44271785020828247
    },
    {
      "classification_loss": 0.4033513069152832,
      "epoch": 16.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5160,
      "total_loss": 0.4033513069152832
    },
    {
      "classification_loss": 0.4693219065666199,
      "epoch": 16.921311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5161,
      "total_loss": 0.4693219065666199
    },
    {
      "classification_loss": 0.4417632818222046,
      "epoch": 16.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5162,
      "total_loss": 0.4417632818222046
    },
    {
      "classification_loss": 0.5684031248092651,
      "epoch": 16.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5163,
      "total_loss": 0.5684031248092651
    },
    {
      "classification_loss": 0.5251765847206116,
      "epoch": 16.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5164,
      "total_loss": 0.5251765847206116
    },
    {
      "classification_loss": 0.4202224910259247,
      "epoch": 16.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5165,
      "total_loss": 0.4202224910259247
    },
    {
      "classification_loss": 0.5071381330490112,
      "epoch": 16.937704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5166,
      "total_loss": 0.5071381330490112
    },
    {
      "classification_loss": 0.4387941062450409,
      "epoch": 16.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5167,
      "total_loss": 0.4387941062450409
    },
    {
      "classification_loss": 0.698150634765625,
      "epoch": 16.944262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5168,
      "total_loss": 0.698150634765625
    },
    {
      "classification_loss": 0.5568454265594482,
      "epoch": 16.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5169,
      "total_loss": 0.5568454265594482
    },
    {
      "classification_loss": 0.4927595853805542,
      "epoch": 16.950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5170,
      "total_loss": 0.4927595853805542
    },
    {
      "classification_loss": 0.4474264979362488,
      "epoch": 16.95409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5171,
      "total_loss": 0.4474264979362488
    },
    {
      "classification_loss": 0.7310193181037903,
      "epoch": 16.957377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5172,
      "total_loss": 0.7310193181037903
    },
    {
      "classification_loss": 0.5112754106521606,
      "epoch": 16.96065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5173,
      "total_loss": 0.5112754106521606
    },
    {
      "classification_loss": 0.6083946228027344,
      "epoch": 16.963934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5174,
      "total_loss": 0.6083946228027344
    },
    {
      "classification_loss": 0.4579053223133087,
      "epoch": 16.9672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5175,
      "total_loss": 0.4579053223133087
    },
    {
      "classification_loss": 0.41619452834129333,
      "epoch": 16.970491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5176,
      "total_loss": 0.41619452834129333
    },
    {
      "classification_loss": 0.40671464800834656,
      "epoch": 16.97377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5177,
      "total_loss": 0.40671464800834656
    },
    {
      "classification_loss": 0.4606677293777466,
      "epoch": 16.977049180327867,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5178,
      "total_loss": 0.4606677293777466
    },
    {
      "classification_loss": 0.5258082747459412,
      "epoch": 16.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5179,
      "total_loss": 0.5258082747459412
    },
    {
      "classification_loss": 0.46681103110313416,
      "epoch": 16.983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5180,
      "total_loss": 0.46681103110313416
    },
    {
      "classification_loss": 0.5459098815917969,
      "epoch": 16.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5181,
      "total_loss": 0.5459098815917969
    },
    {
      "classification_loss": 0.5548986196517944,
      "epoch": 16.990163934426228,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5182,
      "total_loss": 0.5548986196517944
    },
    {
      "classification_loss": 0.5020069479942322,
      "epoch": 16.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5183,
      "total_loss": 0.5020069479942322
    },
    {
      "classification_loss": 0.43776994943618774,
      "epoch": 16.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5184,
      "total_loss": 0.43776994943618774
    },
    {
      "classification_loss": 1.467965006828308,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.467965006828308
    },
    {
      "classification_loss": 1.398400902748108,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.398400902748108
    },
    {
      "classification_loss": 1.288393259048462,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.288393259048462
    },
    {
      "classification_loss": 1.597812533378601,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.597812533378601
    },
    {
      "classification_loss": 1.3079344034194946,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.3079344034194946
    },
    {
      "classification_loss": 1.2984049320220947,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.2984049320220947
    },
    {
      "classification_loss": 1.3817793130874634,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.3817793130874634
    },
    {
      "classification_loss": 1.1702884435653687,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 1.1702884435653687
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.368518352508545,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 5.9986,
      "eval_samples_per_second": 166.706,
      "eval_steps_per_second": 1.334,
      "step": 5185
    },
    {
      "classification_loss": 0.422955185174942,
      "epoch": 17.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5185,
      "total_loss": 0.422955185174942
    },
    {
      "classification_loss": 0.40792199969291687,
      "epoch": 17.003278688524592,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5186,
      "total_loss": 0.40792199969291687
    },
    {
      "classification_loss": 0.44288843870162964,
      "epoch": 17.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5187,
      "total_loss": 0.44288843870162964
    },
    {
      "classification_loss": 0.37787869572639465,
      "epoch": 17.009836065573772,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5188,
      "total_loss": 0.37787869572639465
    },
    {
      "classification_loss": 0.43698716163635254,
      "epoch": 17.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5189,
      "total_loss": 0.43698716163635254
    },
    {
      "classification_loss": 0.4055440127849579,
      "epoch": 17.016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5190,
      "total_loss": 0.4055440127849579
    },
    {
      "classification_loss": 0.49911507964134216,
      "epoch": 17.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5191,
      "total_loss": 0.49911507964134216
    },
    {
      "classification_loss": 0.4019913375377655,
      "epoch": 17.022950819672133,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5192,
      "total_loss": 0.4019913375377655
    },
    {
      "classification_loss": 0.43887194991111755,
      "epoch": 17.02622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5193,
      "total_loss": 0.43887194991111755
    },
    {
      "classification_loss": 0.42366090416908264,
      "epoch": 17.029508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5194,
      "total_loss": 0.42366090416908264
    },
    {
      "classification_loss": 0.4845768213272095,
      "epoch": 17.0327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5195,
      "total_loss": 0.4845768213272095
    },
    {
      "classification_loss": 0.4549869894981384,
      "epoch": 17.036065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5196,
      "total_loss": 0.4549869894981384
    },
    {
      "classification_loss": 0.4389071762561798,
      "epoch": 17.03934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5197,
      "total_loss": 0.4389071762561798
    },
    {
      "classification_loss": 0.4936182200908661,
      "epoch": 17.042622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5198,
      "total_loss": 0.4936182200908661
    },
    {
      "classification_loss": 0.45508500933647156,
      "epoch": 17.04590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5199,
      "total_loss": 0.45508500933647156
    },
    {
      "epoch": 17.049180327868854,
      "grad_norm": 2.826049327850342,
      "learning_rate": 3.0033333333333336e-05,
      "loss": 0.4833,
      "step": 5200
    },
    {
      "classification_loss": 0.46337929368019104,
      "epoch": 17.049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5200,
      "total_loss": 0.46337929368019104
    },
    {
      "classification_loss": 0.48333239555358887,
      "epoch": 17.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5201,
      "total_loss": 0.48333239555358887
    },
    {
      "classification_loss": 0.33313918113708496,
      "epoch": 17.055737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5202,
      "total_loss": 0.33313918113708496
    },
    {
      "classification_loss": 0.4861356019973755,
      "epoch": 17.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5203,
      "total_loss": 0.4861356019973755
    },
    {
      "classification_loss": 0.45713329315185547,
      "epoch": 17.062295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5204,
      "total_loss": 0.45713329315185547
    },
    {
      "classification_loss": 0.5395543575286865,
      "epoch": 17.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5205,
      "total_loss": 0.5395543575286865
    },
    {
      "classification_loss": 0.5019434094429016,
      "epoch": 17.068852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5206,
      "total_loss": 0.5019434094429016
    },
    {
      "classification_loss": 0.4616037607192993,
      "epoch": 17.072131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5207,
      "total_loss": 0.4616037607192993
    },
    {
      "classification_loss": 0.4412846565246582,
      "epoch": 17.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5208,
      "total_loss": 0.4412846565246582
    },
    {
      "classification_loss": 0.5186355113983154,
      "epoch": 17.078688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5209,
      "total_loss": 0.5186355113983154
    },
    {
      "classification_loss": 0.6135559678077698,
      "epoch": 17.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5210,
      "total_loss": 0.6135559678077698
    },
    {
      "classification_loss": 0.43072381615638733,
      "epoch": 17.085245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5211,
      "total_loss": 0.43072381615638733
    },
    {
      "classification_loss": 0.4124157130718231,
      "epoch": 17.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5212,
      "total_loss": 0.4124157130718231
    },
    {
      "classification_loss": 0.43994131684303284,
      "epoch": 17.091803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5213,
      "total_loss": 0.43994131684303284
    },
    {
      "classification_loss": 0.45005908608436584,
      "epoch": 17.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5214,
      "total_loss": 0.45005908608436584
    },
    {
      "classification_loss": 0.5551890134811401,
      "epoch": 17.098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5215,
      "total_loss": 0.5551890134811401
    },
    {
      "classification_loss": 0.3884679675102234,
      "epoch": 17.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5216,
      "total_loss": 0.3884679675102234
    },
    {
      "classification_loss": 0.3807256817817688,
      "epoch": 17.104918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5217,
      "total_loss": 0.3807256817817688
    },
    {
      "classification_loss": 0.48172658681869507,
      "epoch": 17.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5218,
      "total_loss": 0.48172658681869507
    },
    {
      "classification_loss": 0.4874902367591858,
      "epoch": 17.111475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5219,
      "total_loss": 0.4874902367591858
    },
    {
      "classification_loss": 0.40169742703437805,
      "epoch": 17.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5220,
      "total_loss": 0.40169742703437805
    },
    {
      "classification_loss": 0.4409328103065491,
      "epoch": 17.118032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5221,
      "total_loss": 0.4409328103065491
    },
    {
      "classification_loss": 0.41911497712135315,
      "epoch": 17.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5222,
      "total_loss": 0.41911497712135315
    },
    {
      "classification_loss": 0.3643859028816223,
      "epoch": 17.124590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5223,
      "total_loss": 0.3643859028816223
    },
    {
      "classification_loss": 0.5661214590072632,
      "epoch": 17.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5224,
      "total_loss": 0.5661214590072632
    },
    {
      "classification_loss": 0.46552130579948425,
      "epoch": 17.131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5225,
      "total_loss": 0.46552130579948425
    },
    {
      "classification_loss": 0.5362029671669006,
      "epoch": 17.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5226,
      "total_loss": 0.5362029671669006
    },
    {
      "classification_loss": 0.469226211309433,
      "epoch": 17.137704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5227,
      "total_loss": 0.469226211309433
    },
    {
      "classification_loss": 0.5657404065132141,
      "epoch": 17.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5228,
      "total_loss": 0.5657404065132141
    },
    {
      "classification_loss": 0.5253307819366455,
      "epoch": 17.14426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5229,
      "total_loss": 0.5253307819366455
    },
    {
      "classification_loss": 0.47051045298576355,
      "epoch": 17.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5230,
      "total_loss": 0.47051045298576355
    },
    {
      "classification_loss": 0.4753735363483429,
      "epoch": 17.15081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5231,
      "total_loss": 0.4753735363483429
    },
    {
      "classification_loss": 0.43227940797805786,
      "epoch": 17.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5232,
      "total_loss": 0.43227940797805786
    },
    {
      "classification_loss": 0.606611967086792,
      "epoch": 17.15737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5233,
      "total_loss": 0.606611967086792
    },
    {
      "classification_loss": 0.5136987566947937,
      "epoch": 17.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5234,
      "total_loss": 0.5136987566947937
    },
    {
      "classification_loss": 0.4445376992225647,
      "epoch": 17.16393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5235,
      "total_loss": 0.4445376992225647
    },
    {
      "classification_loss": 0.511805534362793,
      "epoch": 17.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5236,
      "total_loss": 0.511805534362793
    },
    {
      "classification_loss": 0.36185604333877563,
      "epoch": 17.17049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5237,
      "total_loss": 0.36185604333877563
    },
    {
      "classification_loss": 0.41084548830986023,
      "epoch": 17.17377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5238,
      "total_loss": 0.41084548830986023
    },
    {
      "classification_loss": 0.42703482508659363,
      "epoch": 17.17704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5239,
      "total_loss": 0.42703482508659363
    },
    {
      "classification_loss": 0.43770265579223633,
      "epoch": 17.18032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5240,
      "total_loss": 0.43770265579223633
    },
    {
      "classification_loss": 0.42271551489830017,
      "epoch": 17.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5241,
      "total_loss": 0.42271551489830017
    },
    {
      "classification_loss": 0.44102048873901367,
      "epoch": 17.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5242,
      "total_loss": 0.44102048873901367
    },
    {
      "classification_loss": 0.5478744506835938,
      "epoch": 17.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5243,
      "total_loss": 0.5478744506835938
    },
    {
      "classification_loss": 0.43595337867736816,
      "epoch": 17.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5244,
      "total_loss": 0.43595337867736816
    },
    {
      "classification_loss": 0.45378348231315613,
      "epoch": 17.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5245,
      "total_loss": 0.45378348231315613
    },
    {
      "classification_loss": 0.4874719977378845,
      "epoch": 17.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5246,
      "total_loss": 0.4874719977378845
    },
    {
      "classification_loss": 0.5066662430763245,
      "epoch": 17.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5247,
      "total_loss": 0.5066662430763245
    },
    {
      "classification_loss": 0.5986019968986511,
      "epoch": 17.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5248,
      "total_loss": 0.5986019968986511
    },
    {
      "classification_loss": 0.34599825739860535,
      "epoch": 17.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5249,
      "total_loss": 0.34599825739860535
    },
    {
      "classification_loss": 0.5877149105072021,
      "epoch": 17.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5250,
      "total_loss": 0.5877149105072021
    },
    {
      "classification_loss": 0.3891323208808899,
      "epoch": 17.21639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5251,
      "total_loss": 0.3891323208808899
    },
    {
      "classification_loss": 0.6141735911369324,
      "epoch": 17.21967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5252,
      "total_loss": 0.6141735911369324
    },
    {
      "classification_loss": 0.5345686674118042,
      "epoch": 17.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5253,
      "total_loss": 0.5345686674118042
    },
    {
      "classification_loss": 0.5042519569396973,
      "epoch": 17.22622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5254,
      "total_loss": 0.5042519569396973
    },
    {
      "classification_loss": 0.5308140516281128,
      "epoch": 17.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5255,
      "total_loss": 0.5308140516281128
    },
    {
      "classification_loss": 0.5598107576370239,
      "epoch": 17.2327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5256,
      "total_loss": 0.5598107576370239
    },
    {
      "classification_loss": 0.4803507924079895,
      "epoch": 17.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5257,
      "total_loss": 0.4803507924079895
    },
    {
      "classification_loss": 0.4620838761329651,
      "epoch": 17.23934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5258,
      "total_loss": 0.4620838761329651
    },
    {
      "classification_loss": 0.30623859167099,
      "epoch": 17.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5259,
      "total_loss": 0.30623859167099
    },
    {
      "classification_loss": 0.5904580354690552,
      "epoch": 17.24590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5260,
      "total_loss": 0.5904580354690552
    },
    {
      "classification_loss": 0.4546811878681183,
      "epoch": 17.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5261,
      "total_loss": 0.4546811878681183
    },
    {
      "classification_loss": 0.4339013993740082,
      "epoch": 17.25245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5262,
      "total_loss": 0.4339013993740082
    },
    {
      "classification_loss": 0.5108678340911865,
      "epoch": 17.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5263,
      "total_loss": 0.5108678340911865
    },
    {
      "classification_loss": 0.49398118257522583,
      "epoch": 17.25901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5264,
      "total_loss": 0.49398118257522583
    },
    {
      "classification_loss": 0.537676990032196,
      "epoch": 17.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5265,
      "total_loss": 0.537676990032196
    },
    {
      "classification_loss": 0.4104483723640442,
      "epoch": 17.2655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5266,
      "total_loss": 0.4104483723640442
    },
    {
      "classification_loss": 0.497971773147583,
      "epoch": 17.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5267,
      "total_loss": 0.497971773147583
    },
    {
      "classification_loss": 0.44906774163246155,
      "epoch": 17.272131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5268,
      "total_loss": 0.44906774163246155
    },
    {
      "classification_loss": 0.4729396402835846,
      "epoch": 17.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5269,
      "total_loss": 0.4729396402835846
    },
    {
      "classification_loss": 0.5067890882492065,
      "epoch": 17.278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5270,
      "total_loss": 0.5067890882492065
    },
    {
      "classification_loss": 0.458590030670166,
      "epoch": 17.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5271,
      "total_loss": 0.458590030670166
    },
    {
      "classification_loss": 0.43897420167922974,
      "epoch": 17.285245901639342,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5272,
      "total_loss": 0.43897420167922974
    },
    {
      "classification_loss": 0.4999607801437378,
      "epoch": 17.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5273,
      "total_loss": 0.4999607801437378
    },
    {
      "classification_loss": 0.45339277386665344,
      "epoch": 17.291803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5274,
      "total_loss": 0.45339277386665344
    },
    {
      "classification_loss": 0.49860644340515137,
      "epoch": 17.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5275,
      "total_loss": 0.49860644340515137
    },
    {
      "classification_loss": 0.39313948154449463,
      "epoch": 17.298360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5276,
      "total_loss": 0.39313948154449463
    },
    {
      "classification_loss": 0.4515959620475769,
      "epoch": 17.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5277,
      "total_loss": 0.4515959620475769
    },
    {
      "classification_loss": 0.4725663959980011,
      "epoch": 17.304918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5278,
      "total_loss": 0.4725663959980011
    },
    {
      "classification_loss": 0.47736623883247375,
      "epoch": 17.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5279,
      "total_loss": 0.47736623883247375
    },
    {
      "classification_loss": 0.5214230418205261,
      "epoch": 17.311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5280,
      "total_loss": 0.5214230418205261
    },
    {
      "classification_loss": 0.39459851384162903,
      "epoch": 17.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5281,
      "total_loss": 0.39459851384162903
    },
    {
      "classification_loss": 0.4556124210357666,
      "epoch": 17.318032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5282,
      "total_loss": 0.4556124210357666
    },
    {
      "classification_loss": 0.45778757333755493,
      "epoch": 17.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5283,
      "total_loss": 0.45778757333755493
    },
    {
      "classification_loss": 0.3960420489311218,
      "epoch": 17.324590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5284,
      "total_loss": 0.3960420489311218
    },
    {
      "classification_loss": 0.46773913502693176,
      "epoch": 17.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5285,
      "total_loss": 0.46773913502693176
    },
    {
      "classification_loss": 0.5334806442260742,
      "epoch": 17.331147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5286,
      "total_loss": 0.5334806442260742
    },
    {
      "classification_loss": 0.5138651132583618,
      "epoch": 17.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5287,
      "total_loss": 0.5138651132583618
    },
    {
      "classification_loss": 0.40246760845184326,
      "epoch": 17.337704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5288,
      "total_loss": 0.40246760845184326
    },
    {
      "classification_loss": 0.4848710596561432,
      "epoch": 17.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5289,
      "total_loss": 0.4848710596561432
    },
    {
      "classification_loss": 0.43093883991241455,
      "epoch": 17.34426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5290,
      "total_loss": 0.43093883991241455
    },
    {
      "classification_loss": 0.48273327946662903,
      "epoch": 17.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5291,
      "total_loss": 0.48273327946662903
    },
    {
      "classification_loss": 0.4681051969528198,
      "epoch": 17.35081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5292,
      "total_loss": 0.4681051969528198
    },
    {
      "classification_loss": 0.5846400260925293,
      "epoch": 17.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5293,
      "total_loss": 0.5846400260925293
    },
    {
      "classification_loss": 0.4340995252132416,
      "epoch": 17.35737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5294,
      "total_loss": 0.4340995252132416
    },
    {
      "classification_loss": 0.3869868516921997,
      "epoch": 17.360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5295,
      "total_loss": 0.3869868516921997
    },
    {
      "classification_loss": 0.6150551438331604,
      "epoch": 17.36393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5296,
      "total_loss": 0.6150551438331604
    },
    {
      "classification_loss": 0.5558955669403076,
      "epoch": 17.367213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5297,
      "total_loss": 0.5558955669403076
    },
    {
      "classification_loss": 0.5360113382339478,
      "epoch": 17.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5298,
      "total_loss": 0.5360113382339478
    },
    {
      "classification_loss": 0.49631375074386597,
      "epoch": 17.373770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5299,
      "total_loss": 0.49631375074386597
    },
    {
      "epoch": 17.37704918032787,
      "grad_norm": 3.874354600906372,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 0.475,
      "step": 5300
    },
    {
      "classification_loss": 0.45676976442337036,
      "epoch": 17.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5300,
      "total_loss": 0.45676976442337036
    },
    {
      "classification_loss": 0.40712645649909973,
      "epoch": 17.380327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5301,
      "total_loss": 0.40712645649909973
    },
    {
      "classification_loss": 0.4415220618247986,
      "epoch": 17.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5302,
      "total_loss": 0.4415220618247986
    },
    {
      "classification_loss": 0.4070075750350952,
      "epoch": 17.386885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5303,
      "total_loss": 0.4070075750350952
    },
    {
      "classification_loss": 0.49493104219436646,
      "epoch": 17.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5304,
      "total_loss": 0.49493104219436646
    },
    {
      "classification_loss": 0.46211427450180054,
      "epoch": 17.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5305,
      "total_loss": 0.46211427450180054
    },
    {
      "classification_loss": 0.5498016476631165,
      "epoch": 17.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5306,
      "total_loss": 0.5498016476631165
    },
    {
      "classification_loss": 0.45959556102752686,
      "epoch": 17.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5307,
      "total_loss": 0.45959556102752686
    },
    {
      "classification_loss": 0.4866102933883667,
      "epoch": 17.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5308,
      "total_loss": 0.4866102933883667
    },
    {
      "classification_loss": 0.4271465837955475,
      "epoch": 17.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5309,
      "total_loss": 0.4271465837955475
    },
    {
      "classification_loss": 0.38634368777275085,
      "epoch": 17.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5310,
      "total_loss": 0.38634368777275085
    },
    {
      "classification_loss": 0.4445321559906006,
      "epoch": 17.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5311,
      "total_loss": 0.4445321559906006
    },
    {
      "classification_loss": 0.4468145966529846,
      "epoch": 17.41639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5312,
      "total_loss": 0.4468145966529846
    },
    {
      "classification_loss": 0.40118470788002014,
      "epoch": 17.41967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5313,
      "total_loss": 0.40118470788002014
    },
    {
      "classification_loss": 0.4831135869026184,
      "epoch": 17.42295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5314,
      "total_loss": 0.4831135869026184
    },
    {
      "classification_loss": 0.3736657202243805,
      "epoch": 17.42622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5315,
      "total_loss": 0.3736657202243805
    },
    {
      "classification_loss": 0.5333402156829834,
      "epoch": 17.42950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5316,
      "total_loss": 0.5333402156829834
    },
    {
      "classification_loss": 0.5306298136711121,
      "epoch": 17.432786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5317,
      "total_loss": 0.5306298136711121
    },
    {
      "classification_loss": 0.518974781036377,
      "epoch": 17.43606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5318,
      "total_loss": 0.518974781036377
    },
    {
      "classification_loss": 0.3884110152721405,
      "epoch": 17.439344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5319,
      "total_loss": 0.3884110152721405
    },
    {
      "classification_loss": 0.42491427063941956,
      "epoch": 17.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5320,
      "total_loss": 0.42491427063941956
    },
    {
      "classification_loss": 0.49893102049827576,
      "epoch": 17.445901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5321,
      "total_loss": 0.49893102049827576
    },
    {
      "classification_loss": 0.5097314119338989,
      "epoch": 17.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5322,
      "total_loss": 0.5097314119338989
    },
    {
      "classification_loss": 0.4465702474117279,
      "epoch": 17.452459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5323,
      "total_loss": 0.4465702474117279
    },
    {
      "classification_loss": 0.45012834668159485,
      "epoch": 17.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5324,
      "total_loss": 0.45012834668159485
    },
    {
      "classification_loss": 0.6283091306686401,
      "epoch": 17.459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5325,
      "total_loss": 0.6283091306686401
    },
    {
      "classification_loss": 0.5586972236633301,
      "epoch": 17.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5326,
      "total_loss": 0.5586972236633301
    },
    {
      "classification_loss": 0.5441571474075317,
      "epoch": 17.465573770491805,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5327,
      "total_loss": 0.5441571474075317
    },
    {
      "classification_loss": 0.43875449895858765,
      "epoch": 17.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5328,
      "total_loss": 0.43875449895858765
    },
    {
      "classification_loss": 0.539214015007019,
      "epoch": 17.472131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5329,
      "total_loss": 0.539214015007019
    },
    {
      "classification_loss": 0.569704532623291,
      "epoch": 17.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5330,
      "total_loss": 0.569704532623291
    },
    {
      "classification_loss": 0.4969407021999359,
      "epoch": 17.478688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5331,
      "total_loss": 0.4969407021999359
    },
    {
      "classification_loss": 0.44880813360214233,
      "epoch": 17.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5332,
      "total_loss": 0.44880813360214233
    },
    {
      "classification_loss": 0.6434726715087891,
      "epoch": 17.485245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5333,
      "total_loss": 0.6434726715087891
    },
    {
      "classification_loss": 0.41726741194725037,
      "epoch": 17.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5334,
      "total_loss": 0.41726741194725037
    },
    {
      "classification_loss": 0.5048054456710815,
      "epoch": 17.491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5335,
      "total_loss": 0.5048054456710815
    },
    {
      "classification_loss": 0.37951111793518066,
      "epoch": 17.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5336,
      "total_loss": 0.37951111793518066
    },
    {
      "classification_loss": 0.4472997188568115,
      "epoch": 17.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5337,
      "total_loss": 0.4472997188568115
    },
    {
      "classification_loss": 0.48803767561912537,
      "epoch": 17.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5338,
      "total_loss": 0.48803767561912537
    },
    {
      "classification_loss": 0.4273054897785187,
      "epoch": 17.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5339,
      "total_loss": 0.4273054897785187
    },
    {
      "classification_loss": 0.5402205586433411,
      "epoch": 17.508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5340,
      "total_loss": 0.5402205586433411
    },
    {
      "classification_loss": 0.48772773146629333,
      "epoch": 17.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5341,
      "total_loss": 0.48772773146629333
    },
    {
      "classification_loss": 0.5247063040733337,
      "epoch": 17.514754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5342,
      "total_loss": 0.5247063040733337
    },
    {
      "classification_loss": 0.49099159240722656,
      "epoch": 17.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5343,
      "total_loss": 0.49099159240722656
    },
    {
      "classification_loss": 0.47664928436279297,
      "epoch": 17.521311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5344,
      "total_loss": 0.47664928436279297
    },
    {
      "classification_loss": 0.4728882610797882,
      "epoch": 17.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5345,
      "total_loss": 0.4728882610797882
    },
    {
      "classification_loss": 0.39806169271469116,
      "epoch": 17.527868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5346,
      "total_loss": 0.39806169271469116
    },
    {
      "classification_loss": 0.40424680709838867,
      "epoch": 17.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5347,
      "total_loss": 0.40424680709838867
    },
    {
      "classification_loss": 0.5157857537269592,
      "epoch": 17.534426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5348,
      "total_loss": 0.5157857537269592
    },
    {
      "classification_loss": 0.4778262674808502,
      "epoch": 17.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5349,
      "total_loss": 0.4778262674808502
    },
    {
      "classification_loss": 0.5900460481643677,
      "epoch": 17.540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5350,
      "total_loss": 0.5900460481643677
    },
    {
      "classification_loss": 0.603546679019928,
      "epoch": 17.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5351,
      "total_loss": 0.603546679019928
    },
    {
      "classification_loss": 0.3719172775745392,
      "epoch": 17.547540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5352,
      "total_loss": 0.3719172775745392
    },
    {
      "classification_loss": 0.4575977921485901,
      "epoch": 17.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5353,
      "total_loss": 0.4575977921485901
    },
    {
      "classification_loss": 0.5920923948287964,
      "epoch": 17.554098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5354,
      "total_loss": 0.5920923948287964
    },
    {
      "classification_loss": 0.48270803689956665,
      "epoch": 17.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5355,
      "total_loss": 0.48270803689956665
    },
    {
      "classification_loss": 0.3983248174190521,
      "epoch": 17.560655737704916,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5356,
      "total_loss": 0.3983248174190521
    },
    {
      "classification_loss": 0.44177427887916565,
      "epoch": 17.56393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5357,
      "total_loss": 0.44177427887916565
    },
    {
      "classification_loss": 0.5124631524085999,
      "epoch": 17.567213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5358,
      "total_loss": 0.5124631524085999
    },
    {
      "classification_loss": 0.4411671757698059,
      "epoch": 17.57049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5359,
      "total_loss": 0.4411671757698059
    },
    {
      "classification_loss": 0.4022538661956787,
      "epoch": 17.57377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5360,
      "total_loss": 0.4022538661956787
    },
    {
      "classification_loss": 0.3646589517593384,
      "epoch": 17.57704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5361,
      "total_loss": 0.3646589517593384
    },
    {
      "classification_loss": 0.4686673879623413,
      "epoch": 17.58032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5362,
      "total_loss": 0.4686673879623413
    },
    {
      "classification_loss": 0.42678818106651306,
      "epoch": 17.58360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5363,
      "total_loss": 0.42678818106651306
    },
    {
      "classification_loss": 0.4961715340614319,
      "epoch": 17.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5364,
      "total_loss": 0.4961715340614319
    },
    {
      "classification_loss": 0.4356861710548401,
      "epoch": 17.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5365,
      "total_loss": 0.4356861710548401
    },
    {
      "classification_loss": 0.5384514331817627,
      "epoch": 17.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5366,
      "total_loss": 0.5384514331817627
    },
    {
      "classification_loss": 0.4077126085758209,
      "epoch": 17.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5367,
      "total_loss": 0.4077126085758209
    },
    {
      "classification_loss": 0.41377779841423035,
      "epoch": 17.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5368,
      "total_loss": 0.41377779841423035
    },
    {
      "classification_loss": 0.44910937547683716,
      "epoch": 17.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5369,
      "total_loss": 0.44910937547683716
    },
    {
      "classification_loss": 0.4943556487560272,
      "epoch": 17.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5370,
      "total_loss": 0.4943556487560272
    },
    {
      "classification_loss": 0.5126374959945679,
      "epoch": 17.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5371,
      "total_loss": 0.5126374959945679
    },
    {
      "classification_loss": 0.6123664379119873,
      "epoch": 17.613114754098362,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5372,
      "total_loss": 0.6123664379119873
    },
    {
      "classification_loss": 0.507037341594696,
      "epoch": 17.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5373,
      "total_loss": 0.507037341594696
    },
    {
      "classification_loss": 0.514909565448761,
      "epoch": 17.619672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5374,
      "total_loss": 0.514909565448761
    },
    {
      "classification_loss": 0.4678610563278198,
      "epoch": 17.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5375,
      "total_loss": 0.4678610563278198
    },
    {
      "classification_loss": 0.4961392283439636,
      "epoch": 17.626229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5376,
      "total_loss": 0.4961392283439636
    },
    {
      "classification_loss": 0.34103095531463623,
      "epoch": 17.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5377,
      "total_loss": 0.34103095531463623
    },
    {
      "classification_loss": 0.504601001739502,
      "epoch": 17.632786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5378,
      "total_loss": 0.504601001739502
    },
    {
      "classification_loss": 0.4428051710128784,
      "epoch": 17.63606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5379,
      "total_loss": 0.4428051710128784
    },
    {
      "classification_loss": 0.4475388824939728,
      "epoch": 17.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5380,
      "total_loss": 0.4475388824939728
    },
    {
      "classification_loss": 0.28595617413520813,
      "epoch": 17.64262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5381,
      "total_loss": 0.28595617413520813
    },
    {
      "classification_loss": 0.39119285345077515,
      "epoch": 17.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5382,
      "total_loss": 0.39119285345077515
    },
    {
      "classification_loss": 0.5246568322181702,
      "epoch": 17.64918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5383,
      "total_loss": 0.5246568322181702
    },
    {
      "classification_loss": 0.5944342017173767,
      "epoch": 17.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5384,
      "total_loss": 0.5944342017173767
    },
    {
      "classification_loss": 0.4728769063949585,
      "epoch": 17.65573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5385,
      "total_loss": 0.4728769063949585
    },
    {
      "classification_loss": 0.4839569628238678,
      "epoch": 17.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5386,
      "total_loss": 0.4839569628238678
    },
    {
      "classification_loss": 0.40850380063056946,
      "epoch": 17.662295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5387,
      "total_loss": 0.40850380063056946
    },
    {
      "classification_loss": 0.40241825580596924,
      "epoch": 17.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5388,
      "total_loss": 0.40241825580596924
    },
    {
      "classification_loss": 0.44089165329933167,
      "epoch": 17.668852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5389,
      "total_loss": 0.44089165329933167
    },
    {
      "classification_loss": 0.5941081643104553,
      "epoch": 17.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5390,
      "total_loss": 0.5941081643104553
    },
    {
      "classification_loss": 0.5429971814155579,
      "epoch": 17.675409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5391,
      "total_loss": 0.5429971814155579
    },
    {
      "classification_loss": 0.4690915644168854,
      "epoch": 17.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5392,
      "total_loss": 0.4690915644168854
    },
    {
      "classification_loss": 0.4299275577068329,
      "epoch": 17.681967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5393,
      "total_loss": 0.4299275577068329
    },
    {
      "classification_loss": 0.442781537771225,
      "epoch": 17.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5394,
      "total_loss": 0.442781537771225
    },
    {
      "classification_loss": 0.5415273308753967,
      "epoch": 17.688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5395,
      "total_loss": 0.5415273308753967
    },
    {
      "classification_loss": 0.4906107187271118,
      "epoch": 17.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5396,
      "total_loss": 0.4906107187271118
    },
    {
      "classification_loss": 0.4820730984210968,
      "epoch": 17.695081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5397,
      "total_loss": 0.4820730984210968
    },
    {
      "classification_loss": 0.49673858284950256,
      "epoch": 17.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5398,
      "total_loss": 0.49673858284950256
    },
    {
      "classification_loss": 0.4788512587547302,
      "epoch": 17.701639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5399,
      "total_loss": 0.4788512587547302
    },
    {
      "epoch": 17.704918032786885,
      "grad_norm": 10.670782089233398,
      "learning_rate": 2.3366666666666668e-05,
      "loss": 0.4736,
      "step": 5400
    },
    {
      "classification_loss": 0.3961127996444702,
      "epoch": 17.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5400,
      "total_loss": 0.3961127996444702
    },
    {
      "classification_loss": 0.5247959494590759,
      "epoch": 17.708196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5401,
      "total_loss": 0.5247959494590759
    },
    {
      "classification_loss": 0.45038753747940063,
      "epoch": 17.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5402,
      "total_loss": 0.45038753747940063
    },
    {
      "classification_loss": 0.363016277551651,
      "epoch": 17.714754098360658,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5403,
      "total_loss": 0.363016277551651
    },
    {
      "classification_loss": 0.4181225895881653,
      "epoch": 17.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5404,
      "total_loss": 0.4181225895881653
    },
    {
      "classification_loss": 0.44778919219970703,
      "epoch": 17.721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5405,
      "total_loss": 0.44778919219970703
    },
    {
      "classification_loss": 0.35760775208473206,
      "epoch": 17.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5406,
      "total_loss": 0.35760775208473206
    },
    {
      "classification_loss": 0.4391162097454071,
      "epoch": 17.727868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5407,
      "total_loss": 0.4391162097454071
    },
    {
      "classification_loss": 0.5397709608078003,
      "epoch": 17.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5408,
      "total_loss": 0.5397709608078003
    },
    {
      "classification_loss": 0.5397195219993591,
      "epoch": 17.7344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5409,
      "total_loss": 0.5397195219993591
    },
    {
      "classification_loss": 0.4928521513938904,
      "epoch": 17.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5410,
      "total_loss": 0.4928521513938904
    },
    {
      "classification_loss": 0.5554897785186768,
      "epoch": 17.74098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5411,
      "total_loss": 0.5554897785186768
    },
    {
      "classification_loss": 0.5457307696342468,
      "epoch": 17.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5412,
      "total_loss": 0.5457307696342468
    },
    {
      "classification_loss": 0.6173021793365479,
      "epoch": 17.74754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5413,
      "total_loss": 0.6173021793365479
    },
    {
      "classification_loss": 0.5711824893951416,
      "epoch": 17.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5414,
      "total_loss": 0.5711824893951416
    },
    {
      "classification_loss": 0.4682932198047638,
      "epoch": 17.75409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5415,
      "total_loss": 0.4682932198047638
    },
    {
      "classification_loss": 0.4367654621601105,
      "epoch": 17.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5416,
      "total_loss": 0.4367654621601105
    },
    {
      "classification_loss": 0.5738149285316467,
      "epoch": 17.76065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5417,
      "total_loss": 0.5738149285316467
    },
    {
      "classification_loss": 0.48265376687049866,
      "epoch": 17.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5418,
      "total_loss": 0.48265376687049866
    },
    {
      "classification_loss": 0.5298206806182861,
      "epoch": 17.7672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5419,
      "total_loss": 0.5298206806182861
    },
    {
      "classification_loss": 0.48952794075012207,
      "epoch": 17.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5420,
      "total_loss": 0.48952794075012207
    },
    {
      "classification_loss": 0.42715781927108765,
      "epoch": 17.77377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5421,
      "total_loss": 0.42715781927108765
    },
    {
      "classification_loss": 0.48405948281288147,
      "epoch": 17.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5422,
      "total_loss": 0.48405948281288147
    },
    {
      "classification_loss": 0.5198419094085693,
      "epoch": 17.78032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5423,
      "total_loss": 0.5198419094085693
    },
    {
      "classification_loss": 0.5533955097198486,
      "epoch": 17.78360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5424,
      "total_loss": 0.5533955097198486
    },
    {
      "classification_loss": 0.46297672390937805,
      "epoch": 17.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5425,
      "total_loss": 0.46297672390937805
    },
    {
      "classification_loss": 0.4353943467140198,
      "epoch": 17.79016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5426,
      "total_loss": 0.4353943467140198
    },
    {
      "classification_loss": 0.5321882963180542,
      "epoch": 17.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5427,
      "total_loss": 0.5321882963180542
    },
    {
      "classification_loss": 0.5665847659111023,
      "epoch": 17.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5428,
      "total_loss": 0.5665847659111023
    },
    {
      "classification_loss": 0.584204912185669,
      "epoch": 17.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5429,
      "total_loss": 0.584204912185669
    },
    {
      "classification_loss": 0.5929545164108276,
      "epoch": 17.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5430,
      "total_loss": 0.5929545164108276
    },
    {
      "classification_loss": 0.4983256459236145,
      "epoch": 17.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5431,
      "total_loss": 0.4983256459236145
    },
    {
      "classification_loss": 0.5119634866714478,
      "epoch": 17.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5432,
      "total_loss": 0.5119634866714478
    },
    {
      "classification_loss": 0.37988725304603577,
      "epoch": 17.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5433,
      "total_loss": 0.37988725304603577
    },
    {
      "classification_loss": 0.48950424790382385,
      "epoch": 17.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5434,
      "total_loss": 0.48950424790382385
    },
    {
      "classification_loss": 0.6585044264793396,
      "epoch": 17.81967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5435,
      "total_loss": 0.6585044264793396
    },
    {
      "classification_loss": 0.45975133776664734,
      "epoch": 17.82295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5436,
      "total_loss": 0.45975133776664734
    },
    {
      "classification_loss": 0.6300166249275208,
      "epoch": 17.82622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5437,
      "total_loss": 0.6300166249275208
    },
    {
      "classification_loss": 0.4635668694972992,
      "epoch": 17.82950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5438,
      "total_loss": 0.4635668694972992
    },
    {
      "classification_loss": 0.471975177526474,
      "epoch": 17.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5439,
      "total_loss": 0.471975177526474
    },
    {
      "classification_loss": 0.5038931369781494,
      "epoch": 17.83606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5440,
      "total_loss": 0.5038931369781494
    },
    {
      "classification_loss": 0.44097644090652466,
      "epoch": 17.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5441,
      "total_loss": 0.44097644090652466
    },
    {
      "classification_loss": 0.4759296178817749,
      "epoch": 17.84262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5442,
      "total_loss": 0.4759296178817749
    },
    {
      "classification_loss": 0.5445811152458191,
      "epoch": 17.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5443,
      "total_loss": 0.5445811152458191
    },
    {
      "classification_loss": 0.580197811126709,
      "epoch": 17.84918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5444,
      "total_loss": 0.580197811126709
    },
    {
      "classification_loss": 0.46477311849594116,
      "epoch": 17.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5445,
      "total_loss": 0.46477311849594116
    },
    {
      "classification_loss": 0.3439011573791504,
      "epoch": 17.855737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5446,
      "total_loss": 0.3439011573791504
    },
    {
      "classification_loss": 0.465240478515625,
      "epoch": 17.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5447,
      "total_loss": 0.465240478515625
    },
    {
      "classification_loss": 0.41816622018814087,
      "epoch": 17.862295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5448,
      "total_loss": 0.41816622018814087
    },
    {
      "classification_loss": 0.38241046667099,
      "epoch": 17.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5449,
      "total_loss": 0.38241046667099
    },
    {
      "classification_loss": 0.43750885128974915,
      "epoch": 17.868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5450,
      "total_loss": 0.43750885128974915
    },
    {
      "classification_loss": 0.5466875433921814,
      "epoch": 17.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5451,
      "total_loss": 0.5466875433921814
    },
    {
      "classification_loss": 0.4229183495044708,
      "epoch": 17.875409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5452,
      "total_loss": 0.4229183495044708
    },
    {
      "classification_loss": 0.48983684182167053,
      "epoch": 17.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5453,
      "total_loss": 0.48983684182167053
    },
    {
      "classification_loss": 0.4283983111381531,
      "epoch": 17.881967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5454,
      "total_loss": 0.4283983111381531
    },
    {
      "classification_loss": 0.5501817464828491,
      "epoch": 17.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5455,
      "total_loss": 0.5501817464828491
    },
    {
      "classification_loss": 0.5018328428268433,
      "epoch": 17.888524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5456,
      "total_loss": 0.5018328428268433
    },
    {
      "classification_loss": 0.5978483557701111,
      "epoch": 17.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5457,
      "total_loss": 0.5978483557701111
    },
    {
      "classification_loss": 0.5671913623809814,
      "epoch": 17.895081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5458,
      "total_loss": 0.5671913623809814
    },
    {
      "classification_loss": 0.5163256525993347,
      "epoch": 17.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5459,
      "total_loss": 0.5163256525993347
    },
    {
      "classification_loss": 0.5997134447097778,
      "epoch": 17.901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5460,
      "total_loss": 0.5997134447097778
    },
    {
      "classification_loss": 0.5331427454948425,
      "epoch": 17.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5461,
      "total_loss": 0.5331427454948425
    },
    {
      "classification_loss": 0.5514678359031677,
      "epoch": 17.908196721311477,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5462,
      "total_loss": 0.5514678359031677
    },
    {
      "classification_loss": 0.4452807903289795,
      "epoch": 17.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5463,
      "total_loss": 0.4452807903289795
    },
    {
      "classification_loss": 0.5927100777626038,
      "epoch": 17.914754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5464,
      "total_loss": 0.5927100777626038
    },
    {
      "classification_loss": 0.5657216310501099,
      "epoch": 17.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5465,
      "total_loss": 0.5657216310501099
    },
    {
      "classification_loss": 0.5542776584625244,
      "epoch": 17.921311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5466,
      "total_loss": 0.5542776584625244
    },
    {
      "classification_loss": 0.4966839551925659,
      "epoch": 17.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5467,
      "total_loss": 0.4966839551925659
    },
    {
      "classification_loss": 0.5026242136955261,
      "epoch": 17.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5468,
      "total_loss": 0.5026242136955261
    },
    {
      "classification_loss": 0.4349251389503479,
      "epoch": 17.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5469,
      "total_loss": 0.4349251389503479
    },
    {
      "classification_loss": 0.39680215716362,
      "epoch": 17.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5470,
      "total_loss": 0.39680215716362
    },
    {
      "classification_loss": 0.6195207238197327,
      "epoch": 17.937704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5471,
      "total_loss": 0.6195207238197327
    },
    {
      "classification_loss": 0.42056867480278015,
      "epoch": 17.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5472,
      "total_loss": 0.42056867480278015
    },
    {
      "classification_loss": 0.44715675711631775,
      "epoch": 17.944262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5473,
      "total_loss": 0.44715675711631775
    },
    {
      "classification_loss": 0.5717840790748596,
      "epoch": 17.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5474,
      "total_loss": 0.5717840790748596
    },
    {
      "classification_loss": 0.40060216188430786,
      "epoch": 17.950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5475,
      "total_loss": 0.40060216188430786
    },
    {
      "classification_loss": 0.5233014822006226,
      "epoch": 17.95409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5476,
      "total_loss": 0.5233014822006226
    },
    {
      "classification_loss": 0.4550377428531647,
      "epoch": 17.957377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5477,
      "total_loss": 0.4550377428531647
    },
    {
      "classification_loss": 0.5395190715789795,
      "epoch": 17.96065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5478,
      "total_loss": 0.5395190715789795
    },
    {
      "classification_loss": 0.4529813230037689,
      "epoch": 17.963934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5479,
      "total_loss": 0.4529813230037689
    },
    {
      "classification_loss": 0.4308176338672638,
      "epoch": 17.9672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5480,
      "total_loss": 0.4308176338672638
    },
    {
      "classification_loss": 0.5209646224975586,
      "epoch": 17.970491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5481,
      "total_loss": 0.5209646224975586
    },
    {
      "classification_loss": 0.45122087001800537,
      "epoch": 17.97377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5482,
      "total_loss": 0.45122087001800537
    },
    {
      "classification_loss": 0.3992546498775482,
      "epoch": 17.977049180327867,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5483,
      "total_loss": 0.3992546498775482
    },
    {
      "classification_loss": 0.43640753626823425,
      "epoch": 17.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5484,
      "total_loss": 0.43640753626823425
    },
    {
      "classification_loss": 0.5594955086708069,
      "epoch": 17.983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5485,
      "total_loss": 0.5594955086708069
    },
    {
      "classification_loss": 0.4918239712715149,
      "epoch": 17.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5486,
      "total_loss": 0.4918239712715149
    },
    {
      "classification_loss": 0.428651362657547,
      "epoch": 17.990163934426228,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5487,
      "total_loss": 0.428651362657547
    },
    {
      "classification_loss": 0.5853835940361023,
      "epoch": 17.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5488,
      "total_loss": 0.5853835940361023
    },
    {
      "classification_loss": 0.3617261052131653,
      "epoch": 17.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5489,
      "total_loss": 0.3617261052131653
    },
    {
      "classification_loss": 1.5548455715179443,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.5548455715179443
    },
    {
      "classification_loss": 1.4731210470199585,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.4731210470199585
    },
    {
      "classification_loss": 1.3536053895950317,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.3536053895950317
    },
    {
      "classification_loss": 1.686703085899353,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.686703085899353
    },
    {
      "classification_loss": 1.3774675130844116,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.3774675130844116
    },
    {
      "classification_loss": 1.3673969507217407,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.3673969507217407
    },
    {
      "classification_loss": 1.4578216075897217,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.4578216075897217
    },
    {
      "classification_loss": 1.2297718524932861,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 1.2297718524932861
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.4425793886184692,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0091,
      "eval_samples_per_second": 166.414,
      "eval_steps_per_second": 1.331,
      "step": 5490
    },
    {
      "classification_loss": 0.42400768399238586,
      "epoch": 18.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5490,
      "total_loss": 0.42400768399238586
    },
    {
      "classification_loss": 0.47598394751548767,
      "epoch": 18.003278688524592,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5491,
      "total_loss": 0.47598394751548767
    },
    {
      "classification_loss": 0.39817142486572266,
      "epoch": 18.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5492,
      "total_loss": 0.39817142486572266
    },
    {
      "classification_loss": 0.4898904263973236,
      "epoch": 18.009836065573772,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5493,
      "total_loss": 0.4898904263973236
    },
    {
      "classification_loss": 0.45654940605163574,
      "epoch": 18.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5494,
      "total_loss": 0.45654940605163574
    },
    {
      "classification_loss": 0.5068698525428772,
      "epoch": 18.016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5495,
      "total_loss": 0.5068698525428772
    },
    {
      "classification_loss": 0.4916255474090576,
      "epoch": 18.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5496,
      "total_loss": 0.4916255474090576
    },
    {
      "classification_loss": 0.5335164666175842,
      "epoch": 18.022950819672133,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5497,
      "total_loss": 0.5335164666175842
    },
    {
      "classification_loss": 0.5473566055297852,
      "epoch": 18.02622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5498,
      "total_loss": 0.5473566055297852
    },
    {
      "classification_loss": 0.3375198245048523,
      "epoch": 18.029508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5499,
      "total_loss": 0.3375198245048523
    },
    {
      "epoch": 18.0327868852459,
      "grad_norm": 1.9489071369171143,
      "learning_rate": 2.0033333333333334e-05,
      "loss": 0.4907,
      "step": 5500
    },
    {
      "classification_loss": 0.5353236198425293,
      "epoch": 18.0327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5500,
      "total_loss": 0.5353236198425293
    },
    {
      "classification_loss": 0.4184574782848358,
      "epoch": 18.036065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5501,
      "total_loss": 0.4184574782848358
    },
    {
      "classification_loss": 0.4951918423175812,
      "epoch": 18.03934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5502,
      "total_loss": 0.4951918423175812
    },
    {
      "classification_loss": 0.5357446670532227,
      "epoch": 18.042622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5503,
      "total_loss": 0.5357446670532227
    },
    {
      "classification_loss": 0.5879946947097778,
      "epoch": 18.04590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5504,
      "total_loss": 0.5879946947097778
    },
    {
      "classification_loss": 0.43890315294265747,
      "epoch": 18.049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5505,
      "total_loss": 0.43890315294265747
    },
    {
      "classification_loss": 0.45128685235977173,
      "epoch": 18.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5506,
      "total_loss": 0.45128685235977173
    },
    {
      "classification_loss": 0.5653393268585205,
      "epoch": 18.055737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5507,
      "total_loss": 0.5653393268585205
    },
    {
      "classification_loss": 0.43593016266822815,
      "epoch": 18.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5508,
      "total_loss": 0.43593016266822815
    },
    {
      "classification_loss": 0.5626600384712219,
      "epoch": 18.062295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5509,
      "total_loss": 0.5626600384712219
    },
    {
      "classification_loss": 0.5745328664779663,
      "epoch": 18.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5510,
      "total_loss": 0.5745328664779663
    },
    {
      "classification_loss": 0.4708016514778137,
      "epoch": 18.068852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5511,
      "total_loss": 0.4708016514778137
    },
    {
      "classification_loss": 0.4723730981349945,
      "epoch": 18.072131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5512,
      "total_loss": 0.4723730981349945
    },
    {
      "classification_loss": 0.4586818516254425,
      "epoch": 18.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5513,
      "total_loss": 0.4586818516254425
    },
    {
      "classification_loss": 0.5044300556182861,
      "epoch": 18.078688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5514,
      "total_loss": 0.5044300556182861
    },
    {
      "classification_loss": 0.5224594473838806,
      "epoch": 18.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5515,
      "total_loss": 0.5224594473838806
    },
    {
      "classification_loss": 0.5077580809593201,
      "epoch": 18.085245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5516,
      "total_loss": 0.5077580809593201
    },
    {
      "classification_loss": 0.4186568260192871,
      "epoch": 18.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5517,
      "total_loss": 0.4186568260192871
    },
    {
      "classification_loss": 0.4547051787376404,
      "epoch": 18.091803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5518,
      "total_loss": 0.4547051787376404
    },
    {
      "classification_loss": 0.43644776940345764,
      "epoch": 18.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5519,
      "total_loss": 0.43644776940345764
    },
    {
      "classification_loss": 0.47873079776763916,
      "epoch": 18.098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5520,
      "total_loss": 0.47873079776763916
    },
    {
      "classification_loss": 0.4545198082923889,
      "epoch": 18.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5521,
      "total_loss": 0.4545198082923889
    },
    {
      "classification_loss": 0.4514097571372986,
      "epoch": 18.104918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5522,
      "total_loss": 0.4514097571372986
    },
    {
      "classification_loss": 0.48081475496292114,
      "epoch": 18.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5523,
      "total_loss": 0.48081475496292114
    },
    {
      "classification_loss": 0.45802056789398193,
      "epoch": 18.111475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5524,
      "total_loss": 0.45802056789398193
    },
    {
      "classification_loss": 0.5373222827911377,
      "epoch": 18.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5525,
      "total_loss": 0.5373222827911377
    },
    {
      "classification_loss": 0.4853382706642151,
      "epoch": 18.118032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5526,
      "total_loss": 0.4853382706642151
    },
    {
      "classification_loss": 0.39886894822120667,
      "epoch": 18.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5527,
      "total_loss": 0.39886894822120667
    },
    {
      "classification_loss": 0.6529729962348938,
      "epoch": 18.124590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5528,
      "total_loss": 0.6529729962348938
    },
    {
      "classification_loss": 0.4066365659236908,
      "epoch": 18.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5529,
      "total_loss": 0.4066365659236908
    },
    {
      "classification_loss": 0.4933164417743683,
      "epoch": 18.131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5530,
      "total_loss": 0.4933164417743683
    },
    {
      "classification_loss": 0.46860364079475403,
      "epoch": 18.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5531,
      "total_loss": 0.46860364079475403
    },
    {
      "classification_loss": 0.5404216051101685,
      "epoch": 18.137704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5532,
      "total_loss": 0.5404216051101685
    },
    {
      "classification_loss": 0.44709885120391846,
      "epoch": 18.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5533,
      "total_loss": 0.44709885120391846
    },
    {
      "classification_loss": 0.36176827549934387,
      "epoch": 18.14426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5534,
      "total_loss": 0.36176827549934387
    },
    {
      "classification_loss": 0.5179038047790527,
      "epoch": 18.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5535,
      "total_loss": 0.5179038047790527
    },
    {
      "classification_loss": 0.4004795551300049,
      "epoch": 18.15081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5536,
      "total_loss": 0.4004795551300049
    },
    {
      "classification_loss": 0.44790953397750854,
      "epoch": 18.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5537,
      "total_loss": 0.44790953397750854
    },
    {
      "classification_loss": 0.5635436773300171,
      "epoch": 18.15737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5538,
      "total_loss": 0.5635436773300171
    },
    {
      "classification_loss": 0.4401986598968506,
      "epoch": 18.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5539,
      "total_loss": 0.4401986598968506
    },
    {
      "classification_loss": 0.47753340005874634,
      "epoch": 18.16393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5540,
      "total_loss": 0.47753340005874634
    },
    {
      "classification_loss": 0.528071939945221,
      "epoch": 18.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5541,
      "total_loss": 0.528071939945221
    },
    {
      "classification_loss": 0.43996089696884155,
      "epoch": 18.17049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5542,
      "total_loss": 0.43996089696884155
    },
    {
      "classification_loss": 0.564871609210968,
      "epoch": 18.17377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5543,
      "total_loss": 0.564871609210968
    },
    {
      "classification_loss": 0.43522489070892334,
      "epoch": 18.17704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5544,
      "total_loss": 0.43522489070892334
    },
    {
      "classification_loss": 0.5366524457931519,
      "epoch": 18.18032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5545,
      "total_loss": 0.5366524457931519
    },
    {
      "classification_loss": 0.49758198857307434,
      "epoch": 18.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5546,
      "total_loss": 0.49758198857307434
    },
    {
      "classification_loss": 0.47958025336265564,
      "epoch": 18.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5547,
      "total_loss": 0.47958025336265564
    },
    {
      "classification_loss": 0.37677282094955444,
      "epoch": 18.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5548,
      "total_loss": 0.37677282094955444
    },
    {
      "classification_loss": 0.5172044038772583,
      "epoch": 18.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5549,
      "total_loss": 0.5172044038772583
    },
    {
      "classification_loss": 0.507926881313324,
      "epoch": 18.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5550,
      "total_loss": 0.507926881313324
    },
    {
      "classification_loss": 0.4572959542274475,
      "epoch": 18.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5551,
      "total_loss": 0.4572959542274475
    },
    {
      "classification_loss": 0.4470178782939911,
      "epoch": 18.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5552,
      "total_loss": 0.4470178782939911
    },
    {
      "classification_loss": 0.5134669542312622,
      "epoch": 18.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5553,
      "total_loss": 0.5134669542312622
    },
    {
      "classification_loss": 0.5642484426498413,
      "epoch": 18.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5554,
      "total_loss": 0.5642484426498413
    },
    {
      "classification_loss": 0.4099405109882355,
      "epoch": 18.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5555,
      "total_loss": 0.4099405109882355
    },
    {
      "classification_loss": 0.47487807273864746,
      "epoch": 18.21639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5556,
      "total_loss": 0.47487807273864746
    },
    {
      "classification_loss": 0.5039670467376709,
      "epoch": 18.21967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5557,
      "total_loss": 0.5039670467376709
    },
    {
      "classification_loss": 0.5440945029258728,
      "epoch": 18.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5558,
      "total_loss": 0.5440945029258728
    },
    {
      "classification_loss": 0.5008182525634766,
      "epoch": 18.22622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5559,
      "total_loss": 0.5008182525634766
    },
    {
      "classification_loss": 0.4694676995277405,
      "epoch": 18.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5560,
      "total_loss": 0.4694676995277405
    },
    {
      "classification_loss": 0.6586281061172485,
      "epoch": 18.2327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5561,
      "total_loss": 0.6586281061172485
    },
    {
      "classification_loss": 0.42443981766700745,
      "epoch": 18.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5562,
      "total_loss": 0.42443981766700745
    },
    {
      "classification_loss": 0.43709686398506165,
      "epoch": 18.23934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5563,
      "total_loss": 0.43709686398506165
    },
    {
      "classification_loss": 0.5354974865913391,
      "epoch": 18.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5564,
      "total_loss": 0.5354974865913391
    },
    {
      "classification_loss": 0.42601779103279114,
      "epoch": 18.24590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5565,
      "total_loss": 0.42601779103279114
    },
    {
      "classification_loss": 0.4434090256690979,
      "epoch": 18.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5566,
      "total_loss": 0.4434090256690979
    },
    {
      "classification_loss": 0.4261206388473511,
      "epoch": 18.25245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5567,
      "total_loss": 0.4261206388473511
    },
    {
      "classification_loss": 0.4901392459869385,
      "epoch": 18.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5568,
      "total_loss": 0.4901392459869385
    },
    {
      "classification_loss": 0.4806347191333771,
      "epoch": 18.25901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5569,
      "total_loss": 0.4806347191333771
    },
    {
      "classification_loss": 0.4191926419734955,
      "epoch": 18.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5570,
      "total_loss": 0.4191926419734955
    },
    {
      "classification_loss": 0.5133988261222839,
      "epoch": 18.2655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5571,
      "total_loss": 0.5133988261222839
    },
    {
      "classification_loss": 0.5688624978065491,
      "epoch": 18.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5572,
      "total_loss": 0.5688624978065491
    },
    {
      "classification_loss": 0.37232545018196106,
      "epoch": 18.272131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5573,
      "total_loss": 0.37232545018196106
    },
    {
      "classification_loss": 0.42426779866218567,
      "epoch": 18.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5574,
      "total_loss": 0.42426779866218567
    },
    {
      "classification_loss": 0.5981050729751587,
      "epoch": 18.278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5575,
      "total_loss": 0.5981050729751587
    },
    {
      "classification_loss": 0.4821617603302002,
      "epoch": 18.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5576,
      "total_loss": 0.4821617603302002
    },
    {
      "classification_loss": 0.5466489195823669,
      "epoch": 18.285245901639342,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5577,
      "total_loss": 0.5466489195823669
    },
    {
      "classification_loss": 0.46949297189712524,
      "epoch": 18.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5578,
      "total_loss": 0.46949297189712524
    },
    {
      "classification_loss": 0.4769713878631592,
      "epoch": 18.291803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5579,
      "total_loss": 0.4769713878631592
    },
    {
      "classification_loss": 0.46325767040252686,
      "epoch": 18.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5580,
      "total_loss": 0.46325767040252686
    },
    {
      "classification_loss": 0.46235206723213196,
      "epoch": 18.298360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5581,
      "total_loss": 0.46235206723213196
    },
    {
      "classification_loss": 0.5434931516647339,
      "epoch": 18.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5582,
      "total_loss": 0.5434931516647339
    },
    {
      "classification_loss": 0.41615456342697144,
      "epoch": 18.304918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5583,
      "total_loss": 0.41615456342697144
    },
    {
      "classification_loss": 0.4432376027107239,
      "epoch": 18.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5584,
      "total_loss": 0.4432376027107239
    },
    {
      "classification_loss": 0.39837631583213806,
      "epoch": 18.311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5585,
      "total_loss": 0.39837631583213806
    },
    {
      "classification_loss": 0.361256867647171,
      "epoch": 18.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5586,
      "total_loss": 0.361256867647171
    },
    {
      "classification_loss": 0.5171201229095459,
      "epoch": 18.318032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5587,
      "total_loss": 0.5171201229095459
    },
    {
      "classification_loss": 0.5287805199623108,
      "epoch": 18.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5588,
      "total_loss": 0.5287805199623108
    },
    {
      "classification_loss": 0.4772922098636627,
      "epoch": 18.324590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5589,
      "total_loss": 0.4772922098636627
    },
    {
      "classification_loss": 0.5370913147926331,
      "epoch": 18.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5590,
      "total_loss": 0.5370913147926331
    },
    {
      "classification_loss": 0.43582358956336975,
      "epoch": 18.331147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5591,
      "total_loss": 0.43582358956336975
    },
    {
      "classification_loss": 0.4612109065055847,
      "epoch": 18.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5592,
      "total_loss": 0.4612109065055847
    },
    {
      "classification_loss": 0.40050390362739563,
      "epoch": 18.337704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5593,
      "total_loss": 0.40050390362739563
    },
    {
      "classification_loss": 0.42124292254447937,
      "epoch": 18.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5594,
      "total_loss": 0.42124292254447937
    },
    {
      "classification_loss": 0.4897382855415344,
      "epoch": 18.34426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5595,
      "total_loss": 0.4897382855415344
    },
    {
      "classification_loss": 0.48289456963539124,
      "epoch": 18.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5596,
      "total_loss": 0.48289456963539124
    },
    {
      "classification_loss": 0.5388477444648743,
      "epoch": 18.35081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5597,
      "total_loss": 0.5388477444648743
    },
    {
      "classification_loss": 0.4906562864780426,
      "epoch": 18.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5598,
      "total_loss": 0.4906562864780426
    },
    {
      "classification_loss": 0.49737489223480225,
      "epoch": 18.35737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5599,
      "total_loss": 0.49737489223480225
    },
    {
      "epoch": 18.360655737704917,
      "grad_norm": 3.152705430984497,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 0.4814,
      "step": 5600
    },
    {
      "classification_loss": 0.44017061591148376,
      "epoch": 18.360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5600,
      "total_loss": 0.44017061591148376
    },
    {
      "classification_loss": 0.5108601450920105,
      "epoch": 18.36393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5601,
      "total_loss": 0.5108601450920105
    },
    {
      "classification_loss": 0.5110307931900024,
      "epoch": 18.367213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5602,
      "total_loss": 0.5110307931900024
    },
    {
      "classification_loss": 0.5022249817848206,
      "epoch": 18.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5603,
      "total_loss": 0.5022249817848206
    },
    {
      "classification_loss": 0.4885181784629822,
      "epoch": 18.373770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5604,
      "total_loss": 0.4885181784629822
    },
    {
      "classification_loss": 0.538003146648407,
      "epoch": 18.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5605,
      "total_loss": 0.538003146648407
    },
    {
      "classification_loss": 0.29443448781967163,
      "epoch": 18.380327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5606,
      "total_loss": 0.29443448781967163
    },
    {
      "classification_loss": 0.5491302609443665,
      "epoch": 18.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5607,
      "total_loss": 0.5491302609443665
    },
    {
      "classification_loss": 0.46943268179893494,
      "epoch": 18.386885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5608,
      "total_loss": 0.46943268179893494
    },
    {
      "classification_loss": 0.43312734365463257,
      "epoch": 18.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5609,
      "total_loss": 0.43312734365463257
    },
    {
      "classification_loss": 0.4932149350643158,
      "epoch": 18.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5610,
      "total_loss": 0.4932149350643158
    },
    {
      "classification_loss": 0.49207520484924316,
      "epoch": 18.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5611,
      "total_loss": 0.49207520484924316
    },
    {
      "classification_loss": 0.4942292869091034,
      "epoch": 18.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5612,
      "total_loss": 0.4942292869091034
    },
    {
      "classification_loss": 0.5881786942481995,
      "epoch": 18.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5613,
      "total_loss": 0.5881786942481995
    },
    {
      "classification_loss": 0.4266309142112732,
      "epoch": 18.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5614,
      "total_loss": 0.4266309142112732
    },
    {
      "classification_loss": 0.398353636264801,
      "epoch": 18.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5615,
      "total_loss": 0.398353636264801
    },
    {
      "classification_loss": 0.48409008979797363,
      "epoch": 18.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5616,
      "total_loss": 0.48409008979797363
    },
    {
      "classification_loss": 0.4457910358905792,
      "epoch": 18.41639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5617,
      "total_loss": 0.4457910358905792
    },
    {
      "classification_loss": 0.5623964667320251,
      "epoch": 18.41967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5618,
      "total_loss": 0.5623964667320251
    },
    {
      "classification_loss": 0.4551633596420288,
      "epoch": 18.42295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5619,
      "total_loss": 0.4551633596420288
    },
    {
      "classification_loss": 0.39769643545150757,
      "epoch": 18.42622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5620,
      "total_loss": 0.39769643545150757
    },
    {
      "classification_loss": 0.5046818852424622,
      "epoch": 18.42950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5621,
      "total_loss": 0.5046818852424622
    },
    {
      "classification_loss": 0.5208169221878052,
      "epoch": 18.432786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5622,
      "total_loss": 0.5208169221878052
    },
    {
      "classification_loss": 0.39650586247444153,
      "epoch": 18.43606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5623,
      "total_loss": 0.39650586247444153
    },
    {
      "classification_loss": 0.46399247646331787,
      "epoch": 18.439344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5624,
      "total_loss": 0.46399247646331787
    },
    {
      "classification_loss": 0.51824951171875,
      "epoch": 18.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5625,
      "total_loss": 0.51824951171875
    },
    {
      "classification_loss": 0.5584332942962646,
      "epoch": 18.445901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5626,
      "total_loss": 0.5584332942962646
    },
    {
      "classification_loss": 0.5828770995140076,
      "epoch": 18.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5627,
      "total_loss": 0.5828770995140076
    },
    {
      "classification_loss": 0.6112687587738037,
      "epoch": 18.452459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5628,
      "total_loss": 0.6112687587738037
    },
    {
      "classification_loss": 0.47346824407577515,
      "epoch": 18.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5629,
      "total_loss": 0.47346824407577515
    },
    {
      "classification_loss": 0.4881249666213989,
      "epoch": 18.459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5630,
      "total_loss": 0.4881249666213989
    },
    {
      "classification_loss": 0.4966348111629486,
      "epoch": 18.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5631,
      "total_loss": 0.4966348111629486
    },
    {
      "classification_loss": 0.4404737055301666,
      "epoch": 18.465573770491805,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5632,
      "total_loss": 0.4404737055301666
    },
    {
      "classification_loss": 0.40970665216445923,
      "epoch": 18.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5633,
      "total_loss": 0.40970665216445923
    },
    {
      "classification_loss": 0.5750328302383423,
      "epoch": 18.472131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5634,
      "total_loss": 0.5750328302383423
    },
    {
      "classification_loss": 0.453346312046051,
      "epoch": 18.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5635,
      "total_loss": 0.453346312046051
    },
    {
      "classification_loss": 0.4203534722328186,
      "epoch": 18.478688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5636,
      "total_loss": 0.4203534722328186
    },
    {
      "classification_loss": 0.417193740606308,
      "epoch": 18.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5637,
      "total_loss": 0.417193740606308
    },
    {
      "classification_loss": 0.4754609763622284,
      "epoch": 18.485245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5638,
      "total_loss": 0.4754609763622284
    },
    {
      "classification_loss": 0.4388332664966583,
      "epoch": 18.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5639,
      "total_loss": 0.4388332664966583
    },
    {
      "classification_loss": 0.45459794998168945,
      "epoch": 18.491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5640,
      "total_loss": 0.45459794998168945
    },
    {
      "classification_loss": 0.5581179857254028,
      "epoch": 18.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5641,
      "total_loss": 0.5581179857254028
    },
    {
      "classification_loss": 0.4297950565814972,
      "epoch": 18.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5642,
      "total_loss": 0.4297950565814972
    },
    {
      "classification_loss": 0.4233405888080597,
      "epoch": 18.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5643,
      "total_loss": 0.4233405888080597
    },
    {
      "classification_loss": 0.48766669631004333,
      "epoch": 18.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5644,
      "total_loss": 0.48766669631004333
    },
    {
      "classification_loss": 0.5317375063896179,
      "epoch": 18.508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5645,
      "total_loss": 0.5317375063896179
    },
    {
      "classification_loss": 0.4221705198287964,
      "epoch": 18.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5646,
      "total_loss": 0.4221705198287964
    },
    {
      "classification_loss": 0.4652329683303833,
      "epoch": 18.514754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5647,
      "total_loss": 0.4652329683303833
    },
    {
      "classification_loss": 0.55442875623703,
      "epoch": 18.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5648,
      "total_loss": 0.55442875623703
    },
    {
      "classification_loss": 0.5807345509529114,
      "epoch": 18.521311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5649,
      "total_loss": 0.5807345509529114
    },
    {
      "classification_loss": 0.5136398673057556,
      "epoch": 18.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5650,
      "total_loss": 0.5136398673057556
    },
    {
      "classification_loss": 0.6139084100723267,
      "epoch": 18.527868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5651,
      "total_loss": 0.6139084100723267
    },
    {
      "classification_loss": 0.41859397292137146,
      "epoch": 18.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5652,
      "total_loss": 0.41859397292137146
    },
    {
      "classification_loss": 0.5076484084129333,
      "epoch": 18.534426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5653,
      "total_loss": 0.5076484084129333
    },
    {
      "classification_loss": 0.3968317210674286,
      "epoch": 18.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5654,
      "total_loss": 0.3968317210674286
    },
    {
      "classification_loss": 0.44232645630836487,
      "epoch": 18.540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5655,
      "total_loss": 0.44232645630836487
    },
    {
      "classification_loss": 0.45525187253952026,
      "epoch": 18.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5656,
      "total_loss": 0.45525187253952026
    },
    {
      "classification_loss": 0.4552960991859436,
      "epoch": 18.547540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5657,
      "total_loss": 0.4552960991859436
    },
    {
      "classification_loss": 0.4697387218475342,
      "epoch": 18.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5658,
      "total_loss": 0.4697387218475342
    },
    {
      "classification_loss": 0.4209102392196655,
      "epoch": 18.554098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5659,
      "total_loss": 0.4209102392196655
    },
    {
      "classification_loss": 0.45826393365859985,
      "epoch": 18.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5660,
      "total_loss": 0.45826393365859985
    },
    {
      "classification_loss": 0.48431119322776794,
      "epoch": 18.560655737704916,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5661,
      "total_loss": 0.48431119322776794
    },
    {
      "classification_loss": 0.4111020863056183,
      "epoch": 18.56393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5662,
      "total_loss": 0.4111020863056183
    },
    {
      "classification_loss": 0.5308760404586792,
      "epoch": 18.567213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5663,
      "total_loss": 0.5308760404586792
    },
    {
      "classification_loss": 0.5499716997146606,
      "epoch": 18.57049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5664,
      "total_loss": 0.5499716997146606
    },
    {
      "classification_loss": 0.4576171338558197,
      "epoch": 18.57377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5665,
      "total_loss": 0.4576171338558197
    },
    {
      "classification_loss": 0.48407885432243347,
      "epoch": 18.57704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5666,
      "total_loss": 0.48407885432243347
    },
    {
      "classification_loss": 0.48380520939826965,
      "epoch": 18.58032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5667,
      "total_loss": 0.48380520939826965
    },
    {
      "classification_loss": 0.4420064091682434,
      "epoch": 18.58360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5668,
      "total_loss": 0.4420064091682434
    },
    {
      "classification_loss": 0.639197587966919,
      "epoch": 18.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5669,
      "total_loss": 0.639197587966919
    },
    {
      "classification_loss": 0.5125650763511658,
      "epoch": 18.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5670,
      "total_loss": 0.5125650763511658
    },
    {
      "classification_loss": 0.4849643409252167,
      "epoch": 18.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5671,
      "total_loss": 0.4849643409252167
    },
    {
      "classification_loss": 0.5719048976898193,
      "epoch": 18.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5672,
      "total_loss": 0.5719048976898193
    },
    {
      "classification_loss": 0.6433385610580444,
      "epoch": 18.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5673,
      "total_loss": 0.6433385610580444
    },
    {
      "classification_loss": 0.40207207202911377,
      "epoch": 18.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5674,
      "total_loss": 0.40207207202911377
    },
    {
      "classification_loss": 0.46471336483955383,
      "epoch": 18.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5675,
      "total_loss": 0.46471336483955383
    },
    {
      "classification_loss": 0.45260995626449585,
      "epoch": 18.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5676,
      "total_loss": 0.45260995626449585
    },
    {
      "classification_loss": 0.6107066869735718,
      "epoch": 18.613114754098362,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5677,
      "total_loss": 0.6107066869735718
    },
    {
      "classification_loss": 0.43222835659980774,
      "epoch": 18.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5678,
      "total_loss": 0.43222835659980774
    },
    {
      "classification_loss": 0.4969930946826935,
      "epoch": 18.619672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5679,
      "total_loss": 0.4969930946826935
    },
    {
      "classification_loss": 0.4598280191421509,
      "epoch": 18.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5680,
      "total_loss": 0.4598280191421509
    },
    {
      "classification_loss": 0.3859075605869293,
      "epoch": 18.626229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5681,
      "total_loss": 0.3859075605869293
    },
    {
      "classification_loss": 0.44222602248191833,
      "epoch": 18.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5682,
      "total_loss": 0.44222602248191833
    },
    {
      "classification_loss": 0.45625320076942444,
      "epoch": 18.632786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5683,
      "total_loss": 0.45625320076942444
    },
    {
      "classification_loss": 0.43523579835891724,
      "epoch": 18.63606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5684,
      "total_loss": 0.43523579835891724
    },
    {
      "classification_loss": 0.5285208225250244,
      "epoch": 18.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5685,
      "total_loss": 0.5285208225250244
    },
    {
      "classification_loss": 0.4219340980052948,
      "epoch": 18.64262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5686,
      "total_loss": 0.4219340980052948
    },
    {
      "classification_loss": 0.42355677485466003,
      "epoch": 18.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5687,
      "total_loss": 0.42355677485466003
    },
    {
      "classification_loss": 0.3873203992843628,
      "epoch": 18.64918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5688,
      "total_loss": 0.3873203992843628
    },
    {
      "classification_loss": 0.3972740173339844,
      "epoch": 18.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5689,
      "total_loss": 0.3972740173339844
    },
    {
      "classification_loss": 0.45947444438934326,
      "epoch": 18.65573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5690,
      "total_loss": 0.45947444438934326
    },
    {
      "classification_loss": 0.6423123478889465,
      "epoch": 18.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5691,
      "total_loss": 0.6423123478889465
    },
    {
      "classification_loss": 0.41993770003318787,
      "epoch": 18.662295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5692,
      "total_loss": 0.41993770003318787
    },
    {
      "classification_loss": 0.445587694644928,
      "epoch": 18.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5693,
      "total_loss": 0.445587694644928
    },
    {
      "classification_loss": 0.41213148832321167,
      "epoch": 18.668852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5694,
      "total_loss": 0.41213148832321167
    },
    {
      "classification_loss": 0.40490567684173584,
      "epoch": 18.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5695,
      "total_loss": 0.40490567684173584
    },
    {
      "classification_loss": 0.564171552658081,
      "epoch": 18.675409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5696,
      "total_loss": 0.564171552658081
    },
    {
      "classification_loss": 0.5228697061538696,
      "epoch": 18.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5697,
      "total_loss": 0.5228697061538696
    },
    {
      "classification_loss": 0.3980379104614258,
      "epoch": 18.681967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5698,
      "total_loss": 0.3980379104614258
    },
    {
      "classification_loss": 0.5851752161979675,
      "epoch": 18.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5699,
      "total_loss": 0.5851752161979675
    },
    {
      "epoch": 18.688524590163933,
      "grad_norm": 5.878291606903076,
      "learning_rate": 1.3366666666666667e-05,
      "loss": 0.4803,
      "step": 5700
    },
    {
      "classification_loss": 0.4569455087184906,
      "epoch": 18.688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5700,
      "total_loss": 0.4569455087184906
    },
    {
      "classification_loss": 0.5153529644012451,
      "epoch": 18.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5701,
      "total_loss": 0.5153529644012451
    },
    {
      "classification_loss": 0.4526485800743103,
      "epoch": 18.695081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5702,
      "total_loss": 0.4526485800743103
    },
    {
      "classification_loss": 0.44240614771842957,
      "epoch": 18.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5703,
      "total_loss": 0.44240614771842957
    },
    {
      "classification_loss": 0.5058774352073669,
      "epoch": 18.701639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5704,
      "total_loss": 0.5058774352073669
    },
    {
      "classification_loss": 0.5117520689964294,
      "epoch": 18.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5705,
      "total_loss": 0.5117520689964294
    },
    {
      "classification_loss": 0.4182555079460144,
      "epoch": 18.708196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5706,
      "total_loss": 0.4182555079460144
    },
    {
      "classification_loss": 0.48526787757873535,
      "epoch": 18.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5707,
      "total_loss": 0.48526787757873535
    },
    {
      "classification_loss": 0.4138871729373932,
      "epoch": 18.714754098360658,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5708,
      "total_loss": 0.4138871729373932
    },
    {
      "classification_loss": 0.6175652146339417,
      "epoch": 18.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5709,
      "total_loss": 0.6175652146339417
    },
    {
      "classification_loss": 0.5716684460639954,
      "epoch": 18.721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5710,
      "total_loss": 0.5716684460639954
    },
    {
      "classification_loss": 0.33923280239105225,
      "epoch": 18.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5711,
      "total_loss": 0.33923280239105225
    },
    {
      "classification_loss": 0.46302101016044617,
      "epoch": 18.727868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5712,
      "total_loss": 0.46302101016044617
    },
    {
      "classification_loss": 0.46998733282089233,
      "epoch": 18.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5713,
      "total_loss": 0.46998733282089233
    },
    {
      "classification_loss": 0.4162583649158478,
      "epoch": 18.7344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5714,
      "total_loss": 0.4162583649158478
    },
    {
      "classification_loss": 0.5488784313201904,
      "epoch": 18.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5715,
      "total_loss": 0.5488784313201904
    },
    {
      "classification_loss": 0.5340749621391296,
      "epoch": 18.74098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5716,
      "total_loss": 0.5340749621391296
    },
    {
      "classification_loss": 0.47547534108161926,
      "epoch": 18.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5717,
      "total_loss": 0.47547534108161926
    },
    {
      "classification_loss": 0.39329424500465393,
      "epoch": 18.74754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5718,
      "total_loss": 0.39329424500465393
    },
    {
      "classification_loss": 0.4974531829357147,
      "epoch": 18.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5719,
      "total_loss": 0.4974531829357147
    },
    {
      "classification_loss": 0.3941117525100708,
      "epoch": 18.75409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5720,
      "total_loss": 0.3941117525100708
    },
    {
      "classification_loss": 0.37120914459228516,
      "epoch": 18.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5721,
      "total_loss": 0.37120914459228516
    },
    {
      "classification_loss": 0.6089892387390137,
      "epoch": 18.76065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5722,
      "total_loss": 0.6089892387390137
    },
    {
      "classification_loss": 0.5398989915847778,
      "epoch": 18.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5723,
      "total_loss": 0.5398989915847778
    },
    {
      "classification_loss": 0.4543250799179077,
      "epoch": 18.7672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5724,
      "total_loss": 0.4543250799179077
    },
    {
      "classification_loss": 0.5419877171516418,
      "epoch": 18.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5725,
      "total_loss": 0.5419877171516418
    },
    {
      "classification_loss": 0.48637720942497253,
      "epoch": 18.77377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5726,
      "total_loss": 0.48637720942497253
    },
    {
      "classification_loss": 0.5121365189552307,
      "epoch": 18.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5727,
      "total_loss": 0.5121365189552307
    },
    {
      "classification_loss": 0.37714236974716187,
      "epoch": 18.78032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5728,
      "total_loss": 0.37714236974716187
    },
    {
      "classification_loss": 0.40750619769096375,
      "epoch": 18.78360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5729,
      "total_loss": 0.40750619769096375
    },
    {
      "classification_loss": 0.4447331130504608,
      "epoch": 18.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5730,
      "total_loss": 0.4447331130504608
    },
    {
      "classification_loss": 0.46779024600982666,
      "epoch": 18.79016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5731,
      "total_loss": 0.46779024600982666
    },
    {
      "classification_loss": 0.4738071858882904,
      "epoch": 18.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5732,
      "total_loss": 0.4738071858882904
    },
    {
      "classification_loss": 0.4261445999145508,
      "epoch": 18.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5733,
      "total_loss": 0.4261445999145508
    },
    {
      "classification_loss": 0.3607232868671417,
      "epoch": 18.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5734,
      "total_loss": 0.3607232868671417
    },
    {
      "classification_loss": 0.5656941533088684,
      "epoch": 18.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5735,
      "total_loss": 0.5656941533088684
    },
    {
      "classification_loss": 0.43150103092193604,
      "epoch": 18.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5736,
      "total_loss": 0.43150103092193604
    },
    {
      "classification_loss": 0.40468981862068176,
      "epoch": 18.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5737,
      "total_loss": 0.40468981862068176
    },
    {
      "classification_loss": 0.4101965129375458,
      "epoch": 18.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5738,
      "total_loss": 0.4101965129375458
    },
    {
      "classification_loss": 0.5888568758964539,
      "epoch": 18.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5739,
      "total_loss": 0.5888568758964539
    },
    {
      "classification_loss": 0.39193642139434814,
      "epoch": 18.81967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5740,
      "total_loss": 0.39193642139434814
    },
    {
      "classification_loss": 0.4939624071121216,
      "epoch": 18.82295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5741,
      "total_loss": 0.4939624071121216
    },
    {
      "classification_loss": 0.42788735032081604,
      "epoch": 18.82622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5742,
      "total_loss": 0.42788735032081604
    },
    {
      "classification_loss": 0.4097386598587036,
      "epoch": 18.82950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5743,
      "total_loss": 0.4097386598587036
    },
    {
      "classification_loss": 0.37115478515625,
      "epoch": 18.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5744,
      "total_loss": 0.37115478515625
    },
    {
      "classification_loss": 0.4416848123073578,
      "epoch": 18.83606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5745,
      "total_loss": 0.4416848123073578
    },
    {
      "classification_loss": 0.3195563554763794,
      "epoch": 18.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5746,
      "total_loss": 0.3195563554763794
    },
    {
      "classification_loss": 0.40562012791633606,
      "epoch": 18.84262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5747,
      "total_loss": 0.40562012791633606
    },
    {
      "classification_loss": 0.4344651997089386,
      "epoch": 18.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5748,
      "total_loss": 0.4344651997089386
    },
    {
      "classification_loss": 0.49386581778526306,
      "epoch": 18.84918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5749,
      "total_loss": 0.49386581778526306
    },
    {
      "classification_loss": 0.44231268763542175,
      "epoch": 18.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5750,
      "total_loss": 0.44231268763542175
    },
    {
      "classification_loss": 0.4965922236442566,
      "epoch": 18.855737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5751,
      "total_loss": 0.4965922236442566
    },
    {
      "classification_loss": 0.46824273467063904,
      "epoch": 18.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5752,
      "total_loss": 0.46824273467063904
    },
    {
      "classification_loss": 0.5052793025970459,
      "epoch": 18.862295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5753,
      "total_loss": 0.5052793025970459
    },
    {
      "classification_loss": 0.49114879965782166,
      "epoch": 18.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5754,
      "total_loss": 0.49114879965782166
    },
    {
      "classification_loss": 0.3830888867378235,
      "epoch": 18.868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5755,
      "total_loss": 0.3830888867378235
    },
    {
      "classification_loss": 0.5144221782684326,
      "epoch": 18.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5756,
      "total_loss": 0.5144221782684326
    },
    {
      "classification_loss": 0.4495869278907776,
      "epoch": 18.875409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5757,
      "total_loss": 0.4495869278907776
    },
    {
      "classification_loss": 0.5399996042251587,
      "epoch": 18.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5758,
      "total_loss": 0.5399996042251587
    },
    {
      "classification_loss": 0.40245869755744934,
      "epoch": 18.881967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5759,
      "total_loss": 0.40245869755744934
    },
    {
      "classification_loss": 0.4990921914577484,
      "epoch": 18.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5760,
      "total_loss": 0.4990921914577484
    },
    {
      "classification_loss": 0.5262149572372437,
      "epoch": 18.888524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5761,
      "total_loss": 0.5262149572372437
    },
    {
      "classification_loss": 0.4264305531978607,
      "epoch": 18.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5762,
      "total_loss": 0.4264305531978607
    },
    {
      "classification_loss": 0.38013702630996704,
      "epoch": 18.895081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5763,
      "total_loss": 0.38013702630996704
    },
    {
      "classification_loss": 0.46108919382095337,
      "epoch": 18.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5764,
      "total_loss": 0.46108919382095337
    },
    {
      "classification_loss": 0.33909285068511963,
      "epoch": 18.901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5765,
      "total_loss": 0.33909285068511963
    },
    {
      "classification_loss": 0.4666285216808319,
      "epoch": 18.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5766,
      "total_loss": 0.4666285216808319
    },
    {
      "classification_loss": 0.5394782423973083,
      "epoch": 18.908196721311477,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5767,
      "total_loss": 0.5394782423973083
    },
    {
      "classification_loss": 0.4824797809123993,
      "epoch": 18.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5768,
      "total_loss": 0.4824797809123993
    },
    {
      "classification_loss": 0.5575457215309143,
      "epoch": 18.914754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5769,
      "total_loss": 0.5575457215309143
    },
    {
      "classification_loss": 0.4246596693992615,
      "epoch": 18.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5770,
      "total_loss": 0.4246596693992615
    },
    {
      "classification_loss": 0.36669644713401794,
      "epoch": 18.921311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5771,
      "total_loss": 0.36669644713401794
    },
    {
      "classification_loss": 0.48421841859817505,
      "epoch": 18.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5772,
      "total_loss": 0.48421841859817505
    },
    {
      "classification_loss": 0.49068334698677063,
      "epoch": 18.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5773,
      "total_loss": 0.49068334698677063
    },
    {
      "classification_loss": 0.43392425775527954,
      "epoch": 18.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5774,
      "total_loss": 0.43392425775527954
    },
    {
      "classification_loss": 0.4442704916000366,
      "epoch": 18.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5775,
      "total_loss": 0.4442704916000366
    },
    {
      "classification_loss": 0.4595470130443573,
      "epoch": 18.937704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5776,
      "total_loss": 0.4595470130443573
    },
    {
      "classification_loss": 0.48787403106689453,
      "epoch": 18.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5777,
      "total_loss": 0.48787403106689453
    },
    {
      "classification_loss": 0.37816914916038513,
      "epoch": 18.944262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5778,
      "total_loss": 0.37816914916038513
    },
    {
      "classification_loss": 0.5996030569076538,
      "epoch": 18.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5779,
      "total_loss": 0.5996030569076538
    },
    {
      "classification_loss": 0.4601547122001648,
      "epoch": 18.950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5780,
      "total_loss": 0.4601547122001648
    },
    {
      "classification_loss": 0.5412896275520325,
      "epoch": 18.95409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5781,
      "total_loss": 0.5412896275520325
    },
    {
      "classification_loss": 0.47833141684532166,
      "epoch": 18.957377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5782,
      "total_loss": 0.47833141684532166
    },
    {
      "classification_loss": 0.42799919843673706,
      "epoch": 18.96065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5783,
      "total_loss": 0.42799919843673706
    },
    {
      "classification_loss": 0.4185839295387268,
      "epoch": 18.963934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5784,
      "total_loss": 0.4185839295387268
    },
    {
      "classification_loss": 0.5562061667442322,
      "epoch": 18.9672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5785,
      "total_loss": 0.5562061667442322
    },
    {
      "classification_loss": 0.4740140438079834,
      "epoch": 18.970491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5786,
      "total_loss": 0.4740140438079834
    },
    {
      "classification_loss": 0.508794903755188,
      "epoch": 18.97377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5787,
      "total_loss": 0.508794903755188
    },
    {
      "classification_loss": 0.45349910855293274,
      "epoch": 18.977049180327867,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5788,
      "total_loss": 0.45349910855293274
    },
    {
      "classification_loss": 0.45491355657577515,
      "epoch": 18.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5789,
      "total_loss": 0.45491355657577515
    },
    {
      "classification_loss": 0.5901339650154114,
      "epoch": 18.983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5790,
      "total_loss": 0.5901339650154114
    },
    {
      "classification_loss": 0.4316595196723938,
      "epoch": 18.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5791,
      "total_loss": 0.4316595196723938
    },
    {
      "classification_loss": 0.37617647647857666,
      "epoch": 18.990163934426228,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5792,
      "total_loss": 0.37617647647857666
    },
    {
      "classification_loss": 0.6910113096237183,
      "epoch": 18.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5793,
      "total_loss": 0.6910113096237183
    },
    {
      "classification_loss": 0.46666356921195984,
      "epoch": 18.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5794,
      "total_loss": 0.46666356921195984
    },
    {
      "classification_loss": 1.545915961265564,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.545915961265564
    },
    {
      "classification_loss": 1.4650951623916626,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.4650951623916626
    },
    {
      "classification_loss": 1.3435710668563843,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.3435710668563843
    },
    {
      "classification_loss": 1.6765425205230713,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.6765425205230713
    },
    {
      "classification_loss": 1.3696420192718506,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.3696420192718506
    },
    {
      "classification_loss": 1.3597959280014038,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.3597959280014038
    },
    {
      "classification_loss": 1.4507495164871216,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.4507495164871216
    },
    {
      "classification_loss": 1.221484661102295,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 1.221484661102295
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.4340825080871582,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 5.9922,
      "eval_samples_per_second": 166.883,
      "eval_steps_per_second": 1.335,
      "step": 5795
    },
    {
      "classification_loss": 0.4847141206264496,
      "epoch": 19.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5795,
      "total_loss": 0.4847141206264496
    },
    {
      "classification_loss": 0.5197320580482483,
      "epoch": 19.003278688524592,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5796,
      "total_loss": 0.5197320580482483
    },
    {
      "classification_loss": 0.5127207040786743,
      "epoch": 19.00655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5797,
      "total_loss": 0.5127207040786743
    },
    {
      "classification_loss": 0.42335009574890137,
      "epoch": 19.009836065573772,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5798,
      "total_loss": 0.42335009574890137
    },
    {
      "classification_loss": 0.40663987398147583,
      "epoch": 19.01311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5799,
      "total_loss": 0.40663987398147583
    },
    {
      "epoch": 19.016393442622952,
      "grad_norm": 3.4098520278930664,
      "learning_rate": 1.0033333333333333e-05,
      "loss": 0.466,
      "step": 5800
    },
    {
      "classification_loss": 0.4812277555465698,
      "epoch": 19.016393442622952,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5800,
      "total_loss": 0.4812277555465698
    },
    {
      "classification_loss": 0.4609237611293793,
      "epoch": 19.01967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5801,
      "total_loss": 0.4609237611293793
    },
    {
      "classification_loss": 0.42338311672210693,
      "epoch": 19.022950819672133,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5802,
      "total_loss": 0.42338311672210693
    },
    {
      "classification_loss": 0.5175145864486694,
      "epoch": 19.02622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5803,
      "total_loss": 0.5175145864486694
    },
    {
      "classification_loss": 0.387667715549469,
      "epoch": 19.029508196721313,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5804,
      "total_loss": 0.387667715549469
    },
    {
      "classification_loss": 0.44602006673812866,
      "epoch": 19.0327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5805,
      "total_loss": 0.44602006673812866
    },
    {
      "classification_loss": 0.5545164346694946,
      "epoch": 19.036065573770493,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5806,
      "total_loss": 0.5545164346694946
    },
    {
      "classification_loss": 0.4268186688423157,
      "epoch": 19.03934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5807,
      "total_loss": 0.4268186688423157
    },
    {
      "classification_loss": 0.5301452279090881,
      "epoch": 19.042622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5808,
      "total_loss": 0.5301452279090881
    },
    {
      "classification_loss": 0.4856853187084198,
      "epoch": 19.04590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5809,
      "total_loss": 0.4856853187084198
    },
    {
      "classification_loss": 0.5316203236579895,
      "epoch": 19.049180327868854,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5810,
      "total_loss": 0.5316203236579895
    },
    {
      "classification_loss": 0.5045124292373657,
      "epoch": 19.052459016393442,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5811,
      "total_loss": 0.5045124292373657
    },
    {
      "classification_loss": 0.48285990953445435,
      "epoch": 19.055737704918034,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5812,
      "total_loss": 0.48285990953445435
    },
    {
      "classification_loss": 0.4473079442977905,
      "epoch": 19.059016393442622,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5813,
      "total_loss": 0.4473079442977905
    },
    {
      "classification_loss": 0.38079676032066345,
      "epoch": 19.062295081967214,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5814,
      "total_loss": 0.38079676032066345
    },
    {
      "classification_loss": 0.5105040073394775,
      "epoch": 19.065573770491802,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5815,
      "total_loss": 0.5105040073394775
    },
    {
      "classification_loss": 0.4780680239200592,
      "epoch": 19.068852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5816,
      "total_loss": 0.4780680239200592
    },
    {
      "classification_loss": 0.39677155017852783,
      "epoch": 19.072131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5817,
      "total_loss": 0.39677155017852783
    },
    {
      "classification_loss": 0.47927162051200867,
      "epoch": 19.075409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5818,
      "total_loss": 0.47927162051200867
    },
    {
      "classification_loss": 0.4978698790073395,
      "epoch": 19.078688524590163,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5819,
      "total_loss": 0.4978698790073395
    },
    {
      "classification_loss": 0.4912640154361725,
      "epoch": 19.081967213114755,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5820,
      "total_loss": 0.4912640154361725
    },
    {
      "classification_loss": 0.512136697769165,
      "epoch": 19.085245901639343,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5821,
      "total_loss": 0.512136697769165
    },
    {
      "classification_loss": 0.5514649748802185,
      "epoch": 19.088524590163935,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5822,
      "total_loss": 0.5514649748802185
    },
    {
      "classification_loss": 0.3804815113544464,
      "epoch": 19.091803278688523,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5823,
      "total_loss": 0.3804815113544464
    },
    {
      "classification_loss": 0.6366591453552246,
      "epoch": 19.095081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5824,
      "total_loss": 0.6366591453552246
    },
    {
      "classification_loss": 0.4772854745388031,
      "epoch": 19.098360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5825,
      "total_loss": 0.4772854745388031
    },
    {
      "classification_loss": 0.41522717475891113,
      "epoch": 19.101639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5826,
      "total_loss": 0.41522717475891113
    },
    {
      "classification_loss": 0.41780439019203186,
      "epoch": 19.104918032786884,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5827,
      "total_loss": 0.41780439019203186
    },
    {
      "classification_loss": 0.4202738106250763,
      "epoch": 19.108196721311476,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5828,
      "total_loss": 0.4202738106250763
    },
    {
      "classification_loss": 0.36687469482421875,
      "epoch": 19.111475409836064,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5829,
      "total_loss": 0.36687469482421875
    },
    {
      "classification_loss": 0.43264132738113403,
      "epoch": 19.114754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5830,
      "total_loss": 0.43264132738113403
    },
    {
      "classification_loss": 0.3738546371459961,
      "epoch": 19.118032786885244,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5831,
      "total_loss": 0.3738546371459961
    },
    {
      "classification_loss": 0.5065003037452698,
      "epoch": 19.121311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5832,
      "total_loss": 0.5065003037452698
    },
    {
      "classification_loss": 0.4305970370769501,
      "epoch": 19.124590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5833,
      "total_loss": 0.4305970370769501
    },
    {
      "classification_loss": 0.36232033371925354,
      "epoch": 19.127868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5834,
      "total_loss": 0.36232033371925354
    },
    {
      "classification_loss": 0.4058896005153656,
      "epoch": 19.131147540983605,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5835,
      "total_loss": 0.4058896005153656
    },
    {
      "classification_loss": 0.5243097543716431,
      "epoch": 19.134426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5836,
      "total_loss": 0.5243097543716431
    },
    {
      "classification_loss": 0.33951911330223083,
      "epoch": 19.137704918032785,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5837,
      "total_loss": 0.33951911330223083
    },
    {
      "classification_loss": 0.5787753462791443,
      "epoch": 19.140983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5838,
      "total_loss": 0.5787753462791443
    },
    {
      "classification_loss": 0.4908762276172638,
      "epoch": 19.14426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5839,
      "total_loss": 0.4908762276172638
    },
    {
      "classification_loss": 0.6050299406051636,
      "epoch": 19.147540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5840,
      "total_loss": 0.6050299406051636
    },
    {
      "classification_loss": 0.5325596928596497,
      "epoch": 19.15081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5841,
      "total_loss": 0.5325596928596497
    },
    {
      "classification_loss": 0.4833814203739166,
      "epoch": 19.154098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5842,
      "total_loss": 0.4833814203739166
    },
    {
      "classification_loss": 0.4510138928890228,
      "epoch": 19.15737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5843,
      "total_loss": 0.4510138928890228
    },
    {
      "classification_loss": 0.6255303621292114,
      "epoch": 19.160655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5844,
      "total_loss": 0.6255303621292114
    },
    {
      "classification_loss": 0.46164852380752563,
      "epoch": 19.16393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5845,
      "total_loss": 0.46164852380752563
    },
    {
      "classification_loss": 0.5334187150001526,
      "epoch": 19.167213114754098,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5846,
      "total_loss": 0.5334187150001526
    },
    {
      "classification_loss": 0.4636446237564087,
      "epoch": 19.17049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5847,
      "total_loss": 0.4636446237564087
    },
    {
      "classification_loss": 0.3450357913970947,
      "epoch": 19.17377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5848,
      "total_loss": 0.3450357913970947
    },
    {
      "classification_loss": 0.5987936854362488,
      "epoch": 19.17704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5849,
      "total_loss": 0.5987936854362488
    },
    {
      "classification_loss": 0.5248106718063354,
      "epoch": 19.18032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5850,
      "total_loss": 0.5248106718063354
    },
    {
      "classification_loss": 0.465300053358078,
      "epoch": 19.18360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5851,
      "total_loss": 0.465300053358078
    },
    {
      "classification_loss": 0.5666468739509583,
      "epoch": 19.18688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5852,
      "total_loss": 0.5666468739509583
    },
    {
      "classification_loss": 0.40902844071388245,
      "epoch": 19.19016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5853,
      "total_loss": 0.40902844071388245
    },
    {
      "classification_loss": 0.45832687616348267,
      "epoch": 19.19344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5854,
      "total_loss": 0.45832687616348267
    },
    {
      "classification_loss": 0.37878480553627014,
      "epoch": 19.19672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5855,
      "total_loss": 0.37878480553627014
    },
    {
      "classification_loss": 0.3057820498943329,
      "epoch": 19.2,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5856,
      "total_loss": 0.3057820498943329
    },
    {
      "classification_loss": 0.5118296146392822,
      "epoch": 19.20327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5857,
      "total_loss": 0.5118296146392822
    },
    {
      "classification_loss": 0.5206108093261719,
      "epoch": 19.20655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5858,
      "total_loss": 0.5206108093261719
    },
    {
      "classification_loss": 0.49839237332344055,
      "epoch": 19.20983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5859,
      "total_loss": 0.49839237332344055
    },
    {
      "classification_loss": 0.3823481500148773,
      "epoch": 19.21311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5860,
      "total_loss": 0.3823481500148773
    },
    {
      "classification_loss": 0.45141297578811646,
      "epoch": 19.21639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5861,
      "total_loss": 0.45141297578811646
    },
    {
      "classification_loss": 0.41425013542175293,
      "epoch": 19.21967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5862,
      "total_loss": 0.41425013542175293
    },
    {
      "classification_loss": 0.4625050127506256,
      "epoch": 19.222950819672132,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5863,
      "total_loss": 0.4625050127506256
    },
    {
      "classification_loss": 0.362887978553772,
      "epoch": 19.22622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5864,
      "total_loss": 0.362887978553772
    },
    {
      "classification_loss": 0.49525564908981323,
      "epoch": 19.229508196721312,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5865,
      "total_loss": 0.49525564908981323
    },
    {
      "classification_loss": 0.4093920886516571,
      "epoch": 19.2327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5866,
      "total_loss": 0.4093920886516571
    },
    {
      "classification_loss": 0.4318031966686249,
      "epoch": 19.236065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5867,
      "total_loss": 0.4318031966686249
    },
    {
      "classification_loss": 0.46535974740982056,
      "epoch": 19.23934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5868,
      "total_loss": 0.46535974740982056
    },
    {
      "classification_loss": 0.47753992676734924,
      "epoch": 19.242622950819673,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5869,
      "total_loss": 0.47753992676734924
    },
    {
      "classification_loss": 0.3910823166370392,
      "epoch": 19.24590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5870,
      "total_loss": 0.3910823166370392
    },
    {
      "classification_loss": 0.3846420645713806,
      "epoch": 19.249180327868853,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5871,
      "total_loss": 0.3846420645713806
    },
    {
      "classification_loss": 0.5701876282691956,
      "epoch": 19.25245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5872,
      "total_loss": 0.5701876282691956
    },
    {
      "classification_loss": 0.4946642220020294,
      "epoch": 19.255737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5873,
      "total_loss": 0.4946642220020294
    },
    {
      "classification_loss": 0.4889811873435974,
      "epoch": 19.25901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5874,
      "total_loss": 0.4889811873435974
    },
    {
      "classification_loss": 0.36517760157585144,
      "epoch": 19.262295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5875,
      "total_loss": 0.36517760157585144
    },
    {
      "classification_loss": 0.4055981934070587,
      "epoch": 19.2655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5876,
      "total_loss": 0.4055981934070587
    },
    {
      "classification_loss": 0.4163752496242523,
      "epoch": 19.268852459016394,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5877,
      "total_loss": 0.4163752496242523
    },
    {
      "classification_loss": 0.43821603059768677,
      "epoch": 19.272131147540982,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5878,
      "total_loss": 0.43821603059768677
    },
    {
      "classification_loss": 0.5351380109786987,
      "epoch": 19.275409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5879,
      "total_loss": 0.5351380109786987
    },
    {
      "classification_loss": 0.42080819606781006,
      "epoch": 19.278688524590162,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5880,
      "total_loss": 0.42080819606781006
    },
    {
      "classification_loss": 0.3975846767425537,
      "epoch": 19.281967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5881,
      "total_loss": 0.3975846767425537
    },
    {
      "classification_loss": 0.4337548613548279,
      "epoch": 19.285245901639342,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5882,
      "total_loss": 0.4337548613548279
    },
    {
      "classification_loss": 0.4652513861656189,
      "epoch": 19.288524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5883,
      "total_loss": 0.4652513861656189
    },
    {
      "classification_loss": 0.6121243834495544,
      "epoch": 19.291803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5884,
      "total_loss": 0.6121243834495544
    },
    {
      "classification_loss": 0.4301532804965973,
      "epoch": 19.295081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5885,
      "total_loss": 0.4301532804965973
    },
    {
      "classification_loss": 0.5095504522323608,
      "epoch": 19.298360655737707,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5886,
      "total_loss": 0.5095504522323608
    },
    {
      "classification_loss": 0.3942551910877228,
      "epoch": 19.301639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5887,
      "total_loss": 0.3942551910877228
    },
    {
      "classification_loss": 0.5751380324363708,
      "epoch": 19.304918032786887,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5888,
      "total_loss": 0.5751380324363708
    },
    {
      "classification_loss": 0.41599026322364807,
      "epoch": 19.308196721311475,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5889,
      "total_loss": 0.41599026322364807
    },
    {
      "classification_loss": 0.4007621109485626,
      "epoch": 19.311475409836067,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5890,
      "total_loss": 0.4007621109485626
    },
    {
      "classification_loss": 0.37470149993896484,
      "epoch": 19.314754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5891,
      "total_loss": 0.37470149993896484
    },
    {
      "classification_loss": 0.4203820824623108,
      "epoch": 19.318032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5892,
      "total_loss": 0.4203820824623108
    },
    {
      "classification_loss": 0.4233737587928772,
      "epoch": 19.321311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5893,
      "total_loss": 0.4233737587928772
    },
    {
      "classification_loss": 0.5256143808364868,
      "epoch": 19.324590163934428,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5894,
      "total_loss": 0.5256143808364868
    },
    {
      "classification_loss": 0.45832473039627075,
      "epoch": 19.327868852459016,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5895,
      "total_loss": 0.45832473039627075
    },
    {
      "classification_loss": 0.5463660359382629,
      "epoch": 19.331147540983608,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5896,
      "total_loss": 0.5463660359382629
    },
    {
      "classification_loss": 0.5749096870422363,
      "epoch": 19.334426229508196,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5897,
      "total_loss": 0.5749096870422363
    },
    {
      "classification_loss": 0.40362730622291565,
      "epoch": 19.337704918032788,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5898,
      "total_loss": 0.40362730622291565
    },
    {
      "classification_loss": 0.5280327796936035,
      "epoch": 19.340983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5899,
      "total_loss": 0.5280327796936035
    },
    {
      "epoch": 19.34426229508197,
      "grad_norm": 2.7846832275390625,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.4643,
      "step": 5900
    },
    {
      "classification_loss": 0.4212372899055481,
      "epoch": 19.34426229508197,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5900,
      "total_loss": 0.4212372899055481
    },
    {
      "classification_loss": 0.38974931836128235,
      "epoch": 19.347540983606557,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5901,
      "total_loss": 0.38974931836128235
    },
    {
      "classification_loss": 0.5581997632980347,
      "epoch": 19.35081967213115,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5902,
      "total_loss": 0.5581997632980347
    },
    {
      "classification_loss": 0.4795430302619934,
      "epoch": 19.354098360655737,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5903,
      "total_loss": 0.4795430302619934
    },
    {
      "classification_loss": 0.5934224724769592,
      "epoch": 19.35737704918033,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5904,
      "total_loss": 0.5934224724769592
    },
    {
      "classification_loss": 0.5252591371536255,
      "epoch": 19.360655737704917,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5905,
      "total_loss": 0.5252591371536255
    },
    {
      "classification_loss": 0.6058127284049988,
      "epoch": 19.36393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5906,
      "total_loss": 0.6058127284049988
    },
    {
      "classification_loss": 0.5327238440513611,
      "epoch": 19.367213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5907,
      "total_loss": 0.5327238440513611
    },
    {
      "classification_loss": 0.45013752579689026,
      "epoch": 19.37049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5908,
      "total_loss": 0.45013752579689026
    },
    {
      "classification_loss": 0.41970664262771606,
      "epoch": 19.373770491803278,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5909,
      "total_loss": 0.41970664262771606
    },
    {
      "classification_loss": 0.43600666522979736,
      "epoch": 19.37704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5910,
      "total_loss": 0.43600666522979736
    },
    {
      "classification_loss": 0.4770912230014801,
      "epoch": 19.380327868852458,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5911,
      "total_loss": 0.4770912230014801
    },
    {
      "classification_loss": 0.3898630440235138,
      "epoch": 19.38360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5912,
      "total_loss": 0.3898630440235138
    },
    {
      "classification_loss": 0.5254225730895996,
      "epoch": 19.386885245901638,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5913,
      "total_loss": 0.5254225730895996
    },
    {
      "classification_loss": 0.39629796147346497,
      "epoch": 19.39016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5914,
      "total_loss": 0.39629796147346497
    },
    {
      "classification_loss": 0.4886291027069092,
      "epoch": 19.39344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5915,
      "total_loss": 0.4886291027069092
    },
    {
      "classification_loss": 0.4573362171649933,
      "epoch": 19.39672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5916,
      "total_loss": 0.4573362171649933
    },
    {
      "classification_loss": 0.5184230804443359,
      "epoch": 19.4,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5917,
      "total_loss": 0.5184230804443359
    },
    {
      "classification_loss": 0.4225793480873108,
      "epoch": 19.40327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5918,
      "total_loss": 0.4225793480873108
    },
    {
      "classification_loss": 0.5796886682510376,
      "epoch": 19.40655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5919,
      "total_loss": 0.5796886682510376
    },
    {
      "classification_loss": 0.47202882170677185,
      "epoch": 19.40983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5920,
      "total_loss": 0.47202882170677185
    },
    {
      "classification_loss": 0.6147792935371399,
      "epoch": 19.41311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5921,
      "total_loss": 0.6147792935371399
    },
    {
      "classification_loss": 0.41817712783813477,
      "epoch": 19.41639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5922,
      "total_loss": 0.41817712783813477
    },
    {
      "classification_loss": 0.5388143658638,
      "epoch": 19.41967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5923,
      "total_loss": 0.5388143658638
    },
    {
      "classification_loss": 0.4958069622516632,
      "epoch": 19.42295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5924,
      "total_loss": 0.4958069622516632
    },
    {
      "classification_loss": 0.4848097860813141,
      "epoch": 19.42622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5925,
      "total_loss": 0.4848097860813141
    },
    {
      "classification_loss": 0.39887917041778564,
      "epoch": 19.42950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5926,
      "total_loss": 0.39887917041778564
    },
    {
      "classification_loss": 0.46477270126342773,
      "epoch": 19.432786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5927,
      "total_loss": 0.46477270126342773
    },
    {
      "classification_loss": 0.4616924822330475,
      "epoch": 19.43606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5928,
      "total_loss": 0.4616924822330475
    },
    {
      "classification_loss": 0.5170417428016663,
      "epoch": 19.439344262295084,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5929,
      "total_loss": 0.5170417428016663
    },
    {
      "classification_loss": 0.4058936536312103,
      "epoch": 19.442622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5930,
      "total_loss": 0.4058936536312103
    },
    {
      "classification_loss": 0.5356823801994324,
      "epoch": 19.445901639344264,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5931,
      "total_loss": 0.5356823801994324
    },
    {
      "classification_loss": 0.4165589213371277,
      "epoch": 19.449180327868852,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5932,
      "total_loss": 0.4165589213371277
    },
    {
      "classification_loss": 0.553577721118927,
      "epoch": 19.452459016393444,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5933,
      "total_loss": 0.553577721118927
    },
    {
      "classification_loss": 0.37236469984054565,
      "epoch": 19.455737704918032,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5934,
      "total_loss": 0.37236469984054565
    },
    {
      "classification_loss": 0.4725996255874634,
      "epoch": 19.459016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5935,
      "total_loss": 0.4725996255874634
    },
    {
      "classification_loss": 0.3733232915401459,
      "epoch": 19.462295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5936,
      "total_loss": 0.3733232915401459
    },
    {
      "classification_loss": 0.377899169921875,
      "epoch": 19.465573770491805,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5937,
      "total_loss": 0.377899169921875
    },
    {
      "classification_loss": 0.5230599045753479,
      "epoch": 19.468852459016393,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5938,
      "total_loss": 0.5230599045753479
    },
    {
      "classification_loss": 0.5617079138755798,
      "epoch": 19.472131147540985,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5939,
      "total_loss": 0.5617079138755798
    },
    {
      "classification_loss": 0.41551223397254944,
      "epoch": 19.475409836065573,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5940,
      "total_loss": 0.41551223397254944
    },
    {
      "classification_loss": 0.4591449201107025,
      "epoch": 19.478688524590165,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5941,
      "total_loss": 0.4591449201107025
    },
    {
      "classification_loss": 0.3052065670490265,
      "epoch": 19.481967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5942,
      "total_loss": 0.3052065670490265
    },
    {
      "classification_loss": 0.41652166843414307,
      "epoch": 19.485245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5943,
      "total_loss": 0.41652166843414307
    },
    {
      "classification_loss": 0.49445196986198425,
      "epoch": 19.488524590163934,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5944,
      "total_loss": 0.49445196986198425
    },
    {
      "classification_loss": 0.4750974178314209,
      "epoch": 19.491803278688526,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5945,
      "total_loss": 0.4750974178314209
    },
    {
      "classification_loss": 0.5207602381706238,
      "epoch": 19.495081967213114,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5946,
      "total_loss": 0.5207602381706238
    },
    {
      "classification_loss": 0.5082443952560425,
      "epoch": 19.498360655737706,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5947,
      "total_loss": 0.5082443952560425
    },
    {
      "classification_loss": 0.37491458654403687,
      "epoch": 19.501639344262294,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5948,
      "total_loss": 0.37491458654403687
    },
    {
      "classification_loss": 0.506957471370697,
      "epoch": 19.504918032786886,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5949,
      "total_loss": 0.506957471370697
    },
    {
      "classification_loss": 0.4660152494907379,
      "epoch": 19.508196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5950,
      "total_loss": 0.4660152494907379
    },
    {
      "classification_loss": 0.47162914276123047,
      "epoch": 19.511475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5951,
      "total_loss": 0.47162914276123047
    },
    {
      "classification_loss": 0.5107061862945557,
      "epoch": 19.514754098360655,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5952,
      "total_loss": 0.5107061862945557
    },
    {
      "classification_loss": 0.4788253903388977,
      "epoch": 19.518032786885247,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5953,
      "total_loss": 0.4788253903388977
    },
    {
      "classification_loss": 0.50895094871521,
      "epoch": 19.521311475409835,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5954,
      "total_loss": 0.50895094871521
    },
    {
      "classification_loss": 0.4619347155094147,
      "epoch": 19.524590163934427,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5955,
      "total_loss": 0.4619347155094147
    },
    {
      "classification_loss": 0.5740430355072021,
      "epoch": 19.527868852459015,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5956,
      "total_loss": 0.5740430355072021
    },
    {
      "classification_loss": 0.4863283634185791,
      "epoch": 19.531147540983607,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5957,
      "total_loss": 0.4863283634185791
    },
    {
      "classification_loss": 0.46428680419921875,
      "epoch": 19.534426229508195,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5958,
      "total_loss": 0.46428680419921875
    },
    {
      "classification_loss": 0.4318215847015381,
      "epoch": 19.537704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5959,
      "total_loss": 0.4318215847015381
    },
    {
      "classification_loss": 0.5479898452758789,
      "epoch": 19.540983606557376,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5960,
      "total_loss": 0.5479898452758789
    },
    {
      "classification_loss": 0.5644268989562988,
      "epoch": 19.544262295081968,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5961,
      "total_loss": 0.5644268989562988
    },
    {
      "classification_loss": 0.5331751704216003,
      "epoch": 19.547540983606556,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5962,
      "total_loss": 0.5331751704216003
    },
    {
      "classification_loss": 0.38382261991500854,
      "epoch": 19.550819672131148,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5963,
      "total_loss": 0.38382261991500854
    },
    {
      "classification_loss": 0.4298354387283325,
      "epoch": 19.554098360655736,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5964,
      "total_loss": 0.4298354387283325
    },
    {
      "classification_loss": 0.4505774974822998,
      "epoch": 19.557377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5965,
      "total_loss": 0.4505774974822998
    },
    {
      "classification_loss": 0.4665068984031677,
      "epoch": 19.560655737704916,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5966,
      "total_loss": 0.4665068984031677
    },
    {
      "classification_loss": 0.49408456683158875,
      "epoch": 19.56393442622951,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5967,
      "total_loss": 0.49408456683158875
    },
    {
      "classification_loss": 0.4742424488067627,
      "epoch": 19.567213114754097,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5968,
      "total_loss": 0.4742424488067627
    },
    {
      "classification_loss": 0.3630821108818054,
      "epoch": 19.57049180327869,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5969,
      "total_loss": 0.3630821108818054
    },
    {
      "classification_loss": 0.39157530665397644,
      "epoch": 19.57377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5970,
      "total_loss": 0.39157530665397644
    },
    {
      "classification_loss": 0.38445600867271423,
      "epoch": 19.57704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5971,
      "total_loss": 0.38445600867271423
    },
    {
      "classification_loss": 0.41998666524887085,
      "epoch": 19.58032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5972,
      "total_loss": 0.41998666524887085
    },
    {
      "classification_loss": 0.4117746651172638,
      "epoch": 19.58360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5973,
      "total_loss": 0.4117746651172638
    },
    {
      "classification_loss": 0.39587798714637756,
      "epoch": 19.58688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5974,
      "total_loss": 0.39587798714637756
    },
    {
      "classification_loss": 0.49680137634277344,
      "epoch": 19.59016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5975,
      "total_loss": 0.49680137634277344
    },
    {
      "classification_loss": 0.4270191192626953,
      "epoch": 19.59344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5976,
      "total_loss": 0.4270191192626953
    },
    {
      "classification_loss": 0.4785918593406677,
      "epoch": 19.59672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5977,
      "total_loss": 0.4785918593406677
    },
    {
      "classification_loss": 0.5647954344749451,
      "epoch": 19.6,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5978,
      "total_loss": 0.5647954344749451
    },
    {
      "classification_loss": 0.4769999384880066,
      "epoch": 19.60327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5979,
      "total_loss": 0.4769999384880066
    },
    {
      "classification_loss": 0.36878693103790283,
      "epoch": 19.60655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5980,
      "total_loss": 0.36878693103790283
    },
    {
      "classification_loss": 0.4222903549671173,
      "epoch": 19.60983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5981,
      "total_loss": 0.4222903549671173
    },
    {
      "classification_loss": 0.41896751523017883,
      "epoch": 19.613114754098362,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5982,
      "total_loss": 0.41896751523017883
    },
    {
      "classification_loss": 0.48317426443099976,
      "epoch": 19.61639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5983,
      "total_loss": 0.48317426443099976
    },
    {
      "classification_loss": 0.5739313364028931,
      "epoch": 19.619672131147542,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5984,
      "total_loss": 0.5739313364028931
    },
    {
      "classification_loss": 0.4683982729911804,
      "epoch": 19.62295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5985,
      "total_loss": 0.4683982729911804
    },
    {
      "classification_loss": 0.5657175779342651,
      "epoch": 19.626229508196722,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5986,
      "total_loss": 0.5657175779342651
    },
    {
      "classification_loss": 0.3567749261856079,
      "epoch": 19.62950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5987,
      "total_loss": 0.3567749261856079
    },
    {
      "classification_loss": 0.43129098415374756,
      "epoch": 19.632786885245903,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5988,
      "total_loss": 0.43129098415374756
    },
    {
      "classification_loss": 0.4597230553627014,
      "epoch": 19.63606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5989,
      "total_loss": 0.4597230553627014
    },
    {
      "classification_loss": 0.2958490550518036,
      "epoch": 19.639344262295083,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5990,
      "total_loss": 0.2958490550518036
    },
    {
      "classification_loss": 0.43280377984046936,
      "epoch": 19.64262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5991,
      "total_loss": 0.43280377984046936
    },
    {
      "classification_loss": 0.5124136805534363,
      "epoch": 19.645901639344263,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5992,
      "total_loss": 0.5124136805534363
    },
    {
      "classification_loss": 0.4131426215171814,
      "epoch": 19.64918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5993,
      "total_loss": 0.4131426215171814
    },
    {
      "classification_loss": 0.4893035590648651,
      "epoch": 19.652459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5994,
      "total_loss": 0.4893035590648651
    },
    {
      "classification_loss": 0.4172961413860321,
      "epoch": 19.65573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5995,
      "total_loss": 0.4172961413860321
    },
    {
      "classification_loss": 0.46111059188842773,
      "epoch": 19.659016393442624,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5996,
      "total_loss": 0.46111059188842773
    },
    {
      "classification_loss": 0.6500391364097595,
      "epoch": 19.662295081967212,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5997,
      "total_loss": 0.6500391364097595
    },
    {
      "classification_loss": 0.4348096251487732,
      "epoch": 19.665573770491804,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5998,
      "total_loss": 0.4348096251487732
    },
    {
      "classification_loss": 0.5118321180343628,
      "epoch": 19.668852459016392,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 5999,
      "total_loss": 0.5118321180343628
    },
    {
      "epoch": 19.672131147540984,
      "grad_norm": 5.036592483520508,
      "learning_rate": 3.3666666666666665e-06,
      "loss": 0.4678,
      "step": 6000
    },
    {
      "classification_loss": 0.4678078293800354,
      "epoch": 19.672131147540984,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6000,
      "total_loss": 0.4678078293800354
    },
    {
      "classification_loss": 0.4796810746192932,
      "epoch": 19.675409836065572,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6001,
      "total_loss": 0.4796810746192932
    },
    {
      "classification_loss": 0.424893319606781,
      "epoch": 19.678688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6002,
      "total_loss": 0.424893319606781
    },
    {
      "classification_loss": 0.44459307193756104,
      "epoch": 19.681967213114753,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6003,
      "total_loss": 0.44459307193756104
    },
    {
      "classification_loss": 0.5265597105026245,
      "epoch": 19.685245901639345,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6004,
      "total_loss": 0.5265597105026245
    },
    {
      "classification_loss": 0.43081358075141907,
      "epoch": 19.688524590163933,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6005,
      "total_loss": 0.43081358075141907
    },
    {
      "classification_loss": 0.4401208758354187,
      "epoch": 19.691803278688525,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6006,
      "total_loss": 0.4401208758354187
    },
    {
      "classification_loss": 0.4345749020576477,
      "epoch": 19.695081967213113,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6007,
      "total_loss": 0.4345749020576477
    },
    {
      "classification_loss": 0.36923375725746155,
      "epoch": 19.698360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6008,
      "total_loss": 0.36923375725746155
    },
    {
      "classification_loss": 0.4716799259185791,
      "epoch": 19.701639344262293,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6009,
      "total_loss": 0.4716799259185791
    },
    {
      "classification_loss": 0.46181872487068176,
      "epoch": 19.704918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6010,
      "total_loss": 0.46181872487068176
    },
    {
      "classification_loss": 0.5882853865623474,
      "epoch": 19.708196721311474,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6011,
      "total_loss": 0.5882853865623474
    },
    {
      "classification_loss": 0.43357348442077637,
      "epoch": 19.711475409836066,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6012,
      "total_loss": 0.43357348442077637
    },
    {
      "classification_loss": 0.542316198348999,
      "epoch": 19.714754098360658,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6013,
      "total_loss": 0.542316198348999
    },
    {
      "classification_loss": 0.43633294105529785,
      "epoch": 19.718032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6014,
      "total_loss": 0.43633294105529785
    },
    {
      "classification_loss": 0.3667346239089966,
      "epoch": 19.721311475409838,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6015,
      "total_loss": 0.3667346239089966
    },
    {
      "classification_loss": 0.426570862531662,
      "epoch": 19.724590163934426,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6016,
      "total_loss": 0.426570862531662
    },
    {
      "classification_loss": 0.5063566565513611,
      "epoch": 19.727868852459018,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6017,
      "total_loss": 0.5063566565513611
    },
    {
      "classification_loss": 0.4277566969394684,
      "epoch": 19.731147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6018,
      "total_loss": 0.4277566969394684
    },
    {
      "classification_loss": 0.5958264470100403,
      "epoch": 19.7344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6019,
      "total_loss": 0.5958264470100403
    },
    {
      "classification_loss": 0.5372186303138733,
      "epoch": 19.737704918032787,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6020,
      "total_loss": 0.5372186303138733
    },
    {
      "classification_loss": 0.32741209864616394,
      "epoch": 19.74098360655738,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6021,
      "total_loss": 0.32741209864616394
    },
    {
      "classification_loss": 0.5818713307380676,
      "epoch": 19.744262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6022,
      "total_loss": 0.5818713307380676
    },
    {
      "classification_loss": 0.6682639122009277,
      "epoch": 19.74754098360656,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6023,
      "total_loss": 0.6682639122009277
    },
    {
      "classification_loss": 0.42697829008102417,
      "epoch": 19.750819672131147,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6024,
      "total_loss": 0.42697829008102417
    },
    {
      "classification_loss": 0.5078520774841309,
      "epoch": 19.75409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6025,
      "total_loss": 0.5078520774841309
    },
    {
      "classification_loss": 0.5737839341163635,
      "epoch": 19.757377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6026,
      "total_loss": 0.5737839341163635
    },
    {
      "classification_loss": 0.45598307251930237,
      "epoch": 19.76065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6027,
      "total_loss": 0.45598307251930237
    },
    {
      "classification_loss": 0.4054367244243622,
      "epoch": 19.763934426229508,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6028,
      "total_loss": 0.4054367244243622
    },
    {
      "classification_loss": 0.5177580118179321,
      "epoch": 19.7672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6029,
      "total_loss": 0.5177580118179321
    },
    {
      "classification_loss": 0.45947927236557007,
      "epoch": 19.770491803278688,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6030,
      "total_loss": 0.45947927236557007
    },
    {
      "classification_loss": 0.4701359272003174,
      "epoch": 19.77377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6031,
      "total_loss": 0.4701359272003174
    },
    {
      "classification_loss": 0.46669331192970276,
      "epoch": 19.777049180327868,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6032,
      "total_loss": 0.46669331192970276
    },
    {
      "classification_loss": 0.4460597038269043,
      "epoch": 19.78032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6033,
      "total_loss": 0.4460597038269043
    },
    {
      "classification_loss": 0.475806325674057,
      "epoch": 19.78360655737705,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6034,
      "total_loss": 0.475806325674057
    },
    {
      "classification_loss": 0.4165823459625244,
      "epoch": 19.78688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6035,
      "total_loss": 0.4165823459625244
    },
    {
      "classification_loss": 0.4466484785079956,
      "epoch": 19.79016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6036,
      "total_loss": 0.4466484785079956
    },
    {
      "classification_loss": 0.4210595190525055,
      "epoch": 19.79344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6037,
      "total_loss": 0.4210595190525055
    },
    {
      "classification_loss": 0.4832778871059418,
      "epoch": 19.79672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6038,
      "total_loss": 0.4832778871059418
    },
    {
      "classification_loss": 0.4876652956008911,
      "epoch": 19.8,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6039,
      "total_loss": 0.4876652956008911
    },
    {
      "classification_loss": 0.3770328462123871,
      "epoch": 19.80327868852459,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6040,
      "total_loss": 0.3770328462123871
    },
    {
      "classification_loss": 0.49401527643203735,
      "epoch": 19.80655737704918,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6041,
      "total_loss": 0.49401527643203735
    },
    {
      "classification_loss": 0.5037272572517395,
      "epoch": 19.80983606557377,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6042,
      "total_loss": 0.5037272572517395
    },
    {
      "classification_loss": 0.4611201882362366,
      "epoch": 19.81311475409836,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6043,
      "total_loss": 0.4611201882362366
    },
    {
      "classification_loss": 0.5616231560707092,
      "epoch": 19.81639344262295,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6044,
      "total_loss": 0.5616231560707092
    },
    {
      "classification_loss": 0.4923865795135498,
      "epoch": 19.81967213114754,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6045,
      "total_loss": 0.4923865795135498
    },
    {
      "classification_loss": 0.5172956585884094,
      "epoch": 19.82295081967213,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6046,
      "total_loss": 0.5172956585884094
    },
    {
      "classification_loss": 0.47352147102355957,
      "epoch": 19.82622950819672,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6047,
      "total_loss": 0.47352147102355957
    },
    {
      "classification_loss": 0.6028103232383728,
      "epoch": 19.82950819672131,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6048,
      "total_loss": 0.6028103232383728
    },
    {
      "classification_loss": 0.42873069643974304,
      "epoch": 19.832786885245902,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6049,
      "total_loss": 0.42873069643974304
    },
    {
      "classification_loss": 0.43040162324905396,
      "epoch": 19.83606557377049,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6050,
      "total_loss": 0.43040162324905396
    },
    {
      "classification_loss": 0.5258972644805908,
      "epoch": 19.839344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6051,
      "total_loss": 0.5258972644805908
    },
    {
      "classification_loss": 0.45048147439956665,
      "epoch": 19.84262295081967,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6052,
      "total_loss": 0.45048147439956665
    },
    {
      "classification_loss": 0.40132713317871094,
      "epoch": 19.845901639344262,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6053,
      "total_loss": 0.40132713317871094
    },
    {
      "classification_loss": 0.49949026107788086,
      "epoch": 19.84918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6054,
      "total_loss": 0.49949026107788086
    },
    {
      "classification_loss": 0.4893997311592102,
      "epoch": 19.852459016393443,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6055,
      "total_loss": 0.4893997311592102
    },
    {
      "classification_loss": 0.5165312886238098,
      "epoch": 19.855737704918035,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6056,
      "total_loss": 0.5165312886238098
    },
    {
      "classification_loss": 0.48692044615745544,
      "epoch": 19.859016393442623,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6057,
      "total_loss": 0.48692044615745544
    },
    {
      "classification_loss": 0.43771108984947205,
      "epoch": 19.862295081967215,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6058,
      "total_loss": 0.43771108984947205
    },
    {
      "classification_loss": 0.5033228397369385,
      "epoch": 19.865573770491803,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6059,
      "total_loss": 0.5033228397369385
    },
    {
      "classification_loss": 0.4422314465045929,
      "epoch": 19.868852459016395,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6060,
      "total_loss": 0.4422314465045929
    },
    {
      "classification_loss": 0.44823169708251953,
      "epoch": 19.872131147540983,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6061,
      "total_loss": 0.44823169708251953
    },
    {
      "classification_loss": 0.5414367914199829,
      "epoch": 19.875409836065575,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6062,
      "total_loss": 0.5414367914199829
    },
    {
      "classification_loss": 0.5709507465362549,
      "epoch": 19.878688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6063,
      "total_loss": 0.5709507465362549
    },
    {
      "classification_loss": 0.42398256063461304,
      "epoch": 19.881967213114756,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6064,
      "total_loss": 0.42398256063461304
    },
    {
      "classification_loss": 0.42906978726387024,
      "epoch": 19.885245901639344,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6065,
      "total_loss": 0.42906978726387024
    },
    {
      "classification_loss": 0.5116906762123108,
      "epoch": 19.888524590163936,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6066,
      "total_loss": 0.5116906762123108
    },
    {
      "classification_loss": 0.45146873593330383,
      "epoch": 19.891803278688524,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6067,
      "total_loss": 0.45146873593330383
    },
    {
      "classification_loss": 0.45466649532318115,
      "epoch": 19.895081967213116,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6068,
      "total_loss": 0.45466649532318115
    },
    {
      "classification_loss": 0.4691484272480011,
      "epoch": 19.898360655737704,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6069,
      "total_loss": 0.4691484272480011
    },
    {
      "classification_loss": 0.4875393211841583,
      "epoch": 19.901639344262296,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6070,
      "total_loss": 0.4875393211841583
    },
    {
      "classification_loss": 0.43563413619995117,
      "epoch": 19.904918032786885,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6071,
      "total_loss": 0.43563413619995117
    },
    {
      "classification_loss": 0.47912776470184326,
      "epoch": 19.908196721311477,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6072,
      "total_loss": 0.47912776470184326
    },
    {
      "classification_loss": 0.42273184657096863,
      "epoch": 19.911475409836065,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6073,
      "total_loss": 0.42273184657096863
    },
    {
      "classification_loss": 0.5173623561859131,
      "epoch": 19.914754098360657,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6074,
      "total_loss": 0.5173623561859131
    },
    {
      "classification_loss": 0.5220003128051758,
      "epoch": 19.918032786885245,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6075,
      "total_loss": 0.5220003128051758
    },
    {
      "classification_loss": 0.5958324670791626,
      "epoch": 19.921311475409837,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6076,
      "total_loss": 0.5958324670791626
    },
    {
      "classification_loss": 0.4118680953979492,
      "epoch": 19.924590163934425,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6077,
      "total_loss": 0.4118680953979492
    },
    {
      "classification_loss": 0.47078657150268555,
      "epoch": 19.927868852459017,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6078,
      "total_loss": 0.47078657150268555
    },
    {
      "classification_loss": 0.6149024367332458,
      "epoch": 19.931147540983606,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6079,
      "total_loss": 0.6149024367332458
    },
    {
      "classification_loss": 0.5664456486701965,
      "epoch": 19.934426229508198,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6080,
      "total_loss": 0.5664456486701965
    },
    {
      "classification_loss": 0.3996637463569641,
      "epoch": 19.937704918032786,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6081,
      "total_loss": 0.3996637463569641
    },
    {
      "classification_loss": 0.4692884087562561,
      "epoch": 19.940983606557378,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6082,
      "total_loss": 0.4692884087562561
    },
    {
      "classification_loss": 0.4933999180793762,
      "epoch": 19.944262295081966,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6083,
      "total_loss": 0.4933999180793762
    },
    {
      "classification_loss": 0.44965243339538574,
      "epoch": 19.947540983606558,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6084,
      "total_loss": 0.44965243339538574
    },
    {
      "classification_loss": 0.49675771594047546,
      "epoch": 19.950819672131146,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6085,
      "total_loss": 0.49675771594047546
    },
    {
      "classification_loss": 0.4125242829322815,
      "epoch": 19.95409836065574,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6086,
      "total_loss": 0.4125242829322815
    },
    {
      "classification_loss": 0.39104124903678894,
      "epoch": 19.957377049180327,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6087,
      "total_loss": 0.39104124903678894
    },
    {
      "classification_loss": 0.46324989199638367,
      "epoch": 19.96065573770492,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6088,
      "total_loss": 0.46324989199638367
    },
    {
      "classification_loss": 0.5197118520736694,
      "epoch": 19.963934426229507,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6089,
      "total_loss": 0.5197118520736694
    },
    {
      "classification_loss": 0.4713258743286133,
      "epoch": 19.9672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6090,
      "total_loss": 0.4713258743286133
    },
    {
      "classification_loss": 0.3999888300895691,
      "epoch": 19.970491803278687,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6091,
      "total_loss": 0.3999888300895691
    },
    {
      "classification_loss": 0.5611708760261536,
      "epoch": 19.97377049180328,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6092,
      "total_loss": 0.5611708760261536
    },
    {
      "classification_loss": 0.5189540386199951,
      "epoch": 19.977049180327867,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6093,
      "total_loss": 0.5189540386199951
    },
    {
      "classification_loss": 0.41848132014274597,
      "epoch": 19.98032786885246,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6094,
      "total_loss": 0.41848132014274597
    },
    {
      "classification_loss": 0.4452679455280304,
      "epoch": 19.983606557377048,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6095,
      "total_loss": 0.4452679455280304
    },
    {
      "classification_loss": 0.5942943096160889,
      "epoch": 19.98688524590164,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6096,
      "total_loss": 0.5942943096160889
    },
    {
      "classification_loss": 0.426236629486084,
      "epoch": 19.990163934426228,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6097,
      "total_loss": 0.426236629486084
    },
    {
      "classification_loss": 0.3319637179374695,
      "epoch": 19.99344262295082,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6098,
      "total_loss": 0.3319637179374695
    },
    {
      "classification_loss": 0.5717021226882935,
      "epoch": 19.99672131147541,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6099,
      "total_loss": 0.5717021226882935
    },
    {
      "epoch": 20.0,
      "grad_norm": 4.99998664855957,
      "learning_rate": 3.3333333333333334e-08,
      "loss": 0.4761,
      "step": 6100
    },
    {
      "classification_loss": 1.5475990772247314,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.5475990772247314
    },
    {
      "classification_loss": 1.4670475721359253,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.4670475721359253
    },
    {
      "classification_loss": 1.3456822633743286,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.3456822633743286
    },
    {
      "classification_loss": 1.6804102659225464,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.6804102659225464
    },
    {
      "classification_loss": 1.3731220960617065,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.3731220960617065
    },
    {
      "classification_loss": 1.3629499673843384,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.3629499673843384
    },
    {
      "classification_loss": 1.4533668756484985,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.4533668756484985
    },
    {
      "classification_loss": 1.2225991487503052,
      "epoch": 20.0,
      "mode": "LoRA",
      "orthogonal_loss": 0.0,
      "step": 6100,
      "total_loss": 1.2225991487503052
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.371,
      "eval_f1": 0.00631911532385466,
      "eval_loss": 1.4366130828857422,
      "eval_precision": 0.6666666666666666,
      "eval_recall": 0.0031746031746031746,
      "eval_runtime": 6.0305,
      "eval_samples_per_second": 165.825,
      "eval_steps_per_second": 1.327,
      "step": 6100
    }
  ],
  "logging_steps": 100,
  "max_steps": 6100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.565719179374592e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
